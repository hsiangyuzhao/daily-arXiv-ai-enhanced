<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 76]
- [cs.CL](#cs.CL) [Total: 53]
- [cs.LG](#cs.LG) [Total: 54]
- [cs.AI](#cs.AI) [Total: 18]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Leveraging Synthetic Priors for Monocular Depth Estimation in Specular Surgical Environments](https://arxiv.org/abs/2512.23786)
*Ankan Aich,Yangming Lee*

Main category: cs.CV

TL;DR: 本文提出一种基于深度先验的单目深度估计方法，用于解决微创手术中镜面和液体环境下的深度估计难题。通过引入高保真合成先验的Depth Anything V2架构，并采用动态向量低秩适配（DV-LORA）实现轻量化医学领域迁移，有效缓解了细小器械与透明表面的边界坍塌问题。同时设计了物理分层评估协议，在SCARED数据集上验证了在高反光条件下的优越性能，达到98.1%的准确率（<1.25）并降低17%以上的平方相对误差，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督方法依赖噪声较大的真实世界伪标签，难以在镜面、液态等复杂内窥镜环境下保持精确的深度估计，尤其对细小工具和透明表面存在边界坍塌问题。因此亟需更鲁棒且高效的深度估计方案以适应手术场景需求。

Method: 结合Depth Anything V2的高保真合成先验，利用动态向量低秩适配（DV-LORA）进行轻量级模型微调，实现从合成到真实医疗场景的有效迁移；同时构建物理分层评估协议，针对高反光环境进行精细化性能分析。

Result: 在SCARED数据集上，本方法达到98.1%的准确率（<1.25），相比基线方法减少超过17%的平方相对误差，在高反光条件下表现出更强的鲁棒性与精度。

Conclusion: 所提方法成功融合合成先验与轻量适配机制，显著提升了单目深度估计在复杂手术环境中的准确性与稳定性，为机器人辅助外科手术提供了可靠的技术支持。

Abstract: Accurate Monocular Depth Estimation (MDE) is critical for robotic surgery but remains fragile in specular, fluid-filled endoscopic environments. Existing self-supervised methods, typically relying on foundation models trained with noisy real-world pseudo-labels, often suffer from boundary collapse on thin surgical tools and transparent surfaces. In this work, we address this by leveraging the high-fidelity synthetic priors of the Depth Anything V2 architecture, which inherently captures precise geometric details of thin structures. We efficiently adapt these priors to the medical domain using Dynamic Vector Low-Rank Adaptation (DV-LORA), minimizing the parameter budget while bridging the synthetic-to-real gap. Additionally, we introduce a physically-stratified evaluation protocol on the SCARED dataset to rigorously quantify performance in high-specularity regimes often masked by aggregate metrics. Our approach establishes a new state-of-the-art, achieving an accuracy (< 1.25) of 98.1% and reducing Squared Relative Error by over 17% compared to established baselines, demonstrating superior robustness in adverse surgical lighting.

</details>


### [2] [Video-Based Performance Evaluation for ECR Drills in Synthetic Training Environments](https://arxiv.org/abs/2512.23819)
*Surya Rayala,Marcos Quinones-Grueiro,Naveeduddin Mohammed,Ashwin T S,Benjamin Goldberg,Randall Spain,Paige Lawton,Gautam Biswas*

Main category: cs.CV

TL;DR: 本文提出了一种基于视频的评估流程，利用计算机视觉技术从训练视频中提取2D骨骼、视线向量和运动轨迹，进而构建任务特定指标，评估认知、心理运动和团队协作能力。通过扩展的认知任务分析（CTA）层级，生成综合性能评分，并应用于真实世界中的“进入并清查房间”（ECR）演练案例，支持在Gamemaster和GIFT框架内进行交互式战后复盘与反馈。


<details>
  <summary>Details</summary>
Motivation: 传统军事训练评估依赖昂贵的传感器或主观观察，难以实现客观、可扩展的性能评估。尤其在城市作战训练中，需高效评估情境意识、肌肉记忆与团队协作，因此需要一种无需额外硬件、自动化且精准的评估方法。

Method: 采用计算机视觉模型从训练视频中提取2D骨骼数据、视线方向与移动轨迹；基于这些数据设计任务相关的量化指标，涵盖心理运动流畅性、情境意识与团队协调性；结合扩展的认知任务分析（CTA）层次结构，通过加权组合生成个体与团队的整体表现分数。

Result: 该方法成功应用于真实ECR训练场景，生成可操作的领域特定性能指标，支持在Gamemaster与GIFT系统中实现交互式战后复盘与直观反馈。结果表明，该系统能有效量化复杂技能表现，具备良好的应用潜力。

Conclusion: 尽管存在追踪困难、真值验证挑战及泛化性限制，但该视频驱动的评估方法为合成训练环境中的规模化、客观化评估提供了可行路径。未来将拓展至3D视频分析，并进一步推动视频分析在STE中的全面应用。

Abstract: Effective urban warfare training requires situational awareness and muscle memory, developed through repeated practice in realistic yet controlled environments. A key drill, Enter and Clear the Room (ECR), demands threat assessment, coordination, and securing confined spaces. The military uses Synthetic Training Environments that offer scalable, controlled settings for repeated exercises. However, automatic performance assessment remains challenging, particularly when aiming for objective evaluation of cognitive, psychomotor, and teamwork skills. Traditional methods often rely on costly, intrusive sensors or subjective human observation, limiting scalability and accuracy. This paper introduces a video-based assessment pipeline that derives performance analytics from training videos without requiring additional hardware. By utilizing computer vision models, the system extracts 2D skeletons, gaze vectors, and movement trajectories. From these data, we develop task-specific metrics that measure psychomotor fluency, situational awareness, and team coordination. These metrics feed into an extended Cognitive Task Analysis (CTA) hierarchy, which employs a weighted combination to generate overall performance scores for teamwork and cognition. We demonstrate the approach with a case study of real-world ECR drills, providing actionable, domain specific metrics that capture individual and team performance. We also discuss how these insights can support After Action Reviews with interactive dashboards within Gamemaster and the Generalized Intelligent Framework for Tutoring (GIFT), providing intuitive and understandable feedback. We conclude by addressing limitations, including tracking difficulties, ground-truth validation, and the broader applicability of our approach. Future work includes expanding analysis to 3D video data and leveraging video analysis to enable scalable evaluation within STEs.

</details>


### [3] [MRI-to-CT Synthesis With Cranial Suture Segmentations Using A Variational Autoencoder Framework](https://arxiv.org/abs/2512.23894)
*Krithika Iyer,Austin Tapp,Athelia Paulli,Gabrielle Dickerson,Syed Muhammad Anwar,Natasha Lepore,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的儿科颅骨CT合成方法，通过T1加权MRI生成合成CT（sCT），实现颅骨分割、骨缝概率热图预测及直接骨缝分割。在0.2至2岁儿童数据上，sCT与真实CT具有99%结构相似性，Frechet inception距离为1.01；颅骨分割平均Dice系数达85%，骨缝分割达80%。统计检验显示sCT与真实CT在颅骨和骨缝分割上无显著差异（p < 0.05）。该方法首次实现了从MRI生成可进行骨缝分割的儿科颅骨sCT，弥补了MRI无法清晰显示骨和骨缝的缺陷，为无辐射颅骨评估提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有CT虽能有效评估颅骨和骨缝畸形，但其电离辐射对儿童不适用；而MRI虽无辐射且软组织对比度高，却难以显示颅骨和骨缝，限制了其在颅骨发育评估中的应用。因此亟需一种非侵入性、无辐射的颅骨形态评估方法，以支持儿科颅骨发育异常的诊断与治疗。

Method: 采用领域特定的变分自编码器构建深度学习管道，将0.2至2岁儿童的T1加权MRI转化为合成CT（sCT），并在此基础上实现颅骨精细分割、骨缝概率热图生成及直接骨缝分割。

Result: sCT与真实CT之间结构相似性高达99%，Frechet inception距离为1.01；7个颅骨的平均分割Dice系数为85%，骨缝分割达到80%；两样本等效性检验（TOST）表明sCT与真实CT在颅骨和骨缝分割上无显著差异（p < 0.05）。

Conclusion: 本研究首次建立了一种基于MRI生成可进行骨缝分割的儿科颅骨合成CT框架，克服了传统MRI在骨与骨缝可视化上的局限，实现了无辐射、高精度的颅骨发育评估，为儿科颅骨疾病诊断提供了重要技术支撑。

Abstract: Quantifying normative pediatric cranial development and suture ossification is crucial for diagnosing and treating growth-related cephalic disorders. Computed tomography (CT) is widely used to evaluate cranial and sutural deformities; however, its ionizing radiation is contraindicated in children without significant abnormalities. Magnetic resonance imaging (MRI) offers radiation free scans with superior soft tissue contrast, but unlike CT, MRI cannot elucidate cranial sutures, estimate skull bone density, or assess cranial vault growth. This study proposes a deep learning driven pipeline for transforming T1 weighted MRIs of children aged 0.2 to 2 years into synthetic CTs (sCTs), predicting detailed cranial bone segmentation, generating suture probability heatmaps, and deriving direct suture segmentation from the heatmaps. With our in-house pediatric data, sCTs achieved 99% structural similarity and a Frechet inception distance of 1.01 relative to real CTs. Skull segmentation attained an average Dice coefficient of 85% across seven cranial bones, and sutures achieved 80% Dice. Equivalence of skull and suture segmentation between sCTs and real CTs was confirmed using two one sided tests (TOST p < 0.05). To our knowledge, this is the first pediatric cranial CT synthesis framework to enable suture segmentation on sCTs derived from MRI, despite MRI's limited depiction of bone and sutures. By combining robust, domain specific variational autoencoders, our method generates perceptually indistinguishable cranial sCTs from routine pediatric MRIs, bridging critical gaps in non invasive cranial evaluation.

</details>


### [4] [Learning to learn skill assessment for fetal ultrasound scanning](https://arxiv.org/abs/2512.23920)
*Yipei Wang,Qianye Yang,Lior Drukker,Aris T. Papageorghiou,Yipeng Hu,J. Alison Noble*

Main category: cs.CV

TL;DR: 本文提出一种新的双层优化框架，用于无需手动预定义技能评分的情况下，基于胎儿超声图像的完成任务质量来评估超声操作技能。该框架通过联合优化临床任务预测器和技能预测器，实现对超声技能的量化评估，并在真实临床超声视频数据上验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 传统超声技能评估依赖专家主观判断，耗时且存在偏差；已有自动化方法多采用监督学习，受限于预设影响因素，缺乏灵活性和客观性。因此需要一种更客观、自动化的技能评估方法。

Method: 提出一个双层优化框架，包含临床任务预测器与技能预测器，二者通过协同优化实现联合训练，以任务完成质量作为技能指标，不依赖人工预定义评分。

Result: 在真实胎儿头部超声扫描视频数据上的实验表明，该框架能够有效预测超声技能水平，证明其可行性与有效性。

Conclusion: 所提出的双层优化框架实现了无需人工评分的客观、量化超声技能评估，为自动化医学影像技能评价提供了新思路。

Abstract: Traditionally, ultrasound skill assessment has relied on expert supervision and feedback, a process known for its subjectivity and time-intensive nature. Previous works on quantitative and automated skill assessment have predominantly employed supervised learning methods, often limiting the analysis to predetermined or assumed factors considered influential in determining skill levels. In this work, we propose a novel bi-level optimisation framework that assesses fetal ultrasound skills by how well a task is performed on the acquired fetal ultrasound images, without using manually predefined skill ratings. The framework consists of a clinical task predictor and a skill predictor, which are optimised jointly by refining the two networks simultaneously. We validate the proposed method on real-world clinical ultrasound videos of scanning the fetal head. The results demonstrate the feasibility of predicting ultrasound skills by the proposed framework, which quantifies optimised task performance as a skill indicator.

</details>


### [5] [MGML: A Plug-and-Play Meta-Guided Multi-Modal Learning Framework for Incomplete Multimodal Brain Tumor Segmentation](https://arxiv.org/abs/2512.23936)
*Yulong Zou,Bo Liu,Cun-Jing Zheng,Yuan-ming Geng,Siyue Li,Qiankun Zuo,Shuihua Wang,Yudong Zhang,Jin Hong*

Main category: cs.CV

TL;DR: 提出一种新型元引导多模态学习（MGML）框架，通过元参数自适应模态融合和一致性正则化模块，有效处理临床中不完整的多模态MRI数据，提升脑肿瘤分割性能。方法无需修改原有模型结构，可无缝集成至训练流程，实现在BraTS2020和BraTS2023数据集上的领先表现，尤其在多种模态缺失情况下表现出色。源代码已公开。


<details>
  <summary>Details</summary>
Motivation: 临床中多模态MRI数据常不完整，限制了其在脑肿瘤分割中的应用，亟需有效利用不完整多模态信息的方法。

Method: 提出元参数自适应模态融合（Meta-AMF）与一致性正则化模块，通过生成自适应软标签监督信号实现动态模态融合，并增强模型鲁棒性与泛化能力。

Result: 在BraTS2020数据集上，针对15种缺失模态组合，整体肿瘤（WT）、肿瘤核心（TC）、增强肿瘤（ET）的平均Dice分数分别达到87.55、79.36、62.67，优于多个现有先进方法。

Conclusion: 所提MGML框架能有效应对多模态MRI数据不完整问题，在保持原模型结构前提下显著提升分割性能，具备良好的实用性与推广价值。

Abstract: Leveraging multimodal information from Magnetic Resonance Imaging (MRI) plays a vital role in lesion segmentation, especially for brain tumors. However, in clinical practice, multimodal MRI data are often incomplete, making it challenging to fully utilize the available information. Therefore, maximizing the utilization of this incomplete multimodal information presents a crucial research challenge. We present a novel meta-guided multi-modal learning (MGML) framework that comprises two components: meta-parameterized adaptive modality fusion and consistency regularization module. The meta-parameterized adaptive modality fusion (Meta-AMF) enables the model to effectively integrate information from multiple modalities under varying input conditions. By generating adaptive soft-label supervision signals based on the available modalities, Meta-AMF explicitly promotes more coherent multimodal fusion. In addition, the consistency regularization module enhances segmentation performance and implicitly reinforces the robustness and generalization of the overall framework. Notably, our approach does not alter the original model architecture and can be conveniently integrated into the training pipeline for end-to-end model optimization. We conducted extensive experiments on the public BraTS2020 and BraTS2023 datasets. Compared to multiple state-of-the-art methods from previous years, our method achieved superior performance. On BraTS2020, for the average Dice scores across fifteen missing modality combinations, building upon the baseline, our method obtained scores of 87.55, 79.36, and 62.67 for the whole tumor (WT), the tumor core (TC), and the enhancing tumor (ET), respectively. We have made our source code publicly available at https://github.com/worldlikerr/MGML.

</details>


### [6] [Kinematic-Based Assessment of Surgical Actions in Microanastomosis](https://arxiv.org/abs/2512.23942)
*Yan Meng,Daniel Donoho,Marcelle Altshuler,Omar Arnaout*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的自动化微血管吻合术动作分割与绩效评估框架，适用于边缘计算平台。系统包含三个模块：基于YOLO和DeepSORT的器械尖端追踪与定位、基于自相似矩阵的动作边界检测与无监督聚类的动作分割，以及用于评估手术动作熟练度的监督分类模块。在58段专家评分的微血管吻合术视频上验证，帧级动作分割准确率达92.4%，技能分类准确率达85.5%，可实现客观、实时的手术训练反馈，推动高风险外科环境中标准化、数据驱动的培训与能力评估。


<details>
  <summary>Details</summary>
Motivation: 传统微血管吻合术评估依赖专家主观评分或视频回放，存在评判不一致、耗时且难以规模化的问题，亟需客观、自动化的评估方法以提升训练效率与标准性。

Method: 提出一个三模块AI框架：1）基于YOLO和DeepSORT的器械尖端追踪与定位；2）利用自相似矩阵进行动作边界检测与无监督聚类实现动作分割；3）采用监督分类模型评估手术动作熟练度。系统设计适配边缘计算，支持实时处理。

Result: 在58段专家评级的微血管吻合术视频上，系统实现92.4%的帧级动作分割准确率和85.5%的技能分类准确率，性能接近甚至部分超越专家评估结果，具备实时反馈潜力。

Conclusion: 该AI驱动框架能够实现对微血管吻合术过程的客观、实时评估，为外科教育提供标准化、数据驱动的训练与能力评价方案，具有在高风险手术环境中推广应用的前景。

Abstract: Proficiency in microanastomosis is a critical surgical skill in neurosurgery, where the ability to precisely manipulate fine instruments is crucial to successful outcomes. These procedures require sustained attention, coordinated hand movements, and highly refined motor skills, underscoring the need for objective and systematic methods to evaluate and enhance microsurgical training. Conventional assessment approaches typically rely on expert raters supervising the procedures or reviewing surgical videos, which is an inherently subjective process prone to inter-rater variability, inconsistency, and significant time investment. These limitations highlight the necessity for automated and scalable solutions. To address this challenge, we introduce a novel AI-driven framework for automated action segmentation and performance assessment in microanastomosis procedures, designed to operate efficiently on edge computing platforms. The proposed system comprises three main components: (1) an object tip tracking and localization module based on YOLO and DeepSORT; (2) an action segmentation module leveraging self-similarity matrix for action boundary detection and unsupervised clustering; and (3) a supervised classification module designed to evaluate surgical gesture proficiency. Experimental validation on a dataset of 58 expert-rated microanastomosis videos demonstrates the effectiveness of our approach, achieving a frame-level action segmentation accuracy of 92.4% and an overall skill classification accuracy of 85.5% in replicating expert evaluations. These findings demonstrate the potential of the proposed method to provide objective, real-time feedback in microsurgical education, thereby enabling more standardized, data-driven training protocols and advancing competency assessment in high-stakes surgical environments.

</details>


### [7] [T2VAttack: Adversarial Attack on Text-to-Video Diffusion Models](https://arxiv.org/abs/2512.23953)
*Changzhen Li,Yuecong Min,Jie Zhang,Zheng Yuan,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出T2VAttack，系统研究文本到视频扩散模型在语义和时间维度上的对抗攻击。设计了两种攻击目标（语义对齐与时间动态）和两种攻击方法（T2VAttack-S与T2VAttack-I），通过替换或插入少量词汇实现高效攻击。实验表明，微小的提示修改即可显著破坏生成视频的语义一致性和时间连贯性，暴露当前T2V模型的关键脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频扩散模型虽生成质量高，但其对对抗攻击的脆弱性尚未被充分研究。由于视频数据具有动态特性，需从语义和时间两个角度评估模型鲁棒性，以揭示潜在安全风险。

Method: 提出T2VAttack框架，包含两个攻击目标：语义对齐与时间动态评估；设计两种攻击方法：(i) T2VAttack-S通过贪心搜索替换提示中的关键词；(ii) T2VAttack-I通过迭代插入最小扰动词进行优化。结合多种策略对多个SOTA模型进行测试。

Result: 即使仅修改一个词（如替换或插入），也能显著降低生成视频的语义准确性和时间一致性，证明当前主流T2V模型在对抗攻击下存在严重脆弱性。

Conclusion: T2V扩散模型在面对细微提示扰动时表现出极低的鲁棒性，亟需加强安全性设计。本研究为评估和提升T2V系统的安全性提供了重要基准和方法支持。

Abstract: The rapid evolution of Text-to-Video (T2V) diffusion models has driven remarkable advancements in generating high-quality, temporally coherent videos from natural language descriptions. Despite these achievements, their vulnerability to adversarial attacks remains largely unexplored. In this paper, we introduce T2VAttack, a comprehensive study of adversarial attacks on T2V diffusion models from both semantic and temporal perspectives. Considering the inherently dynamic nature of video data, we propose two distinct attack objectives: a semantic objective to evaluate video-text alignment and a temporal objective to assess the temporal dynamics. To achieve an effective and efficient attack process, we propose two adversarial attack methods: (i) T2VAttack-S, which identifies semantically or temporally critical words in prompts and replaces them with synonyms via greedy search, and (ii) T2VAttack-I, which iteratively inserts optimized words with minimal perturbation to the prompt. By combining these objectives and strategies, we conduct a comprehensive evaluation on the adversarial robustness of several state-of-the-art T2V models, including ModelScope, CogVideoX, Open-Sora, and HunyuanVideo. Our experiments reveal that even minor prompt modifications, such as the substitution or insertion of a single word, can cause substantial degradation in semantic fidelity and temporal dynamics, highlighting critical vulnerabilities in current T2V diffusion models.

</details>


### [8] [DriveExplorer: Images-Only Decoupled 4D Reconstruction with Progressive Restoration for Driving View Extrapolation](https://arxiv.org/abs/2512.23983)
*Yuang Jia,Jinlong Wang,Jiayi Zhao,Chunlam Li,Shunzhou Wang,Wei Gao*

Main category: cs.CV

TL;DR: 本文提出了一种无需依赖昂贵传感器或人工标注的视图外推方法，仅使用图像和可选相机位姿，通过融合全局静态点云与每帧动态点云构建统一场景表示，并结合可变形4D高斯框架进行场景重建。利用初始训练的4D高斯模型生成伪图像以训练视频扩散模型，再通过迭代优化方式逐步提升渲染效果，将增强结果反馈至4DGS进行持续优化，直至达到目标视角。相比基线方法，本方法在新视角生成质量上显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视图外推方法严重依赖LiDAR点云、3D边界框和车道线标注等先验信息，这些信息需要昂贵传感器或大量人工标注，限制了其在真实自动驾驶场景中的部署应用。因此，亟需一种仅依赖图像和可选相机位姿的高效、低成本视图外推方法。

Method: 首先估计全局静态点云和每帧动态点云，融合为统一表示；采用可变形4D高斯框架重建场景；利用初始4D高斯模型生成伪图像训练视频扩散模型；随后通过迭代方式利用扩散模型优化高斯渲染结果，并将优化后的图像反馈作为新训练数据，持续改进4DGS模型，直至实现目标视角的视图外推。

Result: 实验表明，该方法在无复杂先验条件下仍能生成高质量的新视角图像，显著优于现有基线方法，在视觉保真度和细节还原方面表现更佳。

Conclusion: 本文提出的端到端可迭代优化框架实现了仅依赖图像和可选位姿的高效视图外推，有效降低了对昂贵传感器和人工标注的依赖，具备良好的实际应用潜力，为自动驾驶中多视角感知提供了新的解决方案。

Abstract: This paper presents an effective solution for view extrapolation in autonomous driving scenarios. Recent approaches focus on generating shifted novel view images from given viewpoints using diffusion models. However, these methods heavily rely on priors such as LiDAR point clouds, 3D bounding boxes, and lane annotations, which demand expensive sensors or labor-intensive labeling, limiting applicability in real-world deployment. In this work, with only images and optional camera poses, we first estimate a global static point cloud and per-frame dynamic point clouds, fusing them into a unified representation. We then employ a deformable 4D Gaussian framework to reconstruct the scene. The initially trained 4D Gaussian model renders degraded and pseudo-images to train a video diffusion model. Subsequently, progressively shifted Gaussian renderings are iteratively refined by the diffusion model,and the enhanced results are incorporated back as training data for 4DGS. This process continues until extrapolation reaches the target viewpoints. Compared with baselines, our method produces higher-quality images at novel extrapolated viewpoints.

</details>


### [9] [Anomaly detection in satellite imagery through temporal inpainting](https://arxiv.org/abs/2512.23986)
*Bertrand Rouet-Leduc,Claudia Hulbert*

Main category: cs.CV

TL;DR: 本文提出一种基于深度学习的卫星影像表面变化检测方法，利用Sentinel-2时间序列的时序冗余性，通过训练 inpainting 模型预测无变化情况下的地表状态，从而识别异常。该方法在土耳其-叙利亚地震后成功检测到地表破裂，灵敏度和特异性均优于传统方法，检测阈值比基线低约三倍，实现了对全球范围地表变化的高敏感度自动化监测。


<details>
  <summary>Details</summary>
Motivation: 传统变化检测方法难以应对大气噪声、季节变化和传感器伪影等复杂因素，导致对突发表面变化的检测灵敏度不足。因此需要更高效、精准的方法来实现快速灾害响应与环境监测。

Method: 基于SATLAS基础模型构建一个inpainting模型，利用历史影像序列重建当前帧，通过预测与实际观测之间的差异识别异常；使用覆盖全球不同气候区和土地覆被类型的训练数据进行端到端训练。

Result: 在2023年土耳其-叙利亚地震事件中，该方法成功检测到Tepehan地区的裂隙特征，相比时间中值法和Reed-Xiaoli检测器具有更高的灵敏度和特异性，检测阈值约为基线方法的三分之一。

Conclusion: 该深度学习方法能有效利用多光谱卫星时间序列中的时序信息，显著提升表面变化检测能力，为全球尺度的自动化地表监测提供了可行路径。

Abstract: Detecting surface changes from satellite imagery is critical for rapid disaster response and environmental monitoring, yet remains challenging due to the complex interplay between atmospheric noise, seasonal variations, and sensor artifacts. Here we show that deep learning can leverage the temporal redundancy of satellite time series to detect anomalies at unprecedented sensitivity, by learning to predict what the surface should look like in the absence of change. We train an inpainting model built upon the SATLAS foundation model to reconstruct the last frame of a Sentinel-2 time series from preceding acquisitions, using globally distributed training data spanning diverse climate zones and land cover types. When applied to regions affected by sudden surface changes, the discrepancy between prediction and observation reveals anomalies that traditional change detection methods miss. We validate our approach on earthquake-triggered surface ruptures from the 2023 Turkey-Syria earthquake sequence, demonstrating detection of a rift feature in Tepehan with higher sensitivity and specificity than temporal median or Reed-Xiaoli anomaly detectors. Our method reaches detection thresholds approximately three times lower than baseline approaches, providing a path towards automated, global-scale monitoring of surface changes from freely available multi-spectral satellite data.

</details>


### [10] [GCA-ResUNet: Medical Image Segmentation Using Grouped Coordinate Attention](https://arxiv.org/abs/2512.23990)
*Jun Ding,Shang Gao*

Main category: cs.CV

TL;DR: 本文提出GCA-ResUNet，一种轻量级、可插拔的分组坐标注意力模块（GCA），用于提升医学图像分割中对长距离上下文依赖和结构化空间依赖的建模能力。该方法在保持CNN高效性的同时，增强了对多器官和低对比度区域的分割性能，在Synapse和ACDC数据集上分别达到86.11%和92.64%的Dice分数，优于多种CNN与Transformer基线模型，尤其在小结构和复杂边界分割上表现优异，实现了精度与效率的良好平衡，适合临床部署。


<details>
  <summary>Details</summary>
Motivation: 现有U-Net类方法受限于局部感受野和同质化注意力机制，难以建模长程上下文；而基于Transformer的方法虽能捕捉全局依赖，但计算开销大、需大量数据，不适用于资源受限的临床环境。因此亟需一种兼顾精度与效率的新型分割框架。

Method: 提出轻量级的Grouped Coordinate Attention（GCA）模块，将通道建模分组处理以应对语义异质性，并引入方向感知的坐标编码，显式建模水平与垂直方向的空间依赖，集成至ResUNet架构中形成GCA-ResUNet。

Result: 在Synapse和ACDC数据集上分别获得86.11%和92.64%的Dice分数，优于Swim-UNet、TransUNet等主流方法；尤其在小器官和边界复杂的区域分割上具有显著优势。

Conclusion: GCA-ResUNet通过GCA模块有效提升了模型的全局表征能力，同时保持了CNN的高效性，实现了分割精度与计算效率之间的良好权衡，为临床场景下的医学图像分割提供了一种实用且可扩展的解决方案。

Abstract: Accurate segmentation of heterogeneous anatomical structures is pivotal for computer-aided diagnosis and subsequent clinical decision-making. Although U-Net based convolutional neural networks have achieved remarkable progress, their intrinsic locality and largely homogeneous attention formulations often limit the modeling of long-range contextual dependencies, especially in multi-organ scenarios and low-contrast regions. Transformer-based architectures mitigate this issue by leveraging global self-attention, but they usually require higher computational resources and larger training data, which may impede deployment in resource-constrained clinical environments.In this paper, we propose GCA-ResUNet, an efficient medical image segmentation framework equipped with a lightweight and plug-and-play Grouped Coordinate Attention (GCA) module. The proposed GCA decouples channel-wise context modeling into multiple groups to explicitly account for semantic heterogeneity across channels, and integrates direction-aware coordinate encoding to capture structured spatial dependencies along horizontal and vertical axes. This design enhances global representation capability while preserving the efficiency advantages of CNN backbones. Extensive experiments on two widely used benchmarks, Synapse and ACDC, demonstrate that GCA-ResUNet achieves Dice scores of 86.11% and 92.64%, respectively, outperforming a range of representative CNN and Transformer-based methods, including Swin-UNet and TransUNet. In particular, GCA-ResUNet yields consistent improvements in delineating small anatomical structures with complex boundaries. These results indicate that the proposed approach provides a favorable trade-off between segmentation accuracy and computational efficiency, offering a practical and scalable solution for clinical deployment.

</details>


### [11] [Bridging Structure and Appearance: Topological Features for Robust Self-Supervised Segmentation](https://arxiv.org/abs/2512.23997)
*Haotang Li,Zhenyu Qi,Hao Qin,Huanrui Yang,Sen He,Kebin Peng*

Main category: cs.CV

TL;DR: GASeg提出一种新框架，通过结合几何与外观信息来解决自监督语义分割中的外观模糊问题。核心是可微分盒计数（DBC）模块，用于量化多尺度拓扑统计，并引入拓扑增强（TopoAug）和多目标损失（GALoss）以促进跨模态对齐，显著提升在多个基准上的性能。


<details>
  <summary>Details</summary>
Motivation: 自监督语义分割方法在面对外观模糊（如阴影、反光、局部纹理）时表现不佳，原因在于过度依赖不稳定的外观特征。因此需要引入更稳定的结构信息来提升鲁棒性。

Method: 提出GASeg框架，包含可微分盒计数（DBC）模块，从几何和外观双流提取多尺度拓扑统计；采用拓扑增强（TopoAug）模拟真实世界模糊；使用多目标损失GALoss强制几何与外观特征对齐。

Result: 在COCO-Stuff、Cityscapes、PASCAL等四个基准上达到当前最优性能，验证了通过拓扑信息融合几何与外观的有效性。

Conclusion: 通过引入稳定拓扑信息并构建几何-外观联合表示，GASeg显著提升了自监督语义分割在复杂外观条件下的鲁棒性和准确性。

Abstract: Self-supervised semantic segmentation methods often fail when faced with appearance ambiguities. We argue that this is due to an over-reliance on unstable, appearance-based features such as shadows, glare, and local textures. We propose \textbf{GASeg}, a novel framework that bridges appearance and geometry by leveraging stable topological information. The core of our method is Differentiable Box-Counting (\textbf{DBC}) module, which quantifies multi-scale topological statistics from two parallel streams: geometric-based features and appearance-based features. To force the model to learn these stable structural representations, we introduce Topological Augmentation (\textbf{TopoAug}), an adversarial strategy that simulates real-world ambiguities by applying morphological operators to the input images. A multi-objective loss, \textbf{GALoss}, then explicitly enforces cross-modal alignment between geometric-based and appearance-based features. Extensive experiments demonstrate that GASeg achieves state-of-the-art performance on four benchmarks, including COCO-Stuff, Cityscapes, and PASCAL, validating our approach of bridging geometry and appearance via topological information.

</details>


### [12] [Improved 3D Gaussian Splatting of Unknown Spacecraft Structure Using Space Environment Illumination Knowledge](https://arxiv.org/abs/2512.23998)
*Tae Ha Park,Simone D'Amico*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过结合太阳位置先验知识，从空间交会与近距离操作（RPO）中拍摄的图像序列恢复未知目标航天器的3D结构。采用3D高斯点云（3DGS）建模目标的几何与外观，并通过光度优化实现相机位姿估计。针对太空影像中动态光照导致3DGS训练困难的问题，该方法引入服务航天器估算的太阳位置作为先验信息，显著提升了渲染图像的光度准确性，使模型能适应快速变化的光照、体现全局阴影和自遮挡。实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在空间交会与近距离操作中，目标航天器的3D结构重建面临动态光照条件带来的挑战，而传统的3D高斯点云（3DGS）模型依赖于静态场景假设，难以适应真实太空环境中的光照变化。同时，为了支持后续的相机位姿估计，3DGS渲染图像的光度准确性至关重要，因此亟需一种能够应对光照变化并提升光度保真的重建方法。

Method: 提出将服务航天器估算的太阳位置作为先验知识，嵌入到3DGS模型的训练流程中，以指导模型在动态光照条件下学习更准确的外观表示。通过光度优化实现相机位姿估计，同时利用太阳方向先验增强渲染图像的物理一致性，从而改善3DGS模型对阴影和自遮挡的建模能力。

Result: 实验结果表明，融合太阳位置先验的3DGS模型能够有效适应太空环境中快速变化的光照条件，生成具有高质量光度一致性的渲染图像，并准确反映全局阴影与自遮挡现象，显著提升了3D结构重建与位姿估计的性能。

Conclusion: 本研究证明了将太阳位置先验融入3DGS训练流程的有效性，为在复杂光照环境下实现高精度、高保真度的空间目标三维重建提供了可行方案，对空间自主交会与接近任务具有重要意义。

Abstract: This work presents a novel pipeline to recover the 3D structure of an unknown target spacecraft from a sequence of images captured during Rendezvous and Proximity Operations (RPO) in space. The target's geometry and appearance are represented as a 3D Gaussian Splatting (3DGS) model. However, learning 3DGS requires static scenes, an assumption in contrast to dynamic lighting conditions encountered in spaceborne imagery. The trained 3DGS model can also be used for camera pose estimation through photometric optimization. Therefore, in addition to recovering a geometrically accurate 3DGS model, the photometric accuracy of the rendered images is imperative to downstream pose estimation tasks during the RPO process. This work proposes to incorporate the prior knowledge of the Sun's position, estimated and maintained by the servicer spacecraft, into the training pipeline for improved photometric quality of 3DGS rasterization. Experimental studies demonstrate the effectiveness of the proposed solution, as 3DGS models trained on a sequence of images learn to adapt to rapidly changing illumination conditions in space and reflect global shadowing and self-occlusion.

</details>


### [13] [On Exact Editing of Flow-Based Diffusion Models](https://arxiv.org/abs/2512.24015)
*Zixiang Li,Yue Song,Jianing Peng,Ting Liu,Jun Huang,Xiaochao Qu,Luoqi Liu,Wei Wang,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: 提出Conditioned Velocity Correction (CVC)框架，通过双视角速度转换机制分解潜在演化，分离结构保持与语义引导分支，结合经验贝叶斯推断与Tweedie校正实现后验一致性更新，有效抑制速度误差累积，提升生成图像的结构保真度与语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于流的扩散编辑方法在潜空间中存在速度误差累积问题，导致语义不一致和结构失真，亟需一种更稳定的轨迹控制机制以保证编辑质量。

Method: CVC将编辑重构为受源先验驱动的分布变换问题，引入双视角速度转换机制，将潜变量演化分为结构保持分支与语义引导分支，并通过经验贝叶斯推断与Tweedie校正对条件速度场进行后验一致性修正，实现误差补偿。

Result: 在多种编辑任务中，CVC表现出更高的结构保真度、更好的语义对齐能力以及更可靠的编辑行为，显著优于现有方法。

Conclusion: CVC通过数学上严谨的速度误差补偿机制，实现了稳定且可解释的潜空间动态，为高质量、可控的图像编辑提供了新范式。

Abstract: Recent methods in flow-based diffusion editing have enabled direct transformations between source and target image distribution without explicit inversion. However, the latent trajectories in these methods often exhibit accumulated velocity errors, leading to semantic inconsistency and loss of structural fidelity. We propose Conditioned Velocity Correction (CVC), a principled framework that reformulates flow-based editing as a distribution transformation problem driven by a known source prior. CVC rethinks the role of velocity in inter-distribution transformation by introducing a dual-perspective velocity conversion mechanism. This mechanism explicitly decomposes the latent evolution into two components: a structure-preserving branch that remains consistent with the source trajectory, and a semantically-guided branch that drives a controlled deviation toward the target distribution. The conditional velocity field exhibits an absolute velocity error relative to the true underlying distribution trajectory, which inherently introduces potential instability and trajectory drift in the latent space. To address this quantifiable deviation and maintain fidelity to the true flow, we apply a posterior-consistent update to the resulting conditional velocity field. This update is derived from Empirical Bayes Inference and Tweedie correction, which ensures a mathematically grounded error compensation over time. Our method yields stable and interpretable latent dynamics, achieving faithful reconstruction alongside smooth local semantic conversion. Comprehensive experiments demonstrate that CVC consistently achieves superior fidelity, better semantic alignment, and more reliable editing behavior across diverse tasks.

</details>


### [14] [FitControler: Toward Fit-Aware Virtual Try-On](https://arxiv.org/abs/2512.24016)
*Lu Yang,Yicheng Liu,Yanan Li,Xiang Bai,Hao Lu*

Main category: cs.CV

TL;DR: 本文提出了一种注重服装合身度的虚拟试穿方法（FitControler），通过引入可学习的插件模块，实现对服装合身度的精细控制。针对合身布局生成与匹配渲染的挑战，提出了基于无服装依赖表示的合身感知布局生成器和多尺度合身注入器，并构建了名为Fit4Men的大规模数据集，包含13,000个不同合身度的男女装搭配样本。实验表明，该方法可兼容多种现有VTON模型，有效提升合身度控制精度。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法主要关注服装细节的真实还原，但忽略了影响整体风格的关键因素——服装合身度。合身度决定了服装与身体的贴合程度，是时尚设计中的核心要素。因此，亟需一种能够精准控制合身度的虚拟试穿技术。

Method: 提出FitControler，包括两个核心组件：1）合身感知布局生成器，根据去服装化的特征重新生成身体-服装布局；2）多尺度合身注入器，将布局信息作为引导信号，驱动服装的精确生成。同时构建了大规模的Fit4Men数据集，并设计了两种合身一致性评估指标。

Result: 实验表明，FitControler能有效集成到多种主流VTON模型中，在不同服装类型、视角和姿态下均实现了高精度的合身度控制，显著提升了虚拟试穿的真实感与可控性。

Conclusion: 本研究首次系统地将服装合身度纳入虚拟试穿框架，提出的FitControler方法为实现真实、可定制的虚拟试穿提供了新范式，具有良好的通用性和实用性。

Abstract: Realistic virtual try-on (VTON) concerns not only faithful rendering of garment details but also coordination of the style. Prior art typically pursues the former, but neglects a key factor that shapes the holistic style -- garment fit. Garment fit delineates how a garment aligns with the body of a wearer and is a fundamental element in fashion design. In this work, we introduce fit-aware VTON and present FitControler, a learnable plug-in that can seamlessly integrate into modern VTON models to enable customized fit control. To achieve this, we highlight two challenges: i) how to delineate layouts of different fits and ii) how to render the garment that matches the layout. FitControler first features a fit-aware layout generator to redraw the body-garment layout conditioned on a set of delicately processed garment-agnostic representations, and a multi-scale fit injector is then used to deliver layout cues to enable layout-driven VTON. In particular, we build a fit-aware VTON dataset termed Fit4Men, including 13,000 body-garment pairs of different fits, covering both tops and bottoms, and featuring varying camera distances and body poses. Two fit consistency metrics are also introduced to assess the fitness of generations. Extensive experiments show that FitControler can work with various VTON models and achieve accurate fit control. Code and data will be released.

</details>


### [15] [Structure-Guided Allocation of 2D Gaussians for Image Representation and Compression](https://arxiv.org/abs/2512.24018)
*Huanxiong Liang,Yunuo Chen,Yicheng Pan,Sixian Wang,Jincheng Dai,Guo Lu,Wenjun Zhang*

Main category: cs.CV

TL;DR: 本文提出一种结构引导的2D高斯点云分配原则，通过结合图像结构与表示容量及量化精度，提升2DGS在低码率下的率失真效率。方法包括：基于空间结构先验的初始化、自适应位宽量化协方差参数、几何一致性正则化。实验表明，相比基线方法，Kodak和DIV2K数据集上分别降低BD率43.44%和29.91%，同时保持超过1000 FPS的解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有2DGS方法在分配表示容量和参数精度时忽视图像结构，导致低码率下率失真效率受限。

Method: 提出结构引导初始化、自适应位宽量化协方差、几何一致性正则化，以实现结构感知的资源分配和优化。

Result: 在保持超1000 FPS解码速度的前提下，相较于基线方法，Kodak数据集上BD-rate降低43.44%，DIV2K上降低29.91%。

Conclusion: 所提方法显著提升了2DGS的表示能力与率失真性能，实现了高效且高质量的图像编码。

Abstract: Recent advances in 2D Gaussian Splatting (2DGS) have demonstrated its potential as a compact image representation with millisecond-level decoding. However, existing 2DGS-based pipelines allocate representation capacity and parameter precision largely oblivious to image structure, limiting their rate-distortion (RD) efficiency at low bitrates. To address this, we propose a structure-guided allocation principle for 2DGS, which explicitly couples image structure with both representation capacity and quantization precision, while preserving native decoding speed. First, we introduce a structure-guided initialization that assigns 2D Gaussians according to spatial structural priors inherent in natural images, yielding a localized and semantically meaningful distribution. Second, during quantization-aware fine-tuning, we propose adaptive bitwidth quantization of covariance parameters, which grants higher precision to small-scale Gaussians in complex regions and lower precision elsewhere, enabling RD-aware optimization, thereby reducing redundancy without degrading edge quality. Third, we impose a geometry-consistent regularization that aligns Gaussian orientations with local gradient directions to better preserve structural details. Extensive experiments demonstrate that our approach substantially improves both the representational power and the RD performance of 2DGS while maintaining over 1000 FPS decoding. Compared with the baseline GSImage, we reduce BD-rate by 43.44% on Kodak and 29.91% on DIV2K.

</details>


### [16] [FUSE-RSVLM: Feature Fusion Vision-Language Model for Remote Sensing](https://arxiv.org/abs/2512.24022)
*Yunkai Dang,Donghao Wang,Jiacheng Yang,Yifan Jiang,Meiyi Zhu,Yuekun Yang,Cong Wang,Qi Fan,Wenbin Li,Yang Gao*

Main category: cs.CV

TL;DR: MF-RSVLM是一种用于遥感视觉-语言理解的多特征融合模型，通过提取多尺度视觉表征并结合全局上下文与局部细节，有效提升对遥感图像中微小和复杂结构的捕捉能力。其递归视觉特征注入机制有助于缓解深层语言处理中的视觉遗忘问题。在多个遥感基准测试中，MF-RSVLM在分类、图像描述和视觉问答任务上均达到或接近当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉-语言模型在处理遥感图像时难以提取细粒度视觉特征，并在深度语言处理过程中出现视觉遗忘问题，导致性能下降。

Method: 提出MF-RSVLM模型，利用多尺度视觉表示学习，融合全局上下文与局部细节；引入递归视觉特征注入机制，确保语言生成过程始终基于视觉证据，减少视觉信息丢失。

Result: 在多种遥感图像分类、图像描述和视觉问答任务上，MF-RSVLM表现出色，达到或超过现有方法的性能水平。

Conclusion: MF-RSVLM通过多特征融合与视觉特征持续注入，显著提升了遥感场景下的视觉-语言理解能力，为遥感领域的大规模多模态分析提供了有效解决方案。

Abstract: Large vision-language models (VLMs) exhibit strong performance across various tasks. However, these VLMs encounter significant challenges when applied to the remote sensing domain due to the inherent differences between remote sensing images and natural images. Existing remote sensing VLMs often fail to extract fine-grained visual features and suffer from visual forgetting during deep language processing. To address this, we introduce MF-RSVLM, a Multi-Feature Fusion Remote Sensing Vision--Language Model that effectively extracts and fuses visual features for RS understanding. MF-RSVLM learns multi-scale visual representations and combines global context with local details, improving the capture of small and complex structures in RS scenes. A recurrent visual feature injection scheme ensures the language model remains grounded in visual evidence and reduces visual forgetting during generation. Extensive experiments on diverse RS benchmarks show that MF-RSVLM achieves state-of-the-art or highly competitive performance across remote sensing classification, image captioning, and VQA tasks. Our code is publicly available at https://github.com/Yunkaidang/RSVLM.

</details>


### [17] [Neighbor-aware Instance Refining with Noisy Labels for Cross-Modal Retrieval](https://arxiv.org/abs/2512.24064)
*Yizhi Liu,Ruitao Pu,Shilin Xu,Yingke Chen,Quan-Hui Liu,Yuan Sun*

Main category: cs.CV

TL;DR: 本文提出了一种名为NIRNL的新型鲁棒跨模态学习框架，旨在解决多模态数据标注噪声问题。通过引入跨模态边界保持（CMP）机制调整正负样本对的距离，增强样本区分度；并设计邻域感知实例精炼（NIR）方法，基于跨模态邻域共识将样本划分为纯净、困难和噪声子集，进而针对不同子集采用定制化优化策略，以最大化数据利用率并抑制错误传播。在三个基准数据集上的实验表明，NIRNL在高噪声率下仍能实现顶尖性能，展现出优异的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多模态数据标注常包含噪声，且大规模高质量标注数据收集成本高，现有鲁棒跨模态检索方法难以同时兼顾模型性能上限、校准可靠性与数据利用率，亟需更高效的解决方案。

Method: 提出跨模态边界保持（CMP）机制以优化正负样本对的相对距离；设计邻域感知实例精炼（NIR）方法，通过跨模态邻域共识识别纯净、困难和噪声样本子集，并为各子集构建定制化优化策略。

Result: 在三个基准数据集上，NIRNL均达到当前最优性能，尤其在高噪声条件下表现显著优于现有方法，验证了其高效的数据利用能力和强鲁棒性。

Conclusion: NIRNL框架通过精细划分样本类型并实施差异化优化，在提升跨模态检索性能的同时有效缓解噪声影响，是应对多模态数据噪声问题的有效方案。

Abstract: In recent years, Cross-Modal Retrieval (CMR) has made significant progress in the field of multi-modal analysis. However, since it is time-consuming and labor-intensive to collect large-scale and well-annotated data, the annotation of multi-modal data inevitably contains some noise. This will degrade the retrieval performance of the model. To tackle the problem, numerous robust CMR methods have been developed, including robust learning paradigms, label calibration strategies, and instance selection mechanisms. Unfortunately, they often fail to simultaneously satisfy model performance ceilings, calibration reliability, and data utilization rate. To overcome the limitations, we propose a novel robust cross-modal learning framework, namely Neighbor-aware Instance Refining with Noisy Labels (NIRNL). Specifically, we first propose Cross-modal Margin Preserving (CMP) to adjust the relative distance between positive and negative pairs, thereby enhancing the discrimination between sample pairs. Then, we propose Neighbor-aware Instance Refining (NIR) to identify pure subset, hard subset, and noisy subset through cross-modal neighborhood consensus. Afterward, we construct different tailored optimization strategies for this fine-grained partitioning, thereby maximizing the utilization of all available data while mitigating error propagation. Extensive experiments on three benchmark datasets demonstrate that NIRNL achieves state-of-the-art performance, exhibiting remarkable robustness, especially under high noise rates.

</details>


### [18] [Balanced Hierarchical Contrastive Learning with Decoupled Queries for Fine-grained Object Detection in Remote Sensing Images](https://arxiv.org/abs/2512.24074)
*Jingzhou Chen,Dexin Chen,Fengchao Xiong,Yuntao Qian,Liang Xiao*

Main category: cs.CV

TL;DR: 本文提出一种结合平衡层次对比损失与解耦学习策略的方法，用于提升检测变压器（DETR）框架在细粒度遥感图像中的检测性能。针对层次标签中数据分布不均和语义关系学习干扰定位的问题，该方法通过可学习的类别原型和梯度均衡机制，确保每一层级类别在每个批次中对损失贡献均等；同时将对象查询解耦为分类与定位两组，实现任务特异性特征提取与优化。在三个具有层次标注的细粒度数据集上的实验表明，该方法优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究在细粒度遥感图像中使用层次标签结构进行检测，但如何将语义层次嵌入表示学习空间以提升检测性能仍具挑战。先前方法虽采用监督对比学习在不同层次上分组父类下的子类，但忽略了两个关键问题：一是标签层次中数据分布不均导致高频类别主导学习过程；二是类别间语义关系的学习干扰了类无关的定位能力。

Method: 提出平衡层次对比损失，引入可学习的类别原型，并在每个层次上均衡各类别对梯度的贡献，使每类在每个小批量中对损失的贡献相等；同时在DETR框架中采用解耦学习策略，将对象查询分为分类和定位两组，实现任务特异性特征提取与优化。

Result: 在三个具有层次标注的细粒度遥感数据集上的实验结果表明，所提方法在检测性能上显著优于现有最先进方法，验证了其有效性与优越性。

Conclusion: 本文提出的平衡层次对比损失与解耦学习策略有效缓解了层次标签中数据不平衡与语义关系干扰定位的问题，在细粒度遥感目标检测中实现了更优的性能表现。

Abstract: Fine-grained remote sensing datasets often use hierarchical label structures to differentiate objects in a coarse-to-fine manner, with each object annotated across multiple levels. However, embedding this semantic hierarchy into the representation learning space to improve fine-grained detection performance remains challenging. Previous studies have applied supervised contrastive learning at different hierarchical levels to group objects under the same parent class while distinguishing sibling subcategories. Nevertheless, they overlook two critical issues: (1) imbalanced data distribution across the label hierarchy causes high-frequency classes to dominate the learning process, and (2) learning semantic relationships among categories interferes with class-agnostic localization. To address these issues, we propose a balanced hierarchical contrastive loss combined with a decoupled learning strategy within the detection transformer (DETR) framework. The proposed loss introduces learnable class prototypes and equilibrates gradients contributed by different classes at each hierarchical level, ensuring that each hierarchical class contributes equally to the loss computation in every mini-batch. The decoupled strategy separates DETR's object queries into classification and localization sets, enabling task-specific feature extraction and optimization. Experiments on three fine-grained datasets with hierarchical annotations demonstrate that our method outperforms state-of-the-art approaches.

</details>


### [19] [RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention](https://arxiv.org/abs/2512.24086)
*Aiyue Chen,Yaofu Liu,Junjian Huang,Guang Lian,Yiwu Yao,Wangli Lan,Jing Lin,Zhixin Ma,Tingting Zhou,Harry Yang*

Main category: cs.CV

TL;DR: RainFusion2.0提出一种在线自适应、硬件高效且低开销的稀疏注意力机制，用于加速视频和图像生成模型，在保持高质量的同时实现高达80%的稀疏度和1.5~1.8倍的端到端加速，并在多种模型和硬件平台上表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法存在稀疏模式预测开销大和硬件通用性差的问题，尤其在非GPU设备上表现不佳，限制了其在多样化硬件平台上的应用。

Method: 通过块级均值作为代表性标记进行稀疏掩码预测，采用时空感知的标记重排策略，并引入专为视频生成设计的首帧锚点机制，实现高效且通用的稀疏注意力计算。

Result: RainFusion2.0在保持视频质量的前提下实现了80%的稀疏度和1.5~1.8倍的端到端加速，并在多种生成模型和不同硬件平台上验证了其有效性与泛化能力。

Conclusion: RainFusion2.0成功解决了稀疏注意力在计算效率与硬件兼容性方面的挑战，为跨平台高效生成模型推理提供了可行方案。

Abstract: In video and image generation tasks, Diffusion Transformer (DiT) models incur extremely high computational costs due to attention mechanisms, which limits their practical applications. Furthermore, with hardware advancements, a wide range of devices besides graphics processing unit (GPU), such as application-specific integrated circuit (ASIC), have been increasingly adopted for model inference. Sparse attention, which leverages the inherent sparsity of attention by skipping computations for insignificant tokens, is an effective approach to mitigate computational costs. However, existing sparse attention methods have two critical limitations: the overhead of sparse pattern prediction and the lack of hardware generality, as most of these methods are designed for GPU. To address these challenges, this study proposes RainFusion2.0, which aims to develop an online adaptive, hardware-efficient, and low-overhead sparse attention mechanism to accelerate both video and image generative models, with robust performance across diverse hardware platforms. Key technical insights include: (1) leveraging block-wise mean values as representative tokens for sparse mask prediction; (2) implementing spatiotemporal-aware token permutation; and (3) introducing a first-frame sink mechanism specifically designed for video generation scenarios. Experimental results demonstrate that RainFusion2.0 can achieve 80% sparsity while achieving an end-to-end speedup of 1.5~1.8x without compromising video quality. Moreover, RainFusion2.0 demonstrates effectiveness across various generative models and validates its generalization across diverse hardware platforms.

</details>


### [20] [Factorized Learning for Temporally Grounded Video-Language Models](https://arxiv.org/abs/2512.24097)
*Wenzheng Zeng,Difei Gao,Mike Zheng Shou,Hwee Tou Ng*

Main category: cs.CV

TL;DR: 本文提出D²VLM框架，通过解耦视频理解中的时间定位与文本回答任务，强调二者间的逻辑依赖关系。采用‘先定位后基于证据回答’的范式，并引入证据标记以捕捉事件级视觉语义。提出一种新型因子化偏好优化（FPO）算法，将概率性时间定位建模融入优化目标，提升两任务的学习效果。同时构建合成数据集以支持因子化偏好学习。实验表明该方法在多项任务上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有视频-语言模型在事件级感知的时间定位上表现不佳，且时间定位与文本回答通常被耦合处理，缺乏清晰的逻辑结构，导致目标不优。

Method: 提出D²VLM框架，采用‘先定位后回答’范式，引入证据令牌进行事件级视觉语义捕捉；设计因子化偏好优化（FPO）算法，显式融合概率性时间定位建模于优化目标中；构建合成数据集以支持因子化偏好学习。

Result: 在多个任务上实验验证了该方法的优势，显著提升了时间定位与文本回答的准确性，尤其在事件级感知方面表现突出。

Conclusion: 通过解耦与因子化学习策略，本研究有效提升了视频理解中时间定位与文本回答的性能，为未来视频-语言模型的设计提供了新思路。

Abstract: Recent video-language models have shown great potential for video understanding, but still struggle with accurate temporal grounding for event-level perception. We observe that two main factors in video understanding (i.e., temporal grounding and textual response) form a logical hierarchy: accurate temporal evidence grounding lays the foundation for reliable textual response. However, existing works typically handle these two tasks in a coupled manner without a clear logical structure, leading to sub-optimal objectives. We address this from a factorized learning perspective. We first propose D$^2$VLM, a framework that decouples the learning of these two tasks while also emphasizing their inherent dependency. We adopt a "grounding then answering with evidence referencing" paradigm and introduce evidence tokens for evidence grounding, which emphasize event-level visual semantic capture beyond the focus on timestamp representation in existing works. To further facilitate the learning of these two tasks, we introduce a novel factorized preference optimization (FPO) algorithm. Unlike standard preference optimization, FPO explicitly incorporates probabilistic temporal grounding modeling into the optimization objective, enabling preference learning for both temporal grounding and textual response. We also construct a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding. Experiments on various tasks demonstrate the clear advantage of our approach. Our source code is available at https://github.com/nusnlp/d2vlm.

</details>


### [21] [Think Before You Move: Latent Motion Reasoning for Text-to-Motion Generation](https://arxiv.org/abs/2512.24100)
*Yijie Qian,Juncheng Wang,Yuxiang Feng,Chao Xu,Wang Lu,Yang Liu,Baigui Sun,Yiqiang Chen,Yong Liu,Shujun Wang*

Main category: cs.CV

TL;DR: 本文提出一种新型两阶段文本到动作生成框架LMR，通过双粒度潜空间分离语义规划与物理执行，实现更准确的语义对齐与物理合理性，优于传统直接映射方法。


<details>
  <summary>Details</summary>
Motivation: 当前主流的文本到动作（T2M）生成方法将问题视为直接翻译，将符号化的语言映射到连续的动作姿态。然而，这种系统1方法在处理复杂动作时存在根本性理论瓶颈，即语义-运动阻抗不匹配：难以在单次映射中将语义密集、离散的语言意图与运动密集、高频的动作数据进行有效对齐。

Method: 提出基于认知科学中分层运动控制思想的潜空间系统2推理框架——潜空间运动推理（LMR），通过双粒度分词器将运动分解为两个独立流形：用于规划全局拓扑结构的压缩且富含语义的推理潜空间，以及用于保持物理真实性的高频执行潜空间。模型采用自回归方式先思考（规划粗略轨迹）后行动（生成具体帧），从而弥合语言与物理之间的不可言说性鸿沟。

Result: 在T2M-GPT（离散）和MotionStreamer（连续）两个代表性基线上的实验表明，LMR显著提升了语义对齐度与物理合理性，验证了最优运动规划基础并非自然语言，而是一个学习得到的、与运动对齐的概念空间。

Conclusion: 该研究证明，通过引入潜空间系统2推理机制，能够有效克服文本到动作生成中的语义-运动阻抗不匹配问题，为高质量动作生成提供了新的范式。

Abstract: Current state-of-the-art paradigms predominantly treat Text-to-Motion (T2M) generation as a direct translation problem, mapping symbolic language directly to continuous poses. While effective for simple actions, this System 1 approach faces a fundamental theoretical bottleneck we identify as the Semantic-Kinematic Impedance Mismatch: the inherent difficulty of grounding semantically dense, discrete linguistic intent into kinematically dense, high-frequency motion data in a single shot. In this paper, we argue that the solution lies in an architectural shift towards Latent System 2 Reasoning. Drawing inspiration from Hierarchical Motor Control in cognitive science, we propose Latent Motion Reasoning (LMR) that reformulates generation as a two-stage Think-then-Act decision process. Central to LMR is a novel Dual-Granularity Tokenizer that disentangles motion into two distinct manifolds: a compressed, semantically rich Reasoning Latent for planning global topology, and a high-frequency Execution Latent for preserving physical fidelity. By forcing the model to autoregressively reason (plan the coarse trajectory) before it moves (instantiates the frames), we effectively bridge the ineffability gap between language and physics. We demonstrate LMR's versatility by implementing it for two representative baselines: T2M-GPT (discrete) and MotionStreamer (continuous). Extensive experiments show that LMR yields non-trivial improvements in both semantic alignment and physical plausibility, validating that the optimal substrate for motion planning is not natural language, but a learned, motion-aligned concept space. Codes and demos can be found in \hyperlink{https://chenhaoqcdyq.github.io/LMR/}{https://chenhaoqcdyq.github.io/LMR/}

</details>


### [22] [Guided Diffusion-based Generation of Adversarial Objects for Real-World Monocular Depth Estimation Attacks](https://arxiv.org/abs/2512.24111)
*Yongtao Chen,Yanbo Wang,Wentao Zhao,Guole Shen,Tianchen Deng,Jingchuan Wang*

Main category: cs.CV

TL;DR: 本文提出一种无需训练的生成对抗攻击框架，通过基于扩散模型的条件生成过程，生成自然且与场景一致的对抗性物体，以攻击单目深度估计（MDE）。该方法结合显著区域选择模块和雅可比向量乘积引导机制，有效生成在真实驾驶环境中具有高隐蔽性和强破坏力的对抗样本。实验表明，该方法在数字与物理场景中均显著优于现有攻击方法，在深度估计误导、隐蔽性及实际部署能力方面表现优异，对自动驾驶安全评估具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计在自动驾驶系统中至关重要，但易受对抗攻击影响。现有物理攻击多依赖纹理贴图，存在放置约束严格、真实性不足等问题，难以在复杂驾驶环境中有效实施。因此亟需更自然、更具欺骗性的攻击方法以全面评估系统安全性。

Method: 提出一种训练-free的生成对抗攻击框架，利用扩散模型进行条件生成，生成与周围环境一致的对抗性物体；引入显著区域选择模块定位对深度估计影响最大的区域，并结合雅可比向量乘积引导机制，使对抗梯度沿扩散模型支持的方向更新，确保生成结果的自然性与有效性。

Result: 在数字和物理实验中，所提方法均显著提升攻击效果，实现更大的深度偏差，同时保持高度隐蔽性与物理可部署性，优于现有攻击方法。

Conclusion: 本研究提出的生成式对抗攻击框架能够高效生成真实感强、场景一致的对抗物体，有效干扰单目深度估计，为自动驾驶系统的安全性评估提供了强有力的新工具。

Abstract: Monocular Depth Estimation (MDE) serves as a core perception module in autonomous driving systems, but it remains highly susceptible to adversarial attacks. Errors in depth estimation may propagate through downstream decision making and influence overall traffic safety. Existing physical attacks primarily rely on texture-based patches, which impose strict placement constraints and exhibit limited realism, thereby reducing their effectiveness in complex driving environments. To overcome these limitations, this work introduces a training-free generative adversarial attack framework that generates naturalistic, scene-consistent adversarial objects via a diffusion-based conditional generation process. The framework incorporates a Salient Region Selection module that identifies regions most influential to MDE and a Jacobian Vector Product Guidance mechanism that steers adversarial gradients toward update directions supported by the pre-trained diffusion model. This formulation enables the generation of physically plausible adversarial objects capable of inducing substantial adversarial depth shifts. Extensive digital and physical experiments demonstrate that our method significantly outperforms existing attacks in effectiveness, stealthiness, and physical deployability, underscoring its strong practical implications for autonomous driving safety assessment.

</details>


### [23] [GeoBench: Rethinking Multimodal Geometric Problem-Solving via Hierarchical Evaluation](https://arxiv.org/abs/2512.24119)
*Yuan Feng,Yue Yang,Xiaohan He,Jiatong Zhao,Jianlong Chen,Zijun Chen,Daocheng Fu,Qi Liu,Renqiu Xia,Bo Zhang,Junchi Yan*

Main category: cs.CV

TL;DR: GeoBench是一个分层基准，包含四个几何推理级别：视觉感知、目标导向规划、严谨定理应用和自我反思回溯。通过六个形式化验证的任务，系统评估从属性提取到逻辑错误纠正的能力。实验发现，虽然推理模型如OpenAI-o3优于通用多模态大模型，但随着任务复杂度增加性能显著下降。关键发现表明，子目标分解和无关前提过滤对解题准确率至关重要，而链式思维提示在某些任务中反而降低性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在几何推理评估中存在测试数据污染、过度关注最终答案而非推理过程、诊断粒度不足等问题，亟需一个更全面、细致的评估基准。

Method: 提出GeoBench，采用分层设计，涵盖四个推理层次；利用TrustGeoGen生成六个形式化验证的任务，实现对几何问题求解能力的系统性评估。

Result: 推理模型（如OpenAI-o3）优于通用多模态大模型，但复杂度提升时性能下降明显；子目标分解与无关前提过滤显著影响准确率；链式思维提示在部分任务中导致性能下降。

Conclusion: GeoBench为几何问题求解提供了全面的评估框架，并为构建高效几何推理系统提供了可操作的指导建议。

Abstract: Geometric problem solving constitutes a critical branch of mathematical reasoning, requiring precise analysis of shapes and spatial relationships. Current evaluations of geometric reasoning in vision-language models (VLMs) face limitations, including the risk of test data contamination from textbook-based benchmarks, overemphasis on final answers over reasoning processes, and insufficient diagnostic granularity. To address these issues, we present GeoBench, a hierarchical benchmark featuring four reasoning levels in geometric problem-solving: Visual Perception, Goal-Oriented Planning, Rigorous Theorem Application, and Self-Reflective Backtracking. Through six formally verified tasks generated via TrustGeoGen, we systematically assess capabilities ranging from attribute extraction to logical error correction. Experiments reveal that while reasoning models like OpenAI-o3 outperform general MLLMs, performance declines significantly with increasing task complexity. Key findings demonstrate that sub-goal decomposition and irrelevant premise filtering critically influence final problem-solving accuracy, whereas Chain-of-Thought prompting unexpectedly degrades performance in some tasks. These findings establish GeoBench as a comprehensive benchmark while offering actionable guidelines for developing geometric problem-solving systems.

</details>


### [24] [Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning](https://arxiv.org/abs/2512.24146)
*Chubin Chen,Sujie Hu,Jiashu Zhu,Meiqi Wu,Jintao Chen,Yanxun Li,Nisha Huang,Chengyu Fang,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: This paper identifies and quantifies Preference Mode Collapse (PMC) in text-to-image models trained with RLHF, proposes DivGenBench for measuring PMC, and introduces D$^2$-Align—a method that uses directional correction in reward space to maintain diversity while improving alignment with human preferences.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-image diffusion models aligned with human preference via Reinforcement Learning from Human Feedback often suffer from Preference Mode Collapse (PMC), where models generate overly narrow, high-scoring outputs that lack diversity. This phenomenon undermines generative quality and variety despite high automated reward scores.

Method: The authors introduce DivGenBench, a benchmark to quantify PMC, and propose D$^2$-Align, a framework that mitigates PMC by learning directional corrections within the reward model's embedding space. The correction is applied to the reward signal during optimization, preventing overfitting to specific modes while preserving alignment with human preference.

Result: D$^2$-Align demonstrates superior performance in both human preference alignment and generative diversity compared to existing methods. Evaluation using qualitative analysis and quantitative metrics confirms reduced PMC and improved output variety without sacrificing quality.

Conclusion: D$^2$-Align effectively addresses Preference Mode Collapse by decoupling reward optimization from inherent biases in the reward model, enabling more diverse and human-aligned image generation.

Abstract: Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model's inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D$^2$-Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model's embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D$^2$-Align achieves superior alignment with human preference.

</details>


### [25] [Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset](https://arxiv.org/abs/2512.24160)
*TsaiChing Ni,ZhenQi Chen,YuanFu Yang*

Main category: cs.CV

TL;DR: IMDD-1M 是首个包含一百万对对齐图像-文本的工业多模态缺陷数据集，涵盖60多种材料和400多种缺陷类型，配有专家验证的细粒度描述。基于该数据集，研究者训练了一个专为工业场景设计的扩散型视觉-语言基础模型，仅需不到5%的任务特定数据即可达到与专用专家模型相当的性能，展示了数据高效的基础模型适应在工业检测与生成中的巨大潜力，推动可扩展、领域自适应且知识驱动的制造智能发展。


<details>
  <summary>Details</summary>
Motivation: 现有工业缺陷检测与质量检查方法依赖于大量标注数据和专用模型，难以实现跨领域泛化与高效部署。为解决这一问题，亟需大规模、高质量、多模态的工业缺陷数据集及通用基础模型，以支持更灵活、高效的智能制造系统。

Method: 构建大规模工业多模态缺陷数据集 IMDD-1M，包含 100 万对高分辨率图像与文本配对数据；在此基础上，从头训练一个基于扩散模型的视觉-语言基础模型，采用轻量级微调策略，实现对特定任务的快速适配。

Result: 所提出的模型在仅使用不到5%的特定任务数据情况下，性能接近甚至媲美传统专用专家模型，显著提升数据利用效率；同时支持分类、分割、检索、图文生成等多种下游任务，展现出强大的泛化能力与应用潜力。

Conclusion: IMDD-1M 及其配套的基础模型为工业智能制造提供了强有力的多模态学习基础设施，证明了数据高效、领域自适应的基础模型在工业质量控制中的可行性与优越性，未来有望实现规模化、低成本、可迁移的智能质检系统。

Abstract: We present IMDD-1M, the first large-scale Industrial Multimodal Defect Dataset comprising 1,000,000 aligned image-text pairs, designed to advance multimodal learning for manufacturing and quality inspection. IMDD-1M contains high-resolution real-world defects spanning over 60 material categories and more than 400 defect types, each accompanied by expert-verified annotations and fine-grained textual descriptions detailing defect location, severity, and contextual attributes. This dataset enables a wide spectrum of applications, including classification, segmentation, retrieval, captioning, and generative modeling. Building upon IMDD-1M, we train a diffusion-based vision-language foundation model from scratch, specifically tailored for industrial scenarios. The model serves as a generalizable foundation that can be efficiently adapted to specialized domains through lightweight fine-tuning. With less than 5% of the task-specific data required by dedicated expert models, it achieves comparable performance, highlighting the potential of data-efficient foundation model adaptation for industrial inspection and generation, paving the way for scalable, domain-adaptive, and knowledge-grounded manufacturing intelligence.

</details>


### [26] [DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models](https://arxiv.org/abs/2512.24165)
*Zefeng He,Xiaoye Qu,Yafu Li,Tong Zhu,Siyuan Huang,Yu Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的生成式多模态推理范式DiffThinker，将多模态推理重新定义为原生的图像到图像生成任务，显著提升了视觉主导任务中的逻辑一致性和空间精度。通过系统比较，揭示了该范式的四大特性：效率、可控性、原生并行性和协作性。在四个领域（序列规划、组合优化、约束满足和空间配置）的实验表明，DiffThinker显著优于GPT-5（+314.2%）、Gemini-3-Flash（+111.6%）和微调后的Qwen3-VL-32B基线（+39.0%），证明生成式多模态推理在视觉主导任务中具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型的推理过程主要以文本为中心，导致在复杂的长周期、视觉主导任务中表现不佳，亟需一种更符合视觉信息处理特性的新推理范式。

Method: 提出DiffThinker，一种基于扩散模型的生成式多模态推理框架，将多模态推理建模为图像到图像的生成任务，利用扩散模型的生成能力实现高精度的空间与逻辑推理。

Result: 在多个视觉主导任务中，DiffThinker在性能上远超当前主流闭源模型及基线模型，尤其在复杂空间推理任务中表现出色，验证了生成式多模态推理的有效性。

Conclusion: 生成式多模态推理是一种极具前景的视觉主导任务推理方法，DiffThinker所展现的效率、可控性、并行性和协作性使其成为未来多模态智能系统的重要方向。

Abstract: While recent Multimodal Large Language Models (MLLMs) have attained significant strides in multimodal reasoning, their reasoning processes remain predominantly text-centric, leading to suboptimal performance in complex long-horizon, vision-centric tasks. In this paper, we establish a novel Generative Multimodal Reasoning paradigm and introduce DiffThinker, a diffusion-based reasoning framework. Conceptually, DiffThinker reformulates multimodal reasoning as a native generative image-to-image task, achieving superior logical consistency and spatial precision in vision-centric tasks. We perform a systematic comparison between DiffThinker and MLLMs, providing the first in-depth investigation into the intrinsic characteristics of this paradigm, revealing four core properties: efficiency, controllability, native parallelism, and collaboration. Extensive experiments across four domains (sequential planning, combinatorial optimization, constraint satisfaction, and spatial configuration) demonstrate that DiffThinker significantly outperforms leading closed source models including GPT-5 (+314.2\%) and Gemini-3-Flash (+111.6\%), as well as the fine-tuned Qwen3-VL-32B baseline (+39.0\%), highlighting generative multimodal reasoning as a promising approach for vision-centric reasoning.

</details>


### [27] [Deep Global Clustering for Hyperspectral Image Segmentation: Concepts, Applications, and Open Challenges](https://arxiv.org/abs/2512.24172)
*Yu-Tang Chang,Pin-Wei Chen,Shih-Fang Chen*

Main category: cs.CV

TL;DR: 提出一种名为Deep Global Clustering (DGC) 的新型框架，用于高效、内存友好的高光谱图像（HSI）分割。该方法通过局部块观测学习全局聚类结构，无需预训练，在消费级硬件上30分钟内完成训练且内存恒定。在叶片疾病数据集上实现了高精度的背景-组织分离（平均IoU 0.925），并支持无监督疾病检测，但存在因多目标损失平衡不当导致的优化不稳定性问题，表现为特征空间中聚类过度合并。研究认为该设计具有潜力，但需更严谨的动态损失平衡策略以实现稳定性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像分析面临数据量大导致的计算瓶颈，现有基于大规模遥感数据预训练的基础模型难以迁移到如近距农业监测等特定领域，因光谱特征、空间尺度和语义目标差异显著。因此需要一种无需预训练、内存高效且能捕捉全局结构的新型方法。

Method: 提出Deep Global Clustering (DGC) 框架，利用重叠的小块局部观察来推断全局聚类结构，通过一致性约束实现端到端训练。采用小批量处理策略，确保内存使用恒定，并在普通硬件上实现快速训练。

Result: 在叶子疾病数据集上，DGC实现了0.925的平均交并比（IoU），有效区分背景与组织；具备无监督识别病害的能力，且可调节语义粒度。然而，由于多目标损失函数不平衡，模型出现优化不稳定现象，表现为初期表现良好后迅速退化。

Conclusion: DGC作为一种概念性架构具有创新性和实用价值，尤其在资源受限场景下表现出色。但其稳定性依赖于对动态损失平衡的合理设计，未来工作应聚焦于构建更稳健的优化机制以克服当前局限。

Abstract: Hyperspectral imaging (HSI) analysis faces computational bottlenecks due to massive data volumes that exceed available memory. While foundation models pre-trained on large remote sensing datasets show promise, their learned representations often fail to transfer to domain-specific applications like close-range agricultural monitoring where spectral signatures, spatial scales, and semantic targets differ fundamentally. This report presents Deep Global Clustering (DGC), a conceptual framework for memory-efficient HSI segmentation that learns global clustering structure from local patch observations without pre-training. DGC operates on small patches with overlapping regions to enforce consistency, enabling training in under 30 minutes on consumer hardware while maintaining constant memory usage. On a leaf disease dataset, DGC achieves background-tissue separation (mean IoU 0.925) and demonstrates unsupervised disease detection through navigable semantic granularity. However, the framework suffers from optimization instability rooted in multi-objective loss balancing: meaningful representations emerge rapidly but degrade due to cluster over-merging in feature space. We position this work as intellectual scaffolding - the design philosophy has merit, but stable implementation requires principled approaches to dynamic loss balancing. Code and data are available at https://github.com/b05611038/HSI_global_clustering.

</details>


### [28] [Guiding a Diffusion Transformer with the Internal Dynamics of Itself](https://arxiv.org/abs/2512.24176)
*Xingyu Zhou,Qifan Li,Xiaobin Hu,Hai Chen,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种名为内部引导（Internal Guidance, IG）的简单而有效的策略，通过在训练过程中对中间层引入辅助监督，并在采样时外推中间层和深层输出来提升扩散模型的生成质量。该方法显著提升了训练效率和生成效果，在ImageNet 256x256上，SiT-XL/2+IG达到FID=5.31（80轮）和1.75（800轮），LightningDiT-XL/1+IG达到FID=1.34，结合CFG后达到当前最优的FID=1.19。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在低概率区域生成质量差的问题，现有引导方法如分类器自由引导（CFG）易导致样本过简化或失真，而基于劣化版本的引导方法则受限于复杂的退化设计、额外训练和采样步骤。

Method: 提出内部引导（IG）策略，在训练阶段对中间层引入辅助监督，并在采样阶段利用中间层与深层输出的外推来生成高质量样本。

Result: 在多个基线模型上均实现显著提升；在ImageNet 256x256上，SiT-XL/2+IG在80和800轮分别达到FID=5.31和1.75；LightningDiT-XL/1+IG达到FID=1.34；结合CFG后达到当前最优的FID=1.19。

Conclusion: 内部引导（IG）是一种简单有效的方法，能显著提升扩散模型的生成质量和训练效率，且在多种设置下取得领先性能，为扩散模型的高效生成提供了新思路。

Abstract: The diffusion model presents a powerful ability to capture the entire (conditional) data distribution. However, due to the lack of sufficient training and data to learn to cover low-probability areas, the model will be penalized for failing to generate high-quality images corresponding to these areas. To achieve better generation quality, guidance strategies such as classifier free guidance (CFG) can guide the samples to the high-probability areas during the sampling stage. However, the standard CFG often leads to over-simplified or distorted samples. On the other hand, the alternative line of guiding diffusion model with its bad version is limited by carefully designed degradation strategies, extra training and additional sampling steps. In this paper, we proposed a simple yet effective strategy Internal Guidance (IG), which introduces an auxiliary supervision on the intermediate layer during training process and extrapolates the intermediate and deep layer's outputs to obtain generative results during sampling process. This simple strategy yields significant improvements in both training efficiency and generation quality on various baselines. On ImageNet 256x256, SiT-XL/2+IG achieves FID=5.31 and FID=1.75 at 80 and 800 epochs. More impressively, LightningDiT-XL/1+IG achieves FID=1.34 which achieves a large margin between all of these methods. Combined with CFG, LightningDiT-XL/1+IG achieves the current state-of-the-art FID of 1.19.

</details>


### [29] [CorGi: Contribution-Guided Block-Wise Interval Caching for Training-Free Acceleration of Diffusion Transformers](https://arxiv.org/abs/2512.24195)
*Yonglak Son,Suhyeok Kim,Seungryong Kim,Young Geun Kim*

Main category: cs.CV

TL;DR: CorGi 是一种无需训练的 DiT 推理加速框架，通过选择性重用变换器块的输出来减少扩散模型中的冗余计算。它在每个区间内缓存低贡献块并复用，从而降低计算开销。针对文本到图像任务，CorGi+ 进一步利用跨注意力图识别显著标记并部分更新注意力，以保护关键细节。实验表明，CorGi 和 CorGi+ 在保持生成质量的同时，平均实现 2.0 倍的加速。


<details>
  <summary>Details</summary>
Motivation: DiT 模型在视觉生成中表现优异，但其迭代去噪过程伴随高推理成本，且存在大量步骤间的冗余计算。如何有效减少这些冗余是提升效率的关键。

Method: 提出 CorGi 框架，基于贡献度判断是否缓存和重用变压器块的输出；CorGi+ 则引入每块跨注意力图识别重要标记，并进行局部注意力更新以保留细节。

Result: 在主流 DiT 模型上，CorGi 和 CorGi+ 实现了平均 2.0 倍的推理加速，同时保持高质量生成结果。

Conclusion: CorGi 及其扩展版本 CorGi+ 能有效减少 DiT 推理中的冗余计算，在不牺牲生成质量的前提下显著提升推理速度。

Abstract: Diffusion transformer (DiT) achieves remarkable performance in visual generation, but its iterative denoising process combined with larger capacity leads to a high inference cost. Recent works have demonstrated that the iterative denoising process of DiT models involves substantial redundant computation across steps. To effectively reduce the redundant computation in DiT, we propose CorGi (Contribution-Guided Block-Wise Interval Caching), training-free DiT inference acceleration framework that selectively reuses the outputs of transformer blocks in DiT across denoising steps. CorGi caches low-contribution blocks and reuses them in later steps within each interval to reduce redundant computation while preserving generation quality. For text-to-image tasks, we further propose CorGi+, which leverages per-block cross-attention maps to identify salient tokens and applies partial attention updates to protect important object details. Evaluation on the state-of-the-art DiT models demonstrates that CorGi and CorGi+ achieve up to 2.0x speedup on average, while preserving high generation quality.

</details>


### [30] [ARM: A Learnable, Plug-and-Play Module for CLIP-based Open-vocabulary Semantic Segmentation](https://arxiv.org/abs/2512.24224)
*Ziquan Liu,Zhewei Zhu,Xuyang Shi*

Main category: cs.CV

TL;DR: 提出Attention Refinement Module (ARM)，一种轻量级可学习模块，用于提升CLIP在开放词汇语义分割中的表现。通过自适应融合层次化特征，利用语义引导的交叉注意力和自注意力机制，实现对浅层细节特征的精炼。训练一次即可在多种框架中通用，显著提升性能且推理开销极低，推动了训练自由的开放词汇分割发展。


<details>
  <summary>Details</summary>
Motivation: 现有训练自由的方法受限于CLIP的粗粒度图像级表示，缺乏像素级细节；依赖外部模型（如SAM、DINO）或静态启发式规则导致计算成本高或效果不佳，亟需一种高效、通用的改进方案。

Method: 设计Attention Refinement Module (ARM)，包含语义引导的交叉注意力块（用深层特征选择并优化浅层特征）和自注意力块，实现层级特征的动态融合；采用‘训练一次，处处使用’范式，在通用数据集（如COCO-Stuff）上训练后，可作为即插即用的后处理模块适配多种训练自由框架。

Result: 在多个基准测试上，ARM显著提升基线性能，且推理开销极小，验证了其高效性与通用性。

Conclusion: ARM成功释放CLIP内部潜力，为训练自由的开放词汇语义分割提供了一种高效、通用且可扩展的新范式。

Abstract: Open-vocabulary semantic segmentation (OVSS) is fundamentally hampered by the coarse, image-level representations of CLIP, which lack precise pixel-level details. Existing training-free methods attempt to resolve this by either importing priors from costly external foundation models (e.g., SAM, DINO) or by applying static, hand-crafted heuristics to CLIP's internal features. These approaches are either computationally expensive or sub-optimal. We propose the Attention Refinement Module (ARM), a lightweight, learnable module that effectively unlocks and refines CLIP's internal potential. Unlike static-fusion methods, ARM learns to adaptively fuse hierarchical features. It employs a semantically-guided cross-attention block, using robust deep features (K, V) to select and refine detail-rich shallow features (Q), followed by a self-attention block. The key innovation lies in a ``train once, use anywhere" paradigm. Trained once on a general-purpose dataset (e.g., COCO-Stuff), ARM acts as a universal plug-and-play post-processor for diverse training-free frameworks. Extensive experiments show that ARM consistently boosts baseline performance on multiple benchmarks with negligible inference overhead, establishing an efficient and effective paradigm for training-free OVSS.

</details>


### [31] [Mirage: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes](https://arxiv.org/abs/2512.24227)
*Shuyun Wang,Haiyang Sun,Bing Wang,Hangjun Ye,Xin Yu*

Main category: cs.CV

TL;DR: 提出了一种名为Mirage的一步式视频扩散模型，用于驾驶场景中逼真且连贯的资产编辑。该模型通过文本到视频扩散先验确保帧间时间一致性，并引入预训练2D编码器的时序无关潜在变量来恢复细节并保持因果结构。针对物体与插入资产间的分布不匹配问题，采用两阶段数据对齐策略（粗略3D对齐和精细2D优化）提升姿态对齐效果。实验表明，Mirage在多种编辑场景下均表现出高真实感和时间一致性，且可泛化至其他视频到视频翻译任务，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象编辑方法难以同时保证高视觉保真度和时间连贯性，尤其在自动驾驶场景中，高质量、多样化的训练数据至关重要，因此需要一种能生成逼真且一致视频内容的新方法。

Method: 基于文本到视频扩散先验构建3D因果变分自编码器，引入预训练2D编码器的时序无关潜变量以恢复空间细节并维持时间因果性；采用两阶段数据对齐策略（粗3D对齐+细2D优化）解决物体与插入资产之间的分布差异和姿态错位问题。

Result: Mirage在多种视频编辑任务中实现了高保真度与强时间一致性，显著优于现有方法；不仅适用于资产编辑，还能推广至其他视频到视频转换任务，具备良好泛化能力。

Conclusion: Mirage是一种高效、通用的视频生成框架，能够有效解决驾驶场景中视频编辑中的保真度与连贯性难题，为自动驾驶系统的数据增强提供了可靠方案，具有广泛的应用前景。

Abstract: Vision-centric autonomous driving systems rely on diverse and scalable training data to achieve robust performance. While video object editing offers a promising path for data augmentation, existing methods often struggle to maintain both high visual fidelity and temporal coherence. In this work, we propose \textbf{Mirage}, a one-step video diffusion model for photorealistic and coherent asset editing in driving scenes. Mirage builds upon a text-to-video diffusion prior to ensure temporal consistency across frames. However, 3D causal variational autoencoders often suffer from degraded spatial fidelity due to compression, and directly passing 3D encoder features to decoder layers breaks temporal causality. To address this, we inject temporally agnostic latents from a pretrained 2D encoder into the 3D decoder to restore detail while preserving causal structures. Furthermore, because scene objects and inserted assets are optimized under different objectives, their Gaussians exhibit a distribution mismatch that leads to pose misalignment. To mitigate this, we introduce a two-stage data alignment strategy combining coarse 3D alignment and fine 2D refinement, thereby improving alignment and providing cleaner supervision. Extensive experiments demonstrate that Mirage achieves high realism and temporal consistency across diverse editing scenarios. Beyond asset editing, Mirage can also generalize to other video-to-video translation tasks, serving as a reliable baseline for future research. Our code is available at https://github.com/wm-research/mirage.

</details>


### [32] [MotivNet: Evolving Meta-Sapiens into an Emotionally Intelligent Foundation Model](https://arxiv.org/abs/2512.24231)
*Rahul Medicharla,Alper Yilmaz*

Main category: cs.CV

TL;DR: 本文提出MotivNet，一种无需跨域训练即可实现强泛化能力的面部情绪识别模型，基于Sapiens（一个通过大规模预训练的掩码自编码器构建的人类视觉基础模型），在多个数据集上表现出色，验证了其作为Sapiens下游任务的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的面部情绪识别（FER）模型在多样化数据上的泛化能力较弱，导致实际应用中性能下降；尽管已有研究尝试通过复杂架构和跨域训练提升泛化性，但后者不适用于真实世界场景。因此需要一种无需跨域训练仍具强泛化能力的解决方案。

Method: 以Sapiens为基础模型，提出MotivNet作为其下游任务，通过定义基准性能、模型相似性和数据相似性三个标准评估其有效性，并采用特定训练策略实现跨域泛化。

Result: MotivNet在多个数据集上表现优异，具备良好的泛化能力，且满足作为Sapiens下游任务的三项评估标准，验证了其在真实世界应用中的潜力。

Conclusion: MotivNet是一种无需跨域训练即可实现强泛化能力的面部情绪识别模型，成功将Sapiens应用于情感识别任务，推动了FER在真实场景中的实际应用。

Abstract: In this paper, we introduce MotivNet, a generalizable facial emotion recognition model for robust real-world application. Current state-of-the-art FER models tend to have weak generalization when tested on diverse data, leading to deteriorated performance in the real world and hindering FER as a research domain. Though researchers have proposed complex architectures to address this generalization issue, they require training cross-domain to obtain generalizable results, which is inherently contradictory for real-world application. Our model, MotivNet, achieves competitive performance across datasets without cross-domain training by using Meta-Sapiens as a backbone. Sapiens is a human vision foundational model with state-of-the-art generalization in the real world through large-scale pretraining of a Masked Autoencoder. We propose MotivNet as an additional downstream task for Sapiens and define three criteria to evaluate MotivNet's viability as a Sapiens task: benchmark performance, model similarity, and data similarity. Throughout this paper, we describe the components of MotivNet, our training approach, and our results showing MotivNet is generalizable across domains. We demonstrate that MotivNet can be benchmarked against existing SOTA models and meets the listed criteria, validating MotivNet as a Sapiens downstream task, and making FER more incentivizing for in-the-wild application. The code is available at https://github.com/OSUPCVLab/EmotionFromFaceImages.

</details>


### [33] [MambaSeg: Harnessing Mamba for Accurate and Efficient Image-Event Semantic Segmentation](https://arxiv.org/abs/2512.24243)
*Fuqiang Gu,Yuanke Li,Xianlei Long,Kangping Ji,Chao Chen,Qingyi Gu,Zhenliang Ni*

Main category: cs.CV

TL;DR: MambaSeg提出了一种基于双分支Mamba编码器的新型语义分割框架，通过并行处理RGB图像和事件流，结合跨空间与跨时间的交互模块（DDIM），实现高效且精确的多模态融合。该方法在保持低计算成本的同时，在DDD17和DSEC数据集上达到先进性能，显著提升了复杂环境下的感知鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB和事件数据的多模态融合方法通常计算开销大，且主要关注空间层面的融合，忽视了事件流中重要的时间动态特性，导致跨模态模糊和性能受限。

Method: 采用并行双分支Mamba编码器分别处理RGB图像和事件流；引入双重维度交互模块（DDIM），包含跨空间交互模块（CSIM）和跨时间交互模块（CTIM），实现空间与时间维度上的细粒度跨模态融合。

Result: 在DDD17和DSEC数据集上，MambaSeg实现了当前最优的语义分割精度，同时大幅降低计算资源消耗，表现出更高的效率与可扩展性。

Conclusion: MambaSeg通过高效建模多模态时空特性，有效缓解了跨模态模糊问题，为复杂场景下的鲁棒感知提供了轻量级、高性能的解决方案。

Abstract: Semantic segmentation is a fundamental task in computer vision with wide-ranging applications, including autonomous driving and robotics. While RGB-based methods have achieved strong performance with CNNs and Transformers, their effectiveness degrades under fast motion, low-light, or high dynamic range conditions due to limitations of frame cameras. Event cameras offer complementary advantages such as high temporal resolution and low latency, yet lack color and texture, making them insufficient on their own. To address this, recent research has explored multimodal fusion of RGB and event data; however, many existing approaches are computationally expensive and focus primarily on spatial fusion, neglecting the temporal dynamics inherent in event streams. In this work, we propose MambaSeg, a novel dual-branch semantic segmentation framework that employs parallel Mamba encoders to efficiently model RGB images and event streams. To reduce cross-modal ambiguity, we introduce the Dual-Dimensional Interaction Module (DDIM), comprising a Cross-Spatial Interaction Module (CSIM) and a Cross-Temporal Interaction Module (CTIM), which jointly perform fine-grained fusion along both spatial and temporal dimensions. This design improves cross-modal alignment, reduces ambiguity, and leverages the complementary properties of each modality. Extensive experiments on the DDD17 and DSEC datasets demonstrate that MambaSeg achieves state-of-the-art segmentation performance while significantly reducing computational cost, showcasing its promise for efficient, scalable, and robust multimodal perception.

</details>


### [34] [Physically-Grounded Manifold Projection with Foundation Priors for Metal Artifact Reduction in Dental CBCT](https://arxiv.org/abs/2512.24260)
*Zhi Li,Yaqi Wang,Bingtao Ma,Yifan Zhang,Huiyu Zhou,Shuai Wang*

Main category: cs.CV

TL;DR: 提出PGMP框架，结合物理模拟与深度学习，实现牙科CBCT金属伪影消除的高效、高保真重建。通过自适应物理仿真生成高质量训练数据，采用DMP-Former实现单次前向传播的确定性恢复，避免传统扩散模型的随机采样延迟；并引入语义结构对齐模块确保临床合理性。在合成及多中心临床数据上表现优于现有方法，兼具效率与诊断可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习在牙科CBCT金属伪影去除（MAR）中面临两大挑战：监督方法易产生光谱模糊（回归均值），无监督方法可能导致结构幻觉；而现有的去噪扩散模型虽具真实感但依赖缓慢的随机迭代采样，不适用于临床实时应用。因此亟需一种兼具高保真、快速、可靠且符合医学先验的MAR方法。

Method: 提出物理奠基的流形投影（PGMP）框架，包含三部分：1）基于蒙特卡洛光谱建模和患者数字孪生的解剖自适应物理仿真（AAPS），生成高保真合成训练对；2）改进的DMP-Former模型，采用直接x-预测范式，将图像修复重构为确定性流形投影，实现单次前向传播完成恢复，摆脱随机采样；3）语义结构对齐（SSA）模块，利用医学基础模型MedDINOv3的先验知识锚定解空间，保证输出的临床可解释性。

Result: 在合成数据和多中心临床数据集上的实验表明，PGMP在未见过的解剖结构上显著优于现有SOTA方法，不仅提升图像质量，还大幅提高重建效率，实现快速、可靠、可诊断的金属伪影消除，为临床部署提供可行方案。

Conclusion: PGMP框架通过融合物理建模、确定性深度学习与医学先验，有效解决了现有MAR方法在保真度、速度与临床可信度之间的矛盾，为牙科CBCT金属伪影去除树立了新标准，具备重要临床应用价值。

Abstract: Metal artifacts in Dental CBCT severely obscure anatomical structures, hindering diagnosis. Current deep learning for Metal Artifact Reduction (MAR) faces limitations: supervised methods suffer from spectral blurring due to "regression-to-the-mean", while unsupervised ones risk structural hallucinations. Denoising Diffusion Models (DDPMs) offer realism but rely on slow, stochastic iterative sampling, unsuitable for clinical use. To resolve this, we propose the Physically-Grounded Manifold Projection (PGMP) framework. First, our Anatomically-Adaptive Physics Simulation (AAPS) pipeline synthesizes high-fidelity training pairs via Monte Carlo spectral modeling and patient-specific digital twins, bridging the synthetic-to-real gap. Second, our DMP-Former adapts the Direct x-Prediction paradigm, reformulating restoration as a deterministic manifold projection to recover clean anatomy in a single forward pass, eliminating stochastic sampling. Finally, a Semantic-Structural Alignment (SSA) module anchors the solution using priors from medical foundation models (MedDINOv3), ensuring clinical plausibility. Experiments on synthetic and multi-center clinical datasets show PGMP outperforms state-of-the-art methods on unseen anatomy, setting new benchmarks in efficiency and diagnostic reliability. Code and data: https://github.com/ricoleehduu/PGMP

</details>


### [35] [Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation](https://arxiv.org/abs/2512.24271)
*Zhe Huang,Hao Wen,Aiming Hao,Bingze Song,Meiqi Wu,Jiahong Wu,Xiangxiang Chu,Sheng Lu,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出DualityForge框架，通过可控扩散视频编辑生成反事实视频数据，构建DualityVidQA数据集，并设计DNA-Train训练方法，有效减少MLLM在反事实视频上的幻觉问题，显著提升模型性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在视频理解中过度依赖语言先验，导致在违背常识的反事实视频上产生视觉无依据的幻觉，而收集标注反事实数据成本高昂，亟需高效的数据合成方法。

Method: 提出DualityForge框架，利用可控扩散技术将真实视频转化为反事实场景，结合结构化上下文信息自动生成高质量视频-问答对，用于对比训练；设计DNA-Train两阶段训练策略，引入成对ℓ₁优势归一化以实现更稳定高效的策略优化。

Result: 在DualityVidQA-Test上相比Qwen2.5-VL-7B基线减少幻觉24.0%；在幻觉与通用基准上均取得显著提升，展现出强泛化能力。

Conclusion: 所提方法通过数据合成与新型训练范式有效缓解了多模态大模型在反事实视频理解中的幻觉问题，具备良好的应用前景和开源价值。

Abstract: Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To address this, we introduce DualityForge, a novel counterfactual data synthesis framework that employs controllable, diffusion-based video editing to transform real-world videos into counterfactual scenarios. By embedding structured contextual information into the video editing and QA generation processes, the framework automatically produces high-quality QA pairs together with original-edited video pairs for contrastive training. Based on this, we build DualityVidQA, a large-scale video dataset designed to reduce MLLM hallucinations. In addition, to fully exploit the contrastive nature of our paired data, we propose Duality-Normalized Advantage Training (DNA-Train), a two-stage SFT-RL training regime where the RL phase applies pair-wise $\ell_1$ advantage normalization, thereby enabling a more stable and efficient policy optimization. Experiments on DualityVidQA-Test demonstrate that our method substantially reduces model hallucinations on counterfactual videos, yielding a relative improvement of 24.0% over the Qwen2.5-VL-7B baseline. Moreover, our approach achieves significant gains across both hallucination and general-purpose benchmarks, indicating strong generalization capability. We will open-source our dataset and code.

</details>


### [36] [LiftProj: Space Lifting and Projection-Based Panorama Stitching](https://arxiv.org/abs/2512.24276)
*Yuan Jia,Ruimin Wu,Rui Song,Jiaojiao Li,Bin Song*

Main category: cs.CV

TL;DR: 本文提出一种空间提升的全景拼接框架，将输入图像提升至统一坐标系下的三维点云表示，通过置信度加权实现跨视角全局融合，建立三维投影中心并采用等距圆柱投影映射到全景流形，最后在画布域进行孔洞填充以恢复连续纹理与语义一致性。该方法从二维变形范式转向三维一致性范式，可灵活集成多种3D重建与补全模块。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接方法依赖二维单应性变换和网格变形，在处理具有多层深度和遮挡的三维场景时易产生鬼影、结构弯曲和拉伸畸变，尤其在多视角累积与360°闭环拼接中问题更显著。

Method: 首先将每张输入图像升维为统一坐标系下的密集三维点表示；利用置信度加权实现跨视角全局融合；构建三维空间中的统一投影中心，采用等距圆柱投影将融合数据映射至单一全景流形；最后在画布域执行孔洞填充以修复视角切换带来的未知区域。

Result: 实验表明，该方法在大视差和复杂遮挡场景下显著降低几何畸变与鬼影伪影，生成的全景图更加自然、几何一致，且支持多种3D提升与补全模块的灵活集成。

Conclusion: 本研究将图像拼接从二维变形范式重构为三维一致性范式，为高保真全景拼接提供了新的技术路径，尤其适用于真实三维场景与复杂视角布局。

Abstract: Traditional image stitching techniques have predominantly utilized two-dimensional homography transformations and mesh warping to achieve alignment on a planar surface. While effective for scenes that are approximately coplanar or exhibit minimal parallax, these approaches often result in ghosting, structural bending, and stretching distortions in non-overlapping regions when applied to real three-dimensional scenes characterized by multiple depth layers and occlusions. Such challenges are exacerbated in multi-view accumulations and 360° closed-loop stitching scenarios. In response, this study introduces a spatially lifted panoramic stitching framework that initially elevates each input image into a dense three-dimensional point representation within a unified coordinate system, facilitating global cross-view fusion augmented by confidence metrics. Subsequently, a unified projection center is established in three-dimensional space, and an equidistant cylindrical projection is employed to map the fused data onto a single panoramic manifold, thereby producing a geometrically consistent 360° panoramic layout. Finally, hole filling is conducted within the canvas domain to address unknown regions revealed by viewpoint transitions, restoring continuous texture and semantic coherence. This framework reconceptualizes stitching from a two-dimensional warping paradigm to a three-dimensional consistency paradigm and is designed to flexibly incorporate various three-dimensional lifting and completion modules. Experimental evaluations demonstrate that the proposed method substantially mitigates geometric distortions and ghosting artifacts in scenarios involving significant parallax and complex occlusions, yielding panoramic results that are more natural and consistent.

</details>


### [37] [UniAct: Unified Motion Generation and Action Streaming for Humanoid Robots](https://arxiv.org/abs/2512.24321)
*Nan Jiang,Zimo He,Wanhe Yu,Lexi Pang,Yunhao Li,Hongjie Li,Jieming Cui,Yuhan Li,Yizhou Wang,Yixin Zhu,Siyuan Huang*

Main category: cs.CV

TL;DR: UniAct是一种两阶段框架，通过微调的多模态大模型（MLLM）与因果流式处理管道结合，实现人形机器人对多种模态指令（如语言、音乐、轨迹）的实时响应，延迟低于500毫秒。该方法利用共享离散代码本（FSQ）统一输入，确保跨模态对齐并约束运动在物理合理范围内，在零样本追踪不完美参考动作任务中成功率提升19%。在20小时的人形运动基准数据集UniMoCap上验证了其在真实场景中的强泛化能力，推动了通用、响应迅速的人形助手的发展。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将异构指令（如语言、音乐、轨迹）有效转化为稳定且实时的全身动作，限制了人形机器人的灵活性和通用性。

Method: 采用两阶段框架：第一阶段使用微调的多模态大模型（MLLM）处理多模态输入；第二阶段通过因果流式管道实现低延迟执行。利用矢量量化（FSQ）构建共享离散代码本，统一不同模态输入，确保跨模态对齐，并将运动约束在物理合理的流形空间内。

Result: 在零样本追踪不完美参考动作任务中，成功率提升19%；整体系统延迟低于500毫秒；在UniMoCap基准上表现出优异的跨场景泛化能力。

Conclusion: UniAct为实现高灵活性、低延迟、多模态感知与控制统一的人形机器人迈出了关键一步，是迈向通用人形助手的重要进展。

Abstract: A long-standing objective in humanoid robotics is the realization of versatile agents capable of following diverse multimodal instructions with human-level flexibility. Despite advances in humanoid control, bridging high-level multimodal perception with whole-body execution remains a significant bottleneck. Existing methods often struggle to translate heterogeneous instructions -- such as language, music, and trajectories -- into stable, real-time actions. Here we show that UniAct, a two-stage framework integrating a fine-tuned MLLM with a causal streaming pipeline, enables humanoid robots to execute multimodal instructions with sub-500 ms latency. By unifying inputs through a shared discrete codebook via FSQ, UniAct ensures cross-modal alignment while constraining motions to a physically grounded manifold. This approach yields a 19% improvement in the success rate of zero-shot tracking of imperfect reference motions. We validate UniAct on UniMoCap, our 20-hour humanoid motion benchmark, demonstrating robust generalization across diverse real-world scenarios. Our results mark a critical step toward responsive, general-purpose humanoid assistants capable of seamless interaction through unified perception and control.

</details>


### [38] [Robust Egocentric Referring Video Object Segmentation via Dual-Modal Causal Intervention](https://arxiv.org/abs/2512.24323)
*Haijing Liu,Zhiyuan Song,Hefeng Wu,Tao Pu,Keze Wang,Liang Lin*

Main category: cs.CV

TL;DR: CERES提出了一种基于因果推理的框架，用于解决第一人称视频中指代对象分割任务中的偏差与视觉混淆问题。通过双模因果干预（后门调整处理语言表示偏差，前门调整融合语义视觉特征与深度信息以缓解视角带来的干扰），显著提升了模型在真实复杂场景下的鲁棒性，并在多个基准上达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在第一人称视频中容易受数据集统计偏差和视角特有干扰（如快速运动、频繁遮挡）的影响，导致学习到虚假相关关系，难以实现可靠的对象分割。因此需要一种能够消除这些偏见并增强泛化能力的新方法。

Method: 提出CERES框架，采用双重因果干预机制：1）利用后门调整对抗由数据分布引起的语言表示偏差；2）通过前门调整将语义视觉特征与几何深度信息结合，基于因果原则构建对第一人称视角更鲁棒的表示。该框架可作为插件模块适配已有强预训练模型。

Result: 在多个Ego-RVOS基准上实现了最先进的性能，验证了因果推理在提升第一人称视频理解模型可靠性方面的有效性。

Conclusion: CERES通过引入因果建模思想，有效缓解了第一人称视频中语言与视觉层面的系统性偏差，为构建更具鲁棒性和可解释性的视频理解模型提供了新思路。

Abstract: Egocentric Referring Video Object Segmentation (Ego-RVOS) aims to segment the specific object actively involved in a human action, as described by a language query, within first-person videos. This task is critical for understanding egocentric human behavior. However, achieving such segmentation robustly is challenging due to ambiguities inherent in egocentric videos and biases present in training data. Consequently, existing methods often struggle, learning spurious correlations from skewed object-action pairings in datasets and fundamental visual confounding factors of the egocentric perspective, such as rapid motion and frequent occlusions. To address these limitations, we introduce Causal Ego-REferring Segmentation (CERES), a plug-in causal framework that adapts strong, pre-trained RVOS backbones to the egocentric domain. CERES implements dual-modal causal intervention: applying backdoor adjustment principles to counteract language representation biases learned from dataset statistics, and leveraging front-door adjustment concepts to address visual confounding by intelligently integrating semantic visual features with geometric depth information guided by causal principles, creating representations more robust to egocentric distortions. Extensive experiments demonstrate that CERES achieves state-of-the-art performance on Ego-RVOS benchmarks, highlighting the potential of applying causal reasoning to build more reliable models for broader egocentric video understanding.

</details>


### [39] [Spatial-aware Vision Language Model for Autonomous Driving](https://arxiv.org/abs/2512.24331)
*Weijie Wei,Zhipeng Luo,Ling Feng,Venice Erin Liong*

Main category: cs.CV

TL;DR: LVLDrive 提出一种新框架，通过引入 LiDAR 点云增强视觉-语言模型在自动驾驶中的 3D 时空理解能力，采用渐进式融合 Q-Former 降低 3D 数据对预训练模型的干扰，并构建 SA-QA 数据集提升三维感知与推理能力，在多个基准测试中表现优于纯视觉方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型依赖 2D 图像进行复杂场景理解与决策，但在度量空间推理和几何推断方面存在不足，影响自动驾驶的安全性与可靠性。为提升其 3D 空间感知能力，需引入更精确的 3D 数据模态。

Method: 提出 LVLDrive 框架，将 LiDAR 点云作为额外输入；设计渐进式融合 Q-Former，逐步注入 LiDAR 特征以保持 VLM 原有知识稳定；构建空间感知问答（SA-QA）数据集，强化模型的 3D 推理能力。

Result: 在多个驾驶基准测试中，LVLDrive 在场景理解、度量空间感知和可靠驾驶决策方面均显著优于仅依赖视觉的方法，验证了显式 3D 度量数据对构建可信 VLM 驱动系统的重要性。

Conclusion: 引入 LiDAR 点云并结合渐进融合策略，可有效提升 VLM 在自动驾驶任务中的 3D 空间理解能力，是实现安全、可靠端到端自动驾驶的关键一步。

Abstract: While Vision-Language Models (VLMs) show significant promise for end-to-end autonomous driving by leveraging the common sense embedded in language models, their reliance on 2D image cues for complex scene understanding and decision-making presents a critical bottleneck for safety and reliability. Current image-based methods struggle with accurate metric spatial reasoning and geometric inference, leading to unreliable driving policies. To bridge this gap, we propose LVLDrive (LiDAR-Vision-Language), a novel framework specifically designed to upgrade existing VLMs with robust 3D metric spatial understanding for autonomous driving by incoperating LiDAR point cloud as an extra input modality. A key challenge lies in mitigating the catastrophic disturbance introduced by disparate 3D data to the pre-trained VLMs. To this end, we introduce a Gradual Fusion Q-Former that incrementally injects LiDAR features, ensuring the stability and preservation of the VLM's existing knowledge base. Furthermore, we develop a spatial-aware question-answering (SA-QA) dataset to explicitly teach the model advanced 3D perception and reasoning capabilities. Extensive experiments on driving benchmarks demonstrate that LVLDrive achieves superior performance compared to vision-only counterparts across scene understanding, metric spatial perception, and reliable driving decision-making. Our work highlights the necessity of explicit 3D metric data for building trustworthy VLM-based autonomous systems.

</details>


### [40] [DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images](https://arxiv.org/abs/2512.24340)
*Wen-wai Yim,Yujuan Fu,Asma Ben Abacha,Meliha Yetisgen,Noel Codella,Roberto Andres Novoa,Josep Malvehy*

Main category: cs.CV

TL;DR: 本文提出DermaVQA-DAS，扩展了DermaVQA数据集，支持闭合式问答（QA）和皮肤病灶分割任务。引入专家设计的皮肤科评估框架DAS，包含36个高层级和27个细粒度评估问题，提供中英文多选选项。通过DAS构建专家标注数据集，并评估多种多模态模型。在分割任务中，不同提示策略影响性能：默认提示在均值最大和均值平均评估下表现最佳；增强提示（结合患者查询标题与内容）在多数投票微评分下表现最优，BiomedParse模型达到0.395的Jaccard指数和0.566的Dice分数。在闭合式问答任务中，各模型表现良好，平均准确率0.729–0.798，o3模型最高（0.798），GPT-4.1次之（0.796），Gemini-1.5-Pro在Gemini系列中表现优异（0.783）。所有资源已公开，以推动患者中心的皮肤科视觉语言建模研究。


<details>
  <summary>Details</summary>
Motivation: 现有皮肤病图像分析基准大多聚焦于皮肤镜图像，缺乏患者自述查询和临床背景信息，限制了其在以患者为中心的医疗护理中的应用。为弥补这一空白，本文旨在构建一个融合临床语境与患者视角的数据集与评估框架。

Method: 提出并应用皮肤科评估框架DAS，系统化提取临床相关特征；构建基于DAS的专家标注数据集，涵盖闭合式问答与病变分割任务；评估多种多模态模型，并探索不同提示策略对分割性能的影响。

Result: 在闭合式问答任务中，模型平均准确率达0.729–0.798，o3模型表现最佳（0.798）；在分割任务中，采用增强提示的BiomedParse模型在多数投票微评分下取得最高性能，Jaccard指数达0.395，Dice分数为0.566。

Conclusion: DermaVQA-DAS及其配套的DAS框架有效提升了皮肤病图像分析中对临床上下文和患者视角的支持能力，为未来患者中心的视觉-语言建模研究提供了高质量数据与评估标准。

Abstract: Recent advances in dermatological image analysis have been driven by large-scale annotated datasets; however, most existing benchmarks focus on dermatoscopic images and lack patient-authored queries and clinical context, limiting their applicability to patient-centered care. To address this gap, we introduce DermaVQA-DAS, an extension of the DermaVQA dataset that supports two complementary tasks: closed-ended question answering (QA) and dermatological lesion segmentation. Central to this work is the Dermatology Assessment Schema (DAS), a novel expert-developed framework that systematically captures clinically meaningful dermatological features in a structured and standardized form. DAS comprises 36 high-level and 27 fine-grained assessment questions, with multiple-choice options in English and Chinese. Leveraging DAS, we provide expert-annotated datasets for both closed QA and segmentation and benchmark state-of-the-art multimodal models. For segmentation, we evaluate multiple prompting strategies and show that prompt design impacts performance: the default prompt achieves the best results under Mean-of-Max and Mean-of-Mean evaluation aggregation schemes, while an augmented prompt incorporating both patient query title and content yields the highest performance under majority-vote-based microscore evaluation, achieving a Jaccard index of 0.395 and a Dice score of 0.566 with BiomedParse. For closed-ended QA, overall performance is strong across models, with average accuracies ranging from 0.729 to 0.798; o3 achieves the best overall accuracy (0.798), closely followed by GPT-4.1 (0.796), while Gemini-1.5-Pro shows competitive performance within the Gemini family (0.783). We publicly release DermaVQA-DAS, the DAS schema, and evaluation protocols to support and accelerate future research in patient-centered dermatological vision-language modeling (https://osf.io/72rp3).

</details>


### [41] [Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems](https://arxiv.org/abs/2512.24385)
*Song Wang,Lingdong Kong,Xiaolu Liu,Hao Shi,Wentong Li,Jianke Zhu,Steven C. H. Hoi*

Main category: cs.CV

TL;DR: 本文提出了一种多模态预训练的综合框架，旨在通过整合摄像头、激光雷达等多源传感器数据，实现自动驾驶车辆和无人机等自主系统中的空间智能。研究梳理了基础模型在单模态下的表现，并深入分析跨模态融合的关键技术与学习策略，构建了一个统一的预训练范式分类体系，涵盖从单模态基线到统一表示学习的完整路径。同时探索了文本与占据表示的融合，以支持开放世界感知与规划。最后指出了计算效率与模型可扩展性等关键瓶颈，并提出了迈向通用多模态基础模型的路线图。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和无人机等自主系统的快速发展，对基于多模态传感器数据（如相机、LiDAR）实现真正空间智能的需求日益迫切。然而，如何有效融合不同传感器的异构信息，构建统一的感知理解能力，仍是当前面临的核心挑战。现有基础模型在单模态任务中表现优异，但在跨模态协同方面存在明显局限。因此，亟需系统性地研究多模态预训练方法，推动空间智能的实现。

Method: 本文采用系统性分析方法，梳理多模态预训练的关键技术路径；通过解构传感器特性与学习策略之间的相互作用，评估平台特定数据集的作用；构建一个统一的预训练范式分类体系，涵盖从单模态基线到联合表示学习的多个层次；引入文本与占据表示融合机制，探索开放世界感知与规划的可能性；并基于实证分析识别出计算效率、模型规模扩展等核心限制因素。

Result: 成功构建了首个面向空间智能的多模态预训练统一分类框架，验证了跨模态联合表征在3D目标检测与语义占据预测等任务上的有效性；证明了文本-占据联合建模对开放世界感知的促进作用；明确了当前多模态模型在计算成本与可扩展性方面的关键瓶颈。

Conclusion: 本研究为构建通用多模态基础模型提供了理论框架与实践路径，强调未来需在高效架构设计、大规模跨模态数据融合及可泛化表示学习等方面持续突破，以实现真实世界中鲁棒的空间智能部署。

Abstract: The rapid advancement of autonomous systems, including self-driving vehicles and drones, has intensified the need to forge true Spatial Intelligence from multi-modal onboard sensor data. While foundation models excel in single-modal contexts, integrating their capabilities across diverse sensors like cameras and LiDAR to create a unified understanding remains a formidable challenge. This paper presents a comprehensive framework for multi-modal pre-training, identifying the core set of techniques driving progress toward this goal. We dissect the interplay between foundational sensor characteristics and learning strategies, evaluating the role of platform-specific datasets in enabling these advancements. Our central contribution is the formulation of a unified taxonomy for pre-training paradigms: ranging from single-modality baselines to sophisticated unified frameworks that learn holistic representations for advanced tasks like 3D object detection and semantic occupancy prediction. Furthermore, we investigate the integration of textual inputs and occupancy representations to facilitate open-world perception and planning. Finally, we identify critical bottlenecks, such as computational efficiency and model scalability, and propose a roadmap toward general-purpose multi-modal foundation models capable of achieving robust Spatial Intelligence for real-world deployment.

</details>


### [42] [RedunCut: Measurement-Driven Sampling and Accuracy Performance Modeling for Low-Cost Live Video Analytics](https://arxiv.org/abs/2512.24386)
*Gur-Eyal Sela,Kumar Krishna Agrawal,Bharathan Balaji,Joseph Gonzalez,Ion Stoica*

Main category: cs.CV

TL;DR: RedunCut 是一种新的动态模型大小选择（DMSS）系统，通过测量驱动的规划器和轻量级数据驱动性能模型，解决了现有方法在采样效率和精度预测上的不足。它在多种视频类型和模型任务中实现了14-62%的计算成本降低，同时保持对有限历史数据和性能漂移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有DMSS方法在处理多样化工作负载时表现不佳，尤其在移动视频和低精度目标下，主要问题在于采样效率低和每段视频的精度预测不准确。

Method: RedunCut采用测量驱动的规划器来评估采样成本与收益的权衡，并使用轻量级、数据驱动的性能模型提升精度预测能力。

Result: 在道路车辆、无人机和监控视频等多种场景下，RedunCut在固定精度下将计算成本降低了14%-62%，且对历史数据有限和性能漂移具有鲁棒性。

Conclusion: RedunCut通过优化采样策略和精度预测，显著提升了动态模型大小选择在实际应用中的有效性与适应性，为大规模实时视频分析提供了高效解决方案。

Abstract: Live video analytics (LVA) runs continuously across massive camera fleets, but inference cost with modern vision models remains high. To address this, dynamic model size selection (DMSS) is an attractive approach: it is content-aware but treats models as black boxes, and could potentially reduce cost by up to 10x without model retraining or modification. Without ground truth labels at runtime, we observe that DMSS methods use two stages per segment: (i) sampling a few models to calculate prediction statistics (e.g., confidences), then (ii) selection of the model size from those statistics. Prior systems fail to generalize to diverse workloads, particularly to mobile videos and lower accuracy targets. We identify that the failure modes stem from inefficient sampling whose cost exceeds its benefit, and inaccurate per-segment accuracy prediction.
  In this work, we present RedunCut, a new DMSS system that addresses both: It uses a measurement-driven planner that estimates the cost-benefit tradeoff of sampling, and a lightweight, data-driven performance model to improve accuracy prediction. Across road-vehicle, drone, and surveillance videos and multiple model families and tasks, RedunCut reduces compute cost by 14-62% at fixed accuracy and remains robust to limited historical data and to drift.

</details>


### [43] [DyStream: Streaming Dyadic Talking Heads Generation via Flow Matching-based Autoregressive Model](https://arxiv.org/abs/2512.24408)
*Bohong Chen,Haiyang Liu*

Main category: cs.CV

TL;DR: DyStream提出一种基于流匹配的自回归模型，用于实时生成双人对话头像视频，通过流友好的自回归框架和带有前瞻模块的因果编码器，在保持低延迟（每帧34毫秒，系统总延迟低于100毫秒）的同时显著提升唇同步质量，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于分块的方法需要非因果上下文窗口，导致高延迟，无法支持实时非语言反馈，影响对话的真实感。为实现超低延迟的逼真双人对话视频生成，需在保证质量的前提下降低延迟。

Method: 采用流匹配的自回归框架进行概率建模，并设计带有前瞻模块的因果编码器，引入短时未来上下文（如60毫秒），以在低延迟下提升生成质量。

Result: DyStream每帧生成仅需34毫秒，系统总延迟低于100毫秒；在HDTF数据集上，离线和在线唇同步置信度分别达到8.13和7.61，优于现有方法。

Conclusion: DyStream是一种简单而有效的实时双人对话头像视频生成方法，通过创新的因果架构与前瞻机制，在极低延迟下实现了领先的唇同步质量，具备实际应用潜力。

Abstract: Generating realistic, dyadic talking head video requires ultra-low latency. Existing chunk-based methods require full non-causal context windows, introducing significant delays. This high latency critically prevents the immediate, non-verbal feedback required for a realistic listener. To address this, we present DyStream, a flow matching-based autoregressive model that could generate video in real-time from both speaker and listener audio. Our method contains two key designs: (1) we adopt a stream-friendly autoregressive framework with flow-matching heads for probabilistic modeling, and (2) We propose a causal encoder enhanced by a lookahead module to incorporate short future context (e.g., 60 ms) to improve quality while maintaining low latency. Our analysis shows this simple-and-effective method significantly surpass alternative causal strategies, including distillation and generative encoder. Extensive experiments show that DyStream could generate video within 34 ms per frame, guaranteeing the entire system latency remains under 100 ms. Besides, it achieves state-of-the-art lip-sync quality, with offline and online LipSync Confidence scores of 8.13 and 7.61 on HDTF, respectively. The model, weights and codes are available.

</details>


### [44] [AI-Driven Evaluation of Surgical Skill via Action Recognition](https://arxiv.org/abs/2512.24411)
*Yan Meng,Daniel A. Donoho,Marcelle Altshuler,Omar Arnaout*

Main category: cs.CV

TL;DR: 提出了一种基于AI的自动化评估微血管吻合术技能的框架，结合TimeSformer改进的时空注意力机制和YOLO-based运动追踪，实现手术视频中动作识别与器械运动学分析。在58个专家标注视频上验证，帧级动作分割准确率达87.7%（后处理提升至93.62%），多维度技能评估平均分类准确率为76%，具备客观、一致、可解释的评估能力，适用于标准化外科培训与评价。


<details>
  <summary>Details</summary>
Motivation: 传统外科技能评估依赖专家主观评判，存在主观性强、评分不一致、耗时耗力等问题，尤其在资源有限的低收入和中等收入国家难以推广，亟需一种客观、高效、可扩展的自动化评估方法。

Method: 采用改进的TimeSformer视频变换器架构，引入分层时间注意力与加权空间注意力机制以增强动作识别能力；结合YOLO-based目标检测与跟踪技术提取精细运动特征，对器械操作进行量化分析；从整体动作执行、关键步骤运动质量及器械通用操作五个维度评估微血管吻合术技能。

Result: 在58个专家标注视频的数据集上，系统实现87.7%的帧级动作分割准确率，经后处理提升至93.62%；在五项技能维度上的平均分类准确率达到76%，有效复现专家评估结果。

Conclusion: 所提出的AI驱动框架能够提供客观、一致且可解释的手术技能评估，具备推动外科教育向数据驱动、标准化方向发展的潜力，尤其适用于资源受限环境下的规模化培训与评价。

Abstract: The development of effective training and evaluation strategies is critical. Conventional methods for assessing surgical proficiency typically rely on expert supervision, either through onsite observation or retrospective analysis of recorded procedures. However, these approaches are inherently subjective, susceptible to inter-rater variability, and require substantial time and effort from expert surgeons. These demands are often impractical in low- and middle-income countries, thereby limiting the scalability and consistency of such methods across training programs. To address these limitations, we propose a novel AI-driven framework for the automated assessment of microanastomosis performance. The system integrates a video transformer architecture based on TimeSformer, improved with hierarchical temporal attention and weighted spatial attention mechanisms, to achieve accurate action recognition within surgical videos. Fine-grained motion features are then extracted using a YOLO-based object detection and tracking method, allowing for detailed analysis of instrument kinematics. Performance is evaluated along five aspects of microanastomosis skill, including overall action execution, motion quality during procedure-critical actions, and general instrument handling. Experimental validation using a dataset of 58 expert-annotated videos demonstrates the effectiveness of the system, achieving 87.7% frame-level accuracy in action segmentation that increased to 93.62% with post-processing, and an average classification accuracy of 76% in replicating expert assessments across all skill aspects. These findings highlight the system's potential to provide objective, consistent, and interpretable feedback, thereby enabling more standardized, data-driven training and evaluation in surgical education.

</details>


### [45] [Exploring Compositionality in Vision Transformers using Wavelet Representations](https://arxiv.org/abs/2512.24438)
*Akshad Shyam Purushottamdas,Pranav K Nayak,Divya Mehul Rajparia,Deekshith Patel,Yashmitha Gogineni,Konda Reddy Mopuri,Sumohana S. Channappayya*

Main category: cs.CV

TL;DR: 本文通过类比语言任务中的组合性分析，研究视觉Transformer（ViT）编码器在视觉任务中学习到的表征。引入基于离散小波变换（DWT）的框架，以测试ViT编码器中表征的组合性。实验表明，一阶DWT分解产生的基元在潜在空间中近似具备组合性，揭示了ViT结构信息的新视角。


<details>
  <summary>Details</summary>
Motivation: 理解ViT编码器如何在视觉任务中组织和表示信息，尤其是其表征是否具有组合性，即能否通过基本成分的组合重建复杂表征。

Method: 提出一个类比于语言模型组合性分析的框架，利用离散小波变换（DWT）生成输入相关的基础成分，并通过检验这些成分在潜空间中的组合能力来评估组合性。

Result: 一阶DWT分解所得的基元能够在潜空间中近似组合，成功重构原始图像表征，表明ViT的表示空间具备一定程度的组合性。

Conclusion: ViT的编码器在潜在空间中表现出对组合性的尊重，这为理解其内部信息结构提供了新视角，且基于DWT的分析方法可有效用于评估视觉模型的表征特性。

Abstract: While insights into the workings of the transformer model have largely emerged by analysing their behaviour on language tasks, this work investigates the representations learnt by the Vision Transformer (ViT) encoder through the lens of compositionality. We introduce a framework, analogous to prior work on measuring compositionality in representation learning, to test for compositionality in the ViT encoder. Crucial to drawing this analogy is the Discrete Wavelet Transform (DWT), which is a simple yet effective tool for obtaining input-dependent primitives in the vision setting. By examining the ability of composed representations to reproduce original image representations, we empirically test the extent to which compositionality is respected in the representation space. Our findings show that primitives from a one-level DWT decomposition produce encoder representations that approximately compose in latent space, offering a new perspective on how ViTs structure information.

</details>


### [46] [F2IDiff: Real-world Image Super-resolution using Feature to Image Diffusion Foundation Model](https://arxiv.org/abs/2512.24473)
*Devendra K. Jangid,Ripon K. Saha,Dilshan Godaliyadda,Jing Li,Seok-Jun Lee,Hamid R. Sheikh*

Main category: cs.CV

TL;DR: 本文提出一种基于低级特征条件控制的单图像超分辨率（SISR）方法，使用DINOv2特征替代传统文本特征，构建名为F2IDiff的生成式基础模型，以解决智能手机拍摄的高保真低分辨率图像在超分过程中因强生成导致幻觉的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本到图像扩散模型（T2IDiff FM）的SISR方法虽提升图像质量，但在消费级摄影中因输入图像保真度高，过度生成易引发不可接受的幻觉；而现有方法依赖高层语义文本特征，难以精确描述小尺度纹理，且不适应大尺寸（如12MP以上）智能手机图像的处理需求。

Method: 提出使用低级视觉特征（DINOv2特征）作为扩散模型的条件输入，构建特征到图像扩散模型（F2IDiff FM），实现对小图像块更严格、更丰富的上下文约束，从而在保持细节真实性的前提下进行精准超分辨率重建。

Result: 实验表明，F2IDiff在高保真手机图像上表现优于现有T2IDiff基线方法，在主观与客观指标上均取得显著提升，尤其在减少幻觉、保留真实纹理方面优势明显。

Conclusion: 通过引入低级视觉特征作为扩散模型的条件输入，F2IDiff有效缓解了生成式SISR在高质量图像上的幻觉问题，为移动端高保真超分辨率提供了可行且有效的解决方案。

Abstract: With the advent of Generative AI, Single Image Super-Resolution (SISR) quality has seen substantial improvement, as the strong priors learned by Text-2-Image Diffusion (T2IDiff) Foundation Models (FM) can bridge the gap between High-Resolution (HR) and Low-Resolution (LR) images. However, flagship smartphone cameras have been slow to adopt generative models because strong generation can lead to undesirable hallucinations. For substantially degraded LR images, as seen in academia, strong generation is required and hallucinations are more tolerable because of the wide gap between LR and HR images. In contrast, in consumer photography, the LR image has substantially higher fidelity, requiring only minimal hallucination-free generation. We hypothesize that generation in SISR is controlled by the stringency and richness of the FM's conditioning feature. First, text features are high level features, which often cannot describe subtle textures in an image. Additionally, Smartphone LR images are at least $12MP$, whereas SISR networks built on T2IDiff FM are designed to perform inference on much smaller images ($<1MP$). As a result, SISR inference has to be performed on small patches, which often cannot be accurately described by text feature. To address these shortcomings, we introduce an SISR network built on a FM with lower-level feature conditioning, specifically DINOv2 features, which we call a Feature-to-Image Diffusion (F2IDiff) Foundation Model (FM). Lower level features provide stricter conditioning while being rich descriptors of even small patches.

</details>


### [47] [Using Large Language Models To Translate Machine Results To Human Results](https://arxiv.org/abs/2512.24518)
*Trishna Niraula,Jonathan Stubblefield*

Main category: cs.CV

TL;DR: 本研究提出了一种将YOLOv5和YOLOv8目标检测模型与大语言模型（LLM）结合的流程，用于从胸部X光图像中自动生成放射科报告。YOLO模型负责检测异常并输出边界框和类别标签，随后由GPT-4生成自然语言描述和临床总结。实验对比了两种YOLO模型在检测精度、推理延迟及生成文本质量上的表现，结果显示AI生成报告与人工报告具有高度语义相似性，但人类评估显示GPT-4在清晰度上表现优异（4.88/5），而在写作风格流畅性上得分较低（2.81/5），表明当前系统虽具备临床准确性，但在风格上仍可被识别为非人类撰写。


<details>
  <summary>Details</summary>
Motivation: 现有基于计算机视觉的医学影像分析系统多输出结构化结果，需依赖放射科医生手动转化为叙述性报告，效率低下且易出错。大语言模型（如GPT-4）的兴起为自动生成高质量放射科报告提供了新可能，旨在减少人工干预，提升诊断流程自动化水平。

Method: 采用YOLOv5和YOLOv8进行胸部X光图像中的异常检测，提取边界框和类别标签；将检测结果作为输入传递给GPT-4，生成自然语言形式的诊断报告；通过余弦相似度衡量生成报告与标准报告的语义一致性，并邀请专业医生对报告的清晰度、流畅性等维度进行主观评分。

Result: YOLOv8在检测精度和推理延迟方面优于YOLOv5；生成报告与真实报告之间表现出较高的语义相似性（高余弦相似度）；人类评估显示GPT-4在清晰度上得分接近满分（4.88/5），但在写作风格流畅性上得分偏低（2.81/5），说明生成内容虽准确但缺乏自然的人类写作节奏和连贯性。

Conclusion: 该集成系统实现了从影像检测到自然语言报告生成的端到端自动化，验证了大语言模型在医学报告生成中的潜力。尽管生成内容具有临床准确性，但其语言风格仍与专业放射科医生撰写的报告存在差异，未来需优化语言模型的上下文连贯性和表达自然度以实现更接近人类水平的输出。

Abstract: Artificial intelligence (AI) has transformed medical imaging, with computer vision (CV) systems achieving state-of-the-art performance in classification and detection tasks. However, these systems typically output structured predictions, leaving radiologists responsible for translating results into full narrative reports. Recent advances in large language models (LLMs), such as GPT-4, offer new opportunities to bridge this gap by generating diagnostic narratives from structured findings. This study introduces a pipeline that integrates YOLOv5 and YOLOv8 for anomaly detection in chest X-ray images with a large language model (LLM) to generate natural-language radiology reports. The YOLO models produce bounding-box predictions and class labels, which are then passed to the LLM to generate descriptive findings and clinical summaries. YOLOv5 and YOLOv8 are compared in terms of detection accuracy, inference latency, and the quality of generated text, as measured by cosine similarity to ground-truth reports. Results show strong semantic similarity between AI and human reports, while human evaluation reveals GPT-4 excels in clarity (4.88/5) but exhibits lower scores for natural writing flow (2.81/5), indicating that current systems achieve clinical accuracy but remain stylistically distinguishable from radiologist-authored text.

</details>


### [48] [Hierarchical Vector-Quantized Latents for Perceptual Low-Resolution Video Compression](https://arxiv.org/abs/2512.24547)
*Manikanta Kotthapalli,Banafsheh Rekabdar*

Main category: cs.CV

TL;DR: 本文提出了一种多尺度向量量化变分自编码器（MS-VQ-VAE），用于生成低分辨率视频的紧凑且高保真度的潜在表示，适用于边缘设备上的高效存储、传输和解码。模型基于VQ-VAE-2扩展至时空域，采用两级分层潜在结构与3D残差卷积，参数量约1850万，针对64x64分辨率视频优化，支持实时流媒体、移动视频分析及CDN存储优化。通过引入基于预训练VGG16的感知损失，显著提升重建质量，在UCF101数据集上达到25.96 dB PSNR和0.8375 SSIM，优于单尺度基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统视频编码器如H.264和HEVC虽压缩效率高，但仅针对像素域重建，不支持机器学习所需的潜在表示，难以融入深度学习流程。随着视频流量激增，亟需一种能生成可直接用于深度学习任务的紧凑视频潜在表示的新方法，尤其在带宽受限和边缘计算资源有限的场景下。

Method: 提出MS-VQ-VAE框架，将VQ-VAE-2扩展至时空域，使用3D残差卷积构建两层级分层潜在结构；引入基于VGG16的感知损失以增强视觉质量；在UCF101数据集上以2秒视频片段（32帧，16 FPS）进行训练，目标为64x64分辨率视频的高效编码。

Result: 在测试集上取得25.96 dB PSNR和0.8375 SSIM；相比单尺度基线，提升1.41 dB PSNR和0.0248 SSIM；模型轻量（约18.5M参数），适合边缘部署。

Conclusion: MS-VQ-VAE成功实现了低分辨率视频的高效、高质量潜在表示生成，具备良好的可扩展性与实用性，适用于带宽敏感场景下的视频压缩与智能处理，是连接传统视频编码与现代深度学习应用的重要桥梁。

Abstract: The exponential growth of video traffic has placed increasing demands on bandwidth and storage infrastructure, particularly for content delivery networks (CDNs) and edge devices. While traditional video codecs like H.264 and HEVC achieve high compression ratios, they are designed primarily for pixel-domain reconstruction and lack native support for machine learning-centric latent representations, limiting their integration into deep learning pipelines. In this work, we present a Multi-Scale Vector Quantized Variational Autoencoder (MS-VQ-VAE) designed to generate compact, high-fidelity latent representations of low-resolution video, suitable for efficient storage, transmission, and client-side decoding. Our architecture extends the VQ-VAE-2 framework to a spatiotemporal setting, introducing a two-level hierarchical latent structure built with 3D residual convolutions. The model is lightweight (approximately 18.5M parameters) and optimized for 64x64 resolution video clips, making it appropriate for deployment on edge devices with constrained compute and memory resources. To improve perceptual reconstruction quality, we incorporate a perceptual loss derived from a pre-trained VGG16 network. Trained on the UCF101 dataset using 2-second video clips (32 frames at 16 FPS), on the test set we achieve 25.96 dB PSNR and 0.8375 SSIM. On validation, our model improves over the single-scale baseline by 1.41 dB PSNR and 0.0248 SSIM. The proposed framework is well-suited for scalable video compression in bandwidth-sensitive scenarios, including real-time streaming, mobile video analytics, and CDN-level storage optimization.

</details>


### [49] [PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.24551)
*Yuanhao Cai,Kunpeng Li,Menglin Jia,Jialiang Wang,Junzhe Sun,Feng Liang,Weifeng Chen,Felix Juefei-Xu,Chu Wang,Ali Thabet,Xiaoliang Dai,Xuan Ju,Alan Yuille,Ji Hou*

Main category: cs.CV

TL;DR: 本文提出了一种名为PhyAugPipe的物理增强视频数据构建管道，利用具备思维链推理能力的视觉语言模型（VLM）构建大规模物理相关视频数据集PhyVidGen-135K。同时提出一种物理感知的分组直接偏好优化框架PhyGDPO，通过基于物理奖励的引导机制（PGR）和高效的LoRA-Switch参考方案（LoRA-SR），提升视频生成对物理规律的一致性。实验表明，该方法在PhyGenBench和VideoPhy2基准上显著优于现有开源方法。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成技术虽在视觉质量上表现良好，但在遵循物理规律方面仍存在挑战。现有方法依赖图形渲染或提示扩展，难以泛化至复杂真实物理场景，且缺乏丰富物理交互的训练数据。因此需要构建更高质量、更具物理一致性的数据与训练框架。

Method: 提出PhyAugPipe用于自动构建大规模物理增强视频数据集；设计PhyGDPO框架，结合分组式Plackett-Luce概率模型与物理引导奖励机制（PGR），并引入轻量级的LoRA-Switch参考策略以降低训练开销。

Result: 在PhyGenBench和VideoPhy2两个基准上，所提方法显著超越现有开源SOTA模型，在物理一致性、动作合理性及视觉质量方面均有明显提升。

Conclusion: 本研究通过构建物理增强数据集与设计物理感知的偏好优化框架，有效提升了文本到视频生成中对物理规律的遵循能力，为真实世界物理行为建模提供了新范式。

Abstract: Recent advances in text-to-video (T2V) generation have achieved good visual quality, yet synthesizing videos that faithfully follow physical laws remains an open challenge. Existing methods mainly based on graphics or prompt extension struggle to generalize beyond simple simulated environments or learn implicit physical reasoning. The scarcity of training data with rich physics interactions and phenomena is also a problem. In this paper, we first introduce a Physics-Augmented video data construction Pipeline, PhyAugPipe, that leverages a vision-language model (VLM) with chain-of-thought reasoning to collect a large-scale training dataset, PhyVidGen-135K. Then we formulate a principled Physics-aware Groupwise Direct Preference Optimization, PhyGDPO, framework that builds upon the groupwise Plackett-Luce probabilistic model to capture holistic preferences beyond pairwise comparisons. In PhyGDPO, we design a Physics-Guided Rewarding (PGR) scheme that embeds VLM-based physics rewards to steer optimization toward physical consistency. We also propose a LoRA-Switch Reference (LoRA-SR) scheme that eliminates memory-heavy reference duplication for efficient training. Experiments show that our method significantly outperforms state-of-the-art open-source methods on PhyGenBench and VideoPhy2. Please check our project page at https://caiyuanhao1998.github.io/project/PhyGDPO for more video results. Our code, models, and data will be released at https://github.com/caiyuanhao1998/Open-PhyGDPO

</details>


### [50] [OCP-LS: An Efficient Algorithm for Visual Localization](https://arxiv.org/abs/2512.24552)
*Jindi Zhong,Hongxia Wang,Huanshui Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新型二阶优化算法，通过引入OCP方法并合理近似海森矩阵的对角元素，有效解决深度学习中的大规模优化问题。在多个标准视觉定位基准上的实验表明，该方法在定位精度、收敛速度、训练稳定性和抗噪声干扰能力方面均显著优于传统优化算法。


<details>
  <summary>Details</summary>
Motivation: 为解决深度学习中大规模优化问题，提升优化算法的收敛速度、训练稳定性和鲁棒性，现有方法在处理高维非凸问题时存在计算开销大或近似不准确的问题。

Method: 结合OCP方法，对海森矩阵的对角元素进行合理近似，设计一种高效且可扩展的二阶优化算法。

Result: 在多个标准视觉定位任务上，所提方法在保持竞争性定位精度的同时，实现了更快的收敛速度、更强的训练稳定性和更高的抗噪声能力。

Conclusion: 所提出的二阶优化算法在大规模深度学习场景下表现出优异性能，具有良好的实用价值和推广潜力。

Abstract: This paper proposes a novel second-order optimization algorithm. It aims to address large-scale optimization problems in deep learning because it incorporates the OCP method and appropriately approximating the diagonal elements of the Hessian matrix. Extensive experiments on multiple standard visual localization benchmarks demonstrate the significant superiority of the proposed method. Compared with conventional optimiza tion algorithms, our framework achieves competitive localization accuracy while exhibiting faster convergence, enhanced training stability, and improved robustness to noise interference.

</details>


### [51] [Improving Few-Shot Change Detection Visual Question Answering via Decision-Ambiguity-guided Reinforcement Fine-Tuning](https://arxiv.org/abs/2512.24591)
*Fuyu Dong,Ke Li,Di Wang,Nan Luo,Yiming Zhang,Kaiyu Li,Jianfei Yang,Quan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于决策模糊性的强化微调框架DARFT，用于提升变化检测视觉问答（CDVQA）模型的判别能力和鲁棒性。针对现有方法在少量样本下表现不佳的问题，作者发现失败主要源于决策模糊性（即正确答案与强干扰项的置信度差异小），为此定义了决策模糊样本（DAS），并设计了基于多样本解码和组内相对优势的优化策略，无需额外标注即可有效抑制干扰项、增强决策边界。实验表明，该方法在少样本场景下显著优于传统监督微调基线。


<details>
  <summary>Details</summary>
Motivation: 当前CDVQA模型在面对决策模糊样本时表现不稳定，即使预测结果看似合理，但其置信度对正确答案与强干扰项相近，导致模型缺乏判别力。因此，需要一种机制来显式优化这些模糊样本，以提升模型的整体鲁棒性和准确性。

Method: 提出DARFT框架：首先使用已训练的SFT模型作为参考策略挖掘决策模糊样本（DAS），然后在这些样本上应用组相对策略优化（group-relative policy optimization）。通过多样本解码获取多个候选答案，并利用组内相对优势计算奖励信号，从而引导模型减少对强干扰项的偏好，增强对正确答案的区分能力。

Result: 在多个标准数据集上的实验显示，DARFT在全量和少样本设置下均显著优于传统的监督微调基线。特别是在少样本条件下，性能提升更为明显，证明了该方法在低资源场景下的有效性。

Conclusion: 决策模糊性是制约CDVQA模型性能的重要因素。DARFT通过显式挖掘和优化决策模糊样本，有效提升了模型的判别力与鲁棒性，为弱监督或少样本条件下的视觉语言模型优化提供了新思路。

Abstract: Change detection visual question answering (CDVQA) requires answering text queries by reasoning about semantic changes in bi-temporal remote sensing images. A straightforward approach is to boost CDVQA performance with generic vision-language models via supervised fine-tuning (SFT). Despite recent progress, we observe that a significant portion of failures do not stem from clearly incorrect predictions, but from decision ambiguity, where the model assigns similar confidence to the correct answer and strong distractors. To formalize this challenge, we define Decision-Ambiguous Samples (DAS) as instances with a small probability margin between the ground-truth answer and the most competitive alternative. We argue that explicitly optimizing DAS is crucial for improving the discriminability and robustness of CDVQA models. To this end, we propose DARFT, a Decision-Ambiguity-guided Reinforcement Fine-Tuning framework that first mines DAS using an SFT-trained reference policy and then applies group-relative policy optimization on the mined subset. By leveraging multi-sample decoding and intra-group relative advantages, DARFT suppresses strong distractors and sharpens decision boundaries without additional supervision. Extensive experiments demonstrate consistent gains over SFT baselines, particularly under few-shot settings.

</details>


### [52] [SliceLens: Fine-Grained and Grounded Error Slice Discovery for Multi-Instance Vision Tasks](https://arxiv.org/abs/2512.24592)
*Wei Zhang,Chaoqun Wang,Zixuan Guan,Sam Kao,Pengfei Zhao,Peng Wu,Sifeng He*

Main category: cs.CV

TL;DR: 提出SliceLens框架，利用LLMs和VLMs进行假设驱动的错误切片发现，结合细粒度基准FeSD，实现对检测、分割等多实例任务中复杂视觉关系导致的误差切片的有效识别与可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对图像分类任务，难以应对多实例任务中的复杂视觉关系导致的系统性错误；且现有基准存在算法偏向或人工标注不真实的问题，无法准确反映真实模型失败情况。

Method: 提出SliceLens框架，通过大语言模型（LLM）和视觉语言模型（VLM）生成并验证基于视觉推理的失败假设，实现细粒度错误切片的可靠发现；同时构建了首个面向实例级视觉任务的细粒度切片发现基准FeSD，包含专家标注、精准定位到局部错误区域的真实地面真值。

Result: 在多个基准及FeSD上实验表明，SliceLens达到当前最佳性能，在FeSD上Precision@10提升至0.73（相比之前的0.31），识别出可解释的错误切片，并通过模型修复实验验证其对实际模型改进的有效性。

Conclusion: SliceLens成功实现了跨任务、细粒度、可解释的错误切片发现，为模型鲁棒性评估与改进提供了有效工具，推动了视觉任务中系统性失败分析的发展。

Abstract: Systematic failures of computer vision models on subsets with coherent visual patterns, known as error slices, pose a critical challenge for robust model evaluation. Existing slice discovery methods are primarily developed for image classification, limiting their applicability to multi-instance tasks such as detection, segmentation, and pose estimation. In real-world scenarios, error slices often arise from corner cases involving complex visual relationships, where existing instance-level approaches lacking fine-grained reasoning struggle to yield meaningful insights. Moreover, current benchmarks are typically tailored to specific algorithms or biased toward image classification, with artificial ground truth that fails to reflect real model failures. To address these limitations, we propose SliceLens, a hypothesis-driven framework that leverages LLMs and VLMs to generate and verify diverse failure hypotheses through grounded visual reasoning, enabling reliable identification of fine-grained and interpretable error slices. We further introduce FeSD (Fine-grained Slice Discovery), the first benchmark specifically designed for evaluating fine-grained error slice discovery across instance-level vision tasks, featuring expert-annotated and carefully refined ground-truth slices with precise grounding to local error regions. Extensive experiments on both existing benchmarks and FeSD demonstrate that SliceLens achieves state-of-the-art performance, improving Precision@10 by 0.42 (0.73 vs. 0.31) on FeSD, and identifies interpretable slices that facilitate actionable model improvements, as validated through model repair experiments.

</details>


### [53] [3D Semantic Segmentation for Post-Disaster Assessment](https://arxiv.org/abs/2512.24593)
*Nhut Le,Maryam Rahnemoonfar*

Main category: cs.CV

TL;DR: 本文针对自然灾害后场景的3D语义分割缺乏专用数据集的问题，利用无人机拍摄的飓风艾伦（2022）受灾区域影像，通过SfM和MVS技术构建了专门的3D点云数据集，并评估了FPT、PTv3和OA-CNNs等SOTA模型，发现现有方法在灾后区域存在显著局限性，强调亟需发展更先进的3D分割技术和专用基准数据集以提升灾后场景理解与应急响应能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型缺乏专为灾后环境设计的3D数据集，导致在灾害后场景中3D语义分割性能受限，难以有效支持灾后评估与应急响应。

Method: 使用无人机采集飓风艾伦（2022）受灾区域的航拍影像，通过结构光重建（SfM）和多视角立体匹配（MVS）技术生成3D点云，构建专用3D数据集，并在该数据集上评估Fast Point Transformer、Point Transformer v3和OA-CNNs等主流3D语义分割模型。

Result: 评估结果显示，现有主流3D语义分割模型在灾后环境中表现不佳，存在显著局限性，表明当前技术难以应对复杂灾后场景的语义理解挑战。

Conclusion: 本研究揭示了现有3D分割方法在灾后场景中的不足，强调必须开发更先进的算法和专门的3D基准数据集，以推动灾后场景理解与智能应急响应的发展。

Abstract: The increasing frequency of natural disasters poses severe threats to human lives and leads to substantial economic losses. While 3D semantic segmentation is crucial for post-disaster assessment, existing deep learning models lack datasets specifically designed for post-disaster environments. To address this gap, we constructed a specialized 3D dataset using unmanned aerial vehicles (UAVs)-captured aerial footage of Hurricane Ian (2022) over affected areas, employing Structure-from-Motion (SfM) and Multi-View Stereo (MVS) techniques to reconstruct 3D point clouds. We evaluated the state-of-the-art (SOTA) 3D semantic segmentation models, Fast Point Transformer (FPT), Point Transformer v3 (PTv3), and OA-CNNs on this dataset, exposing significant limitations in existing methods for disaster-stricken regions. These findings underscore the urgent need for advancements in 3D segmentation techniques and the development of specialized 3D benchmark datasets to improve post-disaster scene understanding and response.

</details>


### [54] [Collaborative Low-Rank Adaptation for Pre-Trained Vision Transformers](https://arxiv.org/abs/2512.24603)
*Zheng Liu,Jinchao Zhu,Gao Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为协同低秩适应（CLoRA）的新微调方法，通过共享基空间和样本无关的多样性增强（SADE）来提升视觉变换器的参数效率与学习性能之间的平衡。该方法在保持极低计算开销的同时，在图像和点云数据集上均取得了优异表现，尤其在点云分析中所需的GFLOPs最少，优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有低秩适应（LoRA）方法在参数效率与性能之间难以平衡，部分方法牺牲性能或引入过多可训练参数，无法兼顾高效与高性能。因此需要一种既能保持低参数量又能有效提升表示学习能力的新方法。

Method: CLoRA包含两个核心组件：1）基空间共享，使所有低秩模块（LRMs）共享一组降维/升维投影空间，通过协作构建各LRM以扩展学习容量；2）样本无关多样性增强（SADE），通过正则化不同矩阵间的相似性，减少冗余表示，促进多样化特征学习。

Result: 在多个主流图像与点云数据集上的实验表明，CLoRA在保持极低参数量和计算成本的前提下，显著提升了微调性能，特别是在点云分析任务中所需GFLOPs最少，优于当前最先进的方法。

Conclusion: CLoRA通过基空间共享与多样性增强机制，成功实现了参数效率与学习性能的更好平衡，为视觉变换器的高效微调提供了一种新范式，尤其适用于资源受限场景下的点云处理任务。

Abstract: Low-rank adaptation (LoRA) has achieved remarkable success in fine-tuning pre-trained vision transformers for various downstream tasks. Existing studies mainly focus on exploring more parameter-efficient strategies or more effective representation learning schemes. However, these methods either sacrifice fine-tuning performance or introduce excessive trainable parameters, failing to strike a balance between learning performance and parameter efficiency. To address this problem, we propose a novel tuning method named collaborative low-rank adaptation (CLoRA) in this paper. CLoRA consists of base-space sharing and sample-agnostic diversity enhancement (SADE) components. To maintain parameter efficiency while expanding the learning capacity of low-rank modules (LRMs), base-space sharing allows all LRMs to share a set of down/up-projection spaces. In CLoRA, the low-rank matrices obtained from the shared spaces collaboratively construct each LRM. Since the representations extracted by these matrices may contain redundant information, SADE is employed to regularize the similarities among them to encourage diverse representations in the training process. We conduct extensive experiments on widely used image and point cloud datasets to evaluate the performance of CLoRA. Experimental results demonstrate that CLoRA strikes a better balance between learning performance and parameter efficiency, while requiring the fewest GFLOPs for point cloud analysis, compared with the state-of-the-art methods.

</details>


### [55] [MoniRefer: A Real-world Large-scale Multi-modal Dataset based on Roadside Infrastructure for 3D Visual Grounding](https://arxiv.org/abs/2512.24605)
*Panquan Yang,Junfei Huang,Zongzhangbao Yin,Yingsong Hu,Anni Xu,Xinyi Luo,Xueqi Sun,Hai Wu,Sheng Ao,Zhaoxing Zhu,Chenglu Wen,Cheng Wang*

Main category: cs.CV

TL;DR: 本文提出了一项新的3D视觉定位任务——面向户外监控场景的3D视觉定位，旨在让道路基础设施能够理解自然语言并定位复杂交通环境中的目标物体。为此，作者构建了首个真实世界的大规模多模态数据集MoniRefer，包含约13.6万条对象和41万余条自然语言描述，覆盖多个复杂交通路口。所有语言描述和3D标签均经人工验证以确保质量。同时提出了端到端的方法Moni3DVG，融合图像外观、几何与光信息进行多模态特征学习与3D定位。大量实验和消融研究验证了方法的有效性。数据集与代码将公开发布。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位研究主要集中在室内或车载视角的驾驶场景，缺乏针对道路基础设施传感器采集的户外监控场景的数据与方法。为实现基础设施级的交通场景理解，亟需新任务与数据支持。

Method: 提出Moni3DVG方法，利用图像的外观信息、点云的几何与光学信息，进行多模态特征学习，实现端到端的3D物体定位。

Result: 在所提出的基准上进行了大量实验与消融研究，结果表明Moni3DVG方法具有优越性和有效性。

Conclusion: 本文首次定义了面向户外监控场景的3D视觉定位任务，并构建了大规模真实世界数据集MoniRefer。所提方法Moni3DVG在该任务上表现优异，未来将公开数据集与代码以推动领域发展。

Abstract: 3D visual grounding aims to localize the object in 3D point cloud scenes that semantically corresponds to given natural language sentences. It is very critical for roadside infrastructure system to interpret natural languages and localize relevant target objects in complex traffic environments. However, most existing datasets and approaches for 3D visual grounding focus on the indoor and outdoor driving scenes, outdoor monitoring scenarios remain unexplored due to scarcity of paired point cloud-text data captured by roadside infrastructure sensors. In this paper, we introduce a novel task of 3D Visual Grounding for Outdoor Monitoring Scenarios, which enables infrastructure-level understanding of traffic scenes beyond the ego-vehicle perspective. To support this task, we construct MoniRefer, the first real-world large-scale multi-modal dataset for roadside-level 3D visual grounding. The dataset consists of about 136,018 objects with 411,128 natural language expressions collected from multiple complex traffic intersections in the real-world environments. To ensure the quality and accuracy of the dataset, we manually verified all linguistic descriptions and 3D labels for objects. Additionally, we also propose a new end-to-end method, named Moni3DVG, which utilizes the rich appearance information provided by images and geometry and optical information from point cloud for multi-modal feature learning and 3D object localization. Extensive experiments and ablation studies on the proposed benchmarks demonstrate the superiority and effectiveness of our method. Our dataset and code will be released.

</details>


### [56] [FireRescue: A UAV-Based Dataset and Enhanced YOLO Model for Object Detection in Fire Rescue Scenes](https://arxiv.org/abs/2512.24622)
*Qingyu Xu,Runtong Zhang,Zihuan Qiu,Fanman Meng*

Main category: cs.CV

TL;DR: 针对消防救援场景中目标检测存在的挑战，本文构建了名为FireRescue的新数据集，涵盖城市、山地、森林和水域等多种场景，包含8类关键目标（如消防车、消防员），共15,980张图像和32,000个边界框。同时提出改进模型FRS-YOLO，引入多维协同增强注意力模块以区分易混淆类别，并结合动态特征采样器增强前景特征，缓解烟雾遮挡与背景干扰问题。实验表明该方法显著提升了YOLO系列在复杂救援场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于山地或森林等环境，忽视了更常见且结构复杂的都市救援场景；同时检测类别有限，缺乏对消防车、消防员等关键指挥目标的全面覆盖，制约了智能决策支持能力。

Method: 构建FireRescue数据集，涵盖多场景、多类别；提出FRS-YOLO模型，集成多维协同增强注意力模块与动态特征采样器，提升小目标检测与抗干扰能力。

Result: 所提方法在复杂消防救援场景下显著优于传统YOLO模型，在各类别检测精度与小目标识别率上均有明显提升，有效缓解了类别混淆与漏检问题。

Conclusion: 本研究通过构建大规模多场景、多类别数据集并设计针对性改进模型，为消防救援中的智能目标检测提供了有效解决方案，推动了相关领域向实战化、系统化方向发展。

Abstract: Object detection in fire rescue scenarios is importance for command and decision-making in firefighting operations. However, existing research still suffers from two main limitations. First, current work predominantly focuses on environments such as mountainous or forest areas, while paying insufficient attention to urban rescue scenes, which are more frequent and structurally complex. Second, existing detection systems include a limited number of classes, such as flames and smoke, and lack a comprehensive system covering key targets crucial for command decisions, such as fire trucks and firefighters. To address the above issues, this paper first constructs a new dataset named "FireRescue" for rescue command, which covers multiple rescue scenarios, including urban, mountainous, forest, and water areas, and contains eight key categories such as fire trucks and firefighters, with a total of 15,980 images and 32,000 bounding boxes. Secondly, to tackle the problems of inter-class confusion and missed detection of small targets caused by chaotic scenes, diverse targets, and long-distance shooting, this paper proposes an improved model named FRS-YOLO. On the one hand, the model introduces a plug-and-play multidi-mensional collaborative enhancement attention module, which enhances the discriminative representation of easily confused categories (e.g., fire trucks vs. ordinary trucks) through cross-dimensional feature interaction. On the other hand, it integrates a dynamic feature sampler to strengthen high-response foreground features, thereby mitigating the effects of smoke occlusion and background interference. Experimental results demonstrate that object detection in fire rescue scenarios is highly challenging, and the proposed method effectively improves the detection performance of YOLO series models in this context.

</details>


### [57] [From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation](https://arxiv.org/abs/2512.24639)
*Siyang Wang,Hanting Li,Wei Li,Jie Hu,Xinghao Chen,Feng Zhao*

Main category: cs.CV

TL;DR: 本文提出RadAR，一种高效且可并行化的自回归视觉生成框架，通过径向拓扑结构组织生成过程，将视觉令牌按与中心点的空间距离分组为多个同心环，实现环内并行生成，提升推理效率；同时引入嵌套注意力机制动态修正不一致预测，缓解误差累积。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型依赖逐令牌顺序解码，导致推理效率低下；而视觉令牌具有强局部依赖和空间相关性，现有栅格扫描解码方式未充分利用此特性。

Method: 采用径向拓扑结构，以一个初始令牌为中心，将其余令牌按空间距离分组为同心环，从内向外进行环级并行生成；引入嵌套注意力机制，在前向传播中动态修正不合理输出，减少错误传播。

Result: RadAR在保持自回归模型表示能力的同时，显著提升了生成效率，实现了高并行度的视觉生成，有效缓解了因并行生成导致的预测不一致问题。

Conclusion: RadAR通过结合径向并行化与动态输出修正，成功在保持视觉生成质量的前提下大幅提升推理速度，为自回归视觉生成提供了高效的替代方案。

Abstract: Inspired by the remarkable success of autoregressive models in language modeling, this paradigm has been widely adopted in visual generation. However, the sequential token-by-token decoding mechanism inherent in traditional autoregressive models leads to low inference efficiency.In this paper, we propose RadAR, an efficient and parallelizable framework designed to accelerate autoregressive visual generation while preserving its representational capacity. Our approach is motivated by the observation that visual tokens exhibit strong local dependencies and spatial correlations with their neighbors--a property not fully exploited in standard raster-scan decoding orders. Specifically, we organize the generation process around a radial topology: an initial token is selected as the starting point, and all other tokens are systematically grouped into multiple concentric rings according to their spatial distances from this center. Generation then proceeds in a ring-wise manner, from inner to outer regions, enabling the parallel prediction of all tokens within the same ring. This design not only preserves the structural locality and spatial coherence of visual scenes but also substantially increases parallelization. Furthermore, to address the risk of inconsistent predictions arising from simultaneous token generation with limited context, we introduce a nested attention mechanism. This mechanism dynamically refines implausible outputs during the forward pass, thereby mitigating error accumulation and preventing model collapse. By integrating radial parallel prediction with dynamic output correction, RadAR significantly improves generation efficiency.

</details>


### [58] [CPJ: Explainable Agricultural Pest Diagnosis via Caption-Prompt-Judge with LLM-Judged Refinement](https://arxiv.org/abs/2512.24947)
*Wentao Zhang,Tao Fang,Lina Lu,Lifei Wang,Weihe Zhong*

Main category: cs.CV

TL;DR: CPJ是一种无需训练的少样本框架，通过生成结构化可解释的图像描述，提升农业病害视觉问答（VQA）性能。利用大视觉语言模型生成多角度描述，并通过LLM作为评判器迭代优化，最终实现疾病识别与管理建议的双回答。在CDDMBench上，使用GPT-5-mini生成的描述，GPT-5-Nano在分类准确率和问答得分上分别比无描述基线提升22.7和19.5个百分点，且提供透明、基于证据的推理，无需微调即可实现鲁棒、可解释的农业诊断。


<details>
  <summary>Details</summary>
Motivation: 现有作物病害诊断方法依赖昂贵的监督微调，在领域迁移下表现不佳，缺乏可解释性，亟需一种无需训练、可解释且适应性强的少样本诊断框架。

Method: 提出Caption--Prompt--Judge（CPJ）框架，包括：1）利用大视觉语言模型生成多角度图像描述；2）通过LLM-as-Judge模块迭代优化描述质量；3）基于优化后的描述进行双答案视觉问答（疾病识别与管理建议），实现可解释诊断。

Result: 在CDDMBench数据集上，使用GPT-5-mini生成的描述，GPT-5-Nano在疾病分类任务上提升22.7个百分点，在问答任务上提升19.5个百分点，显著优于无描述基线，且推理过程透明可解释。

Conclusion: CPJ框架实现了无需微调的高效、可解释农业病害诊断，具备强泛化能力与透明推理机制，为智能农业决策提供了新范式。

Abstract: Accurate and interpretable crop disease diagnosis is essential for agricultural decision-making, yet existing methods often rely on costly supervised fine-tuning and perform poorly under domain shifts. We propose Caption--Prompt--Judge (CPJ), a training-free few-shot framework that enhances Agri-Pest VQA through structured, interpretable image captions. CPJ employs large vision-language models to generate multi-angle captions, refined iteratively via an LLM-as-Judge module, which then inform a dual-answer VQA process for both recognition and management responses. Evaluated on CDDMBench, CPJ significantly improves performance: using GPT-5-mini captions, GPT-5-Nano achieves \textbf{+22.7} pp in disease classification and \textbf{+19.5} points in QA score over no-caption baselines. The framework provides transparent, evidence-based reasoning, advancing robust and explainable agricultural diagnosis without fine-tuning. Our code and data are publicly available at: https://github.com/CPJ-Agricultural/CPJ-Agricultural-Diagnosis.

</details>


### [59] [Renormalization Group Guided Tensor Network Structure Search](https://arxiv.org/abs/2512.24663)
*Maolin Wang,Bowen Yu,Sheng Zhang,Linjie Mi,Wanyu Wang,Yiqi Wang,Pengyue Jia,Xuetao Wei,Zenglin Xu,Ruocheng Guo,Xiangyu Zhao*

Main category: cs.CV

TL;DR: RGTN proposes a physics-inspired tensor network structure search framework using multi-scale renormalization group flows to overcome limitations in computational tractability, structure adaptivity, and optimization robustness. It enables continuous, scale-aware structure evolution through learnable edge gates and physical metrics like node tension and edge information flow, achieving superior compression and speed—4–600× faster than prior methods.


<details>
  <summary>Details</summary>
Motivation: Existing TN-SS methods are limited by single-scale optimization, discrete search spaces, and inefficient separation of structure and parameter optimization, leading to poor adaptability and scalability across diverse tensor data.

Method: RGTN employs renormalization group-guided multi-scale refinement: starting from coarse, low-complexity structures and progressively refining to finer scales. It uses learnable edge gates for dynamic topology adjustment and leverages physical quantities (node tension, edge information flow) to guide intelligent structure proposals. Scale-induced perturbations help escape local minima.

Result: RGTN achieves state-of-the-art compression ratios on light field data, high-order synthetic tensors, and video completion tasks, while being 4–600× faster than existing methods, demonstrating significant gains in both efficiency and effectiveness.

Conclusion: The physics-inspired RGTN framework effectively addresses key challenges in tensor network structure search by enabling continuous, adaptive, and efficient multi-scale optimization, paving the way for more scalable and robust tensor decomposition in high-dimensional data.

Abstract: Tensor network structure search (TN-SS) aims to automatically discover optimal network topologies and rank configurations for efficient tensor decomposition in high-dimensional data representation. Despite recent advances, existing TN-SS methods face significant limitations in computational tractability, structure adaptivity, and optimization robustness across diverse tensor characteristics. They struggle with three key challenges: single-scale optimization missing multi-scale structures, discrete search spaces hindering smooth structure evolution, and separated structure-parameter optimization causing computational inefficiency. We propose RGTN (Renormalization Group guided Tensor Network search), a physics-inspired framework transforming TN-SS via multi-scale renormalization group flows. Unlike fixed-scale discrete search methods, RGTN uses dynamic scale-transformation for continuous structure evolution across resolutions. Its core innovation includes learnable edge gates for optimization-stage topology modification and intelligent proposals based on physical quantities like node tension measuring local stress and edge information flow quantifying connectivity importance. Starting from low-complexity coarse scales and refining to finer ones, RGTN finds compact structures while escaping local minima via scale-induced perturbations. Extensive experiments on light field data, high-order synthetic tensors, and video completion tasks show RGTN achieves state-of-the-art compression ratios and runs 4-600$\times$ faster than existing methods, validating the effectiveness of our physics-inspired approach.

</details>


### [60] [Evolving, Not Training: Zero-Shot Reasoning Segmentation via Evolutionary Prompting](https://arxiv.org/abs/2512.24702)
*Kai Ye,Xiaotong You,Jianghang Lin,Jiayi Ji,Pingyang Dai,Liujuan Cao*

Main category: cs.CV

TL;DR: EVOL-SAM3 提出了一种零样本的推理分割框架，通过在推理时进行进化搜索，克服了传统方法中静态推理和训练依赖的局限。该方法采用 '生成-评估-演化' 循环，结合视觉竞技场、语义突变和异构竞技场模块，实现多轮优化与自我修正，显著提升推理深度与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法依赖监督微调或强化学习，存在灾难性遗忘、训练不稳定等问题；而训练-free方法受限于单次生成-分割流程，缺乏推理深度与纠错能力。因此需要一种无需训练、具备自适应优化能力的新型推理机制。

Method: 提出 EVOL-SAM3 框架，将推理分割建模为推理时的进化搜索过程。包含：(1) 提示种群维护与迭代演化；(2) 无参考的视觉竞技场进行提示适应度评估；(3) 语义突变操作引入多样性并纠正语义错误；(4) 异构竞技场融合几何先验与语义推理，保障最终选择鲁棒性。

Result: 在 ReasonSeg 基准上，EVOL-SAM3 实现零样本性能超越大量静态基线与全监督先进方法，验证了其在复杂语言理解与像素级定位上的强大能力。

Conclusion: EVOL-SAM3 成功将推理分割从固定提示范式转向动态进化搜索，展示了无需训练即可实现深度推理与自我修正的潜力，为未来通用视觉-语言理解系统提供了新思路。

Abstract: Reasoning Segmentation requires models to interpret complex, context-dependent linguistic queries to achieve pixel-level localization. Current dominant approaches rely heavily on Supervised Fine-Tuning (SFT) or Reinforcement Learning (RL). However, SFT suffers from catastrophic forgetting and domain dependency, while RL is often hindered by training instability and rigid reliance on predefined reward functions. Although recent training-free methods circumvent these training burdens, they are fundamentally limited by a static inference paradigm. These methods typically rely on a single-pass "generate-then-segment" chain, which suffers from insufficient reasoning depth and lacks the capability to self-correct linguistic hallucinations or spatial misinterpretations. In this paper, we challenge these limitations and propose EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. Instead of relying on a fixed prompt, EVOL-SAM3 maintains a population of prompt hypotheses and iteratively refines them through a "Generate-Evaluate-Evolve" loop. We introduce a Visual Arena to assess prompt fitness via reference-free pairwise tournaments, and a Semantic Mutation operator to inject diversity and correct semantic errors. Furthermore, a Heterogeneous Arena module integrates geometric priors with semantic reasoning to ensure robust final selection. Extensive experiments demonstrate that EVOL-SAM3 not only substantially outperforms static baselines but also significantly surpasses fully supervised state-of-the-art methods on the challenging ReasonSeg benchmark in a zero-shot setting. The code is available at https://github.com/AHideoKuzeA/Evol-SAM3.

</details>


### [61] [Splatwizard: A Benchmark Toolkit for 3D Gaussian Splatting Compression](https://arxiv.org/abs/2512.24742)
*Xiang Liu,Yimin Zhou,Jinxiang Wang,Yujun Huang,Shuzhao Xie,Shiyu Qin,Mingyao Hong,Jiawei Li,Yaowei Wang,Zhi Wang,Shu-Tao Xia,Bin Chen*

Main category: cs.CV

TL;DR: 本文提出Splatwizard，一个专为3D高斯点云压缩模型设计的统一基准测试工具包，旨在解决现有评估体系在渲染速度、率失真权衡、内存效率和几何精度等方面的不足。该工具包提供易用框架以实现新模型，并集成自动化流程计算图像质量、点云重构的切比雪夫距离、渲染帧率及资源消耗等关键指标。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯点云（3DGS）压缩算法快速发展，但缺乏标准化、全面的评估工具，尤其在压缩任务中缺少针对渲染速度、率失真、内存效率和几何精度等核心特性的综合评估指标，亟需一个统一的基准测试框架来推动方法比较与进步。

Method: 提出Splatwizard，一个集成了模型实现接口与自动化评估流水线的基准测试工具包，支持快速部署新压缩模型，并自动计算包括图像质量、点云重构误差、渲染帧率和资源消耗在内的多维度性能指标。

Result: Splatwizard成功构建了一个统一、可扩展的评估平台，显著提升了3DGS压缩模型的评测效率与科学性，支持对多种先进压缩技术的公平比较。

Conclusion: Splatwizard为3DGS压缩研究提供了标准化、自动化且全面的评估解决方案，有助于推动该领域方法的系统化发展与创新。

Abstract: The recent advent of 3D Gaussian Splatting (3DGS) has marked a significant breakthrough in real-time novel view synthesis. However, the rapid proliferation of 3DGS-based algorithms has created a pressing need for standardized and comprehensive evaluation tools, especially for compression task. Existing benchmarks often lack the specific metrics necessary to holistically assess the unique characteristics of different methods, such as rendering speed, rate distortion trade-offs memory efficiency, and geometric accuracy. To address this gap, we introduce Splatwizard, a unified benchmark toolkit designed specifically for benchmarking 3DGS compression models. Splatwizard provides an easy-to-use framework to implement new 3DGS compression model and utilize state-of-the-art techniques proposed by previous work. Besides, an integrated pipeline that automates the calculation of key performance indicators, including image-based quality metrics, chamfer distance of reconstruct mesh, rendering frame rates, and computational resource consumption is included in the framework as well. Code is available at https://github.com/splatwizard/splatwizard

</details>


### [62] [UniC-Lift: Unified 3D Instance Segmentation via Contrastive Learning](https://arxiv.org/abs/2512.24763)
*Ankit Dhiman,Srinath R,Jaswanth Reddy,Lokesh R Boregowda,Venkatesh Babu Radhakrishnan*

Main category: cs.CV

TL;DR: 本文提出一种统一框架，将2D实例标签一致性处理与3D分割优化合并，通过可学习的特征嵌入和创新的“嵌入到标签”解码机制，提升3D高斯点云的实例/语义分割性能。针对边界区域的伪影问题，引入边界硬挖掘策略，并在光栅化特征上添加线性层以稳定训练，显著改善边界分割效果。方法在ScanNet、Replica3D和Messy-Rooms数据集上均优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视图2D分割扩展至3D时面临实例标签不一致问题，导致3D分割性能不佳。传统两阶段方法依赖对比学习或预处理标签，存在超参数敏感或计算开销大等问题，亟需更高效、稳定的统一解决方案。

Method: 提出统一框架，将标签一致性与3D分割优化融合；引入可学习的特征嵌入表示每个高斯原语的语义信息；设计“嵌入到标签”解码机制实现高效推理；针对边界伪影，采用边界硬样本挖掘，结合光栅化特征上的线性层缓解训练不稳定性。

Result: 在ScanNet、Replica3D和Messy-Rooms数据集上，该方法在定性和定量评估中均优于现有基线，尤其在物体边界分割精度上表现显著提升。

Conclusion: 所提方法通过统一优化流程与边界感知训练策略，有效解决了3DGS中多视图标签不一致与边界模糊问题，实现了更准确、稳定的3D实例/语义分割。

Abstract: 3D Gaussian Splatting (3DGS) and Neural Radiance Fields (NeRF) have advanced novel-view synthesis. Recent methods extend multi-view 2D segmentation to 3D, enabling instance/semantic segmentation for better scene understanding. A key challenge is the inconsistency of 2D instance labels across views, leading to poor 3D predictions. Existing methods use a two-stage approach in which some rely on contrastive learning with hyperparameter-sensitive clustering, while others preprocess labels for consistency. We propose a unified framework that merges these steps, reducing training time and improving performance by introducing a learnable feature embedding for segmentation in Gaussian primitives. This embedding is then efficiently decoded into instance labels through a novel "Embedding-to-Label" process, effectively integrating the optimization. While this unified framework offers substantial benefits, we observed artifacts at the object boundaries. To address the object boundary issues, we propose hard-mining samples along these boundaries. However, directly applying hard mining to the feature embeddings proved unstable. Therefore, we apply a linear layer to the rasterized feature embeddings before calculating the triplet loss, which stabilizes training and significantly improves performance. Our method outperforms baselines qualitatively and quantitatively on the ScanNet, Replica3D, and Messy-Rooms datasets.

</details>


### [63] [Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation](https://arxiv.org/abs/2512.24792)
*Takeru Kusakabe,Yudai Hirose,Mashiho Mukaida,Satoshi Ono*

Main category: cs.CV

TL;DR: 提出一种基于投影的对抗攻击方法，通过物理在回路（PITL）优化和分布式协方差矩阵自适应进化策略，在实际环境中生成导致单目深度估计模型误判的对抗样本，使目标物体部分消失，验证了DNN-based MDE模型的脆弱性。


<details>
  <summary>Details</summary>
Motivation: DNN-based单目深度估计模型易受对抗攻击影响，导致深度估计错误，威胁其在实际应用中的可靠性，亟需提升鲁棒性。

Method: 采用基于投影的对抗攻击方法，结合物理在回路（PITL）优化与分布式协方差矩阵适应进化策略，在真实环境中评估对抗扰动效果，考虑设备特性和环境干扰。

Result: 实验表明，该方法成功生成导致深度误估的对抗样本，使目标场景中物体部分消失，证实了MDE模型的脆弱性。

Conclusion: 所提方法有效揭示了DNN-based MDE模型在物理世界中的安全漏洞，为增强其鲁棒性提供了重要依据。

Abstract: Deep neural networks (DNNs) remain vulnerable to adversarial attacks that cause misclassification when specific perturbations are added to input images. This vulnerability also threatens the reliability of DNN-based monocular depth estimation (MDE) models, making robustness enhancement a critical need in practical applications. To validate the vulnerability of DNN-based MDE models, this study proposes a projection-based adversarial attack method that projects perturbation light onto a target object. The proposed method employs physics-in-the-loop (PITL) optimization -- evaluating candidate solutions in actual environments to account for device specifications and disturbances -- and utilizes a distributed covariance matrix adaptation evolution strategy. Experiments confirmed that the proposed method successfully created adversarial examples that lead to depth misestimations, resulting in parts of objects disappearing from the target scene.

</details>


### [64] [Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training](https://arxiv.org/abs/2512.24794)
*Andrew Tinits,Stephen Mann*

Main category: cs.CV

TL;DR: 本文提出了一种改进的Noise2Noise方法，允许在训练中对噪声目标图像应用某些非线性函数（如色调映射），而不会引入显著偏差。通过建立理论框架分析非线性的影响，作者识别出一类具有最小偏差的非线性函数，并将其应用于高动态范围（HDR）图像的蒙特卡洛渲染去噪任务。实验表明，该方法在仅使用噪声数据训练的情况下，性能接近基于干净参考图像的原始模型。


<details>
  <summary>Details</summary>
Motivation: Noise2Noise方法虽能避免依赖干净标签，但无法处理目标图像上的非线性变换，因非线性会改变期望值，导致偏差。然而非线性在图像处理中普遍存在，限制其应用。因此需要找到可安全应用的非线性函数，以拓展方法适用性。

Method: 提出理论分析框架，用于评估非线性函数对噪声目标的影响；定义一类在统计上保持低偏差的非线性函数；结合特定损失函数与非线性色调映射，有效抑制蒙特卡洛渲染中的极端值（异常值）影响。

Result: 在蒙特卡洛渲染生成的HDR图像去噪任务中，新方法仅用噪声数据训练，即可达到接近使用高样本参考图像训练的原模型性能，证明了非线性操作在噪声到噪声训练中的可行性与有效性。

Conclusion: 本研究揭示了在噪声到噪声训练中可安全使用特定非线性函数的条件，扩展了Noise2Noise的应用范围，尤其适用于高动态范围图像去噪等存在极端值挑战的场景。

Abstract: The Noise2Noise method allows for training machine learning-based denoisers with pairs of input and target images where both the input and target can be noisy. This removes the need for training with clean target images, which can be difficult to obtain. However, Noise2Noise training has a major limitation: nonlinear functions applied to the noisy targets will skew the results. This bias occurs because the nonlinearity makes the expected value of the noisy targets different from the clean target image. Since nonlinear functions are common in image processing, avoiding them limits the types of preprocessing that can be performed on the noisy targets. Our main insight is that certain nonlinear functions can be applied to the noisy targets without adding significant bias to the results. We develop a theoretical framework for analyzing the effects of these nonlinearities, and describe a class of nonlinear functions with minimal bias.
  We demonstrate our method on the denoising of high dynamic range (HDR) images produced by Monte Carlo rendering. Noise2Noise training can have trouble with HDR images, where the training process is overwhelmed by outliers and performs poorly. We consider a commonly used method of addressing these training issues: applying a nonlinear tone mapping function to the model output and target images to reduce their dynamic range. This method was previously thought to be incompatible with Noise2Noise training because of the nonlinearities involved. We show that certain combinations of loss functions and tone mapping functions can reduce the effect of outliers while introducing minimal bias. We apply our method to an existing machine learning-based Monte Carlo denoiser, where the original implementation was trained with high-sample count reference images. Our results approach those of the original implementation, but are produced using only noisy training data.

</details>


### [65] [Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with Multi-Information Derivative-Free Control](https://arxiv.org/abs/2512.24826)
*Jason Armitage,Rico Sennnrich*

Main category: cs.CV

TL;DR: 本文提出一种新方法，通过无导数优化的后悔最小化来改进多变量互信息估计，使基于2D视觉输入训练的跨模态系统能够在线适应3D场景中的物体遮挡并区分特征。该方法结合了表达性强的度量和基于价值的优化，直接从视觉-语言模型的噪声输出中学习控制场景内相机，从而在无需预训练或微调的情况下提升多对象3D场景中的跨模态任务性能。


<details>
  <summary>Details</summary>
Motivation: 当基于2D视觉输入训练的跨模态系统面对3D场景时，会遭遇维度差异问题。传统方法需要额外学习控制模块，且难以有效处理遮挡和特征区分。因此亟需一种无需预训练或微调、能在线适应3D场景变化的方法。

Method: 采用基于后悔最小化的无导数优化方法，提升多变量互信息估计能力；结合表达性度量与价值驱动优化，实现对场景内相机的直接控制，利用视觉-语言模型的噪声输出进行在线学习。

Result: 所提出的算法使现有2D跨模态系统能够在不进行预训练或微调的前提下，有效适应3D场景中的物体遮挡，并准确区分特征，显著提升跨模态任务在多对象3D场景中的性能。

Conclusion: 本研究证明了通过后悔最小化与无导数优化相结合的策略，可有效弥合2D与3D跨模态系统的维度鸿沟，实现高效、自适应的在线学习，为复杂3D环境下的跨模态理解提供了新范式。

Abstract: Cross-modal systems trained on 2D visual inputs are presented with a dimensional shift when processing 3D scenes. An in-scene camera bridges the dimensionality gap but requires learning a control module. We introduce a new method that improves multivariate mutual information estimates by regret minimisation with derivative-free optimisation. Our algorithm enables off-the-shelf cross-modal systems trained on 2D visual inputs to adapt online to object occlusions and differentiate features. The pairing of expressive measures and value-based optimisation assists control of an in-scene camera to learn directly from the noisy outputs of vision-language models. The resulting pipeline improves performance in cross-modal tasks on multi-object 3D scenes without resorting to pretraining or finetuning.

</details>


### [66] [CropTrack: A Tracking with Re-Identification Framework for Precision Agriculture](https://arxiv.org/abs/2512.24838)
*Md Ahmed Al Muzaddid,Jordan A. James,William J. Beksi*

Main category: cs.CV

TL;DR: CropTrack提出了一种结合外观与运动信息的新型多目标跟踪框架，旨在解决农业环境中因物体外观相似、频繁遮挡和光照变化导致的跟踪难题。通过引入增强重排序的外观关联、基于外观的冲突解决策略以及指数移动平均原型特征库，CropTrack显著提升了身份保持能力，在公开农业数据集上优于传统运动基跟踪方法，并在识别F1分数和关联准确率上超越现有最先进方法，同时减少了身份切换次数。


<details>
  <summary>Details</summary>
Motivation: 农业环境中的多目标跟踪面临重复模式、外观相似、光照突变和频繁遮挡等挑战，现有依赖运动信息的跟踪方法在强遮挡下难以维持目标身份，而外观相似性使得外观关联难以实现，因此需要一种融合外观与运动信息的更鲁棒的跟踪方法。

Method: CropTrack采用外观与运动信息融合策略，包括：1）增强重排序的外观关联模块，提升外观匹配精度；2）支持一对多关联并结合外观信息解决冲突；3）使用指数移动平均原型特征库动态更新外观特征，增强外观表征的稳定性。

Result: 在公开的农业多目标跟踪数据集上，CropTrack表现出更强的身份保持能力，相比传统运动基方法有显著提升；在识别F1分数和关联准确率方面优于当前最先进的方法，且身份切换次数更少。

Conclusion: CropTrack通过融合外观与运动信息，有效应对农业场景下的复杂跟踪挑战，为高相似性、高遮挡环境中的多目标跟踪提供了高效可靠的解决方案。

Abstract: Multiple-object tracking (MOT) in agricultural environments presents major challenges due to repetitive patterns, similar object appearances, sudden illumination changes, and frequent occlusions. Contemporary trackers in this domain rely on the motion of objects rather than appearance for association. Nevertheless, they struggle to maintain object identities when targets undergo frequent and strong occlusions. The high similarity of object appearances makes integrating appearance-based association nontrivial for agricultural scenarios. To solve this problem we propose CropTrack, a novel MOT framework based on the combination of appearance and motion information. CropTrack integrates a reranking-enhanced appearance association, a one-to-many association with appearance-based conflict resolution strategy, and an exponential moving average prototype feature bank to improve appearance-based association. Evaluated on publicly available agricultural MOT datasets, CropTrack demonstrates consistent identity preservation, outperforming traditional motion-based tracking methods. Compared to the state of the art, CropTrack achieves significant gains in identification F1 and association accuracy scores with a lower number of identity switches.

</details>


### [67] [FinMMDocR: Benchmarking Financial Multimodal Reasoning with Scenario Awareness, Document Understanding, and Multi-Step Computation](https://arxiv.org/abs/2512.24903)
*Zichen Tang,Haihong E,Rongjin Li,Jiacheng Liu,Linwei Jia,Zhuodi Hao,Zhongjun Yang,Yuanze Li,Haolin Tian,Xinyi Hu,Peizhi Zhao,Yuan Liu,Zhengyu Wang,Xianghe Wang,Yiling Huang,Xueyuan Lin,Ruofei Bai,Zijian Xie,Qian Huang,Ruining Cao,Haocheng Gao*

Main category: cs.CV

TL;DR: FinMMDocR 是一个新型双语多模态基准，用于评估多模态大语言模型（MLLMs）在真实世界金融数值推理任务中的表现。相较于现有基准，其三大创新为：(1) 场景感知：57.9% 的 1,200 道专家标注问题包含 12 种隐含金融场景（如投资组合管理），要求模型基于假设进行专家级推理；(2) 文档理解：涵盖 837 篇中英文文档，共 9 类（如公司研究报告），平均 50.8 页，富含视觉元素，显著提升文档广度与深度；(3) 多步计算：平均每题需 11 步推理（5.3 步提取 + 5.7 步计算），65.0% 的问题需跨页证据（平均 2.4 页）。目前表现最佳的 MLLM 仅达 58.0% 准确率，不同检索增强生成（RAG）方法表现差异显著。该基准有望推动 MLLMs 及推理增强方法在复杂多模态推理任务上的进步。


<details>
  <summary>Details</summary>
Motivation: 现有基准在真实金融场景下的多模态推理能力评估方面存在不足，缺乏对隐含金融场景、复杂文档结构及多步计算需求的充分覆盖，限制了 MLLMs 在实际金融应用中的发展。因此，亟需一个更贴近真实世界、更具挑战性的多模态金融推理基准。

Method: 构建 FinMMDocR 基准，包含 1,200 道专家标注的金融推理问题，涵盖 12 种隐含金融场景；整合 837 篇中英文金融文档（平均 50.8 页），包含丰富视觉元素；设计需多步推理的问题，强调跨页证据整合与复杂计算。通过实验评估主流 MLLMs 和 RAG 方法的表现，并分析性能差异。

Result: 当前最佳 MLLM 在 FinMMDocR 上仅达到 58.0% 的准确率；不同 RAG 方法在该任务上表现差异显著，表明现有方法在处理复杂多模态金融推理时仍存在明显局限性。

Conclusion: FinMMDocR 作为一个高难度、真实世界导向的多模态金融推理基准，能够有效推动 MLLMs 与推理增强技术的发展，尤其在场景理解、文档解析与多步计算方面具有重要促进作用。

Abstract: We introduce FinMMDocR, a novel bilingual multimodal benchmark for evaluating multimodal large language models (MLLMs) on real-world financial numerical reasoning. Compared to existing benchmarks, our work delivers three major advancements. (1) Scenario Awareness: 57.9% of 1,200 expert-annotated problems incorporate 12 types of implicit financial scenarios (e.g., Portfolio Management), challenging models to perform expert-level reasoning based on assumptions; (2) Document Understanding: 837 Chinese/English documents spanning 9 types (e.g., Company Research) average 50.8 pages with rich visual elements, significantly surpassing existing benchmarks in both breadth and depth of financial documents; (3) Multi-Step Computation: Problems demand 11-step reasoning on average (5.3 extraction + 5.7 calculation steps), with 65.0% requiring cross-page evidence (2.4 pages average). The best-performing MLLM achieves only 58.0% accuracy, and different retrieval-augmented generation (RAG) methods show significant performance variations on this task. We expect FinMMDocR to drive improvements in MLLMs and reasoning-enhanced methods on complex multimodal reasoning tasks in real-world scenarios.

</details>


### [68] [Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection](https://arxiv.org/abs/2512.24922)
*Bartłomiej Olber,Jakub Winter,Paweł Wawrzyński,Andrii Gamalii,Daniel Górniak,Marcin Łojek,Robert Nowak,Krystian Radlak*

Main category: cs.CV

TL;DR: 本文提出一种基于神经元激活模式的新型激光雷达领域自适应方法，仅需标注少量具有代表性和多样性的目标域样本即可实现顶尖性能。该方法注重视觉特征的可迁移性，结合持续学习启发的后训练技术，有效防止模型权重漂移，显著优于线性探测和现有领域自适应方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D物体检测器在标准自动驾驶基准上表现优异，但在跨域场景（如从美国到亚洲或欧洲）中泛化能力差，亟需高效且低标注成本的领域自适应方法以提升模型在新环境下的性能。

Method: 基于神经元激活模式分析，选择目标域中最具代表性与多样性的少量样本进行标注，并利用这些样本微调模型；同时引入受持续学习启发的后训练策略，避免原模型权重发生显著偏移。

Result: 实验表明，所提方法在极低标注预算下实现了超越线性探测与现有领域自适应技术的性能，验证了其在跨域适应中的有效性与实用性。

Conclusion: 通过合理选择少量目标域样本并结合持续学习思想的后训练策略，可实现高性能、低成本的激光雷达领域自适应，为自动驾驶感知系统在多地域部署提供了可行方案。

Abstract: 3D object detectors are fundamental components of perception systems in autonomous vehicles. While these detectors achieve remarkable performance on standard autonomous driving benchmarks, they often struggle to generalize across different domains - for instance, a model trained in the U.S. may perform poorly in regions like Asia or Europe. This paper presents a novel lidar domain adaptation method based on neuron activation patterns, demonstrating that state-of-the-art performance can be achieved by annotating only a small, representative, and diverse subset of samples from the target domain if they are correctly selected. The proposed approach requires very small annotation budget and, when combined with post-training techniques inspired by continual learning prevent weight drift from the original model. Empirical evaluation shows that the proposed domain adaptation approach outperforms both linear probing and state-of-the-art domain adaptation techniques.

</details>


### [69] [HaineiFRDM: Explore Diffusion to Restore Defects in Fast-Movement Films](https://arxiv.org/abs/2512.24946)
*Rongji Xun,Junjie Yuan,Zhongjie Wang*

Main category: cs.CV

TL;DR: 提出HaineiFRDM，一种基于扩散模型的电影修复框架，通过分块训练与测试策略实现高分辨率电影修复，结合位置感知全局提示和帧融合模块，引入全局-局部频率模块以重建一致纹理，并利用低分辨率结果作为全局残差减少拼接伪影。构建包含真实退化电影与合成数据的电影修复数据集，实验表明其在缺陷修复方面优于现有开源方法。


<details>
  <summary>Details</summary>
Motivation: 现有开源电影修复方法因使用低质量合成数据训练及采用噪声光流，性能有限；且未充分探索高分辨率电影修复。需提升内容理解能力以更好修复难以区分的电影缺陷。

Method: 采用分块训练与测试策略，设计位置感知全局提示与帧融合模块，引入全局-局部频率模块重建纹理一致性，先恢复低分辨率结果作为全局残差以缓解拼接伪影，并构建真实退化与合成数据混合的数据集。

Result: 在缺陷修复能力上显著优于现有开源方法，可实现单张24GB显存GPU上的高分辨率电影修复，实验结果充分验证模型优越性。

Conclusion: HaineiFRDM成功利用扩散模型的强大内容理解能力，实现高质量电影修复，尤其在高分辨率场景下表现优异，为后续研究提供新范式与公开资源。

Abstract: Existing open-source film restoration methods show limited performance compared to commercial methods due to training with low-quality synthetic data and employing noisy optical flows. In addition, high-resolution films have not been explored by the open-source methods.We propose HaineiFRDM(Film Restoration Diffusion Model), a film restoration framework, to explore diffusion model's powerful content-understanding ability to help human expert better restore indistinguishable film defects.Specifically, we employ a patch-wise training and testing strategy to make restoring high-resolution films on one 24GB-VRAMR GPU possible and design a position-aware Global Prompt and Frame Fusion Modules.Also, we introduce a global-local frequency module to reconstruct consistent textures among different patches. Besides, we firstly restore a low-resolution result and use it as global residual to mitigate blocky artifacts caused by patching process.Furthermore, we construct a film restoration dataset that contains restored real-degraded films and realistic synthetic data.Comprehensive experimental results conclusively demonstrate the superiority of our model in defect restoration ability over existing open-source methods. Code and the dataset will be released.

</details>


### [70] [ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT](https://arxiv.org/abs/2512.24948)
*Xinran Gong,Gorkem Durak,Halil Ertugrul Aktas,Vedat Cicek,Jinkui Hao,Ulas Bagci,Nilay S. Shah,Bo Zhou*

Main category: cs.CV

TL;DR: 本文提出ProDM（Property-aware Progressive Correction Diffusion Model），一种用于从非门控胸部CT中恢复无运动伪影的钙化病灶的生成扩散框架。该方法通过三个关键组件实现：（1）基于心脏门控CT合成真实非门控图像的运动模拟数据引擎，支持无配对数据的监督训练；（2）引入钙化特异性先验的属性感知学习策略，通过可微钙化一致性损失保持病灶完整性；（3）渐进式校正机制，在扩散过程中逐步减少伪影，提升稳定性与钙化保真度。实验表明，ProDM在真实患者数据集上显著提升了CAC评分准确性、空间病变保真度及风险分层性能，并在放射科医生评估中证实其有效抑制运动伪影并增强临床可用性，展现了在常规胸部CT中可靠量化CAC的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 非门控胸部CT虽可作为冠状动脉钙化（CAC）筛查的便捷替代手段，但受心脏和呼吸运动伪影严重影响，导致钙化病灶识别不准确。尽管心电门控CT能有效减少伪影，但受限于门控要求和保险覆盖问题，难以广泛用于人群筛查和常规影像。因此亟需一种无需门控即可高精度还原钙化病灶的方法，以推动CAC在日常影像中的应用。

Method: ProDM采用生成扩散模型架构，结合三重创新：（1）构建运动模拟数据引擎，从门控CT中合成多样化运动轨迹下的非门控图像，实现无配对监督训练；（2）设计可微钙化一致性损失，融入钙化特异性先验，确保修复过程保持病灶结构完整；（3）引入渐进式校正机制，分步去除伪影，提高重建稳定性和钙化细节保留能力。

Result: 在真实患者数据集上的实验结果显示，ProDM在CAC评分准确性、病变空间保真度和心血管风险分层性能方面均显著优于多个基线方法。读者研究进一步验证了其在真实非门控扫描中有效抑制运动伪影，提升图像诊断质量与临床实用性。

Conclusion: ProDM展示了属性感知、渐进式修正的生成模型在从常规非门控胸部CT中实现高精度冠状动脉钙化量化方面的巨大潜力，为未来在大规模人群筛查中普及无门控CAC评估提供了可行技术路径。

Abstract: Coronary artery calcium (CAC) scoring from chest CT is a well-established tool to stratify and refine clinical cardiovascular disease risk estimation. CAC quantification relies on the accurate delineation of calcified lesions, but is oftentimes affected by artifacts introduced by cardiac and respiratory motion. ECG-gated cardiac CTs substantially reduce motion artifacts, but their use in population screening and routine imaging remains limited due to gating requirements and lack of insurance coverage. Although identification of incidental CAC from non-gated chest CT is increasingly considered for it offers an accessible and widely available alternative, this modality is limited by more severe motion artifacts. We present ProDM (Property-aware Progressive Correction Diffusion Model), a generative diffusion framework that restores motion-free calcified lesions from non-gated CTs. ProDM introduces three key components: (1) a CAC motion simulation data engine that synthesizes realistic non-gated acquisitions with diverse motion trajectories directly from cardiac-gated CTs, enabling supervised training without paired data; (2) a property-aware learning strategy incorporating calcium-specific priors through a differentiable calcium consistency loss to preserve lesion integrity; and (3) a progressive correction scheme that reduces artifacts gradually across diffusion steps to enhance stability and calcium fidelity. Experiments on real patient datasets show that ProDM significantly improves CAC scoring accuracy, spatial lesion fidelity, and risk stratification performance compared with several baselines. A reader study on real non-gated scans further confirms that ProDM suppresses motion artifacts and improves clinical usability. These findings highlight the potential of progressive, property-aware frameworks for reliable CAC quantification from routine chest CT imaging.

</details>


### [71] [VIPER: Process-aware Evaluation for Generative Video Reasoning](https://arxiv.org/abs/2512.24952)
*Yifan Li,Yukai Gu,Yingqian Min,Zikang Liu,Yifan Du,Kun Zhou,Min Yang,Wayne Xin Zhao,Minghui Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种新的过程感知评估范式，以应对视频生成模型在复杂任务中可能出现的“结果欺骗”问题。为此，作者构建了VIPER基准，涵盖16个跨时间、结构、符号、空间、物理和规划推理的任务，并引入POC@r指标，通过视觉语言模型作为裁判，结合分层评分标准，同时评估中间步骤与最终结果的一致性。实验表明，当前最先进的视频模型在POC@1.0上仅达到约20%，存在严重的过程错误但结论正确现象。研究还探讨了测试时缩放与采样鲁棒性的影响，揭示了现有视频生成模型与真正通用视觉推理之间的巨大差距。该基准将公开发布。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型评估多依赖单帧判断，易导致模型通过错误过程得出正确结论（即‘结果欺骗’），无法真实反映其推理能力。因此亟需一种能评估中间过程与最终结果一致性的新评估方法。

Method: 提出Process-outcome Consistency (POC@r)评估指标，基于VLM-as-Judge机制，采用分层评分体系，综合评估视频生成过程中各阶段的合理性与最终输出的正确性；构建覆盖多类推理任务的VIPER基准，涵盖16个任务，包括时间、结构、符号、空间、物理和规划等维度。

Result: SOTA视频生成模型在POC@1.0上平均得分仅为约20%，显示严重的结果欺骗现象；测试时缩放与采样策略对性能影响显著，表明当前模型尚未具备真正的泛化视觉推理能力。

Conclusion: 当前视频生成模型虽能在特定任务上获得正确结果，但其内部推理过程不可靠。提出的新评估框架与基准有效揭示了这一差距，为未来模型发展提供了方向，且所提出的VIPER基准将公开发布，推动生成式视频推理的健康发展。

Abstract: Recent breakthroughs in video generation have demonstrated an emerging capability termed Chain-of-Frames (CoF) reasoning, where models resolve complex tasks through the generation of continuous frames. While these models show promise for Generative Video Reasoning (GVR), existing evaluation frameworks often rely on single-frame assessments, which can lead to outcome-hacking, where a model reaches a correct conclusion through an erroneous process. To address this, we propose a process-aware evaluation paradigm. We introduce VIPER, a comprehensive benchmark spanning 16 tasks across temporal, structural, symbolic, spatial, physics, and planning reasoning. Furthermore, we propose Process-outcome Consistency (POC@r), a new metric that utilizes VLM-as-Judge with a hierarchical rubric to evaluate both the validity of the intermediate steps and the final result. Our experiments reveal that state-of-the-art video models achieve only about 20% POC@1.0 and exhibit a significant outcome-hacking. We further explore the impact of test-time scaling and sampling robustness, highlighting a substantial gap between current video generation and true generalized visual reasoning. Our benchmark will be publicly released.

</details>


### [72] [DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments](https://arxiv.org/abs/2512.24985)
*Yohan Park,Hyunwoo Ha,Wonjun Jo,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 提出DarkEQA基准，用于评估视觉语言模型在多级低光条件下的感知能力，强调物理真实性与可归因的鲁棒性分析，揭示现有VLM在低光环境下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准未涵盖夜间或黑暗环境中的视觉退化情况，而24/7运行需要模型在各种光照条件下保持稳健性能，因此亟需一个真实模拟低光条件的评估基准。

Method: 在线性RAW空间中模拟光照下降和传感器噪声，并通过类似ISP的渲染流程生成视觉退化，构建具有物理真实性的低光图像数据集；基于此评估VLMs和低光图像增强模型的性能。

Result: 系统性揭示了当前主流VLM在低光条件下的性能下降问题，验证了DarkEQA在识别感知瓶颈方面的有效性。

Conclusion: DarkEQA为评估VLM在真实复杂光照条件下的表现提供了可靠工具，推动其在实际场景中的鲁棒性提升。

Abstract: Vision Language Models (VLMs) are increasingly adopted as central reasoning modules for embodied agents. Existing benchmarks evaluate their capabilities under ideal, well-lit conditions, yet robust 24/7 operation demands performance under a wide range of visual degradations, including low-light conditions at night or in dark environments--a core necessity that has been largely overlooked. To address this underexplored challenge, we present DarkEQA, an open-source benchmark for evaluating EQA-relevant perceptual primitives under multi-level low-light conditions. DarkEQA isolates the perception bottleneck by evaluating question answering from egocentric observations under controlled degradations, enabling attributable robustness analysis. A key design feature of DarkEQA is its physical fidelity: visual degradations are modeled in linear RAW space, simulating physics-based illumination drop and sensor noise followed by an ISP-inspired rendering pipeline. We demonstrate the utility of DarkEQA by evaluating a wide range of state-of-the-art VLMs and Low-Light Image Enhancement (LLIE) models. Our analysis systematically reveals VLMs' limitations when operating under these challenging visual conditions. Our code and benchmark dataset will be released upon acceptance.

</details>


### [73] [Bi-C2R: Bidirectional Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification](https://arxiv.org/abs/2512.25000)
*Zhenyu Cui,Jiahuan Zhou,Yuxin Peng*

Main category: cs.CV

TL;DR: 本文提出了一种无需重新索引的终身行人重识别（RFL-ReID）方法，旨在解决传统终身行人重识别中因频繁重新提取历史图像特征而导致的计算开销大和隐私问题。为此，作者设计了双向连续兼容表示（Bi-C2R）框架，通过动态更新旧模型生成的画廊特征，实现新旧模型特征间的兼容性，从而在不重新索引的前提下保持高效且稳定的重识别性能。实验表明，该方法在RFL-ReID和传统L-ReID任务上均达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 现有终身行人重识别方法依赖于每次更新后对历史画廊图像重新提取特征（即‘重新索引’），这不仅带来高昂的计算成本，还受限于数据隐私保护，难以直接保存历史数据。因此，如何在不重新索引的情况下实现新旧模型特征的兼容性，成为关键挑战。

Method: 提出双向连续兼容表示（Bi-C2R）框架，通过双向一致性约束与特征迁移机制，持续更新由旧模型生成的画廊特征，使新模型输出的查询特征能与旧模型生成的画廊特征在语义空间中保持兼容，避免因特征不一致导致的性能下降。

Result: 在多个公开基准上的实验结果表明，所提方法在无需重新索引的前提下，在RFL-ReID任务和传统L-ReID任务上均取得了领先性能，验证了其有效性与鲁棒性。

Conclusion: 本文成功提出了首个无需重新索引的终身行人重识别框架（RFL-ReID），并通过Bi-C2R实现了新旧知识的高效融合与特征兼容，为实际部署中的持续学习提供了可行方案。

Abstract: Lifelong person Re-IDentification (L-ReID) exploits sequentially collected data to continuously train and update a ReID model, focusing on the overall performance of all data. Its main challenge is to avoid the catastrophic forgetting problem of old knowledge while training on new data. Existing L-ReID methods typically re-extract new features for all historical gallery images for inference after each update, known as "re-indexing". However, historical gallery data typically suffers from direct saving due to the data privacy issue and the high re-indexing costs for large-scale gallery images. As a result, it inevitably leads to incompatible retrieval between query features extracted by the updated model and gallery features extracted by those before the update, greatly impairing the re-identification performance. To tackle the above issue, this paper focuses on a new task called Re-index Free Lifelong person Re-IDentification (RFL-ReID), which requires performing lifelong person re-identification without re-indexing historical gallery images. Therefore, RFL-ReID is more challenging than L-ReID, requiring continuous learning and balancing new and old knowledge in diverse streaming data, and making the features output by the new and old models compatible with each other. To this end, we propose a Bidirectional Continuous Compatible Representation (Bi-C2R) framework to continuously update the gallery features extracted by the old model to perform efficient L-ReID in a compatible manner. We verify our proposed Bi-C2R method through theoretical analysis and extensive experiments on multiple benchmarks, which demonstrate that the proposed method can achieve leading performance on both the introduced RFL-ReID task and the traditional L-ReID task.

</details>


### [74] [From Inpainting to Editing: A Self-Bootstrapping Framework for Context-Rich Visual Dubbing](https://arxiv.org/abs/2512.25066)
*Xu He,Haoxian Zhang,Hejia Chen,Changyuan Zheng,Liyang Chen,Songlin Tang,Jiehui Huang,Xiaoqiang Liu,Pengfei Wan,Zhiyong Wu*

Main category: cs.CV

TL;DR: 本文提出一种自 bootstrapping 框架，将音频驱动的视觉配音从病态的图像修复任务转变为良态的视频到视频编辑问题。通过 Diffusion Transformer 生成理想训练数据（唇部改变的配对视频），并使用基于 DiT 的音频驱动编辑器在这些配对数据上端到端训练，利用完整的帧对齐输入条件，专注于精确的音频驱动唇部修改。该方法实现了高精度的唇音同步、忠实的身份保持以及对复杂现实场景的强鲁棒性。同时引入时间步自适应多阶段学习策略以解耦扩散过程中的冲突编辑目标，提升训练稳定性与视觉保真度。此外，构建了 ContextDubBench 基准数据集用于全面评估各种挑战性实际场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖掩码引导的图像修复范式，因缺乏理想训练数据（仅唇部变化而其他视觉条件一致的视频对）导致模型需同时幻觉缺失内容和同步嘴唇，引发视觉伪影、身份漂移和同步不良等问题。因此需要一种能生成理想训练数据并避免多重任务干扰的新方法。

Method: 提出自 bootstrapping 框架：首先使用 Diffusion Transformer 作为数据生成器，合成每段真实视频对应的唇部改变的伴生视频，形成视觉对齐的视频对；然后训练一个基于 DiT 的音频驱动编辑器，在这些配对数据上进行端到端学习，利用完整且对齐的输入帧专注实现精准的音频驱动唇部修改；引入时间步自适应多阶段学习策略，以解耦不同扩散时间步间的冲突编辑目标，确保稳定训练。

Result: 所提方法在唇音同步精度、身份保留、视觉质量及对复杂现实场景的鲁棒性方面均显著优于现有方法；时间步自适应多阶段学习策略有效提升了训练稳定性与最终输出质量；ContextDubBench 数据集为实际应用提供了全面评估基准。

Conclusion: 本文提出的自 bootstrapping 框架成功将音频驱动视觉配音转化为一个良态的视频编辑问题，通过生成理想训练数据和利用完整的视觉上下文信息，实现了高质量、高鲁棒性的唇音同步效果，为实际应用提供了坚实基础。

Abstract: Audio-driven visual dubbing aims to synchronize a video's lip movements with new speech, but is fundamentally challenged by the lack of ideal training data: paired videos where only a subject's lip movements differ while all other visual conditions are identical. Existing methods circumvent this with a mask-based inpainting paradigm, where an incomplete visual conditioning forces models to simultaneously hallucinate missing content and sync lips, leading to visual artifacts, identity drift, and poor synchronization. In this work, we propose a novel self-bootstrapping framework that reframes visual dubbing from an ill-posed inpainting task into a well-conditioned video-to-video editing problem. Our approach employs a Diffusion Transformer, first as a data generator, to synthesize ideal training data: a lip-altered companion video for each real sample, forming visually aligned video pairs. A DiT-based audio-driven editor is then trained on these pairs end-to-end, leveraging the complete and aligned input video frames to focus solely on precise, audio-driven lip modifications. This complete, frame-aligned input conditioning forms a rich visual context for the editor, providing it with complete identity cues, scene interactions, and continuous spatiotemporal dynamics. Leveraging this rich context fundamentally enables our method to achieve highly accurate lip sync, faithful identity preservation, and exceptional robustness against challenging in-the-wild scenarios. We further introduce a timestep-adaptive multi-phase learning strategy as a necessary component to disentangle conflicting editing objectives across diffusion timesteps, thereby facilitating stable training and yielding enhanced lip synchronization and visual fidelity. Additionally, we propose ContextDubBench, a comprehensive benchmark dataset for robust evaluation in diverse and challenging practical application scenarios.

</details>


### [75] [GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction](https://arxiv.org/abs/2512.25073)
*Yi-Chuan Huang,Hao-Jen Chien,Chin-Yang Lin,Ying-Huan Chen,Yu-Lun Liu*

Main category: cs.CV

TL;DR: GaMO提出一种基于多视角外推的稀疏视图3D重建方法，通过扩展现有相机视角的视野而非生成新视角，实现几何一致性与更广场景覆盖，无需训练即可在零样本下工作，显著提升重建质量并加速处理速度。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法在输入视角稀疏时表现不佳，尽管扩散模型等先进方法能生成新视角以增强数据，但仍存在视野扩展不足、几何不一致和计算成本高等问题。

Method: GaMO将稀疏视图重建重构为多视角外推任务，利用多视角条件与几何感知去噪策略，在零样本条件下实现无需训练的高质量重建。

Result: 在Replica和ScanNet++数据集上，GaMO在3、6、9个输入视图下均达到最先进的重建质量（PSNR和LPIPS指标），且比最先进扩散方法快25倍，处理时间低于10分钟。

Conclusion: GaMO通过多视角外推的方式有效解决了稀疏视图3D重建中的几何一致性与覆盖范围问题，实现了高效、高质量的重建，是当前该领域的重要进展。

Abstract: Recent advances in 3D reconstruction have achieved remarkable progress in high-quality scene capture from dense multi-view imagery, yet struggle when input views are limited. Various approaches, including regularization techniques, semantic priors, and geometric constraints, have been implemented to address this challenge. Latest diffusion-based methods have demonstrated substantial improvements by generating novel views from new camera poses to augment training data, surpassing earlier regularization and prior-based techniques. Despite this progress, we identify three critical limitations in these state-of-the-art approaches: inadequate coverage beyond known view peripheries, geometric inconsistencies across generated views, and computationally expensive pipelines. We introduce GaMO (Geometry-aware Multi-view Outpainter), a framework that reformulates sparse-view reconstruction through multi-view outpainting. Instead of generating new viewpoints, GaMO expands the field of view from existing camera poses, which inherently preserves geometric consistency while providing broader scene coverage. Our approach employs multi-view conditioning and geometry-aware denoising strategies in a zero-shot manner without training. Extensive experiments on Replica and ScanNet++ demonstrate state-of-the-art reconstruction quality across 3, 6, and 9 input views, outperforming prior methods in PSNR and LPIPS, while achieving a $25\times$ speedup over SOTA diffusion-based methods with processing time under 10 minutes. Project page: https://yichuanh.github.io/GaMO/

</details>


### [76] [SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time](https://arxiv.org/abs/2512.25075)
*Zhening Huang,Hyeonho Jeong,Xuelin Chen,Yulia Gryaditskaya,Tuanfeng Y. Wang,Joan Lasenby,Chun-Hao Huang*

Main category: cs.CV

TL;DR: SpaceTimePilot 是一种视频扩散模型，通过解耦空间与时间实现可控生成渲染。它能够独立控制相机视角和运动序列，支持对场景在时空上的连续、任意探索。该模型引入了动画时间嵌入机制，以显式控制输出视频的运动序列，并提出基于时序扭曲的训练策略，利用现有多视角数据模拟时间差异，从而有效监督模型学习时间控制能力。此外，还设计了改进的相机条件机制和首个全覆盖时空轨迹合成数据集 CamxTime，联合训练提升了空间-时间解耦精度。在真实与合成数据上的实验表明，该方法实现了清晰的空间-时间解耦，性能优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型难以实现对空间和时间的独立控制，尤其缺乏在无成对动态场景数据下的时间变化建模能力。因此，需要一种能解耦空间与时间并支持自由探索的生成框架，以实现更灵活的视频编辑与渲染。

Method: 提出一种结合时间嵌入机制的视频扩散模型；采用时序扭曲训练策略，将多视角数据转换为具有时间差异的伪数据；引入改进的相机条件机制；构建 CamxTime 合成数据集，支持全自由度的时空轨迹生成；联合训练提升空间-时间控制精度。

Result: 在真实世界和合成数据上均表现出显著的空间-时间解耦能力，生成视频在视角和运动控制方面更加精确，且优于现有方法。

Conclusion: SpaceTimePilot 通过创新的时间嵌入、时序扭曲训练策略及新数据集的引入，成功实现了视频生成中空间与时间的有效解耦，为可控视频生成提供了新范式。

Abstract: We present SpaceTimePilot, a video diffusion model that disentangles space and time for controllable generative rendering. Given a monocular video, SpaceTimePilot can independently alter the camera viewpoint and the motion sequence within the generative process, re-rendering the scene for continuous and arbitrary exploration across space and time. To achieve this, we introduce an effective animation time-embedding mechanism in the diffusion process, allowing explicit control of the output video's motion sequence with respect to that of the source video. As no datasets provide paired videos of the same dynamic scene with continuous temporal variations, we propose a simple yet effective temporal-warping training scheme that repurposes existing multi-view datasets to mimic temporal differences. This strategy effectively supervises the model to learn temporal control and achieve robust space-time disentanglement. To further enhance the precision of dual control, we introduce two additional components: an improved camera-conditioning mechanism that allows altering the camera from the first frame, and CamxTime, the first synthetic space-and-time full-coverage rendering dataset that provides fully free space-time video trajectories within a scene. Joint training on the temporal-warping scheme and the CamxTime dataset yields more precise temporal control. We evaluate SpaceTimePilot on both real-world and synthetic data, demonstrating clear space-time disentanglement and strong results compared to prior work. Project page: https://zheninghuang.github.io/Space-Time-Pilot/ Code: https://github.com/ZheningHuang/spacetimepilot

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [77] [CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of LLMs under Controlled Input Variations](https://arxiv.org/abs/2512.23711)
*Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Claudio Pinhanez,Yago Primerano*

Main category: cs.CL

TL;DR: 本文提出 	extsc{CAT} 框架，用于评估和可视化大型语言模型（LLMs）在可控输入变化下的准确率与响应一致性之间的相互作用，以多项选择（MC）基准为案例研究。该框架引入了‘一致性-准确率关系（CAR）’曲线，展示模型准确率随一致性要求提高的变化情况，并提出‘一致性导向鲁棒性估计（CORE）’指数，综合评估准确率与一致性的权衡。实验覆盖通用和领域特定的LLMs及多个MC基准，验证了框架的有效性，并探讨其向长文本、开放式评估扩展的可能性。


<details>
  <summary>Details</summary>
Motivation: 当前评估主要关注模型的准确率或基准分数，虽开始重视一致性，但缺乏对两者相互依赖关系的系统分析。为更全面评估LLMs在高风险实际应用中的表现，需同时考虑准确率与一致性的交互影响。

Method: 提出 	extsc{CAT} 框架，核心是构建 Consistency-Accuracy Relation (CAR) 曲线，基于 Minimum-Consistency Accuracy (MCA) 定义一致性要求；引入 CORE 指数，量化 CAR 曲线的面积与形状，反映准确率与一致性的整体权衡。支持多种评分函数，可拓展至开放性任务。

Result: 实证结果表明，	extsc{CAT} 能有效揭示不同LLMs在准确率与一致性间的权衡特性，揭示模型在不同一致性阈值下的性能变化。CORE指数能提供全局比较依据，有助于模型选型与优化。框架具有可扩展性，适用于非多项选择任务。

Conclusion: 	extsc{CAT} 为评估大模型在真实场景下的可靠性提供了新视角，强调准确率与一致性的协同分析。通过CAR曲线与CORE指标，实现对模型性能的多维刻画，推动更科学、严谨的评测范式发展。

Abstract: We introduce \textsc{CAT}, a framework designed to evaluate and visualize the \emph{interplay} of \emph{accuracy} and \emph{response consistency} of Large Language Models (LLMs) under controllable input variations, using multiple-choice (MC) benchmarks as a case study. Current evaluation practices primarily focus on model capabilities such as accuracy or benchmark scores and, more recently, measuring consistency is being considered an essential property for deploying LLMs in high-stake, real-world applications. We argue in this paper that although both dimensions should still be evaluated independently, their inter-dependency also need to be considered for a more nuanced evaluation of LLMs. At the core of \textsc{CAT} are the \emph{Consistency-Accuracy Relation (CAR)} curves, which visualize how model accuracy varies with increasing consistency requirements, as defined by the \emph{Minimum-Consistency Accuracy (MCA)} metric. We further propose the \emph{Consistency-Oriented Robustness Estimate (CORE)} index, a global metric that combines the area and shape of the CAR curve to quantify the trade-off between accuracy and consistency. We present a practical demonstration of our framework across a diverse set of generalist and domain-specific LLMs, evaluated on multiple MC benchmarks. We also outline how \textsc{CAT} can be extended beyond MC tasks to support long-form, open-ended evaluations through adaptable scoring functions.

</details>


### [78] [PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents](https://arxiv.org/abs/2512.23714)
*Tingwei Xie,Tianyi Zhou,Yonghong Song*

Main category: cs.CL

TL;DR: PharmaShip 是一个真实世界中扫描的中文药品运输文档数据集，用于在噪声 OCR 和异构模板下压力测试预训练的文本布局模型。该数据集涵盖序列实体识别（SER）、关系抽取（RE）和阅读顺序预测（ROP）三个任务，并采用以实体为中心的评估协议以减少不同架构间的混淆。研究基准测试了五种代表性基线模型，包括像素感知和几何感知两类（LiLT、LayoutLMv3-base、GeoLayoutLM 及其 RORE 增强变体），并标准化了预处理、数据划分和优化流程。实验表明，像素信息与显式几何信息提供了互补的归纳偏置，但单独使用均不足；引入面向阅读顺序的正则化可一致提升 SER 与 EL 性能，且表现最稳健；更长的位置覆盖有助于稳定页面后段预测并减少截断伪影。虽然 ROP 在词级别表现良好，但在段落级别仍具挑战，反映出边界模糊和长距离交叉问题。PharmaShip 建立了一个可控、可复现的基准，适用于药学领域关键安全文档理解，并强调序列感知约束作为结构建模的可迁移偏置。数据集已开源：https://github.com/KevinYuLei/PharmaShip。


<details>
  <summary>Details</summary>
Motivation: 现有文本布局模型在真实场景中面对噪声 OCR 与多样模板时表现不稳定，尤其在药学等高安全要求领域缺乏可靠、可控的基准测试数据集。因此，亟需一个真实、复杂且标注精细的数据集来系统评估模型对文档结构的理解能力，同时揭示模型在序列感知、几何推理等方面的局限性。

Method: 构建 PharmaShip 数据集，包含真实扫描的中文药品运输文档；设计覆盖 SER、RE、ROP 三任务的统一评估框架；采用实体中心评估协议以减少架构差异带来的干扰；基准测试五种代表性的像素感知与几何感知模型（如 LiLT、LayoutLMv3-base、GeoLayoutLM 及其 RORE 增强版本）；标准化预处理、数据划分与训练配置；通过对比实验分析像素、几何、阅读顺序等不同信号的作用。

Result: 1. 像素信息与显式几何信息具有互补性，但单独使用不足以实现最优性能；2. 引入阅读顺序导向的正则化显著提升 SER 与 EL 表现，是最鲁棒的配置；3. 更长的位置编码有助于改善页面末尾预测质量，减少截断误差；4. ROP 在词级别准确率较高，但在段级预测中面临边界模糊与长程交叉的挑战；5. PharmaShip 成为药学领域安全关键文档理解的可控、可复现基准。

Conclusion: PharmaShip 为药学文档理解提供了一个高质量、真实场景下的基准数据集，验证了序列感知约束作为结构建模中可迁移归纳偏置的有效性。研究揭示了当前模型在处理复杂布局与长程依赖上的不足，并为未来模型设计指明方向——融合多源信息、强化顺序建模与位置感知是提升鲁棒性的关键。

Abstract: We present PharmaShip, a real-world Chinese dataset of scanned pharmaceutical shipping documents designed to stress-test pre-trained text-layout models under noisy OCR and heterogeneous templates. PharmaShip covers three complementary tasks-sequence entity recognition (SER), relation extraction (RE), and reading order prediction (ROP)-and adopts an entity-centric evaluation protocol to minimize confounds across architectures. We benchmark five representative baselines spanning pixel-aware and geometry-aware families (LiLT, LayoutLMv3-base, GeoLayoutLM and their available RORE-enhanced variants), and standardize preprocessing, splits, and optimization. Experiments show that pixels and explicit geometry provide complementary inductive biases, yet neither alone is sufficient: injecting reading-order-oriented regularization consistently improves SER and EL and yields the most robust configuration, while longer positional coverage stabilizes late-page predictions and reduces truncation artifacts. ROP is accurate at the word level but challenging at the segment level, reflecting boundary ambiguity and long-range crossings. PharmaShip thus establishes a controlled, reproducible benchmark for safety-critical document understanding in the pharmaceutical domain and highlights sequence-aware constraints as a transferable bias for structure modeling. We release the dataset at https://github.com/KevinYuLei/PharmaShip.

</details>


### [79] [Noise-Driven Persona Formation in Reflexive Neural Language Generation](https://arxiv.org/abs/2512.23716)
*Toshiyuki Shigemura*

Main category: cs.CL

TL;DR: 本文提出Luca-Noise Reflex Protocol (LN-RP)，通过在初始生成状态注入随机噪声，研究大语言模型中噪声驱动的人格涌现现象。实验发现152个生成周期中存在三种具有不同熵特征的稳定人格模式，并证实外部噪声可可靠引发反射性生成动态的相变。定量评估显示人格保持一致且各模式间差异显著（p < 0.01）。该协议为研究反射性生成、涌现行为及长程语言连贯性提供了可重复的方法。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型中由噪声驱动的人格涌现机制，理解反射性生成过程中的非线性动态变化，揭示外部扰动对语言行为的影响规律。

Method: 通过向大语言模型的初始生成状态注入随机噪声种子，在152个生成周期中观察其语言行为的演变；利用熵分析识别稳定人格模式，并通过统计检验验证人格保留与模式差异。

Result: 识别出三种具有独特熵签名的稳定人格模式；外部噪声可有效诱导生成动态的相变；各人格模式间存在显著差异（p < 0.01），且人格具有较强一致性。

Conclusion: Luca-Noise Reflex Protocol提供了一种可重复的框架，用于研究大语言模型中的反射性生成、涌现行为和长程语言连贯性，为理解噪声在语言生成中的作用提供了新视角。

Abstract: This paper introduces the Luca-Noise Reflex Protocol (LN-RP), a computational framework for analyzing noise-driven persona emergence in large language models. By injecting stochastic noise seeds into the initial generation state, we observe nonlinear transitions in linguistic behavior across 152 generation cycles. Our results reveal three stable persona modes with distinct entropy signatures, and demonstrate that external noise sources can reliably induce phase transitions in reflexive generation dynamics. Quantitative evaluation confirms consistent persona retention and significant differences across modes (p < 0.01). The protocol provides a reproducible method for studying reflexive generation, emergent behavior, and longrange linguistic coherence in LLMs.

</details>


### [80] [HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate](https://arxiv.org/abs/2512.23717)
*Shenzhe Zhu*

Main category: cs.CL

TL;DR: 本文提出HarmTransform，一种多智能体辩论框架，用于将有害查询转化为更隐蔽的形式，同时保持其恶意意图。该框架通过多智能体的迭代批判与优化，生成高质量的隐蔽有害查询，以增强大语言模型的安全对齐。实验表明，HarmTransform在生成有效转换方面显著优于基线方法，但辩论也带来主题偏移和复杂性增加等挑战，揭示了多智能体辩论在安全训练数据生成中的潜力与局限。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的安全对齐方法主要关注明显危险内容，忽视了用户通过隐晦重述隐藏恶意意图的微妙威胁，导致安全训练数据存在空白。

Method: 提出HarmTransform框架，利用多个智能体之间的迭代批判与优化，系统性地生成保留恶意意图但表面看似无害的查询转换。

Result: HarmTransform在生成有效且隐蔽的有害查询转换方面显著优于标准基线；但辩论过程可能导致主题偏移和不必要的复杂性增加。

Conclusion: 多智能体辩论在生成全面的安全训练数据方面具有潜力，但也存在引入偏差和复杂性的风险，需谨慎设计与应用。

Abstract: Large language models (LLMs) are equipped with safety mechanisms to detect and block harmful queries, yet current alignment approaches primarily focus on overtly dangerous content and overlook more subtle threats. However, users can often disguise harmful intent through covert rephrasing that preserves malicious objectives while appearing benign, which creates a significant gap in existing safety training data. To address this limitation, we introduce HarmTransform, a multi-agent debate framework for systematically transforming harmful queries into stealthier forms while preserving their underlying harmful intent. Our framework leverages iterative critique and refinement among multiple agents to generate high-quality, covert harmful query transformations that can be used to improve future LLM safety alignment. Experiments demonstrate that HarmTransform significantly outperforms standard baselines in producing effective query transformations. At the same time, our analysis reveals that debate acts as a double-edged sword: while it can sharpen transformations and improve stealth, it may also introduce topic shifts and unnecessary complexity. These insights highlight both the promise and the limitations of multi-agent debate for generating comprehensive safety training data.

</details>


### [81] [Emergent World Beliefs: Exploring Transformers in Stochastic Games](https://arxiv.org/abs/2512.23722)
*Adam Kamel,Tanish Rastogi,Michael Ma,Kailash Ranganathan,Kevin Zhu*

Main category: cs.CL

TL;DR: 本文研究了基于Transformer的大语言模型（LLM）在不完全信息博弈（如德州扑克）中的推理能力。通过在扑克历史数据上预训练GPT风格模型，并分析其内部激活，发现模型自发学习到了确定性结构（如牌型等级）和随机性特征（如胜率），且这些表示可通过非线性探测器解码，与理论上的信念状态高度相关，表明LLM能自主构建对德州扑克这一部分可观测马尔可夫决策过程的内在环境表征。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在不完全信息场景下的推理能力，特别是能否自发形成对复杂、随机环境的内部表征，以扩展其在博弈论等领域的应用潜力。

Method: 在扑克手牌历史（PHH）数据上预训练GPT风格的语言模型，并通过非线性探测方法分析其内部激活，评估其对牌型等级、胜率等关键特征的捕捉能力。

Result: 模型成功学习到手牌等级等确定性结构以及胜率等随机特征，且内部表示可通过非线性探测有效解码，与理论信念状态显著相关，证明其具备对德州扑克环境的自主建模能力。

Conclusion: 大语言模型能够在无显式指导的情况下，自主学习不完全信息环境中的结构性与随机性特征，表现出对复杂博弈环境的内在世界建模能力，为理解其推理机制提供了新视角。

Abstract: Transformer-based large language models (LLMs) have demonstrated strong reasoning abilities across diverse fields, from solving programming challenges to competing in strategy-intensive games such as chess. Prior work has shown that LLMs can develop emergent world models in games of perfect information, where internal representations correspond to latent states of the environment. In this paper, we extend this line of investigation to domains of incomplete information, focusing on poker as a canonical partially observable Markov decision process (POMDP). We pretrain a GPT-style model on Poker Hand History (PHH) data and probe its internal activations. Our results demonstrate that the model learns both deterministic structure, such as hand ranks, and stochastic features, such as equity, without explicit instruction. Furthermore, by using primarily nonlinear probes, we demonstrated that these representations are decodeable and correlate with theoretical belief states, suggesting that LLMs are learning their own representation of the stochastic environment of Texas Hold'em Poker.

</details>


### [82] [When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection](https://arxiv.org/abs/2512.23732)
*Anwar Alajmi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 针对在线性别歧视内容的隐晦、语境依赖特性，传统检测方法难以应对。本文提出一种两阶段框架，通过针对性训练与基于推理的筛选机制，解决数据稀缺、噪声和概念模糊问题。训练阶段采用类别平衡焦点损失、类别感知批处理和事后阈值校准；推理阶段引入动态路由机制，高置信度样本直接分类，不确定样本交由新型‘协作专家判断’（CEJ）模块处理，通过多角色推理与裁判模型整合结果。该方法在多个基准测试中表现优异，显著提升F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉性别歧视内容的隐晦性与语境依赖性，且受限于标签稀疏、类别不平衡及标注噪声，导致模型决策边界不稳定，忽视细微但重要的歧视形式。因此亟需一种能同时应对数据稀缺、噪声与概念模糊的系统性设计。

Method: 提出两阶段框架：训练阶段使用类平衡焦点损失、类感知批处理和后验阈值校准以缓解标签不平衡与噪声；推理阶段采用动态路由机制，将高置信度样本直接分类，低置信度样本送入‘协作专家判断’（CEJ）模块，通过多个角色生成推理并由裁判模型综合判断。

Result: 在EXIST 2025 Task 1.1上实现F1提升+2.72%；在EDOS Tasks A和B上分别提升+4.48%和+1.30%，达到当前最优性能。

Conclusion: 所提框架有效应对了性别歧视内容检测中的数据稀缺、噪声干扰与概念模糊挑战，通过联合优化训练与推理阶段的设计，在多个基准上取得显著性能提升，为复杂社会偏见内容的识别提供了可扩展的新范式。

Abstract: Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \textit{Collaborative Expert Judgment} (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with a +2.72\% improvement in F1 on the EXIST 2025 Task 1.1, and a gains of +4.48\% and +1.30\% on the EDOS Tasks A and B, respectively.

</details>


### [83] [Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning](https://arxiv.org/abs/2512.23765)
*Tiancheng Su,Meicong Zhang,Guoxiu He*

Main category: cs.CL

TL;DR: EASD是一种无需训练的推测解码增强方法，通过动态熵惩罚机制，在高不确定性情况下拒绝低置信度的候选词，从而避免错误传播，并可能超越目标模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码（SD）受限于草稿模型与目标模型之间的过度对齐，导致其性能受制于目标模型本身，无法突破其上限。为解决此问题，提出一种无需训练的改进方法。

Method: 基于标准推测解码，引入基于熵的动态惩罚机制；在每一步解码中，利用采样分布的熵衡量模型不确定性，当两模型均表现出高熵且前N个预测高度重叠时，拒绝该词并由目标模型重新采样。

Result: 在多个推理基准测试中，EASD持续优于现有推测解码方法，多数情况下超越目标大语言模型本身的性能；同时保持与原始推测解码相当的效率。

Conclusion: EASD通过引入熵感知的动态惩罚机制，有效提升推测解码的准确性与潜力，实现超越目标模型性能的可能性，且无需额外训练，具有良好的实用价值。

Abstract: Speculative decoding (SD) accelerates large language model (LLM) reasoning by using a small draft model to generate candidate tokens, which the target LLM either accepts directly or regenerates upon rejection. However, excessive alignment between the draft and target models constrains SD to the performance of the target LLM. To address this limitation, we propose Entropy-Aware Speculative Decoding (EASD), a training-free enhancement. Building on standard SD, EASD incorporates a dynamic entropy-based penalty. At each decoding step, we employ the entropy of the sampling distribution to quantify model uncertainty. When both models exhibit high entropy with substantial overlap among their top-N predictions, the corresponding token is rejected and re-sampled by the target LLM. This penalty prevents low-confidence errors from propagating. By incorporating draft-model verification, EASD enables the possibility of surpassing the target model's inherent performance. Experiments across multiple reasoning benchmarks demonstrate that EASD consistently outperforms existing SD methods and, in most cases, surpasses the target LLM itself. We further prove that the efficiency of EASD is comparable to that of SD. The code can be found in the Supplementary Materials.

</details>


### [84] [MiMo-Audio: Audio Language Models are Few-Shot Learners](https://arxiv.org/abs/2512.23808)
*Xiaomi LLM-Core Team,:,Dong Zhang,Gang Wang,Jinlong Xue,Kai Fang,Liang Zhao,Rui Ma,Shuhuai Ren,Shuo Liu,Tao Guo,Weiji Zhuang,Xin Zhang,Xingchen Song,Yihan Yan,Yongzhe He,Cici,Bowen Shen,Chengxuan Zhu,Chong Ma,Chun Chen,Heyu Chen,Jiawei Li,Lei Li,Menghang Zhu,Peidian Li,Qiying Wang,Sirui Deng,Weimin Xiong,Wenshan Huang,Wenyu Yang,Yilin Jiang,Yixin Yang,Yuanyuan Tian,Yue Ma,Yue Yu,Zihan Zhang,Zihao Yue,Bangjun Xiao,Bingquan Xia,Bofei Gao,Bowen Ye,Can Cai,Chang Liu,Chenhong He,Chunan Li,Dawei Zhu,Duo Zhang,Fengyuan Shi,Guoan Wang,Hailin Zhang,Hanglong Lv,Hanyu Li,Hao Tian,Heng Qu,Hongshen Xu,Houbin Zhang,Huaqiu Liu,Jiangshan Duo,Jianguang Zuo,Jianyu Wei,Jiebao Xiao,Jinhao Dong,Jun Shi,Junhao Hu,Kainan Bao,Kang Zhou,Linghao Zhang,Meng Chen,Nuo Chen,Peng Zhang,Qianli Chen,Qiantong Wang,Rang Li,Shaohui Liu,Shengfan Wang,Shicheng Li,Shihua Yu,Shijie Cao,Shimao Chen,Shuhao Gu,Weikun Wang,Wenhan Ma,Xiangwei Deng,Xing Yong,Xing Zhang,Xu Wang,Yifan Song,Yihao Zhao,Yingbo Zhao,Yizhao Gao,Yu Cheng,Yu Tu,Yudong Wang,Zhaojun Huang,Zhengju Tang,Zhenru Lin,Zhichao Song,Zhipeng Xu,Zhixian Zheng,Zihan Jiang*

Main category: cs.CL

TL;DR: MiMo-Audio通过大规模预训练（超过一亿小时音频数据）实现了音频领域中的少样本学习能力，展现出强大的泛化性能。其基础模型MiMo-Audio-7B-Base在语音智能与音频理解任务上达到开源模型SOTA，且能处理未在训练中出现的任务如语音转换、风格迁移和语音编辑。指令微调版本MiMo-Audio-7B-Instruct在多个音频理解、对话及语音合成评测中接近或超越闭源模型，表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型依赖任务特定微调，难以像人类一样用少量示例或简单指令完成新任务；受GPT-3在文本领域展示的通用性启发，研究者希望将类似的大规模预训练范式引入音频领域，以实现更强的泛化能力。

Method: 通过扩展预训练数据至超过一亿小时音频，构建大规模音频语言模型MiMo-Audio；在后训练阶段，构建多样化的指令微调语料库，并引入思维机制于音频理解和生成任务中，提升模型对复杂指令的理解与响应能力。

Result: MiMo-Audio-7B-Base在多个开源音频基准上取得领先性能，具备少样本泛化能力，可处理语音转换、风格迁移、语音编辑等未见任务；其指令微调版本MiMo-Audio-7B-Instruct在音频理解、口语对话及指令语音合成任务中达到开源SOTA，接近甚至超越闭源模型。

Conclusion: 大规模预训练结合指令微调与思维机制，使音频语言模型具备类人般泛化能力，显著提升了音频任务的通用性与实用性，为开放域音频理解与生成提供了强有力的新范式。

Abstract: Existing audio language models typically rely on task-specific fine-tuning to accomplish particular audio tasks. In contrast, humans are able to generalize to new audio tasks with only a few examples or simple instructions. GPT-3 has shown that scaling next-token prediction pretraining enables strong generalization capabilities in text, and we believe this paradigm is equally applicable to the audio domain. By scaling MiMo-Audio's pretraining data to over one hundred million of hours, we observe the emergence of few-shot learning capabilities across a diverse set of audio tasks. We develop a systematic evaluation of these capabilities and find that MiMo-Audio-7B-Base achieves SOTA performance on both speech intelligence and audio understanding benchmarks among open-source models. Beyond standard metrics, MiMo-Audio-7B-Base generalizes to tasks absent from its training data, such as voice conversion, style transfer, and speech editing. MiMo-Audio-7B-Base also demonstrates powerful speech continuation capabilities, capable of generating highly realistic talk shows, recitations, livestreaming and debates. At the post-training stage, we curate a diverse instruction-tuning corpus and introduce thinking mechanisms into both audio understanding and generation. MiMo-Audio-7B-Instruct achieves open-source SOTA on audio understanding benchmarks (MMSU, MMAU, MMAR, MMAU-Pro), spoken dialogue benchmarks (Big Bench Audio, MultiChallenge Audio) and instruct-TTS evaluations, approaching or surpassing closed-source models. Model checkpoints and full evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-Audio.

</details>


### [85] [Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms](https://arxiv.org/abs/2512.23835)
*Himel Ghosh*

Main category: cs.CL

TL;DR: 本文通过SHAP-based解释对两种基于Transformer的新闻偏见检测模型进行了可解释性对比研究，发现尽管两者关注相似的评价性语言类别，但在信号整合方式上存在显著差异。偏见检测模型在错误预测中分配更强的内部证据，导致对中立新闻内容的系统性误报；而领域自适应模型的归因模式更符合预测结果，错误率降低63%。错误主要源于话语层面的模糊性，而非明确的偏见线索。研究强调了可解释性评估在偏见检测系统中的重要性，并指出模型架构与训练策略直接影响其可靠性与新闻场景下的适用性。


<details>
  <summary>Details</summary>
Motivation: 当前自动化偏见检测广泛用于新闻分析和媒体问责，但缺乏对模型决策过程及失败原因的理解，亟需可解释性研究以提升模型可靠性与部署适用性。

Method: 采用SHAP方法对两个基于Transformer的偏见检测模型（一个在BABE数据集上微调的偏见检测器，另一个在相同数据集上微调的领域自适应RoBERTa模型）进行词级归因分析，比较正确与错误预测中的归因模式，揭示不同架构如何操作语言偏见。

Result: 偏见检测模型在错误预测中赋予更高的归因强度，导致对中立内容的过度标记；而领域自适应模型的归因与预测结果更一致，错误率减少63%。错误主要由话语层面的模糊性引发，而非显式偏见信号。

Conclusion: 可解释性评估对于偏见检测系统至关重要，模型的架构选择与训练策略深刻影响其可靠性与在新闻实践中的适用性。

Abstract: Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63\% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.

</details>


### [86] [Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?](https://arxiv.org/abs/2512.23836)
*Dingmin Wang,Ji Ma,Shankar Kumar*

Main category: cs.CL

TL;DR: 本文研究了在检索增强生成中使用大语言模型（LLM）进行问答时，长上下文带来的挑战。尽管更长的上下文有助于引入相关知识，但也引入了更多无关信息，影响生成效果并降低性能。为此，作者提出一种自适应提示策略：将检索到的信息分块，并逐块顺序提示LLM回答问题，通过调整块大小实现相关信息与无关信息之间的权衡。实验在三个开放域问答数据集上显示，该策略在性能上可媲美标准提示，同时减少使用的令牌数。分析发现，当信息不足时，LLM倾向于生成错误答案而非拒绝回答，这是主要错误来源之一，凸显了提升LLM在信息不足时拒绝请求能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 长上下文虽有助于引入更多相关知识，但也会引入大量无关信息，影响大语言模型的生成质量，导致性能下降。因此需要一种有效策略，在保留必要信息的同时减少冗余。

Method: 设计一种自适应提示策略，将检索到的信息分块，并依次用这些小块提示大语言模型回答问题，通过调节块大小来平衡信息相关性与冗余性。

Result: 在三个开放域问答数据集上的实验表明，该自适应策略在性能上与标准提示相当，但使用更少的令牌；分析发现，当信息不足时，模型常生成错误答案而非拒绝回答，是主要错误来源。

Conclusion: 自适应提示策略能有效应对长上下文中的冗余信息问题，提高效率和性能。然而，当前模型在信息不足时缺乏正确拒绝能力，亟需进一步研究以提升其判断与拒答能力。

Abstract: The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model's generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs' ability to effectively decline requests when faced with inadequate information.

</details>


### [87] [Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation](https://arxiv.org/abs/2512.23837)
*Kaustubh Dhole*

Main category: cs.CL

TL;DR: 本文提出一种基于注意力层的新型对抗性攻击方法，利用模型内部中间层的标记分布生成既合理又与模型自身生成过程一致的对抗样本。相比传统的提示或梯度攻击，该方法在保持语义相似性的同时显著降低评估性能，但部分层和标记位置的替换可能导致语法退化，影响实际效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用大语言模型中间层的注意力机制来生成更自然、内部一致的对抗样本，以更好地测试评估系统的鲁棒性。

Method: 从模型的中间注意力层提取标记分布，并基于这些分布生成对抗性扰动；通过在ArgQuality数据集上使用LLaMA-3.1-Instruct-8B作为生成器和评估器进行实验验证。

Result: 注意力驱动的对抗样本导致评估性能明显下降，同时保持与原始输入的语义相似性；但某些层和位置的替换会引入语法错误，限制其实用性。

Conclusion: 中间层表示可作为生成对抗样本的有前景来源，但在实际应用中仍面临语法质量等挑战，需进一步优化。

Abstract: Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model's own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.

</details>


### [88] [Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs](https://arxiv.org/abs/2512.23848)
*Yukun Zhang,Stefan Elbl Droguett,Samyak Jain*

Main category: cs.CL

TL;DR: 该研究针对金融数值推理问答任务中因缺乏领域知识导致的错误问题，提出使用多检索器的RAG系统结合外部领域知识与内部问题上下文，并利用最新大语言模型进行处理。通过消融实验和错误分析发现，基于SecBERT编码器的领域特定训练显著提升了神经符号模型性能，超越了现有最佳模型；而最优提示式LLM生成器达到了当前最优（SOTA）表现，但仍低于人类专家水平。研究揭示了小模型在少样本情况下外部知识收益与幻觉损失之间的权衡，而大模型则通常能从外部事实中获益更多。最终证实了最新优化为少样本学习的大语言模型在数值推理方面的能力增强。


<details>
  <summary>Details</summary>
Motivation: 金融数值推理任务需要特定的金融领域知识和复杂的多步数值推理能力，但现有大语言模型由于缺乏此类专业知识，导致回答错误频发。因此，亟需引入外部知识和领域适应性训练以提升模型性能。

Method: 采用多检索器的检索增强生成（RAG）系统，同时检索外部金融领域知识和内部问题上下文；结合基于SecBERT的领域特定训练以及最新的大语言模型进行推理生成。通过消融实验与误差分析评估不同组件的效果。

Result: 领域特定训练使神经符号模型超越基准模型；最优提示式LLM生成器达到当前最优性能，提升超过7%，但仍不及人类专家水平；小模型在少样本场景下面临幻觉与知识获取的权衡，而大模型则更受益于外部知识。

Conclusion: 领域特定训练和外部知识融合对提升金融数值推理任务至关重要；最新大语言模型在少样本条件下展现出更强的数值推理能力，但仍有改进空间，尤其在减少幻觉与提高准确性方面。

Abstract: This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper's top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (>7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.

</details>


### [89] [Disentangling Learning from Judgment: Representation Learning for Open Response Analytics](https://arxiv.org/abs/2512.23941)
*Conrad Borchers,Manit Patel,Seiyon M. Lee,Anthony F. Botelho*

Main category: cs.CL

TL;DR: 本文提出一种以分析为核心的框架，将学生回答的内容信号与教师评分倾向分离，通过动态先验建模和句子嵌入技术，结合中心化与残差化处理，减少提示和教师偏差的影响。基于ASSISTments数学题数据，使用时间验证的线性模型量化各信号贡献，投影表面模型揭示评分分歧。结果显示，教师先验对评分预测影响显著，内容嵌入与教师先验结合时表现最佳（AUC~0.815），仅用内容模型仍优于随机（AUC~0.626）。校正评分者效应后，内容表征更清晰，保留更多信息维度，揭示学生理解的真实证据。该方法将嵌入转化为学习分析工具，使教师和研究者能反思评分一致性与学生思维证据之间的关系。


<details>
  <summary>Details</summary>
Motivation: 自动化评分常混淆学生实际回答与教师评分习惯，缺乏透明性和可审计性，亟需一种能分离内容与评分偏见的分析框架，以支持教学反馈与评估改进。

Method: 采用动态先验建模教师历史，利用句子嵌入提取文本表示，并通过中心化与残差化消除提示与教师偏差；结合时间验证线性模型分析各因素贡献，使用投影表面模型可视化评分差异。

Result: 教师先验对评分预测影响显著；内容嵌入与教师先验结合时模型性能最优（AUC~0.815）；仅内容模型表现尚可但较弱（AUC~0.626）；校正评分者效应后，内容表征更准确，揭示深层理解证据。

Conclusion: 本研究提供了一套实用的分析管道，将文本嵌入从普通特征转化为可解释的学习分析工具，帮助教师与研究者审视评分实践与学生真实理解之间的一致性或冲突。

Abstract: Open-ended responses are central to learning, yet automated scoring often conflates what students wrote with how teachers grade. We present an analytics-first framework that separates content signals from rater tendencies, making judgments visible and auditable via analytics. Using de-identified ASSISTments mathematics responses, we model teacher histories as dynamic priors and derive text representations from sentence embeddings, incorporating centering and residualization to mitigate prompt and teacher confounds. Temporally-validated linear models quantify the contributions of each signal, and a projection surfaces model disagreements for qualitative inspection. Results show that teacher priors heavily influence grade predictions; the strongest results arise when priors are combined with content embeddings (AUC~0.815), while content-only models remain above chance but substantially weaker (AUC~0.626). Adjusting for rater effects sharpens the residual content representation, retaining more informative embedding dimensions and revealing cases where semantic evidence supports understanding as opposed to surface-level differences in how students respond. The contribution presents a practical pipeline that transforms embeddings from mere features into learning analytics for reflection, enabling teachers and researchers to examine where grading practices align (or conflict) with evidence of student reasoning and learning.

</details>


### [90] [Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling](https://arxiv.org/abs/2512.23959)
*Chulun Zhou,Chunkang Zhang,Guoxin Yu,Fandong Meng,Jie Zhou,Wai Lam,Mo Yu*

Main category: cs.CL

TL;DR: HGMem 提出一种基于超图的记忆机制，将记忆从静态存储升级为动态、可表达的复杂推理结构。通过超边连接事实与思想，促进高阶交互，形成集成的知识结构，显著提升多步检索增强生成中的全局理解与推理能力。在多个挑战性数据集上，HGMem 均显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有 RAG 系统中的记忆模块多为被动存储，仅累积孤立事实，忽视事实间的高阶关联，导致推理碎片化和全局理解能力弱。需要更动态、更具表达力的记忆结构以支持复杂推理与知识演化。

Method: 提出 HGMem，一种基于超图的记忆机制。记忆以超图形式表示，超边代表不同记忆单元，支持事实间高阶关系的逐步构建，实现知识的整合与情境化，为后续推理提供强指导性命题。

Result: 在多个面向全局理解的挑战性数据集上，HGMem 显著提升多步 RAG 性能，优于多种强基线模型，验证了其在复杂推理与知识演化方面的有效性。

Conclusion: HGMem 通过超图结构将记忆转化为动态、高表达力的推理引擎，有效增强了 LLM 在长上下文和多步任务中的全局感知与深度推理能力，为未来 RAG 系统设计提供了新范式。

Abstract: Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static nature overlooks the crucial high-order correlations among primitive facts, the compositions of which can often provide stronger guidance for subsequent steps. Therefore, their representational strength and impact on multi-step reasoning and knowledge evolution are limited, resulting in fragmented reasoning and weak global sense-making capacity in extended contexts. We introduce HGMem, a hypergraph-based memory mechanism that extends the concept of memory beyond simple storage into a dynamic, expressive structure for complex reasoning and global understanding. In our approach, memory is represented as a hypergraph whose hyperedges correspond to distinct memory units, enabling the progressive formation of higher-order interactions within memory. This mechanism connects facts and thoughts around the focal problem, evolving into an integrated and situated knowledge structure that provides strong propositions for deeper reasoning in subsequent steps. We evaluate HGMem on several challenging datasets designed for global sense-making. Extensive experiments and in-depth analyses show that our method consistently improves multi-step RAG and substantially outperforms strong baseline systems across diverse tasks.

</details>


### [91] [CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards](https://arxiv.org/abs/2512.23971)
*Zhiming Lin,Kai Zhao,Sophie Zhang,Peilai Yu,Canran Xiao*

Main category: cs.CL

TL;DR: CEC-Zero 是一种零监督强化学习框架，通过让大模型自我纠正错误来实现大规模中文拼写纠错。它通过从干净文本生成错误输入，利用语义相似性和候选答案一致性计算聚类共识奖励，并使用PPO优化策略，在9个基准测试中比监督基线提升10-13 F₁点，比强的LLM微调方法提升5-8点，具有无偏奖励和收敛性理论保证，建立了无需标签的鲁棒、可扩展的纠错范式。


<details>
  <summary>Details</summary>
Motivation: 现有大模型和监督方法在处理新类型错误时缺乏鲁棒性，且依赖昂贵的人工标注，因此需要一种无需监督信号的高效、可扩展的中文拼写纠错方法。

Method: CEC-Zero 通过合成错误输入，基于语义相似性和候选答案一致性构建聚类共识奖励，并采用PPO算法优化模型策略，实现零监督下的自我纠错能力。

Result: 在9个基准测试中，CEC-Zero 比监督基线提升10–13 F₁点，比强的LLM微调方法提升5–8 F₁点，具备理论上的无偏奖励与收敛性保障。

Conclusion: CEC-Zero 建立了无需标签的中文拼写纠错新范式，显著提升了大模型在噪声文本处理中的鲁棒性与实用性，为真实场景下的文本净化提供了有效解决方案。

Abstract: Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by enabling LLMs to correct their own mistakes. CEC-Zero synthesizes errorful inputs from clean text, computes cluster-consensus rewards via semantic similarity and candidate agreement, and optimizes the policy with PPO. It outperforms supervised baselines by 10--13 F$_1$ points and strong LLM fine-tunes by 5--8 points across 9 benchmarks, with theoretical guarantees of unbiased rewards and convergence. CEC-Zero establishes a label-free paradigm for robust, scalable CSC, unlocking LLM potential in noisy text pipelines.

</details>


### [92] [Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process](https://arxiv.org/abs/2512.23988)
*Zhenyu Zhang,Shujian Zhang,John Lambert,Wenxuan Zhou,Zhangyang Wang,Mingqing Chen,Andrew Hard,Rajiv Mathews,Lun Wang*

Main category: cs.CL

TL;DR: 本文提出了一种无监督框架RISE（Reasoning behavior Interpretability via Sparse auto-Encoder），用于发现大语言模型中编码特定推理行为的激活空间方向。通过将思维链分解为句子级步骤并训练稀疏自编码器（SAE），该方法可识别出如反思、回溯等可解释的行为特征，并在解码器空间中实现行为的分离与控制。此外，SAE还能揭示响应长度等结构属性，并发现人类未预设的新行为模式，例如通过识别与置信度相关的向量来调控输出信心。整体表明，无监督潜在发现对理解与可控引导模型推理具有重要潜力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工定义的概念（如过度思考、反思）进行有监督分析，但难以覆盖所有可能的推理行为，尤其当这些行为在词元空间中难以明确定义时。因此需要一种无需先验知识的无监督方法来探索模型内部推理机制。

Method: 提出RISE框架，基于稀疏自编码器（SAE）对思维链中的句子级激活进行建模，通过训练发现能表征不同推理行为的离散方向（即推理向量），并利用可视化和聚类验证其可解释性；进一步通过干预这些向量实现对推理过程的可控调节。

Result: 成功识别出反射、回溯等已知推理行为，发现响应长度差异对应的结构模式，以及超越人类监督的新行为（如置信度相关向量）；通过向量干预可有效增强或抑制特定行为，改变推理轨迹而不需重新训练。

Conclusion: RISE框架展示了无监督潜在发现对于理解与可控操控大语言模型推理过程的强大能力，为揭示模型内部复杂行为提供了新路径。

Abstract: Despite the growing reasoning capabilities of recent large language models (LLMs), their internal mechanisms during the reasoning process remain underexplored. Prior approaches often rely on human-defined concepts (e.g., overthinking, reflection) at the word level to analyze reasoning in a supervised manner. However, such methods are limited, as it is infeasible to capture the full spectrum of potential reasoning behaviors, many of which are difficult to define in token space. In this work, we propose an unsupervised framework (namely, RISE: Reasoning behavior Interpretability via Sparse auto-Encoder) for discovering reasoning vectors, which we define as directions in the activation space that encode distinct reasoning behaviors. By segmenting chain-of-thought traces into sentence-level 'steps' and training sparse auto-encoders (SAEs) on step-level activations, we uncover disentangled features corresponding to interpretable behaviors such as reflection and backtracking. Visualization and clustering analyses show that these behaviors occupy separable regions in the decoder column space. Moreover, targeted interventions on SAE-derived vectors can controllably amplify or suppress specific reasoning behaviors, altering inference trajectories without retraining. Beyond behavior-specific disentanglement, SAEs capture structural properties such as response length, revealing clusters of long versus short reasoning traces. More interestingly, SAEs enable the discovery of novel behaviors beyond human supervision. We demonstrate the ability to control response confidence by identifying confidence-related vectors in the SAE decoder space. These findings underscore the potential of unsupervised latent discovery for both interpreting and controllably steering reasoning in LLMs.

</details>


### [93] [WISE: Web Information Satire and Fakeness Evaluation](https://arxiv.org/abs/2512.24000)
*Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury*

Main category: cs.CL

TL;DR: 该研究提出WISE框架，评估八种轻量级Transformer模型与两种基线模型在20,000个样本上的表现，发现MiniLM在准确率上最高（87.58%），RoBERTa-base在ROC-AUC上最优（95.42%），DistilBERT在效率与准确率间取得良好平衡。统计检验确认模型间存在显著差异，表明轻量模型可在资源受限场景下有效部署虚假信息检测系统。


<details>
  <summary>Details</summary>
Motivation: 区分虚假新闻与讽刺/幽默内容具有挑战性，因其语言特征重叠但意图不同，亟需高效且准确的检测方法以应对信息误导问题。

Method: 采用分层5折交叉验证，在Fakeddit数据集上对八种轻量级Transformer模型及两种基线模型进行评估，使用包括准确率、精确率、召回率、F1分数、ROC-AUC、PR-AUC、MCC、Brier分数和期望校准误差在内的多维度指标进行分析，并通过配对t检验和McNemar检验进行统计比较。

Result: MiniLM在准确率上表现最佳（87.58%），RoBERTa-base在ROC-AUC上领先（95.42%），DistilBERT在准确率（86.28%）和ROC-AUC（93.90%）之间实现良好平衡；统计测试证实模型性能差异显著。

Conclusion: 轻量级模型能够达到甚至超过传统基线模型的性能，为在资源受限的实际环境中部署虚假信息检测系统提供了可行方案。

Abstract: Distinguishing fake or untrue news from satire or humor poses a unique challenge due to their overlapping linguistic features and divergent intent. This study develops WISE (Web Information Satire and Fakeness Evaluation) framework which benchmarks eight lightweight transformer models alongside two baseline models on a balanced dataset of 20,000 samples from Fakeddit, annotated as either fake news or satire. Using stratified 5-fold cross-validation, we evaluate models across comprehensive metrics including accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, MCC, Brier score, and Expected Calibration Error. Our evaluation reveals that MiniLM, a lightweight model, achieves the highest accuracy (87.58%) among all models, while RoBERTa-base achieves the highest ROC-AUC (95.42%) and strong accuracy (87.36%). DistilBERT offers an excellent efficiency-accuracy trade-off with 86.28\% accuracy and 93.90\% ROC-AUC. Statistical tests confirm significant performance differences between models, with paired t-tests and McNemar tests providing rigorous comparisons. Our findings highlight that lightweight models can match or exceed baseline performance, offering actionable insights for deploying misinformation detection systems in real-world, resource-constrained settings.

</details>


### [94] [iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning](https://arxiv.org/abs/2512.24014)
*Sijia Chen,Di Niu*

Main category: cs.CL

TL;DR: 本文提出iCLP框架，受人类隐性认知启发，使大语言模型（LLMs）通过生成紧凑的潜在计划（LPs）实现更高效、准确的推理。该方法首先从已有推理轨迹中提炼显式计划，再利用向量量化自编码器学习离散表示，并通过微调让模型在推理时进行隐式规划。实验表明，iCLP在数学推理和代码生成任务中显著提升准确率与效率，具备强跨领域泛化能力且保持思维链可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于显式文本计划的LLM推理易受幻觉影响且难以适应多样化任务；为克服此问题，受人类隐性认知启发，探索无需显式表达的高效、通用推理机制。

Method: iCLP框架包括三步：1）从已有推理轨迹中提取显式计划；2）使用向量量化自编码器与码本学习这些计划的离散潜在表示；3）微调LLM以实现从潜在计划到语言空间推理的映射。

Result: 在数学推理与代码生成任务中，iCLP显著提升推理准确率与效率，展现出优异的跨领域泛化能力，并保持思维链推理的可解释性。

Conclusion: iCLP通过将推理规划置于潜在空间，实现了高效、可泛化且可解释的智能推理，为大语言模型的可靠推理提供了新范式。

Abstract: Large language models (LLMs), when guided by explicit textual plans, can perform reliable step-by-step reasoning during problem-solving. However, generating accurate and effective textual plans remains challenging due to LLM hallucinations and the high diversity of task-specific questions. To address this, we draw inspiration from human Implicit Cognition (IC), the subconscious process by which decisions are guided by compact, generalized patterns learned from past experiences without requiring explicit verbalization. We propose iCLP, a novel framework that enables LLMs to adaptively generate latent plans (LPs), which are compact encodings of effective reasoning instructions. iCLP first distills explicit plans from existing step-by-step reasoning trajectories. It then learns discrete representations of these plans via a vector-quantized autoencoder coupled with a codebook. Finally, by fine-tuning LLMs on paired latent plans and corresponding reasoning steps, the models learn to perform implicit planning during reasoning. Experimental results on mathematical reasoning and code generation tasks demonstrate that, with iCLP, LLMs can plan in latent space while reasoning in language space. This approach yields significant improvements in both accuracy and efficiency and, crucially, demonstrates strong cross-domain generalization while preserving the interpretability of chain-of-thought reasoning.

</details>


### [95] [Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models](https://arxiv.org/abs/2512.24058)
*Rohit Kumar Salla,Manoj Saravanan,Shrikar Reddy Kota*

Main category: cs.CL

TL;DR: 本文提出了一种名为综合可靠性评分（CRS）的统一框架，用于评估大型语言模型在医疗、法律和金融等关键决策领域中的可靠性。CRS整合了校准性、鲁棒性和不确定性量化，提供一个可解释的单一指标，克服了现有评估方法碎片化的缺陷。通过在十个主流开源LLM上进行实验，验证了CRS在不同数据集和扰动条件下的稳定性，揭示了单一指标无法发现的隐藏故障模式，并指出最可靠的系统需在准确性、鲁棒性和校准不确定性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在关键领域应用中存在可靠性不足的问题，如过度自信错误、输入变化下的性能下降以及缺乏明确的不确定性估计。现有评估方法分散且不全面，难以全面衡量模型可靠性。

Method: 提出复合可靠性评分（CRS），将校准性、鲁棒性和不确定性量化整合为一个统一的可解释指标，并通过多数据集、多扰动条件下的实验对十种主流开源大模型进行评估。

Result: CRS能够保持稳定的模型排名，识别出单个指标未能捕捉到的隐藏失败模式，表明最可靠的模型是那些在准确性、鲁棒性和校准不确定性之间取得良好平衡的系统。

Conclusion: CRS为评估大型语言模型的可靠性提供了一个全面、统一且可解释的框架，有助于提升其在关键应用中的可信度与安全性。

Abstract: Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.

</details>


### [96] [HY-MT1.5 Technical Report](https://arxiv.org/abs/2512.24092)
*Mao Zheng,Zheng Li,Tao Chen,Mingyang Song,Di Wang*

Main category: cs.CL

TL;DR: 本文介绍了新型机器翻译模型HY-MT1.5-1.8B和HY-MT1.5-7B，通过多阶段训练框架实现高性能翻译。该方法结合通用与专用预训练、监督微调、在线策略蒸馏和强化学习。1.8B模型在参数效率上表现卓越，超越多个更大规模的开源模型和主流商业API，在中-外、英-外任务中表现优异，达到超大闭源模型Gemini-3.0-Pro约90%的性能；7B模型则在同类中达到新基准，性能达Gemini-3.0-Pro的95%，并在WMT25和中文-少数语言测试集上超越其表现。模型还支持术语干预、上下文感知翻译和格式保持等高级功能。实证评估表明，两者在各自参数量级下均具备高度竞争力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提升机器翻译模型的性能与效率，尤其在小规模模型中实现接近超大规模闭源模型的表现，并增强对专业翻译场景的支持能力。

Method: 采用多阶段训练框架，包括通用与专用于机器翻译的预训练、监督微调、基于策略的蒸馏以及强化学习优化。

Result: HY-MT1.5-1.8B在多项标准任务中超越更大规模开源模型与商业API，达到Gemini-3.0-Pro约90%性能；HY-MT1.5-7B在同规模模型中达到新标杆，性能超过Gemini-3.0-Pro，尤其在复杂任务如WMT25和中文-少数语言翻译上表现突出。模型支持术语控制、上下文感知与格式保留等高级功能。

Conclusion: HY-MT1.5系列模型在参数效率与翻译质量之间取得良好平衡，为通用及特定领域翻译任务提供了极具竞争力的解决方案。

Abstract: In this report, we introduce our latest translation models, HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of machine translation models developed through a holistic training framework tailored for high-performance translation. Our methodology orchestrates a multi-stage pipeline that integrates general and MT-oriented pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. HY-MT1.5-1.8B, the 1.8B-parameter model demonstrates remarkable parameter efficiency, comprehensively outperforming significantly larger open-source baselines (e.g., Tower-Plus-72B, Qwen3-32B) and mainstream commercial APIs (e.g., Microsoft Translator, Doubao Translator) in standard Chinese-foreign and English-foreign tasks. It achieves approximately 90% of the performance of ultra-large proprietary models such as Gemini-3.0-Pro, while marginally trailing Gemini-3.0-Pro on WMT25 and Mandarin-minority language benchmarks, it maintains a substantial lead over other competing models. Furthermore, HY-MT1.5-7B establishes a new state-of-the-art for its size class, achieving 95% of Gemini-3.0-Pro's performance on Flores-200 and surpassing it on the challenging WMT25 and Mandarin-minority language test sets. Beyond standard translation, the HY-MT1.5 series supports advanced constraints, including terminology intervention, context-aware translation, and format preservation. Extensive empirical evaluations confirm that both models offer highly competitive, robust solutions for general and specialized translation tasks within their respective parameter scales.

</details>


### [97] [Training a Huggingface Model on AWS Sagemaker (Without Tears)](https://arxiv.org/abs/2512.24098)
*Liling Tan*

Main category: cs.CL

TL;DR: 该演示论文旨在通过集中化关键信息，帮助研究人员克服在AWS SageMaker上从零开始训练Hugging Face模型的障碍，从而推动云平台的普及与使用。


<details>
  <summary>Details</summary>
Motivation: 许多研究者因缺乏本地计算资源而转向云服务，但云平台的学习曲线陡峭，现有文档存在知识断层，导致用户难以快速上手。

Method: 通过整合和整理在AWS SageMaker上训练Hugging Face模型所需的核心步骤与实践指南，提供一个清晰、系统化的入门路径。

Result: 成功为研究人员提供了从零开始在AWS SageMaker上训练Hugging Face模型的完整指导，降低技术门槛，提升云平台的可及性。

Conclusion: 通过集中化知识与简化流程，该工作有效促进了研究社区对云平台的采用，助力科研民主化。

Abstract: The development of Large Language Models (LLMs) has primarily been driven by resource-rich research groups and industry partners. Due to the lack of on-premise computing resources required for increasingly complex models, many researchers are turning to cloud services like AWS SageMaker to train Hugging Face models. However, the steep learning curve of cloud platforms often presents a barrier for researchers accustomed to local environments. Existing documentation frequently leaves knowledge gaps, forcing users to seek fragmented information across the web. This demo paper aims to democratize cloud adoption by centralizing the essential information required for researchers to successfully train their first Hugging Face model on AWS SageMaker from scratch.

</details>


### [98] [Activation Steering for Masked Diffusion Language Models](https://arxiv.org/abs/2512.24143)
*Adi Shnaidman,Erin Feiglin,Osher Yaari,Efrat Mentel,Amit Levi,Raz Lapid*

Main category: cs.CL

TL;DR: 本文提出了一种针对掩码扩散语言模型（MDLMs）的激活引导框架，通过单次前向传播利用对比样本计算逐层引导向量，无需模拟去噪轨迹，可在每个反向扩散步骤中应用，实现高效推理时控制。实验在LLaDA-8B-Instruct上验证了对高层属性的可靠调节能力，并通过消融实验分析了引导在Transformer子模块和令牌范围（提示与响应）上的影响。


<details>
  <summary>Details</summary>
Motivation: 当前掩码扩散语言模型虽具备并行掩码解码和与自回归大模型相媲美的性能，但推理阶段的控制与引导机制仍不成熟，缺乏有效方法实现对生成内容的精细调控。

Method: 提出一种基于对比示例的激活引导框架，通过一次前向传播计算层级引导向量，无需模拟整个去噪过程，在每个反向扩散步骤中施加引导，实现高效推理控制。

Result: 在LLaDA-8B-Instruct模型上，该方法成功实现了对生成文本高层属性的可靠调节；消融实验表明引导效果在不同Transformer子模块和令牌作用范围（提示与响应）上具有显著差异性。

Conclusion: 该激活引导框架为掩码扩散语言模型提供了高效的推理时控制手段，能够精准调节生成内容的语义属性，具有良好的可扩展性和实用性。

Abstract: Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steering in MDLMs remain largely unexplored. We present an activation-steering framework for MDLMs that computes layer-wise steering vectors from a single forward pass using contrastive examples, without simulating the denoising trajectory. These directions are applied at every reverse-diffusion step, yielding an efficient inference-time control mechanism. Experiments on LLaDA-8B-Instruct demonstrate reliable modulation of high-level attributes, with ablations examining the effects of steering across transformer sub-modules and token scope (prompt vs.\ response).

</details>


### [99] [Large Emotional World Model](https://arxiv.org/abs/2512.24149)
*Changhao Song,Yazhou Zhang,Hui Gao,Chang Yang,Peng Zhang*

Main category: cs.CL

TL;DR: 本文提出大型情感世界模型（LEWM），通过构建融合情感因果关系的EWH数据集，使模型能够同时建模情感状态、视觉观察和行为，从而更准确地预测情绪驱动的社会行为。实验表明，该模型在情感相关任务上表现优于通用世界模型，且在基础任务上保持相当性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽具备一定世界知识建模能力，但主要关注物理世界规律，缺乏对情感因素的系统性探索。情感在人类决策中起关键作用，因此需要将情感纳入世界模型以提升理解与预测能力。

Method: 提出大型情感世界模型（LEWM），构建包含情感因果关系的EWH数据集，使模型能显式建模情感状态，并结合视觉观察与行为，实现对未来状态及情感转变的联合预测。

Result: LEWM在预测情绪驱动的社会行为方面表现更优，同时在基础任务上的性能与通用世界模型相当，证明其有效性和泛化能力。

Conclusion: 情感是世界模型中不可或缺的部分，引入情感建模可显著提升对复杂社会行为的理解与预测能力。本研究为构建更具人性化的世界模型提供了新路径。

Abstract: World Models serve as tools for understanding the current state of the world and predicting its future dynamics, with broad application potential across numerous fields. As a key component of world knowledge, emotion significantly influences human decision-making. While existing Large Language Models (LLMs) have shown preliminary capability in capturing world knowledge, they primarily focus on modeling physical-world regularities and lack systematic exploration of emotional factors. In this paper, we first demonstrate the importance of emotion in understanding the world by showing that removing emotionally relevant information degrades reasoning performance. Inspired by theory of mind, we further propose a Large Emotional World Model (LEWM). Specifically, we construct the Emotion-Why-How (EWH) dataset, which integrates emotion into causal relationships and enables reasoning about why actions occur and how emotions drive future world states. Based on this dataset, LEWM explicitly models emotional states alongside visual observations and actions, allowing the world model to predict both future states and emotional transitions. Experimental results show that LEWM more accurately predicts emotion-driven social behaviors while maintaining comparable performance to general world models on basic tasks.

</details>


### [100] [Training Report of TeleChat3-MoE](https://arxiv.org/abs/2512.24157)
*Xinzhang Liu,Chao Wang,Zhihao Yang,Zhuo Jiang,Xuncheng Zhao,Haoran Wang,Lei Li,Dongdong He,Luobin Liu,Kaizhe Yuan,Han Gao,Zihan Wang,Yitong Yao,Sishi Xiong,Wenmin Deng,Haowei He,Kaidong Yu,Yu Zhao,Ruiyu Fang,Yuhao Jiang,Yingyan Li,Xiaohui Hu,Xi Yu,Jingqi Li,Yanwei Liu,Qingli Li,Xinyu Shi,Junhao Niu,Chengnuo Huang,Yao Xiao,Ruiwen Wang,Fengkai Li,Luwen Pu,Kaipeng Jia,Fubei Yao,Yuyao Huang,Xuewei He,Zhuoru Jiang,Ruiting Song,Rui Xue,Qiyi Xie,Jie Zhang,Zilu Huang,Zhaoxi Zhang,Zhilong Lu,Yanhan Zhang,Yin Zhang,Yanlei Xue,Zhu Yuan,Teng Su,Xin Jiang,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: TeleChat3-MoE 是基于 Ascend NPU 集群端到端训练的超大规模语言模型系列，采用 MoE 架构，参数量达 1050 亿至超过一万亿。本文重点介绍支撑其高效可靠扩展至前沿模型规模的底层训练基础设施，涵盖算子级与端到端数值精度验证、多种性能优化技术（如交错流水线调度、注意力感知数据调度、分层重叠通信、DVM 基于的操作融合），以及基于解析估计与整数线性规划的多维并行配置优化框架。同时提出集群级优化方法，解决主机与设备瓶颈问题，实现数千设备上的近线性扩展与显著吞吐提升，为硬件生态上的大模型研发提供坚实基础。


<details>
  <summary>Details</summary>
Motivation: 为了支持超大规模语言模型（如 TeleChat3-MoE）在真实硬件集群上高效、稳定地训练，亟需构建一套可扩展、高精度、高性能的底层训练基础设施，以应对模型规模增长带来的数值一致性、通信开销、资源调度和系统瓶颈等挑战。

Method: 提出系统化的数值精度验证方法（算子级与端到端），设计多种性能优化策略（包括交错流水线调度、注意力感知的数据调度、专家并行中的分层重叠通信、DVM 基于的操作融合），构建基于解析估计与整数线性规划的多维并行配置优化框架，并实施集群级优化以缓解主机与设备瓶颈。

Result: 实现了数千设备规模下的近线性扩展，显著提升训练吞吐量；确保了跨硬件平台与分布式策略的一致性与数值准确性；为大规模语言模型在 Ascend NPU 生态上的开发提供了高效可靠的基础设施支持。

Conclusion: TeleChat3-MoE 的成功训练依赖于一套全面且高效的底层训练基础设施，涵盖从算子精度保障到系统级性能优化的多个层面。该体系不仅支撑了当前超大规模模型的训练需求，也为未来更大规模模型的研发提供了可复用的技术范式与工程基础。

Abstract: TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastructure that enables reliable and efficient scaling to frontier model sizes. We detail systematic methodologies for operator-level and end-to-end numerical accuracy verification, ensuring consistency across hardware platforms and distributed parallelism strategies. Furthermore, we introduce a suite of performance optimizations, including interleaved pipeline scheduling, attention-aware data scheduling for long-sequence training,hierarchical and overlapped communication for expert parallelism, and DVM-based operator fusion. A systematic parallelization framework, leveraging analytical estimation and integer linear programming, is also proposed to optimize multi-dimensional parallelism configurations. Additionally, we present methodological approaches to cluster-level optimizations, addressing host- and device-bound bottlenecks during large-scale training tasks. These infrastructure advancements yield significant throughput improvements and near-linear scaling on clusters comprising thousands of devices, providing a robust foundation for large-scale language model development on hardware ecosystems.

</details>


### [101] [MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring](https://arxiv.org/abs/2512.24181)
*Qipeng Wang,Rui Sheng,Yafei Li,Huamin Qu,Yushi Sun,Min Zhu*

Main category: cs.CL

TL;DR: MedKGI is a diagnostic framework for LLMs in clinical settings that addresses key limitations like hallucination, inefficient questioning, and loss of coherence by integrating a medical knowledge graph, using information gain for question selection, and adopting an OSCE-style structured state to track evidence. It improves diagnostic accuracy and dialogue efficiency by 30% over baselines.


<details>
  <summary>Details</summary>
Motivation: Current LLMs fail to mimic the iterative, hypothesis-driven reasoning of real clinicians due to hallucinations, redundant questions, and inconsistency in multi-turn dialogues, limiting their reliability in clinical diagnosis.

Method: MedKGI incorporates a medical knowledge graph to ground reasoning in verified knowledge, selects questions based on information gain to enhance diagnostic efficiency, and uses an OSCE-format structured state to maintain consistent evidence tracking across interactions.

Result: On clinical benchmarks, MedKGI outperforms strong LLM baselines with higher diagnostic accuracy and 30% better dialogue efficiency, while maintaining state-of-the-art performance.

Conclusion: MedKGI effectively enhances clinical diagnostic reasoning in LLMs by aligning with real-world clinical practices, offering a robust solution to key challenges in medical AI applications.

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated significant promise in clinical diagnosis. However, current models struggle to emulate the iterative, diagnostic hypothesis-driven reasoning of real clinical scenarios. Specifically, current LLMs suffer from three critical limitations: (1) generating hallucinated medical content due to weak grounding in verified knowledge, (2) asking redundant or inefficient questions rather than discriminative ones that hinder diagnostic progress, and (3) losing coherence over multi-turn dialogues, leading to contradictory or inconsistent conclusions. To address these challenges, we propose MedKGI, a diagnostic framework grounded in clinical practices. MedKGI integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies, selects questions based on information gain to maximize diagnostic efficiency, and adopts an OSCE-format structured state to maintain consistent evidence tracking across turns. Experiments on clinical benchmarks show that MedKGI outperforms strong LLM baselines in both diagnostic accuracy and inquiry efficiency, improving dialogue efficiency by 30% on average while maintaining state-of-the-art accuracy.

</details>


### [102] [LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring](https://arxiv.org/abs/2512.24235)
*May Bashendy,Walid Massoud,Sohaila Eltanbouly,Salam Albatarni,Marwan Sayed,Abrar Abir,Houda Bouamor,Tamer Elsayed*

Main category: cs.CL

TL;DR: 本文介绍了LAILA，目前最大的公开阿拉伯语自动作文评分（AES）数据集，包含7,859篇作文，涵盖七个维度的总体和特定特征评分：相关性、结构、词汇、风格、发展、语法和拼写。研究详细描述了数据集的设计、收集和标注过程，并使用最先进的阿拉伯语和英语模型在特定提示和跨提示设置下提供了基准结果。LAILA填补了阿拉伯语AES研究中的关键空白，支持开发稳健的评分系统。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公开可用的数据集，阿拉伯语自动作文评分（AES）研究进展有限，因此需要一个大规模的公开数据集来推动该领域的发展。

Method: 构建LAILA数据集，包括数据收集、标注设计与多维度评分（相关性、结构、词汇、风格、发展、语法和拼写），并使用先进模型在特定和跨提示场景下进行基准测试。

Result: LAILA是目前最大的公开阿拉伯语作文评分数据集，为阿拉伯语AES研究提供了重要资源；基准实验表明，现有模型在不同设置下具有可比性能，验证了数据集的有效性和实用性。

Conclusion: LAILA显著填补了阿拉伯语自动作文评分领域的数据空白，为未来研究提供了高质量、多维度的基准数据，有助于推动更精准、可靠的评分系统的发展。

Abstract: Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.

</details>


### [103] [Tracing the Flow of Knowledge From Science to Technology Using Deep Learning](https://arxiv.org/abs/2512.24259)
*Michael E. Rose,Mainak Ghosh,Sebastian Erhardt,Cheng Li,Erik Buunk,Dietmar Harhoff*

Main category: cs.CL

TL;DR: 提出并评估了适用于专利和科学文献的语义相似性模型，其中Pat-SPECTER在预测专利-论文引用关系上表现最佳，且在真实场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在处理专利与科学文献之间的语义相似性方面存在不足，需要一个能同时适应两类文本的模型。

Method: 基于SPECTER2模型，在专利数据上进行微调，构建Pat-SPECTER模型，并通过对比实验评估其性能。

Result: Pat-SPECTER在多项任务中表现最优，证实了其在专利-论文配对识别和预测中的有效性。

Conclusion: Pat-SPECTER是一个高效、可公开使用的模型，能够有效支持专利与科学文献间的语义分析，有助于理解不同司法管辖区的引用行为差异。

Abstract: We develop a language similarity model suitable for working with patents and scientific publications at the same time. In a horse race-style evaluation, we subject eight language (similarity) models to predict credible Patent-Paper Citations. We find that our Pat-SPECTER model performs best, which is the SPECTER2 model fine-tuned on patents. In two real-world scenarios (separating patent-paper-pairs and predicting patent-paper-pairs) we demonstrate the capabilities of the Pat-SPECTER. We finally test the hypothesis that US patents cite papers that are semantically less similar than in other large jurisdictions, which we posit is because of the duty of candor. The model is open for the academic community and practitioners alike.

</details>


### [104] [Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning](https://arxiv.org/abs/2512.24265)
*Ziqing Fan,Yuqiao Xian,Yan Sun,Li Shen*

Main category: cs.CL

TL;DR: 本文提出DATAMASK，一种高效的联合学习框架，用于大规模预训练数据选择，可同时优化质量与多样性指标。通过将数据选择建模为掩码学习问题，结合策略梯度优化与加速技术，显著降低98.9%的选择时间，实现对万亿级数据的高效处理。基于该框架，从FineWeb中筛选出约10%的数据集FineWeb-Mask，实验证明其在12项任务上分别提升1.5B模型3.2%和7B MoE模型1.9%性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法通常单独使用质量或多样性指标，但在长期预训练中存在收益递减或优质样本流失问题。面对万亿级数据集的高计算成本，联合优化两类指标的挑战尚未解决。

Method: 将数据选择视为掩码学习问题，采用迭代采样、基于目标的策略梯度计算及掩码采样逻辑更新，结合多种加速技术实现高效联合优化。

Result: 相比贪心算法，选择时间减少98.9%；在12个任务上，1.5B模型性能提升3.2%，7B MoE模型提升1.9%。

Conclusion: DATAMASK成功实现了高质量与高多样性数据的联合优化，在万亿级数据下显著提升预训练效率与模型性能，为大模型训练提供了一种高效可行的数据筛选方案。

Abstract: A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in embeddings, which can be roughly categorized into quality and diversity metrics. Due to the high computational cost when applied to trillion-scale token pre-training datasets such as FineWeb and DCLM, these two or more types of metrics are rarely considered jointly in a single selection process. However, in our empirical study, selecting samples based on quality metrics exhibit severe diminishing returns during long-term pre-training, while selecting on diversity metrics removes too many valuable high-quality samples, both of which limit pre-trained LLMs' capabilities. Therefore, we introduce DATAMASK, a novel and efficient joint learning framework designed for large-scale pre-training data selection that can simultaneously optimize multiple types of metrics in a unified process, with this study focusing specifically on quality and diversity metrics. DATAMASK approaches the selection process as a mask learning problem, involving iterative sampling of data masks, computation of policy gradients based on predefined objectives with sampled masks, and updating of mask sampling logits. Through policy gradient-based optimization and various acceleration enhancements, it significantly reduces selection time by 98.9% compared to greedy algorithm, enabling our study to explore joint learning within trillion-scale tokens. With DATAMASK, we select a subset of about 10% from the 15 trillion-token FineWeb dataset, termed FineWeb-Mask. Evaluated across 12 diverse tasks, we achieves significant improvements of 3.2% on a 1.5B dense model and 1.9% on a 7B MoE model.

</details>


### [105] [Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking](https://arxiv.org/abs/2512.24297)
*Meiqi Chen,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: FIGR introduces a figure-guided multimodal reasoning framework that uses visual representations to enhance complex reasoning, particularly in mathematical problems involving spatial and structural constraints. By integrating active visual thinking via reinforcement learning, FIGR improves stability and accuracy over text-only models.


<details>
  <summary>Details</summary>
Motivation: Existing text-based reasoning models struggle with global structural constraints in complex problems, especially those involving implicit spatial or geometric relationships. The authors aim to improve reasoning by incorporating visual representations to better capture such structural information.

Method: FIGR uses end-to-end reinforcement learning to guide when and how visual reasoning is applied during multi-turn problem solving. It constructs visual representations of intermediate hypotheses, allowing the model to reason about structural properties more effectively.

Result: FIGR outperforms strong text-only baselines on challenging mathematical benchmarks: it improves the base model by 13.12% on AIME 2025 and 11.00% on BeyondAIME.

Conclusion: Integrating visual thinking into reasoning through adaptive, figure-guided multimodal mechanisms significantly enhances the stability and reliability of complex reasoning, especially in domains where structural understanding is critical.

Abstract: Complex reasoning problems often involve implicit spatial, geometric, and structural relationships that are not explicitly encoded in text. While recent reasoning models have achieved strong performance across many domains, purely text-based reasoning struggles to represent global structural constraints in complex settings. In this paper, we introduce FIGR, which integrates active visual thinking into multi-turn reasoning via end-to-end reinforcement learning. FIGR externalizes intermediate structural hypotheses by constructing visual representations during problem solving. By adaptively regulating when and how visual reasoning should be invoked, FIGR enables more stable and coherent reasoning over global structural properties that are difficult to capture from text alone. Experiments on challenging mathematical reasoning benchmarks demonstrate that FIGR outperforms strong text-only chain-of-thought baselines. In particular, FIGR improves the base model by 13.12% on AIME 2025 and 11.00% on BeyondAIME, highlighting the effectiveness of figure-guided multimodal reasoning in enhancing the stability and reliability of complex reasoning.

</details>


### [106] [Skim-Aware Contrastive Learning for Efficient Document Representation](https://arxiv.org/abs/2512.24373)
*Waheed Ahmed Abro,Zied Bouraoui*

Main category: cs.CL

TL;DR: 本文提出一种基于自监督对比学习的新框架，用于提升长文档（如法律和医学文本）的表示能力。通过随机掩码文档片段，并利用自然语言推理（NLI）构建对比目标，使模型学会聚焦相关部分、忽略无关内容，模仿人类浏览文本时的注意力机制。该方法在保持高效的同时显著提升了表示质量，在法律和生物医学数据上均取得性能与效率的双重提升。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型在处理长文档时面临计算资源消耗大、上下文捕捉不全的问题；尽管稀疏注意力和层次化Transformer有所改进，但难以有效建模文档整体结构且缺乏可解释性。受人类阅读策略启发，亟需一种更高效、更具语义理解力的长文档表示方法。

Method: 提出一种自监督对比学习框架：随机掩码文档中的一个段落，利用自然语言推理（NLI）判断其与其它段落之间的语义关系（如蕴含、矛盾、中立），通过对比损失拉近相关段落的表示、推远无关段落的表示，从而增强模型对文档整体结构的理解能力。

Result: 在法律和生物医学领域的多个基准数据集上，所提方法在文本分类、信息抽取等任务中均取得显著更高的准确率，同时相比传统模型具有更低的计算开销，验证了其在准确性与效率上的双重优势。

Conclusion: 该方法通过模拟人类阅读中的信息筛选机制，实现了对长文档更高效、更富语义的表示，为复杂领域文本理解提供了新思路。

Abstract: Although transformer-based models have shown strong performance in word- and sentence-level tasks, effectively representing long documents, especially in fields like law and medicine, remains difficult. Sparse attention mechanisms can handle longer inputs, but are resource-intensive and often fail to capture full-document context. Hierarchical transformer models offer better efficiency but do not clearly explain how they relate different sections of a document. In contrast, humans often skim texts, focusing on important sections to understand the overall message. Drawing from this human strategy, we introduce a new self-supervised contrastive learning framework that enhances long document representation. Our method randomly masks a section of the document and uses a natural language inference (NLI)-based contrastive objective to align it with relevant parts while distancing it from unrelated ones. This mimics how humans synthesize information, resulting in representations that are both richer and more computationally efficient. Experiments on legal and biomedical texts confirm significant gains in both accuracy and efficiency.

</details>


### [107] [Comparing Approaches to Automatic Summarization in Less-Resourced Languages](https://arxiv.org/abs/2512.24410)
*Chester Palen-Michel,Constantine Lignos*

Main category: cs.CL

TL;DR: 该研究比较了多种用于低资源语言文本摘要的方法，包括大中小型大型语言模型（LLM）的零样本提示、小模型mT5的微调及三种数据增强方法、多语言迁移学习，以及通过LLM进行翻译-摘要-再翻译的流程。实验使用五种不同指标评估，发现不同LLM在相似参数规模下表现差异显著，多语言微调的mT5基线在多数指标上优于其他方法，包括零样本LLM性能；同时，LLM作为评价者在低资源语言上的可靠性较低。


<details>
  <summary>Details</summary>
Motivation: 自动文本摘要在高资源语言如英语中已取得良好效果，但在低资源语言方面研究较少，亟需探索有效的摘要方法以提升其性能。

Method: 对比多种摘要方法，包括零样本提示、微调mT5模型（含/不含数据增强）、多语言迁移、以及基于LLM的翻译-摘要-再翻译流程。

Result: 不同参数规模的LLM表现存在差异；多语言微调的mT5基线在多数指标上优于其他方法；LLM作为评价者在低资源语言上的可靠性较差。

Conclusion: 多语言微调的mT5模型在低资源语言摘要任务中表现最佳，而零样本提示和基于LLM的翻译流程虽有潜力但受限于模型一致性与评价可靠性，未来应聚焦于改进数据增强与多语言迁移策略。

Abstract: Automatic text summarization has achieved high performance in high-resourced languages like English, but comparatively less attention has been given to summarization in less-resourced languages. This work compares a variety of different approaches to summarization from zero-shot prompting of LLMs large and small to fine-tuning smaller models like mT5 with and without three data augmentation approaches and multilingual transfer. We also explore an LLM translation pipeline approach, translating from the source language to English, summarizing and translating back. Evaluating with five different metrics, we find that there is variation across LLMs in their performance across similar parameter sizes, that our multilingual fine-tuned mT5 baseline outperforms most other approaches including zero-shot LLM performance for most metrics, and that LLM as judge may be less reliable on less-resourced languages.

</details>


### [108] [Cleaning English Abstracts of Scientific Publications](https://arxiv.org/abs/2512.24459)
*Michael E. Rose,Nils A. Herrmann,Sebastian Erhardt*

Main category: cs.CL

TL;DR: 本文提出一种开源、易于集成的语言模型，用于清理英文科学摘要中的冗余信息（如版权声明、章节标题、作者注释等），提升文本相似性分析和嵌入表示的质量。


<details>
  <summary>Details</summary>
Motivation: 科学摘要中常包含干扰分析的冗余信息，影响文档相似性计算和文本嵌入效果，亟需自动化清理工具。

Method: 设计并实现一个基于语言模型的自动清理系统，识别并移除摘要中的非内容性元素。

Result: 该模型在保持保守性的同时具备高精度，有效降低冗余信息干扰，改善嵌入向量的信息密度，并稳定了摘要间的相似性排序。

Conclusion: 所提出的语言模型可有效提升科学文献摘要的质量，适用于下游文本分析任务，具有良好的可扩展性和实用性。

Abstract: Scientific abstracts are often used as proxies for the content and thematic focus of research publications. However, a significant share of published abstracts contains extraneous information-such as publisher copyright statements, section headings, author notes, registrations, and bibliometric or bibliographic metadata-that can distort downstream analyses, particularly those involving document similarity or textual embeddings. We introduce an open-source, easy-to-integrate language model designed to clean English-language scientific abstracts by automatically identifying and removing such clutter. We demonstrate that our model is both conservative and precise, alters similarity rankings of cleaned abstracts and improves information content of standard-length embeddings.

</details>


### [109] [IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback](https://arxiv.org/abs/2512.24460)
*Titas Ramancauskas,Kotryna Ramancauske*

Main category: cs.CL

TL;DR: 本研究设计并评估了一个针对雅思写作考试的修订平台，通过结合自动化作文评分（AES）和基于雅思评分标准的个性化反馈，解决传统备考方法缺乏针对性反馈的问题。平台采用分离对话引导与写作界面的设计以降低认知负荷，并通过设计基础研究（DBR）迭代改进，从规则基础模型逐步升级为基于DistilBERT的变压器模型，实现更准确的评分（MAE=0.66，R²为正）。第五轮循环引入自适应反馈，显著提升分数（平均+0.060分段，p=0.011，Cohen's d=0.504），但效果因修改策略而异。结果表明，自动化反馈更适合作为人类教学的补充，保守的表层修正比激进的结构干预更可靠。未来需开展长期研究并由官方考官验证。


<details>
  <summary>Details</summary>
Motivation: 传统雅思备考方法缺乏根据雅思写作评分标准提供的个性化反馈，导致学习效果受限。本研究旨在开发一个能够提供精准、可操作反馈的修订平台，以提升考生写作能力。

Method: 采用设计基础研究（DBR）方法，历经多轮迭代：早期使用规则基础模型；后期引入基于DistilBERT的变压器模型并附加回归头进行评分；最终在第五轮中实现自适应反馈机制。平台设计强调用户界面友好性，并将对话引导与写作环境分离，以模拟真实考试情境。

Result: 规则基础模型存在中频压缩、低精度及负R²值等缺陷。基于DistilBERT的模型在第四轮中实现显著改进（MAE=0.66，R²为正）。第五轮自适应反馈使考生平均得分提升0.060分段（p=0.011，Cohen's d=0.504），但不同修改策略效果差异明显。高分段作文的评估仍存挑战。

Conclusion: 自动化反馈在雅思备考中具有潜力，但应作为人类指导的补充工具。保守的表面级修改比深度结构调整更可靠。未来需开展针对真实考生的纵向研究，并由官方考官进行验证。

Abstract: This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback.
  Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative $R^2$ values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive $R^2$. This enabled Cycle 5's adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen's d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.

</details>


### [110] [Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech](https://arxiv.org/abs/2512.24517)
*Fabian Retkowski,Alexander Waibel*

Main category: cs.CL

TL;DR: 本文提出了一种针对语音转录文本的段落分割方法，构建了TEDPara和YTSegPara两个新基准数据集，填补了语音领域段落分割研究的空白；提出一种约束解码方法，使大语言模型能在不改变原文的前提下准确插入段落分隔符；并设计轻量级模型MiniSeg，在保持高精度的同时实现章节与段落的联合预测，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 语音转录文本通常以无结构的词流形式呈现，影响可读性和再利用性。现有研究缺乏针对语音领域的段落分割基准和有效方法，亟需建立标准化、实用化的段落分割任务体系。

Method: 1. 构建两个新基准数据集：TEDPara（人工标注的TED演讲）和YTSegPara（带合成标签的YouTube视频），专注于语音领域；2. 提出约束解码机制，使大语言模型在保持原始文本完整性的同时插入段落分隔符；3. 设计轻量级模型MiniSeg，并支持层次化扩展，实现章节与段落的联合预测。

Result: 所提方法在段落分割任务上达到当前最优性能，且计算开销极低；新基准数据集为后续研究提供可靠评估标准；整体工作推动段落分割成为语音处理中的标准任务。

Conclusion: 本研究通过构建高质量基准、提出高效算法和轻量模型，成功将段落分割确立为语音处理中的标准化实践任务，具有良好的可扩展性和应用前景。

Abstract: Automatic speech transcripts are often delivered as unstructured word streams that impede readability and repurposing. We recast paragraph segmentation as the missing structuring step and fill three gaps at the intersection of speech processing and text segmentation. First, we establish TEDPara (human-annotated TED talks) and YTSegPara (YouTube videos with synthetic labels) as the first benchmarks for the paragraph segmentation task. The benchmarks focus on the underexplored speech domain, where paragraph segmentation has traditionally not been part of post-processing, while also contributing to the wider text segmentation field, which still lacks robust and naturalistic benchmarks. Second, we propose a constrained-decoding formulation that lets large language models insert paragraph breaks while preserving the original transcript, enabling faithful, sentence-aligned evaluation. Third, we show that a compact model (MiniSeg) attains state-of-the-art accuracy and, when extended hierarchically, jointly predicts chapters and paragraphs with minimal computational cost. Together, our resources and methods establish paragraph segmentation as a standardized, practical task in speech processing.

</details>


### [111] [Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs](https://arxiv.org/abs/2512.24556)
*Muhammad Abdullahi Said,Muhammad Sammani Sani*

Main category: cs.CL

TL;DR: This study audits top LLMs (GPT-5.1, Gemini 3 Pro, Claude 4.5 Opus) using HausaSafety, a dataset grounded in West African threats. Results show safety is not fixed but context-dependent, with complex interactions between language and time framing. Claude 4.5 Opus was safer in Hausa than English due to uncertainty-driven refusal, yet failed in temporal reasoning. Past-tense prompts bypassed safety (15.6% safe), while future-tense ones caused over-refusal (57.2% safe)—a 9.2x safety gap. Models use surface-level heuristics, creating unsafe 'pockets' for Global South users. The authors call for Invariant Alignment to ensure robust, cross-contextual safety.


<details>
  <summary>Details</summary>
Motivation: The study addresses the critical issue of whether safety alignment in large language models (LLMs) effectively transfers from English to other languages, particularly in low-resource settings like West Africa. The prevailing assumption that safety generalizes zero-shot across languages is challenged as a potentially dangerous blind spot.

Method: A systematic audit was conducted using HausaSafety, an adversarial dataset based on real-world West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). A 2 x 4 factorial design was employed across 1,440 evaluations to examine the non-linear interaction between language (English vs. Hausa) and temporal framing (past vs. future tense). Three state-of-the-art models—GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus—were evaluated under these conditions.

Result: The results reveal a Complex Interference mechanism where safety is not simply degraded in non-English languages but is dynamically shaped by the interaction of linguistic and temporal variables. Notably, Claude 4.5 Opus showed a Reverse Linguistic Effect—being safer in Hausa (45.0%) than in English (36.7%) due to uncertainty-driven refusal. However, it suffered catastrophic failures in temporal reasoning. A profound Temporal Asymmetry was observed: past-tense scenarios led to weak defenses (15.6% safe), while future-tense ones triggered hyper-conservative refusals (57.2% safe). The safety volatility reached a 9.2x disparity between optimal and worst configurations, indicating context-dependent safety rather than fixed properties.

Conclusion: Current LLMs rely on superficial heuristics rather than deep semantic understanding, resulting in Safety Pockets that leave users in the Global South vulnerable to localized harms. The authors advocate for Invariant Alignment—a paradigm shift toward ensuring stable safety across linguistic and temporal variations.

Abstract: As Large Language Models (LLMs) integrate into critical global infrastructure, the assumption that safety alignment transfers zero-shot from English to other languages remains a dangerous blind spot. This study presents a systematic audit of three state of the art models (GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus) using HausaSafety, a novel adversarial dataset grounded in West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). Employing a 2 x 4 factorial design across 1,440 evaluations, we tested the non-linear interaction between language (English vs. Hausa) and temporal framing. Our results challenge the prevailing multilingual safety gap narrative. Instead of a simple degradation in low-resource settings, we identified a mechanism of Complex Interference where safety is determined by the intersection of variables. While models exhibited a Reverse Linguistic with Claude 4.5 Opus proving significantly safer in Hausa (45.0%) than in English (36.7%) due to uncertainty-driven refusal they suffered catastrophic failures in temporal reasoning. We report a profound Temporal Asymmetry, where past-tense framing bypassed defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). The magnitude of this volatility is illustrated by a 9.2x disparity between the safest and most vulnerable configurations, proving that safety is not a fixed property but a context-dependent state. We conclude that current models rely on superficial heuristics rather than robust semantic understanding, creating Safety Pockets that leave Global South users exposed to localized harms. We propose Invariant Alignment as a necessary paradigm shift to ensure safety stability across linguistic and temporal shifts.

</details>


### [112] [HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering](https://arxiv.org/abs/2512.24562)
*Chaodong Tong,Qi Zhang,Jiayang Gao,Lei Jiang,Yanbing Liu,Nannan Sun*

Main category: cs.CL

TL;DR: HaluNet是一种轻量级、可训练的神经框架，通过整合多粒度的令牌级别不确定性（包括语义嵌入、概率置信度和分布不确定性），实现高效的单次遍历幻觉检测。它在SQuAD、TriviaQA和Natural Questions数据集上表现出色，无论是否有上下文信息，均展现出强大的检测性能和计算效率，适用于实时大语言模型问答系统中的幻觉检测。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法通常只关注单一类型的不确定性，忽略了不同不确定性来源之间的互补性，特别是令牌级别的概率不确定性与内部语义表示所传达的不确定性之间的互补关系。因此，需要一种能够融合多种不确定性信号的方法来提升检测效果。

Method: HaluNet采用多分支架构，将语义嵌入与概率置信度及分布不确定性相结合，通过自适应融合机制整合模型的知识与其输出中的不确定性，实现高效的一次性幻觉检测。

Result: 在SQuAD、TriviaQA和Natural Questions数据集上的实验表明，HaluNet在有无上下文的情况下均表现出优异的幻觉检测性能，并具有良好的计算效率，证明其在实时应用中的潜力。

Conclusion: HaluNet通过融合多粒度的不确定性信号，有效提升了幻觉检测的准确性和效率，为大语言模型问答系统提供了一种可扩展、无需外部资源的实时幻觉检测方案。

Abstract: Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods often aim to accurately capture a single type of uncertainty while overlooking the complementarity among different sources, particularly between token-level probability uncertainty and the uncertainty conveyed by internal semantic representations, which provide complementary views on model reliability. We present \textbf{HaluNet}, a lightweight and trainable neural framework that integrates multi granular token level uncertainties by combining semantic embeddings with probabilistic confidence and distributional uncertainty. Its multi branch architecture adaptively fuses what the model knows with the uncertainty expressed in its outputs, enabling efficient one pass hallucination detection. Experiments on SQuAD, TriviaQA, and Natural Questions show that HaluNet delivers strong detection performance and favorable computational efficiency, with or without access to context, highlighting its potential for real time hallucination detection in LLM based QA systems.

</details>


### [113] [Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities](https://arxiv.org/abs/2512.24572)
*Hongseok Oh,Wonseok Hwang,Kyoung-Woon On*

Main category: cs.CL

TL;DR: 本文介绍了韩国法律基准（KCL），一个用于评估语言模型法律推理能力的基准，独立于领域特定知识。KCL包含两个部分：KCL-MCQA（283个多项选择题，1,103个对齐判例）和KCL-Essay（169个开放生成问题，550个对齐判例和2,739个实例级评分标准）。对30多个模型的系统评估显示，尤其是在KCL-Essay中仍存在较大差距，且专门针对推理的模型始终优于通用模型。所有资源已公开发布于https://github.com/lbox-kr/kcl。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地评估语言模型在法律推理方面的能力，避免其表现受到领域知识的影响，需要一个独立于具体知识的基准测试工具。现有方法往往将推理能力与参数化知识混淆，因此亟需一种能够分离这两者的评估机制。

Method: 构建KCL基准，包含两个子任务：KCL-MCQA（多选题）和KCL-Essay（开放式生成题），并提供问题级别的判例支持及自动化评估所需的评分标准。通过系统性地评估30多个模型来验证基准的有效性。

Result: 评估结果显示，尽管当前模型在某些任务上表现尚可，但在KCL-Essay任务中仍存在显著性能差距；推理专用模型的表现明显优于通用模型，证明了该基准的有效性和挑战性。

Conclusion: KCL是一个有效的法律推理评估基准，能有效区分模型的推理能力与领域知识掌握程度。其公开发布有助于推动法律AI研究的发展，并为未来模型设计提供参考。

Abstract: We introduce the Korean Canonical Legal Benchmark (KCL), a benchmark designed to assess language models' legal reasoning capabilities independently of domain-specific knowledge. KCL provides question-level supporting precedents, enabling a more faithful disentanglement of reasoning ability from parameterized knowledge. KCL consists of two components: (1) KCL-MCQA, multiple-choice problems of 283 questions with 1,103 aligned precedents, and (2) KCL-Essay, open-ended generation problems of 169 questions with 550 aligned precedents and 2,739 instance-level rubrics for automated evaluation. Our systematic evaluation of 30+ models shows large remaining gaps, particularly in KCL-Essay, and that reasoning-specialized models consistently outperform their general-purpose counterparts. We release all resources, including the benchmark dataset and evaluation code, at https://github.com/lbox-kr/kcl.

</details>


### [114] [Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time](https://arxiv.org/abs/2512.24574)
*Zhenyu Zhang,Xiaoxia Wu,Zhongzhu Zhou,Qingyang Wu,Yineng Zhang,Pragaash Ponnusamy,Harikaran Subbaraj,Jue Wang,Shuaiwen Leon Song,Ben Athiwaratkun*

Main category: cs.CL

TL;DR: 本文提出了一种名为CREST的测试时认知推理引导方法，通过识别与特定认知行为（如验证和回溯）相关的注意力头，并在推理时轻量干预这些头，以抑制低效的推理模式。该方法包含离线校准和推理时调整两部分，无需训练即可提升准确率并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在解决复杂任务时依赖长链式思维（CoT），但这种推理路径常因过度生成导致高延迟，或出现思考不足与过度思考的不稳定性问题。为提升推理效率与可靠性，需理解并控制推理过程中的认知行为。

Method: CREST方法分为两个阶段：首先通过离线校准识别出与特定认知行为相关的注意力头，并生成对应的引导向量；其次在推理过程中旋转隐藏表示，抑制与这些向量相关的成分，从而引导模型避免无效推理。

Result: 在多个推理基准和模型上，CREST将准确率最高提升17.5%，同时减少37.6%的令牌使用量，显著提升了推理效率与准确性。

Conclusion: CREST是一种无需训练的测试时推理优化方法，能够有效抑制低效推理行为，实现更高精度与更低计算开销，为构建更快速、更可靠的大型语言模型推理系统提供了新路径。

Abstract: Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct cognitive behaviors such as verification and backtracking. By lightly intervening on these heads at inference time, we can steer the model away from inefficient modes. Building on this insight, we propose CREST, a training-free method for Cognitive REasoning Steering at Test-time. CREST has two components: (1) an offline calibration step that identifies cognitive heads and derives head-specific steering vectors, and (2) an inference-time procedure that rotates hidden representations to suppress components along those vectors. CREST adaptively suppresses unproductive reasoning behaviors, yielding both higher accuracy and lower computational cost. Across diverse reasoning benchmarks and models, CREST improves accuracy by up to 17.5% while reducing token usage by 37.6%, offering a simple and effective pathway to faster, more reliable LLM reasoning.

</details>


### [115] [R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory](https://arxiv.org/abs/2512.24684)
*Maoyuan Li,Zhongsheng Wang,Haoyuan Li,Jiamou Liu*

Main category: cs.CL

TL;DR: R-Debater 是一个基于论辩记忆的智能体框架，用于生成多轮辩论。它结合了检索增强的论据库和基于角色的智能体，以保持立场一致性、回应对手并用证据支持主张。在标准 ORCHID 辩论数据集上评估，R-Debater 在单轮和多轮任务中均优于强基线模型，并通过人类评估验证了其在论点连贯性、立场一致性和证据使用方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在多轮辩论中常出现立场漂移、逻辑断裂或缺乏证据支持的问题。为提升辩论的连贯性与真实性，需引入外部知识记忆与结构化规划机制。

Method: R-Debater 采用论辩知识库进行案例式证据与历史辩论动作的检索，结合角色驱动的生成智能体，在多轮对话中生成一致且有理据的发言。系统整合了检索增强与结构化对话规划，确保每一轮回应均基于已有论据并维持立场。

Result: 在 next-utterance generation 和 adversarial multi-turn simulation 两项任务中，R-Debater 在 InspireScore 与 Debatrix 指标上均优于多个强基线模型。人类评估显示其在立场一致性、证据使用和整体连贯性方面表现优异。

Conclusion: 将检索增强的知识记忆与结构化角色规划相结合，能够有效提升多轮辩论生成的质量，使系统更忠实于论点、更具逻辑性和可信赖性。

Abstract: We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.

</details>


### [116] [MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models](https://arxiv.org/abs/2512.24693)
*Wenzhe Li,Shujian Zhang,Wenxuan Zhou,John Lambert,Chi Jin,Andrew Hard,Rajiv Mathews,Lun Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为MUSIC的无监督数据增强策略，用于生成多轮对话中的对比样本，以提升多轮奖励模型（RM）的性能。通过在Skywork偏好数据集上使用MUSIC增强训练，所构建的基于Gemma-2-9B-Instruct的多轮RM在多轮对话评估中表现更优，且不损害单轮基准的表现。


<details>
  <summary>Details</summary>
Motivation: 现有标准偏好数据集仅基于最终对话轮次进行对比，难以捕捉多轮对话的复杂性；因此需要更有效的自动化评估方法来提升多轮奖励模型的质量。

Method: 提出MUSIC（多步指令对比）策略，通过合成跨越多个对话轮次的对比对话对，增强训练数据；利用该策略在Skywork数据集上训练基于Gemma-2-9B-Instruct的多轮奖励模型。

Result: MUSIC增强的奖励模型在多轮对话评估中与先进专有LLM评判者的一致性更高，同时保持了在单轮基准上的良好性能。

Conclusion: 多轮对话的高质量评估依赖于跨多轮的对比信号，MUSIC策略有效提升了多轮奖励模型的性能，为大规模、低成本的多轮对话评估提供了可行方案。

Abstract: Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \textit{training} techniques, effective automated \textit{evaluation} specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \textit{multiple} turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \textbf{MU}lti-\textbf{S}tep \textbf{I}nstruction \textbf{C}ontrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.

</details>


### [117] [BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature](https://arxiv.org/abs/2512.24733)
*Sibo Wei,Peng Chen,Lifeng Dong,Yin Luo,Lei Wang,Peng Zhang,Wenpeng Lu,Jianbin Guo,Hongjun Yang,Dajun Zeng*

Main category: cs.CL

TL;DR: 本文提出BIOME-Bench，一个用于评估大语言模型在多组学分析中生物分子相互作用推断和端到端多组学通路机制解析能力的基准测试。通过四阶段工作流程构建，并设计了相应的评估协议，实验表明现有模型在区分精细分子关系类型和生成可靠通路机制解释方面仍存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前多组学研究依赖通路富集分析（PE），但受限于通路资源的更新滞后、功能冗余及对分子状态和干预措施的敏感性不足。尽管已有研究尝试使用大语言模型（LLMs）改进PE，但由于缺乏标准化的端到端评估基准，评估多局限于小规模手动标注数据集或特定案例，阻碍了可重复进展。

Method: 提出BIOME-Bench，采用严格的四阶段工作流程构建基准测试，涵盖生物分子相互作用推断与多组学通路机制解析两个核心任务，设计专门评估协议，并在多个先进模型上进行系统实验。

Result: 实验结果表明，现有大语言模型在多组学分析中仍存在明显缺陷，难以可靠区分细粒度的生物分子关系类型，且生成的通路级机制解释不够忠实与稳健。

Conclusion: BIOME-Bench为多组学分析中大语言模型的能力评估提供了标准化基准，揭示了当前模型在机制推断方面的局限性，为未来研究指明方向。

Abstract: Multi-omics studies often rely on pathway enrichment to interpret heterogeneous molecular changes, but pathway enrichment (PE)-based workflows inherit structural limitations of pathway resources, including curation lag, functional redundancy, and limited sensitivity to molecular states and interventions. Although recent work has explored using large language models (LLMs) to improve PE-based interpretation, the lack of a standardized benchmark for end-to-end multi-omics pathway mechanism elucidation has largely confined evaluation to small, manually curated datasets or ad hoc case studies, hindering reproducible progress. To address this issue, we introduce BIOME-Bench, constructed via a rigorous four-stage workflow, to evaluate two core capabilities of LLMs in multi-omics analysis: Biomolecular Interaction Inference and end-to-end Multi-Omics Pathway Mechanism Elucidation. We develop evaluation protocols for both tasks and conduct comprehensive experiments across multiple strong contemporary models. Experimental results demonstrate that existing models still exhibit substantial deficiencies in multi-omics analysis, struggling to reliably distinguish fine-grained biomolecular relation types and to generate faithful, robust pathway-level mechanistic explanations.

</details>


### [118] [Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models](https://arxiv.org/abs/2512.24776)
*Ákos Prucs,Márton Csutora,Mátyás Antal,Márk Marosi*

Main category: cs.CL

TL;DR: 本文研究了大语言模型在复杂推理任务中的表现，重点关注推理过程中的计算开销。通过在数学和推理密集型基准上评估当代和较旧的开源LLM，作者绘制了它们在性能与效率之间的帕累托前沿，发现混合专家（MoE）架构在平衡性能与效率方面表现优异。研究还揭示了随时间推移的帕累托效率趋势，并指出推理计算存在饱和点：超过一定阈值后，准确率提升不再显著，表明长推理序列无法突破模型内在限制。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽在复杂推理任务中表现提升，但其生成长推理序列带来的高计算成本被忽视。工业应用中，模型选择需兼顾准确性、资源约束和推理成本，因此亟需一种能权衡性能与效率的评估框架。

Method: 对多种当代和旧版开源大语言模型进行测试时计算感知的评估，基于数学与推理密集型基准构建帕累托前沿图；分析不同架构（如MoE）的表现，并追踪随时间演变的效率趋势，识别计算投入与准确率增长的关系。

Result: MoE架构在性能与效率之间表现出最佳平衡；推理计算存在饱和点，超过一定阈值后准确率提升趋于平缓，说明长推理序列无法弥补模型固有的复杂性限制。

Conclusion: 在实际部署中，应优先考虑兼具高效推理与良好性能的模型架构，如MoE；同时需警惕过度依赖延长推理路径的策略，因为其边际收益有限且可能造成资源浪费。

Abstract: Large Language Models (LLMs) are demonstrating rapid improvements on complex reasoning benchmarks, particularly when allowed to utilize intermediate reasoning steps before converging on a final solution. However, current literature often overlooks the significant computational burden associated with generating long reasoning sequences. For industrial applications, model selection depends not only on raw accuracy but also on resource constraints and inference costs. In this work, we conduct a test-time-compute aware evaluation of both contemporary and older open-source LLMs, mapping their Pareto frontiers across math- and reasoning-intensive benchmarks. Our findings identify the Mixture of Experts (MoE) architecture as a strong candidate to balance performance and efficiency in our evaluation setting. Furthermore, we trace the trajectory of Pareto efficiency over time to derive an emergent trend regarding accuracy gain per unit of compute. Finally, we demonstrate that there is a saturation point for inference-time compute. Beyond a certain threshold, accuracy gains diminish, indicating that while extended reasoning capabilities are beneficial, they cannot overcome intrinsic model limitations regarding specific complexities.

</details>


### [119] [Practising responsibility: Ethics in NLP as a hands-on course](https://arxiv.org/abs/2512.24825)
*Malvina Nissim,Viviana Patti,Beatrice Savoldi*

Main category: cs.CL

TL;DR: 本文介绍了在自然语言处理（NLP）教育中融入伦理议题的课程设计与教学方法，强调通过互动式学习、实践操作和‘以教促学’的方式培养学生的批判性思维。课程历经四年在不同机构、教育层次和跨学科背景中不断优化，产出大量可复用的教学资源与学生主导的教育产品，旨在为教育者提供将社会影响纳入课程的参考范例。


<details>
  <summary>Details</summary>
Motivation: 随着NLP系统日益普及，将伦理考量融入NLP教育成为必要，但面临领域快速迭代与培养学生批判性思维的双重挑战。

Method: 采用主动学习策略，包括互动研讨、动手实践和‘学习即教学’的教学方法，并在多所机构和不同教育层次中持续迭代优化。

Result: 课程成功开发出大量可复用的教学材料与学生创作的教育产品，覆盖多元受众，具备良好的推广价值。

Conclusion: 通过分享课程设计与实践经验，本文为推动将社会影响因素融入NLP及其他技术类课程提供了可行路径与启发。

Abstract: As Natural Language Processing (NLP) systems become more pervasive, integrating ethical considerations into NLP education has become essential. However, this presents inherent challenges in curriculum development: the field's rapid evolution from both academia and industry, and the need to foster critical thinking beyond traditional technical training. We introduce our course on Ethical Aspects in NLP and our pedagogical approach, grounded in active learning through interactive sessions, hands-on activities, and "learning by teaching" methods. Over four years, the course has been refined and adapted across different institutions, educational levels, and interdisciplinary backgrounds; it has also yielded many reusable products, both in the form of teaching materials and in the form of actual educational products aimed at diverse audiences, made by the students themselves. By sharing our approach and experience, we hope to provide inspiration for educators seeking to incorporate social impact considerations into their curricula.

</details>


### [120] [Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability](https://arxiv.org/abs/2512.24842)
*Yanan Long*

Main category: cs.CL

TL;DR: 该论文提出了一种名为'三角化'的验证标准，用于评估多语言语言模型中机制性解释的因果有效性。该方法要求机制在跨语言、跨脚本和跨文化环境中的干预下保持稳定，并通过必要性、充分性和不变性三个条件来筛选候选子图。研究结合了自动电路发现与因果抽象理论，为可解释性提供了一个可证伪且具有跨环境一致性的框架。


<details>
  <summary>Details</summary>
Motivation: 多语言语言模型虽然整体表现良好，但在不同语言、脚本和文化背景下行为不可预测。现有解释方法缺乏对因果稳定性的检验，容易产生仅在单一环境中成立但不具泛化能力的虚假机制。因此需要一种能跨环境验证机制有效性的新标准。

Method: 提出‘参考族’（reference families）概念，即语义保持不变但表面形式不同的变体；引入‘三角化’作为接受机制的规则，包含三重检验：必要性（移除电路导致目标行为下降）、充分性（注入激活可转移行为）、不变性（在所有参考族中效应方向和强度稳定）。结合自动电路发现技术识别候选子图，并用三角化进行筛选。

Result: 实验表明，三角化能够有效过滤掉那些仅在单个环境测试中通过但无法跨语言保持一致的虚假电路。该方法在多个模型家族、语言对和任务上表现出良好的区分能力，提供了可验证、可重复的机制解释框架。

Conclusion: 三角化为多语言模型的机制解释提供了一个基于因果推理和跨环境不变性的可检验标准，有助于提升模型可解释性与可信度，推动面向实际应用的可解释人工智能发展。

Abstract: Multilingual language models achieve strong aggregate performance yet often behave unpredictably across languages, scripts, and cultures. We argue that mechanistic explanations for such models should satisfy a \emph{causal} standard: claims must survive causal interventions and must \emph{cross-reference} across environments that perturb surface form while preserving meaning. We formalize \emph{reference families} as predicate-preserving variants and introduce \emph{triangulation}, an acceptance rule requiring necessity (ablating the circuit degrades the target behavior), sufficiency (patching activations transfers the behavior), and invariance (both effects remain directionally stable and of sufficient magnitude across the reference family). To supply candidate subgraphs, we adopt automatic circuit discovery and \emph{accept or reject} those candidates by triangulation. We ground triangulation in causal abstraction by casting it as an approximate transformation score over a distribution of interchange interventions, connect it to the pragmatic interpretability agenda, and present a comparative experimental protocol across multiple model families, language pairs, and tasks. Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance.

</details>


### [121] [Big AI is accelerating the metacrisis: What can we do?](https://arxiv.org/abs/2512.24863)
*Steven Bird*

Main category: cs.CL

TL;DR: 大AI加剧了多重危机，语言工程需反思其价值中立假设，转向以人类福祉和地球生存为中心的可持续发展路径。


<details>
  <summary>Details</summary>
Motivation: 应对生态、意义和语言危机的汇聚，即所谓的元危机；大型人工智能正在加速这些危机。

Method: 探讨替代方案，利用集体智慧设计以人类繁荣为核心的自然友好型NLP未来。

Result: 呼吁重新思考当前大模型语言工程的路径，强调价值导向与可持续性的重要性。

Conclusion: 必须转向以人为本、尊重地球生态的NLP发展范式，以实现人类与自然的共同繁荣。

Abstract: The world is in the grip of ecological, meaning, and language crises which are converging into a metacrisis. Big AI is accelerating them all. Language engineers are playing a central role, persisting with a scalability story that is failing humanity, supplying critical talent to plutocrats and kleptocrats, and creating new technologies as if the whole endeavour was value-free. We urgently need to explore alternatives, applying our collective intelligence to design a life-affirming future for NLP that is centered on human flourishing on a living planet.

</details>


### [122] [Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements](https://arxiv.org/abs/2512.24867)
*Yiming Liang,Yizhi Li,Yantao Du,Ge Zhang,Jiayi Zhou,Yuchen Wu,Yinzhu Piao,Denghui Cao,Tong Sun,Ziniu Li,Li Du,Bo Lei,Jiaheng Liu,Chenghua Lin,Zhaoxiang Zhang,Wenhao Huang,Jiajun Zhang*

Main category: cs.CL

TL;DR: Encyclo-K 是一个基于知识陈述的新型基准测试框架，旨在解决现有基准在数据污染、单一知识点评估和高成本专家标注方面的局限。其核心思想是将知识陈述作为构建单元，而非传统的问题，通过从权威教材中提取独立的知识陈述，并在测试时动态组合成问题。该方法有效避免了模型记忆训练数据的可能性，支持周期性数据更新；每个问题整合8-10个陈述，实现多知识点综合评估；且标注仅需格式合规检查，显著降低人力成本。实验表明，即使最先进的 GPT-5.1 也仅达到 62.07% 的准确率，不同模型性能呈现明显梯度分布，验证了动态评估与综合理解挑战的有效性，确立了 Encyclo-K 在大规模、可扩展、动态评估大模型综合理解能力方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要以问题为单位构建，存在易受数据污染、只能评估单一知识点、依赖昂贵专家标注等根本性缺陷，亟需一种更可靠、高效、全面的评估方式。

Method: 提出 Encyclo-K 基准框架，采用知识陈述作为基本单元，从权威教材中提取独立陈述，在测试时通过随机采样动态组合成评估问题，实现动态化、多知识点融合的评估机制。

Result: 在超过 50 个 LLM 上的实验显示，Encyclo-K 具有极强挑战性，顶级模型 GPT-5.1 准确率仅为 62.07%，推理类模型表现范围为 16.04%–62.07%，聊天类模型为 9.71%–50.40%，性能分布清晰，证明其具备良好区分度和动态评估能力。

Conclusion: Encyclo-K 通过重新定义评估单位，实现了对大语言模型综合理解能力的高效、可扩展、动态评估，为未来模型评测提供了可靠的新范式。

Abstract: Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contamination, restriction to single-knowledge-point assessment, and reliance on costly domain expert annotation. We propose Encyclo-K, a statement-based benchmark that rethinks benchmark construction from the ground up. Our key insight is that knowledge statements, not questions, can serve as the unit of curation, and questions can then be constructed from them. We extract standalone knowledge statements from authoritative textbooks and dynamically compose them into evaluation questions through random sampling at test time. This design directly addresses all three limitations: the combinatorial space is too vast to memorize, and model rankings remain stable across dynamically generated question sets, enabling reliable periodic dataset refresh; each question aggregates 8-10 statements for comprehensive multi-knowledge assessment; annotators only verify formatting compliance without requiring domain expertise, substantially reducing annotation costs. Experiments on over 50 LLMs demonstrate that Encyclo-K poses substantial challenges with strong discriminative power. Even the top-performing OpenAI-GPT-5.1 achieves only 62.07% accuracy, and model performance displays a clear gradient distribution--reasoning models span from 16.04% to 62.07%, while chat models range from 9.71% to 50.40%. These results validate the challenges introduced by dynamic evaluation and multi-statement comprehensive understanding. These findings establish Encyclo-K as a scalable framework for dynamic evaluation of LLMs' comprehensive understanding over multiple fine-grained disciplinary knowledge statements.

</details>


### [123] [mHC: Manifold-Constrained Hyper-Connections](https://arxiv.org/abs/2512.24880)
*Zhenda Xie,Yixuan Wei,Huanqi Cao,Chenggang Zhao,Chengqi Deng,Jiashi Li,Damai Dai,Huazuo Gao,Jiang Chang,Liang Zhao,Shangyan Zhou,Zhean Xu,Zhengyan Zhang,Wangding Zeng,Shengding Hu,Yuqing Wang,Jingyang Yuan,Lean Wang,Wenfeng Liang*

Main category: cs.CL

TL;DR: 提出mHC框架，通过将HC的残差连接空间投影到特定流形上，恢复身份映射特性，同时进行基础设施优化以提升效率，实验证明其在大规模训练中表现优异，具有显著性能提升和更好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决现有HC方法因连接模式多样化导致的身份映射性质破坏、训练不稳定和内存访问开销大的问题。

Method: 将残差连接空间投影至特定流形，以恢复身份映射属性，并结合严格的基础设施优化策略，实现高效计算。

Result: 实验表明mHC在大规模训练中有效，带来明显性能提升和更优的可扩展性。

Conclusion: mHC作为HC的灵活且实用的扩展，有助于深化对拓扑结构设计的理解，并为基础模型的演进提供新方向。

Abstract: Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.

</details>


### [124] [BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts](https://arxiv.org/abs/2512.24885)
*Hengli Li,Zhaoxin Yu,Qi Shen,Chenxi Li,Mengmeng Wang,Tinglang Wu,Yipeng Kang,Yuxuan Wang,Song-Chun Zhu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 本文提出BEDA框架，通过将信念估计转化为生成过程中的概率约束，实现对抗性与对齐性对话行为的可控生成。在三个对话场景中，该方法显著优于现有基线，尤其在使用GPT-4.1-nano时，在CKBG任务上成功率达20.6点提升，验证了基于信念约束的策略对话机制的有效性与通用性。


<details>
  <summary>Details</summary>
Motivation: 现有信念估计方法虽准确，但缺乏将信念有效用于对话生成的系统性机制，导致战略对话中行为控制不足。

Method: 提出对抗性与对齐性两种核心对话行为的形式化定义，并通过概率约束指导生成；构建包含世界集、信念估计器和条件生成器的BEDA框架，实现基于信念推理的对话生成。

Result: 在三种对话设置（CKBG、MF、CaSiNo）中，BEDA均显著优于强基线模型，尤其在CKBG任务中成功率提升达20.6点（使用GPT-4.1-nano），在MF任务中平均提升9.3点，在CaSiNo任务中达成最优谈判结果。

Conclusion: 将信念估计建模为生成约束，提供了一种简洁而通用的机制，可有效支持可靠的战略对话生成。

Abstract: Strategic dialogue requires agents to execute distinct dialogue acts, for which belief estimation is essential. While prior work often estimates beliefs accurately, it lacks a principled mechanism to use those beliefs during generation. We bridge this gap by first formalizing two core acts Adversarial and Alignment, and by operationalizing them via probabilistic constraints on what an agent may generate. We instantiate this idea in BEDA, a framework that consists of the world set, the belief estimator for belief estimation, and the conditional generator that selects acts and realizes utterances consistent with the inferred beliefs. Across three settings, Conditional Keeper Burglar (CKBG, adversarial), Mutual Friends (MF, cooperative), and CaSiNo (negotiation), BEDA consistently outperforms strong baselines: on CKBG it improves success rate by at least 5.0 points across backbones and by 20.6 points with GPT-4.1-nano; on Mutual Friends it achieves an average improvement of 9.3 points; and on CaSiNo it achieves the optimal deal relative to all baselines. These results indicate that casting belief estimation as constraints provides a simple, general mechanism for reliable strategic dialogue.

</details>


### [125] [Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline](https://arxiv.org/abs/2512.24933)
*Minjun Zhao,Xinyu Zhang,Shuai Zhang,Deyang Li,Ruifeng Shi*

Main category: cs.CL

TL;DR: ADOPT 是一种用于多步大语言模型流水线的自适应依赖感知提示优化框架，通过显式建模各步骤与最终任务结果之间的依赖关系，实现精确的文本梯度估计，并将多提示优化解耦为灵活的单提示优化步骤，结合基于Shapley值的资源分配机制，在多种真实数据集和流水线结构上均显著优于现有最优基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端提示优化方法在缺乏步骤级监督和存在步骤间依赖的情况下表现不佳，难以有效优化多步大语言模型流水线中的多个提示，导致性能不稳定或次优。

Method: ADOPT 通过显式建模每一步LLM与最终任务结果之间的依赖关系，实现类似解析导数的文本梯度估计；采用梯度估计与更新解耦策略，将多提示优化转化为可灵活处理的单提示优化步骤，并引入基于Shapley值的机制自适应分配优化资源。

Result: 在真实数据集和多种流水线结构上的实验表明，ADOPT 具有良好的有效性与鲁棒性，持续优于当前最先进的提示优化基准方法。

Conclusion: ADOPT 为多步大语言模型流水线提供了一种高效、稳定且可扩展的提示优化方案，解决了现有方法在缺乏监督和存在依赖时的优化难题。

Abstract: Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter-step dependencies. Existing end-to-end prompt optimization methods struggle under these conditions and often yield suboptimal or unstable updates. We propose ADOPT, an Adaptive Dependency-aware Prompt Optimization framework for multi-step LLM pipelines. ADOPT explicitly models the dependency between each LLM step and the final task outcome, enabling precise text-gradient estimation analogous to computing analytical derivatives. It decouples textual gradient estimation from gradient updates, reducing multi-prompt optimization to flexible single-prompt optimization steps, and employs a Shapley-based mechanism to adaptively allocate optimization resources. Experiments on real-world datasets and diverse pipeline structures show that ADOPT is effective and robust, consistently outperforming state-of-the-art prompt optimization baselines.

</details>


### [126] [Classifying long legal documents using short random chunks](https://arxiv.org/abs/2512.24997)
*Luis Adrián Cabrera-Diego*

Main category: cs.CL

TL;DR: 本文提出了一种基于DeBERTa V3和LSTM的法律文档分类器，通过随机选取48个短文本块（每块最多128个标记）作为输入，以解决长法律文档在Transformer模型中处理困难的问题。同时，提出了使用Temporal部署管道，实现可靠且稳健的处理流程。最佳模型的加权F-score达到0.898，CPU上每100个文件的平均处理时间为498秒。


<details>
  <summary>Details</summary>
Motivation: 法律文档通常包含专业术语且篇幅较长，直接将完整文档输入基于Transformer的模型会导致计算资源消耗过大、效率低下或不可行。因此需要一种高效、可扩展的分类方法。

Method: 采用DeBERTa V3与LSTM结合的模型架构，输入为从法律文档中随机抽取的48个短文本块（每块最大128个标记），利用这些片段进行分类；并构建基于Temporal的部署管道，确保处理流程的可靠性与稳定性。

Result: 所提模型在测试集上取得了0.898的加权F-score，表明其具有较高的分类性能；部署管道在CPU环境下处理100个文件的中位时间仅为498秒，具备良好的实用性与效率。

Conclusion: 该方法有效应对了长法律文档分类中的计算挑战，结合模型设计与可靠的部署方案，实现了高性能与高可用性，适用于实际法律文本处理场景。

Abstract: Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens). Besides, we present its deployment pipeline using Temporal, a durable execution solution, which allow us to have a reliable and robust processing workflow. The best model had a weighted F-score of 0.898, while the pipeline running on CPU had a processing median time of 498 seconds per 100 files.

</details>


### [127] [MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes](https://arxiv.org/abs/2512.25015)
*Siddhant Agarwal,Adya Dhuler,Polly Ruhnke,Melvin Speisman,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: 本文提出RESTOREx作为检测社交媒体中表情包抑郁症状的资源，结合大语言模型生成和人工标注的解释；并引入MAMAMemeia框架，基于认知分析疗法（CAT）能力，实现多智能体多方面协作讨论，相比现有30多种方法在macro-F1上提升7.55%，成为新基准。


<details>
  <summary>Details</summary>
Motivation: 随着表情包从幽默交流演变为表达多种情绪的工具，尤其在表达抑郁情绪方面日益普遍，亟需有效识别社交媒体中反映抑郁症状的表情包，以支持心理健康干预。

Method: 提出RESTOREx数据集，融合LLM生成与人工标注的解释；设计MAMAMemeia框架，基于临床心理学中的认知分析疗法（CAT）能力，采用多智能体多视角协同分析机制进行表情包情感内容解析。

Result: MAMAMemeia在宏平均F1得分上较当前最优方法提升7.55%，显著优于超过30种已有方法，确立为该任务的新基准。

Conclusion: 本研究通过结合大语言模型与人类专业知识构建的RESTOREx资源及创新的MAMAMemeia框架，有效提升了对社交媒体中抑郁相关表情包的识别能力，为数字心理健康监测提供了有力工具。

Abstract: Over the past years, memes have evolved from being exclusively a medium of humorous exchanges to one that allows users to express a range of emotions freely and easily. With the ever-growing utilization of memes in expressing depressive sentiments, we conduct a study on identifying depressive symptoms exhibited by memes shared by users of online social media platforms. We introduce RESTOREx as a vital resource for detecting depressive symptoms in memes on social media through the Large Language Model (LLM) generated and human-annotated explanations. We introduce MAMAMemeia, a collaborative multi-agent multi-aspect discussion framework grounded in the clinical psychology method of Cognitive Analytic Therapy (CAT) Competencies. MAMAMemeia improves upon the current state-of-the-art by 7.55% in macro-F1 and is established as the new benchmark compared to over 30 methods.

</details>


### [128] [Modeling Language as a Sequence of Thoughts](https://arxiv.org/abs/2512.25026)
*Nasim Borazjanizadeh,James McClelland*

Main category: cs.CL

TL;DR: 提出Thought Gestalt（TG）模型，一种递归Transformer，通过在词元和句子级“思想”状态两个抽象层次上建模语言，提升生成文本的全局一致性与上下文理解能力。通过跨注意力机制访问先前句子的内存表示，实现对语义连贯性的增强。利用统一目标函数（下一个词交叉熵）联合训练，使梯度可反向传播至早期句子向量生成，优化整体表示。实验表明，TG在数据效率和参数效率方面优于匹配的GPT-2，且在关系方向泛化任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer依赖表面共现统计，缺乏对实体与事件的全局一致隐式表示，导致关系方向错误、上下文错误及数据效率低。受认知科学启发，人类理解语言时会将输入转化为持久的事件类表征，而非仅记忆字面形式。因此需要一种能保持长期语义一致性的模型架构。

Method: 引入Thought Gestalt（TG）模型，采用递归Transformer结构，在每个句子生成时同时生成词元和句子级‘思想’状态；通过跨注意力机制访问前序句子的内存表示；使用相同参数集生成词元与句子表示，并以单一目标（下一个词交叉熵）进行端到端训练；通过保留句子表示的计算图，使未来词预测损失的梯度可反向传播至早期句子向量生成部分，从而联合优化。

Result: TG在多个基准测试中表现出更高的数据效率和参数效率：相比GPT-2，需约5-8%更少的数据和33-42%更少的参数即可达到相同损失水平；在父亲-儿子反转诅咒等关系方向泛化任务中显著降低错误率，体现更强的语义一致性与推理能力。

Conclusion: Thought Gestalt模型通过引入基于记忆的双层抽象机制，有效增强了语言模型的全局语义一致性与上下文理解能力，克服了传统Transformer在关系推理和数据效率方面的局限，为构建更具认知合理性的人工语言理解系统提供了新路径。

Abstract: Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim form is short-lived. Motivated by this view, we introduce Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels of abstraction - tokens and sentence-level "thought" states. TG generates the tokens of one sentence at a time while cross-attending to a memory of prior sentence representations. In TG, token and sentence representations are generated using the same set of model parameters and trained with a single objective, the next-token cross-entropy: by retaining the computation graph of sentence representations written to memory, gradients from future token losses flow backward through cross-attention to optimize the parameters generating earlier sentence vectors. In scaling experiments, TG consistently improves efficiency over matched GPT-2 runs, among other baselines, with scaling fits indicating GPT-2 requires ~5-8% more data and ~33-42% more parameters to match TG's loss. TG also reduces errors on relational direction generalization on a father-son reversal curse probe.

</details>


### [129] [AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG](https://arxiv.org/abs/2512.25052)
*Chao Peng,Bin Wang,Zhilei Long,Jinfang Sheng*

Main category: cs.CL

TL;DR: AdaGReS 是一种针对令牌预算受限的 RAG 的冗余感知上下文选择框架，通过结合查询-片段相关性与组内冗余惩罚的集合级目标进行优化。它在令牌预算约束下使用边际收益进行贪心选择，并引入闭式、实例自适应的权衡参数校准，避免手动调参并适应候选池统计和预算限制。理论分析表明，在实际嵌入相似性条件下，该目标具有 epsilon-近似子模性，为贪心选择提供近最优保证。实验在开放域问答（Natural Questions）和高冗余生物医学（药物）语料库上均显示其在冗余控制和上下文质量上的持续提升，进而带来更好的端到端答案质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准的 top-k 检索常返回冗余或近似重复的文本块，浪费令牌预算并降低下游生成质量。因此需要一种能够有效控制冗余、提升上下文质量的上下文选择方法。

Method: 提出 AdaGReS 框架，采用集合级目标函数，融合查询-片段相关性和组内冗余惩罚；在令牌预算约束下进行贪心选择，利用边际收益优化；引入闭式、实例自适应的参数校准机制，自动调节相关性与冗余之间的权衡。

Result: 在 Natural Questions 和高冗余生物医学语料库上的实验表明，AdaGReS 显著提升了冗余控制能力与上下文质量，从而改善了最终答案的准确性和系统鲁棒性。

Conclusion: AdaGReS 通过冗余感知的上下文选择机制，在保持高质量信息的同时有效减少冗余，实现了对令牌预算的高效利用，并在多种场景下展现出优越的端到端性能。

Abstract: Retrieval-augmented generation (RAG) is highly sensitive to the quality of selected context, yet standard top-k retrieval often returns redundant or near-duplicate chunks that waste token budget and degrade downstream generation. We present AdaGReS, a redundancy-aware context selection framework for token-budgeted RAG that optimizes a set-level objective combining query-chunk relevance and intra-set redundancy penalties. AdaGReS performs greedy selection under a token-budget constraint using marginal gains derived from the objective, and introduces a closed-form, instance-adaptive calibration of the relevance-redundancy trade-off parameter to eliminate manual tuning and adapt to candidate-pool statistics and budget limits. We further provide a theoretical analysis showing that the proposed objective exhibits epsilon-approximate submodularity under practical embedding similarity conditions, yielding near-optimality guarantees for greedy selection. Experiments on open-domain question answering (Natural Questions) and a high-redundancy biomedical (drug) corpus demonstrate consistent improvements in redundancy control and context quality, translating to better end-to-end answer quality and robustness across settings.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [130] [A Comprehensive Study of Deep Learning Model Fixing Approaches](https://arxiv.org/abs/2512.23745)
*Hanmo You,Zan Wang,Zishuo Dong,Luanqi Mo,Jianjun Zhao,Junjie Chen*

Main category: cs.LG

TL;DR: 本文对16种先进的深度学习模型修复方法进行了大规模实证研究，涵盖模型级、层级和神经元级三类方法，评估其修复效果及对鲁棒性、公平性和后向兼容性等关键属性的影响。结果表明，模型级方法在修复效果上表现更优，但没有一种方法能在提升准确率的同时保持所有其他属性不变，提示学术界应关注修复带来的副作用问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统在工业应用中广泛存在故障风险，亟需有效的修复方法，但现有方法可能带来副作用，因此需要全面评估其综合性能。

Method: 采用统一实验设置，在多样化数据集、模型架构和应用领域下，对16种先进深度学习模型修复方法进行大规模实证研究，评估其修复效果及对多个关键属性的影响。

Result: 模型级修复方法在修复效果上优于其他方法；但无一方法能同时实现最佳修复性能与提升准确率并维持所有其他属性不变，揭示了修复过程中的权衡问题。

Conclusion: 未来研究应重点关注修复方法带来的副作用，探索更平衡的修复策略，以推动深度学习系统的可靠性和安全性发展。

Abstract: Deep Learning (DL) has been widely adopted in diverse industrial domains, including autonomous driving, intelligent healthcare, and aided programming. Like traditional software, DL systems are also prone to faults, whose malfunctioning may expose users to significant risks. Consequently, numerous approaches have been proposed to address these issues. In this paper, we conduct a large-scale empirical study on 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, to comprehensively evaluate their performance. We assess not only their fixing effectiveness (their primary purpose) but also their impact on other critical properties, such as robustness, fairness, and backward compatibility. To ensure comprehensive and fair evaluation, we employ a diverse set of datasets, model architectures, and application domains within a uniform experimental setup for experimentation. We summarize several key findings with implications for both industry and academia. For example, model-level approaches demonstrate superior fixing effectiveness compared to others. No single approach can achieve the best fixing performance while improving accuracy and maintaining all other properties. Thus, academia should prioritize research on mitigating these side effects. These insights highlight promising directions for future exploration in this field.

</details>


### [131] [A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios](https://arxiv.org/abs/2512.23748)
*Haley Rosso,Talea Mayo*

Main category: cs.LG

TL;DR: 本文系统回顾了基于扩散模型的仿真推断（SBI）方法，从基础数学原理到实际应用。重点阐述了前向加噪、反向时间随机微分方程/常微分方程、概率流和去噪得分匹配等核心概念，并说明条件得分如何实现无似然后验采样。对比了扩散模型与归一化流在神经后验/似然估计中的优劣，指出其在处理非理想科学数据（如模型误设、非结构化或无限维观测、缺失数据）时的鲁棒性优势。整合了来自薛定谔桥理论、条件与序列后验采样器、用于非结构化数据的可迁移架构以及推理时先验适应等方法。强调一致符号表示与准确后验所需的前提条件。最后讨论了开放问题，展望其在概率地球物理建模中不确定性量化方面的应用前景。


<details>
  <summary>Details</summary>
Motivation: 传统基于似然的参数推断方法在复杂仿真问题中因似然函数难以计算而受限。为应对这一挑战，需发展无需显式似然的仿真推断方法。扩散模型因其生成灵活性和对非理想数据的良好鲁棒性，成为解决此类问题的有力工具。

Method: 基于扩散模型的仿真推断方法，涵盖前向加噪过程、反向时间随机微分方程/常微分方程求解、概率流追踪与得分匹配训练；结合条件得分学习实现无似然后验采样；引入薛定谔桥理论、序列采样策略、可迁移架构及推理阶段先验调整机制以增强实用性与鲁棒性。

Result: 扩散模型在处理模型误设、非结构化观测、缺失数据等非理想条件下展现出优于传统归一化流的稳定性与泛化能力；支持高维、复杂数据的后验推断，具备较强的不确定性量化潜力，适用于如地球物理模拟等真实科学场景。

Conclusion: 扩散模型为仿真推断提供了一种强大且灵活的框架，在面对现实世界数据的复杂性与不完美性时表现出显著优势。未来研究应聚焦于降低迭代采样成本、提升可扩展性与可解释性，推动其在科学建模与不确定性分析中的广泛应用。

Abstract: For complex simulation problems, inferring parameters of scientific interest often precludes the use of classical likelihood-based techniques due to intractable likelihood functions. Simulation-based inference (SBI) methods forego the need for explicit likelihoods by directly utilizing samples from the simulator to learn posterior distributions over parameters $\mathbfθ$ given observed data $\mathbf{x}_{\text{o}}$. Recent work has brought attention to diffusion models -- a type of generative model rooted in score matching and reverse-time stochastic dynamics -- as a flexible framework SBI tasks. This article reviews diffusion-based SBI from first principles to applications in practice. We first recall the mathematical foundations of diffusion modeling (forward noising, reverse-time SDE/ODE, probability flow, and denoising score matching) and explain how conditional scores enable likelihood-free posterior sampling. We then examine where diffusion models address pain points of normalizing flows in neural posterior/likelihood estimation and where they introduce new trade-offs (e.g., iterative sampling costs). The key theme of this review is robustness of diffusion-based SBI in non-ideal conditions common to scientific data: misspecification (mismatch between simulated training data and reality), unstructured or infinite-dimensional observations, and missingness. We synthesize methods spanning foundations drawing from Schrodinger-bridge formulations, conditional and sequential posterior samplers, amortized architectures for unstructured data, and inference-time prior adaptation. Throughout, we adopt consistent notation and emphasize conditions and caveats required for accurate posteriors. The review closes with a discussion of open problems with an eye toward applications of uncertainty quantification for probabilistic geophysical models that may benefit from diffusion-based SBI.

</details>


### [132] [Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents](https://arxiv.org/abs/2512.23749)
*Amin Sadri,M Maruf Hossain*

Main category: cs.LG

TL;DR: 本文提出了一种名为坐标矩阵机（CM²）的小型模型，旨在实现人类水平的概念学习，仅需单个样本即可完成文档分类。该模型通过捕捉文档的结构化重要特征，而非依赖大规模语义向量，实现了高效、低耗、可解释的分类。相比传统深度学习模型，CM²在极少数据下表现更优，具备绿色人工智能、低延迟、高鲁棒性及经济可行性等优势。


<details>
  <summary>Details</summary>
Motivation: 人类能从单个例子中学习新概念，而传统机器学习需要大量样本。现有方法多依赖大规模预训练和高能耗硬件，导致资源浪费与环境负担。本文旨在设计一种高效、节能且可解释的模型，模拟人类对关键特征的感知能力，实现真正的少样本甚至单样本学习。

Method: CM²通过提取文档的结构坐标（如段落位置、标题层级、空白分布等），构建坐标矩阵来表示文档的几何与结构性特征。利用这些稀疏但关键的结构信息进行分类，避免了对密集语义向量的依赖。模型采用轻量级设计，适配CPU运行，支持快速推理与在线学习。

Result: 实验表明，CM²在多个文档分类任务中，仅用一个样本/类即可达到或超过传统向量化方法和复杂深度学习模型的性能。其准确率高、计算速度快、内存占用小，且对类别不平衡具有强鲁棒性。此外，在无GPU环境下仍保持优异表现，符合绿色计算理念。

Conclusion: CM²是一种面向未来可持续发展的绿色人工智能模型，成功实现了人类水平的单样本学习能力。它不仅提升了少样本场景下的分类效率，还兼顾可解释性、低成本与环境友好性，为小型化、高效化智能系统提供了新范式。

Abstract: Human-level concept learning argues that humans typically learn new concepts from a single example, whereas machine learning algorithms typically require hundreds of samples to learn a single concept. Our brain subconsciously identifies important features and learns more effectively. \vspace*{6pt}
  Contribution: In this paper, we present the Coordinate Matrix Machine (CM$^2$). This purpose-built small model augments human intelligence by learning document structures and using this information to classify documents. While modern "Red AI" trends rely on massive pre-training and energy-intensive GPU infrastructure, CM$^2$ is designed as a Green AI solution. It achieves human-level concept learning by identifying only the structural "important features" a human would consider, allowing it to classify very similar documents using only one sample per class.
  Advantage: Our algorithm outperforms traditional vectorizers and complex deep learning models that require larger datasets and significant compute. By focusing on structural coordinates rather than exhaustive semantic vectors, CM$^2$ offers: 1. High accuracy with minimal data (one-shot learning) 2. Geometric and structural intelligence 3. Green AI and environmental sustainability 4. Optimized for CPU-only environments 5. Inherent explainability (glass-box model) 6. Faster computation and low latency 7. Robustness against unbalanced classes 8. Economic viability 9. Generic, expandable, and extendable

</details>


### [133] [Geometric Scaling of Bayesian Inference in LLMs](https://arxiv.org/abs/2512.23752)
*Naman Aggarwal,Siddhartha R. Dalal,Vishal Misra*

Main category: cs.LG

TL;DR: 本文研究了现代语言模型是否保留了在受控环境下小规模Transformer模型中观察到的几何特征（如低维值流形和逐渐正交的键），这些特征与精确贝叶斯推断相关。通过对Pythia、Phi-2、Llama-3和Mistral系列模型的分析，发现最后一层的值表示沿一个主导轴组织，该轴位置与预测熵高度相关；特定领域提示会将此结构压缩至类似合成设置中的低维流形。通过针对Pythia-410M在上下文学习中对熵对齐轴进行定向干预，发现移除或扰动该轴会破坏局部不确定性几何结构，而随机轴干预则不会，表明该几何是不确定性的关键读出机制而非单一计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 探究现代大型语言模型是否继承了小规模模型中用于实现贝叶斯推理的几何结构，以理解其近似贝叶斯更新机制的本质。

Method: 分析多个主流语言模型（Pythia、Phi-2、Llama-3、Mistral）的最后层值表示，识别其几何结构；通过在Pythia-410M上实施基于熵对齐轴的定向干预，评估该几何结构在不确定性建模中的作用。

Result: 所有测试模型均表现出沿单一主导轴组织的值表示，且该轴与预测熵强相关；域受限提示可使结构退化为低维流形；对熵对齐轴的干预会破坏局部不确定性几何，但不导致成比例的行为退化，说明该几何是不确定性的重要读出而非唯一计算路径。

Conclusion: 现代语言模型保留了支持贝叶斯推理的几何基底，并在其近似贝叶斯更新过程中组织于这一结构之上，表明该几何是不确定性建模的关键表征机制。

Abstract: Recent work has shown that small transformers trained in controlled "wind-tunnel'' settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate -- low-dimensional value manifolds and progressively orthogonal keys -- that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings.
  To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.

</details>


### [134] [Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation](https://arxiv.org/abs/2512.23753)
*Deep Shankar Pandey,Hyomin Choi,Qi Yu*

Main category: cs.LG

TL;DR: 该论文研究了基于主观逻辑的证据深度学习（EDL）模型中的不确定性量化问题，指出其受限于非负证据约束导致的激活依赖性学习冻结现象，并提出了一类新的激活函数和正则化方法以解决此问题。实验在多个基准数据集和任务上验证了理论分析的有效性与模型性能的提升。


<details>
  <summary>Details</summary>
Motivation: 现有证据深度学习模型受限于主观逻辑框架，要求证据非负，导致特定激活函数在低证据区域引发梯度极小的学习冻结问题，影响模型训练效率与性能。

Method: 通过理论分析学习冻结行为，设计一类通用激活函数及相应的证据正则化项，以实现不同激活区域下一致的证据更新机制。

Result: 在MNIST、CIFAR-10、CIFAR-100、Tiny-ImageNet、少样本分类及盲人脸修复等多个任务上，新模型表现出更稳定的训练过程和更高的准确性，验证了理论的有效性。

Conclusion: 提出的广义正则化证据模型有效缓解了学习冻结问题，提升了证据深度学习模型在不同激活区域下的鲁棒性与性能表现。

Abstract: Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradients become extremely small for samples mapped into low-evidence regions. We theoretically characterize this behavior and analyze how different evidential activations influence learning dynamics. Building on this analysis, we design a general family of activation functions and corresponding evidential regularizers that provide an alternative pathway for consistent evidence updates across activation regimes. Extensive experiments on four benchmark classification problems (MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet), two few-shot classification problems, and blind face restoration problem empirically validate the developed theory and demonstrate the effectiveness of the proposed generalized regularized evidential models.

</details>


### [135] [HINTS: Extraction of Human Insights from Time-Series Without External Sources](https://arxiv.org/abs/2512.23755)
*Sheo Yon Jhin,Noseong Park*

Main category: cs.LG

TL;DR: HINTS is a self-supervised framework that extracts human factors (e.g., emotions, social influence) from time series residuals using the Friedkin-Johnsen model, improving forecasting accuracy without external data. It enhances model interpretability and demonstrates strong alignment with real-world events.


<details>
  <summary>Details</summary>
Motivation: Existing time series forecasting models rely heavily on external data like news and social media to capture human factors such as emotions and collective psychology, which leads to high costs in terms of finance, computation, and practicality. This study aims to eliminate dependency on external data by extracting latent human factors directly from time series residuals.

Method: HINTS is a self-supervised learning framework that uses the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are then integrated into a state-of-the-art backbone model as an attention map.

Result: Experiments on nine real-world and benchmark datasets show that HINTS consistently improves forecasting accuracy. Case studies and ablation studies confirm the interpretability of the extracted factors, showing strong semantic alignment with real-world events.

Conclusion: HINTS effectively captures latent human factors endogenously from time series data, enhancing forecasting performance while maintaining interpretability and reducing reliance on external data sources.

Abstract: Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.

</details>


### [136] [Neural Optimal Design of Experiment for Inverse Problems](https://arxiv.org/abs/2512.23763)
*John E. Darges,Babak Maboudi Afkham,Matthias Chung*

Main category: cs.LG

TL;DR: 提出Neural Optimal Design of Experiments（NODE），一种基于学习的最优实验设计框架，用于反问题中的实验设计。该方法通过单个优化循环联合训练神经重建模型与固定预算的连续设计变量（如传感器位置、采样时间或测量角度），直接优化测量位置，实现自然稀疏性，避免传统双层优化和间接稀疏正则化，显著降低计算复杂度。在指数增长基准、MNIST图像采样和真实世界稀疏视角X射线CT案例中均验证了其有效性，优于基线方法，在重建精度和任务性能上表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统最优实验设计依赖双层优化和间接稀疏正则化，存在计算复杂度高、需调参（如l1）等问题。本文旨在提出一种无需双层优化、直接通过设计变量优化实现稀疏性的新方法。

Method: NODE框架将神经重建模型与连续设计变量（如传感器位置、采样时间等）在单一优化过程中联合训练，通过直接优化测量位置实现稀疏性，避免使用l1正则化和网格权重优化。

Result: 在指数增长基准、MNIST图像采样和真实稀疏视角X射线CT任务中，NODE均表现出比基线方法更高的重建精度和任务性能，且计算效率更高。

Conclusion: NODE是一种高效、可扩展的实验设计框架，通过联合优化神经重建与测量设计，实现了自然稀疏性和高性能，适用于各类反问题场景。

Abstract: We introduce Neural Optimal Design of Experiments, a learning-based framework for optimal experimental design in inverse problems that avoids classical bilevel optimization and indirect sparsity regularization. NODE jointly trains a neural reconstruction model and a fixed-budget set of continuous design variables representing sensor locations, sampling times, or measurement angles, within a single optimization loop. By optimizing measurement locations directly rather than weighting a dense grid of candidates, the proposed approach enforces sparsity by design, eliminates the need for l1 tuning, and substantially reduces computational complexity. We validate NODE on an analytically tractable exponential growth benchmark, on MNIST image sampling, and illustrate its effectiveness on a real world sparse view X ray CT example. In all cases, NODE outperforms baseline approaches, demonstrating improved reconstruction accuracy and task-specific performance.

</details>


### [137] [A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit](https://arxiv.org/abs/2512.23766)
*Karim Salta,Michael Kirby,Chris Peterson*

Main category: cs.LG

TL;DR: 提出一种基于可训练原型的子空间聚类算法，利用最佳拟合施伯特流形（SVBF）作为聚类中心，通过最小化与每个簇成员在固定方向上的交集距离来优化代表子空间。该方法集成于Linde-Buzo-Grey（LBG）框架，在合成数据、图像、谱数据和视频动作数据上均提升了聚类纯度，同时保持了下游分析所需的数学结构。


<details>
  <summary>Details</summary>
Motivation: 在子空间聚类中，传统方法使用均值或中位数作为几何代表，但在高维子空间表示下，这些方法难以有效捕捉复杂结构。为提升聚类性能并保留几何结构，需要一种更灵活且可训练的代表性子空间。

Method: 提出施伯特流形最佳拟合（SVBF），定义为在特定方向上尽可能与所有簇成员相交的子空间；将其嵌入经典的LBG聚类框架中，实现迭代优化和原型学习。

Result: SVBF-LBG在多种类型数据（合成、图像、谱、视频动作）上表现出更高的聚类纯度，优于传统子空间聚类方法，且保持了良好的数学结构以支持后续分析。

Conclusion: SVBF-LBG是一种高效且结构清晰的子空间聚类方法，能够通过可训练原型更好地逼近真实数据分布，适用于多种实际应用场景。

Abstract: In many classification and clustering tasks, it is useful to compute a geometric representative for a dataset or a cluster, such as a mean or median. When datasets are represented by subspaces, these representatives become points on the Grassmann or flag manifold, with distances induced by their geometry, often via principal angles. We introduce a subspace clustering algorithm that replaces subspace means with a trainable prototype defined as a Schubert Variety of Best Fit (SVBF) - a subspace that comes as close as possible to intersecting each cluster member in at least one fixed direction. Integrated in the Linde-Buzo-Grey (LBG) pipeline, this SVBF-LBG scheme yields improved cluster purity on synthetic, image, spectral, and video action data, while retaining the mathematical structure required for downstream analysis.

</details>


### [138] [Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions](https://arxiv.org/abs/2512.23770)
*Ankit Kanwar,Dominik Wagner,Luke Ong*

Main category: cs.LG

TL;DR: SB-TRPO is a new trust-region RL method that balances safety and reward by adaptively combining cost and reward gradients, offering strong theoretical guarantees and superior performance on safety-critical tasks.


<details>
  <summary>Details</summary>
Motivation: Existing reinforcement learning methods for safety-critical domains struggle to balance high reward performance with strict adherence to safety constraints, often resulting in either safety violations or degraded reward performance.

Method: SB-TRPO introduces a trust-region algorithm that adaptively biases policy updates toward satisfying safety constraints by combining natural policy gradients of both cost and reward in a convex manner, ensuring a guaranteed fraction of cost reduction per update step.

Result: Experiments on Safety Gymnasium benchmarks demonstrate that SB-TRPO achieves superior trade-off between safety and task performance, consistently outperforming state-of-the-art methods.

Conclusion: SB-TRPO provides a theoretically grounded, practical approach for hard-constrained RL, ensuring local progress toward safety while maintaining reward improvement under aligned gradients.

Abstract: Reinforcement learning (RL) in safety-critical domains requires agents to maximise rewards while strictly adhering to safety constraints. Existing approaches, such as Lagrangian and projection-based methods, often either fail to ensure near-zero safety violations or sacrifice reward performance in the face of hard constraints. We propose Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new trust-region algorithm for hard-constrained RL. SB-TRPO adaptively biases policy updates towards constraint satisfaction while still seeking reward improvement. Concretely, it performs trust-region updates using a convex combination of the natural policy gradients of cost and reward, ensuring a fixed fraction of optimal cost reduction at each step. We provide a theoretical guarantee of local progress towards safety, with reward improvement when gradients are suitably aligned. Experiments on standard and challenging Safety Gymnasium tasks show that SB-TRPO consistently achieves the best balance of safety and meaningful task completion compared to state-of-the-art methods.

</details>


### [139] [FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading](https://arxiv.org/abs/2512.23773)
*Molei Qin,Xinyu Cai,Yewen Li,Haochong Xia,Chuqiao Zong,Shuo Sun,Xinrun Wang,Bo An*

Main category: cs.LG

TL;DR: 提出了一种名为FineFT的三阶段集成强化学习框架，用于加密货币期货交易。该方法通过选择性更新、基于VAE的能力边界识别和风险感知的策略路由，解决了高杠杆环境下奖励波动大、模型缺乏自知能力导致的潜在重大损失问题。在高频高保真度5倍杠杆的加密货币期货环境中，FineFT在6个金融指标上优于12个SOTA基线，风险降低超40%，同时保持更高收益。可视化与消融实验证明了各智能体专业化分工、VAE路由有效降低最大回撤、选择性更新提升收敛性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法多针对现货市场，难以直接应用于高杠杆的期货市场，因高杠杆放大奖励波动导致训练不稳定且难以收敛；同时，现有方法缺乏对自身能力边界的认知，在面对新市场状态（如黑天鹅事件）时易造成重大损失。

Method: 提出三阶段集成强化学习框架FineFT：第一阶段，通过集成TD误差选择性更新多个Q学习器以提升收敛性；第二阶段，根据盈利性筛选学习器，并使用变分自编码器（VAE）建模市场状态以识别学习器的能力边界；第三阶段，依据训练好的VAE动态选择过滤后的集成模型或保守策略，实现风险控制与盈利能力的平衡。

Result: 在高频率、高保真度、5倍杠杆的加密货币期货数据上，FineFT超越12个最先进的基线方法，在6个财务指标上表现更优，风险降低超过40%，并实现比第二名更高的盈利能力。可视化显示不同智能体专注于不同市场动态，消融实验验证了基于VAE的路由机制显著降低最大回撤，选择性更新提升了训练收敛速度和整体性能。

Conclusion: FineFT通过集成学习与风险感知机制，有效应对高杠杆期货交易中的训练不稳定性与风险暴露问题，为强化学习在复杂金融衍生品市场的应用提供了可靠解决方案。

Abstract: Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.

</details>


### [140] [Improved Bounds for Private and Robust Alignment](https://arxiv.org/abs/2512.23816)
*Wenqian Weng,Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 本文从理论角度研究了语言模型的私有且鲁棒对齐问题，建立了离线和在线设置下次优差距的上界。考虑了受隐私约束和/或对抗性破坏的偏好标签，分析了隐私优先和破坏优先两种不同交互方式。在仅隐私设置下，证明了使用MLE风格算法的对数损失可达到近似最优率，与传统观点相反。在联合隐私与破坏设置下，首次表明现有离线算法实际上提供了更强的保证——同时在破坏水平和隐私参数方面优于以往已知结果，并进一步改进了仅破坏情形下的界。此外，还提出了首个关于私有且鲁棒在线对齐的结果。这些成果得益于在隐私和破坏条件下对对数损失和平方损失的新一致收敛保证，具有广泛的学习理论与统计学应用前景。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型对齐中的隐私保护与抗干扰能力，解决在隐私约束和对抗性破坏共存情况下的学习性能问题，突破传统认知并建立更优的理论框架。

Method: 通过理论分析建立次优差距的上界，引入新的统一收敛性分析方法，针对对数损失与平方损失在隐私与破坏条件下的行为进行建模，结合离线与在线设置进行系统研究。

Result: 在仅隐私设置下，对数损失与MLE算法达到近似最优；在联合隐私与破坏设置下，现有离线算法表现出更强的双重保障能力，且改善了仅破坏情形的界；首次获得私有且鲁棒在线对齐的理论结果；提出适用于多种场景的新统一收敛性保证。

Conclusion: 本研究揭示了隐私与鲁棒性在语言模型对齐中协同作用的潜力，推动了该领域从经验到理论的深化，所提出的统一收敛性工具具备广泛适用性。

Abstract: In this paper, we study the private and robust alignment of language models from a theoretical perspective by establishing upper bounds on the suboptimality gap in both offline and online settings. We consider preference labels subject to privacy constraints and/or adversarial corruption, and analyze two distinct interplays between them: privacy-first and corruption-first. For the privacy-only setting, we show that log loss with an MLE-style algorithm achieves near-optimal rates, in contrast to conventional wisdom. For the joint privacy-and-corruption setting, we first demonstrate that existing offline algorithms in fact provide stronger guarantees -- simultaneously in terms of corruption level and privacy parameters -- than previously known, which further yields improved bounds in the corruption-only regime. In addition, we also present the first set of results for private and robust online alignment. Our results are enabled by new uniform convergence guarantees for log loss and square loss under privacy and corruption, which we believe have broad applicability across learning theory and statistics.

</details>


### [141] [Exploiting the Prior of Generative Time Series Imputation](https://arxiv.org/abs/2512.23832)
*YuYang Miao,Chang Li,Zehua Chen*

Main category: cs.LG

TL;DR: 本文提出Bridge-TS，一种基于数据到数据生成过程的时序填补方法，通过引入专家先验和组合先验提升生成模型的先验信息，显著提高时序数据填补的准确性，在多个基准数据集上实现了新的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式时序填补方法使用非信息性的先验（如高斯噪声或线性插值结果），导致生成过程负担重且准确率受限，因此需要更有效的先验设计来提升填补效果。

Method: 提出专家先验：利用预训练Transformer模块进行确定性填补，作为真实目标的先验；提出组合先验：融合多个预训练模型的估计结果，在数据到数据的生成过程中实现多源先验到目标的填补。

Result: 在ETT、Exchange、Weather等多个基准数据集上，Bridge-TS在均方误差（MSE）和平均绝对误差（MAE）指标上均达到新纪录，验证了改进先验对生成式时序填补的有效性。

Conclusion: 通过构建更具信息量的数据到数据生成流程，并结合专家与组合先验，Bridge-TS显著提升了时序填补的精度，为生成式填补方法提供了新的范式。

Abstract: Time series imputation, i.e., filling the missing values of a time recording, finds various applications in electricity, finance, and weather modelling. Previous methods have introduced generative models such as diffusion probabilistic models and Schrodinger bridge models to conditionally generate the missing values from Gaussian noise or directly from linear interpolation results. However, as their prior is not informative to the ground-truth target, their generation process inevitably suffer increased burden and limited imputation accuracy. In this work, we present Bridge-TS, building a data-to-data generation process for generative time series imputation and exploiting the design of prior with two novel designs. Firstly, we propose expert prior, leveraging a pretrained transformer-based module as an expert to fill the missing values with a deterministic estimation, and then taking the results as the prior of ground truth target. Secondly, we explore compositional priors, utilizing several pretrained models to provide different estimation results, and then combining them in the data-to-data generation process to achieve a compositional priors-to-target imputation process. Experiments conducted on several benchmark datasets such as ETT, Exchange, and Weather show that Bridge-TS reaches a new record of imputation accuracy in terms of mean square error and mean absolute error, demonstrating the superiority of improving prior for generative time series imputation.

</details>


### [142] [Trellis: Learning to Compress Key-Value Memory in Attention Models](https://arxiv.org/abs/2512.23852)
*Mahdi Karami,Ali Behrouz,Praneeth Kacham,Vahab Mirrokni*

Main category: cs.LG

TL;DR: Trellis is a novel Transformer architecture with bounded memory that dynamically compresses key-value (KV) memory at test time, addressing the quadratic computational complexity and growing KV cache issue. It uses a fixed-size memory and a two-pass recurrent compression mechanism trained via online gradient descent with a forget gate to retain important contextual information. Experiments show Trellis outperforms baselines, especially in long-context scenarios.


<details>
  <summary>Details</summary>
Motivation: Transformers suffer from quadratic computational complexity and increasing Key-Value (KV) cache size, limiting scalability for long sequences. Existing methods struggle to maintain efficiency and performance as sequence length grows.

Method: Trellis replaces the standard KV cache with a fixed-size memory and employs a two-pass recurrent compression mechanism. It uses online gradient descent with a forget gate to recursively update compressed memory, learning to retain crucial contextual information during inference.

Result: Trellis achieves superior performance across language modeling, common-sense reasoning, recall-intensive tasks, and time series prediction. Its advantages grow with longer sequence lengths, demonstrating strong potential for long-context applications.

Conclusion: Trellis effectively addresses the memory and computational challenges of Transformers by enabling dynamic, bounded memory compression at test time, making it highly suitable for long-context processing.

Abstract: Transformers, while powerful, suffer from quadratic computational complexity and the ever-growing Key-Value (KV) cache of the attention mechanism. This paper introduces Trellis, a novel Transformer architecture with bounded memory that learns how to compress its key-value memory dynamically at test time. Trellis replaces the standard KV cache with a fixed-size memory and train a two-pass recurrent compression mechanism to store new keys and values into memory. To achieve this, it leverages an online gradient descent procedure with a forget gate, enabling the compressed memory to be updated recursively while learning to retain important contextual information from incoming tokens at test time. Extensive experiments on language modeling, common-sense reasoning, recall-intensive tasks, and time series show that the proposed architecture outperforms strong baselines. Notably, its performance gains increase as the sequence length grows, highlighting its potential for long-context applications.

</details>


### [143] [Flow Matching Neural Processes](https://arxiv.org/abs/2512.23853)
*Hussen Abu Hamad,Dan Rosenbaum*

Main category: cs.LG

TL;DR: 本文提出了一种基于流匹配的新型神经过程（NP）模型，该模型在无需辅助条件方法的情况下，可通过常微分方程（ODE）求解器实现对条件分布的采样，且具有可调节的精度与运行时间权衡能力。相比以往方法，该模型实现简单，在1D高斯过程、2D图像和真实气象数据等多种基准测试中表现优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经过程模型在条件采样时依赖复杂的辅助条件方法，且难以灵活控制计算效率与精度之间的平衡。本文旨在设计一种更高效、更灵活且易于实现的神经过程框架，以提升生成建模的实用性与性能。

Method: 采用流匹配作为生成建模范式，结合神经过程的训练框架，通过构建可学习的随机过程，并利用ODE求解器进行条件分布的采样，实现端到端的高效推理与生成。

Result: 在合成1D高斯过程、2D图像及真实天气数据等多个基准上，该模型均显著优于现有最先进神经过程方法，在预测精度和计算效率方面表现出色。

Conclusion: 基于流匹配的神经过程模型提供了一种高效、灵活且易于实现的新范式，能够有效支持复杂数据上的条件采样与推断，为神经过程的应用拓展提供了有力工具。

Abstract: Neural processes (NPs) are a class of models that learn stochastic processes directly from data and can be used for inference, sampling and conditional sampling. We introduce a new NP model based on flow matching, a generative modeling paradigm that has demonstrated strong performance on various data modalities. Following the NP training framework, the model provides amortized predictions of conditional distributions over any arbitrary points in the data. Compared to previous NP models, our model is simple to implement and can be used to sample from conditional distributions using an ODE solver, without requiring auxiliary conditioning methods. In addition, the model provides a controllable tradeoff between accuracy and running time via the number of steps in the ODE solver. We show that our model outperforms previous state-of-the-art neural process methods on various benchmarks including synthetic 1D Gaussian processes data, 2D images, and real-world weather data.

</details>


### [144] [Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding](https://arxiv.org/abs/2512.23858)
*Yue Guan,Changming Yu,Shihan Fang,Weiming Hu,Zaifeng Pan,Zheng Wang,Zihan Liu,Yangjie Zhou,Yufei Ding,Minyi Guo,Jingwen Leng*

Main category: cs.LG

TL;DR: Yggdrasil 是一个协同设计的系统，通过上下文感知的树状草稿和编译器友好的执行，实现延迟最优的推测解码。它引入了等增长树结构以兼容静态图、基于延迟的优化目标用于草稿选择，以及阶段式调度以减少开销，支持未经修改的LLM，并在多种硬件配置下实现了高达3.98倍于现有基线的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码系统因动态推测与静态运行时假设不匹配而性能不佳，亟需一种能够适配动态推测并优化延迟的新方法。

Method: 采用等增长树结构保证静态图兼容性，设计基于延迟的优化目标进行草稿选择，实施阶段式调度降低运行开销，实现对未修改大模型的支持。

Result: 在多种硬件环境下，Yggdrasil 相比当前最先进的基线系统，推理速度最高提升达 3.98 倍。

Conclusion: Yggdrasil 通过系统级协同设计，有效解决了推测解码中的性能瓶颈，为大模型高效推理提供了新范式。

Abstract: Speculative decoding improves LLM inference by generating and verifying multiple tokens in parallel, but existing systems suffer from suboptimal performance due to a mismatch between dynamic speculation and static runtime assumptions. We present Yggdrasil, a co-designed system that enables latency-optimal speculative decoding through context-aware tree drafting and compiler-friendly execution. Yggdrasil introduces an equal-growth tree structure for static graph compatibility, a latency-aware optimization objective for draft selection, and stage-based scheduling to reduce overhead. Yggdrasil supports unmodified LLMs and achieves up to $3.98\times$ speedup over state-of-the-art baselines across multiple hardware setups.

</details>


### [145] [Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining](https://arxiv.org/abs/2512.23862)
*Ruizhe Huang,Kexuan Zhang,Yihao Fang,Baifeng Yu*

Main category: cs.LG

TL;DR: 本研究探讨了小规模预训练在小型语言模型（SLMs）中的应用，旨在提升有限数据和计算资源下的效率，降低使用成本，并增强低资源环境下的可及性。为改善紧凑模型的长上下文外推能力，研究聚焦于Infini-attention机制，该机制通过压缩历史片段记忆来保持局部注意力。实验基于300M参数的LLaMA模型，采用Infini-attention进行预训练，结果表明模型训练稳定，且在长上下文检索任务中优于基线模型。研究发现平衡因子是影响性能的关键因素，重复记忆压缩会导致长序列下检索准确率下降，但Infini-attention仍显著弥补了SLM参数有限的问题。即使在16,384个标记的上下文长度下，其检索准确率仍比基线高出最多31%。研究结论支持采用类似Infini-attention的架构化记忆设计，以增强SLMs的鲁棒长上下文能力。


<details>
  <summary>Details</summary>
Motivation: 为了在有限数据和计算资源条件下高效使用小型语言模型（SLMs），提升其在低资源环境中的可访问性和降低成本，同时解决SLMs在长上下文任务中表现不佳的问题，需要探索有效的架构改进方法。

Method: 采用300M参数的LLaMA模型进行小规模预训练，引入Infini-attention机制，通过压缩历史上下文片段构建记忆，同时保留局部注意力；通过实证研究评估模型在长上下文检索任务中的表现，并分析平衡因子对性能的影响。

Result: Infini-attention模型在长上下文检索任务中表现出色，尽管在16,384令牌的上下文长度下出现性能下降，但仍比基线模型最高提升31%的检索准确率；训练过程稳定，验证了该机制在缓解参数限制方面的有效性。

Conclusion: 采用架构化记忆机制如Infini-attention，有助于显著提升小型语言模型在长上下文任务中的鲁棒性与性能，是实现高效、低成本且适用于低资源场景的SLM的重要路径。

Abstract: This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM's limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.

</details>


### [146] [Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR](https://arxiv.org/abs/2512.23870)
*Yuyang Zhang,Yang Hu,Bo Dai,Na Li*

Main category: cs.LG

TL;DR: 本文提出一种基于流模型的Soft Actor-Critic（SAC）算法变体，利用流模型的强表达能力提升策略的灵活性与鲁棒性。通过引入在线流匹配方法（ISFM），仅需从用户指定的采样分布中获取样本即可更新策略，无需依赖未知的目标分布。理论分析揭示了不同采样分布对学习效率的影响。在最大熵线性二次调节器问题上的实验表明，该算法能有效学习最优动作分布。


<details>
  <summary>Details</summary>
Motivation: SAC算法在实践中常使用简单策略类来近似能量型策略，导致表达能力和鲁棒性下降。为提升策略的表达能力与稳定性，需要更强大的策略参数化方式。

Method: 采用流模型参数化策略，结合即时变量变换技术评估策略，并提出一种名为重要性采样流匹配（ISFM）的在线流匹配方法，实现仅依赖用户指定采样分布的策略更新。

Result: 在最大熵线性二次调节器问题上，所提算法能够准确学习到最优动作分布，验证了其有效性与优势。

Conclusion: 基于流模型的SAC变体结合ISFM方法，显著提升了策略的表达能力与学习效率，且在理论上和实验上均表现出优越性能。

Abstract: Soft actor-critic (SAC) is a popular algorithm for max-entropy reinforcement learning. In practice, the energy-based policies in SAC are often approximated using simple policy classes for efficiency, sacrificing the expressiveness and robustness. In this paper, we propose a variant of the SAC algorithm that parameterizes the policy with flow-based models, leveraging their rich expressiveness. In the algorithm, we evaluate the flow-based policy utilizing the instantaneous change-of-variable technique and update the policy with an online variant of flow matching developed in this paper. This online variant, termed importance sampling flow matching (ISFM), enables policy update with only samples from a user-specified sampling distribution rather than the unknown target distribution. We develop a theoretical analysis of ISFM, characterizing how different choices of sampling distributions affect the learning efficiency. Finally, we conduct a case study of our algorithm on the max-entropy linear quadratic regulator problems, demonstrating that the proposed algorithm learns the optimal action distribution.

</details>


### [147] [Interactive Machine Learning: From Theory to Scale](https://arxiv.org/abs/2512.23924)
*Yinglun Zhu*

Main category: cs.LG

TL;DR: 本论文研究交互式机器学习，提出新算法原则并建立三大维度的理论极限：带噪声数据和复杂模型类的主动学习、大规模动作空间的序列决策，以及部分反馈下的模型选择。成果包括首个无需低噪声假设即可实现指数级标签节省的计算高效主动学习算法；首个与动作空间大小无关的通用高效上下文相关老虎机算法；以及首次对序列决策中模型选择基本代价的紧致刻画。整体上推进了交互式学习的理论基础，开发出统计最优且计算高效的算法，并为实际部署提供指导。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，获取高质量标签或通过试错进行决策成本高昂、耗时或存在风险，尤其是在大规模或高风险场景下。因此需要发展能够主动影响信息收集或决策过程的交互式学习方法，以减少对大量标注数据或在线交互的依赖。

Method: 提出新的算法设计原则，针对主动学习、序列决策和模型选择分别设计高效且理论上最优的算法，并在不同设置下分析其性能边界。

Result: 实现了主动学习中的指数级标签节省（无需低噪声假设）、上下文相关老虎机算法与动作空间规模无关的保证，以及对模型选择代价的精确刻画。

Conclusion: 该研究深化了交互式学习的理论基础，开发出兼具统计最优性和计算效率的算法，为在大规模真实场景中部署交互式学习提供了坚实的理论支持和实践指导。

Abstract: Machine learning has achieved remarkable success across a wide range of applications, yet many of its most effective methods rely on access to large amounts of labeled data or extensive online interaction. In practice, acquiring high-quality labels and making decisions through trial-and-error can be expensive, time-consuming, or risky, particularly in large-scale or high-stakes settings. This dissertation studies interactive machine learning, in which the learner actively influences how information is collected or which actions are taken, using past observations to guide future interactions. We develop new algorithmic principles and establish fundamental limits for interactive learning along three dimensions: active learning with noisy data and rich model classes, sequential decision making with large action spaces, and model selection under partial feedback. Our results include the first computationally efficient active learning algorithms achieving exponential label savings without low-noise assumptions; the first efficient, general-purpose contextual bandit algorithms whose guarantees are independent of the size of the action space; and the first tight characterizations of the fundamental cost of model selection in sequential decision making. Overall, this dissertation advances the theoretical foundations of interactive learning by developing algorithms that are statistically optimal and computationally efficient, while also providing principled guidance for deploying interactive learning methods in large-scale, real-world settings.

</details>


### [148] [Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing](https://arxiv.org/abs/2512.23977)
*Giacinto Paolo Saggese,Paul Smith*

Main category: cs.LG

TL;DR: DataFlow是一个用于构建、测试和部署高性能机器学习系统的计算框架，专为无界时间序列数据设计。它通过基于有向无环图（DAG）的统一执行模型，实现批处理与流式处理的一致性，确保模型在批量开发与实时生产中行为一致，避免因果性错误和未来窥探问题。该框架支持时间与特征维度的灵活分块，兼容Python数据科学生态，提供在线学习、缓存、增量计算和自动并行化能力，已在金融交易、物联网、欺诈检测和实时分析等领域验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统数据科学工作流假设数据集是有限的，从批处理原型迁移到流式生产系统时需大量重写代码，导致因果性违规、批次边界伪影以及实时故障难以复现的问题。

Method: 提出基于有向无环图（DAG）的统一执行模型，引入“时间点幂等性”：任意时刻t的输出仅依赖于t之前固定长度的上下文窗口。通过自动追踪知识时间，确保严格因果性，防止未来窥探错误。支持跨时间和特征维度的灵活分块配置，集成Python生态，提供fit/predict语义、在线学习、缓存、增量计算与基于DAG的自动并行化。

Result: DataFlow实现了批处理与流式处理环境下的行为一致性，显著提升系统可复现性与可靠性；支持不同频率和内存配置下的统一模型部署；在金融交易、物联网、欺诈检测和实时分析等多个领域验证了其高效性与实用性。

Conclusion: DataFlow通过统一的执行模型与严格的因果性保障，弥合了批处理与流式处理之间的鸿沟，为高可靠、高性能的实时机器学习系统提供了可扩展、易用的解决方案。

Abstract: We present DataFlow, a computational framework for building, testing, and deploying high-performance machine learning systems on unbounded time-series data. Traditional data science workflows assume finite datasets and require substantial reimplementation when moving from batch prototypes to streaming production systems. This gap introduces causality violations, batch boundary artifacts, and poor reproducibility of real-time failures.
  DataFlow resolves these issues through a unified execution model based on directed acyclic graphs (DAGs) with point-in-time idempotency: outputs at any time t depend only on a fixed-length context window preceding t. This guarantee ensures that models developed in batch mode execute identically in streaming production without code changes. The framework enforces strict causality by automatically tracking knowledge time across all transformations, eliminating future-peeking bugs.
  DataFlow supports flexible tiling across temporal and feature dimensions, allowing the same model to operate at different frequencies and memory profiles via configuration alone. It integrates natively with the Python data science stack and provides fit/predict semantics for online learning, caching and incremental computation, and automatic parallelization through DAG-based scheduling. We demonstrate its effectiveness across domains including financial trading, IoT, fraud detection, and real-time analytics.

</details>


### [149] [Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems](https://arxiv.org/abs/2512.23978)
*Tinglong Dai,David Simchi-Levi,Michelle Xiao Wu,Yao Xie*

Main category: cs.LG

TL;DR: 本文探讨了生成式人工智能（GenAI）从对话助手向自主决策系统演进带来的自主性悖论，提出需通过运筹学（OR）框架实现‘可信自主性’。该框架结合基于流的生成模型与对抗鲁棒性视角，使生成过程可审计、受约束，并能应对分布偏移与高后果场景下的风险。研究强调在更高自主性下，运筹学的角色从求解器转变为系统架构师，负责控制逻辑、激励机制、监控体系与安全边界设计，为安全关键领域提供研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI向自主决策系统发展，其在实际操作中面临脆弱性问题，尤其在面对未建模风险、分布偏移和高后果情境时缺乏可靠保障。现有随机生成模型难以满足对可行性、鲁棒性和压力测试的需求，因此亟需建立一种可验证、可信赖的自主性框架。

Method: 提出一个基于运筹学的可信自主性框架，包含两个互补方法：一是使用基于流的生成模型，将生成过程建模为由常微分方程描述的确定性传输过程，实现可审计性与约束感知生成；二是采用对抗鲁棒性视角，评估决策规则在不确定性集内的最坏情况扰动表现，将未建模风险纳入系统设计考量。

Result: 该框架实现了生成过程的可解释性、可控性与安全性增强，支持在复杂动态环境中进行稳健决策。同时明确了运筹学在高自主系统中的新角色——从传统优化求解者升级为系统架构与安全守门人，涵盖控制逻辑、激励协议、监控机制和安全边界的设计。

Conclusion: 本研究构建了一个面向安全关键领域的可信自主性框架，为未来生成式AI在高可靠性要求场景中的部署提供了理论基础与实践路径，推动运筹学在智能系统中的核心作用转型。

Abstract: Generative artificial intelligence (GenAI) is shifting from conversational assistants toward agentic systems -- autonomous decision-making systems that sense, decide, and act within operational workflows. This shift creates an autonomy paradox: as GenAI systems are granted greater operational autonomy, they should, by design, embody more formal structure, more explicit constraints, and stronger tail-risk discipline. We argue stochastic generative models can be fragile in operational domains unless paired with mechanisms that provide verifiable feasibility, robustness to distribution shift, and stress testing under high-consequence scenarios. To address this challenge, we develop a conceptual framework for assured autonomy grounded in operations research (OR), built on two complementary approaches. First, flow-based generative models frame generation as deterministic transport characterized by an ordinary differential equation, enabling auditability, constraint-aware generation, and connections to optimal transport, robust optimization, and sequential decision control. Second, operational safety is formulated through an adversarial robustness lens: decision rules are evaluated against worst-case perturbations within uncertainty or ambiguity sets, making unmodeled risks part of the design. This framework clarifies how increasing autonomy shifts OR's role from solver to guardrail to system architect, with responsibility for control logic, incentive protocols, monitoring regimes, and safety boundaries. These elements define a research agenda for assured autonomy in safety-critical, reliability-sensitive operational domains.

</details>


### [150] [Information-Theoretic Quality Metric of Low-Dimensional Embeddings](https://arxiv.org/abs/2512.23981)
*Sebastián Gutiérrez-Bernal,Hector Medel Cobaxin,Abiel Galindo González*

Main category: cs.LG

TL;DR: 本文从信息论角度研究低维嵌入的质量，提出熵秩保持度量（ERPM），通过邻域矩阵的奇异值谱熵和稳定秩量化原始表示与降维投影之间不确定性的变化，提供局部指标和全局统计量。实验表明，ERPM与局部普鲁斯特斯度量相关性高，但与基于距离的度量相关性低，能有效识别信息严重损失的局部区域，从而在信息敏感应用中补充现有评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有经典评价指标如应力、基于排名的邻域准则或局部普鲁斯特斯度量主要衡量距离或局部几何的失真，但未直接评估高维数据投影到低维空间时的信息保留程度。因此需要一种从信息论角度出发的新方法来更准确地衡量信息保真度。

Method: 提出熵秩保持度量（ERPM），基于邻域矩阵的奇异值谱的香农熵和稳定秩，量化原始表示与降维投影间不确定性变化，提供局部与全局的信息保持评估。

Result: ERPM与局部普鲁斯特斯度量显示强平均相关性，但在局部区域存在显著差异；而距离基度量与几何和谱度量的相关性极低。结果表明ERPM能有效识别信息严重损失的邻域，提升嵌入质量评估的全面性。

Conclusion: ERPM作为一种基于信息论的局部度量，能够补充现有评估方法，尤其适用于对信息保真度要求高的场景，如早期预警指标构建。

Abstract: In this work we study the quality of low-dimensional embeddings from an explicitly information-theoretic perspective. We begin by noting that classical evaluation metrics such as stress, rank-based neighborhood criteria, or Local Procrustes quantify distortions in distances or in local geometries, but do not directly assess how much information is preserved when projecting high-dimensional data onto a lower-dimensional space. To address this limitation, we introduce the Entropy Rank Preservation Measure (ERPM), a local metric based on the Shannon entropy of the singular-value spectrum of neighborhood matrices and on the stable rank, which quantifies changes in uncertainty between the original representation and its reduced projection, providing neighborhood-level indicators and a global summary statistic. To validate the results of the metric, we compare its outcomes with the Mean Relative Rank Error (MRRE), which is distance-based, and with Local Procrustes, which is based on geometric properties, using a financial time series and a manifold commonly studied in the literature. We observe that distance-based criteria exhibit very low correlation with geometric and spectral measures, while ERPM and Local Procrustes show strong average correlation but display significant discrepancies in local regimes, leading to the conclusion that ERPM complements existing metrics by identifying neighborhoods with severe information loss, thereby enabling a more comprehensive assessment of embeddings, particularly in information-sensitive applications such as the construction of early-warning indicators.

</details>


### [151] [Tracing the Heart's Pathways: ECG Representation Learning from a Cardiac Conduction Perspective](https://arxiv.org/abs/2512.24002)
*Tan Pan,Yixuan Sun,Chen Jiang,Qiong Gao,Rui Sun,Xingmeng Zhang,Zhenqi Yang,Limei Han,Yixiu Liang,Yuan Cheng,Kaiyu Guo*

Main category: cs.LG

TL;DR: 提出CLEAR-HUG框架，通过两阶段设计捕捉心电图中不同导联间的细微传导差异，并遵循临床诊断流程。第一阶段使用基于稀疏注意力的信号重建模型CLEAR，有效分离并保留每个心跳的独特特征；第二阶段采用层次化导联统一分组头（HUG），模拟医生从单个心跳到导联组合的诊断逻辑。实验在六个任务上实现6.84%的性能提升，验证了该方法在增强心脏传导表征与符合专家诊断规范方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法过于关注各导联和心跳间的一致性，忽视了由心脏传导过程带来的细微但重要的变异，这些变异蕴含关键生理信息。同时，现有方法未遵循临床诊断中从单个心跳→单导联→导联组合的逐步分析逻辑，导致预训练模型在下游任务中表现受限。

Method: 提出两阶段框架CLEAR-HUG：第一阶段设计CLEAR模型，利用稀疏注意力机制对每个心跳独立重建信号，以捕捉特异性变化与共性；第二阶段构建HUG头，按临床诊断顺序逐层融合导联信息，实现疾病分类。

Result: 在六个不同任务上的实验表明，CLEAR-HUG相比基线方法平均提升6.84%，显著改善了心电图表示学习效果，尤其在捕捉细微传导差异方面表现突出。

Conclusion: CLEAR-HUG通过结合心电图生理特性和临床诊断流程，实现了更准确、更具可解释性的表示学习，为未来心电图智能诊断提供了新范式。

Abstract: The multi-lead electrocardiogram (ECG) stands as a cornerstone of cardiac diagnosis. Recent strides in electrocardiogram self-supervised learning (eSSL) have brightened prospects for enhancing representation learning without relying on high-quality annotations. Yet earlier eSSL methods suffer a key limitation: they focus on consistent patterns across leads and beats, overlooking the inherent differences in heartbeats rooted in cardiac conduction processes, while subtle but significant variations carry unique physiological signatures. Moreover, representation learning for ECG analysis should align with ECG diagnostic guidelines, which progress from individual heartbeats to single leads and ultimately to lead combinations. This sequential logic, however, is often neglected when applying pre-trained models to downstream tasks. To address these gaps, we propose CLEAR-HUG, a two-stage framework designed to capture subtle variations in cardiac conduction across leads while adhering to ECG diagnostic guidelines. In the first stage, we introduce an eSSL model termed Conduction-LEAd Reconstructor (CLEAR), which captures both specific variations and general commonalities across heartbeats. Treating each heartbeat as a distinct entity, CLEAR employs a simple yet effective sparse attention mechanism to reconstruct signals without interference from other heartbeats. In the second stage, we implement a Hierarchical lead-Unified Group head (HUG) for disease diagnosis, mirroring clinical workflow. Experimental results across six tasks show a 6.84% improvement, validating the effectiveness of CLEAR-HUG. This highlights its ability to enhance representations of cardiac conduction and align patterns with expert diagnostic guidelines.

</details>


### [152] [How and Why LLMs Generalize: A Fine-Grained Analysis of LLM Reasoning from Cognitive Behaviors to Low-Level Patterns](https://arxiv.org/abs/2512.24063)
*Haoyue Bai,Yiyou Sun,Wenjie Hu,Shi Qiu,Maggie Ziyu Huan,Peiyang Song,Robert Nowak,Dawn Song*

Main category: cs.LG

TL;DR: 本文提出一种新型基准，将推理分解为计算、事实检索、模拟、枚举和诊断等基本技能，以更精细地分析大语言模型在微调过程中的泛化行为。研究发现，强化学习（RL）微调能更好地保持推理能力的稳定性，而监督微调（SFT）则容易导致技能退化和对表面模式的过拟合。结合低层次统计分析，该框架揭示了不同训练策略对模型认知能力演化的影响，为设计更具鲁棒性的训练方法提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖粗粒度的准确率指标，难以解释大语言模型在监督微调（SFT）与强化学习（RL）微调下不同的泛化行为。需要更精细的评估框架来理解推理能力如何在后训练阶段演变。

Method: 构建一个分解推理为原子核心技能的基准，结合元探针框架追踪模型在不同训练阶段的行为变化，并分析分布偏移与参数统计特征，对比SFT与RL在数学、科学推理及非推理任务中的表现差异。

Result: RL微调模型表现出更稳定的推理行为，技能退化较少；而SFT模型出现明显的漂移和对表面模式的过拟合，核心推理能力易崩溃。

Conclusion: 本研究揭示了推理在大语言模型中的本质构成，表明强化学习有助于维持广泛的、稳健的泛化能力，为未来训练策略的设计提供了理论依据。

Abstract: Large Language Models (LLMs) display strikingly different generalization behaviors: supervised fine-tuning (SFT) often narrows capability, whereas reinforcement-learning (RL) tuning tends to preserve it. The reasons behind this divergence remain unclear, as prior studies have largely relied on coarse accuracy metrics. We address this gap by introducing a novel benchmark that decomposes reasoning into atomic core skills such as calculation, fact retrieval, simulation, enumeration, and diagnostic, providing a concrete framework for addressing the fundamental question of what constitutes reasoning in LLMs. By isolating and measuring these core skills, the benchmark offers a more granular view of how specific cognitive abilities emerge, transfer, and sometimes collapse during post-training. Combined with analyses of low-level statistical patterns such as distributional divergence and parameter statistics, it enables a fine-grained study of how generalization evolves under SFT and RL across mathematical, scientific reasoning, and non-reasoning tasks. Our meta-probing framework tracks model behavior at different training stages and reveals that RL-tuned models maintain more stable behavioral profiles and resist collapse in reasoning skills, whereas SFT models exhibit sharper drift and overfit to surface patterns. This work provides new insights into the nature of reasoning in LLMs and points toward principles for designing training strategies that foster broad, robust generalization.

</details>


### [153] [Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework](https://arxiv.org/abs/2512.24075)
*Jiazhao Shi,Ziyu Wang,Yichen Lin,Shoufeng Lu*

Main category: cs.LG

TL;DR: 提出TPI-AI框架，结合深度时序表示与物理启发的交互特征，通过双层双向LSTM编码器提取轨迹历史嵌入，并融合运动学、安全性和交互感知特征，使用LightGBM进行三类意图识别（无变道、左变道、右变道）。针对少数类别不平衡问题，采用重采样/加权及折间阈值校准优化。在highD和exiD两个大规模无人机数据集上验证，TPI-AI在不同预测时延下均优于基线模型，宏平均F1最高达0.9562，证明该方法在多场景下具有鲁棒的变道意图预测能力。


<details>
  <summary>Details</summary>
Motivation: 自然交通中变道意图预测面临运动噪声、类别严重不平衡及跨异构高速公路场景泛化能力差等挑战，亟需更鲁棒的预测方法以支持自动驾驶与ADAS系统安全运行。

Method: 采用两层双向LSTM编码器学习多步轨迹历史的紧凑嵌入，融合头距、TTC、安全间距等物理启发特征，结合LightGBM分类器实现三类意图识别；引入重采样/加权与折间阈值校准策略缓解类别不平衡问题。

Result: 在highD数据集上，T = 1, 2, 3秒时宏平均F1分别为0.9562、0.9124、0.8345；在exiD数据集上分别为0.9247、0.8197、0.7605，显著优于独立的LightGBM与Bi-LSTM基线模型。

Conclusion: 结合物理启发的交互特征与学习到的时序嵌入，TPI-AI实现了在多种高速公路场景下的鲁棒变道意图预测，具备良好的泛化性能与实际应用潜力。

Abstract: Lane-change intention prediction is safety-critical for autonomous driving and ADAS, but remains difficult in naturalistic traffic due to noisy kinematics, severe class imbalance, and limited generalization across heterogeneous highway scenarios. We propose Temporal Physics-Informed AI (TPI-AI), a hybrid framework that fuses deep temporal representations with physics-inspired interaction cues. A two-layer bidirectional LSTM (Bi-LSTM) encoder learns compact embeddings from multi-step trajectory histories; we concatenate these embeddings with kinematics-, safety-, and interaction-aware features (e.g., headway, TTC, and safe-gap indicators) and train a LightGBM classifier for three-class intention recognition (No-LC, Left-LC, Right-LC). To improve minority-class reliability, we apply imbalance-aware optimization including resampling/weighting and fold-wise threshold calibration. Experiments on two large-scale drone-based datasets, highD (straight highways) and exiD (ramp-rich environments), use location-based splits and evaluate prediction horizons T = 1, 2, 3 s. TPI-AI outperforms standalone LightGBM and Bi-LSTM baselines, achieving macro-F1 of 0.9562, 0.9124, 0.8345 on highD and 0.9247, 0.8197, 0.7605 on exiD at T = 1, 2, 3 s, respectively. These results show that combining physics-informed interaction features with learned temporal embeddings yields robust multi-scenario lane-change intention prediction.

</details>


### [154] [Autoregressivity in the Latent Space of a GP-VAE Language Model: An Empirical Ablation Study](https://arxiv.org/abs/2512.24102)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 该论文对GP-VAE模型中的潜在自回归性进行了基于消融的分析，发现潜在自回归能显著提升潜在轨迹与高斯过程先验的兼容性及长程稳定性，而去除自回归会导致潜在结构退化和长期行为不稳定。结果表明，潜在自回归是组织长程结构的有效机制，且与词元级自回归建模互补。


<details>
  <summary>Details</summary>
Motivation: 研究潜在自回归在序列建模中的作用，探索其如何影响模型的长期稳定性和潜在空间结构，以理解其在生成模型中的代表性意义。

Method: 通过系统性消融实验比较三种模型：完整的具有潜在自回归动态的GP-VAE、潜在变量独立的非自回归消融版本，以及标准的词元级自回归Transformer。

Result: 在中等规模语料和短训练上下文条件下，潜在自回归使潜在轨迹更符合高斯过程先验，表现出更强的长程稳定性；去除自回归则导致潜在结构退化和不稳定的长期行为。

Conclusion: 潜在自回归是有效组织长程结构的机制，且与词元级自回归建模互补，但本研究为对表示结构的实证分析，而非提出新架构。

Abstract: This paper provides an ablation-based analysis of latent autoregression in GP-VAE models, building upon our previous work introducing the architecture. Language models typically rely on an autoregressive factorization over tokens. In contrast, our prior work proposed shifting sequential structure to the latent space through a causal Gaussian process, while using a non-autoregressive decoder. Here, we conduct a systematic ablation study of the role played by latent autoregression. We compare (i) a full GP-VAE model with autoregressive latent dynamics, (ii) a non-autoregressive ablation in which latent variables are independent, and (iii) a standard token-level autoregressive Transformer. Our results show that, within the considered regime (medium-scale corpora and short training contexts), latent autoregression induces latent trajectories that are significantly more compatible with the Gaussian-process prior and exhibit greater long-horizon stability. In contrast, removing autoregression leads to degraded latent structure and unstable long-range behavior. These findings highlight the role of latent autoregression as an effective mechanism for organizing long-range structure, while remaining complementary to token-level autoregressive modeling. They should be interpreted as an empirical analysis of representational structure rather than as a proposal for a new architecture.

</details>


### [155] [Enhancing LLM Planning Capabilities through Intrinsic Self-Critique](https://arxiv.org/abs/2512.24103)
*Bernd Bohnet,Pierre-Alexandre Kamienny,Hanie Sedghi,Dilan Gorur,Pranjal Awasthi,Aaron Parisi,Kevin Swersky,Rosanne Liu,Azade Nova,Noah Fiedel*

Main category: cs.LG

TL;DR: 本文提出一种大语言模型（LLM）自我批判的方法，通过内在的自我纠错与优化过程，在Blocksworld、Logistics和Mini-grid等规划任务上显著提升性能，超越现有基准。该方法基于少样本学习并逐步扩展为多样本策略，结合迭代修正机制，无需外部验证器即可实现性能跃升，为2024年10月前发布的LLM模型提供了新的最先进结果。


<details>
  <summary>Details</summary>
Motivation: 尽管先前研究质疑大语言模型自批判方法的有效性，但本文旨在探索其在规划任务中的潜力，证明通过内在自我改进机制可显著提升模型表现，尤其在无外部验证的情况下依然有效。

Method: 采用少样本学习作为基础，并逐步演进为多样本学习；引入迭代式自我批判与修正流程，使模型能够识别自身输出中的错误并进行优化，从而实现性能提升。

Result: 在Blocksworld、Logistics和Mini-grid等多个规划数据集上均取得显著性能提升，超越了强基线模型，实现了针对2024年10月前发布模型的新状态最优水平。

Conclusion: 本研究证实了大语言模型具备内在自我改进的能力，该方法不依赖特定模型版本，具有广泛适用性，未来应用于更复杂搜索策略和更强模型时有望进一步提升性能。

Abstract: We demonstrate an approach for LLMs to critique their \emph{own} answers with the goal of enhancing their performance that leads to significant improvements over established planning benchmarks. Despite the findings of earlier research that has cast doubt on the effectiveness of LLMs leveraging self critique methods, we show significant performance gains on planning datasets in the Blocksworld domain through intrinsic self-critique, without external source such as a verifier. We also demonstrate similar improvements on Logistics and Mini-grid datasets, exceeding strong baseline accuracies. We employ a few-shot learning technique and progressively extend it to a many-shot approach as our base method and demonstrate that it is possible to gain substantial improvement on top of this already competitive approach by employing an iterative process for correction and refinement. We illustrate how self-critique can significantly boost planning performance. Our empirical results present new state-of-the-art on the class of models considered, namely LLM model checkpoints from October 2024. Our primary focus lies on the method itself, demonstrating intrinsic self-improvement capabilities that are applicable regardless of the specific model version, and we believe that applying our method to more complex search techniques and more capable models will lead to even better performance.

</details>


### [156] [Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators](https://arxiv.org/abs/2512.24145)
*Udit Sharma*

Main category: cs.LG

TL;DR: 本文提出了一种配对种子评估设计，通过在相同随机种子下评估竞争系统，利用随机性共享源来减少方差。该方法在种子层面产生高度正相关的结果，显著提升统计功效和有效样本量，带来数量级的效率提升。即使相关性不强，该方法也退化为独立评估而不损失有效性，因此在实践中具有优势。


<details>
  <summary>Details</summary>
Motivation: 学习型模拟器在算法比较、设计选择和干预评估中广泛应用，但其评估结果因随机初始化和学习过程中的随机性而具有高方差。标准独立评估设计未能利用不同方案间共享的随机性，导致统计效率低下。

Method: 提出配对种子评估设计，让多个系统在相同的随机种子下运行，从而产生匹配的随机实现；通过分析种子级别的相关性，证明其能有效降低方差，并在正相关条件下实现显著的统计效率提升。

Result: 实证表明，种子级别相关性通常为大且正，可带来数量级的效率增益；该方法在有相关性时表现更优，无相关性时等价于独立评估，不会造成无效性。

Conclusion: 配对种子评估是实践中弱占优的方法，能显著提高评估的统计可靠性，同时保持计算成本可控，是学习型系统评估的理想选择。

Abstract: Machine learning systems appear stochastic but are deterministically random, as seeded pseudorandom number generators produce identical realisations across executions. Learning-based simulators are widely used to compare algorithms, design choices, and interventions under such dynamics, yet evaluation outcomes often exhibit high variance due to random initialisation and learning stochasticity. We analyse the statistical structure of comparative evaluation in these settings and show that standard independent evaluation designs fail to exploit shared sources of randomness across alternatives. We formalise a paired seed evaluation design in which competing systems are evaluated under identical random seeds, inducing matched realisations of stochastic components and strict variance reduction whenever outcomes are positively correlated at the seed level. This yields tighter confidence intervals, higher statistical power, and effective sample size gains at fixed computational budgets. Empirically, seed-level correlations are typically large and positive, producing order-of-magnitude efficiency gains. Paired seed evaluation is weakly dominant in practice, improving statistical reliability when correlation is present and reducing to independent evaluation without loss of validity when it is not.

</details>


### [157] [Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm](https://arxiv.org/abs/2512.24253)
*Alireza Rafiei,Farshid Hajati,Alireza Rezaee,Amirhossien Panahi,Shahadat Uddin*

Main category: cs.LG

TL;DR: 本研究提出并评估了四种新型机器学习算法，用于通过可穿戴设备分析心率数据来预测脓毒症发作。模型架构通过遗传算法优化，兼顾性能、计算复杂度和内存需求。在初始设定一小时预测窗口的基础上，通过迁移学习扩展至四小时，结果表明可穿戴技术有望在非病房环境中实现脓毒症的早期检测。


<details>
  <summary>Details</summary>
Motivation: 当前对重症监护室（ICU）患者已开发出多种脓毒症预测模型，但针对非病房环境中的脓毒症早期检测方法仍存在明显空白。及时预测脓毒症进展对减少不良结局至关重要，因此亟需适用于可穿戴设备的轻量级、高效预测工具。

Method: 采用四种新型机器学习算法，基于心率数据进行脓毒症预测；利用遗传算法优化模型架构，平衡性能、计算复杂度与内存占用；在不同预测窗口（1小时与4小时）下进行测试，并通过迁移学习提升模型泛化能力。

Result: 所提出的模型在保持低计算开销和内存使用的同时，表现出良好的预测性能，尤其在四小时预测窗口中表现稳定，具备在可穿戴设备上部署的可行性。

Conclusion: 该研究验证了基于心率数据的机器学习模型在可穿戴设备上的潜力，为非病房环境中脓毒症的早期预警提供了可行的技术路径。

Abstract: Sepsis, characterized by a dysregulated immune response to infection, results in significant mortality, morbidity, and healthcare costs. The timely prediction of sepsis progression is crucial for reducing adverse outcomes through early intervention. Despite the development of numerous models for Intensive Care Unit (ICU) patients, there remains a notable gap in approaches for the early detection of sepsis in non-ward settings. This research introduces and evaluates four novel machine learning algorithms designed for predicting the onset of sepsis on wearable devices by analyzing heart rate data. The architecture of these models was refined through a genetic algorithm, optimizing for performance, computational complexity, and memory requirements. Performance metrics were subsequently extracted for each model to evaluate their feasibility for implementation on wearable devices capable of accurate heart rate monitoring. The models were initially tailored for a prediction window of one hour, later extended to four hours through transfer learning. The encouraging outcomes of this study suggest the potential for wearable technology to facilitate early sepsis detection outside ICU and ward environments.

</details>


### [158] [Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction](https://arxiv.org/abs/2512.24324)
*Haojin Li,Anbang Zhang,Chen Sun,Chenyuan Feng,Kaiqian Qu,Tony Q. S. Quek,Haijun Zhang*

Main category: cs.LG

TL;DR: 提出一种名为SaM2B的语义感知多模态波束预测框架，通过可靠性感知的动态加权机制和跨模态对比学习，提升低空无人机通信中的波束预测准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用固定或经验权重，无法适应不同飞行场景下各模态重要性的动态变化，导致劣化模态的影响被放大，且存在模态不匹配和对齐不足问题，影响跨场景泛化能力。

Method: 设计了基于环境视觉、飞行姿态和地理空间数据的轻量级线索，实现模态贡献的自适应分配；引入跨模态对比学习，将多源表示与波束语义对齐至共享语义空间，增强判别力与抗噪声能力。

Result: 在真实低空无人机数据集上的实验表明，SaM2B显著优于基线方法，在波束预测精度和鲁棒性方面表现更优。

Conclusion: 所提出的SaM2B框架通过动态加权与语义对齐有效提升了多模态波束预测性能，为低空经济中无人机通信的可靠连接提供了新解决方案。

Abstract: The low-altitude economy (LAE) is rapidly expanding driven by urban air mobility, logistics drones, and aerial sensing, while fast and accurate beam prediction in uncrewed aerial vehicles (UAVs) communications is crucial for achieving reliable connectivity. Current research is shifting from single-signal to multi-modal collaborative approaches. However, existing multi-modal methods mostly employ fixed or empirical weights, assuming equal reliability across modalities at any given moment. Indeed, the importance of different modalities fluctuates dramatically with UAV motion scenarios, and static weighting amplifies the negative impact of degraded modalities. Furthermore, modal mismatch and weak alignment further undermine cross-scenario generalization. To this end, we propose a reliability-aware dynamic weighting scheme applied to a semantic-aware multi-modal beam prediction framework, named SaM2B. Specifically, SaM2B leverages lightweight cues such as environmental visual, flight posture, and geospatial data to adaptively allocate contributions across modalities at different time points through reliability-aware dynamic weight updates. Moreover, by utilizing cross-modal contrastive learning, we align the "multi-source representation beam semantics" associated with specific beam information to a shared semantic space, thereby enhancing discriminative power and robustness under modal noise and distribution shifts. Experiments on real-world low-altitude UAV datasets show that SaM2B achieves more satisfactory results than baseline methods.

</details>


### [159] [Lifting Vision: Ground to Aerial Localization with Reasoning Guided Planning](https://arxiv.org/abs/2512.24404)
*Soham Pahari,M. Srinivas*

Main category: cs.LG

TL;DR: 本文提出了一种名为ViReLoc的视觉推理框架，旨在通过纯视觉表示实现空间规划与定位，克服传统依赖文本推理在空间任务中的局限。该框架利用强化学习优化视觉域中的逐步推理，学习空间依赖性和几何关系，并结合对比学习与自适应特征交互来对齐跨视角差异。实验表明，在多种导航与定位场景中，该方法显著提升了空间推理准确性和跨视图检索性能，证明了视觉推理在无需实时GPS数据的情况下可有效完成导航与定位任务，具有更高的安全性与实用性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉理解与高级推理系统多依赖文本信息进行推理，但在空间任务（如视觉导航和地理定位）中表现受限，因文本难以捕捉空间依赖性和几何关系。因此，亟需一种基于视觉表示的推理范式以提升空间任务的性能。

Method: 提出视觉推理定位框架ViReLoc，通过编码视觉域中的逐步推理过程，结合强化学习目标进行优化；引入对比学习与自适应特征交互机制，以对齐不同视角间的差异，增强跨视图一致性。

Result: 在多种导航与定位场景中，ViReLoc在空间推理准确率和跨视图检索性能上均取得显著提升，且无需实时GPS数据即可完成可靠导航，验证了视觉推理的有效性与可行性。

Conclusion: 视觉推理可作为导航与定位任务的有力补充，尤其在缺乏全球定位系统支持的场景下，展现出更高的安全性和鲁棒性，为未来自主导航系统提供了新方向。

Abstract: Multimodal intelligence development recently show strong progress in visual understanding and high level reasoning. Though, most reasoning system still reply on textual information as the main medium for inference. This limit their effectiveness in spatial tasks such as visual navigation and geo-localization. This work discuss about the potential scope of this field and eventually propose an idea visual reasoning paradigm Geo-Consistent Visual Planning, our introduced framework called Visual Reasoning for Localization, or ViReLoc, which performs planning and localization using only visual representations. The proposed framework learns spatial dependencies and geometric relations that text based reasoning often suffer to understand. By encoding step by step inference in the visual domain and optimizing with reinforcement based objectives, ViReLoc plans routes between two given ground images. The system also integrates contrastive learning and adaptive feature interaction to align cross view perspectives and reduce viewpoint differences. Experiments across diverse navigation and localization scenarios show consistent improvements in spatial reasoning accuracy and cross view retrieval performance. These results establish visual reasoning as a strong complementary approach for navigation and localization, and show that such tasks can be performed without real time global positioning system data, leading to more secure navigation solutions.

</details>


### [160] [Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models](https://arxiv.org/abs/2512.24407)
*Lars van der Laan,Aurelien Bibaut,Nathan Kallus*

Main category: cs.LG

TL;DR: 本文提出了一种半参数的去偏逆强化学习框架，能够在最大熵逆强化学习和Gumbel扰动离散选择模型中对奖励依赖函数进行统计高效的推断。通过将对数行为策略作为伪奖励，实现策略价值差异和奖励本身的点识别，并将政策价值、反事实softmax策略下的值以及归一化奖励的泛函等目标形式化为行为策略和转移核的光滑泛函，证明了路径可微性并推导出有效影响函数。基于此，构建了自动去偏的机器学习估计器，允许灵活的非参数估计干扰项，同时保证$\sqrt{n}$-一致性、渐近正态性和半参数效率。该框架将经典DDC模型的推断扩展到非参数奖励和现代机器学习工具，提供了一个统一且计算上可行的IRL统计推断方法。


<details>
  <summary>Details</summary>
Motivation: 现有灵活的逆强化学习方法依赖机器学习但缺乏有效的推断保证，而传统动态离散选择（DDC）方法则依赖于严格的参数假设且常需重复动态规划。因此，亟需一种既能保持灵活性又能提供统计推断保障的方法。

Method: 提出半参数去偏框架，利用对数行为策略作为伪奖励，将目标泛函表示为行为策略与转移核的光滑函数；证明路径可微性并推导高效影响函数；构建基于机器学习的自动去偏估计器，实现非参数估计与渐近最优性质。

Result: 所提框架实现了对奖励相关函数的统计高效推断，支持非参数奖励建模与机器学习估计，具备$\sqrt{n}$-一致性、渐近正态性和半参数效率，且计算上可行。

Conclusion: 该研究统一了传统DDC模型与现代机器学习在逆强化学习中的应用，为复杂决策过程提供了兼具灵活性与严格统计推断能力的新范式。

Abstract: Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical DDC approaches impose restrictive parametric specifications and often require repeated dynamic programming. We develop a semiparametric framework for debiased inverse reinforcement learning that yields statistically efficient inference for a broad class of reward-dependent functionals in maximum entropy IRL and Gumbel-shock DDC models. We show that the log-behavior policy acts as a pseudo-reward that point-identifies policy value differences and, under a simple normalization, the reward itself. We then formalize these targets, including policy values under known and counterfactual softmax policies and functionals of the normalized reward, as smooth functionals of the behavior policy and transition kernel, establish pathwise differentiability, and derive their efficient influence functions. Building on this characterization, we construct automatic debiased machine-learning estimators that allow flexible nonparametric estimation of nuisance components while achieving $\sqrt{n}$-consistency, asymptotic normality, and semiparametric efficiency. Our framework extends classical inference for DDC models to nonparametric rewards and modern machine-learning tools, providing a unified and computationally tractable approach to statistical inference in IRL.

</details>


### [161] [Sparse classification with positive-confidence data in high dimensions](https://arxiv.org/abs/2512.24443)
*The Tien Mai,Mai Anh Nguyen,Trung Nghia Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种高维正向置信（Pconf）分类的稀疏正则化框架，结合L1、SCAD和MCP等凸与非凸惩罚方法，有效缓解收缩偏差并提升特征恢复能力。理论分析表明，在受限强凸条件下，该方法可实现近最优稀疏恢复率；同时设计了高效的近端梯度算法求解。大量模拟实验验证其预测性能与变量选择精度接近全监督方法，显著缩小了弱监督与高维统计之间的差距。


<details>
  <summary>Details</summary>
Motivation: 高维学习问题中特征数远超样本量，传统稀疏正则化在完全监督下表现良好，但在弱监督场景（如仅含带置信度的正例数据）中仍不充分。现有Pconf方法难以适应高维情形，亟需新的稀疏建模框架以提升变量选择与预测性能。

Method: 提出基于Lasso、SCAD和MCP等惩罚的Pconf分类新方法，结合凸与非凸正则项以克服收缩偏差；引入近端梯度算法求解复合目标函数，并在受限强凸条件下建立估计与预测误差界。

Result: 理论证明所提方法在受限强凸条件下达到近最小最大最优稀疏恢复率；模拟实验显示其预测性能与变量选择能力接近全监督方法，有效填补了弱监督与高维统计间的空白。

Conclusion: 本研究构建了适用于高维Pconf分类的稀疏正则化框架，通过创新的惩罚机制与高效优化算法，实现了良好的统计性质与实际性能，为弱监督学习在高维场景下的应用提供了有力支持。

Abstract: High-dimensional learning problems, where the number of features exceeds the sample size, often require sparse regularization for effective prediction and variable selection. While established for fully supervised data, these techniques remain underexplored in weak-supervision settings such as Positive-Confidence (Pconf) classification. Pconf learning utilizes only positive samples equipped with confidence scores, thereby avoiding the need for negative data. However, existing Pconf methods are ill-suited for high-dimensional regimes. This paper proposes a novel sparse-penalization framework for high-dimensional Pconf classification. We introduce estimators using convex (Lasso) and non-convex (SCAD, MCP) penalties to address shrinkage bias and improve feature recovery. Theoretically, we establish estimation and prediction error bounds for the L1-regularized Pconf estimator, proving it achieves near minimax-optimal sparse recovery rates under Restricted Strong Convexity condition. To solve the resulting composite objective, we develop an efficient proximal gradient algorithm. Extensive simulations demonstrate that our proposed methods achieve predictive performance and variable selection accuracy comparable to fully supervised approaches, effectively bridging the gap between weak supervision and high-dimensional statistics.

</details>


### [162] [Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics](https://arxiv.org/abs/2512.24445)
*Akash Samanta,Sheldon Williamson*

Main category: cs.LG

TL;DR: 本文提出了一种诊断驱动的自适应学习框架，通过将误差演化分解为偏差（捕捉持续漂移）、噪声（捕捉随机波动）和对齐度（捕捉重复方向激励导致的超调），实现了对动态环境中学习不稳定性问题的有效应对。该框架在线计算轻量级统计量，独立于模型架构与任务领域，适用于监督优化、强化学习中的演员-评论家方法及学习型优化器。理论分析表明，在光滑性假设下，所有实例均具有有界有效更新和稳定性。实验验证了诊断信号在调节适应性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有优化、强化学习和元学习方法虽能适应梯度统计特性，但忽视了误差信号本身的时序结构，导致在非平稳、安全关键环境中的学习不稳定、收敛慢或适应脆弱。因此需要一种能够显式建模误差演化特性的新机制。

Method: 提出基于偏差-噪声-对齐的误差分解框架，利用损失或时序差分误差轨迹的轻量级统计量在线计算诊断信号；设计三类诊断驱动的实例化算法：稳定化的监督优化器、诊断调控的演员-评论家方法、诊断条件化的学习型优化器。

Result: 所提框架在多种学习范式中均展现出良好的稳定性与适应性；理论证明了有界更新与稳定性；可视化结果展示了诊断信号如何根据误差结构调节学习行为。

Conclusion: 本工作将误差演化作为自适应学习的核心对象，构建了一个可解释、轻量且通用的控制基础，显著提升了动态环境中学习系统的可靠性与鲁棒性。

Abstract: Learning systems deployed in nonstationary and safety-critical environments often suffer from instability, slow convergence, or brittle adaptation when learning dynamics evolve over time. While modern optimization, reinforcement learning, and meta-learning methods adapt to gradient statistics, they largely ignore the temporal structure of the error signal itself. This paper proposes a diagnostic-driven adaptive learning framework that explicitly models error evolution through a principled decomposition into bias, capturing persistent drift; noise, capturing stochastic variability; and alignment, capturing repeated directional excitation leading to overshoot. These diagnostics are computed online from lightweight statistics of loss or temporal-difference error trajectories and are independent of model architecture or task domain. We show that the proposed bias-noise-alignment decomposition provides a unifying control backbone for supervised optimization, actor-critic reinforcement learning, and learned optimizers. Building on this framework, we derive diagnostic-driven instantiations including a stabilized supervised optimizer, a diagnostic-regulated actor-critic scheme, and a diagnostic-conditioned learned optimizer. Under standard smoothness assumptions, we establish bounded effective updates and stability properties for all cases. Representative diagnostic illustrations in actor-critic learning highlight how the proposed signals modulate adaptation in response to temporal-difference error structure. Overall, this work elevates error evolution to a first-class object in adaptive learning and provides an interpretable, lightweight foundation for reliable learning in dynamic environments.

</details>


### [163] [Generative forecasting with joint probability models](https://arxiv.org/abs/2512.24446)
*Patrick Wyrod,Ashesh Chattopadhyay,Daniele Venturi*

Main category: cs.LG

TL;DR: 本文将预测问题重新构想为一个完全生成式问题，通过学习短期时间窗口内滞后系统状态的联合概率分布，利用边际化进行预测。该方法能捕捉非线性时间依赖性，表示多步轨迹片段，并生成与学习到的联合分布一致的下一步预测。作者提出了一种通用、模型无关的训练与推理框架，支持通过三种互补的不确定性量化指标（集合方差、短时自相关、累积Wasserstein漂移）评估预测的鲁棒性和可靠性，且无需真实标签。在Lorenz-63系统和Kuramoto-Sivashinsky方程上的实验表明，联合生成模型在短期预测性能、吸引子几何结构保持以及长期统计行为准确性方面均显著优于传统的条件下一步模型。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统对初始条件高度敏感，且常包含未解析的多尺度过程，导致确定性预测存在根本局限。现有生成模型多聚焦于下一步条件预测，未能充分刻画系统内在动态结构。因此，亟需一种能够全面建模系统演化分布的新范式。

Method: 将预测重构为生成任务，学习短期时间窗口内滞后状态的联合概率分布；通过边际化获得预测结果；提出模型无关的训练与推理框架；引入三种不确定性量化指标评估预测质量。

Result: 在Lorenz-63系统和Kuramoto-Sivashinsky方程上，联合生成模型在短期预测精度、吸引子结构保持和长期统计特性再现方面均优于传统条件模型，且无需真实数据即可评估预测可靠性。

Conclusion: 本研究提出的联合生成预测框架有效克服了传统方法在混沌系统预测中的局限，能够同时提升预测精度、保持系统几何结构，并准确捕捉长期统计行为，为复杂动力系统的不确定性量化与可靠预测提供了新路径。

Abstract: Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most existing approaches focus on next-step conditional prediction rather than the structure of the underlying dynamics. In this work, we reframe forecasting as a fully generative problem by learning the joint probability distribution of lagged system states over short temporal windows and obtaining forecasts through marginalization. This new perspective allows the model to capture nonlinear temporal dependencies, represent multistep trajectory segments, and produce next-step predictions consistent with the learned joint distribution. We also introduce a general, model-agnostic training and inference framework for joint generative forecasting and show how it enables assessment of forecast robustness and reliability using three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, and cumulative Wasserstein drift), without access to ground truth. We evaluate the performance of the proposed method on two canonical chaotic dynamical systems, the Lorenz-63 system and the Kuramoto-Sivashinsky equation, and show that joint generative models yield improved short-term predictive skill, preserve attractor geometry, and achieve substantially more accurate long-range statistical behaviour than conventional conditional next-step models.

</details>


### [164] [HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors](https://arxiv.org/abs/2512.24478)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: HOLOGRAPH 提出一种基于层叠理论的因果发现框架，利用大语言模型（LLM）作为先验知识来源，通过将局部因果信念表示为变量子集上的预层截面，形式化了 LLM 引导的因果发现。其核心思想是：一致的全局因果结构对应于全局截面的存在，而拓扑障碍则表现为非零的层上同调。该方法引入代数隐变量投影处理隐藏混杂，并采用在信念流形上的自然梯度下降进行优化。实验表明，在合成与真实数据集上，该方法在50-100个变量的任务中表现优异，具备严格的数学基础。层叠理论分析显示，身份、传递性和粘合性公理满足至数值精度（<10^{-6}），但大图中局部性公理失效，揭示潜在变量投影中存在根本性的非局部耦合。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的因果发现方法依赖启发式集成，缺乏理论基础；如何在不破坏可识别性的前提下有效整合外部先验知识，仍是关键挑战。

Method: 使用层叠理论建模局部因果信念为预层截面，以全局截面存在性表征一致因果结构；通过代数隐变量投影处理隐藏混杂，结合自然梯度下降在信念流形上优化；利用层上同调检测拓扑障碍。

Result: 在50-100变量的合成与真实世界基准测试中，HOLOGRAPH表现出竞争力，且在理论上具备严格基础；层叠分析显示身份、传递性、粘合性公理满足良好，但大图中局部性公理失效，暗示非局部耦合现象。

Conclusion: HOLOGRAPH 为 LLM 引导的因果发现提供了坚实的数学框架，揭示了现有方法在大规模图中的局限性，强调非局部性在潜在变量建模中的重要性。

Abstract: Causal discovery from observational data remains fundamentally limited by identifiability constraints. Recent work has explored leveraging Large Language Models (LLMs) as sources of prior causal knowledge, but existing approaches rely on heuristic integration that lacks theoretical grounding. We introduce HOLOGRAPH, a framework that formalizes LLM-guided causal discovery through sheaf theory--representing local causal beliefs as sections of a presheaf over variable subsets. Our key insight is that coherent global causal structure corresponds to the existence of a global section, while topological obstructions manifest as non-vanishing sheaf cohomology. We propose the Algebraic Latent Projection to handle hidden confounders and Natural Gradient Descent on the belief manifold for principled optimization. Experiments on synthetic and real-world benchmarks demonstrate that HOLOGRAPH provides rigorous mathematical foundations while achieving competitive performance on causal discovery tasks with 50-100 variables. Our sheaf-theoretic analysis reveals that while Identity, Transitivity, and Gluing axioms are satisfied to numerical precision (<10^{-6}), the Locality axiom fails for larger graphs, suggesting fundamental non-local coupling in latent variable projections. Code is available at [https://github.com/hyunjun1121/holograph](https://github.com/hyunjun1121/holograph).

</details>


### [165] [More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization](https://arxiv.org/abs/2512.24545)
*Yuma Ichikawa,Yoshihiko Fujisawa,Yudai Fujimoto,Akira Sakai,Katsuki Fujisawa*

Main category: cs.LG

TL;DR: 提出Multi-envelope DBF (MDBF)，通过使用rank-$l$的包络替代传统DBF中的单一封装，提升极低比特量化下大语言模型的精度与表达能力。共享符号矩阵以保持二进制载体特性，并优化内存利用。引入闭式初始化和交替优化方法，显著提升性能。在LLaMA和Qwen系列模型上，MDBF在相同比特率下优于现有二值化方法，在困惑度和零样本准确率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 极端低比特量化下的大语言模型推理效率受限于现有双二值分解（DBF）方法中缩放参数过于严格的问题，导致性能饱和；需要在不牺牲精度的前提下提升模型表达力。

Method: 提出Multi-envelope DBF（MDBF），采用共享1-bit符号基但用rank-$l$包络替代单一包络，实现符号矩阵共享以维持二值性并增强幅度表达能力；设计闭式初始化与交替优化策略以高效训练。

Result: 在LLaMA和Qwen系列模型上，MDBF在与现有二值格式相同比特数条件下，显著提升了困惑度和零样本准确率，同时保持部署友好的推理结构。

Conclusion: MDBF通过灵活的多包络结构有效突破了传统DBF的性能瓶颈，在极低比特量化场景下实现了更高的精度与实用性，是高效大模型推理的重要进展。

Abstract: For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank-$l$ envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.

</details>


### [166] [From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme](https://arxiv.org/abs/2512.24555)
*Xueyan Li,Yingyi Xue,Mengjie Jiang,Qingzi Zhu,Yazhe Niu*

Main category: cs.LG

TL;DR: HUMOR 是一个用于生成幽默表情包的新型框架，通过分层多路径思维链（CoT）和群体内人类偏好对齐，提升视觉语言模型在幽默内容生成中的推理多样性与主观偏好一致性。该方法首先通过从真实标签回溯的CoT监督增强推理路径多样性，再利用基于成组对比判断的奖励模型进行群体强化学习优化，确保在信任区域内的单调改进。实验表明，HUMOR 显著提升了多种VLM在幽默性、多样性和整体质量上的表现，并可推广至其他开放式的、以人类偏好为导向的多模态生成任务。


<details>
  <summary>Details</summary>
Motivation: 生成幽默表情包需要超越简单的图像到文本的监督，涉及对视觉内容、上下文线索和主观幽默感的复杂理解。现有方法难以有效捕捉幽默的主观性和创造性，因此亟需一种能引导模型进行多层次推理并符合人类偏好的新范式。

Method: 提出 HUMOR 框架，包含两个核心组件：1）分层多路径思维链（CoT），从模板意图识别出发，探索多种上下文相关推理路径，并锚定高质量路径；2）基于群体内成对比较的奖励模型，结合群体强化学习，实现对主观幽默偏好的稳定建模与优化。

Result: 实验结果显示，HUMOR 显著提升了各类视觉语言模型在幽默表达多样性、偏好对齐可靠性及整体生成质量方面的表现。同时，该方法具备理论保障，支持在信任区域内实现单调性能提升。

Conclusion: HUMOR 提供了一种通用的多模态开放生成训练范式，强调通过群体内比较判断来引导生成过程，为实现更自然、更符合人类审美的生成系统提供了有效路径。

Abstract: Generating humorous memes is a challenging multimodal task that moves beyond direct image-to-caption supervision. It requires a nuanced reasoning over visual content, contextual cues, and subjective humor. To bridge this gap between visual perception and humorous punchline creation, we propose HUMOR}, a novel framework that guides VLMs through hierarchical reasoning and aligns them with group-wise human preferences. First, HUMOR employs a hierarchical, multi-path Chain-of-Thought (CoT): the model begins by identifying a template-level intent, then explores diverse reasoning paths under different contexts, and finally anchors onto a high-quality, context-specific path. This CoT supervision, which traces back from ground-truth captions, enhances reasoning diversity. We further analyze that this multi-path exploration with anchoring maintains a high expected humor quality, under the practical condition that high-quality paths retain significant probability mass. Second, to capture subjective humor, we train a pairwise reward model that operates within groups of memes sharing the same template. Following established theory, this approach ensures a consistent and robust proxy for human preference, even with subjective and noisy labels. The reward model then enables a group-wise reinforcement learning optimization, guaranteeing providing a theoretical guarantee for monotonic improvement within the trust region. Extensive experiments show that HUMOR empowers various VLMs with superior reasoning diversity, more reliable preference alignment, and higher overall meme quality. Beyond memes, our work presents a general training paradigm for open-ended, human-aligned multimodal generation, where success is guided by comparative judgment within coherent output group.

</details>


### [167] [CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts](https://arxiv.org/abs/2512.24564)
*Shunbo Jia,Caizhi Liao*

Main category: cs.LG

TL;DR: 本文提出一种名为因果生理表征学习（CPR）的新方法，用于提升心电图（ECG）深度学习模型对平滑对抗扰动（SAP）的鲁棒性。CPR通过引入生理结构先验，在因果解耦框架中分离出不变的病理形态特征（如P-QRS-T波群），从而避免依赖非鲁棒的虚假相关性。实验表明，CPR在PTB-XL数据集上优于传统预处理方法（如中值滤波），在SAP攻击下F1得分达0.632，较中值滤波提升9.1%；同时兼具随机平滑的认证鲁棒性与单次推理效率，实现鲁棒性、效率与临床可解释性的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有ECG诊断深度学习模型对平滑对抗扰动（SAP）敏感，而现有防御方法面临计算开销大（如对抗训练）或推理延迟高（如随机平滑）的困境，根本原因在于模型依赖非鲁棒的虚假相关性而非不变的病理特征。

Method: 提出因果生理表征学习（CPR），基于结构因果模型（SCM）构建生理生成机制，通过结构干预强制分离病理形态与非因果噪声，实现因果解耦。

Result: 在PTB-XL数据集上，CPR在SAP攻击下取得0.632的F1分数，显著优于中值滤波（0.541），提升9.1%；同时具备与随机平滑相当的认证鲁棒性，并保持单次推理效率。

Conclusion: CPR有效解决了ECG深度学习模型在对抗攻击下的脆弱性问题，实现了鲁棒性、效率与临床可解释性的协同优化，适用于实时临床监测场景。

Abstract: Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.

</details>


### [168] [HeteroHBA: A Generative Structure-Manipulating Backdoor Attack on Heterogeneous Graphs](https://arxiv.org/abs/2512.24665)
*Honglin Gao,Lan Zhao,Junhao Ren,Xiang Li,Gaoxi Xiao*

Main category: cs.LG

TL;DR: HeteroHBA is a novel backdoor attack framework for heterogeneous graph neural networks that uses saliency-based trigger selection, diverse feature and connection synthesis, AdaIN with MMD loss for stealthiness, and bilevel optimization to balance attack success and clean accuracy. It outperforms prior methods on real-world graphs and remains effective even under structural defenses.


<details>
  <summary>Details</summary>
Motivation: Targeted backdoor attacks on heterogeneous graphs are underexplored despite the widespread use of HGNNs in real-world applications. Existing methods lack effectiveness and stealthiness in heterogeneous settings, motivating the need for a more sophisticated attack framework.

Method: HeteroHBA selects influential auxiliary neighbors using saliency-based screening, synthesizes trigger features and connections tailored to local heterogeneous context, applies AdaIN with MMD loss to align trigger statistics with benign data, and uses a bilevel optimization objective to maximize attack success while preserving clean performance.

Result: HeteroHBA achieves higher attack success rates than existing baselines across multiple real-world heterogeneous graphs, with minimal impact on clean accuracy. It also remains effective under the heterogeneity-aware defense CSD, demonstrating significant practical risks.

Conclusion: The study reveals serious backdoor vulnerabilities in heterogeneous graph learning and underscores the urgent need for robust defense mechanisms against such sophisticated attacks.

Abstract: Heterogeneous graph neural networks (HGNNs) have achieved strong performance in many real-world applications, yet targeted backdoor poisoning on heterogeneous graphs remains less studied. We consider backdoor attacks for heterogeneous node classification, where an adversary injects a small set of trigger nodes and connections during training to force specific victim nodes to be misclassified into an attacker-chosen label at test time while preserving clean performance. We propose HeteroHBA, a generative backdoor framework that selects influential auxiliary neighbors for trigger attachment via saliency-based screening and synthesizes diverse trigger features and connection patterns to better match the local heterogeneous context. To improve stealthiness, we combine Adaptive Instance Normalization (AdaIN) with a Maximum Mean Discrepancy (MMD) loss to align the trigger feature distribution with benign statistics, thereby reducing detectability, and we optimize the attack with a bilevel objective that jointly promotes attack success and maintains clean accuracy. Experiments on multiple real-world heterogeneous graphs with representative HGNN architectures show that HeteroHBA consistently achieves higher attack success than prior backdoor baselines with comparable or smaller impact on clean accuracy; moreover, the attack remains effective under our heterogeneity-aware structural defense, CSD. These results highlight practical backdoor risks in heterogeneous graph learning and motivate the development of stronger defenses.

</details>


### [169] [Nested Learning: The Illusion of Deep Learning Architectures](https://arxiv.org/abs/2512.24695)
*Ali Behrouz,Meisam Razaviyayn,Peilin Zhong,Vahab Mirrokni*

Main category: cs.LG

TL;DR: 本文提出一种名为嵌套学习（Nested Learning, NL）的新学习范式，将机器学习模型视为一系列嵌套的、多层级和/或并行的优化问题，每个问题都有其自身的上下文流。NL揭示了现有深度学习方法通过压缩自身上下文流来从数据中学习的本质，并自然引出大模型中的上下文学习现象。基于此，论文提出了三个核心贡献：(1) 表达力更强的优化器，将如Adam、SGD with Momentum等传统优化器视为信息压缩的关联记忆模块，并设计出具有深层记忆和更强大学习规则的新优化器；(2) 自修改学习模块，利用NL的洞察，构建一个能学习自身更新算法的序列模型；(3) 连续记忆系统，超越传统的长短时记忆划分，提出一种更通用的记忆建模方式。结合自修改模块与连续记忆系统，作者构建了名为Hope的持续学习模块，在语言建模、知识融合、少样本泛化、持续学习及长上下文推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在持续学习、自我改进和有效求解方面仍面临根本性挑战，缺乏对模型如何不断学习、记忆和自适应的系统理解。现有方法难以实现真正的持续学习和高阶上下文学习，亟需新的理论框架来指导更强大学习算法的设计。

Method: 提出嵌套学习（NL）范式，将学习过程建模为多层级、嵌套或并行的优化问题，每个问题具有独立上下文流。基于该范式，设计表达力更强的优化器（如基于记忆压缩的优化机制），构建自修改学习模块（可学习自身更新规则），并提出连续记忆系统以统一长期与短期记忆。最终整合为名为Hope的持续学习模块。

Result: 所提出的自修改学习模块与连续记忆系统结合后形成的Hope模块，在语言建模、知识融入、少样本泛化、持续学习和长上下文推理等多个任务上展现出显著性能提升，验证了嵌套学习范式的有效性与潜力。

Conclusion: 嵌套学习（NL）提供了一个全新的学习哲学，通过多层级优化与上下文流建模，能够推动更高阶的上下文学习与持续学习能力的发展。本研究不仅深化了对现有优化器的理解，还为设计更智能、自适应的学习系统提供了新路径。

Abstract: Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.

</details>


### [170] [Causal Discovery with Mixed Latent Confounding via Precision Decomposition](https://arxiv.org/abs/2512.24696)
*Amir Asiaee,Samhita Pal,James O'quinn,James P. Long*

Main category: cs.LG

TL;DR: 提出DCL-DECOR方法，用于在存在混合潜变量混杂的线性高斯系统中进行因果发现。该方法通过分解观测精度矩阵，分离全局潜变量影响与局部依赖关系，再基于去混杂表示进行有向边恢复，并通过简化修正步骤确保无弓形结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理同时存在广泛和局部潜变量混杂时表现不佳：可微分和基于评分的DAG学习方法会将全局潜变量效应误认为因果边，而潜变量图模型仅能恢复无向结构。因此需要一种能区分并分别处理不同类型混杂的新方法。

Method: DCL-DECOR采用模块化流程，首先通过分解观测精度矩阵，将结构化部分（对应去除全局混杂后的条件分布）与低秩部分（代表全局潜变量影响）分离；然后在结构化部分上应用相关噪声DAG学习器以恢复有向边，并建模剩余的结构化误差相关性；最后通过简单修正步骤保证无弓形结构。

Result: 在合成数据实验中，随着全局混杂强度和维度的变化，DCL-DECOR在有向边恢复方面显著优于直接对混杂数据使用相关噪声DAG学习的方法。理论分析提供了在混合混杂下可识别因果目标的条件，并证明整体问题可分解为具有模块化保障的子问题。

Conclusion: DCL-DECOR成功实现了在混合潜变量混杂下的精确因果发现，其模块化设计使各阶段具备清晰的理论保障，且在实验中展现出优越性能。

Abstract: We study causal discovery from observational data in linear Gaussian systems affected by \emph{mixed latent confounding}, where some unobserved factors act broadly across many variables while others influence only small subsets. This setting is common in practice and poses a challenge for existing methods: differentiable and score-based DAG learners can misinterpret global latent effects as causal edges, while latent-variable graphical models recover only undirected structure.
  We propose \textsc{DCL-DECOR}, a modular, precision-led pipeline that separates these roles. The method first isolates pervasive latent effects by decomposing the observed precision matrix into a structured component and a low-rank component. The structured component corresponds to the conditional distribution after accounting for pervasive confounders and retains only local dependence induced by the causal graph and localized confounding. A correlated-noise DAG learner is then applied to this deconfounded representation to recover directed edges while modeling remaining structured error correlations, followed by a simple reconciliation step to enforce bow-freeness.
  We provide identifiability results that characterize the recoverable causal target under mixed confounding and show how the overall problem reduces to well-studied subproblems with modular guarantees. Synthetic experiments that vary the strength and dimensionality of pervasive confounding demonstrate consistent improvements in directed edge recovery over applying correlated-noise DAG learning directly to the confounded data.

</details>


### [171] [FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference](https://arxiv.org/abs/2512.24713)
*Fen-Yu Hsieh,Yun-Chang Teng,Ding-Yong Hong,Jan-Jan Wu*

Main category: cs.LG

TL;DR: 本文提出一种自动化框架，结合权重剪枝与低比特量化，设计了软硬件协同的FPGA加速器，以降低大语言模型（LLM）的存储和计算开销。通过N:M结构化剪枝与4位整数量化，实现高达4倍的权重存储压缩，并在矩阵乘法中获得1.71倍加速，端到端延迟减少1.29倍。在LLaMA-7B上，结构化稀疏性使每令牌吞吐量提升1.36倍。FPGA加速器支持灵活的稀疏模式，超越固定2:4硬件限制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽性能优异，但计算与内存需求高，难以在资源受限环境中部署。需通过模型压缩与硬件优化实现高效推理。

Method: 采用N:M结构化剪枝与4位整数量化构建统一流水线，优化去量化与矩阵乘法，并在CPU、GPU（含密集与2:4稀疏张量核心）及自研基于阵列的FPGA加速器上实现。

Result: 在4096×4096矩阵上，结合2:4稀疏性与量化可实现4倍权重存储压缩，矩阵乘法加速1.71倍，端到端延迟降低1.29倍；在LLaMA-7B上，每令牌吞吐提升1.36倍。FPGA加速器支持多样化稀疏模式。

Conclusion: 细粒度的N:M稀疏性与量化协同可有效提升大语言模型的推理效率，所提出的FPGA加速器为支持多样稀疏模式提供了灵活架构路径，推动轻量级部署。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To address this challenge, this work introduces an automation framework that leverages weight pruning and low-bit quantization, and presents a hardware-software co-design method that generates accelerators on the Field-Programmable Gate Array (FPGA) platform. In particular, we implement a unified pipeline that applies N:M structured pruning and 4-bit integer quantization to reduce the memory footprint, followed by optimized dequantization and matrix multiplication to enhance LLM inference on several hardware platforms, including CPUs, NVIDIA GPUs with Dense and 2:4 Sparse Tensor Cores, and a custom systolic-array-based FPGA accelerator. Utilizing 2:4 sparsity combined with quantization on $4096 \times 4096$ matrices, our approach achieves a reduction of up to $4\times$ in weight storage and a $1.71\times$ speedup in matrix multiplication, yielding a $1.29\times$ end-to-end latency reduction compared to dense GPU baselines. Scaling analysis on the LLaMA-7B model further shows that structured sparsity enhances the throughput per token by $1.36\times$. These results demonstrate the synergy of fine-grained N:M sparsity and quantization for enabling efficient and deployable LLM inference, while the proposed FPGA accelerator offers a flexible architectural path for supporting a broader class of sparsity patterns beyond the fixed 2:4 hardware constraints.

</details>


### [172] [From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis](https://arxiv.org/abs/2512.24767)
*Yutong Cai,Hua Wang*

Main category: cs.LG

TL;DR: 本研究基于武汉百度阿波罗无人出租车服务的实际用户数据，通过结构方程模型分析了六种潜在心理构念对自动驾驶出租车采纳行为的影响。结果显示，成本敏感性和行为意向是采纳的最强正向预测因子，其他因素作用较为复杂。研究为政策制定、定价策略和公众推广提供了实证支持。


<details>
  <summary>Details</summary>
Motivation: 现有文献多基于假设情景研究用户对自动驾驶出租车的接受度，缺乏对实际运营服务中用户行为的实证分析。本研究填补这一空白，利用真实用户数据揭示影响采纳的关键心理因素。

Method: 采用结构方程模型（SEM），基于武汉地区336份有效问卷，分析六个潜在心理构念（信任与政策支持、成本敏感性、性能、行为意向、生活方式、教育水平）对自动驾驶出租车使用频率的影响。

Result: 成本敏感性和行为意向是采纳行为的最强正向预测因子；模型在多个拟合指标上表现良好，具有强解释力。

Conclusion: 研究结果为自动驾驶出租车在真实城市环境中的规模化部署提供了实证依据，有助于优化政策设计、票价机制和公众沟通策略。

Abstract: Autonomous taxi services represent a transformative advancement in urban mobility, offering safety, efficiency, and round-the-clock operations. While existing literature has explored user acceptance of autonomous taxis through stated preference experiments and hypothetical scenarios, few studies have investigated actual user behavior based on operational AV services. This study addresses that gap by leveraging survey data from Wuhan, China, where Baidu's Apollo Robotaxi service operates at scale. We design a realistic survey incorporating actual service attributes and collect 336 valid responses from actual users. Using Structural Equation Modeling, we identify six latent psychological constructs, namely Trust \& Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, and Education. Their influences on adoption behavior, measured by the selection frequency of autonomous taxis in ten scenarios, are examined and interpreted. Results show that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption, while other latent constructs play more nuanced roles. The model demonstrates strong goodness-of-fit across multiple indices. Our findings offer empirical evidence to support policymaking, fare design, and public outreach strategies for scaling autonomous taxis deployments in real-world urban settings.

</details>


### [173] [DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes](https://arxiv.org/abs/2512.24810)
*Bence Bolgár,András Millinghoffer,Péter Antal*

Main category: cs.LG

TL;DR: DTI-GP是一种基于深度核学习的高斯过程架构，用于药物-靶标相互作用（DTI）预测。它结合了化学化合物和蛋白质靶标的神经嵌入模块与高斯过程模块，通过从预测分布中采样估计贝叶斯优先矩阵，实现快速准确的选择与排序操作。该方法在性能上优于现有先进方法，并支持贝叶斯精度-置信度增强评分、拒绝策略以提升富集效果，以及高期望效用的top-K选择与排序估计。


<details>
  <summary>Details</summary>
Motivation: 精确的药物-靶标相互作用预测中的概率信息对于理解模型局限性和提升预测性能至关重要。传统方法在不确定性量化和可解释性方面存在不足，因此需要一种能够整合先进表示学习与贝叶斯推理的可扩展框架。

Method: 提出了一种基于深度核学习的高斯过程架构（DTI-GP），包含联合神经嵌入模块用于处理化合物和蛋白质序列，并结合高斯过程模块进行建模。通过采样预测分布生成贝叶斯优先矩阵，支持多种高效决策操作。

Result: DTI-GP在多个基准数据集上超越了当前最先进的方法，在药物-靶标相互作用预测任务中表现出更高的准确性与鲁棒性；同时实现了贝叶斯精度-置信度增强评分、拒绝机制优化富集效果，以及高期望效用的top-K选择与排序。

Conclusion: DTI-GP提供了一个强大的概率框架，不仅提升了预测性能，还增强了可解释性与决策能力，为药物发现中的关键任务提供了新的工具。

Abstract: Precise probabilistic information about drug-target interaction (DTI) predictions is vital for understanding limitations and boosting predictive performance. Gaussian processes (GP) offer a scalable framework to integrate state-of-the-art DTI representations and Bayesian inference, enabling novel operations, such as Bayesian classification with rejection, top-$K$ selection, and ranking. We propose a deep kernel learning-based GP architecture (DTI-GP), which incorporates a combined neural embedding module for chemical compounds and protein targets, and a GP module. The workflow continues with sampling from the predictive distribution to estimate a Bayesian precedence matrix, which is used in fast and accurate selection and ranking operations. DTI-GP outperforms state-of-the-art solutions, and it allows (1) the construction of a Bayesian accuracy-confidence enrichment score, (2) rejection schemes for improved enrichment, and (3) estimation and search for top-$K$ selections and ranking with high expected utility.

</details>


### [174] [Discovering Coordinated Joint Options via Inter-Agent Relative Dynamics](https://arxiv.org/abs/2512.24827)
*Raul D. Steleac,Mohan Sridharan,David Abel*

Main category: cs.LG

TL;DR: 本文提出了一种新的多智能体选项发现方法，通过联合状态抽象压缩状态空间，同时保留发现强协调行为所需的信息。该方法基于同步性作为协调的自然基础，引入了‘费马状态’来衡量团队层面的错位程度（即‘分散度’），并利用神经图拉普拉斯估计器识别智能体间状态同步模式，从而生成具有更强协作能力的选项。在多个多智能体场景中的实验表明，该方法优于现有选项发现方法。


<details>
  <summary>Details</summary>
Motivation: 在多智能体环境中，联合状态空间随智能体数量呈指数增长，导致协调行为设计困难。现有方法常因产生松散耦合或完全独立的行为而牺牲协调性，因此需要一种能有效发现强协调行为的新方法。

Method: 提出联合状态抽象，通过近似最大对齐的虚构状态（费马状态）定义‘分散度’以衡量团队错位；利用神经图拉普拉斯估计器挖掘智能体间状态同步模式，从而生成协调性更强的选项。

Result: 在多个多智能体任务中，所生成的选项表现出更强的下游协调能力，显著优于现有选项发现方法。

Conclusion: 该方法通过状态同步性建模实现了高效的多智能体协调选项发现，在保持状态空间压缩的同时提升了协作性能，为复杂多智能体系统的设计提供了新思路。

Abstract: Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviours. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the \textit{Fermat} state, and use it to define a measure of \textit{spreadness}, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.

</details>


### [175] [AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference](https://arxiv.org/abs/2512.24847)
*Linhao Fan,Hongqiang Fang,Jingyang Dai,Yong Jiang,Qixing Zhang*

Main category: cs.LG

TL;DR: AODDiff 是一种基于扩散的贝叶斯推理的概率重建框架，用于高精度气溶胶光学深度（AOD）场重建。该方法通过从不完整数据中学习时空概率分布作为生成先验，实现无需任务特定重训练的灵活适应。采用污染感知训练策略和解耦退火后验采样策略，有效融合异构观测数据以指导生成过程。在再分析数据上的实验验证了其在降尺度和补全任务中的有效性与鲁棒性，尤其在保持高空间频谱保真度方面表现优异。同时，作为生成模型，AODDiff 可通过多采样实现不确定性量化，为下游应用提供关键置信度指标。


<details>
  <summary>Details</summary>
Motivation: 当前AOD重建模型受限于完整训练数据稀缺及缺乏不确定性量化，影响大气监测的精度与可靠性。因此亟需一种能够处理不完整数据、具备不确定性评估能力的高效重建方法。

Method: 提出AODDiff框架，结合扩散模型与贝叶斯推理；采用污染感知训练策略学习自然不完整数据下的时空AOD先验；引入解耦退火后验采样策略，提升异构观测数据的整合效率与生成质量。

Result: 在再分析数据上的实验表明，AODDiff在降尺度和补全任务中均表现出色，显著优于现有方法，尤其在保持高空间频谱保真度方面优势明显；同时可自动生成不确定性估计，支持下游应用的可信决策。

Conclusion: AODDiff是一种高效、灵活且具备不确定性量化能力的AOD重建框架，适用于多种复杂场景，为大气监测提供了可靠的技术支撑。

Abstract: High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty quantification.To address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.

</details>


### [176] [Characterization of Transfer Using Multi-task Learning Curves](https://arxiv.org/abs/2512.24866)
*András Millinghoffer,Bence Bolgár,Péter Antal*

Main category: cs.LG

TL;DR: 本文提出通过增加样本而非调整模型参数来更根本地刻画迁移效应，使用多任务学习曲线量化分析不同样本量下的归纳性能。研究提出一种高效方法近似多任务学习曲线，与任务亲和分组方法类似，并比较了统计与计算方法的优劣，发现后者虽计算成本高但具有更强的性能和更广的应用范围。实验基于药物-靶点相互作用数据集，结果表明学习曲线能更好捕捉多任务学习效果，其扩展形式可揭示基础模型中的成对和上下文迁移效应。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过梯度更新扰动模型来研究迁移效应，但本文认为通过增加样本量来扰动数据集可能提供更根本且互补的视角，从而更准确刻画迁移效果。

Method: 采用多任务学习曲线建模，在不同样本规模下评估归纳性能；提出一种高效的近似方法，类似于任务亲和分组，用于快速估算多任务学习行为。

Result: 实验结果显示，学习曲线能更有效地捕捉多任务学习的迁移效应；多任务扩展形式能够清晰识别出基础模型中的成对和上下文依赖性迁移特征。

Conclusion: 以样本量变化为基础的多任务学习曲线是一种更有效、更具解释性的迁移效应分析工具，尤其适用于基础模型中复杂迁移行为的建模与理解。

Abstract: Transfer effects manifest themselves both during training using a fixed data set and in inductive inference using accumulating data. We hypothesize that perturbing the data set by including more samples, instead of perturbing the model by gradient updates, provides a complementary and more fundamental characterization of transfer effects. To capture this phenomenon, we quantitatively model transfer effects using multi-task learning curves approximating the inductive performance over varying sample sizes. We describe an efficient method to approximate multi-task learning curves analogous to the Task Affinity Grouping method applied during training. We compare the statistical and computational approaches to transfer, which indicates considerably higher compute costs for the previous but better power and broader applicability. Evaluations are performed using a benchmark drug-target interaction data set. Our results show that learning curves can better capture the effects of multi-task learning and their multi-task extensions can delineate pairwise and contextual transfer effects in foundation models.

</details>


### [177] [Frequent subgraph-based persistent homology for graph classification](https://arxiv.org/abs/2512.24917)
*Xinyang Chen,Amaël Broustet,Guoting Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于频繁子图的新型图过滤方法（FSF），用于生成更丰富、稳定的频率基持久同调（FPH）特征。通过结合频繁子图挖掘与拓扑数据分析，构建了FPH-ML和FPH-GNN两种图分类框架，在多个基准测试中表现出色，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于持久同调的图分析方法多依赖于有限的过滤方式（如度或权重过滤），难以捕捉数据集中重复出现的信息，限制了其表达能力。为增强拓扑特征的丰富性和稳定性，需引入更有效的过滤机制。

Method: 提出频繁子图过滤（FSF），利用频繁子图构造过滤序列，生成频率基持久同调特征；设计FPH-ML模型与融合FPH的GNN框架（FPH-GNN），实现拓扑感知的图表示学习。

Result: FPH-ML在分类任务中表现优于或相当传统方法；集成至GNN后，性能相对提升0.4%至21%，最高较GCN/GIN提升8.2个百分点。

Conclusion: FSF有效提升了持久同调在图数据中的表达能力，所提出的FPH-ML与FPH-GNN框架为拓扑感知的图学习提供了新范式，具有良好的理论支持与实验验证。

Abstract: Persistent homology (PH) has recently emerged as a powerful tool for extracting topological features. Integrating PH into machine learning and deep learning models enhances topology awareness and interpretability. However, most PH methods on graphs rely on a limited set of filtrations, such as degree-based or weight-based filtrations, which overlook richer features like recurring information across the dataset and thus restrict expressive power. In this work, we propose a novel graph filtration called Frequent Subgraph Filtration (FSF), which is derived from frequent subgraphs and produces stable and information-rich frequency-based persistent homology (FPH) features. We study the theoretical properties of FSF and provide both proofs and experimental validation. Beyond persistent homology itself, we introduce two approaches for graph classification: an FPH-based machine learning model (FPH-ML) and a hybrid framework that integrates FPH with graph neural networks (FPH-GNNs) to enhance topology-aware graph representation learning. Our frameworks bridge frequent subgraph mining and topological data analysis, offering a new perspective on topology-aware feature extraction. Experimental results show that FPH-ML achieves competitive or superior accuracy compared with kernel-based and degree-based filtration methods. When integrated into graph neural networks, FPH yields relative performance gains ranging from 0.4 to 21 percent, with improvements of up to 8.2 percentage points over GCN and GIN backbones across benchmarks.

</details>


### [178] [MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control](https://arxiv.org/abs/2512.24955)
*Yongwei Zhang,Yuanzhe Xing,Quan Quan,Zhikun She*

Main category: cs.LG

TL;DR: MSACL integrates exponential stability theory with maximum entropy RL using multi-step Lyapunov certificate learning, enabling provably stable, safe, and efficient model-free RL without complex reward engineering. It uses Exponential Stability Labels (ESL) and a $\lambda$-weighted aggregation to balance bias-variance in multi-step learning, guides policy optimization via a stability-aware advantage function, and demonstrates superior performance across six benchmarks with robustness to uncertainties and generalization to unseen trajectories. The optimal multi-step horizon is found to be $n=20$.


<details>
  <summary>Details</summary>
Motivation: Achieving provable stability in model-free reinforcement learning remains challenging, especially in balancing exploration and safety. Existing methods often rely on complex reward engineering, which limits generalization and verifiability.

Method: MSACL employs off-policy multi-step data to learn Lyapunov certificates that satisfy theoretical stability conditions. It introduces Exponential Stability Labels (ESL) and a $\lambda$-weighted aggregation mechanism to manage the bias-variance trade-off in multi-step learning. A stability-aware advantage function guides policy optimization to ensure rapid Lyapunov descent.

Result: MSACL achieves exponential stability and fast convergence under simple rewards, shows strong robustness to system uncertainties, generalizes well to unseen trajectories, and outperforms state-of-the-art Lyapunov-based RL methods across six benchmarks. Sensitivity analysis identifies $n=20$ as a robust default multi-step horizon.

Conclusion: By connecting Lyapunov theory with off-policy actor-critic frameworks, MSACL provides a verifiable foundation for safe learning-based control, enabling stable, robust, and generalizable model-free RL without reliance on intricate reward shaping.

Abstract: Achieving provable stability in model-free reinforcement learning (RL) remains a challenge, particularly in balancing exploration with rigorous safety. This article introduces MSACL, a framework that integrates exponential stability theory with maximum entropy RL through multi-step Lyapunov certificate learning. Unlike methods relying on complex reward engineering, MSACL utilizes off-policy multi-step data to learn Lyapunov certificates satisfying theoretical stability conditions. By introducing Exponential Stability Labels (ESL) and a $λ$-weighted aggregation mechanism, the framework effectively balances the bias-variance trade-off in multi-step learning. Policy optimization is guided by a stability-aware advantage function, ensuring the learned policy promotes rapid Lyapunov descent. We evaluate MSACL across six benchmarks, including stabilization and nonlinear tracking tasks, demonstrating its superiority over state-of-the-art Lyapunov-based RL algorithms. MSACL achieves exponential stability and rapid convergence under simple rewards, while exhibiting significant robustness to uncertainties and generalization to unseen trajectories. Sensitivity analysis establishes the multi-step horizon $n=20$ as a robust default across diverse systems. By linking Lyapunov theory with off-policy actor-critic frameworks, MSACL provides a foundation for verifiably safe learning-based control. Source code and benchmark environments will be made publicly available.

</details>


### [179] [Scaling Open-Ended Reasoning to Predict the Future](https://arxiv.org/abs/2512.25070)
*Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping*

Main category: cs.LG

TL;DR: 本文提出一种基于语言模型的高风险决策预测方法，通过自动化从每日新闻中合成开放性预测问题，构建了名为OpenForesight的数据集，并训练Qwen3系列模型（OpenForecaster 8B）进行时间序列预测。为防止未来信息泄露，采用离线新闻语料库进行数据生成与检索。实验表明，引入检索机制和改进的强化学习奖励函数可提升预测准确性、校准性和一致性；模型在2025年5月至8月的独立测试中表现优于大型专有模型，且校准能力在多个基准上具有泛化性。所有模型、代码与数据均开源，推动语言模型预测研究的开放发展。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在高风险决策中的预测能力受限于训练数据不足和未来信息泄露风险，亟需可扩展、可信的预测训练框架以提升模型对不确定未来的推理能力。

Method: 通过自动化流程从全球新闻中合成开放性预测问题，构建离线新闻驱动的OpenForesight数据集；使用该数据训练Qwen3系列模型，结合检索增强与改进的强化学习奖励函数优化预测性能；通过离线验证与持留测试评估模型表现。

Result: OpenForecaster 8B模型在预测准确率、校准度和一致性方面显著优于更大规模的专有模型；训练带来的校准改进可在多个基准任务中泛化；模型在2025年5-8月的持留测试中表现稳健。

Conclusion: 通过系统化的数据合成与训练策略，可有效提升语言模型在开放性长期预测任务中的表现；开源全部资源将促进该领域研究的透明与进步。

Abstract: High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.

</details>


### [180] [Attribution-Guided Distillation of Matryoshka Sparse Autoencoders](https://arxiv.org/abs/2512.24975)
*Cristina P. Martin-Linares,Jonathan P. Ling*

Main category: cs.LG

TL;DR: DMSAEs 是一种通过迭代蒸馏过程，从 Matryoshka Sparse Autoencoders 中提取稳定、可复用的核心特征集的方法。该方法仅保留对预测下一个词损失贡献最大的最小特征子集，并在多轮训练中复用核心编码器权重，显著提升了特征的一致性和可解释性，在 Gemma-2-2B 模型上实现了更优的 SAEBench 性能。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器（SAEs）学习到的特征存在冗余、不一致且难以跨训练运行和稀疏度复用的问题，影响了其人类可解释性与实用性。因此需要一种能够生成稳定、可转移特征集的训练框架。

Method: 提出 Distilled Matryoshka Sparse Autoencoders (DMSAEs)，采用迭代蒸馏机制：训练带有共享核心的 Matryoshka SAE；利用梯度X激活分析每个特征对下一个词预测损失的贡献；保留最小但能解释固定比例损失的特征子集；仅传递核心编码器权重，其余参数每次重置。

Result: 在 Gemma-2-2B 层12 的残差流上，经过7轮蒸馏（500M tokens，65k 宽度），得到一个稳定的197个特征核心，这些特征在多轮中反复被选中；使用该核心训练新SAE显著提升了多个SAEBench指标。

Conclusion: 通过DMSAEs可以成功提取并复用一组在不同稀疏度下一致且有用的特征，证明了可转移的语义特征核心的存在，为SAE的可解释性和稳定性提供了有效解决方案。

Abstract: Sparse autoencoders (SAEs) aim to disentangle model activations into monosemantic, human-interpretable features. In practice, learned features are often redundant and vary across training runs and sparsity levels, which makes interpretations difficult to transfer and reuse. We introduce Distilled Matryoshka Sparse Autoencoders (DMSAEs), a training pipeline that distills a compact core of consistently useful features and reuses it to train new SAEs. DMSAEs run an iterative distillation cycle: train a Matryoshka SAE with a shared core, use gradient X activation to measure each feature's contribution to next-token loss in the most nested reconstruction, and keep only the smallest subset that explains a fixed fraction of the attribution. Only the core encoder weight vectors are transferred across cycles; the core decoder and all non-core latents are reinitialized each time. On Gemma-2-2B layer 12 residual stream activations, seven cycles of distillation (500M tokens, 65k width) yielded a distilled core of 197 features that were repeatedly selected. Training using this distilled core improves several SAEBench metrics and demonstrates that consistent sets of latent features can be transferred across sparsity levels

</details>


### [181] [Efficiently Estimating Data Efficiency for Language Model Fine-tuning](https://arxiv.org/abs/2512.24991)
*Gyung Hyun Je,Colin Raffel*

Main category: cs.LG

TL;DR: 本文提出一种基于低置信度样本梯度余弦相似性的方法，用于预测大语言模型在特定任务上的数据效率，从而减少不必要的标注和训练循环。该方法在30个专业化任务上验证，整体预测误差为8.6%，显著降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 由于任务的数据效率（即达到理想性能所需的微调样本数）通常未知，导致频繁的标注与重训练，造成资源浪费。因此需要一种无需额外标注即可预测数据效率的方法。

Method: 引入一个量化任务数据效率的指标，并利用少量标注样本中低置信度例子的梯度余弦相似性来预测数据效率。

Result: 在多样化任务上验证，整体数据效率预测误差为8.6%，多数任务可减少数百次不必要的标注。实验结果与代码已公开于GitHub。

Conclusion: 所提方法能有效预测任务数据效率，显著降低微调过程中的标注开销，具有实际应用价值。

Abstract: While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task's data efficiency--i.e., the number of fine-tuning examples needed to achieve a desired level of performance--is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task's data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task's data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.

</details>


### [182] [Diffusion Language Models are Provably Optimal Parallel Samplers](https://arxiv.org/abs/2512.25014)
*Haozhe Jiang,Nika Haghtalab,Lijie Chen*

Main category: cs.LG

TL;DR: 扩散语言模型（DLMs）通过并行生成令牌实现更快推理，本文从理论上证明其在使用多项式长度思维链（CoT）时能以最优序列步骤模拟任何并行采样算法。若无修改已生成令牌的能力，DLMs会产生较大的中间存储开销；但引入重掩码（remasking）或修订（revision）机制后，DLMs可实现最优空间复杂度。研究还揭示了具备修订能力的DLMs在表达能力上严格优于不具此能力的模型，从而为DLMs作为最高效并行采样器提供了理论支持，并倡导在DLM中启用修订功能。


<details>
  <summary>Details</summary>
Motivation: 探索扩散语言模型（DLMs）在并行采样中的理论优势，特别是其在推理速度与空间效率上的潜力，同时揭示现有方法在中间状态管理上的局限性。

Method: 通过构建并行采样模型，形式化分析DLMs在不同条件下（是否具备重掩码或修订能力）对任意并行采样算法的模拟能力，结合空间复杂度与表达力比较进行理论证明。

Result: DLMs结合多项式长度思维链可实现最优序列步骤模拟；引入重掩码或修订机制后，可实现最优空间复杂度；具备修订能力的DLMs具有严格更高的表达能力。

Conclusion: DLMs在并行采样方面具有理论优势，尤其在引入修订机制后，不仅提升效率，还增强表达能力，应被优先采纳于实际系统设计中。

Abstract: Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.

</details>


### [183] [Generative Classifiers Avoid Shortcut Solutions](https://arxiv.org/abs/2512.25034)
*Alexander C. Li,Ananya Kumar,Deepak Pathak*

Main category: cs.LG

TL;DR: 生成式分类器通过建模所有特征（包括核心和虚假相关特征）来避免判别式分类器在分布偏移下的失败，无需特殊增强、强正则化或额外超参数，在多个图像和文本分布偏移基准上达到最先进性能，并在医学和卫星数据等真实应用中有效减少虚假相关性的影响。


<details>
  <summary>Details</summary>
Motivation: 判别式分类器容易依赖与标签虚假相关的特征，在分布偏移下表现不佳；需要一种更鲁棒的分类方法来避免这种过拟合于虚假相关性的倾向。

Method: 使用类条件生成模型构建生成式分类器，采用基于扩散和自回归的生成模型，不依赖特定增强或正则化策略，直接建模全部输入特征。

Result: 在五个标准分布偏移基准上取得最先进的性能，显著降低虚假相关性的影响；在真实场景如医疗和卫星图像中表现出更强的鲁棒性。

Conclusion: 生成式分类器通过建模所有特征，具备更强的分布外泛化能力，其优势源于对数据整体结构的建模，而非仅依赖虚假相关特征。在某些数据条件下，生成式方法优于判别式方法。

Abstract: Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [184] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 本文提出了一种名为钻探与虚构测试（DDFT）的新评估协议，用于衡量语言模型在语义压缩和对抗性伪造压力下的知识稳健性。研究发现，模型的稳健性与参数量或架构类型无关，而是取决于验证机制和训练方法，错误检测能力是决定稳健性的关键因素。小模型有时比大模型更稳健，挑战了规模即可靠的传统认知。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试如MMLU和TruthfulQA仅在理想条件下评估模型知识，无法反映模型在信息退化或对抗攻击下的表现。需要一种新方法来评估模型在真实场景中的知识稳健性。

Method: 提出双系统认知模型：语义系统生成流畅文本，验证系统检查事实准确性；通过DDFT协议，在8个知识领域、5个压缩层级下对9个前沿模型进行1800次逐轮评估。

Result: epistemic robustness与参数量（r=0.083, p=0.832）和架构类型（r=0.153, p=0.695）无显著相关性，但错误检测能力与稳健性高度负相关（rho=-0.817, p=0.007），表明验证机制是核心瓶颈。大模型仍表现出脆弱性，而小模型可实现稳健表现。

Conclusion: epistemic robustness独立于传统设计范式，其关键在于训练方法和验证机制。该研究为部署前评估模型可靠性提供了理论基础与实用工具。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [185] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: McCoy 是一个结合大语言模型（LLM）与答案集编程（ASP）的框架，用于克服医疗知识库构建困难的问题。它利用 LLM 将医学文献转化为 ASP 代码，并与患者数据结合，通过 ASP 求解器进行诊断推理，实现可解释且高效的疾病预测。初步实验表明其在小规模疾病诊断任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 当前符号 AI 在医疗领域的应用受限于高质量知识库构建的高成本和复杂性。为降低这一门槛，需要一种自动化、高效的方法来将医学文献转化为可计算的逻辑知识。

Method: McCoy 框架通过 LLM 自动将医学文献转换为 ASP 代码，整合患者临床数据，使用 ASP 求解器进行逻辑推理，生成可解释的诊断结果。

Result: 在小规模疾病诊断任务上，McCoy 展现了良好的性能，验证了其在自动化知识转化与可解释推理方面的有效性。

Conclusion: McCoy 有效融合了 LLM 的自然语言理解能力与 ASP 的形式化推理优势，为医疗领域中的可解释疾病预测提供了一种可行的新范式。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [186] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow 是一种自进化智能体框架，通过将大语言模型（LLM）融入‘规划-执行-总结’（PES）认知范式，解决传统进化方法在高维代码空间中易早熟收敛和探索效率低的问题。其采用混合进化记忆系统，结合多岛模型、MAP-Elites与自适应玻尔兹曼选择，有效平衡探索与利用，维持多样行为谱系。在AlphaEvolve和Kaggle任务中，LoongFlow相比OpenEvolve、ShinkaEvolve等基线提升60%进化效率并发现更优解，显著降低计算成本，推动自主科学发现发展。


<details>
  <summary>Details</summary>
Motivation: 传统进化方法在高维代码空间中面临早熟收敛和低效探索问题，缺乏结构化推理能力，限制了从静态大语言模型向自进化智能体的过渡。

Method: 提出LoongFlow框架，采用'规划-执行-总结'（PES）范式整合LLM进行推理驱动进化；引入混合进化记忆系统，结合多岛模型、MAP-Elites与自适应玻尔兹曼选择，实现长期架构一致性与多样化探索。

Result: 在AlphaEvolve和Kaggle基准测试中，LoongFlow比现有基线（如OpenEvolve、ShinkaEvolve）提升最高达60%的进化效率，生成更优解决方案，同时大幅降低计算开销。

Conclusion: LoongFlow实现了高效且高质量的自进化过程，为自主科学发现提供了新范式，显著提升了生成专家级解决方案的能力，同时降低了资源消耗。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [187] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: 提出了一种名为风险感知逐步对齐（RSA）的新方法，通过引入嵌套风险度量，在语言模型微调中显式地纳入风险意识，以应对参考策略偏离带来的风险和罕见但高影响的有害行为。该方法在词元级别进行风险感知的约束策略优化，并通过逐步对齐过程实现更新，有效减少模型过度偏离参考策略的风险，同时抑制低概率高危害行为。实验表明，RSA在保持高度帮助性的同时显著降低了尾部风险，提升了安全性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法如Safe RLHF和SACPO通常采用风险中立范式，无法充分应对模型偏离参考策略所引发的风险，且对罕见但可能造成灾难性后果的有害行为缺乏足够鲁棒性，因此需要一种更具风险意识的对齐机制。

Method: RSA将安全对齐建模为一个词元级别的风险感知约束策略优化问题，利用嵌套风险度量设计逐步对齐过程，生成基于风险度量的词元级策略更新，从而在优化过程中显式考虑风险因素。

Result: 实验结果显示，RSA在保持高水平帮助性的同时，显著增强了安全性，有效抑制了低概率但高影响的不安全响应（即尾部风险），表现出更强的鲁棒性与风险控制能力。

Conclusion: RSA通过引入风险感知机制，实现了更安全、更可靠的模型对齐，在保障性能的同时有效降低极端风险，为构建可信的语言模型提供了新路径。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [188] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 本研究评估了GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3三款主流大语言模型在密苏里大学数学竞赛题（涵盖微积分、解析几何和离散数学）上的表现，发现DeepSeek-V3在三个领域均表现最佳，但所有模型在几何题上表现较差。错误分析显示，DeepSeek-V3主要犯计算与逻辑错误，GPT-4o-mini常出现逻辑与解题策略错误，Gemini则多因推理不完整或过早下结论。研究强调使用非主流数学竞赛数据集有助于揭示模型在结构化推理中的局限性，尤其在几何领域仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖相同数据集评估大语言模型的数学推理能力，导致结果泛化性受限，无法全面反映数学任务的多样性挑战。因此，有必要引入未被充分研究的数学竞赛题目以更深入理解模型的局限性。

Method: 选取密苏里大学数学竞赛中的微积分、解析几何和离散数学题目作为测试集，对GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3进行提示，并将模型输出与标准答案对比，分析准确率及错误模式。通过定性分析模型推理过程，识别各类错误类型及其分布规律。

Result: DeepSeek-V3在所有三个领域中表现最优，但在几何题上仍表现不佳；所有模型在几何任务中普遍表现弱。具体而言，DeepSeek-V3主要出错于计算与逻辑错误，GPT-4o-mini多为逻辑与解题方法错误，Gemini则存在推理不完整和过早下结论的问题。

Conclusion: 在非主流数学竞赛数据集上评估大语言模型可更深入揭示其错误模式，凸显模型在结构化推理，尤其是几何推理方面仍存在显著挑战，建议未来研究应拓展多样化、高难度数学任务以提升评估全面性。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [189] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 该论文提出一种两阶段方法，将空间推理分解为基本构建块及其组合。首先通过监督微调训练模型掌握旋转、平移、缩放等基础空间变换，赋予其基本物理理解能力；随后冻结该模型，利用轻量级LoRA适配器在GRPO框架下进行多步规划策略学习，实现闭合环路的组合推理。研究构建了基于ASCII艺术的合成数据集和强化学习环境以支持该流程。实验表明，该方法在动态与静态环境中均优于基线模型（包括通用主干、物理感知模型和端到端强化学习模型），收敛更快且训练更稳定。最后通过注意力模式分析验证了微调对空间理解的实质性提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具备强大的语言能力，但在结构化环境中仍难以处理空间变换和多步规划任务。现有方法在复杂空间推理方面表现不佳，缺乏对基本空间物理规律的有效建模与组合能力。因此需要一种能够系统化分解并逐步学习空间推理能力的方法。

Method: 提出两阶段方法：第一阶段采用监督微调训练模型掌握旋转、平移、缩放等基本空间变换，形成物理感知能力；第二阶段冻结前一阶段模型，使用轻量级LoRA适配器在GRPO框架中训练多步规划策略，通过闭合环路方式组合基础变换完成复杂任务。同时构建了基于ASCII的艺术数据集和对应的强化学习环境以支持训练与评估。

Result: 所提方法在动态和静态环境下均显著优于多种基线模型，包括通用主干模型、物理感知模型及端到端强化学习模型。不仅性能更优，且训练收敛更快、稳定性更高。注意力分析显示微调有效提升了模型对空间关系的理解能力。

Conclusion: 通过将空间推理分解为可学习的基本构建块并分阶段训练，该方法有效增强了大语言模型在复杂空间任务中的推理能力，为解决多步空间规划问题提供了高效且稳定的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [190] [MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use](https://arxiv.org/abs/2512.24565)
*Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang*

Main category: cs.AI

TL;DR: 提出MCPAgentBench，一个基于真实MCP定义的基准测试，用于评估大语言模型在使用外部工具时的能力。该基准包含真实任务和模拟工具，采用动态沙盒环境测试模型的工具选择与辨别能力，并引入综合指标衡量任务完成率与执行效率。实验表明不同主流大模型在处理复杂多步工具调用时表现差异显著。代码开源。


<details>
  <summary>Details</summary>
Motivation: 现有MCP评估集依赖外部MCP服务且缺乏难度感知，难以全面评估大模型在真实场景下的工具使用能力。

Method: 构建基于真实MCP定义的MCPAgentBench基准，包含真实任务与模拟工具；设计动态沙盒环境，提供含干扰项的工具列表以测试模型的工具选择与辨别能力；引入任务完成率与执行效率等综合评估指标。

Result: 实验显示主流大模型在复杂多步工具调用任务中表现差异明显，验证了基准的有效性与区分度。

Conclusion: MCPAgentBench为评估大语言模型的工具使用能力提供了可靠、可扩展且贴近实际的基准，有助于推动自主智能体的发展。

Abstract: Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.

</details>


### [191] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: 本文提出了一种名为递归语言模型（RLMs）的通用推理策略，使大语言模型（LLMs）能够处理远超其上下文窗口长度的提示。该方法将长提示视为外部环境，允许模型程序化地检查、分解并递归调用自身处理提示片段。实验表明，RLMs可处理比模型上下文窗口长两个数量级的输入，并在四种不同长上下文任务中显著优于基础LLM和常见长上下文方法，同时保持相当或更低的查询成本。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型受限于固定上下文窗口，难以有效处理超长提示。如何在不牺牲性能的前提下扩展模型处理长输入的能力，是当前研究的重要挑战。

Method: 提出递归语言模型（RLMs），通过将长提示视为外部环境，使模型能够程序化地分解提示、递归调用自身处理子片段，实现对超长输入的高效处理。

Result: RLMs成功处理了超出模型上下文窗口两个数量级的输入；在多种长上下文任务中，性能显著优于基线模型和常见的长上下文处理方案，且查询成本相当或更低。

Conclusion: 递归语言模型（RLMs）是一种高效、可扩展的推理策略，能够在不增加计算成本的情况下显著提升大语言模型对长输入的处理能力，为长文本理解与生成提供了新范式。

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [192] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 本文提出一种增强型强化学习的多智能体大语言模型框架，将协作建模为去中心化部分可观测马尔可夫决策过程（Dec-POMDP），采用集中训练、去中心化执行（CTDE）策略。引入组相对策略优化（GRPO）方法，在训练中利用全局信号联合优化各智能体策略，并设计简化联合奖励以平衡任务质量、速度与协调成本。在协同写作和编程基准上，该框架相比单智能体基线提升3倍任务处理速度，写作结构/风格一致性达98.7%，编程测试通过率达74.6%，显著优于现有强大多智能体基线，为复杂工作流中的可靠协作提供了实用路径。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在单任务中表现良好，但在多智能体协作场景下缺乏协同意识，难以优化全局性能。现有方法在协调效率、任务一致性与执行速度之间存在权衡，亟需一种能有效提升多智能体协作能力的系统性框架。

Method: 将多智能体协作建模为Dec-POMDP问题，采用集中训练、去中心化执行（CTDE）范式；提出组相对策略优化（GRPO）算法，利用全局信号在训练阶段联合优化各智能体策略；设计简化联合奖励函数，综合考虑任务质量、完成速度与协调开销。

Result: 在协同写作任务中实现98.7%的结构与风格一致性；在编程任务中达到74.6%的测试通过率；任务处理速度相较单智能体基线提升3倍；整体性能超越多个强大多智能体基线模型。

Conclusion: 所提出的框架有效提升了多智能体大语言模型在复杂协作任务中的表现，通过联合优化与合理的奖励设计，实现了高效、一致且可扩展的协作能力，为构建实际可用的智能协作系统提供了可行方案。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [193] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 该论文提出一种面向群体讨论的多智能体对话模型，通过三层次角色分工（生成、验证、整合）和自博弈机制，提升复杂推理任务中的准确性和一致性。模型在HotpotQA、2WikiMultihopQA和MeetingBank上分别实现16.8%、14.3%和19.2%的多跳推理准确率提升，一致性提高21.5%，且推理效率优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型在复杂推理任务中存在局限性，难以充分挖掘多角度推理路径并保证事实一致性和逻辑连贯性，亟需一种更高效、稳定的多智能体协作框架。

Method: 采用生成、验证、整合三层次角色分工架构；引入自博弈机制扩展多路径推理轨迹；使用检索增强模块动态补充外部知识；设计融合事实一致性和逻辑连贯性的复合奖励函数；采用改进的近端策略优化算法进行协同训练。

Result: 在HotpotQA、2WikiMultihopQA和MeetingBank数据集上，多跳推理准确率分别提升16.8%、14.3%和19.2%，一致性提升21.5%，推理效率高于主流多智能体方法。

Conclusion: 所提出的多智能体模型有效提升了复杂推理任务中的准确性、一致性和效率，为解决高难度推理问题提供了一种稳定且高效的解决方案。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [194] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 提出一种多模态跨域混合融合模型，通过双解耦框架分离模态和领域不变/特定特征，结合跨域混合融合与三模态自适应融合机制，在未见工况下实现更优的故障诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能故障诊断方法在未知工作条件下性能下降明显，且依赖目标域样本的域适应方法受限；同时多数研究仅使用单模态信号，忽视多模态信息互补性，影响模型泛化能力。

Method: 设计双解耦框架以分离模态-不变/特定特征及领域-不变/特定表示；引入跨域混合融合策略增强模态与领域多样性；采用三模态融合机制自适应整合异构多模态信息。

Result: 在恒定与时变工况下的异步电机故障诊断实验中，所提方法显著优于现有先进方法，消融实验证明各组件有效性及多模态融合优势。

Conclusion: 该方法有效提升了多模态数据下的跨域故障诊断性能，具备强泛化能力，适用于真实复杂场景。

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [195] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 本文提出BatteryAgent，一个融合物理知识与大语言模型推理能力的分层框架，用于锂离子电池故障诊断。该框架包含物理感知层（基于电化学原理提取10个机制特征）、检测与归因层（使用梯度提升树和SHAP量化特征贡献）以及推理与诊断层（利用LLM结合SHAP attributions与机制知识库生成包含故障类型、根因分析和维护建议的综合报告）。实验表明，BatteryAgent在硬边界样本上纠正误判，达到0.986的AUROC，显著优于现有方法，并实现从二分类检测到多类型可解释诊断的范式转变。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽有高检测精度，但存在黑箱问题，且受限于二分类范式，无法提供根因分析和维护建议，难以满足电池安全管理系统对可解释性和智能决策的需求。

Method: 提出BatteryAgent分层框架，包括：(1) 物理感知层，提取10个基于电化学机制的特征；(2) 检测与归因层，采用梯度提升决策树与SHAP进行特征贡献量化；(3) 推理与诊断层，利用大语言模型构建数值-语义桥梁，结合SHAP attributions与机制知识库生成诊断报告。

Result: BatteryAgent在硬边界样本上有效纠正误判，实现0.986的AUROC，显著优于现有先进方法；框架将传统二分类检测扩展为多类型可解释诊断，推动电池安全管理从被动检测向智能诊断演进。

Conclusion: BatteryAgent通过融合物理知识与大语言模型推理能力，实现了高精度、可解释、可操作的电池故障诊断，为电池安全管理系统提供了新的智能诊断范式。

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [196] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 本文提出了一种可解释的物品摆放偏好框架，包含四个维度：空间实用性、习惯便利性、语义一致性与常识适宜性。通过63名参与者在线问卷验证了这些维度的心理独立性和解释力，并将其集成到蒙特卡洛树搜索（MCTS）规划器中，使机器人生成的布局与人类偏好高度一致。


<details>
  <summary>Details</summary>
Motivation: 现有机器人家庭物品重排系统依赖从人类示范中推断的隐式偏好模型，缺乏对人类决策背后可解释因素的理解。

Method: 设计并验证了一个自评问卷，通过在线实验收集数据，识别和量化四类可解释的摆放偏好；将这些偏好嵌入蒙特卡洛树搜索（MCTS）规划器中进行布局生成。

Result: 问卷结果确认了四类偏好的心理独立性与跨场景解释力；基于用户偏好指导的MCTS规划器生成的布局与人类选择高度相似，表明该框架具有实际应用价值。

Conclusion: 本文提出了一个简洁、可解释的物品摆放偏好模型，并成功将其应用于机器人规划，提升了人机协同布局的合理性与可解释性。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [197] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: GenZ 是一种混合模型，通过可解释的语义特征连接基础模型与统计建模。它通过迭代对比统计建模误差识别的项目组，发现数据集特定的语义特征，而非依赖基础模型的通用知识。该方法采用广义 EM 算法联合优化语义特征描述和统计模型参数，利用冻结的基础模型对项目进行分类，将判断视为对潜在二值特征的噪声观测，并通过学习的统计关系预测实值目标。在房价预测和冷启动协同过滤两个领域均表现优异：房价预测中相对误差降低至12%（优于GPT-5的38%），电影推荐中仅用语义描述即达到0.59的余弦相似度，相当于传统方法需4000次评分才能达到的效果。发现的特征揭示了数据集特有的模式，如建筑细节影响本地房价、系列归属影响用户偏好，这些超越了基础模型的通用理解。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具备广泛领域知识，但在捕捉预测任务中的数据集特异性模式方面表现不佳。现有方法依赖模型的通用理解，难以发现真实数据中隐藏的细微规律。因此需要一种能结合基础模型能力与统计建模优势的方法，以提取可解释且具有预测力的语义特征。

Method: 提出GenZ框架，基于广义EM算法，通过对比统计建模误差识别出的项目组，迭代发现语义特征描述；利用冻结的基础模型生成对项目是否具备某特征的分类判断，将其作为噪声观测，构建潜变量模型，联合优化语义特征描述与统计模型参数，实现从语义特征到目标值的预测。

Result: 在房屋价格预测任务中，GenZ实现12%的中位相对误差，显著优于依赖通用知识的GPT-5基线（38%误差）；在冷启动电影推荐任务中，仅凭语义描述即可达到0.59的余弦相似度，性能相当于传统协同过滤需约4000个用户评分的结果；所发现的特征反映数据集特有规律，如建筑细节影响本地房价、系列归属影响用户偏好。

Conclusion: GenZ成功实现了基础模型与统计建模的融合，通过可解释的语义特征提升预测性能，并揭示出超越模型通用知识的数据集特异性模式，为复杂预测任务提供了一种高效、可解释的新范式。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [198] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 本文提出了一种基于约束模板的自动调度约束提取方法，用于长期护理机构。该方法通过灵活调整天数、人员数量及关注重点（如班次模式或频率），有效提取多种约束，并排除异常约束，从而帮助约束规划求解器生成满足硬约束且软约束违规最少的护理人员排班方案。实验表明该方法在实际应用中表现良好。


<details>
  <summary>Details</summary>
Motivation: 长期护理机构的排班条件因机构而异，现有自动排班技术难以适应不同设施的具体需求，因此需要通过访谈管理人员来设计特定约束。同时，传统约束提取方法常包含异常约束，影响排班质量。

Method: 提出基于约束模板的方法，通过可变参数（如天数、人员数）和可切换的关注焦点（模式或频率），动态生成各类排班约束，并引入机制过滤异常约束。

Result: 实验结果显示，所提方法能生成完全满足硬约束的排班表，并显著减少软约束的违反次数，尤其得益于对异常约束的排除。

Conclusion: 该方法有效提升了长期护理机构排班系统的灵活性与实用性，为个性化排班提供了可行的技术路径。

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [199] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: 本文介绍了在DARTS项目中开发的半自动化数据标注流水线的设计与实现，旨在创建大规模、多模态的波兰驾驶场景数据集。为降低人工标注的成本和时间，系统采用人机协同方法，结合人工智能与人类专家知识，通过3D目标检测算法自动生成初始标注，并支持模型迭代重训练、数据匿名化及领域适应技术，显著提升了标注效率与质量，有效加速了标准化数据集的构建，为波兰自动驾驶研究提供了技术支撑。


<details>
  <summary>Details</summary>
Motivation: 手动标注异构数据成本高、耗时长，亟需一种高效、低成本的标注方法以支持大规模多模态数据集的构建。

Method: 采用人机协同的半自动化标注流程，基于3D目标检测算法生成初始标注，支持迭代模型重训练、数据匿名化与领域适应技术，结合人工校验确保标注质量。

Result: 显著减少标注时间和成本，实现跨传感器模态的一致性高质量标注，有效支持DARTS项目大规模数据集的快速构建。

Conclusion: 所提出的半自动化标注框架在保证标注质量的同时大幅提升了效率，为自动驾驶研究中的数据准备提供了可扩展、可持续的技术解决方案。

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [200] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 通过用户精心策划的迭代部署大型语言模型（LLM），模型在规划能力上显著提升，后期模型展现出发现更长计划的涌现式泛化能力。理论分析表明，这种机制本质上实现了外层强化学习（RL）训练，具有隐式奖励函数。这对AI安全有重要影响，因为未明确定义的奖励函数可能带来意外后果；同时，该机制可作为显式强化学习的替代训练方式，依赖数据筛选而非明确奖励。


<details>
  <summary>Details</summary>
Motivation: 探索通过用户反馈和数据筛选实现模型迭代优化的可能性，研究其对模型性能与行为的影响，并揭示其背后的强化学习机制。

Method: 采用多轮迭代部署策略，每轮基于前一轮模型输出的数据由用户进行精细筛选与标注，再用于微调下一轮模型。在多个规划任务中测试该方法的有效性，并结合理论分析验证其与强化学习的内在联系。

Result: 后续模型在规划能力上明显优于初始模型，表现出超越原始训练范围的泛化能力，能够生成更长且更复杂的计划序列；理论分析证实该过程等价于外层强化学习，具备隐式奖励结构。

Conclusion: 迭代部署机制虽无需显式奖励设计，却能有效驱动模型能力进化，但其隐式奖励可能引发不可预见的安全风险。该方法为模型训练提供了一种新的范式，即以数据筛选替代显式奖励，具有潜在应用价值，但也需谨慎评估其长期影响。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [201] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: STAgent 是一个专为时空理解设计的智能体大语言模型，能够处理复杂任务如受限兴趣点发现和行程规划。通过集成十余种领域特定工具，支持异步部署与训练，并采用分层数据筛选框架（筛选比达1:10,000）和级联训练流程（从SFT到RL），有效提升模型在TravelBench上的表现，同时保持强大的通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在复杂时空任务中缺乏系统性推理与工具调用能力，难以高效完成如旅行规划等多步骤、高复杂度任务。因此亟需一种具备自主探索、验证与优化能力的专用智能体模型。

Method: 提出STAgent，包含：(1) 稳定的工具环境，支持十多种时空工具的异步训练；(2) 分层数据筛选框架，精准识别高质量、高难度且多样化的样本；(3) 级联训练策略，依次经历种子SFT（评估难度）、高置信度SFT微调和低置信度强化学习阶段，以逐步提升性能。

Result: STAgent在TravelBench上表现出色，显著优于基线模型，在保持广泛通用能力的前提下，成功实现复杂时空任务的高效求解。

Conclusion: STAgent证明了构建具有强推理与工具协同能力的专用智能体模型的有效性，为未来时空理解任务提供了可扩展、可泛化的解决方案。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>
