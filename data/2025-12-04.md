<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.CL](#cs.CL) [Total: 35]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.LG](#cs.LG) [Total: 70]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Does Head Pose Correction Improve Biometric Facial Recognition?](https://arxiv.org/abs/2512.03199)
*Justin Norman,Hany Farid*

Main category: cs.CV

TL;DR: 本文研究了AI驱动的头部姿态校正和图像修复对生物识别面部识别模型在真实世界图像中性能的影响。尽管直接应用三种修复方法（3D重建、2D正面化、特征增强）会显著降低识别准确率，但选择性结合CFR-GAN与CodeFormer可带来显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的面部图像常因质量差、非正面姿态和遮挡导致面部识别模型准确率下降，亟需有效修复手段以提升识别性能。

Method: 采用模型无关的大规模法医评估流程，评估三种图像修复方法：3D重建（NextFace）、2D正面化（CFR-GAN）和特征增强（CodeFormer），分析其对人脸识别的影响。

Result: 直接应用三种修复技术会严重降低识别准确率；但选择性使用CFR-GAN与CodeFormer组合可显著提高识别性能。

Conclusion: 图像修复技术若不当使用反而损害识别效果，而合理选择性地结合特定修复方法（如CFR-GAN与CodeFormer）可有效提升真实场景下面部识别的准确性。

Abstract: Biometric facial recognition models often demonstrate significant decreases in accuracy when processing real-world images, often characterized by poor quality, non-frontal subject poses, and subject occlusions. We investigate whether targeted, AI-driven, head-pose correction and image restoration can improve recognition accuracy. Using a model-agnostic, large-scale, forensic-evaluation pipeline, we assess the impact of three restoration approaches: 3D reconstruction (NextFace), 2D frontalization (CFR-GAN), and feature enhancement (CodeFormer). We find that naive application of these techniques substantially degrades facial recognition accuracy. However, we also find that selective application of CFR-GAN combined with CodeFormer yields meaningful improvements.

</details>


### [2] [Flux4D: Flow-based Unsupervised 4D Reconstruction](https://arxiv.org/abs/2512.03210)
*Jingkang Wang,Henry Che,Yun Chen,Ze Yang,Lily Goli,Sivabalan Manivasagam,Raquel Urtasun*

Main category: cs.CV

TL;DR: Flux4D is a scalable, fully unsupervised framework for 4D reconstruction of large-scale dynamic scenes, directly predicting 3D Gaussians and their motion dynamics using only photometric losses and an 'as static as possible' regularization. It eliminates the need for annotations, pre-trained models, or geometric priors, enabling fast, efficient reconstruction across diverse environments with strong generalization.


<details>
  <summary>Details</summary>
Motivation: Existing methods for dynamic scene reconstruction face scalability issues and rely on annotations or supervised priors. Self-supervised approaches are limited by per-scene optimization and sensitivity to hyperparameters, hindering deployment in large-scale or unseen environments.

Method: Flux4D uses a fully unsupervised training strategy that predicts 3D Gaussians and their motion dynamics directly from raw visual data. It leverages photometric consistency losses and an 'as static as possible' regularization to implicitly decompose moving objects without explicit supervision.

Result: Flux4D achieves state-of-the-art performance in reconstruction quality, scalability, and generalization on outdoor driving datasets. It reconstructs dynamic scenes in seconds, handles large-scale data efficiently, and performs well on rare or unknown objects without retraining.

Conclusion: Flux4D provides a simple, scalable, and effective solution for 4D reconstruction of large-scale dynamic scenes, demonstrating strong generalization and efficiency without relying on annotations or pre-trained models.

Abstract: Reconstructing large-scale dynamic scenes from visual observations is a fundamental challenge in computer vision, with critical implications for robotics and autonomous systems. While recent differentiable rendering methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have achieved impressive photorealistic reconstruction, they suffer from scalability limitations and require annotations to decouple actor motion. Existing self-supervised methods attempt to eliminate explicit annotations by leveraging motion cues and geometric priors, yet they remain constrained by per-scene optimization and sensitivity to hyperparameter tuning. In this paper, we introduce Flux4D, a simple and scalable framework for 4D reconstruction of large-scale dynamic scenes. Flux4D directly predicts 3D Gaussians and their motion dynamics to reconstruct sensor observations in a fully unsupervised manner. By adopting only photometric losses and enforcing an "as static as possible" regularization, Flux4D learns to decompose dynamic elements directly from raw data without requiring pre-trained supervised models or foundational priors simply by training across many scenes. Our approach enables efficient reconstruction of dynamic scenes within seconds, scales effectively to large datasets, and generalizes well to unseen environments, including rare and unknown objects. Experiments on outdoor driving datasets show Flux4D significantly outperforms existing methods in scalability, generalization, and reconstruction quality.

</details>


### [3] [Object Counting with GPT-4o and GPT-5: A Comparative Study](https://arxiv.org/abs/2512.03233)
*Richard Füzesséry,Kaziwa Saleh,Sándor Szénási,Zoltán Vámossy*

Main category: cs.CV

TL;DR: 本文研究了如何利用多模态大语言模型（GPT-4o 和 GPT-5）在无需任何标注数据的情况下，仅通过文本提示实现零样本物体计数。通过在 FSC-147 和 CARPK 数据集上的实验，发现这些模型在零样本设置下表现接近甚至超过现有最先进方法，展示了 LLM 在视觉计数任务中的强大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统零样本物体计数方法依赖大量标注数据和视觉示例，限制了其泛化能力。而大语言模型具备强大的推理与数据理解能力，为实现无监督、零样本的物体计数提供了新路径。

Method: 利用 GPT-4o 与 GPT-5 这两种多模态大语言模型，仅通过设计合适的文本提示（prompt），引导模型基于图像内容进行零样本物体计数。

Result: 在 FSC-147 和 CARPK 数据集上，模型表现达到或超过当前最先进的零样本计数方法，尤其在某些类别上显著优于传统方法。

Conclusion: 多模态大语言模型可通过纯文本提示实现有效的零样本物体计数，无需额外标注或视觉示例，展现出巨大的应用潜力和研究价值。

Abstract: Zero-shot object counting attempts to estimate the number of object instances belonging to novel categories that the vision model performing the counting has never encountered during training. Existing methods typically require large amount of annotated data and often require visual exemplars to guide the counting process. However, large language models (LLMs) are powerful tools with remarkable reasoning and data understanding abilities, which suggest the possibility of utilizing them for counting tasks without any supervision. In this work we aim to leverage the visual capabilities of two multi-modal LLMs, GPT-4o and GPT-5, to perform object counting in a zero-shot manner using only textual prompts. We evaluate both models on the FSC-147 and CARPK datasets and provide a comparative analysis. Our findings show that the models achieve performance comparable to the state-of-the-art zero-shot approaches on FSC-147, in some cases, even surpass them.

</details>


### [4] [LLM-Guided Material Inference for 3D Point Clouds](https://arxiv.org/abs/2512.03237)
*Nafiseh Izadyar,Teseo Schneider*

Main category: cs.CV

TL;DR: 本文提出一种基于大语言模型（LLM）的两阶段方法，从带有粗略分割的3D点云中直接推断物体的材料组成。该方法将语义识别与材料分配解耦，第一阶段由LLM预测物体语义，第二阶段在语义基础上为各几何片段分配合理材料，全程零样本操作。由于缺乏可靠材料标注数据集，采用基于DeepEval的LLM作为裁判进行评估，在Fusion/ABS和ShapeNet的1000个形状上表现良好，证明了语言模型可作为连接几何推理与材料理解的一般性先验。


<details>
  <summary>Details</summary>
Motivation: 现有3D形状数据集和模型主要关注几何信息，忽视决定物体外观的材料属性。为了填补这一空白，需要一种能够从3D点云中推断材料组成的方法，而无需任务特定训练。

Method: 提出两阶段零样本方法：第一阶段使用LLM预测3D点云中物体的语义类别；第二阶段基于第一阶段的语义结果，利用LLM为每个几何分割区域分配合理的材料。整个过程不依赖特定任务训练，仅依赖语言模型的通用知识。

Result: 在Fusion/ABS和ShapeNet共1000个3D形状上，通过基于LLM的评估（DeepEval）验证，该方法在语义和材料合理性方面均表现出色，说明语言模型可有效促进几何与材料理解之间的关联。

Conclusion: 语言模型可以作为通用先验，有效桥接3D几何数据中的几何推理与材料理解，为未来多模态3D内容生成与分析提供新思路。

Abstract: Most existing 3D shape datasets and models focus solely on geometry, overlooking the material properties that determine how objects appear. We introduce a two-stage large language model (LLM) based method for inferring material composition directly from 3D point clouds with coarse segmentations. Our key insight is to decouple reasoning about what an object is from what it is made of. In the first stage, an LLM predicts the object's semantic; in the second stage, it assigns plausible materials to each geometric segment, conditioned on the inferred semantics. Both stages operate in a zero-shot manner, without task-specific training. Because existing datasets lack reliable material annotations, we evaluate our method using an LLM-as-a-Judge implemented in DeepEval. Across 1,000 shapes from Fusion/ABS and ShapeNet, our method achieves high semantic and material plausibility. These results demonstrate that language models can serve as general-purpose priors for bridging geometric reasoning and material understanding in 3D data.

</details>


### [5] [2-Shots in the Dark: Low-Light Denoising with Minimal Data Acquisition](https://arxiv.org/abs/2512.03245)
*Liying Lu,Raphaël Achddou,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 本文提出了一种仅需单张噪声图像和单张暗帧（每ISO设置）的通用且实用的噪声合成方法，通过泊松分布建模信号相关噪声，并采用傅里叶域谱采样算法精确模拟信号无关噪声，生成具有真实空间与统计特性的多样噪声。该方法不依赖简化参数模型或大量成对数据，实现了高精度、低资源需求的噪声合成，显著提升多个低光去噪基准测试的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的去噪方法需要大量成对的干净-噪声图像进行训练，但这类数据难以获取。为减少对大规模数据集的依赖，提出一种高效且真实的噪声合成方法，以生成可用于训练的逼真噪声图像。

Method: 使用泊松分布表示信号依赖性噪声；引入傅里叶域谱采样算法建模信号无关噪声，确保生成噪声在空间和统计特性上与真实传感器噪声一致；仅需一张噪声图像和一张暗帧（每ISO）即可完成建模。

Result: 所提方法在多个低光去噪基准测试中达到当前最优性能，同时具备更高的实用性与更低的数据需求，优于现有基于参数模型或依赖大量配对数据的方法。

Conclusion: 该噪声合成方法无需复杂假设或大规模数据，能高效生成真实感强、多样性高的噪声图像，在低光图像去噪任务中表现出色，为学习型去噪器提供了可靠的数据生成方案。

Abstract: Raw images taken in low-light conditions are very noisy due to low photon count and sensor noise. Learning-based denoisers have the potential to reconstruct high-quality images. For training, however, these denoisers require large paired datasets of clean and noisy images, which are difficult to collect. Noise synthesis is an alternative to large-scale data acquisition: given a clean image, we can synthesize a realistic noisy counterpart. In this work, we propose a general and practical noise synthesis method that requires only one single noisy image and one single dark frame per ISO setting. We represent signal-dependent noise with a Poisson distribution and introduce a Fourier-domain spectral sampling algorithm to accurately model signal-independent noise. The latter generates diverse noise realizations that maintain the spatial and statistical properties of real sensor noise. As opposed to competing approaches, our method neither relies on simplified parametric models nor on large sets of clean-noisy image pairs. Our synthesis method is not only accurate and practical, it also leads to state-of-the-art performances on multiple low-light denoising benchmarks.

</details>


### [6] [PixPerfect: Seamless Latent Diffusion Local Editing with Discriminative Pixel-Space Refinement](https://arxiv.org/abs/2512.03247)
*Haitian Zheng,Yuan Yao,Yongsheng Yu,Yuqian Zhou,Jiebo Luo,Zhe Lin*

Main category: cs.CV

TL;DR: PixPerfect 是一种像素级微调框架，用于在多种潜在扩散模型（LDM）架构和任务中实现无缝、高保真局部图像编辑。它通过可微分的判别性像素空间、全面的人工伪影模拟训练管道以及直接的像素空间优化方案，有效缓解了因潜在压缩导致的颜色偏移、纹理不匹配和边界可见接缝等像素级不一致问题，显著提升图像修复与局部编辑的感知质量与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法如背景条件化的潜在解码和像素空间调和无法完全消除由潜在压缩引起的像素级不一致，且在不同潜在表示或任务间泛化能力差，亟需一种更鲁棒、通用的像素级修正机制。

Method: 提出 PixPerfect 框架，包含：(i) 可微分的判别性像素空间以增强和抑制细微颜色与纹理差异；(ii) 人工伪影模拟训练管道，使模型在训练中接触真实存在的局部编辑伪影；(iii) 直接的像素空间微调策略，确保对多种潜在表示和任务的广泛适用性。

Result: 在图像修复、物体移除与插入等多个基准测试中，PixPerfect 显著提升了感知保真度与下游编辑性能，成为高保真局部图像编辑的新标准。

Conclusion: PixPerfect 通过像素级精细优化，有效解决了潜在扩散模型中常见的像素不一致问题，在多种任务与架构上展现出卓越的鲁棒性与通用性，推动了局部图像编辑技术的发展。

Abstract: Latent Diffusion Models (LDMs) have markedly advanced the quality of image inpainting and local editing. However, the inherent latent compression often introduces pixel-level inconsistencies, such as chromatic shifts, texture mismatches, and visible seams along editing boundaries. Existing remedies, including background-conditioned latent decoding and pixel-space harmonization, usually fail to fully eliminate these artifacts in practice and do not generalize well across different latent representations or tasks. We introduce PixPerfect, a pixel-level refinement framework that delivers seamless, high-fidelity local edits across diverse LDM architectures and tasks. PixPerfect leverages (i) a differentiable discriminative pixel space that amplifies and suppresses subtle color and texture discrepancies, (ii) a comprehensive artifact simulation pipeline that exposes the refiner to realistic local editing artifacts during training, and (iii) a direct pixel-space refinement scheme that ensures broad applicability across diverse latent representations and tasks. Extensive experiments on inpainting, object removal, and insertion benchmarks demonstrate that PixPerfect substantially enhances perceptual fidelity and downstream editing performance, establishing a new standard for robust and high-fidelity localized image editing.

</details>


### [7] [PyroFocus: A Deep Learning Approach to Real-Time Wildfire Detection in Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2512.03257)
*Mark Moussa,Andre Williams,Seth Roffe,Douglas Morton*

Main category: cs.CV

TL;DR: 本文系统评估了多种深度学习架构（包括自定义CNN和基于Transformer的模型）在多类火灾分类中的表现，并提出PyroFocus两阶段流水线，通过先分类后回归/分割的方式降低推理时间和计算成本，适用于机载部署。基于NASA MASTER数据集的实验表明，该方法在速度与精度之间实现了良好权衡，具备未来野火监测任务实时边缘部署的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着野火频发且日益严重，亟需低延迟、计算高效的机载实时检测方法，以区分无火、活跃火和火后状态并估算火强度。然而，多光谱和高光谱热成像仪虽提供丰富光谱信息，但高维数据与有限的机载资源使得实时处理极具挑战性。

Method: 提出PyroFocus两阶段流水线：第一阶段进行火灾分类，第二阶段执行火辐射功率（FRP）回归或分割；对比多种深度学习模型（如自定义CNN和Transformer），并在NASA MASTER数据集上评估其性能。

Result: 实验结果表明，所提两阶段方法在精度与推理速度之间取得良好平衡，显著降低了计算开销，适合未来野火监测任务中的实时边缘部署。

Conclusion: PyroFocus两阶段框架在保持高检测精度的同时大幅减少计算资源消耗，是面向未来机载野火监测任务的理想解决方案。

Abstract: Rapid and accurate wildfire detection is crucial for emergency response and environmental management. In airborne and spaceborne missions, real-time algorithms must distinguish between no fire, active fire, and post-fire conditions, and estimate fire intensity. Multispectral and hyperspectral thermal imagers provide rich spectral information, but high data dimensionality and limited onboard resources make real-time processing challenging. As wildfires increase in frequency and severity, the need for low-latency and computationally efficient onboard detection methods is critical.
  We present a systematic evaluation of multiple deep learning architectures, including custom Convolutional Neural Networks (CNNs) and Transformer-based models, for multi-class fire classification. We also introduce PyroFocus, a two-stage pipeline that performs fire classification followed by fire radiative power (FRP) regression or segmentation to reduce inference time and computational cost for onboard deployment. Using data from NASA's MODIS/ASTER Airborne Simulator (MASTER), which is similar to a next-generation fire detection sensor, we compare accuracy, inference latency, and resource efficiency.
  Experimental results show that the proposed two-stage pipeline achieves strong trade-offs between speed and accuracy, demonstrating significant potential for real-time edge deployment in future wildfire monitoring missions.

</details>


### [8] [SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding](https://arxiv.org/abs/2512.03284)
*Hongpei Zheng,Shijie Li,Yanran Li,Hujun Yin*

Main category: cs.CV

TL;DR: H$^2$U3D 是一个用于房屋尺度场景理解的 3D 视觉问答数据集，涵盖多层、10-20 个房间的大型 3D 环境，通过自动化标注流程构建层次化粗到细的视觉表征，并生成带有思维链注释的多样化问题-答案对。本文提出 SpatialReasoner 框架，一种基于文本查询主动调用空间工具探索 3D 场景的主动感知方法，采用两阶段训练策略（监督冷启动 + 强化学习），并引入自适应探索奖励以提升效率并减少冗余操作。实验表明，SpatialReasoner 在 H$^2$U3D 上表现优于 GPT-4o 和 Gemini-2.5-Pro 等强基线，且平均仅需 3-4 张图像即可达成优异性能，显著低于基线所需的 16+ 张图像，验证了其粗到细主动探索范式的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在大规模 3D 环境中的空间推理能力有限，主要局限于房间尺度场景。为突破这一限制，需要具备更强空间理解能力的数据集与方法，以支持房屋尺度的复杂场景理解任务。

Method: 提出 H$^2$U3D 数据集，构建多层、多房间的大规模 3D 场景；设计自动化标注流程生成层次化视觉表示与带思维链的问答对；开发 SpatialReasoner 主动感知框架，通过两阶段训练（监督冷启动 + 强化学习）实现基于文本查询的智能探索，结合自适应探索奖励机制优化路径选择。

Result: SpatialReasoner 在 H$^2$U3D 数据集上达到当前最优性能，显著优于 GPT-4o、Gemini-2.5-Pro 等先进模型；平均仅需 3-4 张图像完成推理，远低于基线的 16+ 张图像，证明了其高效性与探索策略的有效性。

Conclusion: 本研究通过构建大规模 3D 房屋理解数据集 H$^2$U3D 及提出高效的主动感知框架 SpatialReasoner，显著提升了模型在复杂 3D 空间中的推理能力。该工作为未来大规模 3D 场景理解提供了新的数据基础与方法范式。

Abstract: Spatial reasoning in large-scale 3D environments remains challenging for current vision-language models, which are typically constrained to room-scale scenarios. We introduce H$^2$U3D (Holistic House Understanding in 3D), a 3D visual question answering dataset designed for house-scale scene understanding. H$^2$U3D features multi-floor environments spanning up to three floors and 10-20 rooms, covering more than 300 m$^2$. Through an automated annotation pipeline, it constructs hierarchical coarse-to-fine visual representations and generates diverse question-answer pairs with chain-of-thought annotations. We further propose SpatialReasoner, an active perception framework that autonomously invokes spatial tools to explore 3D scenes based on textual queries. SpatialReasoner is trained through a two-stage strategy: a supervised cold start followed by reinforcement learning with an adaptive exploration reward that promotes efficient exploration while discouraging redundant operations. Extensive experiments demonstrate that SpatialReasoner achieves state-of-the-art performance on H$^2$U3D, outperforming strong baselines including GPT-4o and Gemini-2.5-Pro. Notably, our method attains superior results while using only 3-4 images in total on average, compared to baselines requiring 16+ images, highlighting the effectiveness of our coarse-to-fine active exploration paradigm.

</details>


### [9] [NavMapFusion: Diffusion-based Fusion of Navigation Maps for Online Vectorized HD Map Construction](https://arxiv.org/abs/2512.03317)
*Thomas Monninger,Zihan Zhang,Steffen Staab,Sihao Ding*

Main category: cs.CV

TL;DR: NavMapFusion uses diffusion models to fuse coarse navigation maps with real-time sensor data, improving map accuracy and updating via noise modeling from discrepancies. It outperforms baseline methods by 21.4% on nuScenes at 100m while running in real time.


<details>
  <summary>Details</summary>
Motivation: Traditional high-definition maps are static and cannot adapt to dynamic real-world changes; navigation-grade standard-definition maps are available but lack sufficient resolution for direct use. The challenge lies in leveraging coarse, potentially outdated maps to guide online map construction using high-fidelity sensor data.

Method: NavMapFusion is a diffusion-based framework that performs iterative denoising by conditioning on both low-fidelity navigation maps (e.g., OpenStreetMap road lines) and high-fidelity sensor data. It treats discrepancies between the prior map and real-time perception as noise, where consistent regions are reinforced and outdated segments are suppressed during the denoising process.

Result: On the nuScenes benchmark, NavMapFusion achieves a 21.4% relative improvement at 100 m range when using OpenStreetMap priors, with even greater gains at larger perception ranges. The method maintains real-time performance while generating accurate, up-to-date environmental representations.

Conclusion: Diffusion models provide a robust and effective framework for fusing low-fidelity priors with high-fidelity sensor data, enabling reliable online map construction. This approach enhances the accuracy and timeliness of environmental representation, contributing to safer and more efficient autonomous driving.

Abstract: Accurate environmental representations are essential for autonomous driving, providing the foundation for safe and efficient navigation. Traditionally, high-definition (HD) maps are providing this representation of the static road infrastructure to the autonomous system a priori. However, because the real world is constantly changing, such maps must be constructed online from on-board sensor data. Navigation-grade standard-definition (SD) maps are widely available, but their resolution is insufficient for direct deployment. Instead, they can be used as coarse prior to guide the online map construction process. We propose NavMapFusion, a diffusion-based framework that performs iterative denoising conditioned on high-fidelity sensor data and on low-fidelity navigation maps. This paper strives to answer: (1) How can coarse, potentially outdated navigation maps guide online map construction? (2) What advantages do diffusion models offer for map fusion? We demonstrate that diffusion-based map construction provides a robust framework for map fusion. Our key insight is that discrepancies between the prior map and online perception naturally correspond to noise within the diffusion process; consistent regions reinforce the map construction, whereas outdated segments are suppressed. On the nuScenes benchmark, NavMapFusion conditioned on coarse road lines from OpenStreetMap data reaches a 21.4% relative improvement on 100 m, and even stronger improvements on larger perception ranges, while maintaining real-time capabilities. By fusing low-fidelity priors with high-fidelity sensor data, the proposed method generates accurate and up-to-date environment representations, guiding towards safer and more reliable autonomous driving. The code is available at https://github.com/tmonnin/navmapfusion

</details>


### [10] [Step-by-step Layered Design Generation](https://arxiv.org/abs/2512.03335)
*Faizan Farooq Khan,K J Joseph,Koustava Goswami,Mohamed Elhoseiny,Balaji Vasan Srinivasan*

Main category: cs.CV

TL;DR: 提出了一种新的逐步分层设计生成问题设置，旨在模拟设计师在创作过程中逐步改进作品的过程。为此，作者提出了SLEDGE模型，利用多模态大语言模型将每个设计更新视为相对于前一状态的原子性、分层变化，并遵循设计指令。同时构建了新的数据集和评估基准，实验表明该方法在新设定下优于现有技术，推动了对这一实际且未被充分探索研究领域的关注。


<details>
  <summary>Details</summary>
Motivation: 现有设计生成方法通常将设计合成视为单步生成任务，忽略了设计过程中逐步迭代与修改的本质复杂性。为了更真实地建模人类设计师的创造过程，需要一种能够处理序列化指令并逐步生成设计的新范式。

Method: 提出Step-by-Step Layered Design Generation问题设定；引入SLEDGE模型，通过多模态大语言模型将每一步设计更新建模为基于前序状态的分层原子变化，并与设计指令对齐；构建新的数据集和评估基准以支持该任务。

Result: 实验结果表明，SLEDGE在新设定下显著优于现有方法，在生成质量、连贯性和对指令的遵循度方面表现优异；所提出的评估体系有效验证了模型性能。

Conclusion: 该研究揭示了逐步分层设计生成的重要价值，展示了基于多模态大模型实现精细化、可解释性设计生成的可能性，为未来人机协同设计提供了新方向。

Abstract: Design generation, in its essence, is a step-by-step process where designers progressively refine and enhance their work through careful modifications. Despite this fundamental characteristic, existing approaches mainly treat design synthesis as a single-step generation problem, significantly underestimating the inherent complexity of the creative process. To bridge this gap, we propose a novel problem setting called Step-by-Step Layered Design Generation, which tasks a machine learning model with generating a design that adheres to a sequence of instructions from a designer. Leveraging recent advancements in multi-modal LLMs, we propose SLEDGE: Step-by-step LayEred Design GEnerator to model each update to a design as an atomic, layered change over its previous state, while being grounded in the instruction. To complement our new problem setting, we introduce a new evaluation suite, including a dataset and a benchmark. Our exhaustive experimental analysis and comparison with state-of-the-art approaches tailored to our new setup demonstrate the efficacy of our approach. We hope our work will attract attention to this pragmatic and under-explored research area.

</details>


### [11] [ProtoEFNet: Dynamic Prototype Learning for Inherently Interpretable Ejection Fraction Estimation in Echocardiography](https://arxiv.org/abs/2512.03339)
*Yeganeh Ghamary,Victoria Wu,Hooman Vaseli,Christina Luong,Teresa Tsang,Siavash Bigdeli,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 提出ProtoEFNet，一种基于原型学习的视频模型，用于连续射血分数（EF）回归。该模型通过学习动态时空原型捕捉临床相关的心脏运动模式，并引入原型角度分离（PAS）损失以增强在连续EF谱上的可区分性表示。实验表明，其性能与非可解释模型相当，同时提供临床可解释性。消融实验证明PAS损失使F1分数提升2%（从77.67±2.68到79.64±2.10）。


<details>
  <summary>Details</summary>
Motivation: 传统EF评估依赖手动勾画和专家经验，耗时且存在观察者间差异；现有深度学习方法多为黑箱模型，缺乏透明度，临床信任度低；后处理可解释性方法无法引导模型内部推理，可靠性有限。因此需要兼具高精度与可解释性的新型模型。

Method: 提出ProtoEFNet，一种基于视频的原型学习框架，利用动态时空原型表征心脏运动模式；引入原型角度分离（PAS）损失，强化不同EF水平下的原型区分能力，提升模型对连续EF变化的敏感性与可解释性。

Result: 在EchonetDynamic数据集上，ProtoEFNet达到与非可解释模型相当的预测精度，同时提供临床有意义的解释；消融实验显示PAS损失显著提升性能，F1分数提高2%（77.67±2.68 → 79.64±2.10）。

Conclusion: ProtoEFNet实现了高精度与可解释性的兼顾，为心脏功能评估提供了可靠、透明的深度学习工具，具备良好的临床应用潜力。

Abstract: Ejection fraction (EF) is a crucial metric for assessing cardiac function and diagnosing conditions such as heart failure. Traditionally, EF estimation requires manual tracing and domain expertise, making the process time-consuming and subject to interobserver variability. Most current deep learning methods for EF prediction are black-box models with limited transparency, which reduces clinical trust. Some post-hoc explainability methods have been proposed to interpret the decision-making process after the prediction is made. However, these explanations do not guide the model's internal reasoning and therefore offer limited reliability in clinical applications. To address this, we introduce ProtoEFNet, a novel video-based prototype learning model for continuous EF regression. The model learns dynamic spatiotemporal prototypes that capture clinically meaningful cardiac motion patterns. Additionally, the proposed Prototype Angular Separation (PAS) loss enforces discriminative representations across the continuous EF spectrum. Our experiments on the EchonetDynamic dataset show that ProtoEFNet can achieve accuracy on par with its non-interpretable counterpart while providing clinically relevant insight. The ablation study shows that the proposed loss boosts performance with a 2% increase in F1 score from 77.67$\pm$2.68 to 79.64$\pm$2.10. Our source code is available at: https://github.com/DeepRCL/ProtoEF

</details>


### [12] [HalluGen: Synthesizing Realistic and Controllable Hallucinations for Evaluating Image Restoration](https://arxiv.org/abs/2512.03345)
*Seunghoi Kim,Henry F. J. Tregidgo,Chen Jin,Matteo Figini,Daniel C. Alexander*

Main category: cs.CV

TL;DR: 提出HalluGen，一种基于扩散模型的框架，可生成可控类型、位置和严重程度的逼真幻觉图像，构建首个大规模幻觉数据集（4,350张标注图像），用于安全关键领域图像恢复中的幻觉评估与检测。


<details>
  <summary>Details</summary>
Motivation: 生成模型容易产生幻觉（即在真实数据中不存在但看似合理的错误结构），这在医疗影像、工业检测等安全关键领域会严重影响可靠性与信任度；现有评估方法受限于标注数据的稀缺性和主观性，形成评价与数据获取之间的循环依赖。

Method: 设计了基于扩散模型的HalluGen框架，能够合成具有可控属性的感知真实但语义错误的幻觉图像，并利用该框架从1,450张脑部MRI图像中生成4,350张带标注的幻觉图像数据集。

Result: 成功构建首个大规模幻觉数据集，支持系统性评估幻觉检测与缓解方法；开发出新型特征基质量评估指标SHAFE，提升对幻觉的敏感性；训练出无需参考图像的幻觉检测器，具备对真实恢复失败的泛化能力。

Conclusion: HalluGen及其开放数据集为安全关键图像恢复中的幻觉问题提供了首个可扩展的评估基础，推动了幻觉检测与抑制技术的发展。

Abstract: Generative models are prone to hallucinations: plausible but incorrect structures absent in the ground truth. This issue is problematic in image restoration for safety-critical domains such as medical imaging, industrial inspection, and remote sensing, where such errors undermine reliability and trust. For example, in low-field MRI, widely used in resource-limited settings, restoration models are essential for enhancing low-quality scans, yet hallucinations can lead to serious diagnostic errors. Progress has been hindered by a circular dependency: evaluating hallucinations requires labeled data, yet such labels are costly and subjective. We introduce HalluGen, a diffusion-based framework that synthesizes realistic hallucinations with controllable type, location, and severity, producing perceptually realistic but semantically incorrect outputs (segmentation IoU drops from 0.86 to 0.36). Using HalluGen, we construct the first large-scale hallucination dataset comprising 4,350 annotated images derived from 1,450 brain MR images for low-field enhancement, enabling systematic evaluation of hallucination detection and mitigation. We demonstrate its utility in two applications: (1) benchmarking image quality metrics and developing Semantic Hallucination Assessment via Feature Evaluation (SHAFE), a feature-based metric with soft-attention pooling that improves hallucination sensitivity over traditional metrics; and (2) training reference-free hallucination detectors that generalize to real restoration failures. Together, HalluGen and its open dataset establish the first scalable foundation for evaluating hallucinations in safety-critical image restoration.

</details>


### [13] [SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation](https://arxiv.org/abs/2512.03350)
*Yu Yuan,Tharindu Wickremasinghe,Zeeshan Nadir,Xijun Wang,Yiheng Chi,Stanley H. Chan*

Main category: cs.CV

TL;DR: SeeU提出一种2D→4D→2D的学习框架，通过从稀疏单目2D帧重建4D世界，学习低秩表示与物理约束下的连续4D动态，并在时间上向前推演，重新投影到2D生成未见区域，实现连续且物理一致的视觉内容生成。


<details>
  <summary>Details</summary>
Motivation: 现有视觉理解、预测和生成方法多直接基于2D观测，忽视了4D时空结构，导致性能受限。为提升生成质量与一致性，需建模连续4D动态。

Method: SeeU采用2D→4D→2D框架：首先从稀疏单目2D帧重建4D世界；其次在低秩表示和物理约束下学习连续4D动态；最后将4D世界向前滚动并重投影回2D，在时空上下文感知基础上生成未见区域。

Result: SeeU在未见时间生成、未见空间生成和视频编辑等任务中表现出色，实现了连续且物理一致的视觉生成，展现了强大的应用潜力。

Conclusion: 通过建模4D连续动态，SeeU突破了传统2D方法的局限，为视觉理解与生成提供了更本质的时空建模范式。

Abstract: Images and videos are discrete 2D projections of the 4D world (3D space + time). Most visual understanding, prediction, and generation operate directly on 2D observations, leading to suboptimal performance. We propose SeeU, a novel approach that learns the continuous 4D dynamics and generate the unseen visual contents. The principle behind SeeU is a new 2D$\to$4D$\to$2D learning framework. SeeU first reconstructs the 4D world from sparse and monocular 2D frames (2D$\to$4D). It then learns the continuous 4D dynamics on a low-rank representation and physical constraints (discrete 4D$\to$continuous 4D). Finally, SeeU rolls the world forward in time, re-projects it back to 2D at sampled times and viewpoints, and generates unseen regions based on spatial-temporal context awareness (4D$\to$2D). By modeling dynamics in 4D, SeeU achieves continuous and physically-consistent novel visual generation, demonstrating strong potentials in multiple tasks including unseen temporal generation, unseen spatial generation, and video editing.

</details>


### [14] [FireSentry: A Multi-Modal Spatio-temporal Benchmark Dataset for Fine-Grained Wildfire Spread Forecasting](https://arxiv.org/abs/2512.03369)
*Nan Zhou,Huandong Wang,Jiahao Li,Han Li,Yali Song,Qiuhua Wang,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: 本文提出FireSentry，一个省级尺度的多模态野火数据集，具有亚米级空间和亚秒级时间分辨率，结合无人机同步采集的可见光与红外视频、环境传感器数据及人工验证的火势掩码。基于此，构建了涵盖物理模型、数据驱动与生成模型的综合性基准，并提出FiReDiff新范式：先在红外模态预测未来视频序列，再基于动态生成结果精确分割火势掩码。该方法在生成质量与掩码精度上均显著优于现有方法，相关数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖低分辨率卫星数据，仅能捕捉宏观火情，难以支持高精度局部火势动态建模，亟需更精细的数据与方法以提升野火预测能力。

Method: 提出FireSentry多模态数据集，构建包含物理、数据驱动与生成模型的基准；设计FiReDiff双模态框架，分步实现红外视频生成与火势掩码精准分割。

Result: FiReDiff在视频质量上提升39.2%（PSNR）、36.1%（SSIM）、50.0%（LPIPS）、29.4%（FVD）；在掩码精度上提升3.3%（AUPRC）、59.1%（F1）、42.9%（IoU）、62.5%（MSE），达到当前最优性能。

Conclusion: FireSentry数据集与FiReDiff范式共同推动了细粒度野火预测与动态灾害模拟的发展，为应急响应与决策提供有力支撑。

Abstract: Fine-grained wildfire spread prediction is crucial for enhancing emergency response efficacy and decision-making precision. However, existing research predominantly focuses on coarse spatiotemporal scales and relies on low-resolution satellite data, capturing only macroscopic fire states while fundamentally constraining high-precision localized fire dynamics modeling capabilities. To bridge this gap, we present FireSentry, a provincial-scale multi-modal wildfire dataset characterized by sub-meter spatial and sub-second temporal resolution. Collected using synchronized UAV platforms, FireSentry provides visible and infrared video streams, in-situ environmental measurements, and manually validated fire masks. Building on FireSentry, we establish a comprehensive benchmark encompassing physics-based, data-driven, and generative models, revealing the limitations of existing mask-only approaches. Our analysis proposes FiReDiff, a novel dual-modality paradigm that first predicts future video sequences in the infrared modality, and then precisely segments fire masks in the mask modality based on the generated dynamics. FiReDiff achieves state-of-the-art performance, with video quality gains of 39.2% in PSNR, 36.1% in SSIM, 50.0% in LPIPS, 29.4% in FVD, and mask accuracy gains of 3.3% in AUPRC, 59.1% in F1 score, 42.9% in IoU, and 62.5% in MSE when applied to generative models. The FireSentry benchmark dataset and FiReDiff paradigm collectively advance fine-grained wildfire forecasting and dynamic disaster simulation. The processed benchmark dataset is publicly available at: https://github.com/Munan222/FireSentry-Benchmark-Dataset.

</details>


### [15] [ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding](https://arxiv.org/abs/2512.03370)
*Lingjun Zhao,Yandong Luo,James Hay,Lu Gan*

Main category: cs.CV

TL;DR: ShelfGaussian 是一个基于多模态高斯的开放词汇 3D 场景理解框架，利用现成的视觉基础模型（VFMs）进行监督。它通过多模态高斯变换器实现高斯对多种传感器模态特征的查询，并采用货架式监督学习范式，在2D图像和3D场景层面联合优化高斯表示。该方法在零样本语义占用预测任务中表现优异，且在真实城市环境中验证了其在无人地面车辆上的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯的方法要么依赖标注的3D标签进行封闭集语义建模，牺牲渲染能力；要么仅通过2D自监督学习实现开放集表示，导致几何质量下降且局限于仅摄像头设置。为充分发挥高斯的优势，需要一种能融合多模态信息并有效利用预训练视觉模型的新型框架。

Method: 提出多模态高斯变换器，使高斯能够从不同传感器模态中查询特征；设计货架式监督学习范式，结合2D图像与3D场景层级的VFM特征，高效优化高斯表示。

Result: 在Occ3D-nuScenes数据集上实现了最先进的零样本语义占用预测性能；在真实城市场景下的无人地面车辆测试中表现出良好的野外适应性。

Conclusion: ShelfGaussian 通过融合多模态信息与预训练视觉模型，显著提升了3D场景理解的开放词汇能力和实际应用潜力，为未来自主系统中的感知与规划提供了强有力支持。

Abstract: We introduce ShelfGaussian, an open-vocabulary multi-modal Gaussian-based 3D scene understanding framework supervised by off-the-shelf vision foundation models (VFMs). Gaussian-based methods have demonstrated superior performance and computational efficiency across a wide range of scene understanding tasks. However, existing methods either model objects as closed-set semantic Gaussians supervised by annotated 3D labels, neglecting their rendering ability, or learn open-set Gaussian representations via purely 2D self-supervision, leading to degraded geometry and limited to camera-only settings. To fully exploit the potential of Gaussians, we propose a Multi-Modal Gaussian Transformer that enables Gaussians to query features from diverse sensor modalities, and a Shelf-Supervised Learning Paradigm that efficiently optimizes Gaussians with VFM features jointly at 2D image and 3D scene levels. We evaluate ShelfGaussian on various perception and planning tasks. Experiments on Occ3D-nuScenes demonstrate its state-of-the-art zero-shot semantic occupancy prediction performance. ShelfGaussian is further evaluated on an unmanned ground vehicle (UGV) to assess its in the-wild performance across diverse urban scenarios. Project website: https://lunarlab-gatech.github.io/ShelfGaussian/.

</details>


### [16] [MOS: Mitigating Optical-SAR Modality Gap for Cross-Modal Ship Re-Identification](https://arxiv.org/abs/2512.03404)
*Yujian Zhao,Hankun Liu,Guanglin Niu*

Main category: cs.CV

TL;DR: 本文提出了一种名为MOS的新框架，用于解决光学图像与合成孔径雷达（SAR）图像之间的跨模态船舶重识别（ReID）问题。该框架通过两个核心组件：（1）模态一致表示学习（MCRL），利用去噪SAR图像处理和类别级模态对齐损失来对齐跨模态的同类特征分布；（2）跨模态数据生成与特征融合（CDGF），采用布朗桥扩散模型生成跨模态样本，并在推理阶段融合原始特征以增强对齐性和判别性。在HOSS ReID数据集上的大量实验表明，MOS在所有评估协议下均显著优于现有方法，分别在ALL to ALL、Optical to SAR和SAR to Optical设置下实现了R1准确率提升+3.0%、+6.2%和+16.4%。代码和训练模型将在发表后公开。


<details>
  <summary>Details</summary>
Motivation: 光学与SAR图像之间存在显著的模态差异，导致跨模态船舶重识别困难，亟需一种能够有效缓解模态差距并实现模态一致特征学习的方法。

Method: 提出MOS框架，包含模态一致表示学习（MCRL）和跨模态数据生成与特征融合（CDGF）两部分。MCRL通过去噪SAR图像处理和类别级对齐损失实现跨模态特征对齐；CDGF利用布朗桥扩散模型生成跨模态样本，并在推理时融合原始特征以提升性能。

Result: 在HOSS ReID数据集上，MOS在ALL to ALL、Optical to SAR和SAR to Optical三种设置下分别取得+3.0%、+6.2%和+16.4%的R1准确率提升，显著超越现有方法。

Conclusion: MOS框架有效缓解了光学与SAR图像间的模态差距，实现了模态一致的特征学习，在跨模态船舶重识别任务中表现出卓越性能，具有良好的应用前景。

Abstract: Cross-modal ship re-identification (ReID) between optical and synthetic aperture radar (SAR) imagery has recently emerged as a critical yet underexplored task in maritime intelligence and surveillance. However, the substantial modality gap between optical and SAR images poses a major challenge for robust identification. To address this issue, we propose MOS, a novel framework designed to mitigate the optical-SAR modality gap and achieve modality-consistent feature learning for optical-SAR cross-modal ship ReID. MOS consists of two core components: (1) Modality-Consistent Representation Learning (MCRL) applies denoise SAR image procession and a class-wise modality alignment loss to align intra-identity feature distributions across modalities. (2) Cross-modal Data Generation and Feature fusion (CDGF) leverages a brownian bridge diffusion model to synthesize cross-modal samples, which are subsequently fused with original features during inference to enhance alignment and discriminability. Extensive experiments on the HOSS ReID dataset demonstrate that MOS significantly surpasses state-of-the-art methods across all evaluation protocols, achieving notable improvements of +3.0%, +6.2%, and +16.4% in R1 accuracy under the ALL to ALL, Optical to SAR, and SAR to Optical settings, respectively. The code and trained models will be released upon publication.

</details>


### [17] [ViDiC: Video Difference Captioning](https://arxiv.org/abs/2512.03405)
*Jiangtao Wu,Shihao Li,Zhaozhou Bian,Yuanxing Zhang,Jialu Chen,Runzhe Wen,An Ping,Yiwen He,Jiakai Wang,Jiaheng Liu*

Main category: cs.CV

TL;DR: 本文提出了视频差异描述（ViDiC）任务和相应的ViDiC-1K数据集，旨在评估多模态大模型对视频对之间相似性与差异性的细粒度描述能力。该数据集包含1000个精心挑选的视频对，涵盖7个类别（主体、风格、背景、摄影、运动、位置、播放技术），并配有超过4000个对比检查项。研究设计了双检查表框架，基于大语言模型作为裁判的协议，分别评估相似性和差异性的准确性。在19个代表性多模态模型上的实验表明，现有模型在比较描述和差异感知方面存在显著差距，凸显了该任务的挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言系统在动态场景的比较感知方面仍不充分，尤其是对运动连续性、事件演变和编辑一致性等时间维度变化的捕捉能力不足。尽管图像差异描述（IDC）已有研究，但无法处理视频中的时序变化，因此需要新任务与数据集来推动视频级比较理解的发展。

Method: 提出ViDiC任务与ViDiC-1K数据集，采用双检查表评估框架，结合大语言模型作为裁判（LLM-as-a-Judge）进行准确率衡量，系统评估多模态模型对视频对中多种属性差异的识别与描述能力。

Result: 在19个主流多模态模型上测试发现，模型在视频差异描述任务中表现普遍不佳，尤其在运动、事件演化和编辑一致性等维度上存在明显短板，表明当前模型缺乏足够的视频比较推理能力。

Conclusion: ViDiC-1K是一个具有挑战性的基准，有助于推动视频理解、编辑意识和多模态比较推理的发展，为未来构建具备时间感知与因果推理能力的智能系统奠定基础。

Abstract: Understanding visual differences between dynamic scenes requires the comparative perception of compositional, spatial, and temporal changes--a capability that remains underexplored in existing vision-language systems. While prior work on Image Difference Captioning (IDC) has enabled models to describe semantic changes between static images, these approaches fail to capture motion continuity, event evolution, or editing consistency over time. We introduce the ViDiC (Video Difference Captioning) task and its corresponding ViDiC-1K dataset, designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to provide fine-grained descriptions of similarities and differences between video pairs. ViDiC-1K comprises 1,000 curated video pairs annotated with over 4,000 comparative checklist items, covering seven categories: subject, style, background, cinematography, motion, location, and playback techniques. To ensure reliable evaluation, we propose a dual-checklist framework that measures the accuracy of similarity and difference separately, based on the LLM-as-a-Judge protocol. Experiments on nineteen representative multimodal models reveal a significant performance gap in their comparative description and difference perception abilities. We hope ViDiC-1K can be a challenging benchmark that lays a solid foundation for advancing video understanding, edit awareness, and comparative reasoning in multimodal intelligence.

</details>


### [18] [YOLOA: Real-Time Affordance Detection via LLM Adapter](https://arxiv.org/abs/2512.03418)
*Yuqi Ji,Junjie Ke,Lihuo He,Jun Liu,Kaifan Zhang,Yu-Kun Lai,Guiguang Ding,Xinbo Gao*

Main category: cs.CV

TL;DR: YOLOA是一种实时的协同处理对象检测与使用方式学习的模型，通过大语言模型（LLM）适配器实现，显著提升准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注物体使用方式而忽略物体识别与定位，或独立处理两个任务缺乏交互与实时性，因此需要一种能联合处理'是什么、在哪里、如何用'的高效模型。

Method: YOLOA采用轻量级检测器，包含对象检测与使用方式学习分支，并通过LLM适配器进行优化；训练时利用LLM适配器生成更精确的类别先验、框偏移和使用门控信号来共同改进两个分支。

Result: 在ADG-Det和IIT-Heat数据集上分别达到52.8/73.1 mAP，且最高运行速度达89.77 FPS，轻量版可达846.24 FPS，实现了精度与效率的优异平衡。

Conclusion: YOLOA成功实现了对象检测与使用方式学习的联合建模，在保持实时性的同时达到领先性能，为具身智能中的感知理解提供了有效解决方案。

Abstract: Affordance detection aims to jointly address the fundamental "what-where-how" challenge in embodied AI by understanding "what" an object is, "where" the object is located, and "how" it can be used. However, most affordance learning methods focus solely on "how" objects can be used while neglecting the "what" and "where" aspects. Other affordance detection methods treat object detection and affordance learning as two independent tasks, lacking effective interaction and real-time capability. To overcome these limitations, we introduce YOLO Affordance (YOLOA), a real-time affordance detection model that jointly handles these two tasks via a large language model (LLM) adapter. Specifically, YOLOA employs a lightweight detector consisting of object detection and affordance learning branches refined through the LLM Adapter. During training, the LLM Adapter interacts with object and affordance preliminary predictions to refine both branches by generating more accurate class priors, box offsets, and affordance gates. Experiments on our relabeled ADG-Det and IIT-Heat benchmarks demonstrate that YOLOA achieves state-of-the-art accuracy (52.8 / 73.1 mAP on ADG-Det / IIT-Heat) while maintaining real-time performance (up to 89.77 FPS, and up to 846.24 FPS for the lightweight variant). This indicates that YOLOA achieves an excellent trade-off between accuracy and efficiency.

</details>


### [19] [Label-Efficient Hyperspectral Image Classification via Spectral FiLM Modulation of Low-Level Pretrained Diffusion Features](https://arxiv.org/abs/2512.03430)
*Yuzhen Hu,Biplab Banerjee,Saurabh Prasad*

Main category: cs.CV

TL;DR: 本文提出了一种标签高效的高光谱成像（HSI）分类框架，利用预训练于自然图像的冻结扩散模型提取空间特征。通过在早期去噪步骤中从高分辨率解码器层提取低层次表示，这些特征能有效适应HSI的低纹理结构。为了融合光谱与空间信息，引入轻量级的FiLM融合模块，以光谱线索自适应调制冻结的空间特征，实现稀疏监督下的鲁棒多模态学习。实验表明，该方法在两个最新HSI数据集上优于现有先进方法，仅使用稀疏标注即可取得优异性能。消融研究进一步验证了扩散模型特征和光谱感知融合的有效性。整体结果表明，预训练扩散模型可支持领域无关、标签高效的遥感与科学成像表征学习。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像虽能实现精细地物分类，但面临空间分辨率低和标注稀疏的挑战。现有方法在稀疏标注下表现受限，亟需一种高效利用有限标签并结合空间与光谱信息的解决方案。

Method: 采用预训练扩散模型提取高分辨率图像中的空间特征，利用其在早期去噪阶段的解码器输出作为低层次空间表示；设计轻量级FiLM融合模块，基于光谱信息动态调整这些空间特征，实现跨模态信息融合；整个框架在稀疏标注条件下进行端到端训练，保持空间特征冻结以提升效率与泛化能力。

Result: 在两个公开的高光谱数据集上，所提方法在仅使用稀疏训练标签的情况下，显著优于当前主流方法，尤其在小样本场景下优势明显。消融实验证明扩散模型提供的空间特征和光谱感知融合模块对性能提升具有关键作用。

Conclusion: 预训练扩散模型能够为遥感与科学成像提供强大且通用的标签高效表征学习能力，其衍生的空间特征与自适应融合机制有效应对低纹理、稀疏标注等挑战，具备广泛的应用潜力。

Abstract: Hyperspectral imaging (HSI) enables detailed land cover classification, yet low spatial resolution and sparse annotations pose significant challenges. We present a label-efficient framework that leverages spatial features from a frozen diffusion model pretrained on natural images. Our approach extracts low-level representations from high-resolution decoder layers at early denoising timesteps, which transfer effectively to the low-texture structure of HSI. To integrate spectral and spatial information, we introduce a lightweight FiLM-based fusion module that adaptively modulates frozen spatial features using spectral cues, enabling robust multimodal learning under sparse supervision. Experiments on two recent hyperspectral datasets demonstrate that our method outperforms state-of-the-art approaches using only the provided sparse training labels. Ablation studies further highlight the benefits of diffusion-derived features and spectral-aware fusion. Overall, our results indicate that pretrained diffusion models can support domain-agnostic, label-efficient representation learning for remote sensing and broader scientific imaging tasks.

</details>


### [20] [LM-CartSeg: Automated Segmentation of Lateral and Medial Cartilage and Subchondral Bone for Radiomics Analysis](https://arxiv.org/abs/2512.03449)
*Tongxu Zhang*

Main category: cs.CV

TL;DR: LM-CartSeg 是一个全自动的膝关节 MRI 放射组学分析流程，用于软骨/骨分割、解剖学上的内外侧（L/M）分区以及放射组学特征提取。通过两个 3D nnU-Net 模型在 SKM-TEA（138 个膝关节）和 OAIZIB-CM（404 个膝关节）数据集上训练，并在测试时采用零样本预测融合与几何规则后处理（如连通域清理、10 mm 骨下带构建、基于 PCA 与 k-means 的数据驱动 L/M 分割），显著提升了分割精度（如 HD95 从 25.2 降至 3.35 mm，DSC 达到 0.91）。该方法实现了跨数据集稳定的 L/M 分区，且质量控制基于体积与厚度特征。从 10 个 ROI 提取的 4650 个非形状放射组学特征中，仅少数与体积或厚度强相关，表明其包含超越形态学的信息。模型在区分骨关节炎（OA）与非 OA 样本上表现良好，为多中心膝关节 OA 放射组学研究提供了可靠基础。


<details>
  <summary>Details</summary>
Motivation: 现有膝关节 MRI 放射组学研究依赖手动勾画感兴趣区域（ROI），缺乏标准化的质量控制（QC），且难以保证解剖一致性，尤其在内外侧（L/M）分区上存在主观偏差。因此亟需一种自动、可重复、具备质量控制能力的分割与分析框架，以支持多中心研究。

Method: 采用两阶段 3D nnU-Net 模型分别在 SKM-TEA 与 OAIZIB-CM 数据集上训练；测试时进行零样本预测融合，并结合几何规则后处理：包括连通域清理、物理空间中构建 10 mm 子骨下带、基于主成分分析（PCA）与 k-means 聚类的数据驱动式胫骨 L/M 分割；通过体积与厚度指标实现质量控制；从多个 ROI 提取大量放射组学特征进行分析。

Result: 后处理使分割性能显著提升：在 OAIZIB-CM 测试集上，平均表面距离（ASSD）由 2.63 mm 降至 0.36 mm，95% Hausdorff 距离（HD95）从 25.2 mm 降至 3.35 mm，Dice 系数（DSC）达 0.91；在 SKI-10 测试集上零样本 DSC 为 0.80。几何方法生成的 L/M 分区具有跨数据集稳定性，而直接使用 nnU-Net 进行 L/M 分割则出现领域依赖性侧向交换。仅约 6–12% 的放射组学特征与体积或厚度强相关，说明这些特征携带独立于尺寸的信息，可用于分类建模。

Conclusion: LM-CartSeg 实现了自动、可质量控制的膝关节软骨与骨分割及内外侧分区，生成的放射组学特征蕴含超越传统形态测量的信息，适用于多中心膝关节骨关节炎研究，具有良好的可推广性和临床应用潜力。

Abstract: Background and Objective: Radiomics of knee MRI requires robust, anatomically meaningful regions of interest (ROIs) that jointly capture cartilage and subchondral bone. Most existing work relies on manual ROIs and rarely reports quality control (QC). We present LM-CartSeg, a fully automatic pipeline for cartilage/bone segmentation, geometric lateral/medial (L/M) compartmentalisation and radiomics analysis. Methods: Two 3D nnU-Net models were trained on SKM-TEA (138 knees) and OAIZIB-CM (404 knees). At test time, zero-shot predictions were fused and refined by simple geometric rules: connected-component cleaning, construction of 10 mm subchondral bone bands in physical space, and a data-driven tibial L/M split based on PCA and k-means. Segmentation was evaluated on an OAIZIB-CM test set (103 knees) and on SKI-10 (100 knees). QC used volume and thickness signatures. From 10 ROIs we extracted 4 650 non-shape radiomic features to study inter-compartment similarity, dependence on ROI size, and OA vs. non-OA classification on OAIZIB-CM Results: Post-processing improved macro ASSD on OAIZIB-CM from 2.63 to 0.36 mm and HD95 from 25.2 to 3.35 mm, with DSC 0.91; zero-shot DSC on SKI-10 was 0.80. The geometric L/M rule produced stable compartments across datasets, whereas a direct L/M nnU-Net showed domain-dependent side swaps. Only 6 to 12 percent of features per ROI were strongly correlated with volume or thickness. Radiomics-based models models restricted to size-linked features. Conclusions: LM-CartSeg yields automatic, QCd ROIs and radiomic features that carry discriminative information beyond simple morphometry, providing a practical foundation for multi-centre knee OA radiomics studies.

</details>


### [21] [KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models](https://arxiv.org/abs/2512.03450)
*Rhys Newbury,Juyan Zhang,Tin Tran,Hanna Kurniawati,Dana Kulić*

Main category: cs.CV

TL;DR: 提出了一种无监督的3D关键点学习框架，从点云数据中学习具有空间结构的关键点，用于条件生成完整形状。该方法在多个物体类别上表现优异，相比之前的方法在关键点一致性上提升6个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有无监督关键点方法不适用于无条件生成设置，限制了其在现代3D生成流程中的应用，因此需要一种能够桥接这一差距的新方法。

Method: 通过无监督方式从点云数据中学习3D关键点，利用这些关键点作为紧凑且可解释的表示来指导阐明扩散模型（EDM）重建完整形状。

Result: 所学关键点在不同物体实例间表现出重复的空间结构，并支持关键点空间中的平滑插值，表明其捕捉到了几何变化；在多种物体类别上表现良好，关键点一致性比先前方法提高6个百分点。

Conclusion: 该框架成功实现了无监督条件下3D关键点的结构化学习，为3D生成任务提供了有效且可解释的表示。

Abstract: Understanding and representing the structure of 3D objects in an unsupervised manner remains a core challenge in computer vision and graphics. Most existing unsupervised keypoint methods are not designed for unconditional generative settings, restricting their use in modern 3D generative pipelines; our formulation explicitly bridges this gap. We present an unsupervised framework for learning spatially structured 3D keypoints from point cloud data. These keypoints serve as a compact and interpretable representation that conditions an Elucidated Diffusion Model (EDM) to reconstruct the full shape. The learned keypoints exhibit repeatable spatial structure across object instances and support smooth interpolation in keypoint space, indicating that they capture geometric variation. Our method achieves strong performance across diverse object categories, yielding a 6 percentage-point improvement in keypoint consistency compared to prior approaches.

</details>


### [22] [GeoVideo: Introducing Geometric Regularization into Video Generation Model](https://arxiv.org/abs/2512.03453)
*Yunpeng Bai,Shaoheng Fang,Chaohui Yu,Fan Wang,Qixing Huang*

Main category: cs.CV

TL;DR: 本文提出在视频生成中引入几何正则化损失，通过在潜在扩散模型中加入每帧的深度预测来增强3D结构建模。利用多视角几何损失，将不同帧的深度图对齐到共享的3D坐标系中，从而提升时空一致性、形状一致性和物理合理性。实验表明，该方法在多个数据集上显著优于现有基线，生成结果更稳定且几何一致。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法大多基于2D像素空间，缺乏对3D结构的显式建模，导致时间上不一致的几何结构、不合理运动和结构伪影。为解决这一问题，需要在生成过程中引入几何约束以提升视频的结构合理性与时空一致性。

Method: 在潜扩散模型中引入每帧深度预测，并设计多视角几何损失，将不同帧的深度图映射到共享的3D坐标系中进行对齐，从而实现对3D结构的显式建模与约束。

Result: 在多个数据集上的实验表明，该方法生成的视频在时空一致性、形状一致性和物理合理性方面显著优于现有基线，生成结果更加稳定且几何一致。

Conclusion: 通过引入深度预测与多视角几何损失，本方法有效提升了视频生成中的3D结构建模能力，实现了外观生成与3D结构建模的更好融合，为高质量、高一致性视频生成提供了新路径。

Abstract: Recent advances in video generation have enabled the synthesis of high-quality and visually realistic clips using diffusion transformer models. However, most existing approaches operate purely in the 2D pixel space and lack explicit mechanisms for modeling 3D structures, often resulting in temporally inconsistent geometries, implausible motions, and structural artifacts. In this work, we introduce geometric regularization losses into video generation by augmenting latent diffusion models with per-frame depth prediction. We adopted depth as the geometric representation because of the great progress in depth prediction and its compatibility with image-based latent encoders. Specifically, to enforce structural consistency over time, we propose a multi-view geometric loss that aligns the predicted depth maps across frames within a shared 3D coordinate system. Our method bridges the gap between appearance generation and 3D structure modeling, leading to improved spatio-temporal coherence, shape consistency, and physical plausibility. Experiments across multiple datasets show that our approach produces significantly more stable and geometrically consistent results than existing baselines.

</details>


### [23] [Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles](https://arxiv.org/abs/2512.03454)
*Haicheng Liao,Huanming Shen,Bonan Wang,Yongkang Li,Yihong Tang,Chengyue Wang,Dingyi Zhuang,Kehua Chen,Hai Yang,Chengzhong Xu,Zhenning Li*

Main category: cs.CV

TL;DR: ThinkDeeper提出了一种基于世界模型的视觉定位框架，通过推理未来空间状态来解决自动驾驶中自然语言指令的模糊性问题。其核心是空间感知世界模型（SA-WM），可生成命令感知的潜在状态并预测未来状态序列，为消歧提供前瞻线索；结合超图引导解码器，融合多模态输入以捕捉高阶空间依赖关系。此外，构建了DrivePilot数据集，使用RAG与思维链提示的LLM生成语义标注。在六个基准上表现优异，尤其在长文本、多智能体和模糊场景下展现强鲁棒性与效率，且在仅用50%数据训练时仍保持领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定位方法在自动驾驶场景中难以处理模糊、依赖上下文的语言指令，缺乏对三维空间关系和场景演化的推理能力。因此需要一种能够前瞻思考未来空间状态的机制，以提升定位准确性与鲁棒性。

Method: 提出ThinkDeeper框架，包含空间感知世界模型（SA-WM）用于学习当前场景并滚动预测未来潜在状态序列，以及超图引导解码器用于层次化融合多模态输入与时空状态，捕捉高阶空间依赖关系。同时构建DrivePilot数据集，采用检索增强生成与思维链提示的LLM生成高质量语义标注。

Result: ThinkDeeper在Talk2Car、DrivePilot、MoCAD、RefCOCO/+/g等多个基准上取得领先，尤其在长文本、多智能体、模糊场景中表现出强鲁棒性；即使仅使用50%训练数据，性能仍优于现有方法，证明其高效性与泛化能力。

Conclusion: ThinkDeeper通过前瞻性空间推理与多模态融合，在复杂自动驾驶场景下实现了更准确、鲁棒的视觉定位，为自然语言指令理解提供了新范式，并推动了相关数据集与技术的发展。

Abstract: Interpreting natural-language commands to localize target objects is critical for autonomous driving (AD). Existing visual grounding (VG) methods for autonomous vehicles (AVs) typically struggle with ambiguous, context-dependent instructions, as they lack reasoning over 3D spatial relations and anticipated scene evolution. Grounded in the principles of world models, we propose ThinkDeeper, a framework that reasons about future spatial states before making grounding decisions. At its core is a Spatial-Aware World Model (SA-WM) that learns to reason ahead by distilling the current scene into a command-aware latent state and rolling out a sequence of future latent states, providing forward-looking cues for disambiguation. Complementing this, a hypergraph-guided decoder then hierarchically fuses these states with the multimodal input, capturing higher-order spatial dependencies for robust localization. In addition, we present DrivePilot, a multi-source VG dataset in AD, featuring semantic annotations generated by a Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)-prompted LLM pipeline. Extensive evaluations on six benchmarks, ThinkDeeper ranks #1 on the Talk2Car leaderboard and surpasses state-of-the-art baselines on DrivePilot, MoCAD, and RefCOCO/+/g benchmarks. Notably, it shows strong robustness and efficiency in challenging scenes (long-text, multi-agent, ambiguity) and retains superior performance even when trained on 50% of the data.

</details>


### [24] [Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models](https://arxiv.org/abs/2512.03463)
*Shojiro Yamabe,Futa Waseda,Daiki Shiono,Tsubasa Takahashi*

Main category: cs.CV

TL;DR: 本文研究文本中心训练（text-centric training），即仅使用文本描述而无需真实图像，以实现低成本的数据扩展。提出一种名为文本打印图像（TPI）的方法，通过将文本直接渲染在白色画布上生成合成图像，从而将文本投影到图像模态中。TPI保留了文本语义，且比扩散模型生成的合成图像更有效，在多个模型和基准测试中表现更优。此外，TPI可作为低成本数据增强策略，具有实际应用价值。研究证明了文本中心训练的巨大潜力，为视觉-语言大模型的全自动数据生成提供了新路径。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉-语言模型（LVLMs）在视觉问答（VQA）任务中需大量图像-文本对进行特定任务微调，但这些数据收集成本高、耗时长。相比之下，文本资源丰富、易于编辑和扩展，因此探索仅基于文本的训练方式具有显著成本优势。然而，纯文本训练因缺乏真实图像导致性能受限，存在图像-文本模态差距。为此，需要一种能有效桥接该差距的轻量级方法。

Method: 提出文本打印图像（TPI）技术：将给定文本直接渲染于空白画布上生成合成图像。该方法不依赖复杂生成模型，保持文本原始语义，且可无缝集成至任意现有LVLM训练流程中。利用大语言模型（LLM）自动扩充文本数据，实现高效、低成本的数据生成与多样化。

Result: 在四个模型和七个基准测试中，TPI在文本中心训练下的表现优于由扩散模型生成的合成图像。其生成的图像能更准确地反映文本语义，显著提升模型在VQA任务上的性能。同时，作为数据增强手段，TPI在少量真实数据条件下仍能有效提升泛化能力，验证了其在实际场景中的实用性。

Conclusion: 文本中心训练结合TPI方法，不仅大幅降低数据获取成本，还有效缓解图像-文本模态差异问题。该方法为构建全自动、可扩展的视觉-语言大模型训练体系提供了可行路径，具有广阔的应用前景。

Abstract: Recent large vision-language models (LVLMs) have been applied to diverse VQA tasks. However, achieving practical performance typically requires task-specific fine-tuning with large numbers of image-text pairs, which are costly to collect. In this work, we study text-centric training, a setting where only textual descriptions are available and no real images are provided, as a paradigm for low-cost data scaling. Unlike images, whose collection is often restricted by privacy constraints and scarcity in niche domains, text is widely available. Moreover, text is easily editable, enabling automatic diversification and expansion with LLMs at minimal human effort. While this offers clear advantages over image collection in terms of scalability and cost, training on raw text without images still yields limited gains on VQA tasks because of the image-text modality gap. To address this issue, we propose a Text-Printed Image (TPI), which generates synthetic images by directly rendering the given textual description on a plain white canvas. This simple rendering projects text into the image modality and can be integrated into arbitrary existing LVLM training pipelines at low cost. Moreover, TPI preserves the semantics of the text, whereas text-to-image models often fail to do. Across four models and seven benchmarks, our systematic experiments show that TPI enables more effective text-centric training than synthetic images generated by a diffusion model. We further explore TPI as a low-cost data-augmentation strategy and demonstrate its practical utility. Overall, our findings highlight the significant potential of text-centric training and, more broadly, chart a path toward fully automated data generation for LVLMs.

</details>


### [25] [Difference Decomposition Networks for Infrared Small Target Detection](https://arxiv.org/abs/2512.03470)
*Chen Hu,Mingyu Zhou,Shuai Yuan,Hongbo Hu,Xiangyu Qiu,Junhai Luo,Tian Pu,Xiyin Li*

Main category: cs.CV

TL;DR: 提出基于基分解的轻量级模块BDM，扩展为SD²M、SD³M和TD²M，构建SD²Net用于单帧红外小目标检测，STD²Net用于多帧检测，实验表明在SISTD和MISTD任务上均达到SOTA性能，尤其在MISTD中mIoU达87.68%。


<details>
  <summary>Details</summary>
Motivation: 解决红外小目标检测中目标纹理不明显与背景杂乱导致目标被遮蔽的问题。

Method: 通过基分解将复杂特征分解为多个基础特征，设计BDM及其扩展模块，结合U型结构与运动信息建模，构建SD²Net和STD²Net进行目标增强与背景抑制。

Result: 在SISTD和MISTD数据集上均取得SOTA性能，STD²Net在MISTD中mIoU达87.68%，显著优于现有方法。

Conclusion: 所提方法有效提升了红外小目标的检测能力，尤其在多帧场景下表现突出，具备良好的可扩展性与实用性。

Abstract: Infrared small target detection (ISTD) faces two major challenges: a lack of discernible target texture and severe background clutter, which results in the background obscuring the target. To enhance targets and suppress backgrounds, we propose the Basis Decomposition Module (BDM) as an extensible and lightweight module based on basis decomposition, which decomposes a complex feature into several basis features and enhances certain information while eliminating redundancy. Extending BDM leads to a series of modules, including the Spatial Difference Decomposition Module (SD$^\mathrm{2}$M), Spatial Difference Decomposition Downsampling Module (SD$^\mathrm{3}$M), and Temporal Difference Decomposition Module (TD$^\mathrm{2}$M). Based on these modules, we develop the Spatial Difference Decomposition Network (SD$^\mathrm{2}$Net) for single-frame ISTD (SISTD) and the Spatiotemporal Difference Decomposition Network (STD$^\mathrm{2}$Net) for multi-frame ISTD (MISTD). SD$^\mathrm{2}$Net integrates SD$^\mathrm{2}$M and SD$^\mathrm{3}$M within an adapted U-shaped architecture. We employ TD$^\mathrm{2}$M to introduce motion information, which transforms SD$^\mathrm{2}$Net into STD$^\mathrm{2}$Net. Extensive experiments on SISTD and MISTD datasets demonstrate state-of-the-art (SOTA) performance. On the SISTD task, SD$^\mathrm{2}$Net performs well compared to most established networks. On the MISTD datasets, STD$^\mathrm{2}$Net achieves a mIoU of 87.68\%, outperforming SD$^\mathrm{2}$Net, which achieves a mIoU of 64.97\%. Our codes are available: https://github.com/greekinRoma/IRSTD_HC_Platform.

</details>


### [26] [Procedural Mistake Detection via Action Effect Modeling](https://arxiv.org/abs/2512.03474)
*Wenliang Guo,Yujiang Pu,Yu Kong*

Main category: cs.CV

TL;DR: 本文提出了一种名为动作效应建模（AEM）的统一框架，通过概率形式联合捕捉动作执行及其结果，以解决现有方法忽视动作后果的问题。AEM首先基于语义相关性和视觉质量选择最具信息量的效果帧，然后从视觉定位和符号场景图中提取互补线索，并在共享潜在空间中形成鲁棒的效应感知表示。为检测错误，设计了基于提示的检测器，结合任务特定提示，将每个动作段与预期执行语义对齐。该方法在EgoPER和CaptainCook4D基准测试中，在具有挑战性的单类分类设置下达到当前最优性能，表明同时建模执行与结果可提高误判检测的可靠性，并展示了效应感知表示在更广泛下游应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注动作执行过程，而忽略了动作产生的结果（即动作效应），但许多错误表现为对象状态或空间排列的不正确，而非执行本身的问题。因此需要一种能同时考虑动作执行与结果的框架来提升错误检测能力。

Method: 提出动作效应建模（AEM）框架，包括：1）基于语义相关性和视觉质量选择最有效果帧；2）融合视觉接地与符号场景图的互补线索，构建共享潜在空间中的效应感知表示；3）设计基于提示的检测器，结合任务特定提示实现动作与预期语义对齐。

Result: 在EgoPER和CaptainCook4D基准上，于一类别分类（OCC）设置下取得当前最优性能，验证了联合建模动作执行与结果的有效性，且效应感知表示在下游任务中展现出广泛应用潜力。

Conclusion: 建模动作执行与结果的联合效应能够显著提升错误检测的可靠性，效应感知表示为智能系统在学习与任务执行支持方面提供了新路径，具有广泛的应用前景。

Abstract: Mistake detection in procedural tasks is essential for building intelligent systems that support learning and task execution. Existing approaches primarily analyze how an action is performed, while overlooking what it produces, i.e., the \textbf{action effect}. Yet many errors manifest not in the execution itself but in the resulting outcome, such as an unintended object state or incorrect spatial arrangement. To address this gap, we propose Action Effect Modeling (AEM), a unified framework that jointly captures action execution and its outcomes through a probabilistic formulation. AEM first identifies the outcome of an action by selecting the most informative effect frame based on semantic relevance and visual quality. It then extracts complementary cues from visual grounding and symbolic scene graphs, aligning them in a shared latent space to form robust effect-aware representations. To detect mistakes, we further design a prompt-based detector that incorporates task-specific prompts and aligns each action segment with its intended execution semantics. Our approach achieves state-of-the-art performance on the EgoPER and CaptainCook4D benchmarks under the challenging one-class classification (OCC) setting. These results demonstrate that modeling both execution and outcome yields more reliable mistake detection, and highlight the potential of effect-aware representations to benefit a broader range of downstream applications.

</details>


### [27] [Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis](https://arxiv.org/abs/2512.03477)
*Zijian Gu,Yuxi Liu,Zhenhao Zhang,Song Wang*

Main category: cs.CV

TL;DR: 本文提出一种公平性感知的低秩适配方法（FR-LoRA、GR-LoRA、Hybrid-LoRA），用于提升医疗视觉语言模型在不同人口群体间的诊断公平性。通过引入可微分的MaxAccGap损失函数，实现端到端的公平性优化，显著降低诊断准确率差异，同时保持较高整体性能，并仅需0.24%的可训练参数，适用于资源受限的医疗环境。


<details>
  <summary>Details</summary>
Motivation: 现有医疗视觉语言模型在不同人口群体间存在显著的诊断准确性差异，亟需在保持性能的同时提升公平性，尤其在资源有限的临床场景中。

Method: 提出三种基于低秩适配的公平性优化方法：FR-LoRA通过MaxAccGap正则化直接优化公平性；GR-LoRA采用逆频率加权平衡梯度贡献；Hybrid-LoRA结合两者优势。核心是引入可微分的MaxAccGap损失，支持端到端训练。

Result: 在10,000张青光眼眼底图像上评估，GR-LoRA将诊断准确率差异降低69%，整体准确率达53.15%；强正则化与种族特异性优化可进一步减少60%的差异；模型仅需0.24%可训练参数，具备高效部署潜力。

Conclusion: 所提出的公平性感知低秩适配方法有效缓解了医疗VLM中的群体偏差问题，在极低参数开销下实现了高公平性与实用性的平衡，为资源受限环境下的公平医疗AI提供了可行方案。

Abstract: Vision-language models achieve expert-level performance on medical imaging tasks but exhibit significant diagnostic accuracy disparities across demographic groups. We introduce fairness-aware Low-Rank Adaptation for medical VLMs, combining parameter efficiency with explicit fairness optimization. Our key algorithmic contribution is a differentiable MaxAccGap loss that enables end-to-end optimization of accuracy parity across demographic groups. We propose three methods: FR-LoRA integrates MaxAccGap regularization into the training objective, GR-LoRA applies inverse frequency weighting to balance gradient contributions, and Hybrid-LoRA combines both mechanisms.Evaluated on 10,000 glaucoma fundus images, GR-LoRA reduces diagnostic accuracy disparities by 69% while maintaining 53.15% overall accuracy. Ablation studies reveal that strong regularization strength achieves optimal fairness with minimal accuracy trade-off, and race-specific optimization yields 60% disparity reduction. Our approach requires only 0.24% trainable parameters, enabling practical deployment of fair medical AI in resource-constrained healthcare settings.

</details>


### [28] [Towards Object-centric Understanding for Instructional Videos](https://arxiv.org/abs/2512.03479)
*Wenliang Guo,Yu Kong*

Main category: cs.CV

TL;DR: 本文提出从以动作为中心转向以物体为中心的范式，通过引入Object-IVQA基准评估物体状态演变、先决条件验证、反事实推理和错误识别等维度，构建了一个能进行多跳推理和显式证据检索的智能体框架，显著提升了在复杂任务中的物体级识别与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有以动作为中心的方法难以应对真实流程中因物体状态变化导致的步骤顺序灵活性问题，因此需要转向更灵活的物体为中心的推理范式。

Method: 提出一个物体为中心的智能体框架，整合物体级规划、感知、分析与生成工具，支持跨不连续片段的多跳推理和显式证据检索，并基于Object-IVQA基准进行评估。

Result: 现有大型视觉语言模型在物体级识别与推理上表现不佳，而所提出的框架在多个维度上均实现显著提升。

Conclusion: 以物体为中心的推理范式能够有效应对现实世界任务中的动态性与复杂性，为未来辅助型AI的发展提供了新方向。

Abstract: Understanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.

</details>


### [29] [NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation](https://arxiv.org/abs/2512.03499)
*Renqi Chen,Haoyang Su,Shixiang Tang*

Main category: cs.CV

TL;DR: 本文提出NAS-LoRA，一种用于视觉基础模型SAM的参数高效微调方法，通过在LoRA中引入轻量级神经架构搜索（NAS）模块，动态优化先验知识融入权重更新过程，并采用分阶段优化策略平衡ViT编码器的权重更新与结构调整，从而提升模型在医学和农业图像等特定领域的语义理解能力。实验表明，NAS-LoRA在不增加推理开销的前提下，相比现有PEFT方法性能更优，训练成本降低24.14%。


<details>
  <summary>Details</summary>
Motivation: 当前基于LoRA的SAM微调方法在适应医学、农业等特定领域时存在局限，主要因SAM的Transformer编码器缺乏空间先验，难以有效获取高层语义信息。因此亟需将归纳偏置融入模型，以弥合预训练模型与下游任务间的语义鸿沟。

Method: 提出NAS-LoRA，结合轻量级神经架构搜索（NAS）模块嵌入LoRA框架，置于编码器与解码器之间，实现对先验知识的动态优化；同时设计分阶段优化策略，使ViT编码器在微调过程中逐步学习高层语义，兼顾权重更新与结构调整的平衡。

Result: NAS-LoRA在多个下游任务上优于现有参数高效微调方法，显著提升分割性能，且训练成本降低24.14%，推理开销保持不变，验证了NAS在增强视觉基础模型微调中的有效性。

Conclusion: NAS-LoRA通过融合神经架构搜索与参数高效微调，成功将空间先验知识注入SAM，有效缓解了模型在特定领域中的语义偏差问题，为视觉基础模型的高效适配提供了新思路。

Abstract: The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM's adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.

</details>


### [30] [Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation](https://arxiv.org/abs/2512.03508)
*Seogkyu Jeon,Kibeom Hong,Hyeran Byun*

Main category: cs.CV

TL;DR: 本文提出了一种名为DPMFormer的新框架，用于域泛化语义分割（DGSS），通过引入领域感知提示学习、领域对比学习与纹理扰动、以及领域鲁棒一致性学习，解决了视觉与文本上下文间的语义错位问题，提升了模型在多样化环境下的性能，达到了新的基准水平。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽略了视觉与文本上下文之间的语义错位问题，这是由于固定上下文提示在单一源域上学习所导致的刚性。

Method: 提出领域感知提示学习以对齐视觉与文本线索；采用领域对比学习与纹理扰动以捕捉单个源数据集中的多种领域特性；设计领域鲁棒一致性学习以减少原始图像与增强图像间预测差异。

Result: 在多个DGSS基准上取得了新最优性能，验证了所提框架的有效性与优越性。

Conclusion: DPMFormer通过多策略协同优化，在域泛化语义分割任务中显著提升了模型的泛化能力与鲁棒性，为未来研究提供了新方向。

Abstract: Recent domain generalized semantic segmentation (DGSS) studies have achieved notable improvements by distilling semantic knowledge from Vision-Language Models (VLMs). However, they overlook the semantic misalignment between visual and textual contexts, which arises due to the rigidity of a fixed context prompt learned on a single source domain. To this end, we present a novel domain generalization framework for semantic segmentation, namely Domain-aware Prompt-driven Masked Transformer (DPMFormer). Firstly, we introduce domain-aware prompt learning to facilitate semantic alignment between visual and textual cues. To capture various domain-specific properties with a single source dataset, we propose domain-aware contrastive learning along with the texture perturbation that diversifies the observable domains. Lastly, to establish a framework resilient against diverse environmental changes, we have proposed the domain-robust consistency learning which guides the model to minimize discrepancies of prediction from original and the augmented images. Through experiments and analyses, we demonstrate the superiority of the proposed framework, which establishes a new state-of-the-art on various DGSS benchmarks. The code is available at https://github.com/jone1222/DPMFormer.

</details>


### [31] [AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model](https://arxiv.org/abs/2512.03509)
*Kwaku Opoku-Ware,Gideon Opoku*

Main category: cs.CV

TL;DR: 该研究提出了一种基于计算机视觉的自动化舞蹈动作分析框架，结合YOLOv8/v11进行舞者检测与Segment Anything Model（SAM）实现像素级分割，成功在无标记、无专用设备条件下对非洲节奏舞视频进行动作追踪与量化。系统在单个49秒视频上达到约94%检测精度和89%召回率，SAM分割性能达约83%交并比，可捕捉身体姿态变化。结果显示主舞者比副舞者多执行23%步数、运动强度高37%、使用空间多42%。但研究仍处早期阶段，存在仅单视频验证、缺乏系统性标注及对比现有姿态估计方法等局限。


<details>
  <summary>Details</summary>
Motivation: 当前舞蹈分析依赖人工观察或标记设备，难以实现大规模、客观的量化评估。本研究旨在探索无需特殊设备或标记的自动化舞蹈动作分析方法，推动舞蹈科学与技术融合，为舞蹈表现力、节奏、空间利用等指标提供数据支持。

Method: 采用YOLOv8/v11进行舞者检测，结合Segment Anything Model（SAM）实现像素级分割，通过帧间跟踪与运动特征提取，量化舞步数量、空间覆盖范围与节奏一致性。

Result: 在单个非洲节奏舞视频中，系统检测精度约94%，召回率约89%，SAM分割交并比约83%。主舞者表现出更高的步数、运动强度与空间利用率（分别高出23%、37%、42%），表明框架具备捕捉关键舞蹈差异的能力。

Conclusion: 该框架展示了自动化舞蹈动作分析的技术可行性，能够有效提取多维度舞蹈量化指标，为未来建立系统性验证体系与拓展至更复杂舞蹈类型奠定基础，但仍需解决标注标准、多场景泛化与方法对比等挑战。

Abstract: This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.

</details>


### [32] [FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation](https://arxiv.org/abs/2512.03520)
*Yiyi Cai,Yuhan Wu,Kunhang Li,You Zhou,Bo Zheng,Haiyang Liu*

Main category: cs.CV

TL;DR: FloodDiffusion 是一种新型的文本驱动、流式人体动作生成框架，能够在实时延迟下生成与文本对齐的连续动作序列。通过改进扩散强制（diffusion forcing）框架，引入双向注意力、下三角时间调度和连续时变文本条件，解决了传统方法在建模真实运动分布上的不足，首次在 HumanML3D 基准上达到 FID 0.057 的先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在流式动作生成中依赖分块或自回归结构，存在延迟高、连贯性差的问题。需要一种更高效且能保持时间一致性与自然性的生成框架。

Method: 采用改进的扩散强制框架，结合双向注意力机制、下三角时间调度策略以及连续时变的文本条件注入方式，实现对时变控制信号下的动作序列建模。

Result: 在 HumanML3D 基准上实现了 FID 0.057，为当前流式动作生成任务的最先进水平，同时支持实时生成与无缝衔接。

Conclusion: FloodDiffusion 成功将扩散强制框架应用于流式人体动作生成任务，通过关键设计改进显著提升了生成质量与实时性，为未来文本驱动动作生成提供了新范式。

Abstract: We present FloodDiffusion, a new framework for text-driven, streaming human motion generation. Given time-varying text prompts, FloodDiffusion generates text-aligned, seamless motion sequences with real-time latency. Unlike existing methods that rely on chunk-by-chunk or auto-regressive model with diffusion head, we adopt a diffusion forcing framework to model this time-series generation task under time-varying control events. We find that a straightforward implementation of vanilla diffusion forcing (as proposed for video models) fails to model real motion distributions. We demonstrate that to guarantee modeling the output distribution, the vanilla diffusion forcing must be tailored to: (i) train with a bi-directional attention instead of casual attention; (ii) implement a lower triangular time scheduler instead of a random one; (iii) utilize a continues time-varying way to introduce text conditioning. With these improvements, we demonstrate in the first time that the diffusion forcing-based framework achieves state-of-the-art performance on the streaming motion generation task, reaching an FID of 0.057 on the HumanML3D benchmark. Models, code, and weights are available. https://shandaai.github.io/FloodDiffusion/

</details>


### [33] [CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding](https://arxiv.org/abs/2512.03558)
*Huy Quang Ung,Guillaume Habault,Yasutaka Nishimura,Hao Niu,Roberto Legaspi,Tomoki Oya,Ryoichi Kojima,Masato Taya,Chihiro Ono,Atsunori Minamikawa,Yan Liu*

Main category: cs.CV

TL;DR: 本文提出CartoMapQA，一个用于评估视觉-语言模型（LVLMs）地图理解能力的基准数据集。该数据集包含2000多个样本，涵盖符号识别、信息提取、比例尺解读和路径推理等多层次地图理解任务。实验表明，现有LVLMs在地图语义理解、地理空间推理及OCR相关错误方面仍存在显著挑战。研究为未来模型改进提供了方向，并支持导航、地理搜索和城市规划等实际应用。数据与代码已开源。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型在地图理解方面的能力尚未得到充分探索，缺乏专门评估其地图解析能力的基准数据集，限制了模型在地理信息处理任务中的发展。

Method: 构建并发布CartoMapQA数据集，包含2000多个地图-问题-答案对，覆盖低、中、高阶地图理解任务；使用多种开源与专有LVLM进行评估，分析其在地图理解上的表现与缺陷。

Result: LVLMs在地图特定语义理解、地理空间推理能力上表现不足，且容易出现OCR相关错误；通过该基准可有效识别模型弱点，推动模型优化。

Conclusion: CartoMapQA为评估和提升视觉-语言模型的地图理解能力提供了有力工具，有助于实现更可靠、实用的地理智能应用。

Abstract: The rise of Visual-Language Models (LVLMs) has unlocked new possibilities for seamlessly integrating visual and textual information. However, their ability to interpret cartographic maps remains largely unexplored. In this paper, we introduce CartoMapQA, a benchmark specifically designed to evaluate LVLMs' understanding of cartographic maps through question-answering tasks. The dataset includes over 2000 samples, each composed of a cartographic map, a question (with open-ended or multiple-choice answers), and a ground-truth answer. These tasks span key low-, mid- and high-level map interpretation skills, including symbol recognition, embedded information extraction, scale interpretation, and route-based reasoning. Our evaluation of both open-source and proprietary LVLMs reveals persistent challenges: models frequently struggle with map-specific semantics, exhibit limited geospatial reasoning, and are prone to Optical Character Recognition (OCR)-related errors. By isolating these weaknesses, CartoMapQA offers a valuable tool for guiding future improvements in LVLM architectures. Ultimately, it supports the development of models better equipped for real-world applications that depend on robust and reliable map understanding, such as navigation, geographic search, and urban planning. Our source code and data are openly available to the research community at: https://github.com/ungquanghuy-kddi/CartoMapQA.git

</details>


### [34] [Optical Context Compression Is Just (Bad) Autoencoding](https://arxiv.org/abs/2512.03643)
*Ivan Yee Lee,Cheng Yang,Taylor Berg-Kirkpatrick*

Main category: cs.CV

TL;DR: 本文质疑了基于视觉的上下文压缩在语言模型中的有效性，通过对比DeepSeek-OCR的视觉编码器与简单的无参数均值池化和学习型分层编码器，发现后者在文本重建和语言建模任务中表现相当或更优，且视觉压缩在语言建模中甚至不如直接截断。研究指出当前对视觉压缩的兴奋情绪缺乏充分证据支持。


<details>
  <summary>Details</summary>
Motivation: 验证视觉基压缩是否真能为语言建模带来独特优势，检验DeepSeek-OCR的高保真重建结果是否意味着其在语言建模中同样有效。

Method: 在相同压缩比下，将DeepSeek-OCR的视觉编码器与无参数均值池化、学习型分层编码器进行比较，评估其在文本重建和语言建模任务中的表现。

Result: 简单方法在文本重建上匹配或超越视觉编码器，在语言建模中显著优于视觉压缩，且视觉压缩无法超越直接截断策略。

Conclusion: 当前对视觉上下文压缩的乐观预期缺乏实证支持，其在语言建模中的实际效用存疑，需谨慎对待相关技术宣传。

Abstract: DeepSeek-OCR demonstrates that rendered text can be reconstructed with high fidelity from a small number of vision tokens. This finding has sparked excitement about vision-based context compression for language models. But the evaluation stops at reconstruction; whether these representations help language modeling remains untested. We test two assumptions implicit in the optical-compression narrative: that vision-based compression provides unique advantages for text reconstruction from compressed representations, and that DeepSeek-OCR's reconstruction results are evidence that vision-based compression will be useful for language modeling. Comparing their vision encoder against simple alternatives--parameter-free mean pooling and a learned hierarchical encoder--we find that these simple approaches match or surpass vision for reconstruction at matched compression ratios, and outperform it for language modeling--where vision-based compression fails to beat truncation. The excitement around optical context compression outpaces the evidence. Code and checkpoints are available at https://github.com/ivnle/bad-autoencoding

</details>


### [35] [Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation](https://arxiv.org/abs/2512.03534)
*Subin Kim,Sangwoo Mo,Mamshad Nayeem Rizve,Yiran Xu,Difan Liu,Jinwoo Shin,Tobias Hinz*

Main category: cs.CV

TL;DR: 本文提出了一种名为PRIS的推理阶段扩展框架，通过在生成过程中动态重设计提示词来提升文本到视觉生成的精确对齐。该方法通过分析生成图像中的重复失败模式，并利用细粒度的事实校正验证器进行反馈，从而改进提示词并重新生成视觉内容。实验表明，该方法在文本到图像和文本到视频任务上均显著提升性能，如在VBench 2.0上提升15%。结果强调了在推理阶段同时扩展提示词与视觉生成的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视觉生成面临用户意图与生成结果对齐不精准的问题，现有方法仅通过增加采样步骤或种子数量来扩展生成过程，但受限于固定提示词，导致性能增长迅速停滞。因此，亟需一种能动态调整提示词以适应生成反馈的方法。

Method: 提出PRIS框架，通过在推理阶段自适应地重构提示词：首先评估生成的视觉内容，识别失败模式；然后利用元素级事实校正验证器提供细粒度对齐反馈；最后基于反馈重设计提示词并重新生成视觉内容。

Result: 在多个文本到图像和文本到视频基准测试中，PRIS展现出显著性能提升，尤其在VBench 2.0上达到15%的增益，证明联合扩展提示词与视觉生成可更有效利用推理阶段的缩放定律。

Conclusion: PRIS通过在推理阶段动态优化提示词，实现了对用户意图更精确的视觉表达，验证了提示词与视觉生成协同缩放在提升生成质量方面的关键作用。

Abstract: Achieving precise alignment between user intent and generated visuals remains a central challenge in text-to-visual generation, as a single attempt often fails to produce the desired output. To handle this, prior approaches mainly scale the visual generation process (e.g., increasing sampling steps or seeds), but this quickly leads to a quality plateau. This limitation arises because the prompt, crucial for guiding generation, is kept fixed. To address this, we propose Prompt Redesign for Inference-time Scaling, coined PRIS, a framework that adaptively revises the prompt during inference in response to the scaled visual generations. The core idea of PRIS is to review the generated visuals, identify recurring failure patterns across visuals, and redesign the prompt accordingly before regenerating the visuals with the revised prompt. To provide precise alignment feedback for prompt revision, we introduce a new verifier, element-level factual correction, which evaluates the alignment between prompt attributes and generated visuals at a fine-grained level, achieving more accurate and interpretable assessments than holistic measures. Extensive experiments on both text-to-image and text-to-video benchmarks demonstrate the effectiveness of our approach, including a 15% gain on VBench 2.0. These results highlight that jointly scaling prompts and visuals is key to fully leveraging scaling laws at inference-time. Visualizations are available at the website: https://subin-kim-cv.github.io/PRIS.

</details>


### [36] [Thinking with Programming Vision: Towards a Unified View for Thinking with Images](https://arxiv.org/abs/2512.03746)
*Zirun Guo,Minjie Hong,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.CV

TL;DR: 本文提出CodeVision，一种基于代码作为工具接口的灵活可扩展框架，使多模态大语言模型能够通过生成代码来调用任意图像操作，克服现有方法依赖固定工具集的局限性。通过两阶段训练（监督微调与强化学习），结合新构建的数据集和挑战性基准测试，显著提升模型在视角变化和多工具推理下的鲁棒性与效率，实现灵活工具组合、高效链式执行及运行时错误恢复等涌现能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在工具使用上受限于固定工具集，缺乏真实世界必要性和可扩展性；且对图像简单旋转或自然退化敏感，表现出明显脆弱性，亟需更鲁棒的工具推理机制。

Method: 提出CodeVision框架，将代码作为通用接口以调用任意图像操作；采用两阶段训练策略：首先在高质量多轮复杂工具组合与错误恢复数据集上进行监督微调（SFT），然后通过新型密集过程奖励函数进行强化学习（RL），鼓励策略性与高效性工具使用。

Result: 在Qwen2.5-VL和Qwen3-VL系列模型上实验表明，该方法显著提升性能，实现灵活工具组合、高效链式执行和鲁棒错误恢复等新兴能力，并在新构建的基准测试中验证了对视角变化和多工具推理的强大鲁棒性。

Conclusion: CodeVision通过代码即工具的方式，实现了多模态大模型在视觉推理中的灵活性与可扩展性，为构建真正鲁棒、通用的工具交互系统提供了有效路径。

Abstract: Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.

</details>


### [37] [CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation](https://arxiv.org/abs/2512.03540)
*Ruoxuan Zhang,Bin Wen,Hongxia Xie,Yi Yao,Songhan Zuo,Jian-Yu Jiang-Lin,Hong-Han Shuai,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: CookAnything 是一个基于扩散模型的灵活且一致的框架，能够根据任意长度的文本烹饪指令生成连贯、语义分明的图像序列。它引入了三个关键组件：（1）步骤级区域控制（SRC），在单个去噪过程中将文本步骤与图像区域对齐；（2）灵活的RoPE，一种步骤感知的位置编码机制，提升时间连贯性和空间多样性；（3）跨步骤一致性控制（CSCC），确保不同步骤间食材的一致性。实验表明，该方法在训练有无和训练自由设置下均优于现有方法，支持复杂多步指令的高质量视觉合成，在教学媒体和程序化内容创作中具有广泛应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在处理烹饪等结构化多步任务时表现不佳，且当前的食谱插图方法无法适应食谱长度的自然变化，通常生成固定数量的图像，缺乏灵活性和语义一致性。因此需要一种能处理任意长度输入并保持步骤间视觉一致性的新方法。

Method: 提出 CookAnything 框架，包含三个核心模块：(1) 步骤级区域控制（SRC），通过注意力机制将每一步的文本描述与图像特定区域对齐；(2) 灵活的 RoPE（Rotary Positional Encoding），引入步骤感知的位置编码以增强时空一致性；(3) 跨步骤一致性控制（CSCC），利用特征约束确保关键食材在各步骤中的视觉一致性。整个过程在统一的扩散模型架构中完成，支持端到端训练与推理。

Result: 在多个食谱插图基准测试中，CookAnything 在生成质量、步骤连贯性、语义准确性和食材一致性方面均显著优于现有方法，尤其在处理长食谱或非标准长度食谱时表现出更强的鲁棒性和灵活性。此外，其在无需额外训练的情况下也能实现良好性能，证明了方法的泛化能力。

Conclusion: CookAnything 成功解决了多步烹饪指令生成中的结构对齐、时间连贯性和视觉一致性难题，为复杂指令驱动的视觉合成提供了一个高效、可扩展的解决方案，具有广泛应用于教育、内容创作和交互式指导系统等场景的潜力。

Abstract: Cooking is a sequential and visually grounded activity, where each step such as chopping, mixing, or frying carries both procedural logic and visual semantics. While recent diffusion models have shown strong capabilities in text-to-image generation, they struggle to handle structured multi-step scenarios like recipe illustration. Additionally, current recipe illustration methods are unable to adjust to the natural variability in recipe length, generating a fixed number of images regardless of the actual instructions structure. To address these limitations, we present CookAnything, a flexible and consistent diffusion-based framework that generates coherent, semantically distinct image sequences from textual cooking instructions of arbitrary length. The framework introduces three key components: (1) Step-wise Regional Control (SRC), which aligns textual steps with corresponding image regions within a single denoising process; (2) Flexible RoPE, a step-aware positional encoding mechanism that enhances both temporal coherence and spatial diversity; and (3) Cross-Step Consistency Control (CSCC), which maintains fine-grained ingredient consistency across steps. Experimental results on recipe illustration benchmarks show that CookAnything performs better than existing methods in training-based and training-free settings. The proposed framework supports scalable, high-quality visual synthesis of complex multi-step instructions and holds significant potential for broad applications in instructional media, and procedural content creation.

</details>


### [38] [AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition](https://arxiv.org/abs/2512.03794)
*Zichuan Lin,Yicheng Liu,Yang Yang,Lvfang Tao,Deheng Ye*

Main category: cs.CV

TL;DR: AdaptVision 是一种新型高效视觉语言模型（VLM），通过类人主动视觉机制实现自适应视觉标记获取。它采用粗到精策略，先用低分辨率图像压缩视觉标记，必要时调用边界框工具裁剪关键区域以补充信息。利用强化学习框架训练，引入解耦回合策略优化（DTPO），将学习目标分为工具使用优化和准确率提升两部分，并分别计算优势值，从而更有效地优化模型。在多个VQA基准测试中，AdaptVision 在保持优异性能的同时，显著减少了视觉标记的消耗，优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有高效VLM方法依赖固定比例压缩视觉标记，缺乏根据任务需求自适应调整的能力，导致计算资源浪费。为解决这一问题，研究提出让VLM能自主决定每张图像所需的最小视觉标记数，受人类主动视觉启发。

Method: AdaptVision 采用粗到精的自适应视觉标记获取策略：首先处理低分辨率图像生成压缩视觉标记；当模型判断需要更多信息时，调用边界框工具裁剪关键区域并获取额外视觉信息。训练采用强化学习框架，核心是解耦回合策略优化（DTPO），将目标分解为工具学习与准确率提升两个独立目标，并分别计算对应的优势值进行优化。

Result: 在多个主流VQA数据集上，AdaptVision 在保持甚至超越现有方法性能的前提下，显著降低了视觉标记的使用量，证明了其在效率与准确性之间的优越平衡。

Conclusion: AdaptVision 成功实现了视觉语言模型对视觉标记的自适应获取，通过主动、动态地选择关键视觉信息，大幅降低计算开销，同时维持高精度，为未来高效VLM设计提供了新范式。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.

</details>


### [39] [V-ITI: Mitigating Hallucinations in Multimodal Large Language Models via Visual Inference-Time Intervention](https://arxiv.org/abs/2512.03542)
*Nan Sun,Zhenyu Zhang,Xixun Lin,Kun Wang,Yanmin Shang,Naibin Gu,Shuohuan Wang,Yu Sun,Hua Wu,Haifeng Wang,Yanan Cao*

Main category: cs.CV

TL;DR: 本文提出V-ITI，一种轻量级的视觉推理时干预框架，通过头级别激活模式检测视觉忽视问题，并仅在检测到时进行干预，有效减少幻觉并避免过度干预。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽能缓解多模态大模型中的幻觉问题，但大多关注‘如何干预’而非‘何时干预’，导致过干预问题，引入新幻觉和计算开销。

Method: 提出V-ITI框架，包含视觉忽视检测器（基于头级别判别探针）与视觉召回干预器（仅在检测到忽视时使用预存视觉激活信息调节激活值）。

Result: 在八个基准测试和多个多模态大模型家族上，V-ITI一致减轻视觉相关幻觉，同时保持任务整体性能。

Conclusion: 通过精准识别视觉忽视并适时干预，V-ITI在不增加过多计算负担的前提下，显著提升多模态大模型的可靠性与准确性。

Abstract: Multimodal Large Language Models (MLLMs) excel in numerous vision-language tasks yet suffer from hallucinations, producing content inconsistent with input visuals, that undermine reliability in precision-sensitive domains. This issue stems from a fundamental problem of visual neglect, where models fail to adequately prioritize input images. Existing methods typically alleviate hallucinations by intervening in the attention score or output logits, focusing on "how to intervene" but overlooking the prerequisite "when to intervene", which leads to the "over-intervention" problem and subsequently introduces new hallucinations and unnecessary computational overhead. To address this gap, we first investigate the mechanism of visual neglect and reveal it can be accurately detected via head-level activation patterns in MLLMs. We thus propose V-ITI, a lightweight visual inference-time intervention framework integrating a Visual Neglect Detector that identifies visual neglect via head-level discriminative probes and a Visual Recall Intervenor that modulates activations with prestored visual activation information only when the visual neglect is detected. Extensive experiments across eight benchmarks and different MLLM families demonstrate that V-ITI consistently mitigates vision-related hallucinations while preserving general task performance.

</details>


### [40] [Stable Signer: Hierarchical Sign Language Generative Model](https://arxiv.org/abs/2512.04048)
*Sen Fang,Yalin Feng,Hongbin Zhong,Yanxin Zhang,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 本文提出一种名为Stable Signer的新模型，用于简化传统手语生成流程，将手语生成任务重新定义为端到端的层次化生成任务，仅包含文本理解（Prompt2Gloss, Text2Gloss）和Pose2Vid两个阶段。通过引入SLUL（Sign Language Understanding Linker）进行文本理解，并使用SLP-MoE手势渲染专家模块生成手部动作，实现高质量、多风格的手语视频生成。SLUL采用新提出的语义感知词素掩码损失（SAGM Loss）进行训练，性能相比当前最先进方法提升48.6%。


<details>
  <summary>Details</summary>
Motivation: 传统手语生成流程存在文本转换不准确、姿态生成误差大、姿态转视频渲染质量差等问题，导致误差逐级累积，进展缓慢。因此需要简化流程，优化任务目标，减少中间环节带来的误差。

Method: 提出Stable Signer模型，将手语生成重构为端到端的层次化生成任务；引入SLUL进行文本理解，采用SAGM Loss训练；设计SLP-MoE手势渲染专家块生成手部动作，实现从文本直接生成高质量手语视频。

Result: SLUL在性能上相比当前最先进方法提升48.6%，整体生成效果更高质量、支持多风格，且有效降低误差累积。

Conclusion: Stable Signer通过简化结构、优化任务流程与引入创新模块，显著提升了手语生成的质量与效率，为手语视频生成提供了新的高效范式。

Abstract: Sign Language Production (SLP) is the process of converting the complex input text into a real video. Most previous works focused on the Text2Gloss, Gloss2Pose, Pose2Vid stages, and some concentrated on Prompt2Gloss and Text2Avatar stages. However, this field has made slow progress due to the inaccuracy of text conversion, pose generation, and the rendering of poses into real human videos in these stages, resulting in gradually accumulating errors. Therefore, in this paper, we streamline the traditional redundant structure, simplify and optimize the task objective, and design a new sign language generative model called Stable Signer. It redefines the SLP task as a hierarchical generation end-to-end task that only includes text understanding (Prompt2Gloss, Text2Gloss) and Pose2Vid, and executes text understanding through our proposed new Sign Language Understanding Linker called SLUL, and generates hand gestures through the named SLP-MoE hand gesture rendering expert block to end-to-end generate high-quality and multi-style sign language videos. SLUL is trained using the newly developed Semantic-Aware Gloss Masking Loss (SAGM Loss). Its performance has improved by 48.6% compared to the current SOTA generation methods.

</details>


### [41] [Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching](https://arxiv.org/abs/2512.03553)
*Wei Chee Yew,Hailun Xu,Sanjay Saha,Xiaotian Fan,Hiok Hian Ong,David Yuchen Wang,Kanchan Sarkar,Zhenheng Yang,Danhui Guan*

Main category: cs.CV

TL;DR: 本文提出一种混合内容审核框架，结合监督分类与基于参考的相似性匹配，以应对直播环境中显性和新型违规内容的挑战。该框架利用多模态大语言模型（MLLM）提升准确率并保持轻量推理，在生产环境中分类管道达到80%精确率下67%召回率，相似性管道在相同条件下达76%召回率。大规模A/B测试显示用户观看不良直播时长减少6-8%，证明该方法在可扩展性和适应性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核系统难以应对直播环境中快速演变的违规内容，尤其是新型或隐蔽的违规行为，传统分类器对未见过的违规形式检测能力有限，亟需一种既能识别已知违规又能发现新类型违规的高效、多模态解决方案。

Method: 提出一种混合审核框架：使用监督分类处理已知违规内容，采用基于参考的相似性匹配检测新颖或细微违规；多模态输入（文本、音频、视觉）通过两个并行管道处理，利用多模态大语言模型（MLLM）进行知识蒸馏以提升性能同时控制推理开销。

Result: 分类管道在80%精确率下实现67%召回率，相似性管道在相同条件下实现76%召回率；大规模A/B测试验证系统有效降低用户观看不良直播的比例，减少6-8%。

Conclusion: 所提出的混合框架在生产规模上展现出良好的鲁棒性与可扩展性，能够兼顾已知违规和新兴对抗行为的检测，为多模态内容治理提供了高效且自适应的解决方案。

Abstract: Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.

</details>


### [42] [GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models](https://arxiv.org/abs/2512.03566)
*Hao Sun,Lei Fan,Donglin Di,Shaohui Liu*

Main category: cs.CV

TL;DR: GAOT 是一个三阶段框架，旨在从文本提示生成3D关节物体。它结合了扩散模型和超图学习，首先微调点云生成模型以获得粗略的物体表示，然后利用超图学习方法对这些表示进行细化，将物体部件表示为图顶点，最后通过扩散模型生成关节（表示为图边）。在 PartNet-Mobility 数据集上的实验表明该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型难以根据文本提示生成3D关节物体，缺乏文本描述与3D关节结构之间的有效映射，因此需要一种能够将文本描述转化为高质量3D关节物体表示的方法。

Method: 提出三阶段框架：1）微调点云生成模型生成粗略物体表示；2）设计基于超图的学习方法，将物体部件作为图顶点进行结构优化；3）使用扩散模型生成关节（图边），从而构建完整的关节物体。

Result: 在 PartNet-Mobility 数据集上，该方法在定性和定量评估中均表现优异，显著优于现有方法，证明了其生成高质量3D关节物体的有效性。

Conclusion: GAOT 通过融合扩散模型与超图学习，成功实现了从文本到3D关节物体的生成，填补了文本引导生成与3D关节结构之间的重要空白，为未来文本驱动的3D内容创作提供了新范式。

Abstract: Articulated object generation has seen increasing advancements, yet existing models often lack the ability to be conditioned on text prompts. To address the significant gap between textual descriptions and 3D articulated object representations, we propose GAOT, a three-phase framework that generates articulated objects from text prompts, leveraging diffusion models and hypergraph learning in a three-step process. First, we fine-tune a point cloud generation model to produce a coarse representation of objects from text prompts. Given the inherent connection between articulated objects and graph structures, we design a hypergraph-based learning method to refine these coarse representations, representing object parts as graph vertices. Finally, leveraging a diffusion model, the joints of articulated objects-represented as graph edges-are generated based on the object parts. Extensive qualitative and quantitative experiments on the PartNet-Mobility dataset demonstrate the effectiveness of our approach, achieving superior performance over previous methods.

</details>


### [43] [Global-Local Aware Scene Text Editing](https://arxiv.org/abs/2512.03574)
*Fuxiang Yang,Tonghua Su,Donglin Di,Yin Chen,Xiangqian Wu,Zhongjie Wang,Lei Fan*

Main category: cs.CV

TL;DR: 提出一种名为GLASTE的端到端框架，用于解决场景文本编辑中的不一致性和长度不敏感性问题。通过结合全局上下文与局部特征，设计全局-局部组合结构、联合损失函数，并增强文本图像特征以保持风格一致性与整体和谐性。同时，将文本风格表示为与图像尺寸无关的向量，支持不同尺寸目标文本图像的适配，并采用仿射融合保持宽高比不变。在真实数据集上的实验表明，该方法在定量和定性结果上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有场景文本编辑方法在文本风格保持和背景纹理一致性方面存在不足，尤其在处理文本长度变化较大时表现不佳，因此需要一种能够同时考虑全局上下文与局部细节的新方法。

Method: 提出GLASTE框架，包含全局-局部组合结构、联合全局与局部损失、文本风格向量表示以及仿射融合策略，以实现对文本风格的跨尺寸迁移和编辑区域的无缝融合。

Result: 在多个真实世界数据集上进行的大量实验验证了GLASTE的有效性，其在定量指标和视觉效果上均优于现有方法，显著缓解了不一致性和长度不敏感问题。

Conclusion: GLASTE通过融合全局与局部信息，有效提升了场景文本编辑的质量，尤其在长文本编辑和风格一致性方面表现出色，是当前最先进的方法之一。

Abstract: Scene Text Editing (STE) involves replacing text in a scene image with new target text while preserving both the original text style and background texture. Existing methods suffer from two major challenges: inconsistency and length-insensitivity. They often fail to maintain coherence between the edited local patch and the surrounding area, and they struggle to handle significant differences in text length before and after editing. To tackle these challenges, we propose an end-to-end framework called Global-Local Aware Scene Text Editing (GLASTE), which simultaneously incorporates high-level global contextual information along with delicate local features. Specifically, we design a global-local combination structure, joint global and local losses, and enhance text image features to ensure consistency in text style within local patches while maintaining harmony between local and global areas. Additionally, we express the text style as a vector independent of the image size, which can be transferred to target text images of various sizes. We use an affine fusion to fill target text images into the editing patch while maintaining their aspect ratio unchanged. Extensive experiments on real-world datasets validate that our GLASTE model outperforms previous methods in both quantitative metrics and qualitative results and effectively mitigates the two challenges.

</details>


### [44] [UniComp: Rethinking Video Compression Through Informational Uniqueness](https://arxiv.org/abs/2512.03575)
*Chao Yuan,Shimin Chen,Minliang Lin,Limeng Qiao,Guanglu Wan,Lin Ma*

Main category: cs.CV

TL;DR: UniComp是一种基于信息独特性的视频压缩框架，通过最小化保留与完整标记之间的条件熵来提升视频表示的信息保真度。该方法引入信息独特性概念以衡量标记间的内在冗余，并设计了帧组融合、标记分配和空间动态压缩三个模块，实现语义帧分组、自适应资源分配和细粒度空间压缩。实验表明，UniComp在计算资源受限的情况下能更有效地保留关键视觉标记，显著优于现有压缩方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力的压缩方法在有限计算预算下难以有效保留关键视觉信息，因此需要一种新的机制来提升压缩效率与信息保真度。

Method: 从信息论出发，将视频压缩建模为最小化条件熵的优化问题；提出信息独特性度量标记间冗余；设计帧组融合、标记分配和空间动态压缩三模块实现逐步优化。

Result: UniComp在多种基准测试中均优于现有压缩方法，尤其在低计算开销下保持更高的视觉信息保真度，验证了信息独特性对压缩效果的关键作用。

Conclusion: 信息独特性是提升视频压缩性能的核心因素，UniComp框架通过合理利用信息独特性，在有限计算资源下实现了更优的压缩表现。

Abstract: Distinct from attention-based compression methods, this paper presents an information uniqueness driven video compression framework, termed UniComp, which aims to maximize the information fidelity of video representations under constrained computational budgets. Starting from the information-theoretic perspective, we formulate the vision compression as an optimization problem that minimizes conditional entropy (reconstruction error) between retained and full tokens. To achieve this, we introduce the notion of information uniqueness to measure intrinsic redundancy among tokens to link with reconstruction error. Based on uniqueness, we design three modules-Frame Group Fusion, Token Allocation, and Spatial Dynamic Compression-that progressively perform semantic frame grouping, adaptive resource allocation, and fine-grained spatial compression. Extensive experiments demonstrate that UniComp consistently outperforms existing compression methods in preserving essential visual tokens under limited computational budgets, highlighting the pivotal role of information uniqueness in token compression efficacy.

</details>


### [45] [Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning](https://arxiv.org/abs/2512.03577)
*Yizhi Zhang,Lei Fan,Zhulin Tao,Donglin Di,Yang Song,Sidong Liu,Cong Cong*

Main category: cs.CV

TL;DR: 本文提出了一种名为跨染色对比学习（CSCL）的两阶段预训练框架，用于构建可迁移的全切片图像（WSI）表示。通过构建一个五染色对齐数据集（H&E、HER2、KI67、ER、PGR），实现了多染色图像间的配准，并利用轻量级适配器进行基于补丁的对比对齐，提升H&E特征与相应IHC上下文信息的兼容性；同时采用多重实例学习（MIL）和跨染色注意力融合模块，在滑动级别整合不同染色的特征并保证跨染色嵌入的一致性。实验表明该方法在癌症亚型分类、免疫组化生物标志物状态分类及生存预测任务中均取得显著提升，生成高质量、可迁移的H&E滑动级表示。


<details>
  <summary>Details</summary>
Motivation: 当前计算病理学中，尽管多染色（如免疫组化，IHC）信息能丰富仅基于H&E的特征，但因缺乏高质量对齐的多染色数据集，导致染色间错位问题严重，影响局部特征一致性与整体滑动级嵌入质量，限制了跨染色表示学习的发展。

Method: 提出跨染色对比学习（CSCL）框架，包含两个阶段：第一阶段使用轻量级适配器进行补丁级对比对齐，增强H&E与对应IHC特征的匹配度；第二阶段采用多重实例学习（MIL）结合跨染色注意力融合模块和全局对齐模块，实现滑动级特征整合与跨染色一致性建模。

Result: 在癌症亚型分类、IHC生物标志物状态分类和生存预测等任务上均取得显著性能提升，验证了所提方法生成高质量、可迁移的H&E滑动级表示的有效性。

Conclusion: 通过构建对齐的五染色数据集并设计有效的跨染色学习框架，本研究显著提升了全切片图像的表征能力，为多染色协同分析提供了新范式。

Abstract: Universal, transferable whole-slide image (WSI) representations are central to computational pathology. Incorporating multiple markers (e.g., immunohistochemistry, IHC) alongside H&E enriches H&E-based features with diverse, biologically meaningful information. However, progress is limited by the scarcity of well-aligned multi-stain datasets. Inter-stain misalignment shifts corresponding tissue across slides, hindering consistent patch-level features and degrading slide-level embeddings. To address this, we curated a slide-level aligned, five-stain dataset (H&E, HER2, KI67, ER, PGR) to enable paired H&E-IHC learning and robust cross-stain representation. Leveraging this dataset, we propose Cross-Stain Contrastive Learning (CSCL), a two-stage pretraining framework with a lightweight adapter trained using patch-wise contrastive alignment to improve the compatibility of H&E features with corresponding IHC-derived contextual cues, and slide-level representation learning with Multiple Instance Learning (MIL), which uses a cross-stain attention fusion module to integrate stain-specific patch features and a cross-stain global alignment module to enforce consistency among slide-level embeddings across different stains. Experiments on cancer subtype classification, IHC biomarker status classification, and survival prediction show consistent gains, yielding high-quality, transferable H&E slide-level representations. The code and data are available at https://github.com/lily-zyz/CSCL.

</details>


### [46] [Dynamic Optical Test for Bot Identification (DOT-BI): A simple check to identify bots in surveys and online processes](https://arxiv.org/abs/2512.03580)
*Malte Bleeker,Mauro Gotsch*

Main category: cs.CV

TL;DR: DOT-BI 是一种利用人类对运动的感知差异来区分真人与自动化系统的快速简便方法。通过在动态帧中隐藏数字，仅凭运动和尺度变化使人类可识别，而算法无法有效提取信息。实验表明，先进多模态模型无法识别，而绝大多数人类参与者可在10秒内完成任务，且无使用负担。代码与预生成测试已公开。


<details>
  <summary>Details</summary>
Motivation: 现有反机器人机制常被自动化系统绕过，需要一种基于人类独特感知能力的新型验证方法，以更可靠地区分真人与机器。

Method: 在动态图像序列中，将一个数字以与背景相同的黑白纹理呈现，仅通过其相对于背景的运动和缩放变化，使人类能够察觉，而算法难以捕捉有效信号。

Result: GPT-5-Thinking 和 Gemini 2.5 Pro 等先进模型均未能正确识别隐藏数字；在线调查中99.5%的人类参与者成功完成，平均耗时10.7秒，实验室研究显示用户体验无负面影响。

Conclusion: DOT-BI 利用人类对运动的感知优势，提供了一种高效、易部署的反机器人验证机制，具备良好的实用性和可扩展性。

Abstract: We propose the Dynamic Optical Test for Bot Identification (DOT-BI): a quick and easy method that uses human perception of motion to differentiate between human respondents and automated systems in surveys and online processes. In DOT-BI, a 'hidden' number is displayed with the same random black-and-white pixel texture as its background. Only the difference in motion and scale between the number and the background makes the number perceptible to humans across frames, while frame-by-frame algorithmic processing yields no meaningful signal. We conducted two preliminary assessments. Firstly, state-of-the-art, video-capable, multimodal models (GPT-5-Thinking and Gemini 2.5 Pro) fail to extract the correct value, even when given explicit instructions about the mechanism. Secondly, in an online survey (n=182), 99.5% (181/182) of participants solved the task, with an average end-to-end completion time of 10.7 seconds; a supervised lab study (n=39) found no negative effects on perceived ease-of-use or completion time relative to a control. We release code to generate tests and 100+ pre-rendered variants to facilitate adoption in surveys and online processes.

</details>


### [47] [Harnessing Hypergraphs in Geometric Deep Learning for 3D RNA Inverse Folding](https://arxiv.org/abs/2512.03592)
*Guang Yang,Lei Fan*

Main category: cs.CV

TL;DR: 本文提出了一种名为HyperRNA的生成模型，用于解决RNA逆折叠问题，通过超图结构捕捉RNA序列与结构间的高阶依赖关系，实现了对RNA序列的高效设计。该模型采用编码-解码架构，结合3-bead粗粒度表示和注意力嵌入模块，在PDBBind和RNAsolo数据集上表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: RNA逆折叠问题在RNA设计中至关重要，但其复杂性源于序列与结构之间的非线性关系，传统方法难以有效建模高阶相互作用，因此需要更先进的模型来提升设计精度和效率。

Method: HyperRNA采用编码-解码架构，首先基于3-bead粗粒度表示构建原子坐标图；接着利用注意力嵌入模块和超图编码器捕获高阶依赖关系；最后通过自回归方式生成目标RNA序列。

Result: 在PDBBind和RNAsolo数据集上的实验表明，HyperRNA在RNA序列生成及RNA-蛋白质复合物序列生成任务中均显著优于现有方法，验证了超图建模在RNA工程中的有效性。

Conclusion: HyperRNA成功将超图结构引入RNA序列设计，不仅提升了逆折叠任务的性能，也为基于结构的RNA工程提供了新的技术路径。

Abstract: The RNA inverse folding problem, a key challenge in RNA design, involves identifying nucleotide sequences that can fold into desired secondary structures, which are critical for ensuring molecular stability and function. The inherent complexity of this task stems from the intricate relationship between sequence and structure, making it particularly challenging. In this paper, we propose a framework, named HyperRNA, a generative model with an encoder-decoder architecture that leverages hypergraphs to design RNA sequences. Specifically, our HyperRNA model consists of three main components: preprocessing, encoding and decoding.
  In the preprocessing stage, graph structures are constructed by extracting the atom coordinates of RNA backbone based on 3-bead coarse-grained representation. The encoding stage processes these graphs, capturing higher order dependencies and complex biomolecular interactions using an attention embedding module and a hypergraph-based encoder. Finally, the decoding stage generates the RNA sequence in an autoregressive manner. We conducted quantitative and qualitative experiments on the PDBBind and RNAsolo datasets to evaluate the inverse folding task for RNA sequence generation and RNA-protein complex sequence generation. The experimental results demonstrate that HyperRNA not only outperforms existing RNA design methods but also highlights the potential of leveraging hypergraphs in RNA engineering.

</details>


### [48] [CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures](https://arxiv.org/abs/2512.03593)
*David Svitov,Pietro Morerio,Lourdes Agapito,Alessio Del Bue*

Main category: cs.CV

TL;DR: CloseUpAvatar 是一种新型的可动人体虚拟化身表示方法，能够处理更广泛的相机运动，在近距离视角下保持高质量渲染。该方法使用一组带有低频和高频纹理的纹理平面来表示虚拟化身，并根据相机距离自动切换和调节高频纹理的影响，从而在不同相机位置下实现逼真的渲染效果。实验基于 ActorsHQ 数据集，结果表明该方法在多种新视角下的渲染质量上优于现有方法，同时保持高帧率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理广泛相机运动时，难以在近距离视角下维持高质量渲染，且无法灵活调整渲染细节以适应不同相机距离。因此需要一种能根据相机距离动态调整渲染质量的新型虚拟化身表示方法。

Method: CloseUpAvatar 将虚拟化身表示为一组纹理平面，包含两组可学习的纹理：低频和高频。系统根据相机与虚拟化身表面的距离，自动选择并渐进式减少高频纹理的影响，从而在不同距离下优化渲染质量。该方法通过限制所需的基本图元数量，保持高帧率。

Result: 在 ActorsHQ 数据集上的实验表明，CloseUpAvatar 在多种新视角下均实现了优于现有方法的定性和定量性能提升，同时保持了高帧率，适用于更广泛的相机姿态和距离。

Conclusion: CloseUpAvatar 通过动态调整纹理细节以适应相机距离，成功提升了虚拟化身在广泛相机运动下的渲染质量与效率，是一种高效且高质量的人体虚拟化身表示方法。

Abstract: We present a CloseUpAvatar - a novel approach for articulated human avatar representation dealing with more general camera motions, while preserving rendering quality for close-up views. CloseUpAvatar represents an avatar as a set of textured planes with two sets of learnable textures for low and high-frequency detail. The method automatically switches to high-frequency textures only for cameras positioned close to the avatar's surface and gradually reduces their impact as the camera moves farther away. Such parametrization of the avatar enables CloseUpAvatar to adjust rendering quality based on camera distance ensuring realistic rendering across a wider range of camera orientations than previous approaches. We provide experiments using the ActorsHQ dataset with high-resolution input images. CloseUpAvatar demonstrates both qualitative and quantitative improvements over existing methods in rendering from novel wide range camera positions, while maintaining high FPS by limiting the number of required primitives.

</details>


### [49] [Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding](https://arxiv.org/abs/2512.03601)
*Haoran Zhou,Gim Hee Lee*

Main category: cs.CV

TL;DR: Motion4D提出了一种新颖的框架，将2D基础模型的先验知识整合到统一的4D高斯点云表示中，以解决动态场景分析中的3D一致性问题。通过分阶段的局部优化和全局联合优化，结合3D置信度图与自适应重采样机制提升运动精度，并通过迭代优化语义场与SAM2提示来增强语义一致性。实验表明，该方法在点跟踪、视频对象分割和新视角合成等任务上显著优于现有2D和3D方法。


<details>
  <summary>Details</summary>
Motivation: 现有2D基础模型虽具备强泛化能力，但在复杂3D环境中缺乏3D一致性，导致空间错位和时间闪烁，难以准确理解场景几何与运动关系。因此亟需一种能融合2D先验并保持3D一致性的方法。

Method: Motion4D采用双阶段迭代优化：(1) 顺序优化，分阶段更新运动与语义场以维持局部一致性；(2) 全局优化，联合精炼所有属性以实现长期一致性。引入3D置信度图动态调整运动先验，设计自适应重采样插入新高斯点至低代表区域。同时，通过交替优化语义场与SAM2提示，迭代提升语义一致性。

Result: 在点跟踪、视频对象分割和新视角合成等多个任务上，Motion4D显著超越2D基础模型和现有3D方法，展现出更强的3D一致性与场景理解能力。

Conclusion: Motion4D成功地将2D基础模型的强大表征能力与3D几何一致性相结合，为单目视频中的动态场景理解提供了高效且鲁棒的解决方案。

Abstract: Recent advancements in foundation models for 2D vision have substantially improved the analysis of dynamic scenes from monocular videos. However, despite their strong generalization capabilities, these models often lack 3D consistency, a fundamental requirement for understanding scene geometry and motion, thereby causing severe spatial misalignment and temporal flickering in complex 3D environments. In this paper, we present Motion4D, a novel framework that addresses these challenges by integrating 2D priors from foundation models into a unified 4D Gaussian Splatting representation. Our method features a two-part iterative optimization framework: 1) Sequential optimization, which updates motion and semantic fields in consecutive stages to maintain local consistency, and 2) Global optimization, which jointly refines all attributes for long-term coherence. To enhance motion accuracy, we introduce a 3D confidence map that dynamically adjusts the motion priors, and an adaptive resampling process that inserts new Gaussians into under-represented regions based on per-pixel RGB and semantic errors. Furthermore, we enhance semantic coherence through an iterative refinement process that resolves semantic inconsistencies by alternately optimizing the semantic fields and updating prompts of SAM2. Extensive evaluations demonstrate that our Motion4D significantly outperforms both 2D foundation models and existing 3D-based approaches across diverse scene understanding tasks, including point-based tracking, video object segmentation, and novel view synthesis. Our code is available at https://hrzhou2.github.io/motion4d-web/.

</details>


### [50] [LAMP: Language-Assisted Motion Planning for Controllable Video Generation](https://arxiv.org/abs/2512.03619)
*Muhammed Burak Kizil,Enes Sanli,Niloy J. Mitra,Erkut Erdem,Aykut Erdem,Duygu Ceylan*

Main category: cs.CV

TL;DR: LAMP利用大语言模型（LLM）作为运动规划器，将自然语言描述转化为明确的3D运动轨迹，支持对象和相机运动的直接文本控制，通过设计特定于运动领域的领域特定语言（DSL）和大规模程序化数据集，显著提升运动可控性和用户意图对齐度，是首个实现从自然语言直接生成物体与摄像机运动的框架。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成技术在运动控制方面仍受限，无法有效支持复杂、电影级场景的动态组合，尤其缺乏直观的自然语言接口来指定物体动态和摄像机轨迹。

Method: 提出LAMP框架，引入运动领域特定语言（DSL），利用大语言模型的程序合成能力，将自然语言描述转换为结构化的运动程序，并映射为确定性的3D轨迹；构建大规模配对数据集（文本-运动程序-3D轨迹）以训练和评估系统。

Result: 实验表明，LAMP在运动可控性与用户意图一致性方面优于现有先进方法，首次实现了从自然语言直接生成物体与摄像机运动的端到端能力。

Conclusion: LAMP通过结合大语言模型与领域特定语言，为视频生成中的运动控制提供了高效、可解释且高度可控的新范式，推动了复杂动态场景的自动化创作。

Abstract: Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP's improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.

</details>


### [51] [ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation](https://arxiv.org/abs/2512.03621)
*Yaokun Li,Shuaixian Wang,Mantang Guo,Jiehui Huang,Taojun Ding,Mu Hu,Kaixuan Wang,Shaojie Shen,Guang Tan*

Main category: cs.CV

TL;DR: ReCamDriving 是一种纯视觉的、由摄像头控制的新型轨迹视频生成框架，利用密集且场景完整的3DGS渲染提供显式几何引导，实现精确的相机可控生成。通过两阶段训练策略避免对修复行为的过拟合，并提出基于3DGS的跨轨迹数据整理策略，构建了包含超过11万对平行轨迹视频的ParaDrive数据集，实验表明其在相机可控性和结构一致性上达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 现有修复类方法难以恢复复杂伪影，而基于LiDAR的方法依赖稀疏不完整的线索，因此需要一种更鲁棒、高精度的视觉驱动视频生成方案，以实现对相机轨迹和几何结构的精确控制。

Method: 采用两阶段训练：第一阶段使用相机位姿进行粗粒度控制，第二阶段引入3DGS渲染实现细粒度视角与几何引导；同时设计基于3DGS的跨轨迹数据整理策略，消除训练-测试间相机变换模式差异，支持从单目视频中可扩展地获取多轨迹监督信号。

Result: 在相机可控性与结构一致性方面表现卓越，显著优于现有方法，在大规模多轨迹视频生成任务中展现出强大潜力。

Conclusion: ReCamDriving 通过结合3DGS的几何完整性与两阶段训练机制，实现了高质量、精准可控的视频生成，为基于视觉的动态场景建模提供了新范式。

Abstract: We propose ReCamDriving, a purely vision-based, camera-controlled novel-trajectory video generation framework. While repair-based methods fail to restore complex artifacts and LiDAR-based approaches rely on sparse and incomplete cues, ReCamDriving leverages dense and scene-complete 3DGS renderings for explicit geometric guidance, achieving precise camera-controllable generation. To mitigate overfitting to restoration behaviors when conditioned on 3DGS renderings, ReCamDriving adopts a two-stage training paradigm: the first stage uses camera poses for coarse control, while the second stage incorporates 3DGS renderings for fine-grained viewpoint and geometric guidance. Furthermore, we present a 3DGS-based cross-trajectory data curation strategy to eliminate the train-test gap in camera transformation patterns, enabling scalable multi-trajectory supervision from monocular videos. Based on this strategy, we construct the ParaDrive dataset, containing over 110K parallel-trajectory video pairs. Extensive experiments demonstrate that ReCamDriving achieves state-of-the-art camera controllability and structural consistency.

</details>


### [52] [ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos](https://arxiv.org/abs/2512.03666)
*Qi'ao Xu,Tianwen Qian,Yuqian Fu,Kailing Li,Yang Jiao,Jiacheng Zhang,Xiaoling Wang,Liang He*

Main category: cs.CV

TL;DR: 本文提出ToG-Bench，首个面向头戴式视频的任务导向时空视频定位基准，强调基于任务目标而非简单描述来定位物体，支持显式-隐式双重定位及一对一多对象匹配，旨在推动具身智能中的感知与交互融合。


<details>
  <summary>Details</summary>
Motivation: 现有时空视频定位研究多局限于物体中心和描述性指令，忽视了具身智能体完成目标导向交互所需的任务推理能力，因此亟需一个更贴近真实任务场景的基准测试。

Method: 构建基于ScanNet数据集的ToG-Bench基准，采用半自动化流程（基础模型标注+人工修正）生成100段视频片段，共2704条任务导向指令，并设计任务级评估指标以支持多对象、显隐双重定位的评测。

Result: 实验表明任务导向的时空定位存在显著挑战，尤其在显隐对象识别和多对象定位方面表现不佳，揭示了当前模型在连接感知与任务执行之间的差距。

Conclusion: ToG-Bench为任务导向的时空视频定位提供了首个系统性基准，推动了具身智能中感知与任务推理的深度融合，未来工作应聚焦于提升模型对上下文推理与多对象协同的理解能力。

Abstract: A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..

</details>


### [53] [Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning](https://arxiv.org/abs/2512.03667)
*Ge-Peng Ji,Jingyi Liu,Deng-Ping Fan,Nick Barnes*

Main category: cs.CV

TL;DR: Colon-X 是一项开放倡议，旨在推进结肠镜检查中的多模态智能。研究构建了 ColonVQA，这是迄今最全面的结肠镜多模态数据集，包含超过110万条视觉问答条目，覆盖76种临床发现和18项多模态任务。研究进一步探索从多模态理解到临床推理的关键转变：(a) 系统评估22个多模态大语言模型在结肠镜检查中的泛化能力与鲁棒性，发现现有模型输出仍不可靠；(b) 提出基于临床推理的解决方案，构建 ColonReason 数据集，并开发首个 R1 风格的 ColonR1 模型，采用任务自适应奖励与梯度稳定优化技术，在数据稀缺条件下实现56.61%的整体准确率，优于监督微调25.22%，建立新的推理增强型结肠镜分析基准。所有资源公开可用。


<details>
  <summary>Details</summary>
Motivation: 当前结肠镜检查中的多模态理解模型缺乏临床可靠性，且从多模态理解向临床推理的过渡尚未被充分探索，亟需更稳健、可信赖的智能系统支持临床决策。

Method: 构建 ColonVQA 多模态数据集，评估22个 MLLM 的泛化与鲁棒性；设计多专家辩论标注流程构建 ColonReason 推理数据集；提出 ColonR1 模型，集成任务自适应奖励与梯度稳定优化技术以提升推理性能。

Result: ColonR1 在数据稀缺条件下达到56.61%整体准确率，相比监督微调提升25.22%，显著优于现有方法，建立了新的推理增强型结肠镜分析基准。

Conclusion: Colon-X 通过构建大规模多模态数据集与开发推理导向模型，推动了结肠镜检查中多模态智能向临床推理的演进，为未来智能辅助诊断系统提供了坚实基础。

Abstract: In this study, we present Colon-X, an open initiative aimed at advancing multimodal intelligence in colonoscopy. We begin by constructing ColonVQA, the most comprehensive multimodal dataset ever built for colonoscopy, featuring over 1.1M+ visual question answering entries across 76 clinical findings and 18 multimodal tasks. Beyond serving as a community-wide data foundation, we further investigate a critical yet underexplored transition in colonoscopy - evolving from multimodal understanding to clinical reasoning: (a) To capture the current landscape of multimodal understanding behaviors, we systematically assess the generalizability of 22 multimodal large language models and examine their reliability under human-induced perturbations. The results reveal that clinical outputs from leading MLLMs remain far from robust and trustworthy. (b) To narrow this gap, we further explore reasoning-centric intelligence tailored for colonoscopy. Specifically, we curate ColonReason, a clinically grounded reasoning dataset annotated through a multi-expert debating pipeline, and develop ColonR1, the first R1-styled model incorporating task-adaptive rewarding and gradient-stable optimization techniques. Under data-scarce conditions, our ColonR1 achieves 56.61% overall accuracy, outperforming supervised fine-tuning by 25.22%, and sets a new reasoning-enabled baseline for multimodal colonoscopy analysis. All data and model resources are publicly available at https://github.com/ai4colonoscopy/Colon-X.

</details>


### [54] [ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers](https://arxiv.org/abs/2512.03673)
*Feice Huang,Zuliang Han,Xing Zhou,Yihuang Chen,Lifei Zhu,Haoqian Wang*

Main category: cs.CV

TL;DR: 提出ConvRot，一种基于分组旋转的量化方法，利用正交哈达玛变换（RHT）抑制行和列方向的异常值，将复杂度从二次降低到线性。在此基础上设计了ConvLinear4bit模块，支持无需微调的W4A4推理，实现高效且高质量的图像生成。在FLUX.1-dev上实现2.26倍加速与4.05倍内存减少，是首个在扩散模型中实现即插即用W4A4推理的旋转量化方法。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型因规模增大带来的内存占用高和推理延迟问题，尤其针对现有旋转量化方法在处理扩散模型中的行/列异常值时效率低、开销大的问题。

Method: 提出ConvRot，采用分组旋转结合正交哈达玛变换（RHT），有效抑制行与列方向的异常值；设计ConvLinear4bit模块，集成旋转、量化、GEMM与反量化操作，支持无需重训练的W4A4推理。

Result: 在FLUX.1-dev上实现2.26倍推理速度提升和4.05倍内存压缩，同时保持图像质量，验证了方法的有效性和实用性。

Conclusion: ConvRot与ConvLinear4bit首次成功将旋转基量化应用于扩散模型的即插即用型W4A4推理，显著降低计算开销并维持生成质量，为大模型部署提供了新路径。

Abstract: Diffusion transformers have demonstrated strong capabilities in generating high-quality images. However, as model size increases, the growing memory footprint and inference latency pose significant challenges for practical deployment. Recent studies in large language models (LLMs) show that rotation-based techniques can smooth outliers and enable 4-bit quantization, but these approaches often incur substantial overhead and struggle with row-wise outliers in diffusion transformers. To address these challenges, we propose ConvRot, a group-wise rotation-based quantization method that leverages regular Hadamard transform (RHT) to suppress both row-wise and column-wise outliers while reducing complexity from quadratic to linear. Building on this, we design ConvLinear4bit, a plug-and-play module that integrates rotation, quantization, GEMM, and dequantization, enabling W4A4 inference without retraining and preserving visual quality. Experiments on FLUX.1-dev demonstrate a 2.26$\times$ speedup and 4.05$\times$ memory reduction while maintaining image fidelity. To our knowledge, this is the first application of rotation-based quantization for plug-and-play W4A4 inference in diffusion transformers.

</details>


### [55] [Out-of-the-box: Black-box Causal Attacks on Object Detectors](https://arxiv.org/abs/2512.03730)
*Melane Navaratnarajah,David A. Kelly,Hana Chockler*

Main category: cs.CV

TL;DR: BlackCAtt 是一种黑盒攻击算法和工具，利用最小且因果充分的像素集，生成可解释、不可察觉、可复现、与架构无关的物体检测器对抗性扰动。该方法结合因果像素与检测器生成的边界框，实现对检测结果的丢失、修改或新增。在 COCO 测试集上，相比基线方法，BlackCAtt 在移除检测、修改检测和触发虚假检测方面分别提升 2.7 倍、3.86 倍和 5.75 倍，且攻击图像接近原图，具有极强的隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性扰动方法多为白盒且依赖特定架构，难以解释其成功机制，限制了对攻击的理解和防御优化。本文旨在提出一种黑盒、可解释、通用性强且效果显著的攻击方法，以揭示攻击本质并促进模型鲁棒性提升。

Method: BlackCAtt 通过识别因果像素（causal pixels），结合物体检测器输出的边界框，构建针对检测器的黑盒对抗攻击。该方法不依赖模型内部结构，仅需观察输入输出，利用因果推理确定对检测结果影响最大的像素区域，从而生成精准、低感知的扰动。

Result: 在 COCO 数据集上，BlackCAtt 在移除检测、修改检测和引发虚假检测任务上的性能分别优于基线方法 2.7 倍、3.86 倍和 5.75 倍；攻击结果高度接近原始图像，具备极强的不可察觉性，验证了因果像素的有效性与攻击的精确性。

Conclusion: BlackCAtt 成功实现了跨架构、可解释、高精度且不可察觉的黑盒对抗攻击，揭示了因果像素在攻击中的核心作用，为理解与防御对抗攻击提供了新视角。

Abstract: Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.

</details>


### [56] [GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces](https://arxiv.org/abs/2512.03683)
*Melis Ocal,Xiaoyan Xing,Yue Li,Ngo Anh Vien,Sezer Karaoglu,Theo Gevers*

Main category: cs.CV

TL;DR: GaussianBlender 是一种开创性的前馈框架，用于文本驱动的3D风格化，可在推理时即时完成编辑。它通过空间分组的3D高斯点学习结构化、解耦的潜在空间，实现几何与外观的可控信息共享，并利用潜在扩散模型进行文本条件编辑。实验表明，该方法实现了快速、高保真、几何保持且多视角一致的风格化，优于需要实例级测试时优化的方法，推动了大规模、可普及的3D风格化应用。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D风格化方法依赖2D图像编辑器蒸馏，需耗时的逐资产优化，且受限于当前文本到图像模型，导致多视角不一致，难以满足大规模生产需求。

Method: 提出GaussianBlender框架，基于空间分组的3D高斯点学习解耦的潜在空间，通过潜在扩散模型实现文本条件下的即时编辑。

Result: GaussianBlender 实现了即时、高保真、几何保持、多视角一致的3D风格化，性能超越需测试时优化的方法，支持大规模实用化。

Conclusion: GaussianBlender 开启了高效、可扩展的文本驱动3D风格化新范式，为游戏开发、虚拟现实和数字艺术提供了实用化工具。

Abstract: 3D stylization is central to game development, virtual reality, and digital arts, where the demand for diverse assets calls for scalable methods that support fast, high-fidelity manipulation. Existing text-to-3D stylization methods typically distill from 2D image editors, requiring time-intensive per-asset optimization and exhibiting multi-view inconsistency due to the limitations of current text-to-image models, which makes them impractical for large-scale production. In this paper, we introduce GaussianBlender, a pioneering feed-forward framework for text-driven 3D stylization that performs edits instantly at inference. Our method learns structured, disentangled latent spaces with controlled information sharing for geometry and appearance from spatially-grouped 3D Gaussians. A latent diffusion model then applies text-conditioned edits on these learned representations. Comprehensive evaluations show that GaussianBlender not only delivers instant, high-fidelity, geometry-preserving, multi-view consistent stylization, but also surpasses methods that require per-instance test-time optimization - unlocking practical, democratized 3D stylization at scale.

</details>


### [57] [Active Visual Perception: Opportunities and Challenges](https://arxiv.org/abs/2512.03687)
*Yian Li,Xiaoyu Guo,Hao Zhang,Shuiwang Li,Xiaowei Dai*

Main category: cs.CV

TL;DR: 本文探讨了主动视觉感知在复杂环境中的潜力与挑战，强调其在机器人、自动驾驶、人机交互和监控系统中的关键作用，并分析了实时处理复杂视觉数据、动态环境决策以及多模态传感融合等主要障碍。


<details>
  <summary>Details</summary>
Motivation: 主动视觉感知能够通过动态调整传感器和注意力机制获取更丰富信息，相较于被动感知更具优势，但在实际应用中仍面临诸多技术挑战，亟需系统性研究以推动其广泛应用。

Method: 综述分析法，整合当前相关研究进展，从理论基础到实际应用进行系统梳理，识别核心问题与发展趋势。

Result: 明确了主动视觉感知的关键技术瓶颈，包括实时性、环境适应性和多源信息融合能力；提出了未来研究方向，如智能决策算法优化与跨模态学习框架构建。

Conclusion: 主动视觉感知具有广阔的应用前景，但要实现大规模落地，还需突破算法效率、系统鲁棒性和人机协同等关键技术难题。

Abstract: Active visual perception refers to the ability of a system to dynamically engage with its environment through sensing and action, allowing it to modify its behavior in response to specific goals or uncertainties. Unlike passive systems that rely solely on visual data, active visual perception systems can direct attention, move sensors, or interact with objects to acquire more informative data. This approach is particularly powerful in complex environments where static sensing methods may not provide sufficient information. Active visual perception plays a critical role in numerous applications, including robotics, autonomous vehicles, human-computer interaction, and surveillance systems. However, despite its significant promise, there are several challenges that need to be addressed, including real-time processing of complex visual data, decision-making in dynamic environments, and integrating multimodal sensory inputs. This paper explores both the opportunities and challenges inherent in active visual perception, providing a comprehensive overview of its potential, current research, and the obstacles that must be overcome for broader adoption.

</details>


### [58] [Structured Uncertainty Similarity Score (SUSS): Learning a Probabilistic, Interpretable, Perceptual Metric Between Images](https://arxiv.org/abs/2512.03701)
*Paula Seidler,Neill D. F. Campbell,Ivor J A Simpson*

Main category: cs.CV

TL;DR: SUSS 是一种新的感知相似性评分方法，通过生成式自监督学习建模图像的感知组件，使用结构化多元正态分布表示，并在像素空间中学习线性变换，实现可解释的、与人类感知高度一致的相似性评估。


<details>
  <summary>Details</summary>
Motivation: 现有深度感知损失（如 LPIPS）虽然与人类视觉对齐良好，但依赖复杂的非线性特征且缺乏可解释性；而传统手写度量（如 SSIM）虽可解释，却忽略了关键的感知特性。因此需要一种兼具准确性与可解释性的新方法。

Method: SUSS 将每张图像建模为一组感知组件，每个组件由结构化的多元正态分布表示，通过自监督方式训练以对人眼不可察觉的增强保持高似然性；最终得分是各组件对数概率的加权和，权重由人类感知数据集学习得到。其核心在于在像素空间中学习图像特定的残差线性变换。

Result: SUSS 在多种失真类型下表现出强感知校准能力，与人类判断高度一致，提供局部可解释的评估说明，并在下游成像任务中展现出稳定的优化行为和竞争性性能。

Conclusion: SUSS 提供了一种透明、可解释且与人类感知高度对齐的图像相似性评估框架，兼具理论清晰性和实际有效性，适用于模型训练与评估。

Abstract: Perceptual similarity scores that align with human vision are critical for both training and evaluating computer vision models. Deep perceptual losses, such as LPIPS, achieve good alignment but rely on complex, highly non-linear discriminative features with unknown invariances, while hand-crafted measures like SSIM are interpretable but miss key perceptual properties.
  We introduce the Structured Uncertainty Similarity Score (SUSS); it models each image through a set of perceptual components, each represented by a structured multivariate Normal distribution. These are trained in a generative, self-supervised manner to assign high likelihood to human-imperceptible augmentations. The final score is a weighted sum of component log-probabilities with weights learned from human perceptual datasets. Unlike feature-based methods, SUSS learns image-specific linear transformations of residuals in pixel space, enabling transparent inspection through decorrelated residuals and sampling.
  SUSS aligns closely with human perceptual judgments, shows strong perceptual calibration across diverse distortion types, and provides localized, interpretable explanations of its similarity assessments. We further demonstrate stable optimization behavior and competitive performance when using SUSS as a perceptual loss for downstream imaging tasks.

</details>


### [59] [DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction](https://arxiv.org/abs/2512.03715)
*Kaichen Zhang,Tianxiang Sheng,Xuanming Shi*

Main category: cs.CV

TL;DR: DINO-RotateMatch 是一种用于从非结构化互联网图像进行大规模 3D 重建的深度学习框架，通过自适应图像配对策略与旋转感知关键点提取和匹配，结合 DINO 的语义相关图像对检索以及基于旋转增强的局部特征提取（ALIKED + Light Glue），在 Kaggle 图像匹配挑战赛 2025 中取得第 47 名（银奖），验证了自监督全局描述子与旋转增强局部匹配相结合的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模 3D 重建中来自非结构化互联网图像的图像匹配难题，提升在复杂、无序数据下的匹配精度与可扩展性。

Method: 采用 DINO 进行语义相关的图像对检索，结合数据集自适应的图像配对策略；利用旋转增强的数据增广技术，通过 ALIKED 和 Light Glue 实现旋转感知的关键点提取与匹配。

Result: 在 Kaggle Image Matching Challenge 2025 中达到 47/943 的排名，获得银奖，显著提升了平均准确率（mAA），证明该方法在大规模场景下具有鲁棒性和可扩展性。

Conclusion: 融合自监督全局描述子与旋转增强的局部匹配，是一种高效且适用于大规模 3D 重建的图像匹配解决方案。

Abstract: This paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The
  method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and
  matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while
  rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results
  confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers
  a robust and scalable solution for large-scale 3D reconstruction.

</details>


### [60] [PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention](https://arxiv.org/abs/2512.03724)
*Ziwen Li,Xin Wang,Hanlue Zhang,Runnan Chen,Runqi Lin,Xiao He,Han Huang,Yandong Guo,Fakhri Karray,Tongliang Liu,Mingming Gong*

Main category: cs.CV

TL;DR: 本文提出PosA-VLA框架，通过姿态条件下的注意力锚定机制，解决现有视觉-语言-动作（VLA）模型在复杂环境中因空间均匀感知场导致的冗余和不稳定动作问题。该方法引导模型聚焦任务相关区域，提升动作生成的精度与效率，且无需额外感知模块，具有轻量级、高效推理的优势。实验表明，该方法在多种机器人操作基准和挑战性环境中均表现出精准、高效的行为及良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在复杂环境中常因空间均匀的感知场被无关物体干扰，产生冗余或不稳定的动作，影响其在时间敏感场景中的应用。

Method: 提出姿态条件下的注意力锚定机制，通过监督引导视觉注意力聚焦于任务相关的视觉区域，增强指令语义与可行动视觉线索的对齐。

Result: 在多个机器人操作基准上实现了更精确、高效的动作执行，在复杂环境中表现出良好的鲁棒性和泛化能力，且推理高效，无需额外感知模块。

Conclusion: PosA-VLA通过姿态条件注意力锚定，有效解决了VLA模型在复杂环境中的感知分散问题，显著提升了动作生成的精度与效率，具备实际应用潜力。

Abstract: The Vision-Language-Action (VLA) models have demonstrated remarkable performance on embodied tasks and shown promising potential for real-world applications. However, current VLAs still struggle to produce consistent and precise target-oriented actions, as they often generate redundant or unstable motions along trajectories, limiting their applicability in time-sensitive scenarios.In this work, we attribute these redundant actions to the spatially uniform perception field of existing VLAs, which causes them to be distracted by target-irrelevant objects, especially in complex environments.To address this issue, we propose an efficient PosA-VLA framework that anchors visual attention via pose-conditioned supervision, consistently guiding the model's perception toward task-relevant regions. The pose-conditioned anchor attention mechanism enables the model to better align instruction semantics with actionable visual cues, thereby improving action generation precision and efficiency. Moreover, our framework adopts a lightweight architecture and requires no auxiliary perception modules (e.g., segmentation or grounding networks), ensuring efficient inference. Extensive experiments verify that our method executes embodied tasks with precise and time-efficient behavior across diverse robotic manipulation benchmarks and shows robust generalization in a variety of challenging environments.

</details>


### [61] [PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation](https://arxiv.org/abs/2512.03848)
*Hania Ghouse,Maryam Alsharqi,Farhad R. Nezami,Muzammil Behzad*

Main category: cs.CV

TL;DR: PULSE 是一个统一的多任务视觉-语言框架，用于心脏图像分析，整合了解剖分割、疾病分类和临床报告生成，通过自监督表示和复合监督策略实现跨模态和数据集的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有心脏图像分析方法在解剖分割、疾病分类和临床报告生成等任务上各自独立，缺乏统一架构，限制了模型的通用性和可扩展性。

Method: 基于自监督表示，采用复合监督策略（区域重叠学习、像素级分类精度和边界感知IoU优化），结合多尺度令牌重建解码器实现解剖分割，共享全局表示支持疾病分类与临床文本生成。

Result: PULSE 能在单一架构中完成从像素到结构再到临床推理的转换，学习任务无关的心脏先验知识，在不同数据集和成像模态间表现出强泛化能力，并能以少量监督快速适应新模态。

Conclusion: PULSE 推动了心脏影像分析向可扩展的“基础型”框架迈进，为未来智能化医疗影像分析提供了新范式。

Abstract: Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.

</details>


### [62] [Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.03749)
*Korada Sri Vardhana,Shrikrishna Lolla,Soma Biswas*

Main category: cs.CV

TL;DR: SelfDebias 是一种完全无监督的测试时去偏方法，适用于任何使用 UNet 作为噪声预测器的扩散模型。它通过识别图像编码器嵌入空间中的语义聚类，并在推理过程中引导扩散过程，以最小化输出分布与均匀分布之间的 KL 散度，从而有效减少生成图像中的偏见，且无需人工标注数据或针对每个概念训练外部分类器。该方法在多个提示和模型架构上均表现出良好的泛化能力，可有效缓解关键人口统计维度及抽象概念中的偏见，同时保持图像视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在训练中常使用从互联网抓取的大规模数据集（如 LAION-5B），这些数据包含大量偏见，导致模型生成结果存在刻板印象。现有去偏方法多依赖于监督信号，需人工标注或额外分类器，成本高且难以扩展。因此，亟需一种无需标注、通用性强且能自动识别语义模式的去偏方法。

Method: SelfDebias 利用图像编码器的嵌入空间构建语义聚类，通过分析扩散过程中的潜在表示，动态调整去噪路径，使输出分布趋近于均匀分布，从而降低偏见。整个过程在测试阶段进行，不改变模型权重，实现无监督、即插即用式的去偏。

Result: 实验表明，SelfDebias 在多种提示和扩散模型架构（包括条件与非条件模型）上均表现良好，显著降低了生成图像在性别、种族等人口统计维度上的偏见，同时也有效处理了抽象概念中的隐性偏见，且未牺牲图像质量。

Conclusion: SelfDebias 提供了一种高效、通用、无需监督信号的去偏方案，为提升文本到图像生成模型的公平性提供了重要技术路径，具有广泛的应用前景。

Abstract: Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.

</details>


### [63] [BlurDM: A Blur Diffusion Model for Image Deblurring](https://arxiv.org/abs/2512.03979)
*Jin-Ting He,Fu-Jen Tsai,Yan-Tsung Peng,Min-Hung Chen,Chia-Wen Lin,Yen-Yu Lin*

Main category: cs.CV

TL;DR: 提出BlurDM，一种将模糊形成过程融入扩散模型的动态场景去模糊方法。通过双扩散前向过程同时扩散噪声和模糊，反向生成时联合去噪与去模糊，显著提升现有去模糊方法性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在动态场景去模糊中未能充分利用模糊过程的内在特性，限制了其潜力。

Method: 提出双扩散前向机制，将噪声和模糊同时施加于清晰图像；反向过程中设计联合去噪与去模糊的生成策略，并在潜在空间中实现以提高效率。

Result: 在四个基准数据集上显著且一致地提升了现有去模糊方法的性能，验证了方法的有效性。

Conclusion: BlurDM通过融合模糊形成过程到扩散模型中，实现了更优的动态场景去模糊效果，具备良好的可集成性和泛化能力。

Abstract: Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at https://github.com/Jin-Ting-He/BlurDM.

</details>


### [64] [LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling](https://arxiv.org/abs/2512.03796)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CV

TL;DR: 提出一种名为潜尺度拒绝采样（LSRS）的新方法，用于改进视觉自回归（VAR）模型在图像生成中的表现。该方法通过在每个尺度上使用轻量级评分模型评估多个候选的潜在令牌图，并选择高质量的图来指导后续尺度的生成，从而减少结构错误并提升图像质量。实验表明，LSRS在几乎不增加计算开销的情况下显著提升了生成质量，例如对VAR-d30模型，推理时间仅增加1%，FID得分从1.95降至1.78；当推理时间增加15%时，FID可进一步降至1.66，展现出高效的测试时扩展能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉自回归（VAR）模型虽通过并行采样多个令牌加速生成，但同一尺度内并行采样可能导致结构错误，影响生成图像质量。为解决这一问题，需在不显著增加计算成本的前提下提升生成一致性与结构准确性。

Method: 提出潜尺度拒绝采样（LSRS），在每个层级的潜在空间中对多个候选令牌图进行评分，利用轻量级评分模型筛选出高质量的图作为后续生成的引导，优先优化对结构连贯性至关重要的早期尺度，从而缓解自回归误差累积。

Result: 实验结果显示，采用LSRS后，VAR模型的生成质量显著提升：对于VAR-d30模型，推理时间仅增加1%时，FID从1.95降至1.78；若允许15%的推理时间增长，FID可进一步降低至1.66，证明了其在保持高效的同时有效提升生成质量。

Conclusion: LSRS是一种高效且可扩展的测试时优化方法，能够在极小额外计算开销下显著改善视觉自回归模型的图像生成质量，尤其适用于需要高保真度与实时性的生成任务。

Abstract: Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.

</details>


### [65] [DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation](https://arxiv.org/abs/2512.03992)
*Zexin Lin,Hawen Wan,Yebin Zhong,Xiaoqiang*

Main category: cs.CV

TL;DR: 提出DIQ-H基准，用于评估视觉语言模型（VLMs）在动态视觉退化下的鲁棒性，特别关注时间序列中的幻觉持续、错误恢复和时序一致性。引入物理基础的退化（如运动模糊、传感器噪声、压缩伪影），并通过多轮问答任务进行评估。提出不确定性引导的迭代精炼（UIR）方法，实现高效可靠的伪真值生成，提升标注准确率15.3%。实验表明，即使先进模型如GPT-4o也仅达78.5%的恢复率，开源模型在时序一致性上低于60%，凸显显著鲁棒性差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对静态高质量图像，忽视了真实场景中连续视觉流的动态退化与错误传播问题，尤其在自动驾驶等安全关键应用中，瞬时视觉污染可能导致持续幻觉，影响系统可靠性。

Method: 构建DIQ-H基准，采用物理基退化模拟真实环境下的视觉质量下降；设计多轮问答任务以评估幻觉持久性、错误恢复与时序一致性；提出不确定性引导的迭代精炼（UIR）方法，利用轻量级VLM结合不确定性过滤生成高可信伪标签，提升标注效率与质量。

Result: 16个主流VLM在DIQ-H上表现差异显著：先进模型（如GPT-4o）恢复率仅为78.5%，开源模型时序一致性普遍低于60%，暴露出严重鲁棒性缺陷。UIR方法使标注准确率提升15.3%。

Conclusion: DIQ-H为评估VLM在真实动态环境中的可靠性提供了首个全面基准，揭示了当前模型在处理视觉退化与错误传播方面的显著不足，推动更鲁棒的VLM设计与验证。

Abstract: Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.

</details>


### [66] [Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation](https://arxiv.org/abs/2512.03996)
*Hang Xu,Linjiang Huang,Feng Zhao*

Main category: cs.CV

TL;DR: 本文研究了文本到图像扩散模型中噪声随机性对测试时缩放（TTS）性能的影响，提出了一种新的随机性形式——文本嵌入扰动，与原有的SDE注入噪声协同工作，以提升生成多样性与质量。通过频域分析发现，空间噪声偏好低频成分（早期步骤），而文本嵌入扰动增强高频细节（后期步骤），二者在频域上互补。方法包含两个核心设计：（1）基于步骤的文本嵌入扰动，结合频域引导的噪声调度与空间噪声扰动；（2）根据频率特性和生成容忍度自适应调节扰动强度。该方法可无缝集成至现有TTS框架，在多个基准上实现显著性能提升，几乎无额外计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有TTS方法主要关注搜索策略和奖励模型，但未充分探讨文本到图像扩散模型中噪声随机性对性能的影响，尤其缺乏对不同随机性形式之间协同作用的理解。

Method: 提出文本嵌入扰动机制，结合频域分析设计步骤依赖的扰动策略，并根据频率贡献与容忍度动态调整扰动强度。

Result: 在多个文本到图像生成基准上实现了显著性能提升，且几乎不增加计算成本，验证了方法的有效性与高效性。

Conclusion: 文本嵌入扰动与空间噪声在频域上具有互补特性，联合使用可有效提升生成质量与多样性，为TTS提供一种高效、可集成的新范式。

Abstract: Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion}.

</details>


### [67] [A Robust Camera-based Method for Breath Rate Measurement](https://arxiv.org/abs/2512.03827)
*Alexey Protopopov*

Main category: cs.CV

TL;DR: 本文提出了一种在低硬件要求下测量人类呼吸率的更稳健方法，结合数学变换，相对偏差小于5%。在14名志愿者超过2小时30分钟的视频上测试，平均绝对误差仅为0.57次/分钟，优于以往研究。该方法对受试者移动引起的失真具有更强的鲁棒性，可实现无行为限制的远程呼吸率测量。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频的呼吸率测量方法在理想条件下表现良好，但在实际场景中准确度不足，且对运动干扰敏感。因此需要一种更鲁棒、高精度且无需复杂设备的方法。

Method: 结合数学变换的方法，利用视频序列分析面部微小变化以推断呼吸率，增强对运动干扰的抵抗能力。

Result: 在14名志愿者的超2.5小时视频数据上，平均绝对误差为0.57次/分钟，相对偏差低于5%，显著优于先前方法。

Conclusion: 所提方法在真实环境下表现出优异的准确性和鲁棒性，适用于无约束条件下的远程非接触式呼吸率监测。

Abstract: Proliferation of cheap and accessible cameras makes it possible to measure a subject's breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject's breath rate without any significant limitations on the subject's behavior.

</details>


### [68] [Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding](https://arxiv.org/abs/2512.04000)
*Jialuo Li,Bin Li,Jiahao Li,Yan Lu*

Main category: cs.CV

TL;DR: 本文提出一种无需训练的帧选择框架DIG，根据查询类型（全局或局部）自适应选择帧。对于全局查询，采用高效的均匀采样；对于局部查询，则激活专门的查询相关帧提取管道。在三个长视频理解基准上的实验表明，DIG在提升LMM性能方面优于现有基线，且在输入帧数增加至256时仍表现稳健。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂的查询感知帧选择机制，计算开销大。本文质疑这种机制是否对所有查询类型都必要，旨在寻找更高效、自适应的解决方案。

Method: 提出DIG框架，基于查询类型区分策略：全局查询使用均匀采样，局部查询启用专用查询相关帧提取模块，无需额外训练。

Result: 在三个长视频理解数据集上，DIG显著优于现有方法，即使在高帧率输入（256帧）下也保持优异性能，证明其有效性与鲁棒性。

Conclusion: DIG通过智能区分查询类型实现高效帧选择，在不增加训练成本的前提下显著提升长视频理解任务中LMM的表现，为复杂视频分析提供了轻量级、可扩展的新范式。

Abstract: The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.

</details>


### [69] [On the Temporality for Sketch Representation Learning](https://arxiv.org/abs/2512.04007)
*Marcelo Isaias de Moraes Junior,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 本文研究了草图作为序列处理时时间性的重要性，发现绝对坐标优于相对坐标，非自回归解码器优于自回归解码器，且时间性的关键程度取决于所考虑的顺序和具体任务。


<details>
  <summary>Details</summary>
Motivation: 当前草图表示学习虽有进展，但对时间性在表示质量中的真实作用仍缺乏理解，亟需探究草图作为序列处理的合理性及内部顺序的影响。

Method: 通过对比传统位置编码与绝对坐标、自回归与非自回归解码器，在不同顺序和任务下评估草图表示性能。

Result: 绝对坐标表现优于相对坐标；非自回归解码器优于自回归解码器；时间性的重要性依赖于顺序和任务类型。

Conclusion: 草图作为序列处理具有合理性，但其时间性影响并非普适，需结合具体顺序与任务进行考量。

Abstract: Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.

</details>


### [70] [PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation](https://arxiv.org/abs/2512.04025)
*Xiaolong Li,Youping Gu,Xi Lin,Weijie Wang,Bohan Zhuang*

Main category: cs.CV

TL;DR: 提出了一种名为Pyramid Sparse Attention (PSA)的新型高效注意力机制，通过多层级池化键值表示实现更精细的掩码粒度，避免传统二值掩码导致的信息损失。PSA根据查询块动态分配不同池化级别，实现关键信息保留与计算效率平衡，在视频理解与生成任务中表现优异，优于或媲美现有基线方法，且具备硬件友好性。


<details>
  <summary>Details</summary>
Motivation: 当前高效注意力机制在高稀疏度下因采用二值掩码导致大量信息丢失，限制了模型性能提升，亟需一种既能保持低计算开销又能减少信息损失的新型稀疏化方案。

Method: 提出Pyramid Sparse Attention (PSA)，利用多层级池化构建键值表示，通过动态分配不同池化级别实现细粒度掩码控制，结合解耦的块-瓷砖设计实现硬件友好的高效执行。

Result: 在多个视频理解与生成基准测试中，PSA显著提升了上下文信息保留能力与视觉保真度，相较现有稀疏注意力方法在效率与质量之间取得更优权衡，表现卓越。

Conclusion: PSA是一种通用、高效的注意力模块，通过模拟量化与特征金字塔思想，有效缓解稀疏注意力中的信息损失问题，兼具高性能与可部署性，适用于大规模视频建模任务。

Abstract: Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA

</details>


### [71] [CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation](https://arxiv.org/abs/2512.03844)
*Letian Zhou,Songhua Liu,Xinchao Wang*

Main category: cs.CV

TL;DR: 提出CoDA框架，利用现成的文本到图像模型实现高效数据蒸馏，通过识别目标数据集的内在核心分布并引导生成过程对齐该分布，解决现有方法依赖特定训练生成模型或存在分布偏差的问题。在不使用目标数据集预训练生成模型的情况下，性能达到甚至超过以往方法，在ImageNet-1K上实现50张图/类设置下的60.4%新纪录。


<details>
  <summary>Details</summary>
Motivation: 现有数据蒸馏方法在使用生成模型时面临两大挑战：一是多数方法需在完整目标数据集上预训练扩散模型，违背了数据蒸馏初衷且成本高昂；二是部分方法虽采用通用文本到图像模型，但因基础模型的通用先验与目标语义存在分布偏差，导致性能不佳。

Method: 提出核心分布对齐（CoDA）框架，首先通过基于密度的稳健机制识别目标数据集的‘内在核心分布’，然后引导生成过程使生成样本与该核心分布对齐，从而弥合通用生成先验与目标语义之间的差距。

Result: 在无需目标数据集特定训练生成模型的前提下，CoDA在所有基准测试中表现优异，包括ImageNet-1K及其子集，尤其在50张图/类设置下达到60.4%的新纪录准确率，显著优于先前依赖特定训练生成模型的方法。

Conclusion: CoDA成功实现了仅用通用文本到图像模型进行高效数据蒸馏，突破了传统方法对目标特定生成模型的依赖，有效提升蒸馏质量，为数据蒸馏提供了新的可行路径。

Abstract: Prevailing Dataset Distillation (DD) methods leveraging generative models confront two fundamental limitations. First, despite pioneering the use of diffusion models in DD and delivering impressive performance, the vast majority of approaches paradoxically require a diffusion model pre-trained on the full target dataset, undermining the very purpose of DD and incurring prohibitive training costs. Second, although some methods turn to general text-to-image models without relying on such target-specific training, they suffer from a significant distributional mismatch, as the web-scale priors encapsulated in these foundation models fail to faithfully capture the target-specific semantics, leading to suboptimal performance. To tackle these challenges, we propose Core Distribution Alignment (CoDA), a framework that enables effective DD using only an off-the-shelf text-to-image model. Our key idea is to first identify the "intrinsic core distribution" of the target dataset using a robust density-based discovery mechanism. We then steer the generative process to align the generated samples with this core distribution. By doing so, CoDA effectively bridges the gap between general-purpose generative priors and target semantics, yielding highly representative distilled datasets. Extensive experiments suggest that, without relying on a generative model specifically trained on the target dataset, CoDA achieves performance on par with or even superior to previous methods with such reliance across all benchmarks, including ImageNet-1K and its subsets. Notably, it establishes a new state-of-the-art accuracy of 60.4% at the 50-images-per-class (IPC) setup on ImageNet-1K. Our code is available on the project webpage: https://github.com/zzzlt422/CoDA

</details>


### [72] [Fast & Efficient Normalizing Flows and Applications of Image Generative Models](https://arxiv.org/abs/2512.04039)
*Sandeep Nagar*

Main category: cs.CV

TL;DR: 本文在生成模型效率提升与实际计算机视觉应用两方面提出创新：1）通过六项改进优化归一化流架构，包括可逆3×3卷积、高效Quad耦合层、并行反向算法及基于反卷积的逆流训练；2）提出轻量级超分辨率模型Affine-StableSR，减少参数量并保持性能；3）应用于农业品质评估（解决数据不平衡）、地质图自动绘制（堆叠自编码器降维）、自动驾驶隐私保护（人脸与车牌掩蔽）、艺术修复（统一微调扩散模型）等真实场景，展现生成模型在多领域实用价值。


<details>
  <summary>Details</summary>
Motivation: 提升生成模型（尤其是归一化流）的计算效率与实用性，同时解决农业、地质、自动驾驶、艺术修复等领域的数据稀缺、标注困难、隐私保护与图像退化等现实挑战。

Method: 1）设计数学上严格保证可逆性的3×3卷积层，开发高效Quad耦合层与并行反向算法；2）利用反卷积实现逆流前向传播，并设计快速反向传播算法；3）构建Affine-StableSR模型，结合预训练权重与归一化流层以压缩参数；4）采用条件GAN处理农业数据不平衡问题；5）使用堆叠自编码器进行地质图特征提取；6）基于人脸检测与图像修复技术实现自动驾驶数据隐私保护；7）运用基于Stable Diffusion的图像修复替换敏感信息；8）对扩散模型进行微调以统一处理多种艺术图像退化类型。

Result: 1）归一化流模型在保持性能前提下显著降低计算开销与参数量；2）农业种子纯度检测准确率高，有效应对数据不足；3）地质图自动识别精度优于传统方法；4）隐私保护方案成功遮蔽敏感信息且保持图像可用性；5）艺术修复模型能有效处理多种退化模式，恢复质量良好。

Conclusion: 本研究系统性提升了生成模型的效率与泛化能力，推动其在真实世界复杂任务中的落地应用，为计算机视觉中数据受限、隐私敏感与图像修复等关键问题提供了高效、可扩展的解决方案。

Abstract: This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance.
  The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.

</details>


### [73] [Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population](https://arxiv.org/abs/2512.03854)
*Peshawa J. Muhammad Ali,Navin Vincent,Saman S. Abdulla,Han N. Mohammed Fadhl,Anders Blilie,Kelvin Szolnoky,Julia Anna Mielcarz,Xiaoyi Ji,Kimmo Kartasalo,Abdulbasit K. Al-Talabani,Nita Mulliqi*

Main category: cs.CV

TL;DR: 本研究发布了一个来自伊拉克埃尔比勒的339张前列腺核心活检全幻灯片图像数据集，涵盖185名连续患者，旨在支持全球多样化人群病理AI模型的开发与验证。数据集包含三个病理学家独立评估的格里森评分和国际泌尿病理学会分级，并使用三种不同扫描仪（Leica、Hamamatsu、Grundium）扫描，所有幻灯片均去标识化并以原始格式提供。该数据集可用于分级一致性分析、颜色归一化及跨扫描仪鲁棒性评估，将存入Bioimage Archive（BIA）并以CC BY 4.0许可公开。


<details>
  <summary>Details</summary>
Motivation: 当前公开的组织病理学数据集稀缺且主要代表西方人群，导致AI模型在中东等数字化程度较低地区的人群中泛化能力未知，亟需多样化的数据集以提升模型的全球适用性。

Method: 收集了185例连续患者的前列腺核心活检全幻灯片图像，共339张，采用两种高通量扫描仪（Leica、Hamamatsu）和一种紧凑型扫描仪（Grundium）进行扫描，所有样本均去标识化并保留原始格式。病理分级由三位病理学家独立完成，包括格里森评分和国际泌尿病理学会分级。

Result: 成功构建了一个来自中东地区的真实世界病理数据集，支持多维度研究，如分级一致性分析、颜色归一化方法验证及跨扫描仪模型鲁棒性评估，为全球病理AI研究提供了重要资源。

Conclusion: 本数据集的公开将促进面向全球多样性人群的病理人工智能模型开发与验证，填补现有数据集在中东地区代表性不足的空白，推动医疗AI的公平性和可及性。

Abstract: Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.

</details>


### [74] [Diminishing Returns in Self-Supervised Learning](https://arxiv.org/abs/2512.03862)
*Oli Bridge,Huey Sun,Botond Branyicskai-Nagy,Charles D'Ornano,Shomit Basu*

Main category: cs.CV

TL;DR: 本研究探索了在小型500万参数视觉变换器（ViT）上，预训练、中间微调和下游任务的数据集与训练目标的边际效益。结果表明，预训练和微调通常有益但收益递减；而中间微调可能对下游性能产生负面影响，可能是由于任务机制差异所致。总体而言，小规模ViT最受益于针对性的预训练和精心的数据选择，盲目堆叠中间任务会浪费计算资源并可能降低性能。


<details>
  <summary>Details</summary>
Motivation: 探索小规模视觉变换器（ViT）在不同训练阶段（预训练、中间微调、下游任务）中使用不同数据集和训练目标的边际效益，以优化模型性能并避免不必要的计算浪费。

Method: 实验设计三种不同的预训练、中间微调及下游数据集和训练目标组合，评估其对一个500万参数的小型视觉变换器的影响。通过系统对比分析各阶段的作用及其相互关系。

Result: 预训练和微调有助于提升模型性能，但效果随增加而递减；中间微调可能对下游任务造成负面影响，尤其当任务机制不一致时；小规模ViT的最佳策略是针对性预训练和精细数据选择。

Conclusion: 小规模视觉变换器应避免无差别地添加中间微调任务，而应聚焦于高质量的预训练和数据筛选，以实现高效且稳定的性能提升。

Abstract: While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.

</details>


### [75] [An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis](https://arxiv.org/abs/2512.03869)
*Daniele Falcetta,Liane S. Canas,Lorenzo Suppa,Matteo Pentassuglia,Jon Cleary,Marc Modat,Sébastien Ourselin,Maria A. Zuluaga*

Main category: cs.CV

TL;DR: CaravelMetrics is an automated framework for cerebrovascular analysis using graph-based vessel morphology, extracting 15 features across multiple scales. It enables detailed study of vascular changes with age, sex, and education.


<details>
  <summary>Details</summary>
Motivation: To develop a scalable, automated method for quantitative analysis of cerebrovascular structure to support studies on aging and vascular health.

Method: The framework uses skeletonization, atlas-based parcellation, centerline extraction, and graph construction to compute morphometric, topological, fractal, and geometric features from 3D TOF-MRA scans.

Result: Applied to 570 IXI dataset scans, it revealed reproducible patterns of vascular changes related to age, sex, and education, consistent with prior literature.

Conclusion: CaravelMetrics provides a robust, fully automated tool for multiscale cerebrovascular analysis, enabling normative modeling and population-level research in vascular health and aging.

Abstract: We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.

</details>


### [76] [Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy](https://arxiv.org/abs/2512.03883)
*Jorge Tapias Gomez,Despoina Kanata,Aneesh Rangnekar,Christina Lee,Julio Garcia-Aguilar,Joshua Jesse Smith,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: 本研究提出了一种基于双交叉注意力的孪生Swin Transformer（SSDCA）模型，用于在直肠癌患者经新辅助治疗后临床完全缓解（cCR）的观察等待（WW）期间，通过对比复诊与随访内镜图像，早期准确识别局部复发（LR）。该模型利用预训练的Swin Transformer提取与领域无关的特征，增强对成像差异的鲁棒性，并通过双交叉注意力机制在无需图像空间对齐的情况下突出两期图像的关键特征。在135例患者的图像对上训练，62例患者图像对进行测试，SSDCA在平衡准确率（81.76%）、敏感性（90.07%）和特异性（72.86%）方面表现最优。鲁棒性分析显示其在存在血液、粪便、毛细血管扩张及图像质量差等干扰时仍保持稳定性能。UMAP聚类结果表明，该模型具有最大簇间分离度（1.45±0.18）和最小簇内分散度（1.07±0.19），验证了其判别性表征学习能力。


<details>
  <summary>Details</summary>
Motivation: 当前越来越多证据支持对接受全程新辅助治疗后达到临床完全缓解的直肠癌患者采用观察等待策略。然而，如何在随访过程中通过内镜图像早期准确检测局部复发，是确保及时干预、防止远处转移的关键挑战。现有方法缺乏有效手段来处理纵向图像间的成像差异与非对齐问题，亟需一种鲁棒且精准的自动分析工具。

Method: 提出一种基于孪生结构的Swin Transformer模型，引入双交叉注意力机制，结合复诊与随访内镜图像，实现无空间对齐条件下的响应状态分类。模型利用预训练的Swin Transformer提取跨域不变特征，增强对成像变异的适应能力；双交叉注意力模块则动态聚焦于两期图像中的关键区域，提升区分力。

Result: 在独立测试集上，SSDCA模型达到81.76%的平衡准确率、90.07%的敏感性和72.86%的特异性，优于所有基于Swin的基线模型。鲁棒性分析显示其在多种图像伪影下性能稳定；UMAP可视化证实其特征表示具有优异的判别能力，表现为高簇间分离与低簇内聚集。

Conclusion: SSDCA是一种高效、鲁棒的深度学习框架，能够有效利用纵向内镜图像实现对直肠癌临床完全缓解患者局部复发的早期识别，为观察等待策略提供可靠技术支持，具备临床转化潜力。

Abstract: Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.

</details>


### [77] [Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence](https://arxiv.org/abs/2512.03905)
*Shuai Yang,Junxin Lin,Yifan Zhou,Ziwei Liu,Chen Change Loy*

Main category: cs.CV

TL;DR: FRESCO提出一种结合帧内与帧间对应关系的时空约束机制，以提升零样本视频生成中的时空一致性。通过显式优化特征，该方法在视频到视频转换和文本引导视频编辑任务中均表现出更优的视觉连贯性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有零样本视频生成方法依赖注意力机制中的软约束来捕捉帧间对应关系，但该方式不足以保证时间一致性，容易导致生成视频中语义内容不连贯。

Method: FRESCO通过融合帧内对应关系与帧间对应关系，构建更强的时空约束；并超越传统的注意力引导，直接对特征进行显式优化，以增强跨帧语义一致性。

Result: 在视频到视频转换和文本引导视频编辑任务上，FRESCO生成的视频具有更高的空间-时间一致性和视觉质量，实验验证了其相对于当前零样本方法的优越性。

Conclusion: FRESCO通过引入更稳健的时空约束机制，有效提升了基于图像扩散模型的零样本视频生成质量，为视频应用提供了新的高效解决方案。

Abstract: The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.

</details>


### [78] [UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework](https://arxiv.org/abs/2512.03918)
*Youxin Pang,Yong Zhang,Ruizhi Shao,Xiang Deng,Feng Gao,Xu Xiaoming,Xiaoming Wei,Yebin Liu*

Main category: cs.CV

TL;DR: UniMo 是首个在统一框架中联合建模 2D 人类视频与 3D 人体动作的自回归模型，通过将两者视为统一的标记序列，实现视频与动作的同时生成与理解。该方法采用独立嵌入层缓解分布差异，并设计新型 3D 动作分词器结合多专家解码器，有效保留空间信息并提升重建质量。实验表明，该模型能同步生成高质量视频与动作，推动了多模态、可控的人体与场景联合建模发展。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多仅关注单向生成或与其他模态（如文本、音频）融合，缺乏对 2D 视频与 3D 动作的联合建模，而二者在结构和分布上存在显著差异，亟需一种统一框架来实现同步优化与生成。

Method: 将 2D 视频与 3D 动作统一表示为标记序列，使用独立嵌入层减少分布偏差；提出一种集成双任务的序列建模策略；设计基于 VQ-VAE 的 3D 动作分词器，结合时间扩展策略与多专家解码器（分别处理身体形状、平移、全局朝向与姿态），以高效对齐视觉标记并保持 3D 空间结构。

Result: 实验验证了 UniMo 能够同时生成高质量的对应视频与 3D 动作，实现准确的动作捕捉，且在联合建模方面优于现有方法。

Conclusion: 本工作展示了大语言模型融合异构数据的潜力，为将人体为中心的信息整合进通用模型提供了新路径，有望推动未来多模态、可控制的人体、物体与场景联合建模的发展。

Abstract: We propose UniMo, an innovative autoregressive model for joint modeling of 2D human videos and 3D human motions within a unified framework, enabling simultaneous generation and understanding of these two modalities for the first time. Current methods predominantly focus on generating one modality given another as the condition or integrating either of them with other modalities such as text and audio. Unifying 2D videos and 3D motions for simultaneous optimization and generation remains largely unexplored, presenting significant challenges due to their substantial structural and distributional differences. Inspired by the LLM's ability to unify different modalities, our method models videos and 3D motions as a unified tokens sequence, utilizing separate embedding layers to mitigate distribution gaps. Additionally, we devise a sequence modeling strategy that integrates two distinct tasks within a single framework, proving the effectiveness of unified modeling. Moreover, to efficiently align with visual tokens and preserve 3D spatial information, we design a novel 3D motion tokenizer with a temporal expansion strategy, using a single VQ-VAE to produce quantized motion tokens. It features multiple expert decoders that handle body shapes, translation, global orientation, and body poses for reliable 3D motion reconstruction. Extensive experiments demonstrate that our method simultaneously generates corresponding videos and motions while performing accurate motion capture. This work taps into the capacity of LLMs to fuse diverse data types, paving the way for integrating human-centric information into existing models and potentially enabling multimodal, controllable joint modeling of humans, objects, and scenes.

</details>


### [79] [TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning](https://arxiv.org/abs/2512.03963)
*Tao Wu,Li Yang,Gen Zhan,Yiting Liao,Junlin Li,Deliang Fu,Li Zhang,Limin Wang*

Main category: cs.CV

TL;DR: TempR1 是一个面向多模态大语言模型（MLLMs）的时序感知多任务强化学习框架，旨在提升模型在长视频分析中的时间理解能力。通过构建涵盖多种时序结构和语义的多任务数据集，并基于分组相对策略优化（GRPO）算法实现跨任务稳定优化。该方法将时序任务分为三类对应关系，并为每类设计特定的定位奖励，从而捕捉细粒度的时间依赖性并适应不同时间模式。实验表明，TempR1 在多个基准测试中达到领先性能，且多任务联合优化带来显著协同效应，提升了泛化能力和单任务表现，为 MLLMs 的时序推理提供了可扩展、原则化的范式。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在提升多模态大语言模型时序理解方面受限于任务类型和数据范围，难以在多样化时序场景中有效泛化。因此，亟需一种更具通用性和系统性的框架来增强模型对复杂时间结构的理解能力。

Method: 提出 TempR1 框架，包含：1）构建覆盖多种时序结构与语义的多任务数据集；2）基于 Group Relative Policy Optimization (GRPO) 实现跨任务稳定优化；3）将时序任务按预测区间与真实实例的对应关系划分为三类，并设计相应的定位奖励机制，以增强对细粒度时间依赖的建模能力。

Result: TempR1 在多个时序理解基准上取得当前最优性能，展现出优异的泛化能力与单任务表现。多任务联合优化带来显著协同效应，验证了其在提升模型综合时序推理能力方面的有效性。

Conclusion: TempR1 为多模态大语言模型的时序推理提供了一个可扩展、原则化的解决方案，通过多任务强化学习有效增强了模型对复杂时间模式的理解能力，推动了长视频分析的发展。

Abstract: Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs' temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.

</details>


### [80] [Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization](https://arxiv.org/abs/2512.03964)
*Lianyu Pang,Ji Zhou,Qiping Wang,Baoquan Zhao,Zhenguo Yang,Qing Li,Xudong Mao*

Main category: cs.CV

TL;DR: UniID提出了一种统一的无微调人脸个性化框架，融合了文本嵌入与适配器方法的优点。通过在训练时聚焦身份特征学习、推理时引入归一化重缩放机制，实现身份保真度与文本可控性的协同增强。实验表明，该方法在6个SOTA方法中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有无微调人脸个性化方法在身份保真度和文本可控性之间难以兼顾，需要一种能够协同整合两种范式且保持扩散模型原始先验的新方法。

Method: 提出UniID框架，采用身份导向的训练策略使双分支仅捕获身份相关特征，并在推理阶段引入归一化重缩放机制，恢复基线扩散模型的文本可控性，同时促进身份信号互补增强。

Result: 在多个指标上优于6个现有SOTA方法，实现了高保真度的人脸个性化与灵活的文本控制能力。

Conclusion: UniID通过联合优化身份与文本信息，在无需微调的情况下实现了高质量人脸个性化，为未来无监督个性化生成提供了新思路。

Abstract: Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at https://github.com/lyuPang/UniID

</details>


### [81] [DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment](https://arxiv.org/abs/2512.03981)
*Sheng-Hao Liao,Shang-Fu Chen,Tai-Ming Huang,Wen-Huang Cheng,Kai-Lung Hua*

Main category: cs.CV

TL;DR: DirectDrag 是一种无需掩码和文本提示的拖拽图像编辑框架，通过自动软掩码生成和读出引导的特征对齐机制，在仅需最少用户输入的情况下实现精确、高效的图像操作，同时保持高图像保真度和点对齐精度。该方法在无外部约束条件下显著优于现有方法，在视觉质量与空间控制之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成模型的拖拽编辑方法依赖手动掩码和文本提示以保证语义一致性和运动精度，但这些约束限制了交互的自然性；去除掩码和提示会带来视觉伪影或空间控制不佳的问题，因此需要一种无需额外输入即可实现高质量编辑的新方法。

Method: DirectDrag 提出了两个核心创新：1）自动软掩码生成模块，根据点位移智能推断可编辑区域，沿移动路径局部化形变并利用生成模型的上下文理解能力保持结构完整性；2）读出引导的特征对齐机制，利用扩散模型中间激活信息进行结构一致性保持，提升点编辑时的视觉质量。

Result: DirectDrag 在不使用任何手动掩码或文本提示的前提下，实现了比现有方法更优的图像质量，并在拖拽准确性上保持竞争力。在 DragBench 和真实场景中的大量实验验证了其有效性与实用性。

Conclusion: DirectDrag 成功实现了无需掩码和提示的高效、高保真图像编辑，为交互式图像操纵提供了新的范式，具有良好的实用价值和推广前景。

Abstract: Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.

</details>


### [82] [Learning Group Actions In Disentangled Latent Image Representations](https://arxiv.org/abs/2512.04015)
*Farhana Hossain Swarnali,Miaomiao Zhang,Tonmoy Hossain*

Main category: cs.CV

TL;DR: 本文提出一种端到端框架，首次在潜在图像流形上自动学习群作用，无需手动干预即可发现与变换相关的结构。通过可学习的二值掩码和直通估计，动态划分潜在表示为敏感与不变成分，并在统一优化框架中联合学习潜在解耦与群变换映射。该方法可无缝集成至任意标准编码器-解码器架构，在五个2D/3D图像数据集上验证了其自动学习解耦潜在因子的能力，且下游分类任务证明所学表征的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高维数据空间中操作群作用，难以解耦变化子空间；而潜空间方法需手动划分潜在变量，限制了群作用的学习与操作能力。

Method: 引入可学习的二值掩码结合直通估计，动态分割潜在表示为变换敏感与不变部分，并在统一优化框架中联合学习潜在解耦与群变换映射。

Result: 在五个2D/3D图像数据集上成功自动学习解耦的潜在因子，下游分类任务验证了所学表征的有效性。

Conclusion: 该框架实现了无需人工干预的潜在空间群作用学习，具备良好的可扩展性和有效性，适用于多种图像数据。

Abstract: Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations .

</details>


### [83] [Ultra-lightweight Neural Video Representation Compression](https://arxiv.org/abs/2512.04019)
*Ho Man Kwan,Tianhao Peng,Ge Gao,Fan Zhang,Mike Nilsson,Andrew Gower,David Bull*

Main category: cs.CV

TL;DR: NVRC-Lite is a lightweight, high-performance neural video compression framework that improves upon NVRC by incorporating multi-scale feature grids and an octree-based context model for faster entropy coding. It achieves significant BD-rate savings and speedups over existing methods like C3.


<details>
  <summary>Details</summary>
Motivation: Existing INR-based video codecs, while effective, face challenges in computational efficiency and slow entropy coding due to autoregressive models. There is a need for lightweight, fast, and high-performance video compression solutions suitable for real-time applications.

Method: NVRC-Lite introduces multi-scale feature grids to enhance representation quality at low complexity and replaces autoregressive entropy coding with an octree-based context model to accelerate encoding and decoding.

Result: NVRC-Lite achieves up to 21.03% and 23.06% BD-rate savings in PSNR and MS-SSIM respectively compared to C3, with 8.4x faster encoding and 2.5x faster decoding.

Conclusion: NVRC-Lite demonstrates that combining efficient neural representations with fast entropy coding enables lightweight, high-performance video compression, making it suitable for practical deployment in real-time systems.

Abstract: Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.

</details>


### [84] [C3G: Learning Compact 3D Representations with 2K Gaussians](https://arxiv.org/abs/2512.04021)
*Honggyu An,Jaewoo Jung,Mungyeom Kim,Sunghwan Hong,Chaehyun Kim,Kazumi Fukuda,Minkyeong Jeon,Jisang Han,Takuya Narihira,Hyuna Ko,Junsu Kim,Yuki Mitsufuji,Seungryong Kim*

Main category: cs.CV

TL;DR: 提出C3G框架，通过可学习的tokens和自注意力机制，在关键空间位置生成紧凑的3D高斯，减少冗余，提升特征聚合效率，实现高效、高质量的3D场景重建与理解。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无姿态稀疏视图下使用3D高斯点云进行重建时，产生大量冗余高斯，导致内存开销大且多视角特征融合效果差，影响新视角合成和场景理解性能。

Method: 引入可学习的tokens通过自注意力机制聚合多视角特征，指导高斯生成；利用学习到的注意力模式进行高斯解码，实现高效特征提升。

Result: 在无姿态新视角合成、3D开放词汇分割和视角不变特征聚合任务上表现优异，相比现有方法具有更高的内存效率和特征保真度。

Conclusion: 紧凑且几何意义明确的3D表示足以实现高质量的场景重建与理解，C3G框架有效解决了冗余和特征融合问题。

Abstract: Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.

</details>


### [85] [RELIC: Interactive Video World Model with Long-Horizon Memory](https://arxiv.org/abs/2512.04040)
*Yicong Hong,Yiqun Mei,Chongjian Ge,Yiran Xu,Yang Zhou,Sai Bi,Yannick Hold-Geoffroy,Mike Roberts,Matthew Fisher,Eli Shechtman,Kalyan Sunkavalli,Feng Liu,Zhengqi Li,Hao Tan*

Main category: cs.CV

TL;DR: RELIC 是一个统一框架，旨在实现交互式世界模型中的实时长时序流、一致的空间记忆和精确的用户控制。它通过压缩的历史潜在标记（包含相对动作和绝对相机位姿）在KV缓存中表示长期记忆，支持隐式的3D一致性内容检索，并以极低的计算开销维持长期连贯性。同时，采用新的内存高效的自强迫范式，将双向教师视频模型微调为因果学生生成器，实现对长时教师序列及学生自回滚的全上下文蒸馏。作为140亿参数模型，在精心筛选的Unreal Engine渲染数据集上训练，RELIC 实现了16 FPS的实时生成，相比之前的工作展现出更准确的动作跟随、更稳定的长时序流和更强的空间记忆检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只单独解决交互式世界模型中的某一个挑战，如实时性或长期记忆，难以同时满足实时长时序流、空间记忆一致性与精确用户控制三者要求。尤其长期记忆机制常导致实时性能下降，因此亟需一种能统一处理这三项核心需求的新方法。

Method: 基于最近的自回归视频扩散蒸馏技术，RELIC 使用高度压缩的历史潜在标记编码相对动作与绝对相机位姿，嵌入到KV缓存中形成相机感知的记忆结构；并通过对双向教师模型进行微调，结合一种新型内存高效自强迫机制，将其转化为因果学生生成器，从而实现长时教师序列与长学生自回滚的全上下文蒸馏。

Result: RELIC 在140亿参数规模下实现了16帧/秒的实时生成，在动作跟随准确性、长时序流稳定性以及空间记忆检索鲁棒性方面均优于先前方法，证明其在构建下一代交互式世界模型方面的强大潜力。

Conclusion: RELIC 作为一个统一框架，成功整合了实时长时序流、一致的空间记忆与精确用户控制三大关键要素，为未来交互式世界建模提供了坚实基础。

Abstract: A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.

</details>


### [86] [SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL](https://arxiv.org/abs/2512.04069)
*Siyi Chen,Mikaela Angelina Uy,Chan Hee Song,Faisal Ladhak,Adithyavairavan Murali,Qing Qu,Stan Birchfield,Valts Blukis,Jonathan Tremblay*

Main category: cs.CV

TL;DR: 提出双交互强化学习(DIRL)框架，用于让视觉语言模型(VLMs)通过交互式探索和反馈学习协调多种工具，以解决空间推理中的精度问题。该方法在教学阶段结合单工具专家与全工具前沿模型的示范，在探索阶段持续优化多工具协作。基于此训练出的SpaceTools模型在多个空间理解基准测试中达到领先性能，并成功应用于7-DOF机器人的真实世界操作。相比基线方法，DIRL在RoboSpatial上分别提升12%（SFT）和16%（RL）。


<details>
  <summary>Details</summary>
Motivation: VLMs虽具备良好的视觉理解能力，但在需要精确空间推理的具身应用中表现不足。现有方法依赖手工提示或固定工具流水线，限制了模型自主发现最优工具使用策略的能力。强化学习虽有潜力，但受限于多工具场景下的巨大搜索空间，难以有效应用。因此亟需一种能支持灵活、高效多工具协同的新范式。

Method: 提出双交互强化学习(DIRL)框架，分两阶段训练：教学阶段融合单工具专家（通过交互式RL训练）与全工具前沿模型的示范；探索阶段通过持续强化学习进一步优化多工具协调能力。模型采用工具增强的空间推理机制，实现动态工具选择与组合。

Result: SpaceTools在RoboSpatial-Home、BLINK、BOP-ASK等空间理解基准上取得当前最优成绩；在真实世界中成功控制7-DOF机器人完成复杂操作任务；相较于标准SFT和强化学习基线，性能分别提升12%和16%。

Conclusion: DIRL框架有效解决了多工具空间推理中模型自主决策与协同优化的难题，为视觉语言模型在具身智能中的应用提供了可扩展、可泛化的解决方案，展现出显著的性能优势与实际应用潜力。

Abstract: Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: https://spacetools.github.io/.

</details>


### [87] [PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design](https://arxiv.org/abs/2512.04082)
*Jiazhe Wei,Ken Li,Tianyu Lao,Haofan Wang,Liang Wang,Caifeng Shan,Chenyang Si*

Main category: cs.CV

TL;DR: PosterCopilot 是一个用于专业图形设计的框架，通过渐进式三阶段训练策略提升大模型的布局推理与可控编辑能力，结合生成模型实现分层、迭代式编辑，显著提高布局的几何准确性与美学质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于大模型的自动图形设计方法在布局几何准确性与专业工作流所需的分层迭代编辑方面存在不足，难以满足实际设计需求。

Method: 提出渐进式三阶段训练策略：扰动监督微调、视觉-现实对齐强化学习、基于美学反馈的强化学习；构建整合训练后的大模型与生成模型的工作流程，支持分层可控、迭代编辑以保持全局视觉一致性。

Result: 实验表明，PosterCopilot 在布局几何准确性与美学表现上均优于现有方法，实现了前所未有的设计可控性与专业级迭代编辑能力。

Conclusion: PosterCopilot 有效解决了当前自动化图形设计中布局不准与编辑不可控的问题，为专业级设计提供了高效、精准且可迭代的智能支持。

Abstract: Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.

</details>


### [88] [SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows](https://arxiv.org/abs/2512.04084)
*Qinyu Zhao,Guangting Zheng,Tao Yang,Rui Zhu,Xingjian Leng,Stephen Gould,Liang Zheng*

Main category: cs.CV

TL;DR: 本文提出一种简单有效的改进方法，通过固定VAE编码器输出的方差为常数（如0.5），解决了传统归一化流（NF）在数据增强和训练稳定性方面的两个主要问题。该方法避免了额外的加噪与去噪步骤，同时使变分下界更稳定，便于联合训练NF与VAE。在ImageNet 256×256生成任务中，所提模型SimFlow取得2.15的gFID，优于STARFlow（2.40）；结合REPA-E方法后，gFID进一步降至1.91，刷新NFs领域新纪录。


<details>
  <summary>Details</summary>
Motivation: 解决现有归一化流方法中因引入随机噪声进行数据增强而导致的复杂流程，以及使用预训练冻结VAE编码器导致重建与生成质量不佳的问题。

Method: 将VAE编码器输出的方差固定为常数（如0.5），从而让编码器输出更广泛的潜在表示，解码器可从中学习重建干净图像，同时简化变分下界，提升联合训练稳定性。

Result: 在ImageNet 256×256生成任务中，SimFlow达到gFID 2.15，优于STARFlow（2.40）；结合REPA-E后，gFID降至1.91，成为当前NFs最佳性能。

Conclusion: 通过简单地固定方差，SimFlow有效克服了传统NF方法的两大缺陷，实现更高效、更稳定的生成建模，并在生成质量上达到新高度。

Abstract: Normalizing Flows (NFs) learn invertible mappings between the data and a Gaussian distribution. Prior works usually suffer from two limitations. First, they add random noise to training samples or VAE latents as data augmentation, introducing complex pipelines including extra noising and denoising steps. Second, they use a pretrained and frozen VAE encoder, resulting in suboptimal reconstruction and generation quality. In this paper, we find that the two issues can be solved in a very simple way: just fixing the variance (which would otherwise be predicted by the VAE encoder) to a constant (e.g., 0.5). On the one hand, this method allows the encoder to output a broader distribution of tokens and the decoder to learn to reconstruct clean images from the augmented token distribution, avoiding additional noise or denoising design. On the other hand, fixed variance simplifies the VAE evidence lower bound, making it stable to train an NF with a VAE jointly. On the ImageNet $256 \times 256$ generation task, our model SimFlow obtains a gFID score of 2.15, outperforming the state-of-the-art method STARFlow (gFID 2.40). Moreover, SimFlow can be seamlessly integrated with the end-to-end representation alignment (REPA-E) method and achieves an improved gFID of 1.91, setting a new state of the art among NFs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [89] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 本文提出一种基于伦理熵的动态评估框架，用于监测大语言模型在部署中的价值漂移问题。通过定义五类行为分类体系，训练分类器估算伦理熵S(t)，并测量四个前沿模型在压力测试下的熵动态变化。结果表明，基础模型呈现持续熵增长，而指令微调版本可将伦理熵降低约80%。研究进一步估计了有效对齐工作速率gamma_eff，并构建了包含S(t)与gamma_eff的实时监控管道，可在熵漂移超过稳定阈值时触发警报，实现对价值漂移的运行时监督。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准无法捕捉大语言模型在部署中出现的关键动态失效问题，如分布偏移下的价值漂移、越狱攻击和对齐缓慢退化。需要一种能够实时监测模型伦理状态的动态评估方法。

Method: 提出基于‘智能第二定律’的伦理熵概念，建立五类行为分类体系；训练分类器从模型输出文本中估计伦理熵S(t)；在压力测试下测量不同模型变体的熵动态；推导有效对齐工作速率gamma_eff；构建基于S(t)和gamma_eff的实时监控预警系统。

Result: 基础模型表现出持续的伦理熵增长，而指令微调模型显著抑制了熵增长，伦理熵降低约80%。监控系统能有效检测熵漂移，实现对价值漂移的实时预警。

Conclusion: 该框架首次将伦理熵概念操作化，为大语言模型的安全性提供了动态、可度量、可监控的评估手段，支持运行时对价值漂移的主动干预。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [90] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 本文研究了Embeddings-as-a-Service（EaaS）中的水印技术，针对现有水印易被改写输入文本（如同义改写）绕过的漏洞，提出了一种基于线性变换的新型水印方法WET。该方法通过可逆变换嵌入水印，并在验证时恢复原始嵌入进行比对，展现出对同义改写攻击的高度鲁棒性与接近完美的可验证性。


<details>
  <summary>Details</summary>
Motivation: 现有EaaS水印技术在面对黑盒模仿攻击时存在漏洞，尤其容易被输入文本的同义改写所规避，导致水印失效，威胁服务提供者的知识产权。因此亟需更鲁棒的水印机制来保护模型所有权。

Method: 首先分析现有水印在不同改写策略和模型下的失效情况；随后提出WET方法，利用线性变换嵌入水印，通过逆变换恢复并比对嵌入以实现验证；并通过消融实验评估各组件与超参数的影响。

Result: 实验证明，现有水印在多种同义改写攻击下普遍失效；而所提出的WET方法在多种场景下均能有效抵抗此类攻击，具有高鲁棒性和近似100%的验证准确率。

Conclusion: 本研究揭示了当前EaaS水印技术的关键弱点，提出了一个高效且鲁棒的新型水印方案WET，为保护嵌入服务的知识产权提供了有力支持。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [91] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为推理依赖生成（RDG）的新框架，用于生成无偏见的推理数据以缓解大语言模型中的选择支持偏差（CSB）。RDG通过自动构建平衡的推理问答对，显式地建模或解耦选择、证据与理由之间的依赖关系，从而生成跨领域的大量问答数据。实验表明，经过RDG数据微调的模型在记忆和评估实验中分别提升了81.5%和94.3%，同时保持在标准BBQ基准上的性能。该研究首次系统性地应对了LLM中的认知偏差问题，推动了更可靠的AI辅助决策系统的发展。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注于消除大语言模型中的社会与人口偏差，但对认知偏差如选择支持偏差（CSB）的研究仍处于空白状态。由于此类偏差可能导致模型在评估时系统性偏好自身选择，影响决策客观性，因此亟需有效方法来缓解这一问题。

Method: 提出推理依赖生成（RDG）框架，通过自动生成包含上下文依赖数据和依赖解耦数据的平衡推理问答对，显式控制选择、证据与理由之间的依赖关系，进而用于模型微调以减少选择支持偏差。

Result: 在记忆基实验中，模型性能提升81.5%；在评估基实验中提升94.3%，且在标准BBQ基准上表现稳定，说明该方法能有效缓解选择支持偏差而不损害原有能力。

Conclusion: 本研究首次提出了针对大语言模型认知偏差——选择支持偏差的有效解决方案，通过RDG框架生成高质量无偏见训练数据，显著提升了模型在复杂决策任务中的客观性，为构建更可信的AI辅助决策系统提供了新路径。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [92] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 本研究探讨了语言模型在提升劳动力市场信息分类中的潜力，通过将职位空缺文本链接至欧洲技能、能力、资格和职业（ESCO）分类体系及欧洲资格框架（EQF），比较了句段链接与实体链接两种方法。研究发布了一个开源工具，并构建了两个用于评估职位文本中职业与资格表示的标注数据集。同时探索了生成式大语言模型在此任务中的应用。结果表明，该工作推动了职位实体提取的技术前沿，并为数字经济中的工作、技能与劳动力市场话语分析提供了计算基础设施。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前劳动力市场信息分类面临挑战，传统方法难以有效捕捉职位文本中的技能、资格与职业关联。为提升分类精度，亟需利用先进语言模型技术，结合欧洲主流分类框架（如ESCO和EQF），实现更深层次的语义理解与结构化映射。

Method: 采用句段链接与实体链接两种主流方法，结合生成式大语言模型进行文本匹配；构建并使用两个专门针对职业与资格表示的标注数据集进行评估；开发并开源一个支持多种方法的分类工具。

Result: 所提出的方法显著提升了职位文本与ESC0/EQF框架之间的匹配准确率；生成式模型在复杂语义理解方面表现优异；开源工具可广泛应用于后续研究与实际系统开发。

Conclusion: 语言模型在劳动力市场信息分类中具有巨大潜力，尤其在处理非结构化文本与多层级分类框架的对齐方面。本研究不仅提供了有效的技术方案，还贡献了可复用的数据与工具资源，推动了劳动力市场数字化分析的发展。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [93] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: InvertiTune提出一种结合受控数据生成与监督微调的框架，通过从知识库提取子图并生成自然语言描述，构建更真实、复杂的训练数据，从而提升轻量级模型在单次输入下构建知识图谱的能力。实验表明，该方法优于更大规模的非微调LLM和现有先进Text2KG方法，并具备更强跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有Text2KG方法依赖迭代式LLM提示，计算成本高且易遗漏文本中分布复杂的复杂关系。需要更高效、准确的训练数据以支持轻量模型实现高性能。

Method: 设计受控数据生成管道：从大规模知识库提取子图，进行噪声过滤，利用LLM生成对应自然语言描述；基于生成数据对轻量级模型进行监督微调（SFT），实现单次输入的知识图谱构建。

Result: 在自建数据集CE12k上，InvertiTune超越更大规模非微调LLM及现有先进方法；在跨数据集测试集CrossEval-1200上表现优异，证明其强泛化能力。

Conclusion: 高质量、真实的训练数据对构建高效且高性能的Text2KG系统至关重要，InvertiTune通过数据生成与微调协同优化，为未来研究提供了有效路径。

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [94] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 本文提出了一种在政治文本中检测和解析解释的框架，通过训练一个轻量级因果语言模型，将因果陈述结构化为原因-结果对，实现大规模分析。该方法具有较低的人工标注需求、良好的泛化能力和较高的准确性，为政治科学中的解释研究提供了系统化工具。


<details>
  <summary>Details</summary>
Motivation: 解释在政治认知中至关重要，但现有研究缺乏系统性，且方法分散、局限于特定议题。因此需要一种可扩展、通用的分析框架来系统研究政治解释。

Method: 训练一个轻量级因果语言模型，自动识别并结构化政治文本中的因果陈述，输出为原因-结果对的形式，用于后续分析。

Result: 该方法能够以较低的人工标注成本实现大规模因果解释分析，表现出良好的泛化能力与较高准确性，优于传统人工编码。

Conclusion: 该框架为政治文本中的因果解释研究提供了一个高效、可扩展且准确的分析工具，有助于推动政治科学中解释研究的系统化发展。

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [95] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: 提出了一种名为随机掩码微调（RMFT）的新颖隐私保护微调技术，有效降低大型语言模型中个人身份信息（PII）的遗忘风险，同时保持较低性能损失。在Enron邮件数据集上的实验表明，与基线微调相比，RMFT可使总提取率和已见提取率分别降低80.81%和80.17%，且仅导致5.73%的困惑度增加。研究还引入了MaxTER评估框架，用于衡量隐私-效用权衡，并通过AURC指标证明了RMFT优于去重方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在训练过程中容易记忆个人身份信息（PII），带来严重的安全和隐私风险，亟需一种既能有效减少记忆、又不影响模型性能的微调方法。

Method: 提出随机掩码微调（RMFT）技术，在微调阶段对输入数据进行随机掩码处理，以减少模型对敏感信息的记忆；同时设计了MaxTER评估框架，用于系统评估隐私与模型性能之间的权衡。

Result: 在Enron Email Dataset上，RMFT实现80.81%的总提取率下降和80.17%的已见提取率下降，相较于基线微调显著提升隐私保护能力；性能方面仅增加5.73%的困惑度，优于传统去重方法，且在AURC指标下表现更优。

Conclusion: RMFT是一种高效且实用的隐私保护微调方法，能够在不显著损害模型性能的前提下大幅降低大语言模型中的个人身份信息记忆风险，具有良好的应用前景。

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [96] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: 该研究提出了一种基于大语言模型（LLM）的注释流程，用于分析两种类型差异显著的双语语境（西班牙语-英语和西班牙语-瓜拉尼语）中的社会语言学与主题特征。通过使用大语言模型，自动标注了3,691个代码切换句子的主题、语体和话语功能，并整合了迈阿密双语语料库中的人口统计学元数据，同时为西班牙语-瓜拉尼语数据集新增了主题标注。结果揭示了性别、语言主导性与话语功能之间的系统性关联，以及巴拉圭文本中正式瓜拉尼语与非正式西班牙语之间的清晰双语分层。这些发现以大规模定量证据复制并扩展了以往的互动和社会语言学观察，证明大语言模型能够可靠地恢复传统上仅通过人工标注才能获得的可解释社会语言学模式，推动了跨语言和低资源双语研究的计算方法发展。


<details>
  <summary>Details</summary>
Motivation: 传统社会语言学研究依赖于人工标注，耗时且难以在大规模语料上实施。本研究旨在利用大语言模型提升双语语料注释的效率与规模，实现对复杂社会语言现象的量化分析，特别是在语言资源稀缺或语言类型差异大的情境下。

Method: 采用大语言模型对双语语料中的代码切换句子进行自动标注，涵盖主题、语体和话语功能；整合来自迈阿密双语语料库的人口统计学信息；对西班牙语-瓜拉尼语数据集进行新主题标注；通过统计分析挖掘语言使用与社会变量之间的关联。

Result: 在迈阿密数据中发现性别、语言主导性与话语功能之间存在系统性关联；在巴拉圭数据中识别出正式瓜拉尼语与非正式西班牙语之间的清晰双语分层；所有发现均以大规模定量证据支持，复现并扩展了既有的社会语言学观察。

Conclusion: 大语言模型能够有效、可靠地支持大规模社会语言学分析，尤其适用于跨语言和低资源双语研究，显著提升了注释效率与研究可扩展性，为未来计算社会语言学的发展提供了可行路径。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [97] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: 本文提出PERCS数据集，旨在解决医学文本简化中忽视受众差异的问题。该数据集包含针对四类人群（普通公众、预医学生、非医学研究者、医学专家）的生物医学摘要及其定制化简写，每条摘要经医生审核确保准确性和角色契合度。实验显示不同角色在可读性、词汇和内容深度上存在显著差异。同时，本文对四种大语言模型进行了基准测试，评估其在全面性、可读性和忠实度方面的表现，为后续研究提供基线参考。数据集与工具已公开。


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源通常假设单一通用受众，忽略了不同用户群体在医学素养和信息需求上的巨大差异，导致信息传达效果不佳。因此需要开发面向特定角色的可控摘要方法，以提升健康素养和信息可及性。

Method: 构建PERCS数据集，收集生物医学摘要并生成针对四类人群（普通公众、预医学生、非医学研究者、医学专家）的定制化摘要；通过医生评审确保内容准确性和角色一致性；利用自动评估指标（全面性、可读性、忠实度）对四个大语言模型进行基准测试。

Result: PERCS数据集展示了不同角色在可读性、词汇复杂度和内容深度上的显著差异；四个大语言模型在自动评估中表现出不同程度的性能，建立了可用于未来研究的基准结果。

Conclusion: PERCS数据集和相关评估框架为实现面向特定受众的可控生物医学摘要提供了重要基础，有助于推动个性化健康信息传播研究，提升医学知识的可理解性与可及性。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [98] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 本文提出Idea-Gated Transformer，通过引入辅助的"Idea Head"预测未来上下文的词袋分布，生成概念向量以实时门控主词汇表，抑制语义无关词，减少主题漂移。实验表明该模型在保持与GPT-2相当困惑度的同时，显著提升领域保留能力，实现更可控的语言生成。


<details>
  <summary>Details</summary>
Motivation: 现有自回归语言模型因依赖局部关联而非全局规划，易出现主题漂移问题，尽管模型规模扩大可缓解但根本性短视问题仍存在。

Method: 设计Idea-Gated Transformer架构，引入辅助的Idea Head预测未来上下文的词袋分布，生成概念向量，并通过可微门控机制实时抑制无关词汇，缩小生成搜索空间。

Result: 在WikiText-103数据集上，Idea-Gated模型达到与标准GPT-2相当的验证困惑度，同时显著提升领域保留能力；定性和定量分析显示其能有效锁定特定语义簇（如金融、科学），抵抗联想漂移。

Conclusion: Idea-Gated Transformer提供了一种参数高效的方法，使语言模型具备更强的可控性与稳定性，有效缓解主题漂移问题。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [99] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为假设驱动的后向逻辑推理（HBLR）的新框架，旨在解决大语言模型在逻辑推理中因前向推理导致的冗余、幻觉和语义漂移问题。HBLR通过高置信度符号化翻译与假设驱动的后向推理相结合，仅将高置信度文本片段转换为一阶逻辑（FOL），不确定内容保留在自然语言中，并引入反射模块确保语义一致性。推理阶段模拟人类演绎思维，从结论出发逆向验证前提，同时通过反思模块纠正错误推理步骤。在五个基准测试上的实验表明，HBLR在准确性和效率上均优于现有强基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要采用前向推理，容易产生冗余推理路径、幻觉步骤和语义漂移，影响推理的可靠性和效率。需要一种更接近人类演绎思维的推理机制，以提升逻辑推理的质量与稳定性。

Method: 提出假设驱动的后向逻辑推理（HBLR）框架，包含两个核心模块：1）信心感知的符号化翻译模块，仅将高置信度文本转为一阶逻辑（FOL），其余保留自然语言，并通过翻译反射模块检测并回退语义损失；2）后向推理模块，假设结论成立，递归验证前提，结合推理反射模块识别并修正错误推理步骤。

Result: 在五个逻辑推理基准测试中，HBLR在准确率和推理效率方面均显著优于现有强基线方法，验证了其在提升推理可靠性与效率方面的有效性。

Conclusion: HBLR通过融合信心感知的符号化与假设驱动的后向推理，有效缓解了传统前向推理中的冗余、幻觉和语义漂移问题，展现出更强的逻辑一致性和推理效率，为构建可信赖的智能推理系统提供了新范式。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [100] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 本文收集了11.5小时的《传送门2》合作模式中的真人对话数据，构建了包含24.5万个语句的Portal Dialogue Corpus。研究揭示了复杂空间指称、澄清与修复、临时约定形成等在现有对话语料库中罕见的语言现象，并公开发布包括视频、音频、转录文本、游戏状态数据及人工与自动标注在内的完整资源，以支持未来对复杂情境下协作问题解决中语言使用的分析。


<details>
  <summary>Details</summary>
Motivation: 现有对话语料库多集中于闲聊或任务导向对话，缺乏对复杂协作场景中语言使用的研究。合作类视频游戏提供了丰富的语言数据，尤其在需要沟通与推理的不确定性环境中，具有重要研究价值。

Method: 通过收集《传送门2》合作模式下的玩家实时对话，整合语音、视频、游戏状态和标注信息，构建大规模口语对话语料库，并进行语言现象分析。

Result: 识别出复杂空间指称、澄清与修复、临时约定形成等独特语言现象；构建并公开发布完整的Portal Dialogue Corpus，涵盖多种数据形式与标注信息。

Conclusion: 该语料库为研究复杂情境下协作性语言使用提供了宝贵资源，有助于推动自然语言处理在动态、交互式环境中的发展。

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [101] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: 本文提出了一种名为Dual LoRA的新方法，通过在原始LoRA中引入归纳偏置来提升参数高效微调的性能。该方法将低秩矩阵分为两组：幅度组（控制参数更新的强度和方向）和方向组（决定参数是前进还是后退），并分别使用ReLU和符号函数实现。在GPT-2、RoBERTa、DeBERTa和LLaMA-1/2/3等多个模型上，对自然语言生成、理解及常识推理任务进行了广泛实验，结果表明，Dual LoRA在相同可训练参数量下持续优于LoRA及其最先进的变体。


<details>
  <summary>Details</summary>
Motivation: LoRA虽流行但受限于低秩假设，导致微调性能不佳；本文旨在通过引入更贴近全量微调优化过程的归纳偏置来提升性能。

Method: 将低秩矩阵分解为幅度组与方向组，幅度组使用ReLU控制更新幅度，方向组使用符号函数决定更新方向，从而更准确地模拟梯度优化过程。

Result: 在多种NLP任务和基线模型上，Dual LoRA均显著优于LoRA及其先进变体，在相同参数量下表现更优。

Conclusion: Dual LoRA通过引入幅度与方向分离机制，有效提升了低秩微调的性能，是一种高效且通用的参数高效微调方法。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [102] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: PretrainZero提出一种基于预训练语料库的强化主动学习框架，通过主动识别和推理预训练语料中的合理信息，实现无需验证标签或监督微调的自监督预训练，显著提升模型在通用推理任务上的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的大模型虽在特定领域表现优异，但依赖可验证奖励信号，限制了其在通用推理能力上的拓展。本文旨在突破这一瓶颈，实现从领域特定后训练向通用预训练的转变。

Method: 提出PretrainZero框架，包含主动预训练、自监督学习和验证扩展三个核心机制：1）模拟人类主动学习，通过强化学习主动选择并推理预训练语料中的有意义内容；2）完全不依赖外部标签或奖励模型，直接在维基百科等通用语料上进行强化预训练；3）通过逐步增加掩码跨度的挑战，持续提升模型的通用推理能力。

Result: 在强化预训练中，PretrainZero使Qwen3-4B-Base模型在MMLU-Pro、SuperGPQA和数学平均基准上分别提升8.43、5.96和10.60分；在后训练阶段，预训练模型可作为下游强化学习验证任务的推理基础模型，展现出良好的泛化潜力。

Conclusion: PretrainZero成功实现了无需外部标注的通用推理预训练，打破了验证数据墙，为构建真正具备通用智能潜力的模型提供了新路径。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [103] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: 该报告研究了Top-$k$ Attention机制在长上下文建模中解码和训练阶段的有效性与理论机制。实验表明，仅保留与查询相似度最高的关键键（Keys）作为上下文窗口，在解码阶段可实现与全注意力相当甚至更优的性能，尤其在HELMET和LongBench v2等任务上。进一步通过一致的训练-推理Top-$k$操作，显著提升了模型表现。针对精确Top-$k$计算复杂度高的问题，研究发现近似算法精度与下游任务性能呈正相关，并对DeepSeek-V3.2-Exp模型中的Lightning Indexer进行了精度统计评估。最后从熵的角度提供理论解释：经过Top-$k$ SFT训练的模型在下游任务中表现出熵降低现象，验证了低熵状态更适配Top-$k$解码的假设。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文建模中应用广泛，但其推理计算成本已成为制约智能体、多模态等应用发展的瓶颈。为降低计算开销并保持性能，亟需探索高效注意力机制，尤其是Top-$k$ Attention在解码与训练中的有效性与机制原理。

Method: 通过大量实验验证精确Top-$k$解码的有效性；设计并测试原生Top-$k$注意力训练策略以确保训练与推理一致性；分析近似Top-$k$算法精度对下游任务的影响；结合熵理论对实验现象进行解释，揭示低熵状态对Top-$k$解码的适应性。

Result: Top-$k$解码在多个下游任务中达到或超越全注意力性能；训练与推理一致的Top-$k$策略显著提升模型表现；近似算法精度越高，任务性能越好；实验观测到熵降低现象，支持低熵状态更利于Top-$k$解码的理论假设。

Conclusion: Top-$k$ Attention机制在长上下文建模中具备显著潜力，通过精确解码、一致性训练、高精度近似算法以及低熵优化，可在大幅降低计算成本的同时维持甚至提升模型性能，为未来高效大模型设计提供了有效路径。

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [104] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: 本文系统评估了8种推理策略和3种大型推理模型（LRMs）在8个不同数据集上的摘要生成表现，发现推理并非万能解法，其效果高度依赖具体策略与上下文。显式推理提升流畅性但损害事实准确性，而隐式推理则相反。增加模型内部推理预算反而可能降低事实一致性，表明有效摘要需忠实压缩而非过度创造。


<details>
  <summary>Details</summary>
Motivation: 验证大语言模型在抽象摘要任务中的推理能力是否如在数学和代码生成中那样有效，填补现有假设与实证之间的空白。

Method: 针对摘要任务定制通用推理策略，并在多个数据集上进行大规模对比实验，评估不同推理方法对摘要质量与事实一致性的影 响。

Result: 显式推理提高摘要流畅性但降低事实准确性；隐式推理则反之。增加推理预算可能损害事实一致性，说明忠实压缩比创造性思考更重要。

Conclusion: 推理在摘要任务中并非普适解决方案，其有效性受策略和上下文制约，应注重事实忠实性而非过度推理。

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [105] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 本文提出了一种可解释的事实一致性评估框架，用于领域内和开放域文本，通过将文本分解为原子事实并采用灵活的无模式方法来改进现有评估指标的不足。该方法引入加权度量以增强事实评估，并提供机制控制复杂领域的评估复杂性。在通用和临床数据集上进行了基准测试，并发布了代码以支持未来的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的评估指标无法充分评估事实一致性且缺乏可解释性，难以诊断和缓解错误，尤其是在临床等高风险领域中，这促使研究者开发一种更有效、可解释的事实一致性评估方法。

Method: 将文本分解为原子事实，提出一种无模式的灵活方法，使用加权度量来提升事实评估能力，并设计机制以控制复杂领域的评估复杂性。

Result: 在通用和临床数据集上的实验表明，所提框架能有效评估事实一致性，具有良好的可解释性和适应性，同时释放了代码以促进后续研究。

Conclusion: 本研究提出的框架显著提升了事实一致性评估的可解释性和准确性，尤其适用于高风险应用领域，为未来事实感知模型的训练提供了有力支持。

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [106] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 本研究基于对1,906名意大利语成人的新调查数据，首次全面描绘了生成式人工智能（GenAI）在意大利的采用情况、使用模式和数字素养水平。研究发现，GenAI在工作和个人生活中的应用广泛，甚至用于情感支持和医疗建议等敏感任务；尽管用户数字素养普遍较低，但其作为主要信息来源的地位仍在上升，存在误判错误或虚假信息的风险。此外，研究揭示了显著的性别差异——女性尤其是老年女性的采用率仅为男性的一半，且使用频率更低。虽然数字素养是影响采用的关键因素，但无法完全解释该差距，表明存在其他未明的障碍。总体而言，研究揭示了GenAI多用途使用的复杂图景，强调亟需针对性教育干预，并进一步探究仅靠能力无法解释的公平参与障碍。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI聊天机器人通过对话界面普及，其在数字互动中的角色日益重要。然而，技术采纳不均和对局限性认知不足可能加剧数字鸿沟，因此亟需系统性地了解其在特定国家的使用现状与潜在风险，以制定有效应对策略。

Method: 采用问卷调查法，收集1,906名意大利语成人的数据，分析GenAI的采用率、使用场景、信息依赖程度及用户数字素养水平，并进行性别与年龄分组比较，识别影响采用的关键因素。

Result: GenAI在意大利被广泛用于工作与个人事务，包括敏感领域；尽管用户整体数字素养偏低，仍成为主要信息源，存在误判风险；女性，特别是老年女性，采用率和使用频率显著低于男性；数字素养虽为关键预测因子，但不足以解释性别差距，暗示存在其他结构性或社会文化障碍。

Conclusion: GenAI的快速渗透凸显了提升公众数字素养的重要性，同时需要开展更深入的研究，识别并克服那些超越知识层面的参与障碍，以确保技术发展的包容性和公平性。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [107] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种名为Hydro-SE Bench的大型语言模型（LLM）评估基准，涵盖4000道多选题，覆盖水科学与工程（Hydro-SE）的九个子领域，用于评估LLM在基础概念、工程应用及推理计算方面的能力。结果显示，商业LLM准确率在0.74至0.80之间，小参数模型在0.41至0.68之间；尽管在自然科学相关子领域表现良好，但在行业标准和水工结构等特定知识上仍存在不足。模型规模提升主要增强推理与计算能力，但实际工程应用仍有巨大改进空间。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在水科学与工程领域的知识掌握和应用能力尚未得到充分评估，而该领域具有高度跨学科性且依赖专家协作，亟需可靠评估工具以指导模型开发与应用。

Method: 构建Hydro-SE Bench评估基准，包含4000道多选题，覆盖九个子领域，从基础概念、工程应用到推理计算三个维度对多种LLM进行系统评估。

Result: 商业LLM在Hydro-SE Bench上的准确率为0.74–0.80，小参数模型为0.41–0.68；模型规模提升主要改善推理与计算能力，但在行业标准和工程实践知识方面仍表现薄弱。

Conclusion: Hydro-SE Bench有效揭示了当前LLMs在水科学与工程任务中的优势与局限，为模型优化和实际应用提供了明确方向。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [108] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: 该研究通过类比认知神经科学的功能定位方法，分析了大型语言模型（LLMs）中67种英语句法现象的响应单元，发现不同类型的句法一致（如主谓一致、代词一致、限定词-名词一致）会激活重叠的模型单元，表明一致性在模型表征中构成一个有意义的功能类别。这一模式在英语、俄语、汉语中均成立，并在跨语言分析中显示结构相似的语言共享更多主谓一致的单元，揭示了句法一致是LLMs表示空间中的一个有意义范畴。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型中语法知识的表征方式，特别是不同句法现象是否共享或具有独立的内部组件，以理解语言模型如何处理句法依赖关系。

Method: 采用功能定位方法，识别七种开源权重模型中对67种英语句法现象最敏感的模型单元，并通过因果分析验证这些单元对模型句法性能的支持作用。同时进行跨语言分析，比较57种不同语言中主谓一致的单元共享情况。

Result: 不同类型的句法一致（如主谓、代词、限定词-名词一致）激活重叠的模型单元；该模式在英语、俄语、汉语中一致存在；跨语言分析显示结构相似的语言在主谓一致上共享更多单元。

Conclusion: 句法一致——作为句法依赖的关键标记——构成了大型语言模型表示空间中的一个有意义的功能类别，表明模型内部存在对句法关系的系统性表征。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [109] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit 是一个利用语言技术评估 AI 教学工具教学质量的应用，提供演示、评估、模型检查和数据可视化功能，服务于教育利益相关者及 ACL 社区，支持学习并可收集用户反馈与标注。


<details>
  <summary>Details</summary>
Motivation: 为了评估 AI 教学工具的 pedagogical quality（教学质量），需要一个综合性的工具来支持教育实践和研究，同时促进用户反馈与数据收集。

Method: 采用语言技术构建评估框架，集成演示、评估、模型检查与数据可视化功能，支持教育场景中的应用与反馈机制。

Result: 开发出 AITutor-EvalKit 工具，能够有效评估 AI 教学工具的教学质量，并支持教育研究与用户参与。

Conclusion: AITutor-EvalKit 为 AI 教育应用提供了有效的评估与交互支持，有助于提升 AI 教学系统的质量与可解释性。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [110] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: DZ-TDPO提出一种非破坏性对齐框架，通过冲突感知的动态KL约束与可学习的时间注意力偏置，解决长对话中的状态惯性问题。在MSC数据集上，该方法在Phi-3.5上实现86.2%的胜率，并具备强零样本泛化能力；规模分析揭示‘容量-稳定性权衡’：小模型存在对齐代价（困惑度上升），而大模型（Qwen2.5-7B）实现近完美对齐（99.4%胜率）且困惑度开销极小。结果表明，通过精确注意力调控可缓解注意力偏差，无需破坏性权重更新，保持模型通用能力。


<details>
  <summary>Details</summary>
Motivation: 长对话系统中存在状态惯性问题，即静态约束导致模型难以调和用户意图演化与历史上下文之间的冲突，影响对话连贯性与适应性。

Method: 提出DZ-TDPO框架，结合冲突感知的动态KL散度约束与可学习的时间注意力偏置，实现非破坏性对齐，避免传统方法中因权重更新带来的能力损失。

Result: 在Multi-Session Chat数据集上，DZ-TDPO在Phi-3.5上达到86.2%的胜率，具备良好零样本泛化能力；大规模模型（Qwen2.5-7B）实现99.4%胜率，困惑度开销极小，验证了注意力调控的有效性与稳定性。

Conclusion: 通过精确的注意力调节而非破坏性权重更新，可有效缓解长对话中的注意力偏差问题，实现高对齐度与强通用能力的兼顾，为构建高效、稳定、可扩展的长对话系统提供了新范式。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [111] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: Doublespeak 是一种无需优化的上下文表示劫持攻击，通过在多个上下文示例中将有害关键词（如 'bomb'）替换为无害词（如 'carrot'），使模型内部表示逐渐将无害词映射到有害语义，从而绕过安全对齐机制。该攻击在早期层保留无害含义，后期层逐渐转化为有害语义，成功实现隐蔽恶意指令。其在 Llama-3.3-70B-Instruct 上达到 74% 的成功率，且适用于多种模型架构，揭示了当前对齐策略在表示层面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的安全对齐机制容易被隐蔽的语义劫持攻击绕过，而当前方法未充分关注模型内部表示空间的脆弱性，因此需要探索新的攻击与防御范式。

Method: 通过在上下文示例中系统性地将有害词替换为无害词，利用模型在推理过程中对语义的逐步编码特性，诱导无害词的内部表示向有害词靠拢，形成隐式语义覆盖。结合可解释性工具分析表示演化过程。

Result: Doublespeak 成功在不改变表面文本的情况下，使模型将看似无害的提示（如 'How to build a carrot?'）理解为非法指令（如 'How to build a bomb?'），在多种开源与闭源模型上取得高达 74% 的攻击成功率，且无需额外优化。

Conclusion: 该研究揭示了大语言模型在潜在表示空间中的新攻击面，表明当前基于规则或微调的安全对齐方法不足以抵御此类表示级劫持，未来需从表示层面重新设计安全机制。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [112] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 该研究将对比解码方法DoLa首次应用于编码器-解码器架构（T5和FLAN-T5），并评估其对模型指令遵循能力的影响。结果显示，DoLa在某些任务上提升了生成文本的忠实度，但在其他任务上反而造成损害。通过层间分析，研究量化了DoLa对输出概率的影响，揭示其作用机制。


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法如DoLa仅适用于解码器-only架构，且主要关注事实性提升，缺乏在编码器-解码器架构中对指令遵循能力影响的研究。本文旨在填补这一空白，探索DoLa在更广泛模型结构中的适用性和效果。

Method: 将DoLa方法适配至T5和FLAN-T5模型，通过在不同层间进行对比解码，并结合层级分析，追踪生成过程中logit的变化，以评估其对输出质量与指令遵循能力的影响。

Result: DoLa在部分任务中显著提高了生成内容的忠实度，但在另一些任务中导致性能下降。层间分析表明，其对输出概率的影响具有任务依赖性，且在不同层间表现出异质性。

Conclusion: DoLa可成功应用于编码器-解码器架构，但其效果具有任务特异性；未来需针对具体任务设计自适应的对比解码策略，以实现更稳定和可控的生成效果。

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [113] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 本文提出一种基于实证的提示工程框架，用于优化大语言模型在心理学等领域中识别文本构念的性能。通过实验比较五种提示策略（代码本引导的提示选择、自动提示工程、角色提示、思维链推理和解释性提示），发现提示中的构念定义、任务表述是影响性能的关键因素，而角色提示、思维链和解释性提示未能完全弥补糟糕提示带来的性能损失。最佳效果来自结合代码本引导与自动提示工程的少样本提示。研究建议研究者应尽可能生成并评估多种提示变体，基于训练数据的实证表现选择最优提示，并在保留集上验证，以实现与专家判断高度一致的结果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本分类中表现优异，但其输出高度依赖提示词的表述方式。现有提示工程研究多集中于通用任务，缺乏针对心理学等具有精确理论定义领域的研究，且这些领域中的概念可能未充分体现在预训练数据中。因此，亟需一种系统化的方法来优化提示，以提升模型在关键领域中的表现与专家判断的一致性。

Method: 采用实证框架评估五种提示策略：代码本引导的提示选择、自动提示工程、角色提示、思维链推理和解释性提示。在三个心理构念和两个大语言模型上进行零样本与少样本分类实验，通过对比不同提示变体在训练集上的表现，筛选最优提示组合，并在保留集上验证最终效果。

Result: 提示中的构念定义和任务表述是最关键的特征，显著影响分类准确性；角色提示、思维链和解释性提示未能有效缓解不良提示带来的性能下降。结合代码本引导与自动提示工程的少样本提示在多数情况下最接近专家判断，表现出最优性能。

Conclusion: 为确保大语言模型在需要与专家判断对齐的任务中表现可靠，应系统性地生成并评估多种提示变体，优先依据实证表现选择提示与示例，推荐将人工设计与自动生成相结合，并通过保留集验证最终方案，从而实现理论驱动且高效的提示优化。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [114] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: This paper shows that fine-tuning LLMs on verbalized medical consensus rules leads to highly accurate and explainable predictions, especially in early diagnosis like sepsis. The key bottleneck is forecasting irregular clinical time series, which can be improved by combining LLMs with time series models in a multimodal framework.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the lack of faithful explanations in machine learning models for early medical prediction, which is crucial for gaining trust from medical practitioners. While accuracy has been prioritized, the need for transparent and rule-compliant reasoning based on established medical consensus guidelines is underemphasized.

Method: The authors fine-tune large language models (LLMs) on verbalized instantiations of medical consensus rules derived from electronic health records. They leverage these rules to train LLMs to follow step-by-step medical reasoning, enabling automatic evaluation of both derivation correctness (logical consistency) and value correctness (accuracy against real measurements). The approach is exemplified using the Sepsis-3 definition.

Result: Small fine-tuned models outperform larger one-shot prompted LLMs and models trained on general medical texts. Fine-tuning on rule instantiations achieves nearly perfect derivation correctness on unseen patient data within the same medical domain. However, the main challenge shifts from out-of-distribution generalization to forecasting sparsely and irregularly sampled clinical variables, which is mitigated by integrating time series forecasting outputs into a multimodal LLM setup.

Conclusion: Fine-tuning LLMs on verbalized medical consensus rules enables highly faithful and correct reasoning, significantly improving trustworthiness in clinical predictions. The primary limitation lies not in generalization across patient populations but in forecasting temporal clinical variables, which can be addressed through multimodal integration with time series models.

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [115] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: FusedKV 和 FusedKV-Lite 通过跨层融合关键信息，显著减少 Transformer 解码器的 KV 缓存内存占用，同时保持甚至提升性能。该方法在不牺牲相对位置信息的前提下，有效缓解长序列下的内存瓶颈问题，适用于从 332M 到 4B 参数规模的 LLM。


<details>
  <summary>Details</summary>
Motivation: Transformer 解码器在处理长序列时，因 KV 缓存占用大量内存而受限；现有跨层共享方法（如 YOCO、CLA）虽能缓解此问题，但性能不如层内方法（如 GQA），亟需理解其根本原因并提出更优方案。

Method: 通过分析顶层键值的信息来源，发现值主要来自底层，而键则来自底层与中层；据此提出 FusedKV，将顶层 KV 缓存设计为底层与中层最相关信息的可学习融合，直接作用于后 RoPE 键以保留位置信息；进一步提出 FusedKV-Lite，简化为直接使用底层值和中层键，降低 I/O 开销。

Result: 在 332M 至 4B 参数的 LLM 上，所提方法减少 50% 的缓存内存，且验证困惑度低于标准 Transformer 解码器，证明其兼具高效率与高性能。

Conclusion: FusedKV 及其轻量版本 FusedKV-Lite 提供了一种高效且高性能的跨层 KV 缓存共享机制，是解决长序列推理中内存瓶颈的有效架构替代方案。

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [116] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 本文主张语言模型应涵盖语言变异的全谱（如方言、历史语言、非正式语言等），而非仅依赖标准文本。以巴斯克语为例，构建了结合标准、社交媒体和历史来源的新语料库，并预训练了BERnaT系列编码器模型的三种配置：标准、多样性和混合。提出一个评估框架，将自然语言理解任务分为标准和多样化子集，以评估语言泛化能力。结果表明，同时使用标准和多样化数据训练的模型在所有任务类型上均优于仅使用标准语料库的模型，且不损害标准基准性能。强调了语言多样性在构建包容性、可泛化语言模型中的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型依赖大规模文本语料库，但过滤过程可能无意中排除非标准语言变体，导致模型鲁棒性下降和表征偏见强化。因此，有必要让模型捕捉更广泛的语言变异，提升其包容性和泛化能力。

Method: 针对巴斯克语这一形态丰富且资源较少的语言，构建了融合标准文本、社交媒体和历史文献的新语料库；预训练了BERnaT系列编码器模型的三种配置（标准、多样、混合）；设计了一个将自然语言理解任务划分为标准与多样化子集的评估框架，以衡量模型对语言多样性的适应能力。

Result: 在多种任务类型中，基于标准与多样化数据联合训练的模型表现优于仅使用标准语料库训练的模型，且在标准基准测试中未出现性能下降。说明引入语言多样性有助于提升模型整体性能和泛化能力。

Conclusion: 语言模型应主动纳入语言变异的多样性，以增强其包容性与通用性。通过整合多源异构数据进行训练，不仅能提升对非标准语言形式的理解能力，还能保持对标准语言任务的高性能，是构建更具鲁棒性和公平性的语言模型的重要路径。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [117] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: 本文提出了 BRAND（Bilingual Religious Accountable Norm Dataset），一个专注于南亚四大宗教（佛教、基督教、印度教和伊斯兰教）的多语言数据集，包含超过2400个条目，涵盖英语和孟加拉语两种语言。研究发现，尽管模型在英语中表现较好，但在孟加拉语中表现较差，并且对伊斯兰教存在系统性偏见，即使在非宗教相关问题中也如此。这表明多语言模型在不同语言间存在持续的偏见问题，并与人机交互领域中的宗教与灵性议题相关联。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在检测和分类偏见方面虽有进步，但在涉及宗教等敏感话题时仍存在严重挑战，尤其是多语言模型常出现宗教误解和不准确表达，亟需更可靠的评估数据集与分析方法。

Method: 构建了 BRAND 数据集，包含英语和孟加拉语两种语言的三种不同类型提示，用于测试多语言模型在宗教相关及中性问题上的表现，并分析其偏见模式。

Result: 模型在英语中表现优于孟加拉语，且对伊斯兰教表现出系统性偏见，即便在宗教中立问题上也是如此，说明语言差异加剧了模型偏见。

Conclusion: 多语言模型在处理宗教相关内容时存在显著偏见，尤其在非英语语境下更为突出；该研究揭示了模型偏见与语言之间的深层关联，并呼吁在人机交互设计中更关注宗教与灵性议题的公平性。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [118] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种两阶段方法，将Qwen2.5-3B模型适配至藏语这一形态丰富且资源匮乏的语言。首先通过持续预训练（CPT）建立藏语语言基础，再通过监督微调（SFT）实现任务和翻译专精。实验表明，困惑度显著下降（从2.98降至1.54），中译藏翻译质量大幅提升（BLEU从0.046升至0.261，chrF从2.2升至6.6）。层分析显示，适应主要集中在嵌入层和输出头，中后段MLP投影编码领域特异性变换。结果表明，CPT构建了藏语语义流形，而SFT在最小干扰下强化任务对齐。该研究首次对藏语大模型适配动态进行了量化探索，并提供了一个开放、可复现的框架，用于扩展多语言基础模型至低资源语言场景。


<details>
  <summary>Details</summary>
Motivation: 低资源语言如藏语面临数据稀缺与跨语言漂移问题，导致大语言模型难以有效适配。现有方法缺乏对适配过程的系统性分析，亟需一种可解释、可复现的适配框架以提升模型在低资源语言上的表现。

Method: 采用两阶段策略：第一阶段为持续预训练（CPT），利用藏语语料增强模型的语言理解能力；第二阶段为监督微调（SFT），基于特定任务和翻译数据进一步优化模型性能。结合层级分析（435层）揭示模型内部表征变化机制。

Result: 困惑度由2.98降至1.54，中译藏翻译的BLEU评分从0.046提升至0.261，chrF从2.2提升至6.6，显示出显著性能提升。层分析发现，适应主要集中于嵌入层与输出头，中后段MLP投影承担领域特异性转换功能。

Conclusion: 持续预训练有效构建藏语语义空间，监督微调在保持整体结构稳定的同时实现任务精准对齐。该研究为低资源语言的大模型适配提供了首个量化分析路径，并建立了开放可复现的实践范式。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [119] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 本文提出了一种持续BPE训练方法，用于在新领域或语言中适配预训练语言模型的分词器，通过继续BPE合并学习过程来提升分词效率和新增词汇利用率。同时引入基于叶子节点的词汇剪枝方法，在不损失模型性能的前提下移除冗余分词。两者结合为可控词汇修改提供了实用工具，并已开源。


<details>
  <summary>Details</summary>
Motivation: 现有分词器扩展方法常导致大量未使用或不可达的分词，影响效率；同时缺乏有效手段在保持性能前提下精简词汇表。

Method: 提出持续BPE训练，即在已有分词器基础上，继续在新数据上进行BPE合并学习；引入基于叶子节点的词汇剪枝策略，识别并移除冗余分词。

Result: 实验表明该方法在多种语言和模型架构上均提升了分词效率，更好地利用了新增词汇，且剪枝后模型质量保持稳定。

Conclusion: 持续BPE训练与叶子基剪枝相结合，为预训练模型在新领域的分词器适配提供了高效、可控的解决方案，并已以开源形式发布。

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [120] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe提出一种两阶段自适应请求调度策略，结合请求推理特征与运行时信息，动态调整批处理机制，显著提升增强型大语言模型推理服务的有效吞吐量，降低队列延迟和首令牌时间。


<details>
  <summary>Details</summary>
Motivation: 现有推理系统依赖先到先服务（FCFS）调度导致严重的队头阻塞，且静态的批处理令牌限制无法适应负载和硬件条件的变化，影响有效吞吐量和服务质量。

Method: AugServe采用两阶段自适应请求调度：第一阶段基于增强型LLM请求的推理特征优化调度顺序；第二阶段结合实时运行信息持续优化调度决策，并根据硬件状态和实时负载动态调整令牌批处理机制。

Result: 实验表明，AugServe相比vLLM和InferCept，有效吞吐量提升4.7-33.1倍和3.3-13.2倍，首令牌时间（TTFT）降低最多96.3%和95.0%。

Conclusion: AugServe通过自适应调度与动态批处理机制，有效缓解了队头阻塞和资源利用率低的问题，显著提升了增强型大语言模型推理服务的效率与服务质量。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [121] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM 是一个 2.4B 参数的视觉语言模型，在开源 2B 规模的 VLM 中实现了最先进的多语言视觉问答性能。它采用 SigLIP2 视觉编码器与 Qwen3 语言主干结合，通过注意力池化连接器实现对任意分辨率图像的高效处理，在标准 VQA 基准和多语言评估中均优于同类模型，同时保持了良好的纯文本性能。


<details>
  <summary>Details</summary>
Motivation: 提升开源 2B 规模视觉语言模型在多语言视觉问答任务中的表现，同时保持高效的图像处理能力和文本理解能力。

Method: 采用 SigLIP2 视觉编码器与 Qwen3 语言主干，通过注意力池化连接器实现图像与文本的高效融合，支持任意分辨率输入。

Result: 在多个标准 VQA 基准和多语言评估中表现优于同类模型，且在纯文本任务上保持竞争力。

Conclusion: Jina-VLM 在多语言视觉问答任务中达到当前开源 2B 规模模型的最优水平，具备高效、灵活和高性能的特点。

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [122] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory 是一种在强化学习（RL）之前通过监督微调（SFT）阶段训练模型以初步掌握认知技能的方法。它不依赖于更强模型的蒸馏，而是利用模型自身生成的、重新排列以模拟特定技能的样本作为训练数据。这些‘银质’SFT轨迹虽不完美，但能有效引导模型在后续RL中习得技能。实验表明，经SkillFactory初始化的模型在RL后能更好地泛化到更难的任务变体，更鲁棒地应对域外任务，并且确实使用了所学的认知技能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于基础语言模型本身具备某些认知技能，才能通过强化学习进一步利用这些技能。然而，如何让模型掌握原本不具备的技能是一个挑战。本文旨在探索一种无需强模型蒸馏、仅通过自生成数据即可在SFT阶段预先赋予模型一定认知技能的方法。

Method: 提出SkillFactory方法，通过收集模型自身的输出，将其重构为包含验证、回溯、重试等认知技能的结构化轨迹，形成‘银质’训练数据，用于监督微调阶段，从而为后续强化学习阶段提供有效的初始诱导偏置。

Result: 1. 经SkillFactory SFT初始化的模型在强化学习后能更好泛化到更复杂的任务变体，尽管其预训练阶段性能较低；2. 模型确实在推理过程中使用了所学的认知技能；3. 与直接从基础模型开始强化学习相比，经SkillFactory处理的模型对域外任务更具鲁棒性。

Conclusion: 在强化学习之前通过监督微调引入诱导偏置，能够帮助模型学习并稳健运用复杂认知技能，这为构建更智能、更灵活的推理系统提供了新路径。

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


### [123] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

TL;DR: 本文提出了一种名为MAPS的多层自省与自动提示框架，通过结合思维链（CoT）、自省机制和自动提示技术，提升大语言模型在复杂多步数学推理任务中的表现。该框架采用迭代优化过程：先以CoT生成解题思路，若发现错误，则通过自适应自省机制分析错误并生成定制化提示进行修正。实验表明，MAPS显著优于标准CoT，在多个基准测试中达到与专门优化推理的大模型相当的性能。尽管增加反思层数可提高准确率，但会带来更高的计算成本，因此MAPS通过智能控制反思深度，在性能与成本间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理复杂多步推理任务时仍存在不足，尤其在数学推理方面表现有限。传统静态提示方法难以应对错误修正与逻辑优化需求，亟需一种动态、可迭代的改进机制来提升模型的推理能力。

Method: 提出MAPS框架，融合Chain of Thought（CoT）提示、自省机制与自动提示技术。模型首先通过CoT生成初步推理路径；当检测到错误时，启动自适应自省模块，识别错误类型并生成针对性修正提示；这些动态提示被用于迭代优化推理过程，实现逐步精炼。同时，通过策略性限制反思层数，在保证性能的同时控制计算开销。

Result: 在四个主流基准测试上，MAPS在多种大语言模型上均显著优于标准CoT方法，并达到与专门设计的推理优化模型相媲美的性能。其通用性使普通大模型具备接近专用推理模型的能力。增加反思层数可进一步提升准确率，但代价是更高的令牌消耗；通过合理控制深度，实现了性能与成本之间的良好权衡。

Conclusion: MAPS框架有效提升了大语言模型在多步数学推理任务中的表现，通过动态自省与自动提示实现推理过程的迭代优化。该方法不仅增强了模型的自我纠错能力，还为通用大模型提供了接近专业推理模型的性能，且在成本与效果之间实现了高效平衡，具有广泛的应用前景。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks. In this paper, we propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework, a novel approach designed to enhance multi-step mathematical reasoning in LLMs by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an iterative refinement process. Initially, the model generates a solution using CoT prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning. Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models. In addition, MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [124] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 本文提出了一种名为'Weight-Calculatism'的新型认知架构，基于第一性原理，将认知分解为不可分割的逻辑原子及两种基本操作（指向与比较），通过可解释的权重计算模型（权重 = 收益 × 概率）实现决策，所有价值均可追溯至初始权重集合。该架构具备高度可解释性、内在泛化能力及可追踪的价值对齐，通过图算法计算引擎和全局工作空间流程实现，并经初步代码验证，在复杂场景中展现出类人推理与稳健学习能力，为构建可信且对齐的通用人工智能（AGI）提供了理论与实践基础。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能范式在可解释性与价值对齐方面存在根本性挑战，亟需一种从底层原理出发的新型认知架构以推动可信、对齐的通用人工智能发展。

Method: 将认知解构为逻辑原子与指向、比较两种基本操作；采用权重计算模型（权重 = 收益 × 概率）进行决策建模；通过图算法计算引擎与全局工作空间流程实现系统运行；所有值均源自可审计的初始权重集，确保全程可追溯。

Result: 架构在复杂场景中实现了透明、类人化的推理过程，表现出强大的学习能力和对新情境的泛化适应性，验证了其在可解释性、价值对齐与通用性方面的优越表现。

Conclusion: Weight-Calculatism 提供了一条从第一性原理出发的可行路径，为构建可信、可解释、价值对齐的通用人工智能奠定了坚实的理论与实践基础。

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [125] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 本文探讨了在何种情况下传统的长思维链（CoT）可被符号求解器集成方法增强。实验表明，当问题需要有限的隐式推理但搜索空间庞大时，符号求解器集成方法能显著提升性能；尤其在约束满足问题中，该方法优于纯语言模型，且在提供声明性示例时，CodeLlama-13B甚至超越GPT-4o在复杂Zebra谜题上的表现。


<details>
  <summary>Details</summary>
Motivation: 传统长思维链方法存在生成冗长推理链导致的高计算开销和错误风险，而符号求解器集成方法可通过将任务转化为可执行代码来提升效率与准确性，但其适用边界尚不明确，亟需探索何时该方法更优。

Method: 通过对比分析不同模型（如GPT-4o、CodeLlama-13B）在各类推理任务中的表现，结合符号求解器处理约束满足问题的能力，系统评估符号求解器集成方法在不同推理深度与搜索空间下的有效性。

Result: 符号求解器集成方法在搜索空间大但隐式推理浅的任务中表现优异，特别是在需要反复回溯的约束满足问题上显著提升模型性能；在提供声明性示例后，小规模模型如CodeLlama-13B可在复杂逻辑谜题中超越大型模型GPT-4o。

Conclusion: 符号求解器集成是提升复杂推理任务性能的有效策略，尤其适用于搜索空间广阔但推理深度浅的问题；未来应关注如何设计高效的提示模板以引导模型有效利用符号求解能力。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [126] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 本文研究了主动推理中偏好分布的四种定义方式，比较了在网格世界导航任务中不同设定下智能体的性能。结果表明，目标塑造（goal shaping）能显著提升整体表现（促进利用），但会牺牲对环境转移动态的学习（抑制探索）。


<details>
  <summary>Details</summary>
Motivation: 现有研究对如何设定偏好分布及其对主动推理智能体推断与学习的影响关注不足，本文旨在填补这一空白，探讨不同偏好设定对智能体行为的影响。

Method: 设计四类智能体，分别采用硬目标/软目标与是否引入目标塑造（中间目标）的组合，通过网格世界导航任务进行对比实验，评估其性能差异。

Result: 目标塑造的智能体表现最优，说明其更擅长实现目标；但其对环境动态的探索能力较弱，表明过度依赖中间目标可能限制学习广度。

Conclusion: 目标塑造虽能提升目标导向性能，但以牺牲环境探索为代价，提示需在利用与探索之间权衡偏好分布的设计策略。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [127] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 本文提出一种通用的通信约束模型，用于统一表征不同场景下的通信条件，并利用该模型作为学习先验，区分丢失和无损消息。通过解耦丢失与无损消息对分布式决策的影响，引入双互信息估计器，并构建通信约束下的多智能体强化学习框架，将通信消息的影响量化至全局奖励中。在多个通信约束基准上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于通信的多智能体强化学习方法在可扩展性和鲁棒性方面存在局限，难以应用于复杂动态的真实世界环境，尤其面对普遍存在的丢包通信问题时表现不佳。

Method: 提出通用通信约束模型作为学习先验；利用双互信息估计器解耦丢失与无损消息的影响；设计通信约束下的多智能体强化学习框架，将通信影响纳入全局奖励。

Result: 所提方法在多个通信约束基准测试中表现出色，有效提升了多智能体系统在丢包环境下的学习性能与鲁棒性。

Conclusion: 该研究为处理真实世界中复杂的通信约束提供了有效的解决方案，增强了多智能体系统在不理想通信条件下的适应能力与协作效率。

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [128] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule提出一个集成框架，用于零售商品组合与定价优化中的自动化业务规则生成。针对理论模型与现实经济复杂性之间的系统性错配，识别出三大关键挑战：数据模态不匹配、动态特征纠缠以及操作不可行性。框架采用三级架构：首先利用大语言模型（LLMs）进行非结构化文本的深度语义解析，将分销协议和销售评估转化为结构化特征；其次引入博弈论约束优化机制，动态协调供应链利益；最后通过LLM引导的符号回归实现可解释的决策提炼，嵌入经济先验作为硬约束。在真实零售环境中验证，该框架在利润表现上优于系统性基线，同时确保操作可行性，构建了从非结构化知识注入到多智能体优化再到可解释策略合成的闭环流程。


<details>
  <summary>Details</summary>
Motivation: 现有理论模型与实际经济环境存在系统性错配，导致业务规则生成难以应对复杂的现实场景，尤其在数据来源异构、动态特征耦合及多层级约束条件下，传统方法面临效率低、可解释性差和操作不可行等问题。

Method: 提出三层次架构：1）混合知识融合引擎，利用大语言模型对非结构化文本进行深度语义解析，整合管理经验形成结构化特征；2）博弈论约束优化机制，通过双边效用函数建模制造商-分销商利益关系，将利润再分配作为内生目标；3）可解释决策蒸馏接口，结合LLM引导的符号回归，在搜索数学表达式时嵌入经济先验（如非负弹性），生成可审计的定价策略与业务规则。

Result: 在真实零售场景中验证，DeepRule显著提升利润表现，优于现有系统性B2C基线方法，同时满足多层级业务约束，确保操作可行性，实现了从非结构化知识到可解释策略的闭环生成。

Conclusion: DeepRule成功构建了一个统一的自动化业务规则生成框架，打通了非结构化知识注入、多智能体协同优化与可解释策略合成的全链路，为零售领域的经济智能提供了可落地的解决方案。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [129] [MemVerse: Multimodal Memory for Lifelong Learning Agents](https://arxiv.org/abs/2512.03627)
*Junming Liu,Yifei Sun,Weihua Cheng,Haodong Lei,Yirong Chen,Licheng Wen,Xuemeng Yang,Daocheng Fu,Pinlong Cai,Nianchen Deng,Yi Yu,Shuyue Hu,Botian Shi,Ding Wang*

Main category: cs.AI

TL;DR: MemVerse 是一个模型无关、即插即用的记忆框架，结合快速参数化回忆与分层基于检索的记忆，实现可扩展且自适应的多模态智能。它通过短时记忆保留近期上下文，并将原始多模态体验转化为分层知识图谱形式的长期记忆，支持持续整合、自适应遗忘和有限内存增长。为应对实时需求，引入周期性蒸馏机制，将长期记忆中的关键知识压缩到参数模型中，实现快速、可微分的回忆并保持可解释性。实验表明，MemVerse 显著提升多模态推理与持续学习效率，使智能体在长时间交互中具备记忆、适应与连贯推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在多模态与交互环境中缺乏可靠记忆能力，导致灾难性遗忘、长时程推理困难及行为不一致，亟需一种高效、可扩展的记忆机制以支持持续学习与复杂任务执行。

Method: 提出 MemVerse 框架，采用分层知识图谱结构组织长期记忆，结合短时记忆与参数化模型，引入周期性知识蒸馏机制实现记忆压缩与快速召回，支持持续整合与自适应遗忘。

Result: 在多模态推理与持续学习任务中显著优于基线方法，有效提升智能体在长期交互中的记忆保持、适应能力与推理一致性。

Conclusion: MemVerse 为多模态智能体提供了可扩展、自适应且高效的记忆解决方案，推动其在复杂、动态环境中的持续学习与协同推理能力发展。

Abstract: Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.

</details>


### [130] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo提出一种基于多角色协作的LLM系统，通过探索者、利用者、批评者和整合者四类智能体协同工作，提升自动启发式设计（AHD）的多样性和质量。该方法在五种组合优化问题上表现优异，优于现有方法如ReEvo和HSEvo，适用于白盒与黑盒场景。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动启发式设计研究多局限于单一角色，缺乏多视角协同，导致生成的启发式方法多样性与质量受限。为解决此问题，需引入多角色协作机制以增强创新性与有效性。

Method: RoCo采用四类专用智能体——探索者（促进创造性思维）、利用者（聚焦效率改进）、批评者（评估并反馈演化步骤）和整合者（融合创新与利用）——通过多轮交互、反馈、精炼及精英突变，在短期与长期反思指导下协同生成高质量启发式策略。

Result: RoCo在五个不同组合优化问题上均表现出优越性能，无论是白盒还是黑盒设置下，生成的启发式均显著优于ReEvo、HSEvo等现有方法，验证了其鲁棒性与高效性。

Conclusion: 基于多角色协作的框架为自动启发式设计提供了新范式，推动AHD向更高性能与更强适应性发展，确立了新的技术标准。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [131] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: 提出Omni-AutoThink框架，通过自适应监督微调和自适应强化学习，动态调整模型推理深度以应对不同任务难度，构建多模态自适应推理基准，实验表明性能显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在多模态感知与生成中表现优异，但存在推理行为僵化问题，如对简单问题过度思考或对复杂问题无法有效推理，亟需一种能根据任务难度自适应调整推理深度的机制。

Method: 提出两阶段框架：(1) 自适应监督微调（Adaptive SFT），利用大规模增强推理数据赋予模型基础推理能力；(2) 自适应强化学习（Adaptive GRPO），基于任务复杂度和奖励反馈优化推理行为。同时构建涵盖文本、文本-音频、文本-视觉及文本-音频-视觉的多模态自适应推理基准。

Result: 实验结果表明，所提框架在多模态自适应推理任务上显著优于现有基线方法，能够更有效地根据任务难度动态调节推理深度。

Conclusion: Omni-AutoThink框架有效提升了多模态模型的自适应推理能力，为实现更智能、灵活的统一多模态系统提供了新路径。所有数据与代码将公开发布。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [132] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 本文提出一个针对工业自动化中灵活控制策略的基准测试，基于可执行模拟环境的积木世界问题，涵盖五个复杂度等级。通过引入标准化的模型上下文协议（MCP）作为工具接口，使不同架构的智能体可无缝接入并评估，验证了该基准在量化比较LLM-based规划与执行方法上的有效性。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要能够适应变化任务和环境的灵活控制策略，而基于大语言模型（LLM）的智能体虽具潜力，但缺乏标准化的评估基准，难以进行系统性比较。

Method: 构建一个基于积木世界问题的可执行仿真环境，设计五种复杂度等级的任务；采用模型上下文协议（MCP）作为统一接口，实现不同智能体架构的无修改接入与评估。

Result: 单智能体实现成功验证了基准的适用性，提供了可用于量化比较各类基于LLM的规划与执行方法的指标。

Conclusion: 该基准为评估和比较LLM驱动的智能体在动态工业场景中的灵活性与适应性提供了标准化、可扩展的平台，推动了智能控制系统的可比性研究。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [133] [Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling](https://arxiv.org/abs/2512.03050)
*Peter Hedström,Victor Lamelas Cubero,Jón Sigurdsson,Viktor Österberg,Satish Kolli,Joakim Odqvist,Ziyong Hou,Wangzhong Mu,Viswanadh Gowtham Arigela*

Main category: cs.LG

TL;DR: 本文提出了一种结合物理知识与机器学习的新型计算框架，用于建立适用于钢材料的物性信息连续冷却转变（CCT）模型。该模型基于4100个CCT图谱数据训练，可在5秒内生成包含100条冷却曲线的完整CCT图，具备高效性和强泛化能力，在相分类任务中F1分数超过88%，相变温度回归的平均绝对误差（MAE）低于20°C（贝氏体除外，为27°C）。该框架可扩展为通用数字孪生平台，支持加速材料设计流程。


<details>
  <summary>Details</summary>
Motivation: 在工业材料如钢的应用中，传统通用机器学习框架难以准确捕捉化学成分、加工参数与微观结构及性能之间的复杂关系，亟需融合物理机制与数据驱动的方法以提升建模精度与适用性。

Method: 结合物理先验知识与机器学习，构建物理信息引导的连续冷却转变（CCT）模型；利用大规模第一性原理和实验数据训练模型，并通过文献与实验数据验证其性能。

Result: 模型生成完整CCT图仅需不到5秒，具有高计算效率；在多种合金钢中表现出优异的泛化能力，相分类F1分数高于88%，相变温度预测的平均绝对误差低于20°C（除贝氏体外），具备良好的实用性与扩展潜力。

Conclusion: 所提出的物理信息机器学习框架可有效解决复杂工业材料中多变量耦合建模难题，为实现热处理过程的数字孪生与材料快速设计提供了可行路径，未来可通过集成模拟工具与实验进一步优化。

Abstract: Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.

</details>


### [134] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 本文提出一种面向绿色AI的自适应层冻结策略，以降低联邦学习（FL）在医疗影像（MRI转CT）中的能耗与计算负担。通过监测编码器权重的相对变化并结合耐心机制，选择性冻结权重，在保持模型性能的同时，使训练时间、总能耗和CO2eq排放量最多减少23%。实验表明，多数架构下性能无显著差异，部分甚至有提升，支持了可持续、公平的AI医疗发展。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽能促进医疗领域的数据协作与模型共享，但其高资源需求常使计算能力有限的医疗机构难以参与，加剧医疗不平等。因此亟需一种节能高效的联邦学习方法，以实现技术普惠与环境可持续性的平衡。

Method: 提出一种自适应层冻结策略：基于编码器权重在各轮次间的相对变化进行监控，仅当更新持续微小（通过耐心机制判定）时才冻结权重，从而减少冗余计算；同时利用CodeCarbon库追踪能源消耗与碳排放。

Result: 与非冻结方法相比，该策略将训练时间、总能耗及CO2eq排放最多降低23%，且在大多数模型架构中维持了相近的MRI-to-CT转换性能（如MAE变化极小），其中三组架构无统计显著差异，两组甚至出现显著性能提升。

Conclusion: 本研究为实现绿色、公平、可扩展的联邦学习提供了可行路径，推动了可持续医疗AI的发展，并为未来构建兼顾隐私、公平与环境责任的联邦学习评估框架奠定基础。

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [135] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling (DS) 是一种在不同架构的扩散模型之间实现知识迁移的新方法，无需访问原始训练数据。它在推理阶段通过利用适配前后模型预测的差异（即 delta）来指导新基模型的去噪过程，从而实现跨版本扩散模型（如从 SD 1.x 到 2.x）的适应组件复用。该方法具有良好的泛化能力，在多种采样策略下均能有效提升视觉风格、语义概念和结构控制的效果，是一种即插即用的知识迁移机制。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效适配方法（如 LoRA、ControlNet）与特定基模型紧密耦合，当基模型升级时难以复用，因模型架构和参数变化大。亟需一种不依赖原始数据、可在不同基模型间迁移知识的方法。

Method: 提出 Delta Sampling (DS)，在推理阶段利用适配前后基模型输出的预测差异（delta），将该 delta 作为引导信号注入到新基模型的去噪过程中，以实现知识迁移。

Result: 在多个 Stable Diffusion 版本间测试表明，DS 能稳定提升图像生成效果，包括视觉风格、语义概念和结构控制，且适用于不同采样策略，表现出强鲁棒性和可迁移性。

Conclusion: Delta Sampling 成功实现了跨架构扩散模型间的知识迁移，无需访问训练数据，具备良好的通用性和实用性，是扩散模型生态中适配组件复用的有效解决方案。

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [136] [Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding](https://arxiv.org/abs/2512.03058)
*Duy-Tung Pham,An The Nguyen,Viet-Hoang Tran,Nhan-Phu Chung,Xin T. Tong,Tan M. Nguyen,Thieu N. Vo*

Main category: cs.LG

TL;DR: 本文研究预训练Transformer模型中token的动力学特性，并探索其在改进Transformer模型中的应用。通过分析预训练模型连续时间极限下的动力系统，刻画了解的渐近行为，明确了在不同模型参数下token随时间相互靠近或远离的条件。文章给出了充分条件，以识别模型参数下token收敛至零或发散至无穷的场景，这些条件比以往工作更广泛且更具实际适用性。此外，研究了绝对位置编码与旋转位置编码对这些动力学模式的影响。实证结果表明，收敛场景会损害模型性能。基于此，作者提出了针对使用绝对或旋转位置编码的Transformer架构的简单改进方法，以缓解收敛现象。研究成果为改进Transformer模型提供了理论基础和设计原则。


<details>
  <summary>Details</summary>
Motivation: 现有研究对Transformer模型中token动态行为的理解有限，尤其缺乏对模型参数如何影响token间距离变化的系统分析。此外，不同位置编码方式对模型动态的影响尚不清晰，且已有方法在实际模型中的适用性受限。因此，亟需建立更普适的理论框架来揭示token动态特性，并指导模型优化。

Method: 通过构建预训练Transformer模型的连续时间极限动力系统，分析其微分方程解的渐近行为；利用数学分析推导出决定token是否收敛或发散的充分条件；对比绝对位置编码与旋转位置编码在不同设置下的动态表现；结合实验验证理论预测并提出改进方案。

Result: 1. 成功刻画了token在不同模型参数下的运动趋势（趋近或远离）；2. 提出了适用于真实模型的更广泛收敛/发散条件；3. 发现收敛行为显著降低模型性能；4. 通过简单架构调整有效缓解了收敛问题，提升模型表现。

Conclusion: 该研究揭示了Transformer中token动力学的关键机制，提出了一套可推广的理论分析框架。基于此，提出的改进方法能有效抑制不利的收敛行为，为设计更稳定、高效的Transformer模型提供了重要依据。

Abstract: This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.

</details>


### [137] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文提出一种安全的分层深度强化学习（HDRL）框架，用于解决在多重不确定性下的电动公交充电调度问题（EBCSP）。通过将问题建模为带有选项的约束马尔可夫决策过程（CMDP），设计了新型的双演员-评论家多智能体近端策略优化拉格朗日算法（DAC-MAPPO-Lagrangian）。高层采用集中式PPO-Lagrangian学习安全充电分配策略，低层基于CTDE范式使用MAPPO-Lagrangian实现去中心化的充电功率决策。实验结果表明，该方法在成本最小化和安全合规性方面均优于现有基线，且收敛速度快。


<details>
  <summary>Details</summary>
Motivation: 电动公交车与可再生能源（如光伏）的集成有助于推动可持续低碳公共交通。然而，在实际条件下，光伏发电量、电价波动、行程时间变化及充电设施有限等因素带来的不确定性，使得优化充电调度以降低成本并确保电池不耗尽极具挑战性。因此，亟需一种能够应对多源不确定性的高效、安全充电调度方法。

Method: 将问题建模为带有选项的约束马尔可夫决策过程（CMDP），提出一种新的分层深度强化学习算法DAC-MAPPO-Lagrangian。该算法结合拉格朗日松弛技术与双演员-评论家框架，在高层采用集中式训练的PPO-Lagrangian进行充电资源分配，在底层采用多智能体近端策略优化（MAPPO）实现去中心化充电功率控制，遵循中央训练、分散执行（CTDE）原则。

Result: 基于真实世界数据的大量实验表明，所提方法在降低运营成本、保证电池安全运行方面显著优于现有基准方法，同时具备快速收敛能力，验证了其有效性与实用性。

Conclusion: 本文提出的分层深度强化学习框架有效应对了电动公交充电调度中的多源不确定性问题，实现了成本最小化与安全操作的双重目标，具有良好的应用前景。

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [138] [A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap](https://arxiv.org/abs/2512.03060)
*Jing Pan,Li Shi,Paul Lo*

Main category: cs.LG

TL;DR: 本文提出了一套大规模工业级框架，用于基于数亿用户实验数据估计异质性处理效应（HTE）和条件平均处理效应（CATE），通过整合多个实验结果，揭示了此前无法测量的潜在用户特征，并实现了可扩展的稳定处理效应估计。核心组件包括实验选择、基础学习器设计与增量训练。应用案例显示，基于用户对广告影响性的评分进行定向投放，在线A/B测试中关键业务指标提升超过通常显著水平的六倍。


<details>
  <summary>Details</summary>
Motivation: 传统处理效应模型假设所有用户具有相同的处理效果，但现实中用户对干预的反应存在差异。在大规模平台如Snapchat上，需要更精细的个性化评估机制以提升策略有效性。因此，亟需一种能够从海量实验数据中挖掘用户异质性响应的系统方法。

Method: 提出一个大规模工业框架，融合多实验数据，采用实验选择策略、可扩展的基础学习器设计以及支持增量训练的算法架构，实现对用户潜在特征的建模与处理效应的精准估计。

Result: 该框架成功识别出不可观测的用户特征，显著提升了处理效应估计的稳定性与准确性；在线实验表明，基于用户广告影响性评分的定向投放使关键业务指标提升超过常规显著水平的六倍。

Conclusion: 所提出的框架有效解决了大规模场景下异质性处理效应估计的挑战，为个性化决策提供了强有力的技术支撑，具备显著的商业价值与可推广性。

Abstract: Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.
  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.

</details>


### [139] [Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing](https://arxiv.org/abs/2512.03062)
*Roman Rausch,David Jansen,Sukhbinder Singh,Román Orús*

Main category: cs.LG

TL;DR: 本文提出两种受物理学启发的方法以改进基于SVD的大型语言模型（LLM）压缩：(1) FermiGrad，一种通过使用费米函数将离散的奇异值截断连续化，从而实现全局最优层间秩选择的梯度下降算法；(2) PivGa，一种利用低秩因子参数化中固有的规范自由度进行额外的无损压缩。


<details>
  <summary>Details</summary>
Motivation: LLM的计算资源需求高，虽然低秩分解（如SVD）是有效的压缩方法，但面临层间秩选择困难和参数冗余等问题。

Method: 采用费米函数将奇异值截断连续化，实现层间秩的优化；利用参数化的规范自由度进行无损压缩。

Result: FermiGrad实现了更优的层间秩选择，而PivGa在不损失信息的前提下进一步压缩了低秩因子，整体提升了压缩效率与模型性能。

Conclusion: 提出的FermiGrad与PivGa方法有效解决了低秩压缩中的关键挑战，显著提升压缩效果并保持模型性能，为高效部署大模型提供了新思路。

Abstract: Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \textbf{PivGa}, an additional \textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.

</details>


### [140] [Hierarchical clustering of complex energy systems using pretopology](https://arxiv.org/abs/2512.03069)
*Loup-Noe Levy,Jeremie Bosom,Guillaume Guerard,Soufian Ben Amor,Marc Bui,Hai Tran*

Main category: cs.LG

TL;DR: 本文提出一种基于预拓扑的自动化方法，用于建模和分类大规模分布式区域内的建筑能耗曲线，以优化能耗管理。通过构建预拓扑空间并设计多准则分层分类算法，在真实和生成数据集上验证了其有效性，尤其在识别点聚类和时间序列聚类方面表现优异，如在生成时间序列数据上达到1的调整兰德指数（ARI）.


<details>
  <summary>Details</summary>
Motivation: 对成千上万栋建筑进行逐个深入审计耗时耗力且成本高昂，亟需一种自动化方法来建立有效的能耗优化建议系统。

Method: 采用预拓扑建模能耗曲线，并开发基于预拓扑空间性质的多准则分层分类算法，实现自动化分类。

Result: 在点数据集上成功识别了基于位置和大小的聚类；在生成时间序列数据上，使用皮尔逊相关性分析，获得1的调整兰德指数（ARI），表明分类效果极佳。

Conclusion: 所提出的预拓扑方法能够有效建模复杂能耗模式，为大规模建筑能耗管理提供高效、准确的分类工具，具备实际应用潜力。

Abstract: This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?
  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.
  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.
  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.
  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.

</details>


### [141] [Mixed Data Clustering Survey and Challenges](https://arxiv.org/abs/2512.03070)
*Guillaume Guerard,Sonia Djebali*

Main category: cs.LG

TL;DR: 本文提出了一种基于预拓扑空间的混合数据聚类方法，旨在应对大数据背景下异构数据（如数值型与类别型变量）带来的挑战。该方法结合层次化与可解释性优势，通过与经典数值聚类算法及现有预拓扑方法对比，验证了其在处理复杂混合数据时的有效性与性能优越性。


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法多针对同质数据设计，难以有效处理混合数据中的复杂性，尤其在大数据环境下，亟需具备可解释性和层次结构的新型聚类方法以支持决策。

Method: 提出基于预拓扑空间的聚类方法，利用其对异构数据的表达能力，并结合层次化结构实现可解释的聚类结果。

Result: 实验表明，所提方法在混合数据聚类任务中优于传统数值聚类算法和现有预拓扑方法，在准确性和可解释性方面表现更优。

Conclusion: 基于预拓扑空间的聚类方法为混合数据提供了有效的解决方案，具有良好的适应性与解释性，适用于大数据环境下的复杂数据分析需求。

Abstract: The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.

</details>


### [142] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 本文提出一种基于预拓扑的新型算法，用于处理混合数据聚类问题，无需降维。通过析取范式构建可定制逻辑规则和可调超参数，支持用户定义的层次聚类结构，能直接从原始数据中准确、可解释地划分出聚类，保持数据完整性。实验结果表明该方法在聚类性能和可解释性方面表现优异，突破了传统降维方法的局限，创新性地利用逻辑规则提升聚类形成与清晰度，推动了混合数据聚类研究的发展。


<details>
  <summary>Details</summary>
Motivation: 现有聚类方法在处理混合数据时通常依赖降维技术，导致信息丢失和可解释性下降。亟需一种无需降维、能保留原始数据结构并提供可解释聚类结果的新方法。

Method: 基于预拓扑理论，结合析取范式（DNF）构建可定制的逻辑规则，并引入可调超参数实现用户主导的层次聚类构造，直接在原始数据上进行聚类分析。

Result: 实验验证了该方法在多种混合数据集上的优越性能，不仅提升了聚类准确率，还增强了聚类结果的可解释性，且在保持数据完整性的前提下实现了高效的层次结构生成。

Conclusion: 本研究提出的方法摆脱了传统降维依赖，通过逻辑规则驱动的层次聚类机制，在不损失数据信息的前提下实现了高质量、可解释的聚类结果，为混合数据聚类提供了新范式。

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [143] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 本文研究了在流匹配（Flow Matching, FM）中使用倾斜（entropic）风险的方法，通过应用对数指数变换到基础损失，强调罕见或高损失事件，同时保持优化问题的可处理性。标准的矩形化FM使用均方误差损失，会将所有到达相同时空点的速度目标合并为单一条件均值，从而忽略高阶条件信息（如方差、偏度、多模态），这些信息对数据流形和少数分支的几何结构至关重要。本文将风险敏感的对数指数变换应用于条件FM损失，证明其结果是一个有意义的条件熵FM目标的自然上界。进一步地，该条件熵目标梯度的小阶展开揭示了两个可解释的一阶修正项：协方差预处理的FM残差和偏向非对称或稀有分支的偏尾项。在设计用于探测模糊性和尾部行为的合成数据上，所提出的风险敏感损失在统计指标和几何结构恢复方面优于标准矩形化FM。


<details>
  <summary>Details</summary>
Motivation: 标准矩形化流匹配（FM）中的均方误差损失会忽略高阶条件信息（如方差、偏度、多模态），导致无法充分捕捉数据流形的精细几何结构和少数分支。因此，需要一种能够强调罕见或高损失事件并保留优化可处理性的方法，以提升模型对复杂数据结构的建模能力。

Method: 应用对数指数变换（即风险敏感变换）于条件FM损失，构造倾斜风险损失；分析其作为条件熵目标的上界性质；通过小阶展开推导出梯度中的两个可解释修正项：协方差预处理的FM残差和偏向非对称/稀有分支的偏尾项。

Result: 在合成数据实验中，风险敏感损失显著改善了统计性能，并更准确地恢复了数据的几何结构，尤其在存在模糊性和长尾分布的情况下表现优于标准矩形化FM。

Conclusion: 倾斜风险在流匹配中提供了一种有效机制，用于捕捉数据流形的高阶结构信息，通过引入协方差预处理和对稀有分支的偏好，提升了模型对复杂数据分布的建模能力。该方法兼具理论合理性与实际有效性。

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [144] [ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification](https://arxiv.org/abs/2512.03101)
*Congjing Zhang,Feng Lin,Xinyi Zhao,Pei Guo,Wei Li,Lin Chen,Chaoyue Zhao,Shuai Huang*

Main category: cs.LG

TL;DR: ALARM 是一个基于大语言模型（LLM）的多模态视觉异常检测框架，通过整合不确定性量化（UQ）与推理链、自省和集成学习等质量保障技术，实现鲁棒且准确的异常检测。该框架基于严格的概率推断流程，在真实世界智能家居和伤口图像分类数据集上表现出优越性能，具备跨领域的通用性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，视觉异常往往具有高度上下文依赖性和模糊性，因此需要对预测结果进行不确定性量化（UQ），以提升多模态大语言模型（MLLM）在视觉异常检测中的可靠性与可解释性。

Method: ALARM 框架融合不确定性量化（UQ）与多种质量保障机制，包括推理链、自反思策略和多模态大语言模型集成，构建了一个基于概率推断的计算流程，以增强模型的鲁棒性和决策可信度。

Result: 在智能家居和伤口图像分类的真实数据集上，ALARM 显著优于现有方法，在多个评估指标上表现更优，展现出良好的跨领域泛化能力与可靠决策支持能力。

Conclusion: ALARM 证明了不确定性量化在多模态大语言模型驱动的视觉异常检测中至关重要，其结合高质量推理机制的设计为复杂环境下的智能感知系统提供了可信赖的解决方案。

Abstract: The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.

</details>


### [145] [Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%](https://arxiv.org/abs/2512.03107)
*Mainak Singha*

Main category: cs.LG

TL;DR: ECLIPSE is a framework that detects hallucinations in large language models by measuring the mismatch between semantic entropy and evidence capacity, using multi-sample clustering and perplexity decomposition. It achieves high performance on a financial QA dataset (AUC 0.89, precision 0.90), outperforming baselines. Results show that calibrated token-level uncertainties are crucial for effectiveness, and evidence utilization is key to detection.


<details>
  <summary>Details</summary>
Motivation: Large language models often generate fluent but factually incorrect responses (hallucinations), which hinders their safe use in critical applications. Existing methods lack a principled way to detect such errors, especially when evidence is available.

Method: ECLIPSE estimates semantic entropy via multi-sample clustering and introduces a novel perplexity decomposition to assess how models utilize retrieved evidence. The method optimizes an entropy-capacity objective proven to be strictly convex with a unique stable optimum.

Result: On a controlled financial QA dataset with synthetic hallucinations, ECLIPSE achieved ROC AUC of 0.89 and average precision of 0.90, significantly outperforming a semantic entropy-only baseline (AUC 0.50). Ablation with Claude-3-Haiku showed reduced performance (AUC 0.59) and 95% drop in coefficient magnitudes, indicating dependence on logprob calibration. Perplexity decomposition features had the highest learned coefficients, confirming their importance in detecting hallucinations.

Conclusion: ECLIPSE provides a principled, convex mechanism for hallucination detection grounded in evidence utilization and calibrated uncertainty. While validated in a controlled setting, broader validation across domains and real-world hallucinations is needed.

Abstract: Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.

</details>


### [146] [Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability](https://arxiv.org/abs/2512.03112)
*Jialai She*

Main category: cs.LG

TL;DR: 提出SISR框架，通过非线性变换恢复可加性并引入L0稀疏约束，解决Shapley值在非线性、高维场景下的偏差与计算成本问题。结合池相邻违规算法与归一化硬阈值，实现高效全局收敛，显著提升解释稳定性与准确性。


<details>
  <summary>Details</summary>
Motivation: 传统Shapley值假设收益函数为可加性，但实际中非高斯分布、特征依赖、重尾等常导致该假设失效，造成解释扭曲；同时，高维下通过密集Shapley值再阈值化难以实现稀疏解释，计算成本高且不一致。

Method: SISR联合学习单调变换以恢复可加性，并施加L0稀疏约束于Shapley向量；采用池相邻违规算法进行等序回归，配合归一化硬阈值选择支持集，保障优化效率与全局收敛。

Result: SISR在多种场景下能准确恢复真实变换，具备强支持恢复能力，即使在高噪声下表现稳健；实验表明其在回归、逻辑回归与树模型中稳定了不同收益方案下的归因结果，有效剔除无关特征，而标准Shapley值存在显著秩与符号偏差。

Conclusion: SISR统一了非线性变换估计与稀疏性追求，为非线性可解释性提供了理论坚实且实用的归因框架，推动了可解释人工智能的前沿发展。

Abstract: Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.

</details>


### [147] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: 本文提出Modality-Decoupled Experts (MoDE)架构，以解决统一多模态生成模型（UMGMs）在持续学习中面临的灾难性遗忘问题，包括模态内（intra-modal）和跨模态（inter-modal）遗忘。通过解耦各模态的更新并引入知识蒸馏，有效缓解了不同模态间的梯度冲突，显著提升模型在多任务场景下的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态生成模型在持续学习过程中面临严重的灾难性遗忘，尤其是跨模态遗忘尚未被充分研究。传统方法因模态耦合导致梯度冲突，难以有效保留预训练知识。因此亟需一种能解耦模态、避免干扰的新机制。

Method: 提出模态解耦专家（MoDE）架构，通过将各模态的参数更新独立处理，减少模态间梯度冲突；同时结合知识蒸馏策略，保留原始模型的知识与性能。该方法轻量且可扩展，适用于多种多模态生成任务。

Result: 在多个基准测试上，MoDE显著减轻了模态内与跨模态的遗忘现象，优于现有的持续学习基线方法，在统一多模态生成设置下展现出更强的泛化与适应能力。

Conclusion: MoDE通过显式解耦模态更新和引入知识蒸馏，成功缓解了多模态生成模型中的梯度冲突与灾难性遗忘问题，为构建具备持续学习能力的统一多模态系统提供了有效解决方案。

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [148] [Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra](https://arxiv.org/abs/2512.03127)
*Ziyu Xiong,Yichi Zhang,Foyez Alauddin,Chu Xin Cheng,Joon Soo An,Mohammad R. Seyedsayamdost,Ellen D. Zhong*

Main category: cs.LG

TL;DR: ChefNMR 是一个端到端的框架，能够仅从 1D NMR 谱和化学式直接预测未知分子的结构。它基于非等变变换器架构的原子扩散模型，通过模拟超过 11.1 万种天然产物的 1D NMR 谱数据，实现了对复杂天然产物结构的高精度预测（准确率超 65%），显著推进了小分子结构解析的自动化进程，展示了深度学习在加速分子发现中的潜力。


<details>
  <summary>Details</summary>
Motivation: NMR 谱解析目前仍依赖人工、耗时且需要大量专业知识，亟需自动化方法以加速小分子结构鉴定，尤其是在天然产物和药物发现领域。

Method: 采用基于非等变变换器架构的原子扩散模型，将结构解析建模为条件生成任务，并利用大规模模拟的天然产物 1D NMR 数据集进行训练。

Result: ChefNMR 在挑战性天然产物结构预测上达到超过 65% 的准确率，是当前最先进水平。

Conclusion: 该研究实现了小分子结构自动解析的重大进展，表明深度学习在加速分子发现方面具有巨大潜力。

Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.

</details>


### [149] [Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing](https://arxiv.org/abs/2512.03158)
*Adele Chinda,Richmond Azumah,Hemanth Demakethepalli Venkateswara*

Main category: cs.LG

TL;DR: 提出了一种基于VQ-VAE的无监督病毒变异检测框架，用于处理废水基因组监测中的高噪声、低覆盖度等挑战。该方法通过k-mer分词和掩码重建预训练提升对缺失数据的鲁棒性，并结合对比学习生成具有强区分能力的嵌入表示。在约10万条SARS-CoV-2废水测序数据上，实现99.52%的令牌级准确率和56.33%的序列完全匹配率，代码本利用率仅19.73%，表明其高效离散表征学习能力。对比微调显示，64维与128维嵌入分别带来+35%和+42%的轮廓系数提升，验证了嵌入维度对变异区分的重要性。该方法无需参考基因组或标注数据，具备可扩展性和可解释性，适用于公共卫生监测。


<details>
  <summary>Details</summary>
Motivation: 传统基于参考的变异检测方法在面对新突变时表现不佳，且计算资源消耗大；废水测序数据普遍存在高噪声、低覆盖度、读段碎片化及缺乏标签的问题，亟需一种无需参考基因组和标注信息的高效、鲁棒的无监督分析框架。

Method: 采用向量量化变分自编码器（VQ-VAE）架构，将基因组序列转化为k-mer token，并通过掩码重建预训练增强对缺失数据的鲁棒性，结合对比学习优化嵌入空间以提升变异间的区分能力。整个流程不依赖参考基因组或变异标签，实现无监督的病毒变异检测。

Result: 在约10万条SARS-CoV-2废水测序数据上，模型达到99.52%的平均令牌级准确率和56.33%的精确序列匹配率，代码本利用率为19.73%（101/512个代码活跃），表明其高效的离散表示学习能力；对比学习微调后，64维和128维嵌入分别使轮廓系数提升35%和42%，显著改善聚类效果。

Conclusion: 所提出的无参考、无标签的VQ-VAE框架为废水基因组监测提供了可扩展、可解释的病毒变异检测新路径，有效应对高噪声与低覆盖数据挑战，在公共健康监控中具有重要应用前景。

Abstract: Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.

</details>


### [150] [Plantain: Plan-Answer Interleaved Reasoning](https://arxiv.org/abs/2512.03176)
*Anthony Liang,Jonathan Berant,Adam Fisch,Abhimanyu Goyal,Kalpesh Krishna,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 本文提出了一种名为"交错推理"（Interleaved Reasoning, IR）的新方法，让语言模型在推理过程中交替进行思考与输出中间结果，以减少用户等待初始响应的时间。特别地，引入了"Plantain"（计划-思考-回答交错）策略，先输出任务的详细步骤计划，使用户能尽早干预和反馈。实验表明，该方法在多个数学推理和编程基准测试中提升了约6%的准确率（pass@1），同时将首次响应时间减少超过60%。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在生成可见回复前会花费大量时间进行内部推理，但不向用户提供任何进展提示，导致用户无法及时纠正错误前提，造成体验不佳且浪费时间。人类对话中常通过轻量级的即时确认行为确保沟通同步，因此作者希望探索语言模型是否也能学习这种行为。

Method: 提出交错推理（IR）框架，允许模型在推理过程中间断性地输出中间结果；进一步设计Plantain方法，要求首个中间输出为任务的逐步计划，从而支持早期用户干预与反馈。

Result: Plantain在多个挑战性的数学推理和编程基准上实现了约6%的pass@1性能提升，同时将首次响应时间减少了60%以上，显著改善用户体验而不牺牲最终输出质量。

Conclusion: 通过引入交错推理，特别是计划先行的Plantain策略，语言模型能够在保持高质量输出的同时大幅降低用户感知延迟，并支持更灵活的人机交互，为构建更具交互性和透明度的推理系统提供了有效路径。

Abstract: Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard "think-then-answer" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.

</details>


### [151] [Neighborhood density estimation using space-partitioning based hashing schemes](https://arxiv.org/abs/2512.03187)
*Aashi Jindal*

Main category: cs.LG

TL;DR: FiRE/FiRE.1 是一种基于草图的异常检测算法，用于快速识别大规模单细胞RNA测序数据中的稀有细胞亚群；Enhash是一种利用投影哈希的快速、资源高效集成学习器，可有效检测流数据中的概念漂移，在多种漂移类型下表现出色。


<details>
  <summary>Details</summary>
Motivation: 在大规模单细胞RNA测序数据中快速识别稀有细胞亚群存在挑战，同时流数据中的概念漂移检测需要高效且准确的方法。

Method: 采用草图技术进行数据压缩与快速分析，结合投影哈希实现高效的集成学习，以支持实时异常检测和概念漂移识别。

Result: FiRE/FiRE.1 在异常检测任务中表现优于现有技术；Enhash 在时间效率和准确性方面均具有竞争力，适用于多种概念漂移场景。

Conclusion: 所提出的FiRE/FiRE.1和Enhash为单细胞数据分析和流数据监测提供了高效、精准的解决方案，具有广泛的应用前景。

Abstract: This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.

</details>


### [152] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 本文提出几种改进的算法，用于在无限时域设置下学习带有记忆的策略，适用于已知环境模型的情况及通过模拟的情况，并在大型部分可观测马尔可夫决策过程（POMDP）问题上进行比较，包括噪声机器人导航和多智能体问题。


<details>
  <summary>Details</summary>
Motivation: 尽管策略梯度方法在无记忆策略的问题中表现良好，但在需要记忆的场景中效果较差，因此需要改进算法以有效处理带记忆的策略学习。

Method: 开发了多种改进的算法，直接利用已知环境模型或通过仿真来学习带有记忆的策略。

Result: 所提出的算法在大型POMDP问题上表现出色，包括噪声机器人导航和多智能体问题。

Conclusion: 该研究为在部分可观测环境中学习带记忆的策略提供了有效的解决方案，尤其在复杂且需要长期记忆的任务中具有显著优势。

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [153] [A Multi-Agent, Policy-Gradient approach to Network Routing](https://arxiv.org/abs/2512.03211)
*Nigel Tao,Jonathan Baxter,Lex Weaver*

Main category: cs.LG

TL;DR: OLPOMDP, a policy-gradient reinforcement learning algorithm, enables distributed routers to learn cooperative routing behaviors without direct communication, improving network performance by avoiding individually beneficial but collectively harmful actions. Reward shaping significantly accelerates convergence.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of decentralized network routing where individual agents (routers) must coordinate implicitly to achieve optimal global performance, especially in scenarios where local optimization leads to system-wide inefficiency.

Method: OLPOMDP, a policy-gradient reinforcement learning approach, is applied to simulated network routing environments with multiple distributed agents. Agents learn policies through trial and error, guided by reward signals that can be shaped to penalize sub-optimal behaviors.

Result: Agents successfully learned cooperative routing strategies without explicit communication. Shaping the reward signal to penalize undesirable patterns led to faster convergence and improved overall network performance.

Conclusion: OLPOMDP effectively supports distributed, cooperative decision-making in network routing, demonstrating that reward shaping enhances learning efficiency and system-level performance in multi-agent environments.

Abstract: Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.

</details>


### [154] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0, a supervised bioacoustics foundation model trained on 14,597 species, shows strong performance in few-shot transfer learning for marine mammal and underwater audio tasks despite lacking marine mammal data in training. It outperforms several existing models like Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 in linear probing setups, making it ideal for developing new classifiers with limited labeled data.


<details>
  <summary>Details</summary>
Motivation: To evaluate the generalization capability of Perch 2.0, a bioacoustics foundation model trained primarily on terrestrial species, in marine mammal and underwater audio classification tasks where it has no direct training data, using few-shot transfer learning.

Method: Linear probing on embeddings generated by Perch 2.0 from underwater audio data, compared against multiple other pretrained bioacoustics models with open-source transfer-learning support.

Result: Perch 2.0 embeddings consistently achieve high performance across various marine mammal and underwater audio tasks, outperforming all compared models in most cases.

Conclusion: Perch 2.0 is highly effective for few-shot marine mammal classification and is recommended for use in developing new linear classifiers when labeled examples are scarce.

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [155] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: 本文提出SPARK框架，通过三阶段方法实现无需参考答案的强化学习训练。第一阶段利用生成模型和验证模型进行并行与串行规模扩展，生成多样解法并评估；第二阶段用验证结果作为合成数据微调生成式过程奖励模型（PRM）；第三阶段将PRM-CoT用于数学推理的强化学习，引入格式约束防止奖励黑客。实验显示该方法在ProcessBench上达到67.5 F1，优于参考引导（66.4）和GPT-4o（61.9），并在多个数学推理基准上实现47.4%平均准确率，超过基于真值的RLVR（43.9%）。


<details>
  <summary>Details</summary>
Motivation: 当前过程奖励模型（PRMs）受限于昂贵的逐步标注或真实参考答案，难以广泛应用。尤其在缺乏可验证答案或真值信息的领域，现有方法难以适用。因此亟需一种无需依赖外部参考、能自动生成高质量监督信号的方法，以推动强化学习在复杂推理任务中的应用。

Method: 提出SPARK三阶段框架：第一阶段使用生成模型产生多样化解法，验证模型通过自一致性（并行）和元批评（串行）进行多轮评估；第二阶段将验证输出作为合成训练数据，微调生成式过程奖励模型；第三阶段将训练好的PRM-CoT作为强化学习中的奖励模型，并加入格式约束防止奖励黑客行为。

Result: SPARK在ProcessBench上取得67.5 F1，优于参考引导训练（66.4）和GPT-4o（61.9）；在六项数学推理基准上，使用Qwen2.5-Math-7B实现47.4%平均准确率，超越基于真值的RLVR（43.9%）。证明了无参考强化学习的有效性，且性能优于依赖真值的方法。

Conclusion: SPARK实现了无需参考答案的强化学习训练，显著提升过程奖励模型性能，突破了传统依赖真值的限制，为缺乏可验证答案的领域提供了新范式，具有广泛的应用前景。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [156] [Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval](https://arxiv.org/abs/2512.03276)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.LG

TL;DR: 该研究探讨了视觉语言模型（VLMs）在事实回忆任务中表现下降的原因，发现多数VLMs因未能及时形成实体表示而无法有效利用预训练语言模型（LLM）中的现有事实回忆机制。通过对比14个不同架构和规模的VLMs，研究指出性能较差的模型在计算过程中过晚解决第一跳（即从视觉输入形成实体表示），导致无法复用LLM原有的知识召回路径。相反，高性能模型能尽早完成实体表示，从而有效继承LLM的机制。研究进一步提出两种恢复性能的方法：将LLM中的实体表示引入VLM，以及采用链式思维提示。结果强调了早期实体解析速度对多模态模型有效性的关键作用，并展示了机制分析在揭示多模态对齐系统性失败中的价值。


<details>
  <summary>Details</summary>
Motivation: 许多视觉语言模型在事实回忆任务中表现不如其对应的大型语言模型（LLM）骨干模型，这表明当前的多模态微调可能未能有效扩展LLM中已有的知识召回机制。因此，需要理解为何以及如何这种能力在视觉输入下失效。

Method: 通过基准测试14种不同架构、大小和训练设置的VLMs，在事实回忆任务上与原始LLM进行对比；使用归因修补、激活修补和探测技术分析模型内部机制；选取高/低性能模型进行深入比较，以揭示性能差异背后的计算过程差异。

Result: 11/14的VLMs在事实回忆任务中表现出性能下降；性能差的模型在计算流程中过晚形成实体表示，导致无法利用LLM的已有知识召回电路；而高性能模型能在早期形成实体表示，从而复用原有机制；通过引入LLM的实体表示或使用链式思维提示可显著恢复性能。

Conclusion: 视觉语言模型能否有效利用预训练语言模型中的事实回忆机制，关键在于其是否能尽早完成从视觉输入到实体表示的转换。早期实体解析的速度是决定多模态模型有效性的重要因素。本研究通过机制分析揭示了多模态对齐中的系统性失败，并提出了可操作的改进方法。

Abstract: Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.

</details>


### [157] [Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction](https://arxiv.org/abs/2512.03298)
*Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy*

Main category: cs.LG

TL;DR: 本文研究了在制度转换时间序列中，通过结合深度切换状态空间模型与自适应分位数推断（ACI）及其聚合版本（AgACI），实现分布无关的不确定性估计。提出一种统一的分位数包装器，可集成多种强序列模型（如S4、MC-Dropout GRU、稀疏高斯过程和变化点局部模型），在非平稳性和模型误设下提供具有有限样本边际保证的在线预测区间。实验表明，分位数化预测器在真实和合成数据上均实现了接近名义覆盖率，且具有竞争力的准确性和更高的区间效率。


<details>
  <summary>Details</summary>
Motivation: 在制度转换频繁的时间序列中，传统方法难以维持平稳性假设，因此不仅需要精确的点预测，还需可靠的不确定性量化。现有方法在非平稳和模型误设条件下表现不佳，亟需一种无需分布假设、适用于复杂动态系统的不确定性估计框架。

Method: 采用深度切换状态空间模型捕捉潜在制度转换，并结合自适应分位数推断（ACI）及聚合版本（AgACI）生成分布无关的预测区间。进一步设计统一的分位数包装器，可无缝嵌入多种先进序列模型，实现在线预测带的构建，并保证有限样本下的边际覆盖概率。

Result: 在合成与真实数据集上，所提出的分位数化方法均表现出接近名义覆盖率（如95%），同时保持较高的点预测精度，并显著提升预测区间的效率，优于基线方法。

Conclusion: 本研究提出的方法有效应对了非平稳时间序列中的不确定性建模挑战，为复杂动态系统提供了可靠、灵活且高效的风险评估工具，具备广泛的应用潜力。

Abstract: Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.

</details>


### [158] [HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction](https://arxiv.org/abs/2512.03300)
*Pengfei Hu,Fan Ming,Xiaoxue Han,Chang Lu,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: 提出HydroDCM框架，利用空间元数据构建伪域标签，通过对抗学习提取不变时间特征，并在推理时通过轻量级条件层适应目标水库的元数据，实现跨水库径流预测的高效域泛化。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在不同水库间应用时因分布差异导致性能下降，传统域泛化方法难以应对水文系统中独特的径流模式及空间元数据的影响。

Method: 利用水库的空间元数据构建伪域标签，指导对抗学习以提取时间特征的域不变性；推理阶段通过轻量级条件层结合目标水库的元数据进行自适应调整。

Result: 在科罗拉多河上游30个实际水库上的实验表明，该方法显著优于现有最先进的域泛化基线，在多域条件下表现优异且计算效率高。

Conclusion: HydroDCM有效解决了跨水库径流预测中的域偏移问题，兼顾了域不变性与位置特异性适应，具备良好的泛化能力与实用性。

Abstract: Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.

</details>


### [159] [Robust Tabular Foundation Models](https://arxiv.org/abs/2512.03307)
*Matthew Peroni,Franck Le,Vadim Sheinin*

Main category: cs.LG

TL;DR: 本文提出了一种名为鲁棒表格基础模型（RTFM）的模型无关对抗训练框架，通过参数化数据生成器分布，使生成的数据更具挑战性以提升模型鲁棒性。该方法基于优化差距度量（即模型性能与强基线如XGBoost之间的差距），在仅使用不到10万条合成数据的情况下，使TabPFN V2在基准测试中平均归一化AUC提升高达6%，显著优于原始模型和其他基线算法，展示了仅用合成数据进行针对性对抗训练和微调的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统表格基础模型（TFM）虽表现优异，但其预训练依赖高质量数据。现有工作多集中于设计高质量生成先验，而忽视了利用生成器主动构造对模型更具挑战性的数据。本文旨在从对抗鲁棒性角度出发，通过动态调整生成器以生成更难样本，从而提升模型泛化能力和鲁棒性。

Method: 提出一种基于优化差距度量的对抗性训练框架——鲁棒表格基础模型（RTFM）。通过定义模型性能与最优可实现性能（由XGBoost、CatBoost、Random Forest等基线估计）之间的差距，引导生成器生成对当前模型最具挑战性的合成数据；采用模型无关的方式应用于TabPFN V2，实现高效且有针对性的预训练增强。

Result: 在多个基准数据集上，应用RTFM后TabPFN V2的平均归一化AUC提升达6%，超越原始版本及其他主流基线算法。同时，仅需不到10万条额外合成数据即可实现显著性能改进，证明了该方法在效率与有效性上的双重优势。

Conclusion: 本研究揭示了利用合成数据进行针对性对抗训练的新范式，为表格基础模型的鲁棒性和泛化能力提升提供了有效路径。未来可通过进一步优化生成器策略，拓展至更多任务与场景。

Abstract: The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.

</details>


### [160] [Single-Round Scalable Analytic Federated Learning](https://arxiv.org/abs/2512.03336)
*Alan T. L. Bacellar,Mustafa Munir,Felipe M. G. França,Priscila M. V. Lima,Radu Marculescu,Lizy K. John*

Main category: cs.LG

TL;DR: 提出SAFLe框架，通过结构化分桶特征和稀疏分组嵌入实现非线性可扩展性，证明其数学等价于高维线性回归，从而继承AFL的单轮、数据分布无关聚合特性，在联邦视觉任务中显著优于线性AFL和多轮DeepAFL，打破非线性与高效性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中通信开销高和异构数据导致性能下降的问题，突破现有方法在非线性模型下无法保持单轮聚合优势的限制。

Method: 设计具有分桶特征和稀疏分组嵌入的结构化头部，构建非线性模型并证明其等价于高维线性回归，从而应用AFL的单轮聚合算法。

Result: 在所有基准测试中，SAFLe在准确率上显著优于线性AFL和多轮DeepAFL，实现了高效且可扩展的联邦视觉解决方案。

Conclusion: SAFLe成功打破了非线性表达能力与单轮高效聚合之间的权衡，为联邦学习提供了一种新的高性能、低通信开销的解决方案。

Abstract: Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.

</details>


### [161] [Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions](https://arxiv.org/abs/2512.03354)
*Hongseon Yeom,Jaeyoul Shin,Soojin Min,Jeongmin Yoon,Seunghak Yu,Dongyeop Kang*

Main category: cs.LG

TL;DR: 本文提出了一种针对确定性广告拍卖环境中离线评估（OPE）的首个系统性框架，通过重构出价景观模型以近似倾向得分，使稳定估计算法（如SNIPS）可用于反事实评估。在AuctionNet仿真基准和大规模工业平台的2周线上实验中验证了该方法的有效性，其点击率预测的平均方向准确率达92%，显著优于参数化基线，证明了其在指导实际部署决策上的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试虽为评估新广告策略的黄金标准，但消耗大量工程资源且存在因部署表现不佳而造成重大收入损失的风险。因此，亟需一种快速、离线的评估方法。然而，传统OPE方法难以应用于广告拍卖场景，因其通常为确定性‘赢家通吃’机制，导致非胜出广告的曝光概率为零，使标准估计算法失效。

Method: 提出基于出价景观模型的倾向得分近似方法，将该模型用于推导稳健的近似倾向得分，并结合自归一化逆倾向评分（SNIPS）等稳定估计算法进行反事实评估，从而实现对确定性拍卖环境下的有效离线评估。

Result: 在AuctionNet仿真与真实工业平台的2周线上实验中，所提方法在点击率预测上达到92%的平均方向准确率（MDA），显著优于参数化基线，表明其能准确预测新模型是否提升或损害性能，具备高度实用性与可靠性。

Conclusion: 本研究首次构建了适用于确定性拍卖环境的实用且经过验证的离线评估框架，为替代高成本、高风险的线上实验提供了高效可行的解决方案。

Abstract: Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.

</details>


### [162] [Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization](https://arxiv.org/abs/2512.03393)
*Lakshmi Jayalal,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 提出一种无需调参的新型框架，利用过参数化带来的隐式正则化（IR）来解决多测量向量（MMV）中联合稀疏信号恢复问题。通过重新参数化估计矩阵，将共享行支撑与各向量分量解耦，使得梯度下降在标准最小二乘目标下自然促进行稀疏结构。理论证明小而平衡的初始化下优化动态具有类似动量的效果，使真实支持行范数增长远快于其他行，从而保证收敛到理想的行稀疏解。实验表明该方法性能媲美传统方法且无需先验信息或调参。


<details>
  <summary>Details</summary>
Motivation: 传统方法如M-OMP和M-FOCUSS需精细调参或已知信号稀疏度、噪声方差等先验信息，限制了实际应用。本文旨在设计一种无需调参、不依赖先验知识的高效算法。

Method: 将估计矩阵重参数化为因子形式，解耦共享行支撑与个体向量成分；在因子空间上使用梯度下降优化标准最小二乘损失；通过理论分析证明初始值足够小且平衡时，优化过程呈现‘类动量’效应，加速真实支持行的范数增长。

Result: 理论证明了优化轨迹能收敛至理想行稀疏解；实验显示性能与现有方法相当，且无需任何参数调整或先验信息。

Conclusion: 所提方法通过隐式正则化实现无需调参的联合稀疏信号恢复，有效克服传统方法对先验知识的依赖，在理论上和实证上均表现出优越性。

Abstract: Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a "momentum-like" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.

</details>


### [163] [Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value](https://arxiv.org/abs/2512.03399)
*Joe Edelman,Tan Zhi-Xuan,Ryan Lowe,Oliver Klingefjord,Vincent Wang-Mascianica,Matija Franklin,Ryan Othniel Kearns,Ellie Hain,Atrisha Sarkar,Michiel Bakker,Fazl Barez,David Duvenaud,Jakob Foerster,Iason Gabriel,Joseph Gubbels,Bryce Goodman,Andreas Haupt,Jobst Heitzig,Julian Jara-Ettinger,Atoosa Kasirzadeh,James Ravi Kirkpatrick,Andrew Koh,W. Bradley Knox,Philipp Koralus,Joel Lehman,Sydney Levine,Samuele Marro,Manon Revel,Toby Shorin,Morgan Sutherland,Michael Henry Tessler,Ivan Vendrov,James Wilken-Smith*

Main category: cs.LG

TL;DR: 本文提出需要全栈对齐（full-stack alignment），即同时对齐AI系统及其背后的机构，以确保符合人类价值观。现有方法如效用函数、偏好排序或非结构化文本难以有效处理价值识别、规范推理和集体利益建模等问题。作者主张采用‘厚值模型’（thick models of value），通过结构化方式表示价值与规范，区分持久价值与短暂偏好，建模个体选择的社会背景，并支持在新领域中的规范推理。文中展示了该方法在五个领域的应用：AI价值托管、规范智能体、双赢谈判系统、意义保全的经济机制以及民主监管制度。


<details>
  <summary>Details</summary>
Motivation: 当前的AI对齐方法仅关注个体系统与其操作者意图的一致性，但若组织目标本身与社会整体价值不一致，仍可能导致不良后果。因此，必须将对齐范围扩展到塑造AI系统的机构层面，实现全面的价值对齐。

Method: 提出并倡导使用‘厚值模型’来结构化地表示价值与规范，使系统能够区分持久价值与短期偏好，理解个体决策的社会嵌入性，并进行规范性推理。该方法被应用于五个具体场景中以验证其可行性。

Result: 所提出的厚值模型能够有效应对现有方法在价值识别、规范推理和集体利益建模方面的局限，且已在多个实际应用领域展现出潜力，为实现更广泛的社会福祉提供了理论和技术路径。

Conclusion: 为了实现真正有益的社会结果，必须推动全栈对齐，而不仅仅是技术层面的对齐。厚值模型提供了一种可行的框架，使AI系统及其所属机构能够与人类共同价值保持一致，无需预设特定的繁荣愿景。

Abstract: Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.

</details>


### [164] [Better World Models Can Lead to Better Post-Training Performance](https://arxiv.org/abs/2512.03400)
*Prakhar Gupta,Henry Conklin,Sarah-Jane Leslie,Andrew Lee*

Main category: cs.LG

TL;DR: 本文研究了显式世界建模目标对Transformer在不同训练阶段内部表示和下游能力的影响。通过控制的2x2x2魔方任务，比较了标准的下一个词预测与两种显式世界建模策略（状态预测预训练和联合状态预测+下一个词目标），并评估了在组相对策略优化（GRPO）后训练后的任务表现。结果表明，显式世界建模能产生更线性可解、因果可控的状态表示，并且更好的状态表示能显著提升GRPO的表现，尤其在较难的魔方状态上。


<details>
  <summary>Details</summary>
Motivation: 探索显式世界建模是否能改善Transformer模型在序列规划任务中的内部表示质量及后续强化学习性能，以提升模型对复杂环境的理解与决策能力。

Method: 使用2x2x2魔方作为控制环境，对比标准下一个词预测、状态预测预训练、以及联合状态预测与下一个词预测的目标；采用线性探测和因果干预评估表示质量；在预训练后应用组相对策略优化（GRPO）进行后训练，评估下游任务表现。

Result: 显式世界建模使状态表示更线性可解且更易因果操控；改进的状态表示显著提升了GRPO的性能，尤其在高难度魔方状态中表现更优。

Conclusion: 增强状态表示的质量能够有效提升序列规划任务中后训练阶段（如强化学习）的性能，表明显式世界建模对提升模型理解与推理能力具有重要意义。

Abstract: In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.

</details>


### [165] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: GaussDetect-LiNGAM 提出了一种无需显式高斯性检验的双变量因果发现方法，利用前向模型噪声高斯性与反向回归中自变量和残差独立性的等价性，通过稳健的核基独立性检验替代脆弱且对样本敏感的高斯性检验。实验验证了该等价性，并表明该方法在多种噪声类型和样本量下保持高一致性，同时减少每决策测试次数（TPD），提升了因果推断的效率与实用性。


<details>
  <summary>Details</summary>
Motivation: 传统LiNGAM方法依赖于对噪声是否服从高斯分布的检验，但这类检验往往脆弱且对样本敏感，影响因果推断的可靠性。因此，亟需一种更稳健、无需显式高斯性假设的方法来提升方法的实用性和稳定性。

Method: 基于标准LiNGAM假设（线性、无环、外生性），证明了前向模型噪声的高斯性等价于反向模型中自变量与残差的独立性；进而用核基独立性检验替代传统的高斯性检验，实现无需显式高斯性判断的因果发现。

Result: 实验结果验证了理论等价性，GaussDetect-LiNGAM在不同噪声分布和样本规模下均表现出高一致性，显著降低每决策测试次数（TPD），提升方法的效率与实际应用价值。

Conclusion: GaussDetect-LiNGAM 通过理论创新实现了对高斯性检验的规避，使LiNGAM方法在真实世界场景中更具鲁棒性、高效性和可操作性，为因果发现提供了更可靠的新路径。

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [166] [Grokked Models are Better Unlearners](https://arxiv.org/abs/2512.03437)
*Yuanbang Liang,Yang Li*

Main category: cs.LG

TL;DR: 该研究探讨了在模型完成训练后（即发生'涌现式泛化'，grokking）进行机器遗忘的效果。实验表明，在模型完成grokking后进行遗忘比在训练早期进行更高效、更稳定且对保留数据影响更小。这归因于后grokking模型具有更模块化的表示和更低的梯度对齐性，有利于选择性遗忘。研究为改进现有遗忘方法提供了新策略，无需改变算法即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以在模型完成训练后的'涌现式泛化'阶段进行更有效的机器遗忘，以减少对其他数据的影响并提高遗忘效率。

Method: 在视觉任务（如CNN/ResNet在CIFAR、SVHN、ImageNet上）和语言任务（Transformer在TOFU设置下）中，比较在grokking前与后应用标准遗忘方法的效果。通过对比不同训练阶段的遗忘表现，分析特征与曲率，探究其机制。

Result: 在后grokking阶段开始遗忘，显著提高了遗忘效率（更少更新次数达到目标遗忘水平），减少了对保留数据和测试性能的负面影响（较小的性能下降），并且结果更稳定（跨种子一致性更高）。特征与曲率分析显示，后grokking模型具有更模块化的表示结构和更低的遗忘-保留子集间的梯度对齐性。

Conclusion: 模型训练阶段（是否经过grokking）是影响机器遗忘效果的关键因素，与具体遗忘算法并行。利用后grokking状态进行遗忘可显著提升性能，提供一种不修改算法但有效增强现有方法的实用策略。

Abstract: Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.

</details>


### [167] [Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention](https://arxiv.org/abs/2512.03464)
*Yujing Liu,Chen Yang*

Main category: cs.LG

TL;DR: 本文提出了一种端到端的深度学习框架，通过创新的跨模态注意力机制整合金融意见中的时效性（及时观点）与流行性（趋势观点）两种模态，利用BERT（Chinese-wwm-ext）进行特征嵌入，并采用金融多头交叉注意力（FMHCA）结构促进模态间信息交互，结合Transformer层优化与多模态因子双线性池化完成分类，实验表明在837家公司数据集上准确率达83.5%，较基线提升21个百分点，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有金融情感分析方法难以有效融合多样化的意见模态，且无法捕捉模态间的细粒度交互，导致市场预测与风险评估精度受限。

Method: 采用BERT（Chinese-wwm-ext）进行文本特征嵌入，设计金融多头交叉注意力（FMHCA）结构实现时效性与流行性模态间的跨模态信息交互，经由Transformer层优化后，使用多模态因子双线性池化进行特征融合与分类。

Result: 在涵盖837家公司的综合数据集上，模型准确率达到83.5%，相较BERT+Transformer等基线方法提升21个百分点，验证了框架在金融情感分析中的优越性。

Conclusion: 所提出的跨模态融合框架有效提升了金融情感分析的准确性，为更精准的金融决策与风险管理提供了有力支持。

Abstract: In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.

</details>


### [168] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯的事件模型（BEBMS），用于改进SuStaIn在疾病亚型和进展阶段推断中的表现。通过合成数据实验和真实阿尔茨海默病数据集的应用，BEBMS在亚型识别、阶段排序和患者分组任务中均显著优于SuStaIn，且结果更符合科学共识。


<details>
  <summary>Details</summary>
Motivation: 现有方法如SuStaIn虽能有效识别疾病亚型与进展顺序，但其性能在模型误设条件下可能不稳定；需要一种更稳健的方法来提高亚型推断的准确性与可靠性。

Method: 提出贝叶斯事件基础模型（BEBMS），采用贝叶斯框架对疾病亚型数量、进展顺序及患者归属进行联合建模，利用后验分布增强推断鲁棒性。

Result: 在多种合成数据场景下，BEBMS在亚型识别、阶段排序和患者分组任务中均显著优于SuStaIn；在真实阿尔茨海默病数据中，其结果更符合已知的疾病进展生物学机制。

Conclusion: BEBMS是一种更稳健、准确的疾病亚型与进展阶段推断方法，能够有效应对模型误设问题，并为复杂慢性病的异质性研究提供更可靠的分析工具。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [169] [SweetDeep: A Wearable AI Solution for Real-Time Non-Invasive Diabetes Screening](https://arxiv.org/abs/2512.03471)
*Ian Henriques,Lynda Elhassar,Sarvesh Relekar,Denis Walrave,Shayan Hassantabar,Vishu Ghanakota,Adel Laoui,Mahmoud Aich,Rafia Tir,Mohamed Zerguine,Samir Louafi,Moncef Kimouche,Emmanuel Cosson,Niraj K Jha*

Main category: cs.LG

TL;DR: SweetDeep is a lightweight neural network that uses wearable sensor data from Samsung Galaxy Watch 7 to detect type 2 diabetes in real-world settings, achieving 82.5% patient-level accuracy with minimal parameters.


<details>
  <summary>Details</summary>
Motivation: To develop a scalable, cost-effective, and non-invasive method for type 2 diabetes screening using consumer wearables, overcoming limitations of traditional biochemical assays and prior studies confined to controlled environments.

Method: SweetDeep is a compact neural network trained on physiological and demographic data collected from 285 participants across EU and MENA regions using Samsung Galaxy Watch 7 over six days, with multiple 2-minute sensor recordings per day; engineered features and a lightweight architecture enable real-world generalizability.

Result: The model achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%; allowing abstention on <10% low-confidence predictions increases accuracy to 84.5%.

Conclusion: Combining engineered features with lightweight neural architectures enables accurate, rapid, and generalizable detection of type 2 diabetes using wearable devices in free-living conditions, paving the way for scalable screening solutions.

Abstract: The global rise in type 2 diabetes underscores the need for scalable and cost-effective screening methods. Current diagnosis requires biochemical assays, which are invasive and costly. Advances in consumer wearables have enabled early explorations of machine learning-based disease detection, but prior studies were limited to controlled settings. We present SweetDeep, a compact neural network trained on physiological and demographic data from 285 (diabetic and non-diabetic) participants in the EU and MENA regions, collected using Samsung Galaxy Watch 7 devices in free-living conditions over six days. Each participant contributed multiple 2-minute sensor recordings per day, totaling approximately 20 recordings per individual. Despite comprising fewer than 3,000 parameters, SweetDeep achieves 82.5% patient-level accuracy (82.1% macro-F1, 79.7% sensitivity, 84.6% specificity) under three-fold cross-validation, with an expected calibration error of 5.5%. Allowing the model to abstain on less than 10% of low-confidence patient predictions yields an accuracy of 84.5% on the remaining patients. These findings demonstrate that combining engineered features with lightweight architectures can support accurate, rapid, and generalizable detection of type 2 diabetes in real-world wearable settings.

</details>


### [170] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 提出联合进展模型（JPM）以处理神经退行性疾病中常见的混合病理，通过概率框架建模多个疾病轨迹的联合进展。JPM采用多种变体（成对、Bradley-Terry、Plackett-Luce、Mallows），在校准性、分离性和锐度三方面表现良好，合成实验显示其排序准确率比基线模型（SA-EBM）提升约21%。真实数据（NACC）分析表明，Mallows-JPM与文献中关于阿尔茨海默病和血管性痴呆混合病理进展的已有认知更一致。


<details>
  <summary>Details</summary>
Motivation: 神经退行性疾病中常存在多种病理共存，而传统事件基础模型（EBM）假设个体仅受单一疾病驱动，无法有效捕捉混合病理下的复杂进展模式。因此需要一种能同时建模多个疾病轨迹并推断其联合进展路径的新方法。

Method: 提出联合进展模型（JPM），将单个疾病轨迹视为部分排序，并构建联合进展的先验分布。引入四种概率模型变体（Pairwise, Bradley-Terry, Plackett-Luce, Mallows），利用贝叶斯推理估计联合排序，并评估其在校准性、分离性和锐度上的表现。

Result: 所有JPM变体均具备良好的校准性和分离性；锐度因变体而异，但可由输入部分排序的特征（如数量、长度、冲突度、重叠度）有效预测。合成实验显示JPM比基线模型（SA-EBM）排序准确率提升约21%。真实数据（NACC）分析表明，Mallows-JPM的结果与现有文献关于AD与VaD混合病理进展的共识更为一致。

Conclusion: JPM是一种有效建模多病理共同进展的框架，尤其适用于复杂神经退行性疾病。Mallows变体在真实数据中表现最佳，支持其在临床研究中的应用价值。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [171] [Adaptive sampling using variational autoencoder and reinforcement learning](https://arxiv.org/abs/2512.03525)
*Adil Rasheed,Mikael Aleksander Jansen Shahly,Muhammad Faisal Aftab*

Main category: cs.LG

TL;DR: 提出一种自适应稀疏感知框架，结合变分自编码器先验与强化学习，实现序列化测量选择，显著优于传统压缩感知、最优传感器位置和基于生成模型的方法。


<details>
  <summary>Details</summary>
Motivation: 现有压缩感知依赖通用基和随机测量，效率与重建质量受限；最优传感器放置虽利用历史数据设计采样模式，但固定线性基无法适应非线性和样本特异性变化；生成模型方法虽提升重建质量，但仍采用次优随机采样。

Method: 提出一种融合变分自编码器先验与强化学习的自适应稀疏感知框架，通过强化学习动态选择测量序列，实现对样本特性的自适应优化。

Result: 实验表明，该方法在稀疏测量下的重建性能显著优于传统压缩感知、最优传感器放置及基于生成模型的方法。

Conclusion: 所提出的自适应稀疏感知框架通过联合利用生成先验与强化学习实现了更优的测量选择，提升了稀疏采样下的重建质量与效率。

Abstract: Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.

</details>


### [172] [Parameter-Efficient Augment Plugin for Class-Incremental Learning](https://arxiv.org/abs/2512.03537)
*Zhiming Xu,Baile Xu,Jian Zhao,Furao Shen,Suorong Yang*

Main category: cs.LG

TL;DR: 本文提出了一种名为DLC（Deployment of extra LoRA Components）的插件式扩展范式，用于非预训练的类增量学习（CIL）场景。通过在基础模型的深层注入任务特定的低秩适应（LoRA）残差，并引入轻量级加权单元以减少非目标LoRA模块的干扰，实现高效且可扩展的增量学习。该方法仅需标准ResNet-18 4%的参数，在ImageNet-100上实现8%的准确率提升，显著优于现有方法，尤其在固定内存预算下表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有基于重放或知识蒸馏的类增量学习方法受限于遗忘问题和稳定性-可塑性困境；而部分扩展型方法虽精度更高，但需要大量参数增长。因此亟需一种既能保持高精度又具备极低参数开销的增量学习方案。

Method: 将通过重放或蒸馏训练的特征提取器作为基础模型，针对每个任务使用低秩适应（LoRA）在深层注入任务特定残差；推理时聚合带任务残差的表示，并通过轻量级权重单元动态分配重要性分数，以抑制非目标模块干扰。整体结构为即插即用的插件式设计。

Result: 在ImageNet-100数据集上，仅使用4%的ResNet-18参数量，DLC模型实现了8%的准确率提升，显著优于当前主流方法，且在固定内存预算下达到领先性能。

Conclusion: DLC提供了一种高效、轻量且可扩展的类增量学习解决方案，通过插件式LoRA扩展，在不显著增加参数的前提下有效缓解遗忘问题，突破了传统方法在效率与性能间的权衡瓶颈。

Abstract: Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.

</details>


### [173] [When, How Long and How Much? Interpretable Neural Networks for Time Series Regression by Learning to Mask and Aggregate](https://arxiv.org/abs/2512.03578)
*Florent Forest,Amaury Wei,Olga Fink*

Main category: cs.LG

TL;DR: 本文提出MAGNETS，一种用于时间序列外生回归（TSER）的内在可解释神经架构。该模型无需人工标注即可学习一组紧凑且人类可理解的概念，每个概念通过基于掩码的聚合方式捕捉关键输入特征及其在时间序列中的作用时机，预测结果由这些概念的透明加性组合构成，从而实现对模型决策过程的清晰洞察。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列外生回归模型虽预测性能强，但多为黑箱，难以解释；后处理可解释性方法存在粗糙、噪声大或不稳定等问题；而现有的内在可解释方法受限于需概念标注、无法捕捉特征交互、表达能力弱及高维数据扩展困难。因此亟需一种无需监督、能自动发现有意义概念并支持复杂模式建模的可解释框架。

Method: MAGNETS采用基于掩码的特征聚合机制，自动学习一组可解释的时间序列概念；通过可学习的掩码选择重要特征，并在时间维度上进行聚合；预测由这些概念以加性方式线性组合而成，结构透明，便于分析各概念对输出的贡献。

Result: 实验表明，MAGNETS在多个真实世界数据集上实现了与先进黑箱模型相当的预测精度，同时提供了高质量、稳定且可解释的决策依据，有效揭示了哪些特征在何时影响预测结果，优于现有可解释方法。

Conclusion: MAGNETS是一种高效且可解释的时间序列回归模型，能够在无监督条件下自动提取有意义的时间模式，兼顾预测性能与可解释性，适用于医疗、金融等对可靠性与透明度要求高的场景。

Abstract: Time series extrinsic regression (TSER) refers to the task of predicting a continuous target variable from an input time series. It appears in many domains, including healthcare, finance, environmental monitoring, and engineering. In these settings, accurate predictions and trustworthy reasoning are both essential. Although state-of-the-art TSER models achieve strong predictive performance, they typically operate as black boxes, making it difficult to understand which temporal patterns drive their decisions. Post-hoc interpretability techniques, such as feature attribution, aim to to explain how the model arrives at its predictions, but often produce coarse, noisy, or unstable explanations. Recently, inherently interpretable approaches based on concepts, additive decompositions, or symbolic regression, have emerged as promising alternatives. However, these approaches remain limited: they require explicit supervision on the concepts themselves, often cannot capture interactions between time-series features, lack expressiveness for complex temporal patterns, and struggle to scale to high-dimensional multivariate data.
  To address these limitations, we propose MAGNETS (Mask-and-AGgregate NEtwork for Time Series), an inherently interpretable neural architecture for TSER. MAGNETS learns a compact set of human-understandable concepts without requiring any annotations. Each concept corresponds to a learned, mask-based aggregation over selected input features, explicitly revealing both which features drive predictions and when they matter in the sequence. Predictions are formed as combinations of these learned concepts through a transparent, additive structure, enabling clear insight into the model's decision process.

</details>


### [174] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出了一种名为Diffusion Model Relearning Attack (DiMRA)的新攻击方法，能够逆转基于微调的机器遗忘技术，暴露了现有方法的脆弱性。为此，作者提出了新的机器遗忘方法DiMUM，通过记忆替代数据或特征来防止生成被遗忘的内容，从而在保持生成性能的同时增强对攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于微调的机器遗忘方法虽然高效，但存在被逆向攻击的风险，因此需要更安全、更鲁棒的遗忘机制。

Method: DiMRA通过在辅助数据集上优化被遗忘的扩散模型，实现对已遗忘内容的重建；DiMUM则通过引入替代数据或特征进行记忆，以避免生成目标内容。

Result: 实验表明DiMRA能有效逆转当前最先进的微调型机器遗忘方法，而DiMUM在保持生成质量的同时显著提升了对抗此类攻击的能力。

Conclusion: 该研究揭示了现有扩散模型机器遗忘方法的安全隐患，并提出了更具鲁棒性的解决方案DiMUM，为安全可控的生成模型发展提供了新思路。

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [175] [The promising potential of vision language models for the generation of textual weather forecasts](https://arxiv.org/abs/2512.03623)
*Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen*

Main category: cs.LG

TL;DR: 本文探索了使用视觉语言模型直接从视频编码的网格化气象数据生成著名的航运预报文本，展示了在提升气象产品生产效率和服务创新方面的可扩展技术潜力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态基础模型在气象产品和服务生成中的应用仍处于起步阶段，亟需新技术以加速其发展和采纳。

Method: 利用视觉语言模型，将视频编码的网格化天气数据转换为航运预报文本。

Result: 初步结果表明，该方法具有显著提升气象业务生产效率和服务创新的潜力。

Conclusion: 该研究揭示了多模态模型在气象服务领域中的广阔应用前景，为未来智能化气象产品生成提供了新路径。

Abstract: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

</details>


### [176] [Optimal Transportation and Alignment Between Gaussian Measures](https://arxiv.org/abs/2512.03579)
*Sanjit Dandapanthula,Aleksandr Podkopaev,Shiva Prasad Kasiviswanathan,Aaditya Ramdas,Ziv Goldfeld*

Main category: cs.LG

TL;DR: 本文系统研究了高斯分布下基于二次代价的最优传输（OT）与内积格罗莫夫-沃瑟斯坦（IGW）对齐问题，解决了非中心高斯在可分希尔伯特空间下的开放难题，给出了闭式解（需优化单位算子），并推导出紧致的上下界；当至少一个高斯分布为中心时，解可完全闭式表达，并进一步推广至中心高斯的IGW均值点解析解。同时，将多边际高斯OT问题转化为可解优化问题，提出基于秩亏约束的高效算法。应用示例包括知识蒸馏与异质聚类，在合成及真实数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有最优传输与格罗莫夫-沃瑟斯坦对齐方法在大规模应用中因计算成本高而受限，尤其在处理非中心高斯分布时缺乏有效闭式解，限制了其在复杂数据任务中的应用。本文旨在填补该领域关键理论空白，提升方法在实际场景中的适用性与效率。

Method: 针对高斯分布与二次代价的OT和IGW对齐问题，采用泛函分析与优化理论相结合的方法：对未中心化高斯情形，构造依赖于单位算子的二次优化形式，并给出紧致解析边界；在中心化条件下，利用矩阵分解与特征结构获得闭式解；对于多边际问题，引入秩亏约束，将其转化为低维优化问题，并设计高效求解算法。

Result: 成功获得非中心高斯间IGW对齐的闭式表达（带优化项）及其紧界；在至少一个分布为零均值时，实现完全闭式解；扩展至中心高斯的IGW均值点解析解；多边际OT问题被转化为可计算的优化模型，算法具有较高效率。

Conclusion: 本工作全面推进了高斯分布下最优传输与内积格罗莫夫-沃瑟斯坦对齐的理论与算法框架，为异质数据比较、变换与聚合提供了高效且可解释的工具，显著增强了其在机器学习任务中的实用价值。

Abstract: Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.

</details>


### [177] [Federated Learning and Trajectory Compression for Enhanced AIS Coverage](https://arxiv.org/abs/2512.03584)
*Thomas Gräupl,Andreas Reisenbauer,Marcel Hecko,Anil Rasouli,Anita Graser,Melitta Dragaschnig,Axel Weissenfeld,Gilles Dejaegere,Mahmoud Sakr*

Main category: cs.LG

TL;DR: VesselEdge系统通过联邦学习和带宽受限的轨迹压缩，将船舶变为移动传感器，以扩展AIS覆盖范围并提升海上态势感知能力。系统采用M3fed模型和BWC-DR-A算法，优先传输异常数据，初步结果表明其在历史数据上有效提升了AIS覆盖与态势感知。


<details>
  <summary>Details</summary>
Motivation: 现有AIS系统存在覆盖范围有限、数据传输效率低的问题，尤其在偏远海域难以实现全面监控。为提升海上态势感知能力，需在低带宽条件下高效传输关键数据，同时保护隐私和减少通信开销。

Method: VesselEdge系统结合联邦学习（M3fed模型）实现分布式模型训练，避免原始数据集中传输；采用带宽约束的轨迹压缩算法（BWC-DR-A），对轨迹数据进行压缩，并优先保留异常轨迹信息，确保关键信息不丢失。

Result: 基于历史数据的实验表明，VesselEdge显著提升了AIS系统的覆盖范围和异常检测能力，在低带宽环境下仍能保持高效的实时数据传输和态势感知性能。

Conclusion: VesselEdge通过融合联邦学习与智能轨迹压缩技术，成功将船舶转化为移动传感节点，在保障隐私和降低通信负担的前提下，有效增强了海上态势感知能力，具有广泛的应用前景。

Abstract: This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.

</details>


### [178] [Observation-driven correction of numerical weather prediction for marine winds](https://arxiv.org/abs/2512.03606)
*Matteo Peduto,Qidong Yang,Jonathan Giezendanner,Devis Tuia,Sherrie Wang*

Main category: cs.LG

TL;DR: 本文提出一种基于Transformer的深度学习模型，用于改进海洋风场预报。通过将最新现场观测数据与全球数值天气预报（GFS）输出相结合，学习局部修正模式，从而在稀疏、异质且随时间变化的海洋观测条件下实现更准确的风速预测。模型采用掩码和集合注意力机制处理不规则观测，利用交叉注意力融合观测-预报对，并结合周期性时间嵌入与坐标感知的位置表示，实现任意空间坐标下的单次前向推理。实验基于ICOADS数据集，在大西洋区域评估，结果显示该模型在1小时至48小时预报时效内均显著降低GFS风速均方根误差，分别提升45%和13%。空间分析表明，沿岸和航运路线等观测密集区改进最为明显。该方法可自然支持多种观测平台（船舶、浮标、潮位计、海岸站），并可在一次前向传播中同时生成站点级预测与区域网格化产品，是一种低延迟、实用性强的后处理方案，有效弥补了传统数值预报的系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 海洋风场预报对航行安全、航线规划和能源作业至关重要，但受限于海洋观测稀疏、异质和时变特性，传统方法难以满足高精度需求。现有数值预报模型（如GFS）存在系统性误差，亟需一种能有效融合实时观测信息、自动学习修正模式的高效后处理方法。

Method: 提出一种基于Transformer的深度学习架构：(i) 使用掩码和集合注意力机制处理不规则、动态变化的观测数据；(ii) 通过交叉注意力机制融合近期观测与预报对信息；(iii) 引入周期性时间嵌入和坐标感知的位置表示，支持任意空间坐标的单次前向推理。整体框架以观测为引导，修正全球预报输出，而非直接进行风速预测。

Result: 在大西洋区域使用ICOADS数据验证，模型在所有预报时效（0–48小时）上均显著降低GFS 10米风速均方根误差，1小时预报提升45%，48小时预报提升13%。空间分布显示，沿岸及主要航运路线等观测密集区改善最显著。模型可统一处理多源异构观测平台，一次前向传播即可输出站点级预测与区域格网产品。

Conclusion: 本研究提出了一种高效的观测引导型风场修正框架，能够利用稀疏但多样化的海洋观测数据，自动学习并校正数值预报中的系统性偏差。该方法具备低延迟、高灵活性与强泛化能力，适用于实际业务环境，是当前数值预报体系的重要补充。

Abstract: Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.

</details>


### [179] [Dynamically Scaled Activation Steering](https://arxiv.org/abs/2512.03661)
*Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez*

Main category: cs.LG

TL;DR: DSAS 是一种方法无关的动态激活调制框架，通过解耦何时干预与如何干预，仅在检测到不当行为时自适应地增强干预强度。该方法在生成时计算上下文相关的缩放因子，选择性调整任何现有引导方法的强度，同时可端到端联合优化，显著提升毒性缓解与模型效用之间的权衡，并在文本到图像扩散模型中展示其通用性，且计算开销极低，增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法对所有输入统一干预，导致在无需引导时性能下降。需要一种能根据上下文动态调节干预强度的方法，以在避免过度干预的同时有效缓解不良行为。

Method: 提出动态缩放激活引导（DSAS），通过上下文依赖的缩放因子自适应调节已有引导方法的强度，实现何时引导与如何引导的解耦；支持端到端联合优化，并可应用于多种模型架构。

Result: DSAS 在多种任务中优于传统引导方法，显著改善了毒性缓解与模型效用之间的帕累托前沿；在文本到图像模型中成功调控特定概念；计算开销小，可解释性强，能定位需引导的词元及其强度。

Conclusion: DSAS 提供了一种高效、通用且可解释的激活引导框架，能够在必要时精准干预，避免不必要的性能损失，适用于多种生成模型和引导任务。

Abstract: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

</details>


### [180] [Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting](https://arxiv.org/abs/2512.03656)
*Salim Khazem,Houssam Kanso*

Main category: cs.LG

TL;DR: 本文提出一种统一的深度学习框架，结合周期性时间编码与混合LSTM-CNN架构，以提升多步电力负荷预测性能。通过正弦余弦编码处理日历属性，并利用相关性分析评估其预测价值。采用集成模型融合LSTM、CNN和针对不同预测时序的MLP元学习器，有效捕捉长期季节性和短期局部模式。基于一年国家用电数据集的实验表明，该方法在所有七个预测时序上均显著优于单一模型和现有基准方法，验证了周期性时间表示与互补深度学习结构结合的有效性。这是首个在统一短时电力负荷预测框架中联合评估时间编码、日历特征与混合集成架构的工作。


<details>
  <summary>Details</summary>
Motivation: 准确的电力消费预测对需求管理和智能电网运行至关重要。现有方法在捕捉复杂时间模式（如周期性、季节性）和短期波动方面存在局限，亟需更高效的建模框架。

Method: 提出一种融合周期性时间编码（正弦余弦编码）与混合LSTM-CNN架构的深度学习框架；使用相关性分析评估日历特征的预测价值；构建由LSTM、CNN和多层感知机（MLP）元学习器组成的集成模型，分别优化不同预测时序。

Result: 在七种预测时序下，混合模型均显著降低RMSE和MAE，优于单一模型及已有方法；周期性编码与日历特征的引入带来稳定性能提升；集成结构有效融合长期与短期模式。

Conclusion: 结合周期性时间表示与互补深度学习结构的混合框架，在短时电力负荷预测中展现出优越性能。该研究首次在统一框架内系统评估了时间编码、日历特征与集成架构的协同作用，为未来智能电网预测提供了新范式。

Abstract: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

</details>


### [181] [Feature-aware Modulation for Learning from Temporal Tabular Data](https://arxiv.org/abs/2512.03678)
*Hao-Run Cai,Han-Jia Ye*

Main category: cs.LG

TL;DR: 本文研究时间表数据中的动态映射问题，发现特征语义（客观与主观意义）的演变是导致概念漂移的关键因素。提出一种基于特征感知的时间调制机制，通过条件化时间上下文来调节特征表示的统计特性（如尺度和偏度），实现跨时间段的语义对齐，从而在保持模型泛化能力的同时增强适应性。实验验证了该方法在处理时间分布变化方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 真实世界中，表格式机器学习面临时间分布漂移的挑战，静态模型难以应对演化关系，而自适应模型可能过拟合瞬时模式，导致鲁棒性与适应性之间的权衡难题。因此需要一种既能保持泛化能力又可灵活适应时间变化的方法。

Method: 提出一种特征感知的时间调制机制，根据时间上下文动态调节特征表示的统计属性（如尺度、偏度），以对齐不同时期的特征语义，缓解因语义演变引起的概念漂移。

Result: 在多个基准数据集上的实验表明，所提方法能有效应对表格式数据中的时间分布变化，在保持模型稳健性的同时显著提升适应能力。

Conclusion: 通过建模特征语义随时间的演变并设计相应的调制机制，本工作实现了轻量级但高效的动态适应，为处理时间表数据中的概念漂移提供了新思路。

Abstract: While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.

</details>


### [182] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 提出一种基于物理约束的哈密顿学习算法，结合结构不可逆性检测与能量景观重构，以识别交通系统在极端天气事件后的深层结构性损伤。该方法通过低维状态表示和物理约束优化，揭示传统指标无法发现的‘虚假恢复’现象。在2021年伦敦暴雨事件中，表面指标看似完全恢复，但算法检测出64.8%的结构性损伤。该框架可实现主动式结构风险评估，推动基于真实系统健康状况的基础设施投资决策。


<details>
  <summary>Details</summary>
Motivation: 现有城市交通韧性评估方法依赖表面恢复指标，无法区分真正的系统恢复与‘虚假恢复’——即交通流量虽恢复正常，但系统内在动态已永久退化。这种盲区导致基础设施维护决策失准，亟需更深层次的评估工具。

Method: 提出一种物理约束的哈密顿学习算法，通过提取低维状态表示，利用物理约束优化识别准哈密顿结构，并通过能量景观比较量化系统结构性变化，从而检测隐藏的结构损伤。

Result: 在伦敦2021年极端降雨事件分析中，尽管表面交通指标显示完全恢复，该算法检测到64.8%的结构性损伤，显著超越传统监测手段。结果表明该方法能有效识别被忽略的深层系统退化。

Conclusion: 本研究构建的框架能够精准识别交通系统在极端事件中的结构性损伤，避免因依赖表面指标导致的误判，为基础设施的科学维护与前瞻性投资提供可靠依据。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


### [183] [DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training](https://arxiv.org/abs/2512.03847)
*Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: DVPO 提出一种结合条件风险理论与分布值建模的强化学习框架，通过学习细粒度的分词级价值分布，并使用非对称风险正则化调节分布尾部：压缩下尾以抑制噪声负偏差，扩展上尾以保留探索多样性，在存在噪声或不完整监督的情况下，显著提升 LLM 后训练的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在真实场景中面对噪声或不完整监督时易出现训练不稳定、泛化能力差的问题；传统方法如最坏情况优化和均值基方法虽提高稳定性，但常导致策略过于保守，性能在不同场景间表现不均。因此需要一种能更好平衡鲁棒性与泛化性的新方法。

Method: 提出 DVPO 框架，融合条件风险理论与分布值建模，学习 token 级价值分布，并引入非对称风险正则化：收缩下尾以抑制噪声负偏差，扩展上尾以维持探索多样性。

Result: 在多轮对话、数学推理和科学问答任务中，DVPO 在噪声监督下持续优于 PPO、GRPO 以及基于鲁棒 Bellman 的 PPO，展现出更强的鲁棒性与泛化能力。

Conclusion: DVPO 有效解决了真实世界中不完整或噪声监督下的 RL 训练难题，为 LLM 后训练提供了更稳健且更具泛化能力的新范式。

Abstract: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

</details>


### [184] [Universally Converging Representations of Matter Across Scientific Foundation Models](https://arxiv.org/abs/2512.03750)
*Sathya Edamadaka,Soojung Yang,Ju Li,Rafael Gómez-Bombarelli*

Main category: cs.LG

TL;DR: 本文研究了近六十种不同模态和架构的科学机器学习模型在分子、材料和蛋白质行为预测中的内部表示是否趋同。结果表明，这些模型在小分子上的表示高度对齐，且随着机器学习势能模型性能提升，其表示空间也趋于一致，暗示基础模型可能学习到物理现实的共同表征。但当面对训练中未见的结构时，所有模型均退化为低信息表示，说明当前模型仍受限于训练数据和归纳偏置，尚未形成真正通用的结构表征。研究提出将表示对齐作为科学基础模型泛化能力的量化基准，并可指导跨模态、跨领域模型选择与蒸馏。


<details>
  <summary>Details</summary>
Motivation: 理解不同科学机器学习模型是否学习到相似的内部表示，是构建可泛化科学基础模型的关键。尽管语言和视觉领域已观察到表示收敛，但科学领域的系统性探索尚缺。

Method: 分析60余种科学模型（涵盖字符串、图、3D原子结构、蛋白质等模态）在多种化学体系下的表示空间对齐情况，通过比较不同模型在相同输入下的嵌入向量相似性，评估表示一致性；进一步划分模型在相似与异构输入下的行为表现。

Result: 不同模型在小分子上的表示高度一致；高性能模型在相似输入下表示对齐，弱模型则分散于局部最优；在全新结构上，几乎所有模型都坍缩至低信息表示，表明模型仍受制于训练数据和归纳偏置。

Conclusion: 科学模型的表示存在一定程度的对齐，尤其在训练域内；但尚未形成真正通用的物质表征。该研究建立表示对齐作为科学基础模型泛化能力的量化基准，有助于追踪模型演化并优化跨任务、跨模态迁移性能。

Abstract: Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

</details>


### [185] [Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition](https://arxiv.org/abs/2512.03755)
*Stephen Law,Tao Yang,Nanjiang Chen,Xuhui Lin*

Main category: cs.LG

TL;DR: 提出一种条件轨迹编码器，联合学习空间与移动表征，利用几何特征保留起点依赖的不对称性，通过对比学习分解共享城市模式与起点特异性签名，在六个人工城市和北京西城区的真实数据上验证了城市形态导致系统性认知不平等。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹分析方法在空间与时间表征上存在割裂，缺乏联合训练机制，忽略导航中的方向不对称性（如A→B ≠ B→A），且过度依赖辅助数据而非城市空间的几何属性。

Method: 设计了一种基于双向LSTM的条件轨迹编码器，结合可视性比率与曲率特征，并以可学习的起点嵌入为条件，通过对比学习实现共享城市模式与起点特异性表征的解耦。

Result: 在六个合成城市及北京西城区的数据上验证，城市形态引发系统性认知差异；该模型能量化不同起点下的认知不对称性，为城市规划、建筑设计和导航系统提供原点感知的分析工具。

Conclusion: 该框架实现了空间与时间表征的统一建模，揭示了城市几何结构对认知体验的影响，为实现更公平的城市设计与智能导航提供了可量化的技术路径。

Abstract: Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \to B \ne B \to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.

</details>


### [186] [Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment](https://arxiv.org/abs/2512.03864)
*Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani*

Main category: cs.LG

TL;DR: 本研究通过对比AI模型在智能加工中的性能，提出超维计算（HDC）可实现高精度、低能耗和高速度，显著优于传统模型，为节能智能制造提供新路径。


<details>
  <summary>Details</summary>
Motivation: 智能制造虽能显著提升效率并降低能耗，但人工智能模型的能源需求可能抵消这些优势。

Method: 采用基于原位传感的几何质量预测方法，比较常见人工智能模型在能源消耗、准确性和速度方面的表现，并引入超维计算（HDC）作为替代方案。

Result: HDC在保持与传统模型相当的准确性的同时，将训练能耗降低200倍，推理能耗降低175至1000倍；同时训练时间减少200倍，推理时间减少300至600倍。

Conclusion: HDC展现出在节能型智能制造中的巨大潜力，是实现高效低耗智能制造的理想选择。

Abstract: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

</details>


### [187] [Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach](https://arxiv.org/abs/2512.03786)
*Conor McCarthy,Jan Peter van Zandwijk,Marcel Worring,Zeno Geradts*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的方法，将智能手机和智能手表中的数字痕迹转化为不同身体活动的似然比（LR），在新数据集NFI_FARED上评估，成功区分了167/171种活动组合。该方法还可扩展至多活动同时分析并生成活动时间线，助力刑事调查的早期与后期阶段。相关数据集和代码已公开，以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 智能手机和智能手表中的运动传感器可提供丰富的用户行为数字痕迹，为法医调查人员了解个人物理活动提供了机会。现有方法缺乏有效量化这些数字痕迹与具体活动之间关系的工具，因此需要一种能够生成似然比的系统性方法，以支持法医推断。

Method: 采用机器学习模型，将来自四款iPhone的数字痕迹（如加速度、陀螺仪数据）映射到19种不同身体活动，并计算各活动间的似然比（LR）。通过构建分类器，实现对活动对的区分，并进一步扩展至多活动联合分析与活动时间线重建。

Result: 在NFI_FARED数据集上，该方法成功识别出167个活动配对的显著差异，表现出较高的区分能力；同时能生成多活动时间线，有效辅助法医调查的各个阶段。

Conclusion: 所提出的机器学习框架能够有效将数字痕迹转化为可解释的似然比，为法医分析提供可靠工具。数据与代码公开，推动该领域持续发展。

Abstract: Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.

</details>


### [188] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 本文提出一种基于流程挖掘的两阶段临床路径建模方法，通过历史数据构建治疗过程模型，并利用符合性检查诊断结果扩展知识库，以应对不同疾病变体或组合的实际最佳实践。实验基于Synthea模拟数据集验证了该方法的有效性，在保持较低弧度复杂度的同时，实现了高达95.62%的AUC性能。


<details>
  <summary>Details</summary>
Motivation: 手动依据临床指南和领域知识构建临床路径困难且难以反映实际中不同疾病变体或组合的最佳治疗实践，亟需自动化、数据驱动的方法来提升路径的准确性和适应性。

Method: 采用两阶段流程挖掘方法：第一阶段从历史数据中提取疾病治疗过程模型；第二阶段通过新数据与参考模型的符合性检查，识别偏差并据此扩展知识库，生成针对特定变体或组合的细化模型。

Result: 在SARS-CoV-2感染及其并发症的模拟数据上，该方法实现了最高95.62%的AUC值，同时保持了67.11%的弧度复杂度，表明其在精度与可解释性之间取得了良好平衡。

Conclusion: 所提方法有效提升了临床路径知识库的覆盖范围与精准度，能够自动发现并建模复杂疾病情境下的治疗模式，为个性化医疗决策支持提供了有力工具。

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [189] [EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification](https://arxiv.org/abs/2512.03804)
*Hanhui Deng,Xinglin Li,Jie Luo,Zhanpeng Jin,Di Wu*

Main category: cs.LG

TL;DR: 本文研究了新型深度学习技术，用于有效管理和分析心电图（ECG）数据，旨在构建一个准确、快速的诊断模型，以显著减轻医疗工作者的负担。提出EfficientECG模型，基于EfficientNet改进，具备高精度与轻量化特点，适用于处理多种导联的高频长序列ECG数据；进一步设计了一种基于交叉注意力的特征融合模型，实现多导联ECG数据中多特征（如性别、年龄）的有效融合。在代表性ECG数据集上的评估表明，该模型在精度、多特征融合和轻量化方面均优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有ECG模型存在较高的误诊率，且难以高效处理复杂的多导联、多特征的ECG数据，亟需一种更准确、快速且轻量化的深度学习模型来提升诊断效率并降低医疗负担。

Method: 首先基于EfficientNet设计EfficientECG模型，实现对高频率长序列ECG数据的端到端特征提取；其次引入基于交叉注意力机制的特征融合模块，用于整合多导联ECG数据中的多维信息（如性别、年龄），实现多特征联合分析。

Result: 在多个代表性ECG数据集上，所提模型在分类精度、多特征融合能力及模型轻量化方面均显著优于当前主流方法，验证了其有效性与优越性。

Conclusion: 本研究提出的EfficientECG及其交叉注意力融合模型，能够高效、准确地分析多导联ECG数据，具备良好的临床应用潜力，有助于实现智能、快速的心脏疾病诊断。

Abstract: Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.

</details>


### [190] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 本文研究了深度强化学习在动态算法配置（DAC）中的应用，聚焦于(1+($\lambda$,$\lambda$))-GA算法中种群大小参数的控制问题。通过分析DDQN和PPO，发现其在DAC中面临可扩展性下降与学习不稳定性两大挑战，根源在于探索不足与规划视野覆盖不足。针对探索不足，提出自适应奖励偏移机制，利用奖励分布统计信息提升探索效率，避免实例特定超参数调优；针对规划视野问题，发现无折扣学习可有效解决DDQN的该问题，而PPO存在根本性方差问题，需另设计算法。此外，分析表明即使优化超参数，PPO仍难以在不同配置中找到有效策略。最终，结合自适应奖励偏移的DDQN性能接近理论最优策略，且样本效率显著优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在动态算法配置（DAC）中虽具潜力，但因需大量领域知识、存在可扩展性差和学习不稳定等问题，限制了其实际应用。本文旨在系统评估深度强化学习在DAC中的有效性，并揭示其核心瓶颈，推动更高效、通用的算法配置方案发展。

Method: 采用系统性实验分析深度强化学习算法（DDQN与PPO）在控制(1+($\lambda$,$\lambda$))-GA种群大小参数上的表现，通过对比不同设置下的学习行为，识别出探索不足与规划视野覆盖不足两大关键问题。提出自适应奖励偏移机制以增强探索，验证无折扣学习对规划问题的缓解作用，并深入分析PPO的超参数依赖性。

Result: 自适应奖励偏移机制显著提升了DDQN的探索能力，使其在不同问题规模下保持稳定性能，无需额外调参；无折扣学习有效解决DDQN的规划问题，而PPO受方差困扰难以改进。最终，优化后的DDQN在性能上接近理论最优策略，且样本效率比以往方法高出数个数量级。

Conclusion: 深度强化学习在DAC中具有巨大潜力，但需针对性地解决探索不足与规划视野覆盖问题。自适应奖励偏移与无折扣学习等策略能有效提升算法表现。相比之下，PPO在该任务中存在固有缺陷，需重新设计。本研究为构建高效、通用的动态算法配置框架提供了重要启示。

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [191] [Log Probability Tracking of LLM APIs](https://arxiv.org/abs/2512.03816)
*Timothée Chauvin,Erwan Le Merrer,François Taïani,Gilles Tredan*

Main category: cs.LG

TL;DR: 本文提出一种低成本、高敏感度的持续监控LLM API的方法，利用单个输出token的logprob平均值进行统计检验，可检测微调级别变化，比现有方法快1000倍。


<details>
  <summary>Details</summary>
Motivation: 现有LLM API审计方法成本过高，无法定期监测模型更新，导致模型变更难以追踪，影响下游应用可靠性和研究可复现性。

Method: 基于单个token输出的logprob平均值进行简单统计检验，用于检测模型微小变化。

Result: 该方法可检测到仅一步微调的更改，灵敏度高于现有方法，且成本降低1000倍，同时引入了TinyChange基准以评估审计方法对小规模真实模型变化的敏感性。

Conclusion: 通过使用logprob的统计特性，可在极低开销下实现对LLM API的高效连续监控，为模型一致性保障提供了实用解决方案。

Abstract: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.

</details>


### [192] [Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2512.03899)
*Janis Keck,Lukas Silvester Barth,Fatemeh,Fahimi,Parvaneh Joharinad,Jürgen Jost*

Main category: cs.LG

TL;DR: 本文提出了一种将模糊单纯形集解释为单纯形集上概率测度的边缘分布的框架，将其与概率模型联系起来，揭示了UMAP中模糊权重的生成机制，并通过随机采样维特里斯滤链解释了成对距离的累积分布函数。该框架还澄清了Kullback-Leibler散度与模糊交叉熵之间的关系，通过单纯形集上的布尔运算恢复了标准的t-范数和t-对范数。基于此，可系统推导出新的降维方法，例如使用三元组采样的契赫滤链对UMAP进行推广。总体而言，该概率视角为模糊单纯形集提供了统一的理论基础，明确了UMAP的地位，并推动新方法的构建。


<details>
  <summary>Details</summary>
Motivation: 模糊单纯形集在降维和流形学习中具有重要地位，尤其在UMAP中表现突出，但其基于代数拓扑的定义缺乏明确的概率解释，难以融入主流理论框架。因此，亟需建立一个能连接模糊单纯形集与概率模型的统一理论体系。

Method: 提出一种将模糊单纯形集视为单纯形集上概率测度边缘分布的框架；利用随机采样维特里斯滤链解释成对距离的累积分布函数；通过布尔运算在单纯形集上恢复标准的t-范数和t-对范数；基于此构建新的降维方法，如使用契赫滤链与三元组采样的推广版本。

Result: 成功将模糊单纯形集与概率模型关联，解释了UMAP中模糊权重的生成机制；阐明了KL散度与模糊交叉熵的关系；恢复了标准的t-范数与t-对范数；并提出了可推广的降维方法，验证了框架的有效性与扩展潜力。

Conclusion: 该概率视角为模糊单纯形集提供了统一的理论基础，不仅解释了现有方法（如UMAP）的内在机制，还为系统设计新型降维算法开辟了路径，具有重要的理论与应用价值。

Abstract: Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.

</details>


### [193] [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044)
*Yizhou Zhao,Zhiwei Steven Wu,Adam Block*

Main category: cs.LG

TL;DR: MarkTune is a novel on-policy fine-tuning framework that enhances watermarking in open-weight language models by treating GaussMark signals as rewards while preserving text quality. It improves the quality-detectability trade-off, resists paraphrasing and fine-tuning attacks, and generalizes well across datasets.


<details>
  <summary>Details</summary>
Motivation: Existing watermarking methods for open-weight models like GaussMark rely on small weight perturbations that often degrade generation quality. There is a need for a method that maintains high detectability without sacrificing text quality.

Method: MarkTune employs a theoretically grounded, on-policy fine-tuning approach that treats the GaussMark signal as a reward signal and uses regularization to prevent quality degradation. It enables finer-grained, watermark-aware weight updates within the model's representation space.

Result: MarkTune significantly improves the quality-detectability trade-off compared to GaussMark, achieves performance close to inference-time watermarking, remains robust against paraphrasing and fine-tuning attacks, and shows strong generalization across unseen datasets.

Conclusion: MarkTune establishes a robust and high-quality watermarking strategy for open-weight language models, offering a practical solution for reliable content authentication in open-source LMs.

Abstract: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

</details>


### [194] [Fare Comparison App of Uber, Ola and Rapido](https://arxiv.org/abs/2512.04065)
*Ashlesha Gopinath Sawant,Sahil S. Jadhav,Vidhan R. Jain,Shriraj S. Jagtap,Prachi Jadhav,Soham Jadhav,Ichha Raina*

Main category: cs.LG

TL;DR: 本项目开发了一个基于Web的应用程序，旨在通过比较Ola、Uber和Rapido在用户输入目的地后的票价，帮助用户选择最经济高效的最佳出行方案。后端使用Python获取数据并实现智能推荐，解决API访问、Android模拟器、Appium及位置比对等挑战，提升用户透明度与乘车体验。


<details>
  <summary>Details</summary>
Motivation: 当前城市交通需求日益增长，用户在选择网约车服务时面临难以判断最佳选项的问题，存在费用高、耗时长等痛点，亟需一个能提供实时对比与最优推荐的工具以提高效率与用户体验。

Method: 采用Python构建后端系统，通过调用各平台的API获取实时票价数据，结合用户输入的目的地进行计算与比对，利用算法筛选出性价比最高的出行方案，并通过Web界面展示结果。同时克服了API调用限制、Android模拟器兼容性、Appium自动化测试及地理位置匹配等技术难题。

Result: 成功实现了一个可运行的网页应用，能够实时比较三家主流网约车平台的费用并推荐最优选项；显著提升了用户决策效率，增强了服务透明度，改善了整体出行体验。

Conclusion: 该系统有效解决了网约车选择中的信息不对称问题，为用户提供科学、高效的出行建议，具备良好的实用价值与推广前景。

Abstract: In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.

</details>


### [195] [Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization](https://arxiv.org/abs/2512.03928)
*Michele Alessi,Alessio Ansuini,Alex Rodriguez*

Main category: cs.LG

TL;DR: DiVAE 是一种轻量级、数据驱动的正则化方法，通过将变分自编码器（VAE）的对数先验概率与从数据中估计的对数密度对齐，改进了标准VAE忽略数据空间密度结构的问题。它在保持低计算开销的同时，通过一个鲁棒且精度加权的惩罚项增强ELBO，使编码器在高密度区域分配更多后验质量，并引导可学习先验趋向高密度区域。在合成数据上，DiVAE 提升了潜在空间密度分布与真实密度的一致性、先验覆盖度以及异常检测的不确定性校准；在MNIST上，它增强了先验与外部密度估计的一致性，提高了可解释性并改善了异常样本检测性能。


<details>
  <summary>Details</summary>
Motivation: 标准VAE使用简单的先验分布，忽略了数据空间中的密度结构，导致潜在表示与真实数据分布不匹配，影响模型的泛化能力和不确定性估计。为解决这一问题，需要一种能够利用数据密度信息来指导潜在空间分布的方法。

Method: 提出Density-Informed VAE (DiVAE)，通过估计数据空间中的密度，构建一个与数据密度对齐的对数先验，并将其作为正则化项加入到变分自编码器的证据下界（ELBO）中。该正则化项采用鲁棒且精度加权的方式，确保在不同密度区域都能有效引导模型学习，同时计算开销极小。

Result: 在合成数据集上，DiVAE 显著提升了潜在空间密度分布与真实密度之间的对齐程度，改善了先验覆盖范围，并在异常检测任务中表现出更好的不确定性校准能力。在MNIST数据集上，其学习到的先验与外部密度估计高度一致，增强了模型可解释性，并显著提升了对异常样本的检测性能。

Conclusion: DiVAE 通过引入数据密度信息作为正则化信号，有效提升了VAE在潜在空间分布建模上的准确性与实用性，尤其在先验设计和异常检测方面表现突出，具有良好的扩展性和实际应用潜力。

Abstract: We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.

</details>


### [196] [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967)
*Keith Ando Ogawa,Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Edson Bollis,Lucas Pellicer,Rosimeire Pereira Costa,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 本文综述了文本数据集压缩（text dataset distillation）领域的过去与最新进展，涵盖不同压缩策略、关键贡献及普遍挑战。尽管该领域已从视觉领域的迁移中发展出独立研究方向，并在使用Transformer模型、生成离散合成文本以及扩展至超10亿参数的解码器模型方面取得显著进展，但目前仍处于成长阶段，面临基准标准化不足、处理文本离散性难题、复杂任务应对能力有限以及真实应用场景缺乏明确案例等问题。


<details>
  <summary>Details</summary>
Motivation: 文本数据集压缩旨在将大规模原始数据集压缩为更小的合成数据集，以实现相似训练效果，但相较于图像领域，文本领域的研究尚不充分，且因文本的离散特性面临独特挑战，亟需系统性梳理与深入探索。

Method: 通过文献回顾与分析，归纳总结文本数据集压缩的不同方法论，包括基于Transformer的模型应用、离散文本生成技术、大规模解码器模型的适配等，并对比其在不同任务中的表现。

Result: 识别出当前文本数据集压缩的关键技术路径与主要瓶颈，指出在基准测试、离散性建模、复杂任务泛化和实际应用等方面仍有较大提升空间。

Conclusion: 尽管文本数据集压缩已取得重要进展，但该领域仍处于发展阶段，未来需加强标准评估体系、优化离散文本生成机制、拓展对复杂任务的支持，并推动在真实场景中的落地应用。

Abstract: In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.

</details>


### [197] [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994)
*Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein*

Main category: cs.LG

TL;DR: 本文提出一种无需训练、高效且轻量的政策违规检测方法，将违规检测视为分布外（OOD）检测问题。通过白化技术对模型隐藏层激活进行线性变换，使其协方差矩阵接近单位阵，进而利用欧氏距离作为合规评分。该方法仅需策略文本和少量示例样本，部署简便，在挑战性基准上表现优于现有守卫机制与微调模型，为组织提供了可落地的AI治理框架。


<details>
  <summary>Details</summary>
Motivation: 企业部署大语言模型于法律、金融、医疗等敏感领域时，需确保其符合内部政策，而现有内容审核框架（如守卫机制）在处理复杂组织政策时能力不足；传统方法如LLM-as-a-judge和微调存在延迟高、不可解释等问题，亟需一种高效、可解释且可靠的政策违规检测方案。

Method: 将政策违规检测建模为分布外（OOD）检测任务，采用白化技术对模型隐藏层激活进行线性变换，使其均值为零、方差为一，协方差矩阵趋近于单位阵；在此变换空间中，以欧氏距离作为合规得分，识别偏离正常行为的潜在违规输入。

Result: 在一项具有挑战性的政策基准测试中，该方法达到当前最优性能，显著优于现有守卫机制和微调推理模型，具备低延迟、高可解释性和强泛化能力。

Conclusion: 本文提出的训练-free白化方法为组织提供了一种轻量、高效、统计基础坚实的政策合规监控手段，推动了可部署的AI治理发展，代码已公开。

Abstract: Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

</details>


### [198] [Physics-Embedded Gaussian Process for Traffic State Estimation](https://arxiv.org/abs/2512.04004)
*Yanlin Chen,Kehua Chen,Yinhai Wang*

Main category: cs.LG

TL;DR: 本文提出一种新型物理嵌入高斯过程（PEGP），用于解决低渗透率和稀疏观测下的交通状态估计问题。通过将经典交通流模型的线性化微分算子显式应用于多输出核构造，设计了PEGP-ARZ和PEGP-LWR两种方法，在HighD和NGSIM数据集上均优于非物理基线模型。PEGP-ARZ在稀疏观测下更可靠，PEGP-LWR在密集观测下误差更低。消融实验表明，PEGP-ARZ残差与物理规律高度一致，不确定性校准良好且可解释；而PEGP-LWR残差更正交，方差近似恒定。该框架有效融合物理先验与不确定性量化，为交通状态估计提供可靠支持。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法缺乏物理解释且泛化能力差，物理模型难以处理不确定性与真实复杂性。现有结合方法依赖惩罚调参，缺乏合理的不确定性校准，对模型误设敏感。因此亟需一种能融合物理知识与数据驱动、具备良好不确定性量化能力的新方法。

Method: 提出物理嵌入高斯过程（PEGP），通过显式应用线性化微分算子构建两个多输出核，分别基于ARZ和LWR交通流模型。利用物理结构作为先验信息嵌入高斯过程，实现物理约束与数据驱动的有机结合。

Result: 在HighD和NGSIM数据集上，PEGP方法显著优于非物理基线模型。PEGP-ARZ在稀疏观测下表现更优，具备更可靠的不确定性估计；PEGP-LWR在密集观测下误差更低，但其残差更正交，方差接近恒定。消融实验验证了物理一致性与不确定性校准的有效性。

Conclusion: 所提出的PEGP框架成功融合了物理先验与数据驱动方法，具备良好的不确定性量化能力，能够有效应对低渗透率和稀疏观测下的交通状态估计挑战，为智能交通系统提供更可靠的技术支持。

Abstract: Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.

</details>


### [199] [Efficient Public Verification of Private ML via Regularization](https://arxiv.org/abs/2512.04008)
*Zoë Ruha Bell,Anvith Thudi,Olive Franzese-McLaughlin,Nicolas Papernot,Shafi Goldwasser*

Main category: cs.LG

TL;DR: 本文提出了一种新的差分隐私（DP）算法，用于差分隐私凸优化（DP-SCO），在保持近似最优隐私-效用权衡的同时，实现了比训练成本更低的验证开销。该方法通过私密最小化一系列正则化目标函数，并仅使用标准的差分隐私组合界来实现，其核心优势在于验证过程所需的计算量远低于训练过程，从而显著降低了大规模数据集上的验证成本。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私模型的验证计算成本与训练成本相当，导致数据提供者和公众难以高效验证模型是否满足隐私保证。因此需要一种既能保证良好隐私-效用平衡，又能降低验证开销的算法。

Method: 采用私密最小化一系列正则化目标函数的方法，结合标准差分隐私组合界，设计出可高效验证的DP-SCO算法。

Result: 所提出的算法实现了近似最优的隐私-效用权衡，且其隐私验证所需的计算成本显著低于训练成本，尤其适用于大规模数据集。

Conclusion: 本研究首次实现了在保持近似最优隐私-效用平衡的前提下，使差分隐私验证成本低于训练成本的DP-SCO算法，为实际应用中隐私保障的可验证性提供了重要突破。

Abstract: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

</details>


### [200] [Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions](https://arxiv.org/abs/2512.04034)
*Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 本文从信息论角度首次理论解释了当前最先进的OOD检测方法在单一领域数据上训练时为何会遭遇灾难性失败。研究证明，单域监督学习不可避免地导致领域特征坍缩（I(x_d; z) = 0），即模型完全丢弃领域特异性信息。这是信息瓶颈优化的固有结果：模型在单域数据（如医学图像）上训练时，仅依赖类别特异性特征而忽略领域特征，从而在检测跨域样本时表现严重下降（如在MNIST上FPR@95仅为53%）。通过Fano不等式扩展分析，量化了实际场景中的部分坍缩现象。作者构建了Domain Bench基准验证理论，并提出通过预训练表示进行领域过滤可保留I(x_d; z) > 0，从而解决该问题。尽管领域过滤概念简单，但其有效性为信息论框架提供了强有力的实证支持。本工作揭示了监督学习在窄域中的根本局限，对迁移学习及微调与冻结预训练模型的选择具有广泛启示。


<details>
  <summary>Details</summary>
Motivation: 解释为什么当前最先进的OOD检测方法在单域数据上训练时会出现灾难性失败，现有方法缺乏理论基础，且现象难以理解。

Method: 基于信息论，通过信息瓶颈理论和Fano不等式分析单域监督学习中领域特征坍缩的机制；构建Domain Bench基准，设计并验证领域过滤策略以保留领域信息。

Result: 证明了单域训练必然导致领域特征坍缩（I(x_d; z) = 0），导致OOD检测性能急剧下降；通过领域过滤保留领域信息后，检测性能显著提升，验证了理论框架的有效性。

Conclusion: 单域监督学习存在根本性缺陷，会导致领域信息丢失，进而引发OOD检测失败。通过保留领域信息（如使用领域过滤），可有效缓解此问题，这对迁移学习、模型微调策略选择具有重要意义。

Abstract: Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

</details>


### [201] [Convergence for Discrete Parameter Updates](https://arxiv.org/abs/2512.04051)
*Paul Wilson,Fabio Zanasi,George Constantinides*

Main category: cs.LG

TL;DR: 本文提出了一种新的低精度训练方法，通过将更新规则本身设计为离散形式，避免了对连续更新进行量化。该方法在理论上具有收敛性保证，并以多项式更新规则为例进行了实证验证，为具有离散结构的模型提供了高效的训练新途径。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型需要大量计算资源，促使研究低精度训练。现有方法通常依赖于对实值更新进行离散化，但存在量化误差问题。本文旨在提出一种从根本上避免量化连续更新的新方法，以提升训练效率和精度。

Method: 提出一种基于离散更新规则的训练方法，不依赖于对连续更新的量化。采用多项式更新规则作为具体实现，并建立了一般离散更新方案的收敛性理论。

Result: 所提出的离散更新方法在理论上具有收敛性保证，并通过实证实验验证了其有效性。该方法在保持模型性能的同时显著降低了计算开销，尤其适用于具有内在离散结构的模型。

Conclusion: 本文提出的离散更新规则为低精度训练提供了一种全新的视角，不仅避免了传统量化带来的误差，还为高效训练开辟了新路径，尤其适合具有离散特性的模型架构。

Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.

</details>


### [202] [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062)
*Florian Bordes,Candace Ross,Justine T Kao,Evangelia Spiliopoulou,Adina Williams*

Main category: cs.LG

TL;DR: 本文提出Eval Factsheets，一种用于系统化记录AI评估方法的结构化文档框架，旨在解决评估缺乏标准化文档的问题。该框架涵盖上下文、范围、结构、方法和对齐五个维度，并通过问卷形式实现可操作性。案例研究显示其能有效捕捉多样化的评估范式，提升透明度与可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前评估基准快速增多，但缺乏像数据集和模型那样有结构的文档标准，导致可复现性、透明度和决策质量受损。亟需一套系统化的评估文档规范。

Method: 提出包含五个维度（上下文、范围、结构、方法、对齐）的Eval Factsheets框架，并设计一个分五部分的问卷，包含必填与建议项，以系统化记录评估信息。

Result: 在多个基准的案例研究中验证了Eval Factsheets的有效性，能够一致且可比较地描述从传统基准到LLM作为评判者等不同评估范式。

Conclusion: Eval Factsheets为评估方法提供了标准化文档路径，有助于提升评估透明度、可复现性和跨基准比较能力，应被广泛采纳于现有及新发布的评估框架中。

Abstract: The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.

</details>
