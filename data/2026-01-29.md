<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 48]
- [cs.CL](#cs.CL) [Total: 55]
- [cs.LG](#cs.LG) [Total: 86]
- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Size Matters: Reconstructing Real-Scale 3D Models from Monocular Images for Food Portion Estimation](https://arxiv.org/abs/2601.20051)
*Gautham Vinod,Bruce Coburn,Siddeshwar Raghavan,Jiangpeng He,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种从单目图像中恢复真实尺度3D重建物体的方法，以解决饮食摄入量精确评估中的份量估计难题。该方法利用大规模数据集训练的模型提取丰富的视觉特征来估计重建物体的真实尺度，从而将单视图3D重建转化为具有物理意义的真实尺寸模型。在两个公开数据集上的大量实验和消融研究显示，该方法显著优于现有技术，平均绝对体积估计误差降低近30%，展现出在精准营养领域的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 当前饮食摄入监测面临的关键挑战是：从单目图像中准确恢复食物的份量（体积）信息，而现有的3D重建方法虽能实现良好的几何结构重建，却无法恢复真实世界尺度，限制了其在精准营养中的应用。因此，迫切需要一种能够恢复真实尺度的3D重建方法。

Method: 提出了一种基于深度学习的单目图像3D重建方法，通过使用在大规模数据集上预训练的视觉模型提取丰富特征，用于估计重建物体的真实尺度，并将该尺度信息融入3D重建过程中，实现真正符合物理尺度的三维建模。

Result: 在两个公开数据集上的实验结果表明，该方法在体积估计方面显著优于现有方法，平均绝对体积估计误差减少约30%，证明了其在提升饮食摄入量评估精度方面的有效性。

Conclusion: 本研究成功实现了从单目图像中恢复真实尺度的3D食物重建，为精准营养领域提供了更可靠的饮食评估工具，具有重要的临床与应用价值。

Abstract: The rise of chronic diseases related to diet, such as obesity and diabetes, emphasizes the need for accurate monitoring of food intake. While AI-driven dietary assessment has made strides in recent years, the ill-posed nature of recovering size (portion) information from monocular images for accurate estimation of ``how much did you eat?'' is a pressing challenge. Some 3D reconstruction methods have achieved impressive geometric reconstruction but fail to recover the crucial real-world scale of the reconstructed object, limiting its usage in precision nutrition. In this paper, we bridge the gap between 3D computer vision and digital health by proposing a method that recovers a true-to-scale 3D reconstructed object from a monocular image. Our approach leverages rich visual features extracted from models trained on large-scale datasets to estimate the scale of the reconstructed object. This learned scale enables us to convert single-view 3D reconstructions into true-to-life, physically meaningful models. Extensive experiments and ablation studies on two publicly available datasets show that our method consistently outperforms existing techniques, achieving nearly a 30% reduction in mean absolute volume-estimation error, showcasing its potential to enhance the domain of precision nutrition. Code: https://gitlab.com/viper-purdue/size-matters

</details>


### [2] [DiSa: Saliency-Aware Foreground-Background Disentangled Framework for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2601.20064)
*Zhen Yao,Xin Li,Taotao Jing,Shuai Zhang,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: DiSa提出了一种新颖的显著性感知前景-背景解耦框架，以解决视觉语言模型在开放词汇语义分割中因显著性偏差和空间定位能力不足导致的性能问题。通过设计显著性感知解耦模块（SDM）和分层精炼模块（HRM），DiSa分别建模前景与背景特征，并利用像素级空间上下文和多层级特征更新实现更精确的边界分割。在六个基准测试中，DiSa均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（如CLIP）的开放词汇语义分割方法存在前景偏差（忽略背景区域）和空间定位能力弱（边界模糊）的问题，限制了其在复杂场景中的表现。

Method: 提出DiSa框架，包含两个核心模块：1）显著性感知解耦模块（SDM），通过引入显著性线索，将前景与背景特征进行分离建模；2）分层精炼模块（HRM），利用像素级空间上下文和多层级通道特征更新，提升分割精度与边界清晰度。

Result: 在六个公开基准数据集上，DiSa在多个指标上均取得领先结果，显著优于当前最先进的方法，尤其在复杂场景下的背景分割和边界保持方面表现突出。

Conclusion: DiSa通过显式建模显著性并解耦前景与背景特征，有效缓解了视觉语言模型在开放词汇语义分割中的固有缺陷，为未来开放词汇图像理解提供了新的技术路径。

Abstract: Open-vocabulary semantic segmentation aims to assign labels to every pixel in an image based on text labels. Existing approaches typically utilize vision-language models (VLMs), such as CLIP, for dense prediction. However, VLMs, pre-trained on image-text pairs, are biased toward salient, object-centric regions and exhibit two critical limitations when adapted to segmentation: (i) Foreground Bias, which tends to ignore background regions, and (ii) Limited Spatial Localization, resulting in blurred object boundaries. To address these limitations, we introduce DiSa, a novel saliency-aware foreground-background disentangled framework. By explicitly incorporating saliency cues in our designed Saliency-aware Disentanglement Module (SDM), DiSa separately models foreground and background ensemble features in a divide-and-conquer manner. Additionally, we propose a Hierarchical Refinement Module (HRM) that leverages pixel-wise spatial contexts and enables channel-wise feature refinement through multi-level updates. Extensive experiments on six benchmarks demonstrate that DiSa consistently outperforms state-of-the-art methods.

</details>


### [3] [Sparse CLIP: Co-Optimizing Interpretability and Performance in Contrastive Learning](https://arxiv.org/abs/2601.20075)
*Chuan Qin,Constantin Venhoff,Sonia Joseph,Fanyi Xiao,Stefan Scherer*

Main category: cs.CV

TL;DR: 本文提出一种将稀疏性直接整合到CLIP训练中的方法，生成既可解释又高性能的表示。与后处理的稀疏自编码器（SAEs）相比，该方法在保持下游任务性能的同时，提升了可解释性并保留了多模态能力。研究揭示了跨模态知识的形成机制，并展示了基于稀疏CLIP表示的视觉语言模型具备可解释的视觉引导控制能力，挑战了可解释性与性能不可兼得的传统观念。


<details>
  <summary>Details</summary>
Motivation: CLIP虽成功但其密集且不透明的潜在表示带来可解释性挑战；传统认为可解释性与性能存在权衡，现有后处理方法如SAEs常导致性能下降且丧失多模态能力，因此亟需一种能同时优化可解释性与性能的训练策略。

Method: 在CLIP训练过程中直接引入稀疏性约束，通过设计稀疏正则化机制使模型学习稀疏且有意义的特征表示，从而实现可解释性与性能的协同优化。

Result: 所提出的稀疏CLIP在下游任务中表现优异，显著提升可解释性，保留多模态特性，实现了语义概念的清晰对齐，并揭示了跨模态知识的训练动态；基于此构建的视觉语言模型支持可解释的视觉引导控制。

Conclusion: 可解释性与性能并非必然冲突，通过在训练阶段集成稀疏性，可实现两者的共同优化，为未来多模态模型的设计提供了新范式。

Abstract: Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in vision-language representation learning, powering diverse downstream tasks and serving as the default vision backbone in multimodal large language models (MLLMs). Despite its success, CLIP's dense and opaque latent representations pose significant interpretability challenges. A common assumption is that interpretability and performance are in tension: enforcing sparsity during training degrades accuracy, motivating recent post-hoc approaches such as Sparse Autoencoders (SAEs). However, these post-hoc approaches often suffer from degraded downstream performance and loss of CLIP's inherent multimodal capabilities, with most learned features remaining unimodal.
  We propose a simple yet effective approach that integrates sparsity directly into CLIP training, yielding representations that are both interpretable and performant. Compared to SAEs, our Sparse CLIP representations preserve strong downstream task performance, achieve superior interpretability, and retain multimodal capabilities. We show that multimodal sparse features enable straightforward semantic concept alignment and reveal training dynamics of how cross-modal knowledge emerges. Finally, as a proof of concept, we train a vision-language model on sparse CLIP representations that enables interpretable, vision-based steering capabilities. Our findings challenge conventional wisdom that interpretability requires sacrificing accuracy and demonstrate that interpretability and performance can be co-optimized, offering a promising design principle for future models.

</details>


### [4] [NucFuseRank: Dataset Fusion and Performance Ranking for Nuclei Instance Segmentation](https://arxiv.org/abs/2601.20104)
*Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Sepideh Hatamikia,Diana Mechtcheriakova,Amirreza Mahbod*

Main category: cs.CV

TL;DR: 本文聚焦于核实例分割任务中的数据集问题，而非模型开发。通过文献综述识别并标准化了多个公开的H&E染色图像数据集，构建了统一测试集（NucFuse-test）和训练集（NucFuse-train），利用两种先进模型系统评估并排名各数据集性能，提出了一套新的基准以支持更公平、高效的模型训练与评估。


<details>
  <summary>Details</summary>
Motivation: 当前核实例分割研究多集中于新算法开发，而忽视了数据集的标准化与可比性，导致模型评估缺乏一致性。为解决这一问题，需建立统一的数据标准与评估基准。

Method: 通过文献回顾筛选公开手动标注的H&E图像数据集，将其统一为标准格式；采用基于CNN和混合CNN-视觉变压器的两种先进模型进行系统评估；构建统一测试集（NucFuse-test）与训练集（NucFuse-train）以提升性能与公平比较。

Result: 成功构建了可复用的统一数据集框架，实现了跨数据集的公平评估；发现不同数据集在分割性能上存在显著差异；融合数据集后模型性能得到提升；提供了可公开访问的实现代码与基准。

Conclusion: 本研究为H&E染色图像中的核实例分割任务建立了新的基准，推动了该领域数据集标准化与模型评估的规范化发展。

Abstract: Nuclei instance segmentation in hematoxylin and eosin (H&E)-stained images plays an important role in automated histological image analysis, with various applications in downstream tasks. While several machine learning and deep learning approaches have been proposed for nuclei instance segmentation, most research in this field focuses on developing new segmentation algorithms and benchmarking them on a limited number of arbitrarily selected public datasets.
  In this work, rather than focusing on model development, we focused on the datasets used for this task. Based on an extensive literature review, we identified manually annotated, publicly available datasets of H&E-stained images for nuclei instance segmentation and standardized them into a unified input and annotation format. Using two state-of-the-art segmentation models, one based on convolutional neural networks (CNNs) and one based on a hybrid CNN and vision transformer architecture, we systematically evaluated and ranked these datasets based on their nuclei instance segmentation performance. Furthermore, we proposed a unified test set (NucFuse-test) for fair cross-dataset evaluation and a unified training set (NucFuse-train) for improved segmentation performance by merging images from multiple datasets.
  By evaluating and ranking the datasets, performing comprehensive analyses, generating fused datasets, conducting external validation, and making our implementation publicly available, we provided a new benchmark for training, testing, and evaluating nuclei instance segmentation models on H&E-stained histological images.

</details>


### [5] [Look in the Middle: Structural Anchor Pruning for Scalable Visual RAG Indexing](https://arxiv.org/abs/2601.20107)
*Zhuchenyang Liu,Ziyu Hu,Yao Zhang,Yu Xiao*

Main category: cs.CV

TL;DR: 提出了一种无需训练的剪枝方法SAP，通过识别中间层的关键视觉块，在保持高检索精度的同时将索引向量减少超过90%，并引入OSR协议分析层间信息对压缩效率的影响。


<details>
  <summary>Details</summary>
Motivation: 现有无训练剪枝方法在高压缩率下性能下降，且传统方法依赖最终层特征，而结构信号在此处已衰减，因此需要一种能捕捉持久结构信息的新方法。

Method: 提出Structural Anchor Pruning (SAP)，从中间层识别关键视觉块进行剪枝，并设计Oracle Score Retention (OSR)协议评估不同层的信息保留能力。

Result: 在ViDoRe基准上，SAP实现超过90%的索引向量压缩，同时保持优异的检索保真度，证明其在视觉文档检索中的高效与可扩展性。

Conclusion: 中间层包含持久的语义结构锚点，是实现高效率、高保真无训练剪枝的关键，SAP为视觉RAG提供了可行且高效的解决方案。

Abstract: Recent Vision-Language Models (e.g., ColPali) enable fine-grained Visual Document Retrieval (VDR) but incur prohibitive index vector size overheads. Training-free pruning solutions (e.g., EOS-attention based methods) can reduce index vector size by approximately 60% without model adaptation, but often underperform random selection in high-compression scenarios (> 80%). Prior research (e.g., Light-ColPali) attributes this to the conclusion that visual token importance is inherently query-dependent, thereby questioning the feasibility of training-free pruning. In this work, we propose Structural Anchor Pruning (SAP), a training-free pruning method that identifies key visual patches from middle layers to achieve high performance compression. We also introduce Oracle Score Retention (OSR) protocol to evaluate how layer-wise information affects compression efficiency. Evaluations on the ViDoRe benchmark demonstrate that SAP reduces index vectors by over 90% while maintaining robust retrieval fidelity, providing a highly scalable solution for Visual RAG. Furthermore, our OSR-based analysis reveals that semantic structural anchor patches persist in the middle layers, unlike traditional pruning solutions that focus on the final layer where structural signals dissipate.

</details>


### [6] [Efficient Token Pruning for LLaDA-V](https://arxiv.org/abs/2601.20168)
*Zhewen Wan,Tianchen Song,Chen Lin,Zhiyong Zhao,Xianpeng Lang*

Main category: cs.CV

TL;DR: 本文针对基于扩散的大型多模态模型LLaDA-V计算开销大的问题，提出一种结构化视觉标记剪枝策略。通过分析发现其跨模态信息聚合主要集中在中后期层，因此提出在首个去噪步骤的中后期层进行剪枝，以减少计算量并保持性能。该方法是首个应用于扩散型多模态模型的结构化剪枝工作，相比FastV更聚焦于中后期层，有效降低后续步骤的计算负担。实验表明，该方法可将计算成本降低高达65%，同时保持平均95%的任务性能。


<details>
  <summary>Details</summary>
Motivation: LLaDA-V等基于扩散的多模态模型因双向注意力机制和迭代去噪过程导致计算开销大，且跨模态信息在中后期层才充分聚合，存在延迟对齐问题。为提升效率，需在不损失关键语义的前提下减少冗余计算。

Method: 提出一种基于视觉感知的结构化标记剪枝策略，针对性地在首个去噪步骤的中后期层移除部分视觉标记，以减少计算量；该策略与模型的延迟注意力聚合特性相匹配，避免早期剪枝带来的性能下降。

Result: 在多个基准测试上，最优配置下计算成本降低最高达65%，平均任务性能保持在95%以上，验证了剪枝策略的有效性与高效性。

Conclusion: 本研究首次探索了扩散型多模态模型中的结构化标记剪枝，揭示了中后期层在跨模态信息聚合中的关键作用，并提出了与之匹配的剪枝策略，为高效推理提供了新思路，展示了视觉感知剪枝在该类模型中的巨大潜力。

Abstract: Diffusion-based large multimodal models, such as LLaDA-V, have demonstrated impressive capabilities in vision-language understanding and generation. However, their bidirectional attention mechanism and diffusion-style iterative denoising paradigm introduce significant computational overhead, as visual tokens are repeatedly processed across all layers and denoising steps. In this work, we conduct an in-depth attention analysis and reveal that, unlike autoregressive decoders, LLaDA-V aggregates cross-modal information predominantly in middle-to-late layers, leading to delayed semantic alignment. Motivated by this observation, we propose a structured token pruning strategy inspired by FastV, selectively removing a proportion of visual tokens at designated layers to reduce FLOPs while preserving critical semantic information. To the best of our knowledge, this is the first work to investigate structured token pruning in diffusion-based large multimodal models. Unlike FastV, which focuses on shallow-layer pruning, our method targets the middle-to-late layers of the first denoising step to align with LLaDA-V's delayed attention aggregation to maintain output quality, and the first-step pruning strategy reduces the computation across all subsequent steps. Our framework provides an empirical basis for efficient LLaDA-V inference and highlights the potential of vision-aware pruning in diffusion-based multimodal models. Across multiple benchmarks, our best configuration reduces computational cost by up to 65% while preserving an average of 95% task performance.

</details>


### [7] [TeleStyle: Content-Preserving Style Transfer in Images and Videos](https://arxiv.org/abs/2601.20175)
*Shiwen Zhang,Xiaoyan Yang,Bojia Zi,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleStyle 是一种轻量级但高效的图像和视频风格化模型，基于 Qwen-Image-Edit 构建，通过结合高质量的定制风格数据与大量合成风格三元组，采用课程持续学习框架进行训练，实现对未见风格的良好泛化能力，同时保持内容精确保真。引入视频到视频风格化模块以提升时序一致性与视觉质量，在风格相似性、内容一致性和美学质量三项核心指标上达到当前最优表现。代码与预训练模型已开源。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers (DiTs) 在内容与风格特征上存在固有纠缠问题，导致内容保真度与风格迁移效果难以兼顾；现有方法在处理未见风格时泛化能力不足，且视频风格化中存在时序不一致问题，亟需一种高效、通用且能保持高保真内容还原的风格迁移方法。

Method: TeleStyle 采用基于 Qwen-Image-Edit 的基础架构，构建包含真实与合成风格的混合数据集，设计课程持续学习（Curriculum Continual Learning）训练策略，有效融合干净与噪声数据；引入视频到视频风格化模块，增强时间连贯性与视觉质量。

Result: 在三个核心评估指标（风格相似性、内容一致性、美学质量）上均达到当前最佳性能，显著优于现有方法，尤其在未见风格泛化方面表现突出。

Conclusion: TeleStyle 成功解决了 DiT 模型在内容-风格解耦上的挑战，实现了高质量、高保真的图像与视频风格迁移，具备良好的泛化能力与实用性，为未来多模态风格迁移提供了新范式。

Abstract: Content-preserving style transfer, generating stylized outputs based on content and style references, remains a significant challenge for Diffusion Transformers (DiTs) due to the inherent entanglement of content and style features in their internal representations. In this technical report, we present TeleStyle, a lightweight yet effective model for both image and video stylization. Built upon Qwen-Image-Edit, TeleStyle leverages the base model's robust capabilities in content preservation and style customization. To facilitate effective training, we curated a high-quality dataset of distinct specific styles and further synthesized triplets using thousands of diverse, in-the-wild style categories. We introduce a Curriculum Continual Learning framework to train TeleStyle on this hybrid dataset of clean (curated) and noisy (synthetic) triplets. This approach enables the model to generalize to unseen styles without compromising precise content fidelity. Additionally, we introduce a video-to-video stylization module to enhance temporal consistency and visual quality. TeleStyle achieves state-of-the-art performance across three core evaluation metrics: style similarity, content consistency, and aesthetic quality. Code and pre-trained models are available at https://github.com/Tele-AI/TeleStyle

</details>


### [8] [DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment](https://arxiv.org/abs/2601.20218)
*Haoyou Deng,Keyu Yan,Chaojie Mao,Xiang Wang,Yu Liu,Changxin Gao,Nong Sang*

Main category: cs.CV

TL;DR: DenseGRPO提出了一种新的框架，通过引入密集奖励来解决基于GRPO的文本到图像生成中稀疏奖励问题。该方法通过预测每一步的奖励增益作为中间步骤的密集奖励，并利用基于ODE的方法对中间干净图像进行评分，从而实现反馈信号与各步骤贡献之间的对齐。此外，还提出了一种奖励感知的探索空间校准机制，自适应调整SDE采样器中的时间步特定随机性注入，以确保在所有时间步上都有合适的探索空间。实验表明，该方法在多个标准基准测试中均表现出色，证明了有效密集奖励在流匹配模型对齐中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的文本到图像生成方法虽然在人类偏好对齐方面取得了显著进展，但仍面临稀疏奖励问题：整个去噪轨迹的终端奖励被应用于所有中间步骤，导致全局反馈信号与中间步骤的细粒度贡献不匹配。为解决这一问题，需要更精细的奖励机制来准确反映每一步的贡献。

Method: 提出一种名为DenseGRPO的新框架，包含两个核心组件：(1) 采用基于ODE的方法，对中间干净图像应用奖励模型，预测每一步的奖励增益，作为该步骤的密集奖励；(2) 发现现有方法中均匀探索设置与随时间变化的噪声强度之间存在不匹配，因此提出奖励感知的探索空间校准方案，通过自适应调整SDE采样器中每个时间步的随机性注入，优化探索空间。

Result: 在多个标准基准测试上的大量实验验证了DenseGRPO的有效性，结果表明，使用有效的密集奖励能够显著提升流匹配模型与人类偏好的对齐效果，且所提出的探索空间校准机制有助于改善训练稳定性与生成质量。

Conclusion: DenseGRPO通过引入密集奖励和奖励感知的探索空间校准机制，有效解决了传统GRPO方法中的稀疏奖励问题，显著提升了文本到图像生成中的人类偏好对齐能力，为未来基于强化学习的生成模型设计提供了新思路。

Abstract: Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem: the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce \textbf{DenseGRPO}, a novel framework that aligns human preference with dense rewards, which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach. This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards, a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space. Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler, ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.

</details>


### [9] [Feature Projection Learning for Better Vision-Language Reasoning](https://arxiv.org/abs/2601.20224)
*Yi Zhang,Weicheng Lin,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: FPL is a novel, efficient method that transforms classification into feature projection, achieving state-of-the-art performance with low computational cost and minimal parameters.


<details>
  <summary>Details</summary>
Motivation: Existing methods for adapting Vision-Language Pre-Trained models like CLIP to downstream tasks face issues such as limited performance, high parameter count, and long training times.

Method: Proposes FPL (Feature Projection Learning), a simple yet efficient method that uses a projection model to map class prototype features into the query image feature space and reconstruct the image feature map. Classification is redefined as a feature projection task using negative average squared reconstruction error as the class score.

Result: FPL achieves superior accuracy compared to state-of-the-art methods, demonstrating significant improvements in performance while maintaining efficiency.

Conclusion: FPL effectively adapts CLIP models to downstream tasks with minimal overhead, offering a highly efficient and accurate solution for vision-language transfer learning.

Abstract: Vision-Language Pre-Trained models, notably CLIP, that utilize contrastive learning have proven highly adept at extracting generalizable visual features. To inherit the well-learned knowledge of VLP models for downstream tasks, several approaches aim to adapt them efficiently with limited supervision. However, these methods either suffer from limited performance, excessive learnable parameters, or extended training times, all of which hinder their effectiveness in adapting the CLIP model to downstream tasks. In this work, we propose a simple yet efficient and effective method called \textit{\textbf{F}eature \textbf{P}rojection \textbf{L}earning(FPL)} to address these problems. Specifically, we develop a projection model that projects class prototype features into the query image feature space and reconstructs the query image feature map. The negative average squared reconstruction error is used as the class score. In this way, we transform the classification problem into a feature projection problem. The final output of this method is a combination of the prediction from the projection model and the original pre-trained CLIP. Comprehensive empirical evaluations confirm that FPL delivers superior accuracy, surpassing the current state-of-the-art methods by a substantial margin.

</details>


### [10] [Reversible Efficient Diffusion for Image Fusion](https://arxiv.org/abs/2601.20260)
*Xingxin Xu,Bing Cao,DongDong Li,Qinghua Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出Reversible Efficient Diffusion（RED）模型，通过显式监督训练解决扩散模型在图像融合中细节丢失和计算效率低的问题，避免分布估计，提升融合图像的细节保留与视觉质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像融合中因马尔可夫过程中的噪声累积导致细节损失和结果退化，而端到端训练中的显式监督又面临计算效率挑战。

Method: 设计可逆高效扩散框架，采用显式监督训练，避免传统扩散模型对分布估计的依赖，提升生成效率与融合质量。

Result: RED模型在多模态图像融合任务中有效保留了细节信息，提升了视觉保真度，并显著改善了计算效率。

Conclusion: RED模型成功结合了扩散模型的强大生成能力与显式监督的优势，在不依赖分布估计的前提下实现了高效且高质量的图像融合。

Abstract: Multi-modal image fusion aims to consolidate complementary information from diverse source images into a unified representation. The fused image is expected to preserve fine details and maintain high visual fidelity. While diffusion models have demonstrated impressive generative capabilities in image generation, they often suffer from detail loss when applied to image fusion tasks. This issue arises from the accumulation of noise errors inherent in the Markov process, leading to inconsistency and degradation in the fused results. However, incorporating explicit supervision into end-to-end training of diffusion-based image fusion introduces challenges related to computational efficiency. To address these limitations, we propose the Reversible Efficient Diffusion (RED) model - an explicitly supervised training framework that inherits the powerful generative capability of diffusion models while avoiding the distribution estimation.

</details>


### [11] [A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency](https://arxiv.org/abs/2601.20284)
*Debopom Sutradhar,Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Reem E. Mohamed,Sami Azam*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的无源域适应方法，通过多视图增强和潜在空间一致性技术，直接从目标域学习域不变特征，无需访问源域数据或复杂的伪标签技术。该方法通过在潜在空间中最小化多个增强视图之间的特征表示距离，实现特征一致性，同时采用基于ConvNeXt的编码器和结合分类与一致性目标的损失函数，有效提升模型性能。在Office-31、Office-Home和Office-Caltech数据集上分别达到90.72%、84%和97.12%的平均分类准确率，并分别优于现有方法1.23%、7.26%和1.77%。


<details>
  <summary>Details</summary>
Motivation: 现有域适应方法通常需要源域数据访问、对抗训练或复杂的伪标签技术，计算成本高且限制实际应用。为解决这些问题，亟需一种仅依赖目标域数据即可实现高效域适应的新方法。

Method: 提出一种基于多视图增强和潜在空间一致性的无源域适应方法，通过生成目标域数据的多个增强视图，强制其在潜在空间中的特征表示保持一致；设计基于ConvNeXt的编码器与联合分类与一致性损失函数，实现仅从目标域学习可迁移特征。

Result: 在Office-31、Office-Home和Office-Caltech数据集上分别取得90.72%、84%和97.12%的平均分类准确率，相比现有方法分别提升1.23%、7.26%和1.77%。

Conclusion: 所提方法首次实现仅依赖目标域数据进行域适应，通过多视图一致性和高效编码器设计，在多个基准数据集上显著超越已有方法，具备良好的实用性和可扩展性。

Abstract: Domain adaptation (DA) addresses the challenge of transferring knowledge from a source domain to a target domain where image data distributions may differ. Existing DA methods often require access to source domain data, adversarial training, or complex pseudo-labeling techniques, which are computationally expensive. To address these challenges, this paper introduces a novel source-free domain adaptation method. It is the first approach to use multiview augmentation and latent space consistency techniques to learn domain-invariant features directly from the target domain. Our method eliminates the need for source-target alignment or pseudo-label refinement by learning transferable representations solely from the target domain by enforcing consistency between multiple augmented views in the latent space. Additionally, the method ensures consistency in the learned features by generating multiple augmented views of target domain data and minimizing the distance between their feature representations in the latent space. We also introduce a ConvNeXt-based encoder and design a loss function that combines classification and consistency objectives to drive effective adaptation directly from the target domain. The proposed model achieves an average classification accuracy of 90. 72\%, 84\%, and 97. 12\% in Office-31, Office-Home and Office-Caltech datasets, respectively. Further evaluations confirm that our study improves existing methods by an average classification accuracy increment of +1.23\%, +7.26\%, and +1.77\% on the respective datasets.

</details>


### [12] [Artifact-Aware Evaluation for High-Quality Video Generation](https://arxiv.org/abs/2601.20297)
*Chen Zhu,Jiashu Zhu,Yanxun Li,Meiqi Wu,Bingze Song,Chubin Chen,Jiahong Wu,Xiangxiang Chu,Yangang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种针对视频生成质量的综合评估协议，聚焦于影响人类感知的三个关键维度：外观、运动和相机。通过定义10种常见的生成失败类别构成分类体系，并构建了包含8万段视频的大型数据集GenVID，每段视频均经过精细标注。基于该数据集，提出了DVAR框架，用于细粒度识别与分类生成伪影。实验表明，该方法显著提升了伪影检测精度，有效实现了低质量内容的过滤。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成评估方法仅提供粗粒度的质量评分，缺乏对具体伪影的定位与分类能力，难以满足对生成视频质量精细化评估的需求。

Method: 提出三轴评估框架（外观、运动、相机），建立10类常见伪影的分类体系；构建大规模标注数据集GenVID（80k视频）；设计DVAR框架实现细粒度伪影识别与分类。

Result: DVAR在伪影检测任务中表现优异，显著提升检测准确率，并能有效识别和过滤低质量生成视频。

Conclusion: 本文提出的评估协议与DVAR框架为生成视频的质量评估提供了系统化、细粒度的解决方案，推动了视频生成技术的可信评估与应用落地。

Abstract: With the rapid advancement of video generation techniques, evaluating and auditing generated videos has become increasingly crucial. Existing approaches typically offer coarse video quality scores, lacking detailed localization and categorization of specific artifacts. In this work, we introduce a comprehensive evaluation protocol focusing on three key aspects affecting human perception: Appearance, Motion, and Camera. We define these axes through a taxonomy of 10 prevalent artifact categories reflecting common generative failures observed in video generation. To enable robust artifact detection and categorization, we introduce GenVID, a large-scale dataset of 80k videos generated by various state-of-the-art video generation models, each carefully annotated for the defined artifact categories. Leveraging GenVID, we develop DVAR, a Dense Video Artifact Recognition framework for fine-grained identification and classification of generative artifacts. Extensive experiments show that our approach significantly improves artifact detection accuracy and enables effective filtering of low-quality content.

</details>


### [13] [Towards Compact and Robust DNNs via Compression-aware Sharpness Minimization](https://arxiv.org/abs/2601.20301)
*Jialuo He,Huangxun Chen*

Main category: cs.CV

TL;DR: C-SAM提出了一种新的压缩感知尖锐度最小化方法，通过在训练中对剪枝掩码进行扰动，使模型在结构变化下保持平坦的损失景观，从而在保持紧凑性的同时提升对输入变化的鲁棒性。实验表明，C-SAM在多个数据集和模型上显著提升了认证鲁棒性（最高达42%），同时保持与未剪枝模型相当的任务准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法如SAM虽能提升DNN对输入变化的鲁棒性，但在与模型压缩（如剪枝）结合时存在缺陷：剪枝后应用SAM受限于早期剪枝模式，而先剪枝再应用SAM则可能破坏由连续参数空间中的平坦性带来的鲁棒性。因此需要一种能够联合优化剪枝结构与鲁棒性的新方法。

Method: 提出C-SAM框架，将传统的参数扰动改为掩码扰动，即在训练过程中对剪枝掩码施加扰动，使损失函数在模型结构变化下趋于平坦，从而发现既能保持紧凑性又能增强鲁棒性的剪枝模式。

Result: 在CelebA-HQ、Flowers-102和CIFAR-10-C等多个数据集上，使用ResNet-18、GoogLeNet和MobileNet-V2等模型进行实验，C-SAM在保持任务准确率接近未剪枝模型的前提下，显著提升了认证鲁棒性，最高提升达42%。

Conclusion: C-SAM通过掩码扰动实现了对模型结构的尖锐度感知学习，有效解决了剪枝与鲁棒性之间的矛盾，在保证模型紧凑性的同时大幅增强了对输入扰动的鲁棒性，是面向边缘设备部署的理想选择。

Abstract: Sharpness-Aware Minimization (SAM) has recently emerged as an effective technique for improving DNN robustness to input variations. However, its interplay with the compactness requirements of on-device DNN deployments remains less explored. Simply pruning a SAM-trained model can undermine robustness, since flatness in the continuous parameter space does not necessarily translate to robustness under the discrete structural changes induced by pruning. Conversely, applying SAM after pruning may be fundamentally constrained by architectural limitations imposed by an early, robustness-agnostic pruning pattern. To address this gap, we propose Compression-aware ShArpness Minimization (C-SAM), a framework that shifts sharpness-aware learning from parameter perturbations to mask perturbations. By explicitly perturbing pruning masks during training, C-SAM promotes a flatter loss landscape with respect to model structure, enabling the discovery of pruning patterns that simultaneously optimize model compactness and robustness to input variations. Extensive experiments on CelebA-HQ, Flowers-102, and CIFAR-10-C across ResNet-18, GoogLeNet, and MobileNet-V2 show that C-SAM consistently achieves higher certified robustness than strong baselines, with improvements of up to 42%, while maintaining task accuracy comparable to the corresponding unpruned models.

</details>


### [14] [Bridging the Applicator Gap with Data-Doping:Dual-Domain Learning for Precise Bladder Segmentation in CT-Guided Brachytherapy](https://arxiv.org/abs/2601.20302)
*Suresh Das,Siladittya Manna,Sayantari Ghosh*

Main category: cs.CV

TL;DR: 本文研究了在医学图像分割中因协变量偏移导致的性能退化问题，提出一种双域学习策略，利用大量无施源器（NA）CT数据与少量有施源器（WA）CT数据相结合，以提升模型在分布偏移下的鲁棒性和泛化能力。实验表明，仅用10-30%的WA数据掺杂于主要NA数据中，即可达到与纯WA数据训练模型相当的分割性能，Dice系数最高达0.94，IoU最高达0.92，显著提升了膀胱分割的临床可靠性。


<details>
  <summary>Details</summary>
Motivation: 在妇科腔内放疗中，带施源器的CT扫描（WA）数据稀缺且存在显著解剖形变和成像伪影，导致自动分割困难；而无施源器的CT数据（NA）虽易获取但分布不同，如何有效利用有限的WA数据与大量NA数据协同训练，是提升模型泛化能力的关键挑战。

Method: 提出双域学习策略，将大规模的NA数据与少量的WA数据混合训练，通过系统性实验在轴向、冠状面和矢状面三个方向上验证多种深度学习架构的性能，评估不同比例WA数据掺杂的效果。

Result: 掺入10%-30%的WA数据即可实现与全WA数据训练模型相当的分割性能，获得高达0.94的Dice系数和0.92的IoU，证明该方法能有效缓解数据稀缺与分布偏移问题。

Conclusion: 将解剖结构相似但分布不同的数据集（如NA与WA CT）进行融合训练，可显著提升深度学习模型在数据稀缺场景下的分割性能，为放疗计划中的器官分割提供了高效可靠的解决方案。

Abstract: Performance degradation due to covariate shift remains a major challenge for deep learning models in medical image segmentation. An open question is whether samples from a shifted distribution can effectively support learning when combined with limited target domain data. We investigate this problem in the context of bladder segmentation in CT guided gynecological brachytherapy, a critical task for accurate dose optimization and organ at risk sparing. While CT scans without brachytherapy applicators (no applicator: NA) are widely available, scans with applicators inserted (with applicator: WA) are scarce and exhibit substantial anatomical deformation and imaging artifacts, making automated segmentation particularly difficult.
  We propose a dual domain learning strategy that integrates NA and WA CT data to improve robustness and generalizability under covariate shift. Using a curated assorted dataset, we show that NA data alone fail to capture the anatomical and artifact related characteristics of WA images. However, introducing a modest proportion of WA data into a predominantly NA training set leads to significant performance improvements. Through systematic experiments across axial, coronal, and sagittal planes using multiple deep learning architectures, we demonstrate that doping only 10 to 30 percent WA data achieves segmentation performance comparable to models trained exclusively on WA data.
  The proposed approach attains Dice similarity coefficients of up to 0.94 and Intersection over Union scores of up to 0.92, indicating effective domain adaptation and improved clinical reliability. This study highlights the value of integrating anatomically similar but distribution shifted datasets to overcome data scarcity and enhance deep learning based segmentation for brachytherapy treatment planning.

</details>


### [15] [Physically Guided Visual Mass Estimation from a Single RGB Image](https://arxiv.org/abs/2601.20303)
*Sungjae Lee,Junhan Jeong,Yeonjoo Hong,Kwang In Kim*

Main category: cs.CV

TL;DR: 本文提出一种物理结构化的单图像质量估计框架，通过结合三维几何、材料语义和外观信息，利用实例自适应门控机制融合多模态特征，并在仅质量监督下预测体积和密度相关的潜在因子，显著提升质量估计性能。


<details>
  <summary>Details</summary>
Motivation: 从视觉输入中估计物体质量具有挑战性，因为质量依赖于几何体积和材料密度，而这两者均无法直接从RGB图像中观测到，因此需要物理上合理的表示来约束可能解的空间。

Method: 通过单目深度估计恢复物体中心的三维几何以推断体积，使用视觉-语言模型提取粗略的材料语义以指导密度推理，再通过实例自适应门控机制融合几何、语义和外观表示，并采用两个物理引导的回归头分别预测体积和密度相关潜在因子，仅需质量标签进行训练。

Result: 在image2mass和ABO-500数据集上的实验表明，该方法持续优于现有最先进方法。

Conclusion: 所提出的物理结构化框架有效缓解了单图像质量估计中的模糊性问题，通过融合物理可解释的表征显著提升了估计精度。

Abstract: Estimating object mass from visual input is challenging because mass depends jointly on geometric volume and material-dependent density, neither of which is directly observable from RGB appearance. Consequently, mass prediction from pixels is ill-posed and therefore benefits from physically meaningful representations to constrain the space of plausible solutions. We propose a physically structured framework for single-image mass estimation that addresses this ambiguity by aligning visual cues with the physical factors governing mass. From a single RGB image, we recover object-centric three-dimensional geometry via monocular depth estimation to inform volume and extract coarse material semantics using a vision-language model to guide density-related reasoning. These geometry, semantic, and appearance representations are fused through an instance-adaptive gating mechanism, and two physically guided latent factors (volume- and density-related) are predicted through separate regression heads under mass-only supervision. Experiments on image2mass and ABO-500 show that the proposed method consistently outperforms state-of-the-art methods.

</details>


### [16] [Structure-constrained Language-informed Diffusion Model for Unpaired Low-dose Computed Tomography Angiography Reconstruction](https://arxiv.org/abs/2601.20304)
*Genyuan Zhang,Zihao Wang,Zhifan Gao,Lei Xu,Zhen Zhou,Haijun Yu,Jianjia Zhang,Xiujian Liu,Weiwei Zhang,Shaoyu Wang,Huazhu Fu,Fenglin Liu,Weiwen Wu*

Main category: cs.CV

TL;DR: 提出一种结构约束的语言引导扩散模型（SLDM），用于从低剂量碘对比剂CT中生成高剂量效果的图像，提升图像质量并减少对比剂用量。该方法通过结构先验信息和空间智能的语义监督，增强结构一致性与准确性，并引入减影血管增强模块以优化对比剂区域的可视化。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在处理不完全配对的低剂量与正常剂量图像时，难以实现准确的图像增强，主要受限于模型对特定解剖结构的识别能力不足。为解决这一问题，需提升模型对结构和空间关系的理解能力。

Method: 提出结构约束的语言引导扩散模型（SLDM），结合图像结构先验信息进行推理约束，引入具有空间智能的语义监督策略，融合视觉感知与空间推理能力，并采用减影血管增强模块提升对比剂区域的对比度，从而实现高质量的低剂量CT血管成像重建。

Result: 定性与定量实验结果均表明，SLDM在低剂量对比剂CT血管造影的图像重建方面表现优异，显著提升了图像质量与诊断可用性，有效实现了结构一致性和细节保真度。

Conclusion: 所提出的SLDM模型能够有效克服现有方法在不完全配对数据下的局限性，通过结构与空间智能的联合建模，实现更精准、可靠的低剂量CT图像增强，具有良好的临床应用前景。

Abstract: The application of iodinated contrast media (ICM) improves the sensitivity and specificity of computed tomography (CT) for a wide range of clinical indications. However, overdose of ICM can cause problems such as kidney damage and life-threatening allergic reactions. Deep learning methods can generate CT images of normal-dose ICM from low-dose ICM, reducing the required dose while maintaining diagnostic power. However, existing methods are difficult to realize accurate enhancement with incompletely paired images, mainly because of the limited ability of the model to recognize specific structures. To overcome this limitation, we propose a Structure-constrained Language-informed Diffusion Model (SLDM), a unified medical generation model that integrates structural synergy and spatial intelligence. First, the structural prior information of the image is effectively extracted to constrain the model inference process, thus ensuring structural consistency in the enhancement process. Subsequently, semantic supervision strategy with spatial intelligence is introduced, which integrates the functions of visual perception and spatial reasoning, thus prompting the model to achieve accurate enhancement. Finally, the subtraction angiography enhancement module is applied, which serves to improve the contrast of the ICM agent region to suitable interval for observation. Qualitative analysis of visual comparison and quantitative results of several metrics demonstrate the effectiveness of our method in angiographic reconstruction for low-dose contrast medium CT angiography.

</details>


### [17] [OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion](https://arxiv.org/abs/2601.20308)
*Shuoyan Wei,Feng Li,Chen Zhou,Runmin Cong,Yao Zhao,Huihui Bai*

Main category: cs.CV

TL;DR: OSDEnhancer是首个实现真实世界时空视频超分辨率（STVSR）的一步扩散方法，通过线性预插值初始化时空结构，采用时间细化与空间增强混合专家（TR-SE MoE）模型分别学习时序一致性和空间细节，并结合双向可变形变分自编码器（VAE） decoder实现跨帧重构，显著提升重建质量与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有STVSR方法多基于简化退化假设，在复杂真实场景中表现不佳；同时扩散模型在时空超分辨率中的潜力尚未充分探索，亟需一种能同时处理高保真重建与时序一致性的鲁棒框架。

Method: 提出OSDEnhancer框架，包含线性预插值初始化、TR-SE混合专家模型（分离学习时序与空间特征并协同优化）、以及双向可变形VAE解码器用于递归时空聚合与传播。

Result: 在多种真实世界数据集上均达到当前最优性能，具备出色的重建质量与泛化能力，尤其在复杂未知退化条件下表现优异。

Conclusion: OSDEnhancer为真实世界STVSR提供了首个高效、端到端的扩散模型解决方案，有效融合时空建模与自适应特征学习，推动了视频超分辨率技术向更真实、更鲁棒的方向发展。

Abstract: Diffusion models (DMs) have demonstrated exceptional success in video super-resolution (VSR), showcasing a powerful capacity for generating fine-grained details. However, their potential for space-time video super-resolution (STVSR), which necessitates not only recovering realistic visual content from low-resolution to high-resolution but also improving the frame rate with coherent temporal dynamics, remains largely underexplored. Moreover, existing STVSR methods predominantly address spatiotemporal upsampling under simplified degradation assumptions, which often struggle in real-world scenarios with complex unknown degradations. Such a high demand for reconstruction fidelity and temporal consistency makes the development of a robust STVSR framework particularly non-trivial. To address these challenges, we propose OSDEnhancer, a novel framework that, to the best of our knowledge, represents the first method to achieve real-world STVSR through an efficient one-step diffusion process. OSDEnhancer initializes essential spatiotemporal structures through a linear pre-interpolation strategy and pivots on training temporal refinement and spatial enhancement mixture of experts (TR-SE MoE), which allows distinct expert pathways to progressively learn robust, specialized representations for temporal coherence and spatial detail, further collaboratively reinforcing each other during inference. A bidirectional deformable variational autoencoder (VAE) decoder is further introduced to perform recurrent spatiotemporal aggregation and propagation, enhancing cross-frame reconstruction fidelity. Experiments demonstrate that the proposed method achieves state-of-the-art performance while maintaining superior generalization capability in real-world scenarios.

</details>


### [18] [CPiRi: Channel Permutation-Invariant Relational Interaction for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.20318)
*Jiyuan Xu,Wenyu Zhang,Xin Jing,Shuai Chen,Shuai Zhang,Jiahao Nie*

Main category: cs.CV

TL;DR: 提出CPiRi框架，解决多变量时间序列预测中通道依赖与独立模型的局限性，通过时空解耦架构和排列不变正则化训练策略实现通道排列不变性，支持未见通道的归纳泛化且无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，通道依赖模型易受通道顺序影响导致过拟合，而通道独立模型忽略通道间依赖关系，限制性能提升。需要一种既能捕捉跨通道结构又对通道顺序不敏感的模型。

Method: 采用时空解耦架构：冻结预训练的时间编码器提取高质量时序特征，轻量级空间模块学习内容驱动的跨通道关系；结合通道打乱策略进行排列不变正则化训练，确保模型对通道顺序变化鲁棒。

Result: 在多个基准数据集上达到最先进性能；在通道顺序打乱时保持稳定；仅用一半通道训练即可对未见通道实现强归纳泛化；在大规模数据集上具备实际效率。

Conclusion: CPiRi通过理论分析与实验验证，实现了通道排列不变性与高效泛化能力，适用于动态变化的多变量时间序列场景，具有良好的实用性与扩展性。

Abstract: Current methods for multivariate time series forecasting can be classified into channel-dependent and channel-independent models. Channel-dependent models learn cross-channel features but often overfit the channel ordering, which hampers adaptation when channels are added or reordered. Channel-independent models treat each channel in isolation to increase flexibility, yet this neglects inter-channel dependencies and limits performance. To address these limitations, we propose \textbf{CPiRi}, a \textbf{channel permutation invariant (CPI)} framework that infers cross-channel structure from data rather than memorizing a fixed ordering, enabling deployment in settings with structural and distributional co-drift without retraining. CPiRi couples \textbf{spatio-temporal decoupling architecture} with \textbf{permutation-invariant regularization training strategy}: a frozen pretrained temporal encoder extracts high-quality temporal features, a lightweight spatial module learns content-driven inter-channel relations, while a channel shuffling strategy enforces CPI during training. We further \textbf{ground CPiRi in theory} by analyzing permutation equivariance in multivariate time series forecasting. Experiments on multiple benchmarks show state-of-the-art results. CPiRi remains stable when channel orders are shuffled and exhibits strong \textbf{inductive generalization} to unseen channels even when trained on \textbf{only half} of the channels, while maintaining \textbf{practical efficiency} on large-scale datasets. The source code is released at https://github.com/JasonStraka/CPiRi.

</details>


### [19] [GVGS: Gaussian Visibility-Aware Multi-View Geometry for Accurate Surface Reconstruction](https://arxiv.org/abs/2601.20331)
*Mai Su,Qihan Yu,Zhongtao Wang,Yilong Li,Chengwei Pan,Yisong Chen,Guoping Wang*

Main category: cs.CV

TL;DR: 本文提出一种新的3D高斯点云渲染方法，通过引入可见性感知的多视图几何一致性约束和渐进式四叉树校准的单目深度约束，有效提升了表面重建的准确性。该方法在DTU和TNT数据集上均表现出优于现有高斯基与隐式表面重建方法的几何精度。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点云方法在表面重建方面仍面临挑战，尤其是多视图几何一致性在大几何差异下不可靠，而单目深度先验存在尺度模糊性和局部不一致性问题，导致高斯深度监督不准确。

Method: 提出可见性感知的多视图几何一致性约束，通过聚合共享高斯原语在多视角中的可见性实现更精确稳定的几何监督；同时设计渐进式四叉树校准的单目深度约束，从粗到细的空间尺度进行块级仿射校准，缓解尺度模糊性并保留细节。

Result: 在DTU和TNT数据集上的大量实验表明，该方法在几何精度上持续优于现有的基于高斯和隐式表面的重建方法。

Conclusion: 所提方法有效解决了高斯点云表面重建中的深度监督不准确问题，显著提升了几何重建质量，具备良好的稳定性和细节保持能力。

Abstract: 3D Gaussian Splatting enables efficient optimization and high-quality rendering, yet accurate surface reconstruction remains challenging. Prior methods improve surface reconstruction by refining Gaussian depth estimates, either via multi-view geometric consistency or through monocular depth priors. However, multi-view constraints become unreliable under large geometric discrepancies, while monocular priors suffer from scale ambiguity and local inconsistency, ultimately leading to inaccurate Gaussian depth supervision. To address these limitations, we introduce a Gaussian visibility-aware multi-view geometric consistency constraint that aggregates the visibility of shared Gaussian primitives across views, enabling more accurate and stable geometric supervision. In addition, we propose a progressive quadtree-calibrated Monocular depth constraint that performs block-wise affine calibration from coarse to fine spatial scales, mitigating the scale ambiguity of depth priors while preserving fine-grained surface details. Extensive experiments on DTU and TNT datasets demonstrate consistent improvements in geometric accuracy over prior Gaussian-based and implicit surface reconstruction methods. Codes are available at an anonymous repository: https://github.com/GVGScode/GVGS.

</details>


### [20] [PalmBridge: A Plug-and-Play Feature Alignment Framework for Open-Set Palmprint Verification](https://arxiv.org/abs/2601.20351)
*Chenke Zhang,Ziyuan Yang,Licheng Yan,Shuyi Li,Andrew Beng Jin Teoh,Bob Zhang,Yi Zhang*

Main category: cs.CV

TL;DR: PalmBridge is a plug-and-play feature-space alignment framework for open-set palmprint verification that uses vector quantization to learn compact representative vectors from training features. These vectors help suppress domain-induced variations while preserving identity information by mapping and blending feature vectors. The method improves generalization across datasets and reduces EER with minimal computational cost.


<details>
  <summary>Details</summary>
Motivation: Existing deep palmprint models often overfit to specific dataset textures due to assuming closed and stationary data distributions, leading to poor performance under real-world domain shifts. Data augmentation alone fails when the target deployment distribution differs significantly from the training data, necessitating a more robust solution for feature-level adaptation.

Method: PalmBridge employs vector quantization to learn a set of representative vectors directly from training features. Each feature vector is mapped to its nearest representative via minimum distance, then blended with the original vector. The representatives are jointly optimized with the backbone using task supervision, feature-consistency loss, and orthogonality regularization to create a stable, shared embedding space.

Result: Experiments across multiple datasets and backbones show PalmBridge consistently reduces Equal Error Rate (EER) in intra-dataset open-set evaluation and enhances cross-dataset generalization, with only negligible to modest increases in runtime.

Conclusion: PalmBridge effectively addresses domain shift in palmprint recognition by aligning feature spaces through learned representative vectors, achieving improved robustness and generalization without significant computational overhead.

Abstract: Palmprint recognition is widely used in biometric systems, yet real-world performance often degrades due to feature distribution shifts caused by heterogeneous deployment conditions. Most deep palmprint models assume a closed and stationary distribution, leading to overfitting to dataset-specific textures rather than learning domain-invariant representations. Although data augmentation is commonly used to mitigate this issue, it assumes augmented samples can approximate the target deployment distribution, an assumption that often fails under significant domain mismatch. To address this limitation, we propose PalmBridge, a plug-and-play feature-space alignment framework for open-set palmprint verification based on vector quantization. Rather than relying solely on data-level augmentation, PalmBridge learns a compact set of representative vectors directly from training features. During enrollment and verification, each feature vector is mapped to its nearest representative vector under a minimum-distance criterion, and the mapped vector is then blended with the original vector. This design suppresses nuisance variation induced by domain shifts while retaining discriminative identity cues. The representative vectors are jointly optimized with the backbone network using task supervision, a feature-consistency objective, and an orthogonality regularization term to form a stable and well-structured shared embedding space. Furthermore, we analyze feature-to-representative mappings via assignment consistency and collision rate to assess model's sensitivity to blending weights. Experiments on multiple palmprint datasets and backbone architectures show that PalmBridge consistently reduces EER in intra-dataset open-set evaluation and improves cross-dataset generalization with negligible to modest runtime overhead.

</details>


### [21] [Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models](https://arxiv.org/abs/2601.20354)
*Zengbin Wang,Xuecai Hu,Yong Wang,Feng Xiong,Man Zhang,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出SpatialGenEval基准，用于系统评估文本到图像（T2I）模型在复杂空间关系上的智能表现。该基准包含1,230个长且信息密集的提示，覆盖25个真实场景，涵盖10个空间子领域及对应的多选题。实验表明，高阶空间推理仍是当前模型的主要瓶颈。此外，作者构建了SpatialT2I数据集，通过重写提示以保持图像一致性并保留信息密度，微调主流基础模型后显著提升性能（如Stable Diffusion-XL提升+4.2%），验证了数据驱动范式对增强T2I模型空间智能的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型在处理复杂空间关系（如位置、遮挡、因果）方面表现不佳，而现有评估基准因提示过短或信息稀疏，难以有效衡量此类能力。因此亟需一个更全面、信息密集的评估框架和高质量数据集来推动模型改进。

Method: 提出SpatialGenEval基准，设计1,230个长且信息丰富的提示，覆盖25个真实场景，每个提示包含10个空间子领域及对应多选题；同时构建SpatialT2I数据集，通过重写提示生成15,400个保持信息密度与图像一致性的文本-图像对，用于微调模型。

Result: 对21个SOTA模型的评估显示，高阶空间推理仍是主要瓶颈；在三个主流基础模型上使用SpatialT2I数据集微调后，空间关系生成效果显著改善，性能平均提升4.2%至5.7%，生成结果更符合真实空间逻辑。

Conclusion: SpatialGenEval为评估T2I模型的空间智能提供了系统性标准，而SpatialT2I数据集证明了数据驱动方法在提升模型空间理解能力方面的有效性，推动了从‘生成视觉’向‘理解空间’的演进。

Abstract: Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.

</details>


### [22] [CURVE: Learning Causality-Inspired Invariant Representations for Robust Scene Understanding via Uncertainty-Guided Regularization](https://arxiv.org/abs/2601.20355)
*Yue Liang,Jiatong Du,Ziyi Yang,Yanjun Huang,Hong Chen*

Main category: cs.CV

TL;DR: CURVE是一种基于因果推理的框架，通过变分不确定性建模与不确定性引导的结构正则化，抑制高方差、环境相关的关系，提升场景图在分布外情况下的泛化能力。该方法采用原型条件去偏，分离不变的交互动态与环境依赖变化，实现稀疏且域稳定的拓扑结构。实验表明，CURVE在零样本迁移和低数据量的模拟到真实场景适应中表现优异，能学习到稳定的稀疏拓扑并提供可靠的不确定性估计以支持分布漂移下的风险预测。


<details>
  <summary>Details</summary>
Motivation: 场景图虽为场景理解提供了结构化抽象，但常因过度拟合于虚假相关性而严重限制了其在分布外情况下的泛化能力。

Method: 提出一种基于因果推理的框架CURVE，结合变分不确定性建模与不确定性引导的结构正则化；采用原型条件去偏策略，分离不变的交互动态与环境依赖的变化，实现稀疏且域稳定的拓扑结构。

Result: 在零样本迁移和低数据量的模拟到真实场景适应任务中，CURVE展现出学习域稳定稀疏拓扑的能力，并能提供可靠的不确定性估计，支持分布变化下的风险预测。

Conclusion: CURVE有效提升了场景图模型在分布外情况下的泛化性能，通过因果机制与不确定性建模实现了更鲁棒、可解释的场景理解。

Abstract: Scene graphs provide structured abstractions for scene understanding, yet they often overfit to spurious correlations, severely hindering out-of-distribution generalization. To address this limitation, we propose CURVE, a causality-inspired framework that integrates variational uncertainty modeling with uncertainty-guided structural regularization to suppress high-variance, environment-specific relations. Specifically, we apply prototype-conditioned debiasing to disentangle invariant interaction dynamics from environment-dependent variations, promoting a sparse and domain-stable topology. Empirically, we evaluate CURVE in zero-shot transfer and low-data sim-to-real adaptation, verifying its ability to learn domain-stable sparse topologies and provide reliable uncertainty estimates to support risk prediction under distribution shifts.

</details>


### [23] [RAW-Flow: Advancing RGB-to-RAW Image Reconstruction with Deterministic Latent Flow Matching](https://arxiv.org/abs/2601.20364)
*Zhen Liu,Diedong Feng,Hai Jiang,Liaoyuan Zeng,Hao Wang,Chaoyu Feng,Lei Lei,Bing Zeng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: RAW-Flow提出一种生成式视角下的RGB-to-RAW重建方法，将逆ISP问题建模为确定性潜在空间传输问题，利用流匹配学习潜在空间中的向量场，以实现结构细节和颜色信息的高保真重建。通过引入跨尺度上下文引导模块和双域潜在自编码器，有效提升了特征对齐与重建质量。实验表明，该方法在定量和视觉效果上均优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的RGB-to-RAW重建方法多采用直接回归，受限于逆ISP问题的病态性及量化RGB图像中的信息损失，常出现细节不一致和颜色偏差。因此需要更有效的建模方式来恢复高质量的RAW数据。

Method: 将RGB-to-RAW重建重构为确定性潜在空间传输问题，使用流匹配学习潜在空间向量场；引入跨尺度上下文引导模块注入层次化特征；设计双域潜在自编码器并加入特征对齐约束，支持稳定训练与高保真重建。

Result: 在多个评估指标和视觉对比中，RAW-Flow显著优于现有主流方法，在结构细节和颜色还原方面表现更优，验证了其有效性与优越性。

Conclusion: 通过生成式框架与流匹配机制，RAW-Flow成功解决了传统回归方法在细节与色彩一致性上的缺陷，为高保真RGB-to-RAW重建提供了新范式。

Abstract: RGB-to-RAW reconstruction, or the reverse modeling of a camera Image Signal Processing (ISP) pipeline, aims to recover high-fidelity RAW data from RGB images. Despite notable progress, existing learning-based methods typically treat this task as a direct regression objective and struggle with detail inconsistency and color deviation, due to the ill-posed nature of inverse ISP and the inherent information loss in quantized RGB images. To address these limitations, we pioneer a generative perspective by reformulating RGB-to-RAW reconstruction as a deterministic latent transport problem and introduce a novel framework named RAW-Flow, which leverages flow matching to learn a deterministic vector field in latent space, to effectively bridge the gap between RGB and RAW representations and enable accurate reconstruction of structural details and color information. To further enhance latent transport, we introduce a cross-scale context guidance module that injects hierarchical RGB features into the flow estimation process. Moreover, we design a dual-domain latent autoencoder with a feature alignment constraint to support the proposed latent transport framework, which jointly encodes RGB and RAW inputs while promoting stable training and high-fidelity reconstruction. Extensive experiments demonstrate that RAW-Flow outperforms state-of-the-art approaches both quantitatively and visually.

</details>


### [24] [HINT: Hierarchical Interaction Modeling for Autoregressive Multi-Human Motion Generation](https://arxiv.org/abs/2601.20383)
*Mengge Liu,Yan Di,Gu Wang,Yun Qu,Dekai Zhu,Yanyan Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: HINT 是首个基于扩散模型的自回归多人群体动作生成框架，通过分层交互建模实现复杂交互下的动作生成。其采用解耦的运动表示，在归一化潜在空间中分离局部运动语义与人与人之间的交互，从而支持可变人数和长度的文本输入。结合滑动窗口策略，HINT 能高效在线生成长序列动作，同时捕捉窗口内精细交互与跨窗口长期一致性。在公开数据集上的实验表明，HINT 性能媲美先进离线模型，并显著优于现有自回归基线，尤其在 InterHuman 数据集上达到 FID 3.100，大幅超越此前最优的 5.154。


<details>
  <summary>Details</summary>
Motivation: 现有离线方法受限于固定长度和固定人数，难以处理可变长度文本和动态参与者数量；因此需要一种自回归框架，能够逐步生成动作并适应变化的输入条件，以实现更灵活、真实的多人群体动作生成。

Method: 提出 HINT 框架，包含：1）解耦的运动表示，在归一化潜在空间中分离局部运动与交互信息；2）滑动窗口机制，用于高效在线生成，结合窗口内局部与跨窗口全局条件，建模历史轨迹、人际依赖关系及与文本的对齐。

Result: HINT 在多个公开基准上表现优异，性能接近甚至超过强健的离线模型；在 InterHuman 数据集上取得 FID 3.100，显著优于之前的 5.154，证明其在长序列生成与复杂交互建模方面的优势。

Conclusion: HINT 是首个实现多人群体动作生成的自回归扩散框架，通过解耦表示与滑动窗口机制，有效解决了可变输入长度、人数及长期一致性问题，为复杂交互场景下的动作生成提供了新范式。

Abstract: Text-driven multi-human motion generation with complex interactions remains a challenging problem. Despite progress in performance, existing offline methods that generate fixed-length motions with a fixed number of agents, are inherently limited in handling long or variable text, and varying agent counts. These limitations naturally encourage autoregressive formulations, which predict future motions step by step conditioned on all past trajectories and current text guidance. In this work, we introduce HINT, the first autoregressive framework for multi-human motion generation with Hierarchical INTeraction modeling in diffusion. First, HINT leverages a disentangled motion representation within a canonicalized latent space, decoupling local motion semantics from inter-person interactions. This design facilitates direct adaptation to varying numbers of human participants without requiring additional refinement. Second, HINT adopts a sliding-window strategy for efficient online generation, and aggregates local within-window and global cross-window conditions to capture past human history, inter-person dependencies, and align with text guidance. This strategy not only enables fine-grained interaction modeling within each window but also preserves long-horizon coherence across all the long sequence. Extensive experiments on public benchmarks demonstrate that HINT matches the performance of strong offline models and surpasses autoregressive baselines. Notably, on InterHuman, HINT achieves an FID of 3.100, significantly improving over the previous state-of-the-art score of 5.154.

</details>


### [25] [Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models](https://arxiv.org/abs/2601.20419)
*Yuhao Sun,Chengyi Cai,Jiacheng Zhang,Zesheng Ye,Xingliang Yuan,Feng Liu*

Main category: cs.CV

TL;DR: This paper proposes BiFTA, a dual refinement framework that removes redundant image patches and text descriptions to improve fine-grained text-visual alignment in CLIP, achieving state-of-the-art zero-shot performance across multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to address the issue of redundant information in fine-grained text descriptions and localized image patches, which hampers effective text-visual alignment in pre-trained vision-language models like CLIP.

Method: The method proposed is BiFTA (Bi-refinement for Fine-grained Text-visual Alignment), which includes two components: View Refinement (removing redundant image patches with high IoU) and Description Refinement (removing redundant text descriptions with high cosine similarity) to enhance diversity and distinctiveness in both modalities.

Result: BiFTA achieves superior zero-shot performance on 6 benchmark datasets across both ViT-based and ResNet-based CLIP models, demonstrating that removing redundant information improves text-visual alignment effectiveness.

Conclusion: The study concludes that refining both visual views and textual descriptions by eliminating redundancy significantly enhances zero-shot performance, validating the importance of data purity in vision-language alignment.

Abstract: Recent research has shown that aligning fine-grained text descriptions with localized image patches can significantly improve the zero-shot performance of pre-trained vision-language models (e.g., CLIP). However, we find that both fine-grained text descriptions and localized image patches often contain redundant information, making text-visual alignment less effective. In this paper, we tackle this issue from two perspectives: \emph{View Refinement} and \emph{Description refinement}, termed as \textit{\textbf{Bi}-refinement for \textbf{F}ine-grained \textbf{T}ext-visual \textbf{A}lignment} (BiFTA). \emph{View refinement} removes redundant image patches with high \emph{Intersection over Union} (IoU) ratios, resulting in more distinctive visual samples. \emph{Description refinement} removes redundant text descriptions with high pairwise cosine similarity, ensuring greater diversity in the remaining descriptions. BiFTA achieves superior zero-shot performance on 6 benchmark datasets for both ViT-based and ResNet-based CLIP, justifying the necessity to remove redundant information in visual-text alignment.

</details>


### [26] [Quartet of Diffusions: Structure-Aware Point Cloud Generation through Part and Symmetry Guidance](https://arxiv.org/abs/2601.20425)
*Chenliang Zhou,Fangcheng Zhong,Weihao Xia,Albert Miao,Canberk Baykal,Cengiz Oztireli*

Main category: cs.CV

TL;DR: 提出Quartet of Diffusions框架，通过四个协同扩散模型显式建模3D点云的全局形状、对称性、语义部件及其空间组合，实现结构感知生成，支持精细控制和高质量输出。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D点云生成中要么将形状生成视为整体过程，要么仅支持部件组合，缺乏对对称性和部件先验的系统性建模，导致生成结果在结构一致性与多样性上受限。

Method: 采用四个协调的扩散模型分别学习全局形状潜在变量、对称性、语义部件及其空间组装分布；通过解耦生成流程实现可解释性，并利用中心全局潜在变量保证部件间的结构连贯性。

Result: 实验表明，该方法在生成质量、多样性及结构一致性方面均达到当前最优性能，是首个在整个生成过程中同时整合并强制执行对称性与部件先验的3D点云生成框架。

Conclusion: Quartet of Diffusions首次实现了对称性与部件先验在3D点云生成中的全面集成，显著提升了生成结果的质量与可控性，为结构化形状生成提供了新范式。

Abstract: We introduce the Quartet of Diffusions, a structure-aware point cloud generation framework that explicitly models part composition and symmetry. Unlike prior methods that treat shape generation as a holistic process or only support part composition, our approach leverages four coordinated diffusion models to learn distributions of global shape latents, symmetries, semantic parts, and their spatial assembly. This structured pipeline ensures guaranteed symmetry, coherent part placement, and diverse, high-quality outputs. By disentangling the generative process into interpretable components, our method supports fine-grained control over shape attributes, enabling targeted manipulation of individual parts while preserving global consistency. A central global latent further reinforces structural coherence across assembled parts. Our experiments show that the Quartet achieves state-of-the-art performance. To our best knowledge, this is the first 3D point cloud generation framework that fully integrates and enforces both symmetry and part priors throughout the generative process.

</details>


### [27] [Youtu-Parsing: Perception, Structuring and Recognition via High-Parallelism Decoding](https://arxiv.org/abs/2601.20430)
*Kun Yin,Yunfei Wu,Bing Liu,Zhongpeng Cai,Xiaotian Li,Huang Chen,Xin Li,Haoyu Cao,Yinsong Liu,Deqiang Jiang,Xing Sun,Yunsheng Wu,Qianyu Li,Antai Guo,Yanzhen Liao,Yanqiu Qu,Haodong Lin,Chengxu He,Shuangyin Liu*

Main category: cs.CV

TL;DR: Youtu-Parsing 是一种高效且通用的文档解析模型，采用基于动态分辨率视觉编码器的Vision Transformer（ViT）与提示引导的Youtu-LLM-2B语言模型结合，支持布局分析和区域提示解码。通过引入令牌并行与查询并行的高并行解码策略，实现5–11倍速度提升（令牌并行），并在多区域预测中额外获得2倍加速，同时保持输出质量。该模型可处理文本、公式、表格、图表、印章及层级结构等复杂文档元素，具备对罕见字符、多语言和手写内容的强鲁棒性，在OmniDocBench和olmOCR-bench上达到当前最佳性能，适用于大规模文档智能应用。


<details>
  <summary>Details</summary>
Motivation: 现有文档解析方法在处理复杂结构化内容时效率低、扩展性差，难以满足大规模文档智能应用的需求。尤其在高结构化场景（如表格识别）中，传统自回归解码方式速度慢，无法充分发挥并行计算优势。因此亟需一种高效、灵活且可扩展的文档解析框架，以兼顾速度与精度，并支持多样化的文档元素理解。

Method: 提出Youtu-Parsing模型，其核心为解耦式架构：使用动态分辨率视觉编码器提取共享文档特征；结合提示引导的Youtu-LLM-2B语言模型进行布局分析与区域提示解码。引入两种并行解码机制——令牌并行（每步并发生成最多64个候选令牌，经验证机制筛选）和查询并行（同时预测最多5个边界框的内容），从而大幅提高推理效率。

Result: 在OmniDocBench和olmOCR-bench两个基准测试中均达到当前最优（SOTA）性能；令牌并行带来5–11倍加速，查询并行提供额外2倍加速，整体推理效率显著提升；在处理表格、多语言、罕见字符及手写内容时表现出优异鲁棒性。

Conclusion: Youtu-Parsing通过创新的并行解码策略与解耦架构，实现了高效、高精度、强泛化能力的文档内容提取，在大规模文档智能系统中具有重要实用价值和推广潜力。

Abstract: This paper presents Youtu-Parsing, an efficient and versatile document parsing model designed for high-performance content extraction. The architecture employs a native Vision Transformer (ViT) featuring a dynamic-resolution visual encoder to extract shared document features, coupled with a prompt-guided Youtu-LLM-2B language model for layout analysis and region-prompted decoding. Leveraging this decoupled and feature-reusable framework, we introduce a high-parallelism decoding strategy comprising two core components: token parallelism and query parallelism. The token parallelism strategy concurrently generates up to 64 candidate tokens per inference step, which are subsequently validated through a verification mechanism. This approach yields a 5--11x speedup over traditional autoregressive decoding and is particularly well-suited for highly structured scenarios, such as table recognition. To further exploit the advantages of region-prompted decoding, the query parallelism strategy enables simultaneous content prediction for multiple bounding boxes (up to five), providing an additional 2x acceleration while maintaining output quality equivalent to standard decoding. Youtu-Parsing encompasses a diverse range of document elements, including text, formulas, tables, charts, seals, and hierarchical structures. Furthermore, the model exhibits strong robustness when handling rare characters, multilingual text, and handwritten content. Extensive evaluations demonstrate that Youtu-Parsing achieves state-of-the-art (SOTA) performance on both the OmniDocBench and olmOCR-bench benchmarks. Overall, Youtu-Parsing demonstrates significant experimental value and practical utility for large-scale document intelligence applications.

</details>


### [28] [MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models](https://arxiv.org/abs/2601.20433)
*Wenbo Xu,Wei Lu,Xiangyang Luo,Jiantao Zhou*

Main category: cs.CV

TL;DR: MARE提出了一种基于视觉-语言模型的可解释深度伪造检测方法，通过多模态对齐与强化学习提升检测准确性和可靠性。该方法结合人类反馈的强化学习（RLHF）设计综合奖励函数，鼓励生成与空间位置一致的推理内容，并引入伪造解耦模块以捕捉高级面部语义中的伪造痕迹，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法多为分类或空间定位，难以应对生成模型快速发展的挑战；同时缺乏可解释性，限制了模型在实际应用中的可信度。因此需要更准确、可靠的可解释检测方法。

Method: MARE采用多模态对齐机制，结合视觉-语言模型，利用人类反馈的强化学习（RLHF）设计综合奖励函数，引导模型生成与图像空间位置一致的文本推理内容；同时引入伪造解耦模块，从高层面部语义中分离并捕捉伪造痕迹，增强真实性判断能力。

Result: 在多个数据集上的定量与定性实验表明，MARE在检测准确率和可靠性方面均达到当前最优水平，生成的推理内容具有良好的可解释性与一致性。

Conclusion: MARE通过多模态对齐与强化学习机制，有效提升了视觉-语言模型在深度伪造检测中的准确性、可靠性和可解释性，为未来对抗虚假内容提供了有力工具。

Abstract: Deepfake detection is a widely researched topic that is crucial for combating the spread of malicious content, with existing methods mainly modeling the problem as classification or spatial localization. The rapid advancements in generative models impose new demands on Deepfake detection. In this paper, we propose multimodal alignment and reinforcement for explainable Deepfake detection via vision-language models, termed MARE, which aims to enhance the accuracy and reliability of Vision-Language Models (VLMs) in Deepfake detection and reasoning. Specifically, MARE designs comprehensive reward functions, incorporating reinforcement learning from human feedback (RLHF), to incentivize the generation of text-spatially aligned reasoning content that adheres to human preferences. Besides, MARE introduces a forgery disentanglement module to capture intrinsic forgery traces from high-level facial semantics, thereby improving its authenticity detection capability. We conduct thorough evaluations on the reasoning content generated by MARE. Both quantitative and qualitative experimental results demonstrate that MARE achieves state-of-the-art performance in terms of accuracy and reliability.

</details>


### [29] [Efficient Autoregressive Video Diffusion with Dummy Head](https://arxiv.org/abs/2601.20499)
*Hang Guo,Zhaoyang Jia,Jiahao Li,Bin Li,Yuanhao Cai,Jiangshan Wang,Yawei Li,Yan Lu*

Main category: cs.CV

TL;DR: 提出Dummy Forcing方法，通过控制不同注意力头的上下文访问，减少头间上下文冗余，并实现动态头类型分类和上下文打包，无需额外训练即可实现2.0倍加速，视频生成速度达24.3 FPS，质量损失小于0.5%。


<details>
  <summary>Details</summary>
Motivation: 发现自回归视频扩散模型中的多头自注意力机制对历史帧利用不足，约25%的注意力头仅关注当前帧，丢弃其键值缓存对性能影响小，因此需要优化上下文管理以提升效率。

Method: 提出Dummy Forcing方法，通过异构内存分配控制各注意力头的上下文访问，结合动态头编程实现头类型自适应分类，并引入上下文打包技术实现更激进的缓存压缩。

Result: 无需额外训练，相比基线模型实现最高2.0倍加速，支持24.3 FPS视频生成，质量下降小于0.5%。

Conclusion: Dummy Forcing有效提升了自回归视频扩散模型中注意力机制的上下文利用效率，显著加速推理过程，同时保持高质量输出。

Abstract: The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising. In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression. Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.

</details>


### [30] [Comparative evaluation of training strategies using partially labelled datasets for segmentation of white matter hyperintensities and stroke lesions in FLAIR MRI](https://arxiv.org/abs/2601.20503)
*Jesse Phitidis,Alison Q. Smithard,William N. Whiteley,Joanna M. Wardlaw,Miguel O. Bernabeu,Maria Valdés Hernández*

Main category: cs.CV

TL;DR: 本文研究了六种利用部分标注数据训练联合白质高信号（WMH）和缺血性卒中病变（ISL）分割模型的策略。通过整合私有和公开的部分标注数据集，共获得2052例MRI影像，其中1341例和1152例分别具有WMH和ISL的真值标注。研究发现，多种方法能有效利用部分标注数据提升模型性能，其中伪标签方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: WMH和ISL在FLAIR序列上视觉上相互混淆，且常在同一患者中出现，导致深度学习模型的分割与区分困难。因此，需要探索有效利用部分标注数据的方法以提升模型性能。

Method: 整合多个私有和公开的部分标注数据集，构建大规模训练数据集；采用六种不同的训练策略，包括使用伪标签等方法，对联合分割模型进行训练与评估。

Result: 多种方法能有效利用部分标注数据提升模型性能，其中伪标签策略表现最优，显著提高了WMH和ISL的分割准确率。

Conclusion: 在缺乏完全标注数据的情况下，利用伪标签等策略可有效提升联合分割模型的性能，为脑小血管病影像分析提供了可行的技术路径。

Abstract: White matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) are imaging features associated with cerebral small vessel disease (SVD) that are visible on brain magnetic resonance imaging (MRI) scans. The development and validation of deep learning models to segment and differentiate these features is difficult because they visually confound each other in the fluid-attenuated inversion recovery (FLAIR) sequence and often appear in the same subject. We investigated six strategies for training a combined WMH and ISL segmentation model using partially labelled data. We combined privately held fully and partially labelled datasets with publicly available partially labelled datasets to yield a total of 2052 MRI volumes, with 1341 and 1152 containing ground truth annotations for WMH and ISL respectively. We found that several methods were able to effectively leverage the partially labelled data to improve model performance, with the use of pseudolabels yielding the best result.

</details>


### [31] [Latent Temporal Discrepancy as Motion Prior: A Loss-Weighting Strategy for Dynamic Fidelity in T2V](https://arxiv.org/abs/2601.20504)
*Meiqi Wu,Bingze Song,Ruimin Lin,Chen Zhu,Xiaokun Feng,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为潜在时间差异（LTD）的运动先验，用于指导损失加权，以解决视频生成模型在动态变化场景下质量下降的问题。LTD通过测量潜在空间中帧间变化，对差异较大的区域施加更大的惩罚，同时保持对稳定区域的常规优化，从而提升训练稳定性并更好地重建高频动态。在VBench和VMBench两个基准测试中，该方法分别优于强基线3.31%和3.58%，显著提升了运动质量。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型采用静态损失函数，无法有效应对剧烈动态变化带来的噪声干扰和时序不一致性问题，导致运动视频生成质量下降。因此需要一种能够感知运动变化并自适应调整损失权重的方法。

Method: 引入潜在时间差异（LTD）作为运动先验，通过量化潜在空间中帧间变化程度，动态调整损失权重：对高差异区域施加更大惩罚，对稳定区域维持常规优化，实现对复杂动态的更好建模。

Result: 在通用基准VBench上提升3.31%，在运动聚焦基准VMBench上提升3.58%，显著改善了视频生成中的运动质量与时序一致性。

Conclusion: LTD作为一种运动感知的损失加权机制，有效提升了扩散模型在动态视频生成任务中的表现，为复杂运动建模提供了新思路。

Abstract: Video generation models have achieved notable progress in static scenarios, yet their performance in motion video generation remains limited, with quality degrading under drastic dynamic changes. This is due to noise disrupting temporal coherence and increasing the difficulty of learning dynamic regions. {Unfortunately, existing diffusion models rely on static loss for all scenarios, constraining their ability to capture complex dynamics.} To address this issue, we introduce Latent Temporal Discrepancy (LTD) as a motion prior to guide loss weighting. LTD measures frame-to-frame variation in the latent space, assigning larger penalties to regions with higher discrepancy while maintaining regular optimization for stable regions. This motion-aware strategy stabilizes training and enables the model to better reconstruct high-frequency dynamics. Extensive experiments on the general benchmark VBench and the motion-focused VMBench show consistent gains, with our method outperforming strong baselines by 3.31% on VBench and 3.58% on VMBench, achieving significant improvements in motion quality.

</details>


### [32] [Say Cheese! Detail-Preserving Portrait Collection Generation via Natural Language Edits](https://arxiv.org/abs/2601.20511)
*Zelong Sun,Jiahui Wu,Ying Ba,Dong Jing,Zhiwu Lu*

Main category: cs.CV

TL;DR: 本文提出了一个名为Portrait Collection Generation (PCG)的新任务，旨在通过自然语言指令编辑参考肖像图生成连贯的肖像集。为此，作者构建了CHEESE数据集（包含24K肖像集和573K样本），并提出SCheese框架，结合文本引导生成与分层身份及细节保持机制，实现多属性修改与高保真细节保留。实验表明该方法在PCG任务上达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体平台的普及，用户对创建多样化、高质量肖像集的需求增加。现有方法难以同时处理复杂的多属性修改（如姿态、空间布局、摄像机视角）以及保持身份、服装、配饰等细节的高保真度，因此需要新的任务定义与方法支持。

Method: 提出SCheese框架，采用自适应特征融合机制维持身份一致性，并引入ConsistencyNet注入细粒度特征以保证细节一致性；同时基于大视觉-语言模型与反演验证构建大规模标注数据集CHEESE。

Result: SCheese在所提出的PCG任务上表现优异，显著优于现有方法；CHEESE数据集为该任务提供了高质量、大规模的训练与评估基础。

Conclusion: 本文首次定义并推动了Portrait Collection Generation任务的发展，通过构建CHEESE数据集与提出SCheese框架，有效解决了复杂多属性编辑与高保真细节保持的挑战，为未来个性化肖像生成提供了新方向。

Abstract: As social media platforms proliferate, users increasingly demand intuitive ways to create diverse, high-quality portrait collections. In this work, we introduce Portrait Collection Generation (PCG), a novel task that generates coherent portrait collections by editing a reference portrait image through natural language instructions. This task poses two unique challenges to existing methods: (1) complex multi-attribute modifications such as pose, spatial layout, and camera viewpoint; and (2) high-fidelity detail preservation including identity, clothing, and accessories. To address these challenges, we propose CHEESE, the first large-scale PCG dataset containing 24K portrait collections and 573K samples with high-quality modification text annotations, constructed through an Large Vison-Language Model-based pipeline with inversion-based verification. We further propose SCheese, a framework that combines text-guided generation with hierarchical identity and detail preservation. SCheese employs adaptive feature fusion mechanism to maintain identity consistency, and ConsistencyNet to inject fine-grained features for detail consistency. Comprehensive experiments validate the effectiveness of CHEESE in advancing PCG, with SCheese achieving state-of-the-art performance.

</details>


### [33] [IOTA: Corrective Knowledge-Guided Prompt Learning via Black-White Box Framework](https://arxiv.org/abs/2601.20526)
*Shaokun Wang,Yifan Yu,Yuhang He,Weili Guan,Yihong Gong*

Main category: cs.CV

TL;DR: 提出IOTA框架，结合数据驱动的黑箱模块与知识驱动的白箱模块，通过对比错误预测与正确认知生成可解释的纠正知识，并以提示选择策略引导模型优化，在12个图像分类基准上验证了其在少样本及难度递增设置下的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法将预训练模型视为黑箱，仅依赖数据驱动优化，忽视了模型内在先验知识，限制了下游任务适应能力。

Method: 设计黑-白箱混合提示学习框架IOTA，白箱模块通过对比错误与正确认知生成纠正知识，并将其转化为可解释的人类提示；黑箱模块则利用该提示进行优化，结合知识与数据驱动信号实现有效适配。

Result: 在12个图像分类基准上，无论在少样本还是从易到难的迁移场景中，IOTA均表现出色，优于现有最先进方法。

Conclusion: 整合知识驱动与数据驱动信号的IOTA框架显著提升了预训练模型在下游任务中的适应性能，证明了纠正知识的有效性与方法的优越性。

Abstract: Recently, adapting pre-trained models to downstream tasks has attracted increasing interest. Previous Parameter-Efficient-Tuning (PET) methods regard the pre-trained model as an opaque Black Box model, relying purely on data-driven optimization and underutilizing their inherent prior knowledge. This oversight limits the models' potential for effective downstream task adaptation. To address these issues, we propose a novel black-whIte bOx prompT leArning framework (IOTA), which integrates a data-driven Black Box module with a knowledge-driven White Box module for downstream task adaptation. Specifically, the White Box module derives corrective knowledge by contrasting the wrong predictions with the right cognition. This knowledge is verbalized into interpretable human prompts and leveraged through a corrective knowledge-guided prompt selection strategy to guide the Black Box module toward more accurate predictions. By jointly leveraging knowledge- and data-driven learning signals, IOTA achieves effective downstream task adaptation. Experimental results on 12 image classification benchmarks under few-shot and easy-to-hard adaptation settings demonstrate the effectiveness of corrective knowledge and the superiority of our method over state-of-the-art methods.

</details>


### [34] [Advancing Open-source World Models](https://arxiv.org/abs/2601.20540)
*Robbyant Team,Zelin Gao,Qiuyu Wang,Yanhong Zeng,Jiapeng Zhu,Ka Leong Cheng,Yixuan Li,Hanlin Wang,Yinghao Xu,Shuailei Ma,Yihang Chen,Jie Liu,Yansong Cheng,Yao Yao,Jiayi Zhu,Yihao Meng,Kecheng Zheng,Qingyan Bai,Jingye Chen,Zehong Shen,Yue Yu,Xing Zhu,Yujun Shen,Hao Ouyang*

Main category: cs.CV

TL;DR: LingBot-World is an open-sourced world simulator based on video generation, offering high-fidelity environments with diverse styles, long-term memory for contextual consistency over minutes, and real-time interactivity with under 1-second latency at 16 FPS. It aims to bridge the gap between open-source and closed-source technologies, supporting applications in content creation, gaming, and robot learning.


<details>
  <summary>Details</summary>
Motivation: To create a high-fidelity, interactive, and scalable world simulator that supports long-term consistency and real-time interaction, while making advanced simulation technology accessible through open-source release.

Method: Leveraging video generation techniques to build a dynamic world model capable of maintaining realism, style diversity, temporal consistency, and low-latency interactivity.

Result: LingBot-World achieves high-fidelity simulation across varied environments, supports minute-level horizons with consistent context, and enables real-time interaction with less than 1 second latency at 16 frames per second.

Conclusion: The open-sourcing of LingBot-World empowers the research and development community by providing a powerful, accessible platform for applications in content creation, gaming, and robot learning, narrowing the gap between open-source and proprietary simulation technologies.

Abstract: We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as "long-term memory". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.

</details>


### [35] [DeepSeek-OCR 2: Visual Causal Flow](https://arxiv.org/abs/2601.20552)
*Haoran Wei,Yaofeng Sun,Yukun Li*

Main category: cs.CV

TL;DR: DeepSeek-OCR 2 introduces DeepEncoder V2, a novel encoder that dynamically reorders visual tokens based on image semantics, inspired by human causal reasoning in visual perception. Unlike traditional vision-language models that use fixed raster-scan ordering, DeepEncoder V2 enables flexible, semantically guided token processing, aiming to achieve genuine 2D reasoning through cascaded 1D causal structures.


<details>
  <summary>Details</summary>
Motivation: Traditional vision-language models process visual tokens in a rigid, fixed order (e.g., top-left to bottom-right), which does not align with human visual perception. Humans perceive images through flexible, causally-informed scanning patterns, especially in complex layouts. To bridge this gap, the authors aim to develop a model that mimics human-like, semantically driven visual processing.

Method: DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, allowing it to intelligently reorder visual tokens according to image semantics before feeding them into the LLM. This approach leverages two cascaded 1D causal reasoning structures to simulate effective 2D image understanding.

Result: The proposed method demonstrates the feasibility of achieving effective 2D image understanding through dynamic reordering of visual tokens via 1D causal reasoning cascades. It offers a new architectural paradigm for vision-language models with potential for improved semantic coherence and reasoning.

Conclusion: DeepSeek-OCR 2 presents a promising step toward true 2D reasoning in vision-language models by incorporating dynamic, semantically aware token reordering inspired by human cognition. The model opens new avenues for more natural and efficient visual understanding in AI systems.

Abstract: We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.

</details>


### [36] [DiffVC-RT: Towards Practical Real-Time Diffusion-based Perceptual Neural Video Compression](https://arxiv.org/abs/2601.20564)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: cs.CV

TL;DR: DiffVC-RT 是首个实现实时扩散模型感知视频压缩的框架，通过高效信息架构、显式与隐式时序一致性建模以及异步并行解码管道，在保持高视觉质量的同时实现 80.1% 的比特率节省（以 LPIPS 计），在 NVIDIA H800 上达到 206/30 fps 的编码/解码速度，显著推动了扩散模型在视频压缩中的实用化。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的神经视频压缩（NVC）面临严重信息丢失、推理延迟高和时序不一致等关键挑战，限制了其实际部署。

Method: 提出高效且信息丰富的模型架构，通过模块替换与剪枝降低计算复杂度；引入零成本在线时序偏移模块与混合隐式一致性约束以增强时序一致性；设计异步并行解码流水线结合混合半精度计算，支持异步潜空间解码与并行帧重建。

Result: 在 HEVC 数据集上相比 VTM-17.0 实现 80.1% 的比特率节省（以 LPIPS 衡量），720p 视频在 NVIDIA H800 上实现 206/30 fps 的实时编码与解码速度，是扩散模型视频压缩领域的重要里程碑。

Conclusion: DiffVC-RT 成功实现了实时、高质量的扩散模型感知视频压缩，为未来可扩展、低延迟的视频压缩系统奠定了基础。

Abstract: The practical deployment of diffusion-based Neural Video Compression (NVC) faces critical challenges, including severe information loss, prohibitive inference latency, and poor temporal consistency. To bridge this gap, we propose DiffVC-RT, the first framework designed to achieve real-time diffusion-based perceptual NVC. First, we introduce an Efficient and Informative Model Architecture. Through strategic module replacements and pruning, this architecture significantly reduces computational complexity while mitigating structural information loss. Second, to address generative flickering artifacts, we propose Explicit and Implicit Consistency Modeling. We enhance temporal consistency by explicitly incorporating a zero-cost Online Temporal Shift Module within the U-Net, complemented by hybrid implicit consistency constraints. Finally, we present an Asynchronous and Parallel Decoding Pipeline incorporating Mixed Half Precision, which enables asynchronous latent decoding and parallel frame reconstruction via a Batch-dimension Temporal Shift design. Experiments show that DiffVC-RT achieves 80.1% bitrate savings in terms of LPIPS over VTM-17.0 on HEVC dataset with real-time encoding and decoding speeds of 206 / 30 fps for 720p videos on an NVIDIA H800 GPU, marking a significant milestone in diffusion-based video compression.

</details>


### [37] [StructAlign: Structured Cross-Modal Alignment for Continual Text-to-Video Retrieval](https://arxiv.org/abs/2601.20597)
*Shaokun Wang,Weili Guan,Jizhou Han,Jianlong Wu,Yupeng Hu,Liqiang Nie*

Main category: cs.CV

TL;DR: 提出 StructAlign 方法以解决持续文本到视频检索（CTVR）中的灾难性遗忘问题，通过引入等角紧框架（ETF）几何先验和跨模态对齐损失缓解模态间失配，同时设计跨模态关系保持损失抑制模态内特征漂移，从而有效提升模型在持续学习中的性能。


<details>
  <summary>Details</summary>
Motivation: CTVR 面临灾难性遗忘挑战，主要由模态内特征漂移和跨模态非协作特征漂移导致，现有方法难以同时应对两类漂移问题。

Method: 提出基于等角紧框架（ETF）的结构化跨模态对齐方法，包括跨模态 ETF 对齐损失以促进类别级特征对齐，以及跨模态关系保持损失以维持模态间相似性关系，联合缓解跨模态与模态内特征漂移。

Result: 在多个基准数据集上的实验表明，该方法显著优于现有最先进的持续检索方法，在保持旧知识的同时有效学习新类别。

Conclusion: StructAlign 通过引入几何先验和双损失机制，有效缓解了 CTVR 中的灾难性遗忘问题，为多模态持续学习提供了新的解决方案。

Abstract: Continual Text-to-Video Retrieval (CTVR) is a challenging multimodal continual learning setting, where models must incrementally learn new semantic categories while maintaining accurate text-video alignment for previously learned ones, thus making it particularly prone to catastrophic forgetting. A key challenge in CTVR is feature drift, which manifests in two forms: intra-modal feature drift caused by continual learning within each modality, and non-cooperative feature drift across modalities that leads to modality misalignment. To mitigate these issues, we propose StructAlign, a structured cross-modal alignment method for CTVR. First, StructAlign introduces a simplex Equiangular Tight Frame (ETF) geometry as a unified geometric prior to mitigate modality misalignment. Building upon this geometric prior, we design a cross-modal ETF alignment loss that aligns text and video features with category-level ETF prototypes, encouraging the learned representations to form an approximate simplex ETF geometry. In addition, to suppress intra-modal feature drift, we design a Cross-modal Relation Preserving loss, which leverages complementary modalities to preserve cross-modal similarity relations, providing stable relational supervision for feature updates. By jointly addressing non-cooperative feature drift across modalities and intra-modal feature drift, StructAlign effectively alleviates catastrophic forgetting in CTVR. Extensive experiments on benchmark datasets demonstrate that our method consistently outperforms state-of-the-art continual retrieval approaches.

</details>


### [38] [Person Re-ID in 2025: Supervised, Self-Supervised, and Language-Aligned. What Works?](https://arxiv.org/abs/2601.20598)
*Lakshman Balasubramanian*

Main category: cs.CV

TL;DR: 该研究系统评估了监督学习、自监督学习和语言对齐模型三种训练范式在跨域场景下的表现，发现监督模型在训练域内表现优异但在跨域时性能急剧下降，而语言对齐模型（如SigLIP2）展现出意外的跨域鲁棒性，即使未专门为此训练。研究通过11个模型和9个数据集的实验揭示了当前模型在泛化能力上的局限性，并强调了基础模型在提供更具迁移性的视觉表征方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决人物重识别（ReID）在跨域应用中的泛化难题，探索不同训练范式对模型鲁棒性的影响，特别是基础模型是否能通过更丰富的视觉表示提升跨域性能。

Method: 对比分析三种训练范式：监督学习、自监督学习与语言对齐模型，在11个模型和9个数据集上进行跨域性能评估，重点考察模型在非训练域数据上的表现。

Result: 监督模型在训练域内表现优秀，但跨域性能显著下降；语言对齐模型表现出强跨域鲁棒性，即便未显式训练于此类任务；基础模型如SigLIP2在生成可迁移视觉表征方面具有优势。

Conclusion: 当前主流监督模型缺乏跨域泛化能力，而语言对齐的基础模型展现出更强的通用性和鲁棒性，提示未来ReID研究应更多依赖具备丰富语义先验的预训练框架以提升实际应用中的适应性。

Abstract: Person Re-Identification (ReID) remains a challenging problem in computer vision. This work reviews various training paradigm and evaluates the robustness of state-of-the-art ReID models in cross-domain applications and examines the role of foundation models in improving generalization through richer, more transferable visual representations. We compare three training paradigms, supervised, self-supervised, and language-aligned models. Through the study the aim is to answer the following questions: Can supervised models generalize in cross-domain scenarios? How does foundation models like SigLIP2 perform for the ReID tasks? What are the weaknesses of current supervised and foundational models for ReID? We have conducted the analysis across 11 models and 9 datasets. Our results show a clear split: supervised models dominate their training domain but crumble on cross-domain data. Language-aligned models, however, show surprising robustness cross-domain for ReID tasks, even though they are not explicitly trained to do so. Code and data available at: https://github.com/moiiai-tech/object-reid-benchmark.

</details>


### [39] [GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection](https://arxiv.org/abs/2601.20618)
*Shuguang Zhang,Junhong Lian,Guoxin Yu,Baoxun Xu,Xiang Ao*

Main category: cs.CV

TL;DR: 提出GDCNet框架，通过多模态大模型生成客观图像描述作为语义锚点，计算文本与生成描述之间的语义和情感差异，结合视觉-文本保真度，利用门控模块融合特征，实现更准确的跨模态讽刺检测。在MMSD2.0等基准上表现优异，达到新最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖跨模态嵌入错位检测不一致，但在视觉与文本关系松散或语义间接时效果差；虽有使用大语言模型生成讽刺线索，但生成内容多样性与主观性带来噪声。

Method: 利用多模态大模型生成客观、事实性的图像描述作为稳定语义锚点，计算原始文本与生成描述间的语义和情感差异，并测量视觉-文本保真度，通过门控融合机制整合多源特征，自适应调整模态权重。

Result: 在多个多模态讽刺检测基准上取得优异表现，尤其在MMSD2.0上达到新的状态领先水平，验证了方法的有效性与鲁棒性。

Conclusion: GDCNet通过引入由多模态大模型生成的客观描述作为语义参考，有效缓解了跨模态不一致检测中的噪声与模糊问题，显著提升了讽刺识别的准确性与稳定性，为未来多模态讽刺检测提供了新思路。

Abstract: Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.

</details>


### [40] [ProSkill: Segment-Level Skill Assessment in Procedural Videos](https://arxiv.org/abs/2601.20661)
*Michele Mazzamuto,Daniele Di Mauro,Gianpiero Francesca,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 本文提出了ProSkill，首个用于程序性任务中动作级技能评估的基准数据集。该数据集通过创新的可扩展标注协议，从成对比较中生成绝对技能评分，采用瑞士轮赛制进行高效成对比较，并利用基于ELO的评分系统聚合为一致的连续全局分数。该数据集支持绝对与成对评估，填补了复杂程序性活动缺乏大规模数据集的空白，且可用于评估现有最先进的技能评估算法，揭示当前方法的局限性，凸显其研究价值。所有数据和代码已公开。


<details>
  <summary>Details</summary>
Motivation: 现有技能评估研究多集中于体育领域，缺乏针对复杂程序性活动的大规模数据集；现有方法仅限于少量动作、成对比较或二元标签，无法实现全面、客观的技能评估。因此需要一个包含绝对与成对标注的大型数据集以推动该领域发展。

Method: 提出一种新型可扩展的标注协议：先通过瑞士轮赛制进行高效的成对比较，再利用ELO评分系统将成对结果聚合为一致的连续绝对技能分数，从而构建具有绝对评分的技能评估数据集。

Result: 在使用ProSkill数据集对主流技能评估算法进行基准测试后，发现现有最先进方法表现不佳，表明该任务仍具挑战性，进一步验证了ProSkill数据集的价值与必要性。

Conclusion: ProSkill是首个面向程序性任务的动作级技能评估基准数据集，具备绝对与成对标注，其标注协议高效可靠，能够有效推动技能评估研究的发展，为未来算法改进提供重要基础。

Abstract: Skill assessment in procedural videos is crucial for the objective evaluation of human performance in settings such as manufacturing and procedural daily tasks. Current research on skill assessment has predominantly focused on sports and lacks large-scale datasets for complex procedural activities. Existing studies typically involve only a limited number of actions, focus on either pairwise assessments (e.g., A is better than B) or on binary labels (e.g., good execution vs needs improvement). In response to these shortcomings, we introduce ProSkill, the first benchmark dataset for action-level skill assessment in procedural tasks. ProSkill provides absolute skill assessment annotations, along with pairwise ones. This is enabled by a novel and scalable annotation protocol that allows for the creation of an absolute skill assessment ranking starting from pairwise assessments. This protocol leverages a Swiss Tournament scheme for efficient pairwise comparisons, which are then aggregated into consistent, continuous global scores using an ELO-based rating system. We use our dataset to benchmark the main state-of-the-art skill assessment algorithms, including both ranking-based and pairwise paradigms. The suboptimal results achieved by the current state-of-the-art highlight the challenges and thus the value of ProSkill in the context of skill assessment for procedural videos. All data and code are available at https://fpv-iplab.github.io/ProSkill/

</details>


### [41] [bi-modal textual prompt learning for vision-language models in remote sensing](https://arxiv.org/abs/2601.20675)
*Pankhi Kashyap,Mainak Singha,Biplab Banerjee*

Main category: cs.CV

TL;DR: BiMoRS is a lightweight bi-modal prompt learning framework designed for remote sensing (RS) imagery, addressing challenges like multi-label scenes and high intra-class variability. It uses a frozen image captioning model (BLIP-2) to generate textual summaries, which are fused with CLIP visual features via a BERT tokenizer and a cross-attention module to create contextualized prompts. The method improves generalization on RS datasets and outperforms baselines by up to 2% on average across three domain generalization tasks.


<details>
  <summary>Details</summary>
Motivation: Existing prompt learning methods struggle with the unique characteristics of remote sensing imagery, such as multi-label scenes, high intra-class variability, and diverse spatial resolutions, leading to poor transferability and difficulty in identifying dominant semantic cues or generalizing to novel classes.

Method: BiMoRS leverages a frozen BLIP-2 model to generate captions from RS images, tokenizes them using BERT, fuses them with high-level visual features from CLIP, and employs a lightweight cross-attention module to condition learnable query prompts on the fused representation, enabling contextualized prompting without modifying the CLIP backbone.

Result: BiMoRS achieves consistent performance gains across four RS datasets under three domain generalization tasks, outperforming strong baselines by up to 2% on average.

Conclusion: BiMoRS effectively addresses the limitations of current prompt learning methods in remote sensing by integrating textual and visual information through a lightweight, non-invasive framework, demonstrating strong transferability and generalization on RS data.

Abstract: Prompt learning (PL) has emerged as an effective strategy to adapt vision-language models (VLMs), such as CLIP, for downstream tasks under limited supervision. While PL has demonstrated strong generalization on natural image datasets, its transferability to remote sensing (RS) imagery remains underexplored. RS data present unique challenges, including multi-label scenes, high intra-class variability, and diverse spatial resolutions, that hinder the direct applicability of existing PL methods. In particular, current prompt-based approaches often struggle to identify dominant semantic cues and fail to generalize to novel classes in RS scenarios. To address these challenges, we propose BiMoRS, a lightweight bi-modal prompt learning framework tailored for RS tasks. BiMoRS employs a frozen image captioning model (e.g., BLIP-2) to extract textual semantic summaries from RS images. These captions are tokenized using a BERT tokenizer and fused with high-level visual features from the CLIP encoder. A lightweight cross-attention module then conditions a learnable query prompt on the fused textual-visual representation, yielding contextualized prompts without altering the CLIP backbone. We evaluate BiMoRS on four RS datasets across three domain generalization (DG) tasks and observe consistent performance gains, outperforming strong baselines by up to 2% on average. Codes are available at https://github.com/ipankhi/BiMoRS.

</details>


### [42] [Decoupling Perception and Calibration: Label-Efficient Image Quality Assessment Framework](https://arxiv.org/abs/2601.20689)
*Xinyue Li,Zhichao Zhang,Zhiming Xu,Shubo Xu,Xiongkuo Min,Yitong Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出LEAF框架，通过从大型多模态语言模型（MLLM）教师中蒸馏感知质量先验到轻量级学生回归器，实现低人类标注成本下的MOS校准，显著减少对人工标注的需求并保持与人类评分的高度相关性。


<details>
  <summary>Details</summary>
Motivation: 当前基于MLLM的图像质量评估（IQA）受限于大量主观评分（MOS）标注，而核心瓶颈并非感知能力，而是MOS尺度校准；因此需要一种更高效、少标注的方法来实现高质量评估。

Method: 利用MLLM教师进行密集监督（点级判断和成对偏好），并估计决策可靠性；通过联合蒸馏使轻量级学生模型学习教师的质量感知模式，并在少量MOS子集上进行校准以匹配人类标注。

Result: 在用户生成和AI生成的IQA基准测试中，该方法显著降低对人工标注的依赖，同时保持强MOS对齐相关性，使轻量级IQA在标注预算有限时成为可行方案。

Conclusion: LEAF框架有效解决了MLLM-based IQA中的标注瓶颈问题，实现了高质量图像质量评估与极低标注成本之间的平衡，为实际应用提供了可行路径。

Abstract: Recent multimodal large language models (MLLMs) have demonstrated strong capabilities in image quality assessment (IQA) tasks. However, adapting such large-scale models is computationally expensive and still relies on substantial Mean Opinion Score (MOS) annotations. We argue that for MLLM-based IQA, the core bottleneck lies not in the quality perception capacity of MLLMs, but in MOS scale calibration. Therefore, we propose LEAF, a Label-Efficient Image Quality Assessment Framework that distills perceptual quality priors from an MLLM teacher into a lightweight student regressor, enabling MOS calibration with minimal human supervision. Specifically, the teacher conducts dense supervision through point-wise judgments and pair-wise preferences, with an estimate of decision reliability. Guided by these signals, the student learns the teacher's quality perception patterns through joint distillation and is calibrated on a small MOS subset to align with human annotations. Experiments on both user-generated and AI-generated IQA benchmarks demonstrate that our method significantly reduces the need for human annotations while maintaining strong MOS-aligned correlations, making lightweight IQA practical under limited annotation budgets.

</details>


### [43] [LEMON: How Well Do MLLMs Perform Temporal Multimodal Understanding on Instructional Videos?](https://arxiv.org/abs/2601.20705)
*Zhuang Yu,Lei Shen,Jing Zhao,Shiliang Sun*

Main category: cs.CV

TL;DR: LEMON 是一个针对多模态理解的讲座式评估基准，专注于需要长时程推理和跨模态整合的 STEM 讲座视频。它包含 2,277 个视频片段，覆盖 5 个学科和 29 门课程，共生成 4,181 个高质量问答对，涵盖多种题型和认知任务。该基准具有语义丰富、模态紧密耦合、时间与教学结构明确以及多轮问答关联等特点，显著优于现有视频基准。实验表明，即使 GPT-4o 等先进 MLLM 在时间推理和教学预测上仍存在明显短板，凸显其挑战性。LEMON 可推动长时序教学内容中多模态感知、推理与生成的发展。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在长时序、知识密集型、时间结构化的教育内容上表现尚不明确，缺乏专门针对此类内容的评估基准，亟需一个能全面检验模型在复杂教学场景下能力的评测体系。

Method: 构建 LEMON 基准，选取真实 STEM 讲座视频，设计高精度问答对，涵盖多学科、多任务、多模态与多轮交互，系统评估模型在感知、推理、生成等层面的表现。

Result: 实验显示，当前最先进的多模态大模型如 GPT-4o 在时间推理和教学意图预测等任务上表现不佳，存在显著性能差距，验证了 LEMON 的挑战性与有效性。

Conclusion: LEMON 是一个可扩展且极具挑战性的基准，能够有效推动多模态大模型在长时序教学内容中的理解与生成能力发展，为未来研究提供重要参考。

Abstract: Recent multimodal large language models (MLLMs) have shown remarkable progress across vision, audio, and language tasks, yet their performance on long-form, knowledge-intensive, and temporally structured educational content remains largely unexplored. To bridge this gap, we introduce LEMON, a Lecture-based Evaluation benchmark for MultimOdal uNderstanding, focusing on STEM lecture videos that require long-horizon reasoning and cross-modal integration. LEMON comprises 2,277 video segments spanning 5 disciplines and 29 courses, with an average duration of 196.1 seconds, yielding 4,181 high-quality QA pairs, including 3,413 multiple-choice and 768 open-ended questions. Distinct from existing video benchmarks, LEMON features: (1) semantic richness and disciplinary density, (2) tightly coupled video-audio-text modalities, (3) explicit temporal and pedagogical structure, and (4) contextually linked multi-turn questioning. It further encompasses six major tasks and twelve subtasks, covering the full cognitive spectrum from perception to reasoning and then to generation. Comprehensive experiments reveal substantial performance gaps across tasks, highlighting that even state-of-the-art MLLMs like GPT-4o struggle with temporal reasoning and instructional prediction. We expect LEMON to serve as an extensible and challenging benchmark for advancing multimodal perception, reasoning, and generation in long-form instructional contents.

</details>


### [44] [Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction](https://arxiv.org/abs/2601.20720)
*Matej Halinkovic,Nina Masarykova,Alexey Vinel,Marek Galinski*

Main category: cs.CV

TL;DR: Li-ViP3D++ 是一种基于查询的多模态感知与轨迹预测框架，通过提出查询门控可变形融合（QGDF）在查询空间中实现相机与激光雷达的端到端融合。该方法通过掩码注意力聚合多视角图像信息，利用可微分的鸟瞰图采样提取激光雷达上下文，并通过查询条件门控自适应加权视觉与几何线索。模型联合优化检测、跟踪和多假设轨迹预测，在nuScenes数据集上显著提升性能（EPA 0.335，mAP 0.502），降低误检率（FP ratio 0.147），且推理速度更快（139.82 ms vs. 145.91 ms）。


<details>
  <summary>Details</summary>
Motivation: 现有模块化流水线限制信息流动并放大上游误差；尽管已有基于查询的端到端感知与预测模型，但相机与激光雷达在查询空间中的互补性未被充分挖掘。当前融合方法依赖启发式对齐和离散选择步骤，导致信息利用不充分并引入偏差。

Method: 提出查询门控可变形融合（QGDF）机制：（i）通过跨相机和特征层级的掩码注意力聚合图像证据；（ii）通过可微分的鸟瞰图采样提取激光雷达上下文，并引入学习的每查询偏移量；（iii）采用查询条件门控机制，自适应地调整每个目标的视觉与几何线索权重。整个模型以端到端方式联合优化检测、跟踪与轨迹预测。

Result: 在nuScenes数据集上，Li-ViP3D++ 在端到端行为和检测质量方面均优于基线，取得更高的 EPA（0.335）和 mAP（0.502），同时大幅降低误报率（FP ratio 0.147），且推理速度更快（139.82 ms vs. 145.91 ms），证明了查询空间内可微分融合的有效性与实用性。

Conclusion: 查询空间中的全可微分相机-激光雷达融合能够显著提升端到端感知与预测系统的鲁棒性，同时保持良好的部署效率，为自动驾驶系统提供了更优的多模态融合范式。

Abstract: End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explored. Models often rely on fusion schemes that introduce heuristic alignment and discrete selection steps which prevent full utilization of available information and can introduce unwanted bias. We propose Li-ViP3D++, a query-based multimodal PnP framework that introduces Query-Gated Deformable Fusion (QGDF) to integrate multi-view RGB and LiDAR in query space. QGDF (i) aggregates image evidence via masked attention across cameras and feature levels, (ii) extracts LiDAR context through fully differentiable BEV sampling with learned per-query offsets, and (iii) applies query-conditioned gating to adaptively weight visual and geometric cues per agent. The resulting architecture jointly optimizes detection, tracking, and multi-hypothesis trajectory forecasting in a single end-to-end model. On nuScenes, Li-ViP3D++ improves end-to-end behavior and detection quality, achieving higher EPA (0.335) and mAP (0.502) while substantially reducing false positives (FP ratio 0.147), and it is faster than the prior Li-ViP3D variant (139.82 ms vs. 145.91 ms). These results indicate that query-space, fully differentiable camera-LiDAR fusion can increase robustness of end-to-end PnP without sacrificing deployability.

</details>


### [45] [Compression Tells Intelligence: Visual Coding, Visual Token Technology, and the Unification](https://arxiv.org/abs/2601.20742)
*Xin Jin,Jinming Liu,Yuntao Wei,Junyan Lin,Zhicheng Wang,Jianguo Huang,Xudong Yang,Yanxiao Liu,Wenjun Zeng*

Main category: cs.CV

TL;DR: 本文综述了视觉编码与视觉标记技术两大主流技术体系，揭示其在压缩效率与模型性能之间的内在联系，并提出统一的优化框架。基于该框架，实现双向知识迁移，预测下一代视觉编解码与标记技术的发展方向。实验表明，面向任务的标记技术在多模态大模型、AIGC和具身智能等实际应用中具有巨大潜力，为未来建立类似H.264/265的通用高效智能标记标准提供了可能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉编码与视觉标记技术在压缩效率与模型性能之间的共性，推动二者融合以指导下一代智能视觉系统的设计与标准化。

Method: 通过分析视觉编码与视觉标记技术的本质，提出统一的优化框架，结合理论建模与实验验证，实现跨技术体系的洞察与前瞻。

Result: 验证了任务导向型视觉标记在多模态大模型、AI生成内容及具身智能中的显著潜力，展示了向通用高效智能标记标准演进的可能性。

Conclusion: 压缩效率与模型性能之间存在深层关联，统一的优化视角可加速智能视觉技术发展，未来有望形成类传统编解码标准的通用智能标记体系。

Abstract: "Compression Tells Intelligence", is supported by research in artificial intelligence, particularly concerning (multimodal) large language models (LLMs/MLLMs), where compression efficiency often correlates with improved model performance and capabilities. For compression, classical visual coding based on traditional information theory has developed over decades, achieving great success with numerous international industrial standards widely applied in multimedia (e.g., image/video) systems. Except that, the recent emergingvisual token technology of generative multi-modal large models also shares a similar fundamental objective like visual coding: maximizing semantic information fidelity during the representation learning while minimizing computational cost. Therefore, this paper provides a comprehensive overview of two dominant technique families first -- Visual Coding and Vision Token Technology -- then we further unify them from the aspect of optimization, discussing the essence of compression efficiency and model performance trade-off behind. Next, based on the proposed unified formulation bridging visual coding andvisual token technology, we synthesize bidirectional insights of themselves and forecast the next-gen visual codec and token techniques. Last but not least, we experimentally show a large potential of the task-oriented token developments in the more practical tasks like multimodal LLMs (MLLMs), AI-generated content (AIGC), and embodied AI, as well as shedding light on the future possibility of standardizing a general token technology like the traditional codecs (e.g., H.264/265) with high efficiency for a wide range of intelligent tasks in a unified and effective manner.

</details>


### [46] [FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models](https://arxiv.org/abs/2601.20791)
*Haonan Zhong,Wei Song,Tingxu Han,Maurice Pagnucco,Jingling Xue,Yang Song*

Main category: cs.CV

TL;DR: FairT2V 是一种无需微调的去偏框架，用于文本到视频生成，通过基于锚点的球面测地变换中和提示嵌入，减少由预训练文本编码器引起的性别偏见，同时保持语义和时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 文本到视频扩散模型存在显著的性别偏见，尤其源于预训练文本编码器对中性提示中的隐含性别关联的编码，但目前对此类偏见的研究仍不充分。

Method: 通过分析发现偏见主要来自文本编码器；提出基于锚点的球面测地变换来中和提示嵌入，并在早期身份形成阶段使用动态去噪调度以维持时间一致性；引入结合VideoLLM推理与人工验证的视频级公平性评估协议。

Result: 在Open-Sora模型上实验表明，FairT2V显著降低了不同职业场景下的群体偏见，且对视频质量影响极小。

Conclusion: FairT2V 有效缓解了文本到视频生成中的性别偏见问题，为实现更公平的生成模型提供了可行路径。

Abstract: Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos.
  Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.

</details>


### [47] [A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion](https://arxiv.org/abs/2601.20847)
*Willams de Lima Costa,Thifany Ketuli Silva de Souza,Jonas Ferreira Silva,Carlos Gabriel Bezerra Pereira,Bruno Reis Vila Nova,Leonardo Silvino Brito,Rafael Raider Leoni,Juliano Silva,Valter Ferreira,Sibele Miguel Soares Neto,Samantha Uehara,Daniel Giacomo,João Marcelo Teixeira,Veronica Teichrieb,Cristiano Coelho de Araújo*

Main category: cs.CV

TL;DR: 本文提出一种多模态框架，融合图像与惯性测量数据，通过轻量级双向交叉注意力模块和自适应门控层提升道路表面分类（RSC）在不同环境下的泛化能力。为弥补现有基准数据集的不足，作者构建了新数据集ROAD，包含真实世界多模态数据、视觉仅数据和合成数据三部分，覆盖多样光照、天气与路面条件。实验表明，该方法在PVS基准上比当前最佳方法提升1.4个百分点，在ROAD多模态子集上提升11.6个百分点，且对少数类表现更优，具备在夜间、暴雨、混合路面等复杂场景下的稳定性能。结果证明，结合低成本摄像头与IMU传感器及多模态注意力机制，可为道路表面理解提供高效、鲁棒的解决方案，尤其适用于环境变化大且成本敏感的地区。


<details>
  <summary>Details</summary>
Motivation: 现有道路表面分类技术受限于感知模态单一和数据集环境多样性不足，难以在复杂或变化环境下泛化，亟需更鲁棒、可扩展的解决方案以支持环境感知型预测性维护系统。

Method: 提出一种基于轻量级双向交叉注意力模块与自适应门控层的多模态融合框架，结合图像与惯性测量数据，动态调整各模态贡献以应对领域偏移。同时构建新数据集ROAD，包含真实世界、视觉仅和合成三类数据，用于全面评估模型性能。

Result: 在PVS基准上较之前最好方法提升1.4个百分点，在新构建的ROAD多模态子集上提升11.6个百分点；在少数类上F1分数更高，且在夜间、暴雨、混合路面等极端条件下保持稳定性能。

Conclusion: 融合低成本摄像头与IMU传感器，并采用多模态注意力机制，可实现高效、鲁棒的道路表面分类，为环境变化大且资源受限区域提供可行的智能交通感知基础。

Abstract: Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.

</details>


### [48] [FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models](https://arxiv.org/abs/2601.20857)
*Hongyu Zhou,Zisen Shao,Sheng Miao,Pan Wang,Dongfeng Bai,Bingbing Liu,Yiyi Liao*

Main category: cs.CV

TL;DR: FreeFix是一种无需微调的新型方法，通过利用预训练图像扩散模型提升神经辐射场和3D高斯点阵在远超视图下的渲染质量，采用交错的2D-3D优化策略与像素级置信度掩码，实现高质量且具强泛化能力的多视角一致性合成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在泛化与保真度之间存在权衡：微调扩散模型可提高保真度但易过拟合，而免微调方法虽保持泛化性却常牺牲细节质量。本文旨在突破这一瓶颈，提升远超视图下的渲染表现。

Method: 提出一种交错的2D-3D精炼策略，结合预训练图像扩散模型进行一致性优化；引入每像素置信度掩码，识别不确定区域进行针对性修正，避免全局微调。

Result: 在多个数据集上验证，FreeFix显著提升了多帧一致性，性能达到或超越依赖微调的方法，同时保持了良好的泛化能力。

Conclusion: FreeFix成功实现了无需微调下高质量、高一致性的新视角合成，为高效且鲁棒的3D内容生成提供了新范式。

Abstract: Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [49] [From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text](https://arxiv.org/abs/2601.19913)
*Shinwoo Park,Yo-Sub Han*

Main category: cs.CL

TL;DR: 该研究探讨了通过结构化校准提升专家识别人类撰写韩语文本与大语言模型输出的能力，提出LREAD评分标准，基于韩国国家写作规范并针对微小语言特征（如标点使用、空格行为、语体转换）进行调整。在三阶段纵向盲测实验中，韩语语言学专业学生的表现从60%准确率提升至100%，且标注者间一致性显著提高（Fleiss' kappa从-0.09升至0.82）。相比现有大模型检测工具，经过校准的人类更依赖语言特异性的细微诊断，这些特征难以被粗粒度的语篇先验捕捉。研究证明，基于评分标准的专家判断可作为非英语语境下自动化检测的有效可解释补充，并公开了完整评分标准和校准检测特征分类体系。


<details>
  <summary>Details</summary>
Motivation: 当前人类撰写的韩语文本与流畅的大语言模型输出之间难以区分，即使对语言学训练有素的读者也容易因表面形式良好而过度信任生成文本。因此，亟需探索如何将专家检测能力视为可学习技能，并通过系统化方法加以提升。

Method: 引入LREAD评分标准，结合韩国国家写作标准并适配微小语言特征；采用三阶段纵向盲测设计：第一阶段仅凭直觉判断；第二阶段要求依据标准打分并提供明确理由；第三阶段评估在保留的小学作文上的领域专精表现。

Result: 在三阶段测试中，多数投票准确率从60%提升至100%，标注者间一致性显著增强（Fleiss' kappa从-0.09上升至0.82）。经校准的人类专家更依赖语言特定的微诊断特征，这些特征未被现有自动检测器充分捕捉。

Conclusion: 基于评分标准的结构化校准能够显著提升专家在非英语语境下的文本检测能力，为自动化检测提供了可解释的补充手段，适用于韩语等非英语语言环境。研究公开了完整评分标准与检测特征分类体系，支持后续研究与应用。

Abstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior, and register shifts). In a three-phase longitudinal blind protocol with Korean linguistics majors, Phase 1 measures intuition-only detection, Phase 2 enforces criterion-level scoring with explicit justifications, and Phase 3 evaluates domain-focused mastery on held-out elementary essays. Across phases, majority-vote accuracy increases from 60% to 100%, accompanied by stronger inter-annotator agreement (Fleiss' kappa: -0.09 --> 0.82). Compared to state-of-the-art LLM detectors, calibrated humans rely more on language-specific micro-diagnostics that are not well captured by coarse discourse priors. Our findings suggest that rubric-scaffolded expert judgment can serve as an interpretable complement to automated detectors for non-English settings, and we release the full rubric and a taxonomy of calibrated detection signatures.

</details>


### [50] [Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments](https://arxiv.org/abs/2601.19914)
*Maxwell Crouse,Ibrahim Abdelaziz,Kshitij Fadnis,Siva Sankalp Patel,Kinjal Basu,Chulaka Gunasekara,Sadhana Kumaravel,Asim Munawar,Pavan Kapanipathi*

Main category: cs.CL

TL;DR: 本文提出了一种名为DiGiT-TC的新方法，用于生成不依赖于状态保持环境的多轮工具调用合成数据。该方法通过创新的生成模式，在用户请求中隐式表示某些工具调用，从而在无状态环境中仍能生成具有状态环境特征的对话。实验表明，该方法在标准工具调用基准上表现优异，即使在状态化场景下也展现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有合成多轮工具调用数据的方法通常假设存在可维护状态的执行环境，但在实际应用中（如企业级数据安全要求高或工具规范来自多个来源），这种状态环境并不总是可用。因此，需要一种无需依赖状态环境即可生成高质量工具调用对话的方法。

Method: 提出DiGiT-TC方法，采用一种新颖的生成模式，使工具调用信息能够被隐式嵌入到用户请求中，从而在无状态环境下也能模拟出类似状态环境下的对话行为。

Result: 在标准工具调用基准测试中，DiGiT-TC表现出色，即便在支持状态的设置下也实现了显著的性能提升，证明其在真实复杂场景中的有效性与鲁棒性。

Conclusion: DiGiT-TC是一种高效且实用的合成数据生成方法，能够在缺乏状态保持环境的情况下生成高质量、具备现实意义的多轮工具调用对话，为训练小型语言模型提供了强有力的支持。

Abstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is available, this is advantageous as it allows for the validity of an interaction to be determined by whether or not the state of the execution environment matches to some prespecified objective. Unfortunately, this does not hold in many real-world tool use settings, e.g., in enterprise settings where data security is of the utmost importance or in cases where tool specifications are synthesized from multiple sources. In this work, we address this gap by introducing a data generation method, DiGiT-TC, that is designed to produce tool calling conversations that have the characteristics of conversations generated through search in a stateful environment. The key to our technique lies in a novel generation pattern that allows our approach to implicitly represent certain tool calls in the user request. We validate our approach on standard tool calling benchmarks and demonstrate that, even in stateful problem settings, our approach results in strong performance gains.

</details>


### [51] [Modeling Next-Token Prediction as Left-Nested Intuitionistic Implication](https://arxiv.org/abs/2601.19915)
*Paul Tarau*

Main category: cs.CL

TL;DR: 提出了一种基于直觉逻辑的神经架构——箭头语言模型（Arrow Language Model），通过将前缀编码为左嵌套蕴含链，利用非交换组合保持顺序。下一词预测对应于假言推理（modus ponens），序列处理则对应于柯里-霍华德对应下的构造性证明扩展。该模型通过基于Prolog的定理证明器验证了其基本性质，并揭示了交换与非交换序列、单标记与多标记预测之间的关系。研究发现，乘法RNN在形式上自然地从下一词预测的证明论解释中产生，同时提出了一个实用的低秩神经实现，将该模型置于Transformer和状态空间模型的框架中进行定位。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型依赖注意力机制对令牌进行加性嵌入混合，但缺乏对序列顺序的内在逻辑建模。本文旨在探索一种基于直觉逻辑的替代架构，以更严谨的数学基础来解释和实现序列生成过程，从而增强模型的可解释性和推理能力。

Method: 采用直觉蕴含逻辑构建左嵌套蕴含链表示前缀，将下一词预测视为假言推理操作；利用柯里-霍华德对应将序列处理视为构造性证明扩展；设计基于Prolog的定理证明器验证模型性质；提出低秩神经实现方式，并与Transformer及状态空间模型进行对比分析。

Result: 成功构建了具有逻辑基础的神经架构，证明其等价于乘法RNN；低秩实现具备实用性；模型在序列建模方面展现出与现有主流模型不同的理论优势，尤其在顺序敏感性和推理能力方面表现突出。

Conclusion: 该研究为语言模型提供了全新的逻辑基础视角，表明基于直觉逻辑的神经架构不仅能有效建模序列，还具备更强的可解释性与推理能力，是当前Transformer主导范式的重要补充与替代方案。

Abstract: We introduce the \emph{Arrow Language Model}, a neural architecture derived from an intuitionistic-logic interpretation of next-token prediction. Instead of representing tokens as additive embeddings mixed by attention, we encode a prefix as a \emph{left-nested implication chain} whose structure preserves order through non-commutative composition. Next-token prediction corresponds to \emph{modus ponens}, and sequence processing becomes constructive proof extension under the Curry--Howard correspondence. Our Prolog-based specialized theorem provers validate fundamental properties of the neural models, among which relations between commutative vs. non-commutative sequencing and single-token vs. multi-token prediction choices. We show that a neural architecture equivalent to multiplicative RNNs arises naturally from a proof-theoretic interpretation of next-token prediction as nested intuitionistic implication, we present a practical low-rank neural realization and position the model relative to Transformers and state-space models.
  Keywords: logic-based derivation of neural architectures, intuitionistic implicational logic, token-as-operator neural models, state-space models, alternatives to transformer-based foundational models.

</details>


### [52] [PaperAudit-Bench: Benchmarking Error Detection in Research Papers for Critical Automated Peer Review](https://arxiv.org/abs/2601.19916)
*Songjun Tu,Yiwen Ma,Jiahao Lin,Qichao Zhang,Xiangyuan Lan,Junfeng. Li,Nan Xu,Linjing Li,Dongbin Zhao*

Main category: cs.CL

TL;DR: 本文提出PaperAudit-Bench，包含PaperAudit-Dataset（用于长上下文下评估的错误数据集）和PaperAudit-Review（结合结构化错误检测与证据感知生成的自动化评审框架），实验表明大模型在识别复杂、分布性错误时表现不一，而引入显式错误检测可提升评审严格性和区分度，且数据集支持通过SFT和RL训练轻量级检测器，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型生成的同行评审虽流畅，但在面对细微且分散于论文各部分的实质性问题时缺乏足够的批判性严谨性，亟需更可靠的评估工具与方法以提升评审质量。

Method: 构建PaperAudit-Bench，包括覆盖单节内及跨节推理错误的PaperAudit-Dataset，以及融合结构化错误检测与证据感知生成的PaperAudit-Review自动化评审框架，并利用该数据集进行SFT与强化学习训练轻量级检测器。

Result: 实验显示不同模型在错误检测能力上存在显著差异；引入显式错误检测的评审流程能产生更严格、更具区分度的评估结果；轻量级检测器可通过该数据集有效训练，实现低成本高效率的错误识别。

Conclusion: PaperAudit-Bench为长上下文场景下的学术评审评估提供了可靠基准，显式错误检测机制显著提升评审质量，且轻量级检测器训练可行，具备实际应用潜力。

Abstract: Large language models can generate fluent peer reviews, yet their assessments often lack sufficient critical rigor when substantive issues are subtle and distributed across a paper. In this paper, we introduce PaperAudit-Bench, which consists of two components: (1) PaperAudit-Dataset, an error dataset covering both errors identifiable within individual sections and those requiring cross-section reasoning, designed for controlled evaluation under long-context settings; and (2) PaperAudit-Review, an automated review framework that integrates structured error detection with evidence-aware review generation to support critical assessment. Experiments on PaperAudit-Bench reveal large variability in error detectability across models and detection depths, highlighting the difficulty of identifying such errors under long-context settings. Relative to representative automated reviewing baselines, incorporating explicit error detection into the review workflow produces systematically stricter and more discriminative evaluations, demonstrating its suitability for peer review. Finally, we show that the dataset supports training lightweight LLM detectors via SFT and RL, enabling effective error detection at reduced computational cost.

</details>


### [53] [Lowest Span Confidence: A Zero-Shot Metric for Efficient and Black-Box Hallucination Detection in LLMs](https://arxiv.org/abs/2601.19918)
*Yitong Qiao,Licheng Pan,Yu Mi,Lei Liu,Yue Shen,Fei Sun,Zhixuan Chu*

Main category: cs.CL

TL;DR: 提出了一种名为最低片段置信度（LSC）的新颖零样本度量方法，用于在资源受限条件下检测大语言模型中的幻觉。该方法仅需一次前向传播和输出概率，通过滑动窗口机制评估语义连贯片段的联合似然，识别低置信度区域以捕捉与事实不一致相关的局部不确定性模式，有效缓解困惑度稀释效应和最小词元概率的噪声敏感性，在多个SOTA模型和基准上均显著优于现有零样本基线。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法通常依赖于昂贵的采样策略或白盒模型状态，这些假设在常见的API场景中不现实且效率低下，因此需要一种在极低资源需求下仍能有效检测幻觉的方法。

Method: 提出最低片段置信度（LSC）方法，利用滑动窗口机制分析可变长度n-gram的边际置信度，通过识别最低置信度区域来捕捉与事实不一致相关的局部不确定性模式，仅需一次前向传播和输出概率。

Result: 在多种SOTA LLM和多样化的基准测试中，LSC始终优于现有的零样本基线，即使在资源受限条件下也表现出强大的幻觉检测性能。

Conclusion: LSC是一种高效、鲁棒且适用于实际部署场景的零样本幻觉检测方法，能够在仅需单次前向传播的情况下实现优异的检测效果，为高风险应用中的可靠性提供了有力支持。

Abstract: Hallucinations in Large Language Models (LLMs), i.e., the tendency to generate plausible but non-factual content, pose a significant challenge for their reliable deployment in high-stakes environments. However, existing hallucination detection methods generally operate under unrealistic assumptions, i.e., either requiring expensive intensive sampling strategies for consistency checks or white-box LLM states, which are unavailable or inefficient in common API-based scenarios. To this end, we propose a novel efficient zero-shot metric called Lowest Span Confidence (LSC) for hallucination detection under minimal resource assumptions, only requiring a single forward with output probabilities. Concretely, LSC evaluates the joint likelihood of semantically coherent spans via a sliding window mechanism. By identifying regions of lowest marginal confidence across variable-length n-grams, LSC could well capture local uncertainty patterns strongly correlated with factual inconsistency. Importantly, LSC can mitigate the dilution effect of perplexity and the noise sensitivity of minimum token probability, offering a more robust estimate of factual uncertainty. Extensive experiments across multiple state-of-the-art (SOTA) LLMs and diverse benchmarks show that LSC consistently outperforms existing zero-shot baselines, delivering strong detection performance even under resource-constrained conditions.

</details>


### [54] [FastWhisper: Adaptive Self-knowledge Distillation for Real-time Automatic Speech Recognition](https://arxiv.org/abs/2601.19919)
*Junseok Lee,Nahoon Kim,Sangyong Lee,Chang-Jae Chun*

Main category: cs.CL

TL;DR: 本文提出了一种自适应自知识蒸馏（ASKD）方法，通过动态降低学生模型对教师模型的依赖，增强其自训练能力，并利用自知识蒸馏提升学生模型的泛化性能。进一步将Whisper模型压缩为更小的FastWhisper版本，在后训练设置下，FastWhisper的词错误率比教师模型低1.07%，推理速度提升5倍。


<details>
  <summary>Details</summary>
Motivation: 先前的知识蒸馏方法主要关注学生模型学习教师模型的预测分布，但可能继承教师模型的缺陷，导致泛化能力下降。因此需要一种新方法来缓解这一问题。

Method: 提出自适应自知识蒸馏（ASKD），通过动态调整学生模型对教师模型的依赖程度，增强其自我训练能力，并结合自知识蒸馏机制提升泛化性能。

Result: 在后训练设置下，FastWhisper的词错误率比原始Whisper模型低1.07%，且推理速度提升了5倍。

Conclusion: ASKD有效提升了学生模型的泛化能力，同时实现高效压缩；所提出的FastWhisper在保持高精度的同时显著提升推理效率。

Abstract: Knowledge distillation is one of the most effective methods for model compression. Previous studies have focused on the student model effectively training the predictive distribution of the teacher model. However, during training, the student model may inherit the shortcomings of the teacher model, which can lead to a decline in generalization capacity. To mitigate this issue, we propose adaptive self-knowledge distillation (ASKD), which dynamically reduces the dependence of the teacher model to improve the self-training capacity, and performs the self-knowledge distillation method to improve the generalization capacity of the student model. We further distill the Whisper model into a smaller variant, called FastWhisper. In our post-training setting, FastWhisper achieved a word error rate of 1.07% lower than the teacher model Whisper, and its relative inference time was 5 times faster.

</details>


### [55] [Demystifying Multi-Agent Debate: The Role of Confidence and Diversity](https://arxiv.org/abs/2601.19921)
*Xiaochen Zhu,Caiqi Zhang,Yizhou Chi,Tom Stafford,Nigel Collier,Andreas Vlachos*

Main category: cs.CL

TL;DR: 本文研究了多智能体辩论（MAD）在提升大语言模型性能中的应用，发现传统MAD因缺乏观点多样性与信心校准而表现不佳。为此提出两种轻量级改进：一是基于多样性的初始答案选择，提高正确假设的初始出现概率；二是基于信心的辩论协议，使智能体根据他人信心进行更新。理论和实验证明，这两种方法能显著提升辩论成功率，优于传统MAD和多数投票，在六个推理型问答基准上均表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体辩论（MAD）虽计算成本高，但常不如简单多数投票有效，其根本原因在于缺乏观点多样性与信心校准机制，导致无法可靠提升决策质量。

Method: 提出两种干预措施：(1) 多样性感知初始化，从更丰富的候选答案中选取初始答案以增加正确解存在的可能性；(2) 信心调节辩论协议，允许智能体表达校准后的信心，并据此调整自身信念。

Result: 在六个推理型问答任务中，所提方法均显著优于传统MAD和多数投票，且理论分析表明多样性初始化提升成功先验概率，信心调节使辩论系统性趋向正确答案。

Conclusion: 通过引入观点多样性和信心校准机制，可显著提升多智能体辩论的有效性，揭示了人类集体决策机制对大模型辩论设计的启发意义。

Abstract: Multi-agent debate (MAD) is widely used to improve large language model (LLM) performance through test-time scaling, yet recent work shows that vanilla MAD often underperforms simple majority vote despite higher computational cost. Studies show that, under homogeneous agents and uniform belief updates, debate preserves expected correctness and therefore cannot reliably improve outcomes. Drawing on findings from human deliberation and collective decision-making, we identify two key mechanisms missing from vanilla MAD: (i) diversity of initial viewpoints and (ii) explicit, calibrated confidence communication. We propose two lightweight interventions. First, a diversity-aware initialisation that selects a more diverse pool of candidate answers, increasing the likelihood that a correct hypothesis is present at the start of debate. Second, a confidence-modulated debate protocol in which agents express calibrated confidence and condition their updates on others' confidence. We show theoretically that diversity-aware initialisation improves the prior probability of MAD success without changing the underlying update dynamics, while confidence-modulated updates enable debate to systematically drift to the correct hypothesis. Empirically, across six reasoning-oriented QA benchmarks, our methods consistently outperform vanilla MAD and majority vote. Our results connect human deliberation with LLM-based debate and demonstrate that simple, principled modifications can substantially enhance debate effectiveness.

</details>


### [56] [HEART: A Unified Benchmark for Assessing Humans and LLMs in Emotional Support Dialogue](https://arxiv.org/abs/2601.19922)
*Laya Iyer,Kriti Aggarwal,Sanmi Koyejo,Gail Heyman,Desmond C. Ong,Subhabrata Mukherjee*

Main category: cs.CL

TL;DR: HEART is a framework that directly compares human and LLM performance in emotional-support conversations across five dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following. It uses blinded human raters and LLM-as-judge evaluators to assess responses in multi-turn dialogues. Results show some frontier models match or exceed average human empathy and consistency, while humans still lead in adaptive reframing, tension-naming, and nuanced tone shifts—especially under adversarial conditions. Human and LLM judge preferences align on ~80% of comparisons, indicating convergence in evaluation criteria. HEART establishes a unified benchmark for assessing affective conversational competence independent of general language or reasoning ability.


<details>
  <summary>Details</summary>
Motivation: Current language models excel in linguistic fluency but lack clear understanding of interpersonal skills crucial for supportive conversation—such as emotion reading, tone adjustment, and handling distress. There is no standardized way to compare human and model performance in these nuanced social domains. This work aims to fill that gap by creating a rigorous, science-grounded evaluation framework.

Method: The HEART framework evaluates paired human and model responses in multi-turn emotional-support dialogues using blinded human raters and an ensemble of LLM-as-judge evaluators. Evaluations follow a rubric based on interpersonal communication science, measuring five key dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following.

Result: Frontier LLMs achieve or surpass average human performance in perceived empathy and consistency. Humans retain advantages in adaptive reframing, naming emotional tension, and subtle tone modulation—particularly in challenging turns. Human and LLM judges agree on ~80% of pairwise comparisons, with similar rationale focus across HEART dimensions, suggesting converging standards for evaluating supportive quality.

Conclusion: HEART positions supportive dialogue as a distinct capability axis, separable from general reasoning or linguistic fluency. It provides a unified empirical foundation for understanding the strengths, weaknesses, and scaling trends of model-generated support relative to human judgment, enabling future development of more socially competent AI.

Abstract: Supportive conversation depends on skills that go beyond language fluency, including reading emotions, adjusting tone, and navigating moments of resistance, frustration, or distress. Despite rapid progress in language models, we still lack a clear way to understand how their abilities in these interpersonal domains compare to those of humans. We introduce HEART, the first-ever framework that directly compares humans and LLMs on the same multi-turn emotional-support conversations. For each dialogue history, we pair human and model responses and evaluate them through blinded human raters and an ensemble of LLM-as-judge evaluators. All assessments follow a rubric grounded in interpersonal communication science across five dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following. HEART uncovers striking behavioral patterns. Several frontier models approach or surpass the average human responses in perceived empathy and consistency. At the same time, humans maintain advantages in adaptive reframing, tension-naming, and nuanced tone shifts, particularly in adversarial turns. Human and LLM-as-judge preferences align on about 80 percent of pairwise comparisons, matching inter-human agreement, and their written rationales emphasize similar HEART dimensions. This pattern suggests an emerging convergence in the criteria used to assess supportive quality. By placing humans and models on equal footing, HEART reframes supportive dialogue as a distinct capability axis, separable from general reasoning or linguistic fluency. It provides a unified empirical foundation for understanding where model-generated support aligns with human social judgment, where it diverges, and how affective conversational competence scales with model size.

</details>


### [57] [Table-BiEval: A Self-Supervised, Dual-Track Framework for Decoupling Structure and Content in LLM Evaluation](https://arxiv.org/abs/2601.19923)
*Boxiang Zhao,Qince Li,Zhonghao Wang,Zelin Cao,Yi Wang,Peng Cheng,Bo Lin*

Main category: cs.CL

TL;DR: 本文提出Table-BiEval，一种无需人工参与的自监督评估框架，用于量化评估大语言模型在将自然语言转化为结构化格式及处理表格信息方面的表现。该框架通过确定性中间表示，分离结构与内容，利用内容语义准确率和归一化树编辑距离进行评估，实证分析了15个先进LLM在层次结构与扁平表格两个拓扑维度上的性能。结果表明模型间存在显著差异，中等规模模型在结构效率上甚至优于大型模型，且深层递归嵌套仍是当前架构的普遍瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法有效衡量大语言模型在生成代码类输出时的结构保真度，传统文本指标难以检测语义偏移，亟需一种无需人工干预的自动化评估机制来精准评估模型在结构化任务中的表现。

Method: 提出Table-BiEval框架，基于确定性中间表示，通过计算内容语义准确率和归一化树编辑距离，实现对结构与内容的解耦评估，并应用于15个主流大语言模型在层次结构与扁平表格任务上的性能测试。

Result: 实验结果显示不同模型间性能差异显著；中等规模模型在结构效率方面表现优于大型模型；深层递归嵌套仍是当前大语言模型架构中的普遍瓶颈。

Conclusion: Table-BiEval提供了一种高效、可扩展的自监督评估方法，能够有效揭示大语言模型在结构化输出任务中的真实能力，为模型选型与架构优化提供了重要依据。

Abstract: As Large Language Models (LLMs) evolve into autonomous agents, the capability to faithfully translate natural language into rigorous structured formats-essential for tool invocation-and to convert complex tabular information into machine-readable specifications has become paramount. However, current evaluations lack effective methodologies to measure this structural fidelity without costly human intervention, as traditional text metrics fail to detect semantic drift in code-like outputs. This paper proposes Table-BiEval, a novel approach based on a human-free, self-supervised evaluation framework, to assess LLMs performance quantitatively. By leveraging deterministic Intermediate Representations, our framework calculates Content Semantic Accuracy and Normalized Tree Edit Distance to decouple structure from content. Also, it empirically evaluates 15 state-of-the-art LLMs across dual topological dimensions-hierarchical structures and flat tables. The results reveal substantial variability, highlighting that mid-sized models can surprisingly outperform larger counterparts in structural efficiency and confirming that deep recursive nesting remains a universal bottleneck for current architectures.

</details>


### [58] [OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling](https://arxiv.org/abs/2601.19924)
*Yitian Chen,Cheng Cheng,Yinan Sun,Zi Ling,Dongdong Ge*

Main category: cs.CL

TL;DR: 本文提出OPT-ENGINE，一个可扩展的基准框架，用于评估大语言模型（LLMs）在优化建模中的表现，涵盖10个运筹学领域任务，包括5个线性规划和5个混合整数规划。通过该框架，研究了LLMs在复杂度提升下的泛化能力与推理瓶颈，发现工具集成推理在复杂任务中表现更稳健，而纯文本推理存在上限；同时，约束自动构建是主要性能瓶颈。结果为下一代优化型LLMs的发展提供了指导。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在优化建模方面虽有进展，但其在复杂真实任务中的能力边界尚不明确，缺乏可控且可扩展的评估框架，亟需系统评估其泛化能力和推理瓶颈。

Method: 提出OPT-ENGINE基准框架，包含10个运筹学任务，涵盖线性规划与混合整数规划，设计不同复杂度层级，通过对比工具集成推理与纯文本推理，分析模型在问题理解、约束建模与解生成各阶段的表现，识别瓶颈环节。

Result: 工具集成推理在高复杂度任务中表现出更强的鲁棒性，而纯文本推理达到性能天花板；约束自动化建模是主要瓶颈环节。

Conclusion: 当前LLMs在复杂优化任务中受限于约束建模能力，未来应重点发展工具协同的推理架构以提升性能。

Abstract: Large Language Models (LLMs) have demonstrated impressive progress in optimization modeling, fostering a rapid expansion of new methodologies and evaluation benchmarks. However, the boundaries of their capabilities in automated formulation and problem solving remain poorly understood, particularly when extending to complex, real-world tasks. To bridge this gap, we propose OPT-ENGINE, an extensible benchmark framework designed to evaluate LLMs on optimization modeling with controllable and scalable difficulty levels. OPT-ENGINE spans 10 canonical tasks across operations research, with five Linear Programming and five Mixed-Integer Programming. Utilizing OPT-ENGINE, we conduct an extensive study of LLMs' reasoning capabilities, addressing two critical questions: 1.) Do LLMs' performance remain robust when generalizing to out-of-distribution optimization tasks that scale in complexity beyond current benchmark levels? and 2.) At what stage, from problem interpretation to solution generation, do current LLMs encounter the most significant bottlenecks? Our empirical results yield two key insights: first, tool-integrated reasoning with external solvers exhibits significantly higher robustness as task complexity escalates, while pure-text reasoning reaches a ceiling; second, the automated formulation of constraints constitutes the primary performance bottleneck. These findings provide actionable guidance for developing next-generation LLMs for advanced optimization. Our code is publicly available at \textcolor{blue}{https://github.com/Cardinal-Operations/OPTEngine}.

</details>


### [59] [Evaluating Large Language Models for Abstract Evaluation Tasks: An Empirical Study](https://arxiv.org/abs/2601.19925)
*Yinuo Liu,Emre Sezgin,Eric A. Youngstrom*

Main category: cs.CL

TL;DR: 该研究评估了ChatGPT-5、Gemini-3-Pro和Claude-Sonnet-4.5在评审学术摘要方面的一致性与可靠性，发现LLMs之间具有良好至优秀的一致性（ICC 0.59–0.87），与人类评审者在整体质量及客观维度上达到中等一致性（ICC ~0.45–0.60），但在主观维度上仅达公平水平（ICC 0.23–0.38）。Gemini在部分维度表现较差。三者与人类平均分差异较小，表明其可批量处理大量摘要，具备辅助评审的潜力，但应在人类专家主导下作为补充工具使用。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在评估复杂学术内容方面的可行性，特别是在科学评审场景中替代或辅助人类评审的潜力，以应对人工评审工作量大、效率低的问题。

Method: 选取160篇本地会议摘要，由14名人类评审员和三款LLMs（ChatGPT-5、Gemini-3-Pro、Claude-Sonnet-4.5）依据同一评分标准进行评分。通过计算组内相关系数（ICC）评估LLM间一致性及与人类评审者的吻合度，并利用Bland-Altman图分析系统偏差与一致性模式。

Result: LLMs之间具有一致性（ICC 0.59–0.87），ChatGPT与Claude在整体质量与客观指标上与人类评审者达到中等一致性（ICC ~0.45–0.60），在主观维度为公平水平（ICC 0.23–0.38）；Gemini在部分维度表现不佳，且在影响与适用性上无可靠性。三款LLM与人类平均分差异较小（分别为0.24、0.42、-0.02），显示其在批量评审中具备实用性。

Conclusion: LLMs可在批量处理学术摘要时提供有效辅助，尤其在客观评价方面表现稳定，但其在主观判断上的局限性表明仍需人类专家参与，应将AI作为补充工具而非替代方案。

Abstract: Introduction: Large language models (LLMs) can process requests and generate texts, but their feasibility for assessing complex academic content needs further investigation. To explore LLM's potential in assisting scientific review, this study examined ChatGPT-5, Gemini-3-Pro, and Claude-Sonnet-4.5's consistency and reliability in evaluating abstracts compared to one another and to human reviewers. Methods: 160 abstracts from a local conference were graded by human reviewers and three LLMs using one rubric. Composite score distributions across three LLMs and fourteen reviewers were examined. Inter-rater reliability was calculated using intraclass correlation coefficients (ICCs) for within-AI reliability and AI-human concordance. Bland-Altman plots were examined for visual agreement patterns and systematic bias. Results: LLMs achieved good-to-excellent agreement with each other (ICCs: 0.59-0.87). ChatGPT and Claude reached moderate agreement with human reviewers on overall quality and content-specific criteria, with ICCs ~.45-.60 for composite, impression, clarity, objective, and results. They exhibited fair agreement on subjective dimensions, with ICC ranging from 0.23-0.38 for impact, engagement, and applicability. Gemini showed fair agreement on half criteria and no reliability on impact and applicability. Three LLMs showed acceptable or negligible mean difference (ChatGPT=0.24, Gemini=0.42, Claude=-0.02) from the human mean composite scores. Discussion: LLMs could process abstracts in batches with moderate agreement with human experts on overall quality and objective criteria. With appropriate process architecture, they can apply a rubric consistently across volumes of abstracts exceeding feasibility for a human rater. The weaker performance on subjective dimensions indicates that AI should serve a complementary role in evaluation, while human expertise remains essential.

</details>


### [60] [The Grammar of Transformers: A Systematic Review of Interpretability Research on Syntactic Knowledge in Language Models](https://arxiv.org/abs/2601.19926)
*Nora Graichen,Iria de-Dios-Flores,Gemma Boleda*

Main category: cs.CL

TL;DR: 本研究系统回顾了337篇评估基于Transformer的语言模型句法能力的论文，分析了1015个模型结果，涵盖多种句法现象和可解释性方法。结果显示，当前研究方法多样但过度集中于英语、BERT模型及易检测的现象（如词性、一致关系）；模型在形式导向现象上表现良好，但在语义接口层面（如指代消解、填空-间隙依赖）表现不一且较弱。建议未来研究应报告完整数据、更好对齐理论与方法、增加机制性方法使用，并拓展语言与现象的覆盖面。


<details>
  <summary>Details</summary>
Motivation: 评估Transformer语言模型在句法能力上的表现，揭示当前研究中的局限与偏差，为未来研究提供方向。

Method: 系统性文献综述，分析337篇相关论文中的1015个模型结果，涵盖多种句法现象与可解释性方法。

Result: 模型在形式导向句法现象（如词性、一致关系）上表现良好，但在语法-语义接口现象（如指代、填空-间隙依赖）上表现不稳定且较弱；研究高度集中于英语和BERT模型，且多关注易测现象。

Conclusion: 当前研究虽方法多样，但存在语言、模型和现象范围过窄的问题；建议未来研究应扩大语言覆盖、丰富研究现象、提升方法严谨性，并加强机制性分析。

Abstract: We present a systematic review of 337 articles evaluating the syntactic abilities of Transformer-based language models, reporting on 1,015 model results from a range of syntactic phenomena and interpretability methods. Our analysis shows that the state of the art presents a healthy variety of methods and data, but an over-focus on a single language (English), a single model (BERT), and phenomena that are easy to get at (like part of speech and agreement). Results also suggest that TLMs capture these form-oriented phenomena well, but show more variable and weaker performance on phenomena at the syntax-semantics interface, like binding or filler-gap dependencies. We provide recommendations for future work, in particular reporting complete data, better aligning theoretical constructs and methods across studies, increasing the use of mechanistic methods, and broadening the empirical scope regarding languages and linguistic phenomena.

</details>


### [61] [Attribution Techniques for Mitigating Hallucinated Information in RAG Systems: A Survey](https://arxiv.org/abs/2601.19927)
*Yuqing Zhao,Ziyao Liu,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 本文调查了基于属性的技巧如何在RAG系统中用于减轻幻觉，填补了统一管道、清晰分类和系统比较方面的空白。通过提出幻觉类型的分类法、统一的属性技术管道，并根据目标幻觉类型回顾技术，讨论其优缺点及实践指南，为未来研究和实际应用提供了洞见。


<details>
  <summary>Details</summary>
Motivation: LLM生成的回答常出现幻觉，缺乏可靠依据；尽管RAG框架通过引入外部参考增强了回答质量，但其检索器与生成器之间的复杂交互也引入了新的幻觉形式。现有基于属性的技术虽有助于确保回答可验证地基于检索内容，但缺乏统一的流程、明确的分类体系以及系统性比较，限制了其有效应用。因此，亟需一个全面的分析框架来识别失败模式并指导实践选择。

Method: 本文提出了一个针对RAG系统中幻觉类型的分类法，构建了一个统一的属性技术实现管道，对不同属性技术按其所针对的幻觉类型进行了系统回顾，并从实际应用角度分析其优势与局限性，提供实用建议。

Result: 该研究成功建立了幻觉类型分类体系，提出了标准化的属性技术流程，系统梳理了各类技术的有效性与适用场景，明确了不同技术在应对特定幻觉类型时的表现差异，为研究人员和开发者提供了可操作的指导原则。

Conclusion: 本综述揭示了当前RAG系统中幻觉问题的多样性和复杂性，强调了基于属性的方法在提升生成可靠性方面的重要性。通过建立分类框架与统一流程，为未来研究指明方向，并为实际部署中的技术选型提供科学依据。

Abstract: Large Language Models (LLMs)-based question answering (QA) systems play a critical role in modern AI, demonstrating strong performance across various tasks. However, LLM-generated responses often suffer from hallucinations, unfaithful statements lacking reliable references. Retrieval-Augmented Generation (RAG) frameworks enhance LLM responses by incorporating external references but also introduce new forms of hallucination due to complex interactions between the retriever and generator. To address these challenges, researchers have explored attribution-based techniques that ensure responses are verifiably supported by retrieved content. Despite progress, a unified pipeline for these techniques, along with a clear taxonomy and systematic comparison of their strengths and weaknesses, remains lacking. A well-defined taxonomy is essential for identifying specific failure modes within RAG systems, while comparative analysis helps practitioners choose appropriate solutions based on hallucination types and application context. This survey investigates how attribution-based techniques are used within RAG systems to mitigate hallucinations and addresses the gap by: (i) outlining a taxonomy of hallucination types in RAG systems, (ii) presenting a unified pipeline for attribution techniques, (iii) reviewing techniques based on the hallucinations they target, and (iv) discussing strengths and weaknesses with practical guidelines. This work offers insights for future research and practical use of attribution techniques in RAG systems.

</details>


### [62] [Towards a Mechanistic Understanding of Large Reasoning Models: A Survey of Training, Inference, and Failures](https://arxiv.org/abs/2601.19928)
*Yi Hu,Jiaqi Gu,Ruxin Wang,Zijun Yao,Hao Peng,Xiaobao Wu,Jianhui Chen,Muhan Zhang,Liangming Pan*

Main category: cs.CL

TL;DR: 本文系统综述了大型推理模型（LRMs）的机制理解，涵盖训练动态、推理机制和非预期行为三大维度，旨在弥合黑箱性能与机制透明性之间的差距，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在性能上取得显著进展，但其内部工作机制尚不清晰，亟需深入探索以提升模型的可解释性和可靠性。

Method: 通过整合近期研究成果，从训练动态、推理机制和非预期行为三个层面系统梳理并分析大型推理模型的内在机制。

Result: 揭示了大型推理模型在训练过程中的关键行为模式，阐明了其推理机制的本质，并识别出潜在的非预期行为，为后续研究提供了理论基础。

Conclusion: 未来的研究应聚焦于应用可解释性、改进方法论以及构建统一的理论框架，以推动大型推理模型的机制研究走向深入。

Abstract: Reinforcement learning (RL) has catalyzed the emergence of Large Reasoning Models (LRMs) that have pushed reasoning capabilities to new heights. While their performance has garnered significant excitement, exploring the internal mechanisms driving these behaviors has become an equally critical research frontier. This paper provides a comprehensive survey of the mechanistic understanding of LRMs, organizing recent findings into three core dimensions: 1) training dynamics, 2) reasoning mechanisms, and 3) unintended behaviors. By synthesizing these insights, we aim to bridge the gap between black-box performance and mechanistic transparency. Finally, we discuss under-explored challenges to outline a roadmap for future mechanistic studies, including the need for applied interpretability, improved methodologies, and a unified theoretical framework.

</details>


### [63] [Stingy Context: 18:1 Hierarchical Code Compression for LLM Auto-Coding](https://arxiv.org/abs/2601.19929)
*David Linus Ostby*

Main category: cs.CL

TL;DR: Stingy Context 提出一种基于树的分层压缩方案，实现 18:1 的上下文压缩比，在自动编码任务中显著减少上下文长度。通过 TREEFRAG 拆解技术，将 23.9 万 token 的真实源码库压缩至 1.1 万 token，同时保持任务准确性。在 12 个前沿模型上对 40 个实际问题测试，成功率高达 94%–97%，成本低，优于传统平坦方法，并缓解了‘迷失在中间’的问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理长上下文时面临计算资源消耗高、信息丢失等问题，尤其在代码生成等任务中易出现‘迷失在中间’现象。为提升效率与准确性，亟需一种高效且保真的上下文压缩方法。

Method: 提出 Stingy Context 压缩框架，采用分层树结构组织上下文，并引入 TREEFRAG 拆解算法，按代码结构层次提取关键片段，实现高效压缩。

Result: 在真实代码库上实现 18:1 的压缩比（239k → 11k tokens），12 个前沿模型在 40 个真实问题上均达到 94%–97% 的成功率，显著优于扁平压缩方法，有效缓解上下文遗忘问题。

Conclusion: Stingy Context 通过树状分层压缩与 TREEFRAG 拆解，实现了高效率、高保真度的上下文压缩，为大规模代码生成任务提供了可行且高效的解决方案。

Abstract: We introduce Stingy Context, a hierarchical tree-based compression scheme achieving 18:1 reduction in LLM context for auto-coding tasks. Using our TREEFRAG exploit decomposition, we reduce a real source code base of 239k tokens to 11k tokens while preserving task fidelity. Empirical results across 12 Frontier models show 94 to 97% success on 40 real-world issues at low cost, outperforming flat methods and mitigating lost-in-the-middle effects.

</details>


### [64] [SDUs DAISY: A Benchmark for Danish Culture](https://arxiv.org/abs/2601.19930)
*Jacob Nielsen,Stine L. Beltoft,Peter Schneider-Kamp,Lukas Galke Poech*

Main category: cs.CL

TL;DR: 本文提出一个名为Daisy的新基准，基于2006年丹麦文化纲要，涵盖从公元前1300年到当代流行音乐、丹麦设计与建筑的741个封闭式问答对，通过语言模型生成问题并经人工审核，兼顾主流与边缘知识，全面反映丹麦文化遗产。


<details>
  <summary>Details</summary>
Motivation: 为了建立一个能全面反映丹麦文化遗产的基准数据集，覆盖从古代考古发现到当代文化的广泛主题，同时兼顾主流与边缘知识，以促进对丹麦文化深度理解的研究。

Method: 基于丹麦文化纲要2006年选定的主题，查询每个文化作品的维基百科页面，利用语言模型生成随机问题，并通过人工审核或修正形成最终数据集。

Result: 构建了一个包含741个闭合式问答对的数据集，覆盖从公元前1300年至当代的多个文化领域，包括诗歌、音乐、设计、建筑等，具有高多样性与深度。

Conclusion: Daisy是一个全面且高质量的文化遗产基准，能够支持对丹麦文化多维度、深层次的理解与研究，为相关领域的自然语言处理任务提供可靠资源。

Abstract: We introduce a new benchmark for Danish culture via cultural heritage, Daisy, based on the curated topics from the Danish Culture Canon 2006. For each artifact in the culture canon, we query the corresponding Wikipedia page and have a language model generate random questions. This yields a sampling strategy within each work, with a mix of central of peripheral questions for each work, not only knowledge of mainstream information, but also in-depth cornerstones defining the heritage of Danish Culture, defined by the Canon committee. Each question-answer pair is humanly approved or corrected in the final dataset consisting of 741 close-ended question answer pairs covering topics, from 1300 BC. archaeological findings, 1700 century poems and musicals pieces to contemporary pop music and Danish design and architecture.

</details>


### [65] ["Newspaper Eat" Means "Not Tasty": A Taxonomy and Benchmark for Coded Languages in Real-World Chinese Online Reviews](https://arxiv.org/abs/2601.19932)
*Ruyuan Wan,Changye Li,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: 该研究提出CodedLang数据集，包含7,744条中文Google地图评论，其中900条带有细粒度编码语言标注。构建了七类编码策略分类体系，涵盖音近、形近及跨语言替换等。实验表明现有语言模型在识别和理解编码语言方面表现不佳，尤其在依赖发音的表达上。研究强调编码语言是真实世界NLP系统亟待解决的重要挑战。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型对编码语言处理能力弱，受限于缺乏真实世界数据集和清晰分类体系。编码语言在日常交流中广泛存在，但其复杂性使模型难以准确理解，亟需系统性研究支持。

Method: 构建CodedLang数据集，收集并标注中文地图评论中的编码语言实例；设计七类编码策略分类体系；对主流语言模型进行编码语言检测、分类与评分预测任务的基准测试；开展编码与解码形式的语音分析以探究发音驱动型编码机制。

Result: 即使先进的语言模型在编码语言识别与理解任务中仍表现不佳，尤其在音近型编码上失误率较高；语音分析揭示发音特征在编码语言形成中起关键作用。

Conclusion: 编码语言是真实世界自然语言处理中被忽视但至关重要的挑战，需要更精细的数据、分类框架和模型改进来应对。

Abstract: Coded language is an important part of human communication. It refers to cases where users intentionally encode meaning so that the surface text differs from the intended meaning and must be decoded to be understood. Current language models handle coded language poorly. Progress has been limited by the lack of real-world datasets and clear taxonomies. This paper introduces CodedLang, a dataset of 7,744 Chinese Google Maps reviews, including 900 reviews with span-level annotations of coded language. We developed a seven-class taxonomy that captures common encoding strategies, including phonetic, orthographic, and cross-lingual substitutions. We benchmarked language models on coded language detection, classification, and review rating prediction. Results show that even strong models can fail to identify or understand coded language. Because many coded expressions rely on pronunciation-based strategies, we further conducted a phonetic analysis of coded and decoded forms. Together, our results highlight coded language as an important and underexplored challenge for real-world NLP systems.

</details>


### [66] [Text-to-State Mapping for Non-Resolution Reasoning: The Contradiction-Preservation Principle](https://arxiv.org/abs/2601.19933)
*Kei Saito*

Main category: cs.CL

TL;DR: 本文提出文本到状态的映射函数φ，将自然语言输入转化为非解析推理（NRR）框架中的叠加态，以保持语义模糊性。通过形式化矛盾保留原则，确保真正模糊表达在状态表示中保持非零熵。利用大语言模型生成解释，并在68个涵盖词汇、结构和语用模糊性的句子上验证，所提方法使平均香农熵H(S)达到1.087比特，而基线单解释方法为0.000比特，成功实现推理过程的延迟坍缩。


<details>
  <summary>Details</summary>
Motivation: 现有非解析推理框架虽有状态空间与算子设计，但缺乏自然语言到数学结构的映射机制，导致语义模糊性无法有效维持。

Method: 引入文本到状态映射函数φ，结合大语言模型生成解释，基于矛盾保留原则设计提取协议，确保模糊表达在状态中保持非零熵。

Result: 在68个测试句上，模糊输入的平均香农熵为1.087比特，显著高于基线方法的0.000比特，验证了框架对语义模糊性的有效保留。

Conclusion: 该框架填补了自然语言与非解析推理状态空间之间的算法鸿沟，实现了语言模型推理中架构坍缩的推迟，为保持语义多样性提供了可计算路径。

Abstract: Non-Resolution Reasoning (NRR) provides a formal framework for maintaining semantic ambiguity rather than forcing premature interpretation collapse. While the foundational architecture establishes state spaces and operators for ambiguity-preserving computation, the critical question of how natural language maps to these mathematical structures remains open. This paper introduces the text-to-state mapping function φ that transforms linguistic input into superposition states within the NRR framework. We formalize the Contradiction-Preservation Principle, which requires that genuinely ambiguous expressions maintain non-zero entropy in their state representations, and develop extraction protocols using existing Large Language Models as interpretation generators. Empirical validation across 68 test sentences spanning lexical, structural, and pragmatic ambiguity demonstrates that our mapping achieves mean Shannon entropy H(S) = 1.087 bits for ambiguous inputs while baseline single-interpretation approaches yield H(S) = 0.000. The framework provides the missing algorithmic bridge between raw text and the formal state spaces on which NRR operators act, enabling architectural collapse deferment in language model inference.

</details>


### [67] [Quantifying non deterministic drift in large language models](https://arxiv.org/abs/2601.19934)
*Claire Nicholson*

Main category: cs.CL

TL;DR: 本研究通过重复运行实验，量化了在无操作员干预条件下大语言模型输出的基准行为漂移（即相同提示产生的输出差异）。评估了gpt-4o-mini和llama3.1-8b两个公开模型在五类提示下的表现，涵盖精确重复、扰动输入和重用模式，在温度为0.0和0.7时进行测试。使用唯一输出比例、词汇相似性和词数统计等指标衡量漂移，发现即使在温度为0.0时仍存在非确定性，且不同模型规模、部署方式和提示类型表现出不同的变异模式。研究将结果置于概念漂移、行为漂移及基础设施引起的非确定性背景中讨论，指出词汇度量的局限性，并强调语义方法的前景。该工作为未来漂移缓解与控制方法提供了系统性的基准参考。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在实际应用中，相同提示常产生不一致输出，即便解码参数固定。这种现象可能影响任务可靠性，但缺乏对基础行为漂移的系统性量化研究。因此，亟需建立一个无稳定技术干预下的基准，以评估后续的漂移控制方法。

Method: 通过设计重复运行实验，对gpt-4o-mini和llama3.1-8b模型在多种提示类别（精确重复、扰动输入、重用模式）下进行测试，设定温度为0.0和0.7，采用唯一输出比例、词汇相似性、词数统计等指标分析输出变异性，实现跨模型、跨提示模式和跨部署类型的比较。

Result: 即使在温度为0.0时，模型输出仍存在显著非确定性；不同模型大小、部署方式和提示类型表现出不同的漂移模式；词汇度量存在局限，语义层面的分析更具潜力。

Conclusion: 本研究建立了无稳定技术干预下的行为漂移基准，为未来漂移缓解与控制方法的评估提供了可比参照点，强调了发展更先进语义度量工具的重要性。

Abstract: Large language models (LLMs) are widely used for tasks ranging from summarisation to decision support. In practice, identical prompts do not always produce identical outputs, even when temperature and other decoding parameters are fixed. In this work, we conduct repeated-run experiments to empirically quantify baseline behavioural drift, defined as output variability observed when the same prompt is issued multiple times under operator-free conditions. We evaluate two publicly accessible models, gpt-4o-mini and llama3.1-8b, across five prompt categories using exact repeats, perturbed inputs, and reuse modes at temperatures of 0.0 and 0.7. Drift is measured using unique output fractions, lexical similarity, and word count statistics, enabling direct comparison across models, prompting modes, and deployment types. The results show that nondeterminism persists even at temperature 0.0, with distinct variability patterns by model size, deployment, and prompt type. We situate these findings within existing work on concept drift, behavioural drift, and infrastructure-induced nondeterminism, discuss the limitations of lexical metrics, and highlight emerging semantic approaches. By establishing a systematic empirical baseline in the absence of stabilisation techniques, this study provides a reference point for evaluating future drift mitigation and control methods.

</details>


### [68] [Benchmarking von ASR-Modellen im deutschen medizinischen Kontext: Eine Leistungsanalyse anhand von Anamnesegesprächen](https://arxiv.org/abs/2601.19945)
*Thomas Schuster,Julius Trögele,Nico Döring,Robin Krüger,Matthieu Hoffmann,Holger Friedrich*

Main category: cs.CL

TL;DR: 本文构建了一个模拟医生-患者对话的德语医疗领域数据集，评估了29种不同的自动语音识别（ASR）模型，涵盖开源模型（Whisper、Voxtral、Wav2Vec2）和商业API（AssemblyAI、Deepgram），使用WER、CER、BLEU等指标进行评测，并进行了定性语义分析。结果表明，最佳模型的词错误率（WER）可低于3%，但部分模型在医学术语或方言影响下的表现显著较差。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对德语医疗场景，特别是包含方言的专门评估基准，而自动语音识别在减轻医护人员文档负担方面具有巨大潜力，因此亟需建立适合该领域的评测体系。

Method: 构建模拟医生-患者对话的数据集，选取29种ASR模型（包括开源与商业系统），采用多种评价指标（WER、CER、BLEU）进行定量评估，并辅以定性语义分析。

Result: 最佳ASR模型的词错误率（WER）已低于3%，但部分模型在处理医学术语或方言变体时错误率明显升高，显示出显著性能差异。

Conclusion: 本研究填补了德语医疗领域ASR评估的空白，揭示了不同模型在真实医疗场景中的表现差异，为后续优化和选型提供了重要依据。

Abstract: Automatic Speech Recognition (ASR) offers significant potential to reduce the workload of medical personnel, for example, through the automation of documentation tasks. While numerous benchmarks exist for the English language, specific evaluations for the German-speaking medical context are still lacking, particularly regarding the inclusion of dialects. In this article, we present a curated dataset of simulated doctor-patient conversations and evaluate a total of 29 different ASR models. The test field encompasses both open-weights models from the Whisper, Voxtral, and Wav2Vec2 families as well as commercial state-of-the-art APIs (AssemblyAI, Deepgram). For evaluation, we utilize three different metrics (WER, CER, BLEU) and provide an outlook on qualitative semantic analysis. The results demonstrate significant performance differences between the models: while the best systems already achieve very good Word Error Rates (WER) of partly below 3%, the error rates of other models, especially concerning medical terminology or dialect-influenced variations, are considerably higher.

</details>


### [69] [On the Effectiveness of LLM-Specific Fine-Tuning for Detecting AI-Generated Text](https://arxiv.org/abs/2601.20006)
*Michał Gromadzki,Anna Wróblewska,Agnieszka Kaliska*

Main category: cs.CL

TL;DR: 本研究构建了大规模的人类写作与AI生成文本语料库，提出两种新型微调策略（按LLM和按LLM家族），在覆盖21个大模型的1亿词基准上，最佳检测器达到99.6%的标记级准确率，显著优于现有开源基线。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，AI生成文本日益接近人类写作，导致在教育、出版和数字安全等领域面临真实性验证难题，因此亟需高效可靠的AI生成文本检测技术。

Method: 构建了10亿词人类文本语料库和19亿词AI生成文本语料库，采用多种检测模型并提出两种新型训练范式：按LLM和按LLM家族微调，通过大规模数据训练与评估实现高精度检测。

Result: 在1亿词的跨模型基准测试中，最优微调检测器达到99.6%的标记级准确率，显著超越现有开源检测系统。

Conclusion: 本研究通过大规模语料和创新训练策略，实现了对AI生成文本的高精度检测，为应对生成内容真实性挑战提供了有效技术方案。

Abstract: The rapid progress of large language models has enabled the generation of text that closely resembles human writing, creating challenges for authenticity verification in education, publishing, and digital security. Detecting AI-generated text has therefore become a crucial technical and ethical issue. This paper presents a comprehensive study of AI-generated text detection based on large-scale corpora and novel training strategies. We introduce a 1-billion-token corpus of human-authored texts spanning multiple genres and a 1.9-billion-token corpus of AI-generated texts produced by prompting a variety of LLMs across diverse domains. Using these resources, we develop and evaluate numerous detection models and propose two novel training paradigms: Per LLM and Per LLM family fine-tuning. Across a 100-million-token benchmark covering 21 large language models, our best fine-tuned detector achieves up to $99.6\%$ token-level accuracy, substantially outperforming existing open-source baselines.

</details>


### [70] [TAIGR: Towards Modeling Influencer Content on Social Media via Structured, Pragmatic Inference](https://arxiv.org/abs/2601.20032)
*Nishanth Sridhar Nakshatri,Eylon Caplan,Rajkumar Pujari,Dan Goldwasser*

Main category: cs.CL

TL;DR: 本文提出TAIGR框架，用于分析健康类社交媒体影响者的对话内容，通过三阶段方法识别核心建议、构建论证图并进行概率推断，证明在健康内容验证中需考虑话语的语用与论证结构而非简单处理为事实陈述集合。


<details>
  <summary>Details</summary>
Motivation: 当前健康类影响者的内容多以对话叙事和修辞策略表达，传统基于声明的验证方法难以捕捉其实际含义，因此需要一种能理解话语语用和论证结构的新方法。

Method: TAIGR框架包含三个阶段：(1) 识别影响者的核心推荐（即‘核心建议’）；(2) 构建论证图以表示支持该建议的理由；(3) 使用因子图进行概率推理以验证核心建议的合理性。

Result: 在健康类短视频文本上的评估表明，仅靠将文本视为扁平化声明集合无法实现准确验证，必须建模其话语的语用与论证结构才能提升准确性。

Conclusion: TAIGR框架有效提升了对健康影响者话语内容的验证能力，强调了在内容真实性评估中理解其论证结构的重要性。

Abstract: Health influencers play a growing role in shaping public beliefs, yet their content is often conveyed through conversational narratives and rhetorical strategies rather than explicit factual claims. As a result, claim-centric verification methods struggle to capture the pragmatic meaning of influencer discourse. In this paper, we propose TAIGR (Takeaway Argumentation Inference with Grounded References), a structured framework designed to analyze influencer discourse, which operates in three stages: (1) identifying the core influencer recommendation--takeaway; (2) constructing an argumentation graph that captures influencer justification for the takeaway; (3) performing factor graph-based probabilistic inference to validate the takeaway. We evaluate TAIGR on a content validation task over influencer video transcripts on health, showing that accurate validation requires modeling the discourse's pragmatic and argumentative structure rather than treating transcripts as flat collections of claims.

</details>


### [71] [Counterfactual Cultural Cues Reduce Medical QA Accuracy in LLMs: Identifier vs Context Effects](https://arxiv.org/abs/2601.20102)
*Amirhossein Haji Mohammad Rezaei,Zahra Shakeri*

Main category: cs.CL

TL;DR: 本文提出一个反事实基准测试，通过在150个MedQA测试题中引入文化相关标识符、上下文线索或其组合，生成1650个变体，涵盖原住民加拿大人、中东穆斯林、东南亚三组及中性对照组。研究发现，文化信息显著影响模型诊断准确率（p<10^-14），尤其当标识符与上下文共现时，准确率下降3-7个百分点；而人类验证的评分体系显示，超过一半的文化相关解释导致错误诊断，表明文化推理与诊断失败相关。研究释放了完整提示和增强数据以支持后续评估与缓解。


<details>
  <summary>Details</summary>
Motivation: 现有医疗语言模型在面对非决定性文化信息时可能改变临床正确诊断，影响医疗公平性与可持续性，亟需评估和缓解文化偏见带来的诊断错误。

Method: 构建反事实基准：将150个MedQA题目扩展为1650个变体，通过插入文化标识符、上下文线索或两者结合，每组包含三种文化类型及一个长度匹配的中性对照组，并由临床医生验证金标准答案不变。评估GPT-5.2、Llama-3.1-8B、DeepSeek-R1、MedGemma（4B/27B）在仅选项和简要解释两种提示下的表现。使用人类验证的评分体系（κ=0.76）通过LLM作为裁判分析解释质量与诊断结果的关系。

Result: 所有模型在文化线索影响下准确率显著下降（Cochran's Q, p<10^-14），尤其在标识符与上下文共现时降幅最大（3-7个百分点）；中性编辑仅引起微小且非系统性变化。超过一半的文化相关解释导致错误诊断，说明文化推理与诊断失败高度关联。

Conclusion: 当前医疗语言模型对文化信息敏感，易产生诊断偏差。必须开发更鲁棒的模型与评估机制，以确保医疗AI在跨文化情境下保持准确性与公平性。研究公开数据与提示，支持未来对文化偏见的检测与缓解。

Abstract: Engineering sustainable and equitable healthcare requires medical language models that do not change clinically correct diagnoses when presented with non-decisive cultural information. We introduce a counterfactual benchmark that expands 150 MedQA test items into 1650 variants by inserting culture-related (i) identifier tokens, (ii) contextual cues, or (iii) their combination for three groups (Indigenous Canadian, Middle-Eastern Muslim, Southeast Asian), plus a length-matched neutral control, where a clinician verified that the gold answer remains invariant in all variants. We evaluate GPT-5.2, Llama-3.1-8B, DeepSeek-R1, and MedGemma (4B/27B) under option-only and brief-explanation prompting. Across models, cultural cues significantly affect accuracy (Cochran's Q, $p<10^-14$), with the largest degradation when identifier and context co-occur (up to 3-7 percentage points under option-only prompting), while neutral edits produce smaller, non-systematic changes. A human-validated rubric ($κ=0.76$) applied via an LLM-as-judge shows that more than half of culturally grounded explanations end in an incorrect answer, linking culture-referential reasoning to diagnostic failure. We release prompts and augmentations to support evaluation and mitigation of culturally induced diagnostic errors.

</details>


### [72] [FFE-Hallu:Hallucinations in Fixed Figurative Expressions:Benchmark of Idioms and Proverbs in the Persian Language](https://arxiv.org/abs/2601.20105)
*Faezeh Hosseini,Mohammadali Yousefzadeh,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文提出首个针对大语言模型（LLMs）中隐喻幻觉的综合性基准测试FFEHallu，聚焦波斯语这一语言资源较少但语言丰富的语言。该基准包含600个精心设计的实例，涵盖三项任务：从语义生成隐喻表达、检测四种构造类别的伪造隐喻表达、以及英波跨语言隐喻翻译。评估六种先进多语言LLM后发现，多数模型在区分真实与虚构表达方面表现不佳，且在跨语言翻译中频繁产生幻觉。尽管GPT4.1表现相对较好，但整体仍暴露出当前模型在处理隐喻语言和文化语境方面的显著缺陷，凸显了构建专门评估基准以识别并缓解隐喻幻觉的必要性。


<details>
  <summary>Details</summary>
Motivation: 隐喻表达（如成语、谚语）具有文化根基、非组合性和固定性，对大语言模型构成持续挑战。现有模型常出现‘隐喻幻觉’——即生成或认可看似合理但实际不存在的表达。由于波斯语等语言在研究中被忽视，亟需专门评估工具来揭示模型在隐喻理解与生成中的系统性弱点。

Method: 构建FFEHallu基准，包含三类任务：(i) 从语义生成隐喻表达；(ii) 检测四类受控构造的伪造隐喻表达；(iii) 英文到波斯语的隐喻表达翻译。通过对比六种主流多语言大模型在该基准上的表现，分析其在隐喻识别、生成与跨语言转换中的能力。

Result: 大多数模型在区分真实与高质量伪造隐喻表达方面表现薄弱，且在跨语言翻译中频繁产生虚假隐喻。虽然GPT4.1在拒绝虚假表达方面表现较优，但仍存在误判与生成错误的情况。整体表明当前大语言模型在文化语境与隐喻理解上存在严重不足。

Conclusion: 当前大语言模型在处理隐喻语言方面存在系统性缺陷，尤其在文化背景理解和非组合性表达生成上表现不佳。为提升模型鲁棒性，必须建立针对隐喻幻觉的专用评估基准，并推动更深层次的文化与语言建模。

Abstract: Figurative language, particularly fixed figurative expressions (FFEs) such as idioms and proverbs, poses persistent challenges for large language models (LLMs). Unlike literal phrases, FFEs are culturally grounded, largely non-compositional, and conventionally fixed, making them especially vulnerable to figurative hallucination. We define figurative hallucination as the generation or endorsement of expressions that sound idiomatic and plausible but do not exist as authentic figurative expressions in the target language. We introduce FFEHallu, the first comprehensive benchmark for evaluating figurative hallucination in LLMs, with a focus on Persian, a linguistically rich yet underrepresented language. FFEHallu consists of 600 carefully curated instances spanning three complementary tasks: (i) FFE generation from meaning, (ii) detection of fabricated FFEs across four controlled construction categories, and (iii) FFE to FFE translation from English to Persian. Evaluating six state of the art multilingual LLMs, we find systematic weaknesses in figurative competence and cultural grounding. While models such as GPT4.1 demonstrate relatively strong performance in rejecting fabricated FFEs and retrieving authentic ones, most models struggle to reliably distinguish real expressions from high quality fabrications and frequently hallucinate during cross lingual translation. These findings reveal substantial gaps in current LLMs handling of figurative language and underscore the need for targeted benchmarks to assess and mitigate figurative hallucination.

</details>


### [73] [Rewarding Intellectual Humility Learning When Not To Answer In Large Language Models](https://arxiv.org/abs/2601.20126)
*Abha Jha,Akanksha Mahajan,Ashwath Vaithinathan Aravindan,Praveen Saravanan,Sai Sailaja Policharla,Sonal Chaturbhuj Gehlot*

Main category: cs.CL

TL;DR: 该研究探讨了基于可验证奖励的强化学习（RLVR）作为一种训练范式，通过奖励模型在不确定时选择“我不知道”来促进智力谦逊，从而减少大语言模型（LLM）的幻觉问题。在MedMCQA和Hendrycks Math基准上对Granite-3.3-2B-Instruct和Qwen-3-4B-Instruct进行微调与评估，采用三元奖励结构（-1, r_abs, 1），并测试不同放弃回答奖励的影响。研究发现适度的放弃奖励（r_abs ≈ -0.25 到 0.3）能有效减少错误回答且不影响准确率，在多选任务中表现稳定；大模型对放弃激励更具鲁棒性。开放问答任务中因探索不足存在局限，可通过监督式放弃训练部分缓解。结果表明可验证奖励设计是缓解幻觉的有效且灵活的方法。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常产生幻觉或不可验证的内容，影响其在事实性领域的可靠性。为提升模型的可信度，需引入机制鼓励模型在不确定时主动放弃回答，体现智力谦逊。因此，研究旨在探索一种能够有效引导模型合理放弃回答的训练方法。

Method: 采用基于可验证奖励的强化学习（RLVR）框架，设计三元奖励函数（-1, r_abs, 1），其中奖励值取决于回答正确性、错误性及是否选择放弃回答。在MedMCQA和Hendrycks Math两个基准上对两种大模型进行微调，并系统测试不同放弃奖励值（r_abs）的影响。同时，对比结合监督微调（SFT）先教授放弃策略的组合方法，以增强模型在开放问答中的探索能力。

Result: 在多选任务中，适度的放弃奖励（r_abs ≈ -0.25 到 0.3）显著降低错误回答率，且准确率下降不明显；大模型表现出更强的鲁棒性。在开放问答任务中，由于缺乏足够探索，效果受限，但通过先进行监督式放弃训练可部分改善。整体验证了可验证奖励设计在抑制幻觉方面的可行性与灵活性。

Conclusion: 可验证奖励设计是一种实用且灵活的手段，可用于缓解大语言模型的幻觉问题。通过合理设置放弃奖励，可在不严重损害性能的前提下提升模型的诚实性与可靠性，尤其在高复杂度任务中具有应用潜力。相关代码已公开，支持复现与进一步研究。

Abstract: Large Language Models (LLMs) often produce hallucinated or unverifiable content, undermining their reliability in factual domains. This work investigates Reinforcement Learning with Verifiable Rewards (RLVR) as a training paradigm that explicitly rewards abstention ("I don't know") alongside correctness to promote intellectual humility. We fine-tune and evaluate Granite-3.3-2B-Instruct and Qwen-3-4B-Instruct on the MedMCQA and Hendrycks Math benchmarks using a ternary reward structure ($-1$, r_abs, 1) under varying abstention reward structures. We further study the effect of combining RLVR with supervised fine-tuning strategies that teach abstention prior to reinforcement learning. Our results show that moderate abstention rewards (r_abs $\approx -0.25$ to 0.3) consistently reduce incorrect responses without severe accuracy degradation on multiple-choice tasks, with larger models exhibiting greater robustness to abstention incentives. On open-ended question answering, we observe limitations due to insufficient exploration, which can be partially mitigated through supervised abstention training. Overall, these findings demonstrate the feasibility and flexibility of verifiable reward design as a practical approach for hallucination mitigation in language models. Reproducible code for our abstention training framework is available here https://github.com/Mystic-Slice/rl-abstention.

</details>


### [74] [BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and Non-Hate Speech Classification](https://arxiv.org/abs/2601.20129)
*Akif Islam,Sujan Kumar Roy,Md. Ekramul Hamid*

Main category: cs.CL

TL;DR: 本文提出一个大规模的孟加拉语二元情感数据集 BengaliSent140，通过整合七个现有孟加拉语文本数据集构建而成。该数据集包含139,792个唯一文本样本，涵盖68,548个仇恨言论和71,244个非仇恨样本，具有相对平衡的类别分布。研究统一了不同来源的异构标注体系，将其转化为二元情感标签（0: 非仇恨，1: 仇恨），并验证了其在深度学习模型训练与评估中的可用性。数据集已公开发布于 Kaggle。


<details>
  <summary>Details</summary>
Motivation: 当前孟加拉语情感分析研究受限于缺乏大规模、多样化且标注一致的数据集。现有数据集通常规模小或局限于单一领域（如社交媒体评论），难以满足现代深度学习模型对海量异质数据的需求。因此，亟需一个更全面、更具代表性的统一数据集以推动该领域的进展。

Method: 将七个现有的孟加拉语文本数据集进行整合，系统性地将不同来源的异构标注方案统一为二元情感分类任务（非仇恨/仇恨），确保标签一致性；并通过清洗与标准化处理，构建出一个大规模、跨领域、结构一致的统一数据集 BengaliSent140。

Result: 成功构建了一个包含139,792条文本样本的大规模孟加拉语情感数据集，其中仇恨与非仇恨样本数量接近平衡，覆盖多个语境与领域；实验表明该数据集适用于深度学习模型的训练与基准测试，具备良好的实用价值。

Conclusion: BengaliSent140 是目前最全面、最具代表性的孟加拉语二元情感数据集之一，能够有效支持深度学习模型的训练与评估，为未来孟加拉语自然语言处理研究提供坚实基础。

Abstract: Sentiment analysis for the Bengali language has attracted increasing research interest in recent years. However, progress remains constrained by the scarcity of large-scale and diverse annotated datasets. Although several Bengali sentiment and hate speech datasets are publicly available, most are limited in size or confined to a single domain, such as social media comments. Consequently, these resources are often insufficient for training modern deep learning based models, which require large volumes of heterogeneous data to learn robust and generalizable representations. In this work, we introduce BengaliSent140, a large-scale Bengali binary sentiment dataset constructed by consolidating seven existing Bengali text datasets into a unified corpus. To ensure consistency across sources, heterogeneous annotation schemes are systematically harmonized into a binary sentiment formulation with two classes: Not Hate (0) and Hate (1). The resulting dataset comprises 139,792 unique text samples, including 68,548 hate and 71,244 not-hate instances, yielding a relatively balanced class distribution. By integrating data from multiple sources and domains, BengaliSent140 offers broader linguistic and contextual coverage than existing Bengali sentiment datasets and provides a strong foundation for training and benchmarking deep learning models. Baseline experimental results are also reported to demonstrate the practical usability of the dataset. The dataset is publicly available at https://www.kaggle.com/datasets/akifislam/bengalisent140/

</details>


### [75] [Mind the Shift: Using Delta SSL Embeddings to Enhance Child ASR](https://arxiv.org/abs/2601.20142)
*Zilai Wang,Natarajan Balaji Shankar,Kaiyuan Zhang,Zihan Wang,Abeer Alwan*

Main category: cs.CL

TL;DR: This work introduces delta SSL embeddings to enhance child ASR by capturing fine-tuning-induced representation shifts. Fusion of delta embeddings with finetuned features, especially WavLM with delta W2V2, achieves significant WER reductions and sets a new state of the art on the MyST corpus.


<details>
  <summary>Details</summary>
Motivation: Child automatic speech recognition (ASR) is challenging due to limited data and domain mismatch between pretraining and child speech. Fine-tuning SSL models on child speech causes shifts in the representation space, which may hinder performance.

Method: The paper proposes using delta SSL embeddings—defined as the differences between embeddings from a fine-tuned model and its pretrained counterpart—to capture task-specific information. Multiple fusion strategies are evaluated, combining delta embeddings with finetuned embeddings from other SSL models.

Result: Delta embedding fusion with WavLM achieves up to a 10% relative WER reduction for HuBERT and a 4.4% reduction for W2V2. Fusing WavLM with delta W2V2 embeddings results in a WER of 9.64, setting a new state of the art on the MyST corpus.

Conclusion: Delta embeddings effectively capture complementary task-specific information, and feature fusion is a promising approach for improving child ASR performance using SSL models.

Abstract: Self-supervised learning (SSL) models have achieved impressive results across many speech tasks, yet child automatic speech recognition (ASR) remains challenging due to limited data and pretraining domain mismatch. Fine-tuning SSL models on child speech induces shifts in the representation space. We hypothesize that delta SSL embeddings, defined as the differences between embeddings from a finetuned model and those from its pretrained counterpart, encode task-specific information that complements finetuned features from another SSL model. We evaluate multiple fusion strategies on the MyST childrens corpus using different models. Results show that delta embedding fusion with WavLM yields up to a 10 percent relative WER reduction for HuBERT and a 4.4 percent reduction for W2V2, compared to finetuned embedding fusion. Notably, fusing WavLM with delta W2V2 embeddings achieves a WER of 9.64, setting a new state of the art among SSL models on the MyST corpus. These findings demonstrate the effectiveness of delta embeddings and highlight feature fusion as a promising direction for advancing child ASR.

</details>


### [76] [Trajectory2Task: Training Robust Tool-Calling Agents with Synthesized Yet Verifiable Data for Complex User Intents](https://arxiv.org/abs/2601.20144)
*Ziyi Wang,Yuxuan Lu,Yimeng Zhang,Jing Huang,Jiri Gesi,Xianfeng Tang,Chen Luo,Yisi Sang,Hanqing Lu,Manling Li,Dakuo Wang*

Main category: cs.CL

TL;DR: 提出Trajectory2Task数据生成管道，用于在模糊、变化和不可行的用户场景下研究大规模工具调用，通过多轮探索生成有效工具调用轨迹，并转化为可验证的任务，支持闭环评估与训练；在七个先进大模型上测试发现频繁失败，但基于成功轨迹微调轻量级模型后，在三种场景下均实现一致改进，且泛化能力增强。


<details>
  <summary>Details</summary>
Motivation: 现实世界中用户请求常具模糊性、动态变化或受政策限制，而现有研究多基于理想化、固定任务，缺乏对复杂交互模式的数据覆盖，亟需更贴近实际的评估与训练数据。

Method: 设计Trajectory2Task数据生成管道：先通过多轮对话探索生成有效的工具调用轨迹，再将这些轨迹转化为带有可控意图调整的用户任务，确保任务可验证并支持闭环训练与评估。

Result: 在生成的复杂用户场景任务上，七种主流LLM表现不佳，频繁失败；利用任务回放获得的成功轨迹对轻量级模型进行微调后，模型在三类场景下均有显著提升，且在未见过的工具使用领域表现出更强泛化能力。

Conclusion: Trajectory2Task有效生成了符合真实场景的复杂任务数据，能够揭示现有LLM在工具调用中的局限性，并通过微调显著提升模型在复杂、动态和受限情境下的工具调用能力与泛化性能。

Abstract: Tool-calling agents are increasingly deployed in real-world customer-facing workflows. Yet most studies on tool-calling agents focus on idealized settings with general, fixed, and well-specified tasks. In real-world applications, user requests are often (1) ambiguous, (2) changing over time, or (3) infeasible due to policy constraints, and training and evaluation data that cover these diverse, complex interaction patterns remain under-represented. To bridge the gap, we present Trajectory2Task, a verifiable data generation pipeline for studying tool use at scale under three realistic user scenarios: ambiguous intent, changing intent, and infeasible intents. The pipeline first conducts multi-turn exploration to produce valid tool-call trajectories. It then converts these trajectories into user-facing tasks with controlled intent adaptations. This process yields verifiable task that support closed-loop evaluation and training. We benchmark seven state-of-the-art LLMs on the generated complex user scenario tasks and observe frequent failures. Finally, using successful trajectories obtained from task rollouts, we fine-tune lightweight LLMs and find consistent improvements across all three conditions, along with better generalization to unseen tool-use domains, indicating stronger general tool-calling ability.

</details>


### [77] [Improving X-Codec-2.0 for Multi-Lingual Speech: 25 Hz Latent Rate and 24 kHz Sampling](https://arxiv.org/abs/2601.20185)
*Husein Zolkepli*

Main category: cs.CL

TL;DR: 本文提出对X-Codec-2.0进行简单有效的改进，通过增加池化层并增大解码器步幅，将潜在率从50 Hz降低至25 Hz，同时将输出采样率从16 kHz提升至24 kHz，从而在不改变核心架构的前提下提升了时间效率和音频保真度。在多语言Common Voice 17测试集上，新配置相比原始版本在UTMOSv2评分上提高了0.29分，达到25 Hz下所有编码器的最佳性能。代码、模型权重及生成对比已公开。


<details>
  <summary>Details</summary>
Motivation: 原始X-Codec-2.0虽然在神经音频压缩和多语言语音建模方面表现优异，但其50 Hz的潜在率限制了时间效率，且16 kHz的输出采样率影响音频保真度，因此需要在不改变核心架构的基础上提升效率与质量。

Method: 引入额外的池化操作并增大解码器的步幅，从而降低潜在率至25 Hz，同时将输出采样率提升至24 kHz。该方法保持了原有模型结构不变，仅调整部分超参数。

Result: 在多语言Common Voice 17测试集上，新配置在UTMOSv2评分上比原始X-Codec-2.0提升0.29分，成为25 Hz下性能最佳的音频编码器。

Conclusion: 通过简单的池化与步幅调整，可在不改变核心架构的情况下显著提升音频编码器的时间效率与感知质量，证明了该优化策略的有效性与实用性。

Abstract: X-Codec-2.0 has shown strong performance in neural audio compression and multilingual speech modeling, operating at a 50 Hz latent rate and a 16 kHz sampling rate using frozen HuBERT features. While effective, this configuration limits temporal efficiency and audio fidelity. In this work, we explore a simple and effective modification by introducing additional pooling and increasing the decoder hop size. This reduces the latent rate from 50 Hz to 25 Hz and simultaneously raises the output sampling rate from 16 kHz to 24 kHz, improving efficiency and perceptual quality without altering the core architecture. Evaluated on the multilingual Common Voice 17 test set, the proposed configuration achieves a 0.29 MOS improvement over the original X-Codec-2.0 baseline based on UTMOSv2, and attains the best reported performance among all codecs operating at 25 Hz. The source code, checkpoints, and generation comparisons are released at \href{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}.

</details>


### [78] [Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems](https://arxiv.org/abs/2601.20230)
*Haoyuan Yu,Yuxuan Chen,Minjie Cai*

Main category: cs.CL

TL;DR: 本文提出了一种将复杂对话分解为最小对话单元的框架，使系统能够独立处理每个单元并预测何时切换到下一个单元。该框架基于多模态大语言模型构建了一个半级联的全双工对话系统，辅以语音活动检测（VAD）和文本转语音（TTS）等模块，实现无需训练、即插即用的运行方式。在HumDial数据集上的实验表明，该框架在人类类似语音对话系统挑战赛（全双工交互赛道）测试集中排名第二。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 全双工语音交互对于自然的人机交互至关重要，但现有系统难以高效处理复杂的连续对话。为提升系统对实时对话流的响应能力与灵活性，需要一种能分解对话、独立处理并动态切换的机制。

Method: 将复杂对话分解为最小对话单元，利用多模态大语言模型作为核心，结合语音活动检测（VAD）和文本转语音（TTS）等辅助模块，构建半级联的全双工对话系统，实现无需训练的即插即用运行。

Result: 在HumDial数据集上的实验验证了该框架的有效性，在人类类似语音对话系统挑战赛（全双工交互赛道）测试集中取得第二名的成绩。系统具备良好的实时性与可扩展性。

Conclusion: 所提出的全双工对话框架通过对话单元分解与多模态大模型协同，实现了高效、灵活且无需训练的语音交互，显著提升了系统在真实场景中的表现，具有较强的实用价值。

Abstract: Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.

</details>


### [79] [Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy](https://arxiv.org/abs/2601.20253)
*Si Chen,Le Huy Khiem,Annalisa Szymanski,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 本文提出一种基于专家指南和布卢姆认知分类的自动化基准生成框架，将专业实践转化为基于违规的场景，生成可自动评分的多选题和多轮对话，覆盖四个认知层次，实现对实际应用领域中模型上下文推理能力的可重复、可扩展评估。在教学、营养学和护理三个领域验证发现，大语言模型在高阶推理（分析）上表现较好，但在低阶任务（记忆）上错误率更高，揭示了非直观的模型行为。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型评估基准依赖于预设的人类考试数据集，但在实践性领域（如教学、营养学、护理）这些数据往往不可得。此外，这些领域知识以程序性为主，依赖专业判断，传统基准难以捕捉此类复杂推理能力。因此需要一种能从专家指南出发，自动生成高质量、可扩展评估基准的方法。

Method: 基于布卢姆认知分类，将专家撰写的实践指南转化为隐含违规情境；通过规则与模板生成多选题和多轮对话，覆盖记忆、理解、应用、分析四个认知层次；支持自动评分，确保评估的确定性与可复现性。

Result: 在教学、营养学和护理三个领域构建了大规模、心理测量学支持的评估基准；结果显示，尽管大语言模型在高阶推理任务中表现接近人类，但在基础记忆任务中表现较差，暴露出其在真实世界情境下的非直观缺陷。

Conclusion: 该框架能够有效生成适用于实践性领域的自动化评估基准，揭示大语言模型在不同认知层级上的真实推理能力，为现实场景中的上下文推理评估提供了可靠工具。

Abstract: Open-ended question answering (QA) evaluates a model's ability to perform contextualized reasoning beyond factual recall. This challenge is especially acute in practice-based domains, where knowledge is procedural and grounded in professional judgment, while most existing LLM benchmarks depend on pre-existing human exam datasets that are often unavailable in such settings. We introduce a framework for automated benchmark generation from expert-authored guidelines informed by Bloom's Taxonomy. It converts expert practices into implicit violation-based scenarios and expands them into auto-graded multiple-choice questions (MCQs) and multi-turn dialogues across four cognitive levels, enabling deterministic, reproducible, and scalable evaluation. Applied to three applied domains: teaching, dietetics, and caregiving, we find differences between model and human-like reasoning: LLMs sometimes perform relatively better on higher-order reasoning (Analyze) but fail more frequently on lower-level items (Remember). We produce large-scale, psychometrically informed benchmarks that surface these non-intuitive model behaviors and enable evaluation of contextualized reasoning in real-world settings.

</details>


### [80] [SoftHateBench: Evaluating Moderation Models Against Reasoning-Driven, Policy-Compliant Hostility](https://arxiv.org/abs/2601.20256)
*Xuanyu Su,Diana Inkpen,Nathalie Japkowicz*

Main category: cs.CL

TL;DR: 本文提出一个名为 	extsc{SoftHateBench} 的生成式基准，用于系统评估社交媒体中软仇恨言论的检测能力。该基准结合了论题模型（AMT）与相关性理论（RT），将显性仇恨立场转化为看似中立但隐含敌意的论述，覆盖7个社会文化领域和28个目标群体，共4,745个实例。实验表明，现有基于编码器的检测模型、通用大模型及安全模型在面对软仇恨时性能显著下降，凸显当前系统对推理驱动型敌意的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 当前内容审核系统主要针对表面毒性特征优化，难以应对以合理化论述为外壳的软仇恨言论。然而，现有评测基准缺乏对这一差距的系统性衡量，亟需新的方法与数据集来揭示并解决该问题。

Method: 整合论题模型（AMT）与相关性理论（RT），构建统一框架：AMT负责重构仇恨立场为看似中立的讨论结构，同时保持原始敌意立场；RT确保生成内容在逻辑上连贯且符合语境相关性，从而生成真实可信的软仇恨文本。

Result: 在涵盖7个社会文化领域和28个目标群体的4,745个软仇恨实例上进行评估，发现所有类型模型（编码器、通用LLM、安全模型）在软仇恨任务上的表现均显著低于硬仇恨任务，表明现有系统对推理驱动型仇恨缺乏鲁棒性。

Conclusion: 	extsc{SoftHateBench} 有效揭示了当前仇恨言论检测系统的局限性，证明软仇恨是威胁内容安全的重要盲区。未来工作应聚焦于提升模型对隐蔽性、逻辑化敌意的理解能力。

Abstract: Online hate on social media ranges from overt slurs and threats (\emph{hard hate speech}) to \emph{soft hate speech}: discourse that appears reasonable on the surface but uses framing and value-based arguments to steer audiences toward blaming or excluding a target group. We hypothesize that current moderation systems, largely optimized for surface toxicity cues, are not robust to this reasoning-driven hostility, yet existing benchmarks do not measure this gap systematically. We introduce \textbf{\textsc{SoftHateBench}}, a generative benchmark that produces soft-hate variants while preserving the underlying hostile standpoint. To generate soft hate, we integrate the \emph{Argumentum Model of Topics} (AMT) and \emph{Relevance Theory} (RT) in a unified framework: AMT provides the backbone argument structure for rewriting an explicit hateful standpoint into a seemingly neutral discussion while preserving the stance, and RT guides generation to keep the AMT chain logically coherent. The benchmark spans \textbf{7} sociocultural domains and \textbf{28} target groups, comprising \textbf{4,745} soft-hate instances. Evaluations across encoder-based detectors, general-purpose LLMs, and safety models show a consistent drop from hard to soft tiers: systems that detect explicit hostility often fail when the same stance is conveyed through subtle, reasoning-based language. \textcolor{red}{\textbf{Disclaimer.} Contains offensive examples used solely for research.}

</details>


### [81] [Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale](https://arxiv.org/abs/2601.20276)
*Tianwei Lin,Zuyi Zhou,Xinda Zhao,Chenke Wang,Xiaohong Li,Yu Chen,Chuanrui Hu,Jian Pei,Yafeng Deng*

Main category: cs.CL

TL;DR: 提出EMB-S基准，用于评估长上下文LLM在复杂语义干扰下的证据检索能力，发现语义区分能力是主要瓶颈而非上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有NIAH评估过于理想化，无法反映真实环境中长上下文模型的证据检索挑战，尤其在存在语义干扰时表现不佳。

Method: 构建326M-token MemoryBank，设计对抗性NIAH式测试集，包含经过碰撞检测的近似错误负样本和真实证据集，并采用解耦诊断协议分别评估文档定位与问答质量。

Result: 在从孤立领域到全局共享环境的多层级测试中，模型在良性条件下表现良好，但在语义干扰下证据获取能力显著下降，表明语义辨别力是关键瓶颈。

Conclusion: 长上下文模型的性能受限于语义区分能力，而非单纯依赖上下文长度；需改进模型对复杂语义环境的鲁棒性。

Abstract: Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.

</details>


### [82] [MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting](https://arxiv.org/abs/2601.20300)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: MiLorE-SSL 是一种轻量级框架，结合 LoRA 和软混合专家（MoE）机制，实现高效持续的多语言自监督学习。通过低秩适应和灵活的专家共享，减少跨语言干扰，并利用有限的历史数据重放缓解遗忘问题。在 ML-SUPERB 上实验表明，仅需 2.14% 的可训练参数即可提升新旧语言表现。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习模型在新增语言时面临重训练成本高和灾难性遗忘问题，亟需一种高效、低成本的持续多语言训练方法。

Method: 提出 MiLorE-SSL 框架，采用 LoRA 实现低秩微调，结合软混合专家机制促进跨语言专家共享，并引入有限历史数据重放以缓解遗忘。

Result: 在 ML-SUPERB 基准上，MiLorE-SSL 在新语言上表现优异，同时提升已有语言性能，仅需 2.14% 的可训练参数。

Conclusion: MiLorE-SSL 有效解决了多语言自监督学习中持续扩展语言的能力瓶颈，具备高效、低资源消耗的优势，适用于实际部署场景。

Abstract: Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.

</details>


### [83] [SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger](https://arxiv.org/abs/2601.20312)
*Kaiyuan Chen,Guangmin Zheng,Jin Wang,Xiaobing Zhou,Xuejie Zhang*

Main category: cs.CL

TL;DR: 提出SAPO方法，通过主动缩小推理-验证差距，实现小语言模型的自适应过程优化，克服现有自进化方法中细粒度推理步骤忽略及蒙特卡洛过程监督计算效率低的问题，在数学和代码任务上表现优于多数现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自进化方法忽视细粒度推理步骤的影响，导致推理器与验证器之间存在差距，且蒙特卡洛过程监督计算效率低下，难以缓解该差距。

Method: 受错误相关负波（ERN）启发，提出自适应过程优化（SAPO）方法，通过主动最小化推理-验证差距，高效引入过程监督信号，避免依赖低效的蒙特卡洛估计。

Result: 实验表明，SAPO在数学和代码两类挑战性任务上均显著优于大多数现有自进化方法；同时构建了两个新基准，用于评估过程奖励模型在数学与编码任务中的表现。

Conclusion: SAPO有效缩小了推理-验证差距，提升了小语言模型的自进化能力，为高效过程监督提供了新思路。

Abstract: Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity (ERN), which the reasoner can localize error following incorrect decisions, guiding rapid adjustments, we propose a Self-Adaptive Process Optimization (SAPO) method for self-improvement in Small Language Models (SLMs). SAPO adaptively and efficiently introduces process supervision signals by actively minimizing the reasoner-verifier gap rather than relying on inefficient MC estimations. Extensive experiments demonstrate that the proposed method outperforms most existing self-evolution methods on two challenging task types: mathematics and code. Additionally, to further investigate SAPO's impact on verifier performance, this work introduces two new benchmarks for process reward models in both mathematical and coding tasks.

</details>


### [84] [Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning](https://arxiv.org/abs/2601.20326)
*Zeyu Xing,Xing Li,Hui-Ling Zhen,Mingxuan Yuan,Sinno Jialin Pan*

Main category: cs.CL

TL;DR: 本文提出将KV缓存作为轻量级表示，用于下游任务而无需额外计算或存储完整隐藏状态。尽管其表达能力弱于专用嵌入，但在链式嵌入（Chain-of-Embedding）和快慢思维切换（Fast/Slow Thinking Switching）两项应用中表现优异，显著提升推理效率并减少生成令牌数，证明了KV缓存在大模型推理中具有免费且高效的表征潜力。


<details>
  <summary>Details</summary>
Motivation: 传统KV缓存仅用于加速自回归解码，但其蕴含的上下文信息可被重用于下游任务。现有方法需重新计算或存储完整隐藏状态，成本高昂。本文旨在探索利用已有KV缓存作为轻量级表示，以实现高效、低成本的推理与采样。

Method: 将预生成的KV缓存转化为轻量级嵌入表示，直接用于下游任务如链式推理与思维模式切换；通过设计适配机制，使这些表示在不显著影响性能的前提下支持快速推理与动态决策。

Result: 在Llama-3.1-8B-Instruct和Qwen2-7B-Instruct上，链式嵌入任务达到竞争性甚至更优性能；在Qwen3-8B和DeepSeek-R1-Distil-Qwen-14B上，快慢思维切换使生成令牌数减少最多5.7倍，精度损失极小。

Conclusion: KV缓存可作为免费且有效的推理表示基础，为大模型推理中的表示复用开辟新方向，具备广泛的应用前景。

Abstract: KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.

</details>


### [85] [CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria](https://arxiv.org/abs/2601.20327)
*Xinyu Hu,Yancheng He,Weixun Wang,Tao Feng,Li Lin,Jiashun Liu,Wenbo Su,Bo Zheng,Xiaojun Wan*

Main category: cs.CL

TL;DR: 提出CE-RM-4B，一种基于两阶段滚动生成和统一查询标准的点式生成奖励模型，仅用约5.7K高质量数据，在多种基准测试中表现优异，尤其在Best-of-N场景下，并显著提升下游强化学习实践效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge范式虽在基准测试中表现良好，但在强化学习实践中效果不佳，主要因过度依赖成对评估和评估标准优化不足。

Method: 采用专用的两阶段滚动生成方法，结合统一查询式评估标准训练点式生成奖励模型。

Result: 在多个奖励模型基准测试中表现优越，特别是在Best-of-N场景下，且在下游强化学习任务中带来更有效的改进。

Conclusion: CE-RM-4B通过优化评估方法和训练策略，有效缩小了自动评估性能与实际强化学习应用之间的差距，展现出更强的实用性。

Abstract: Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.

</details>


### [86] [PsychePass: Calibrating LLM Therapeutic Competence via Trajectory-Anchored Tournaments](https://arxiv.org/abs/2601.20330)
*Zhuang Chen,Dazhen Wan,Zhangkai Zheng,Guanqun Bi,Xiyao Xiao,Binghang Li,Minlie Huang*

Main category: cs.CL

TL;DR: 本文提出PsychePass框架，通过轨迹锚定的锦标赛机制评估大语言模型在心理健康领域的治疗能力。针对当前评估方法中存在的过程漂移和标准漂移问题，该框架通过受控的客户端模拟和动态双人对抗赛实现稳定评估，并将比赛轨迹转化为可信奖励信号以支持强化学习优化模型性能。实验表明该方法在一致性与有效性方面均优于现有方法，且与人类专家判断高度一致。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在心理健康领域的应用面临评估难题，主要源于咨询过程的非结构化和长期性特征。现有评估方法缺乏固定基准，导致过程漂移（客户端模拟偏离目标）和标准漂移（静态评分不稳定），难以可靠衡量模型的治疗能力。

Method: 提出PsychePass框架，包含两个核心部分：1）轨迹锚定的客户端模拟，使客户能够精确控制咨询流程，以探测模型多维度能力；2）基于瑞士制锦标赛的判断锚定，通过动态成对对抗生成稳定的Elo评分体系。同时，将比赛轨迹转换为奖励信号，用于指导基于策略的强化学习优化模型。

Result: 实验验证了PsychePass的有效性，其评估结果表现出高度稳定性与一致性，且与人类专家评价高度吻合。此外，利用锦标赛生成的奖励信号可显著提升大语言模型在心理咨询服务中的表现。

Conclusion: PsychePass通过引入轨迹锚定的评估机制，有效解决了大语言模型在心理健康领域评估中的不稳定性问题，实现了更可靠、可扩展的治疗能力评估，并为模型持续优化提供了新路径。

Abstract: While large language models show promise in mental healthcare, evaluating their therapeutic competence remains challenging due to the unstructured and longitudinal nature of counseling. We argue that current evaluation paradigms suffer from an unanchored defect, leading to two forms of instability: process drift, where unsteered client simulation wanders away from specific counseling goals, and standard drift, where static pointwise scoring lacks the stability for reliable judgment. To address this, we introduce Ps, a unified framework that calibrates the therapeutic competence of LLMs via trajectory-anchored tournaments. We first anchor the interaction trajectory in simulation, where clients precisely control the fluid consultation process to probe multifaceted capabilities. We then anchor the battle trajectory in judgments through an efficient Swiss-system tournament, utilizing dynamic pairwise battles to yield robust Elo ratings. Beyond ranking, we demonstrate that tournament trajectories can be transformed into credible reward signals, enabling on-policy reinforcement learning to enhance LLMs' performance. Extensive experiments validate the effectiveness of PsychePass and its strong consistency with human expert judgments.

</details>


### [87] [Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents](https://arxiv.org/abs/2601.20412)
*Qihao Wang,Yue Hu,Mingzhe Lu,Jiayue Wu,Yanbing Liu,Yuanmin Tang*

Main category: cs.CL

TL;DR: 本文提出一种基于认知负荷理论的框架，用于评估大语言模型在使用外部工具时的真实能力边界。通过将任务复杂度分解为内在负荷（由新颖的工具交互图形式化）和外在负荷（源于任务表述模糊），构建了首个可参数化调整认知负荷的基准ToolLoad-Bench。实验揭示了随着认知负荷增加出现的性能突降现象，精确刻画了各模型的能力极限。该框架预测与实证结果高度一致，为理解智能体的局限性和构建更高效系统提供了原则性方法和实践基础。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要报告最终准确率，仅反映模型能做什么，却无法揭示其认知瓶颈。为了从简单性能评分转向诊断性评估，需要一种能够识别模型真正能力边界的评价方法。

Method: 提出基于认知负荷理论的分析框架，将任务复杂度分解为内在负荷（通过工具交互图量化）和外在负荷（由任务表述模糊引起）。构建可参数化调节认知负荷的ToolLoad-Bench基准，支持受控实验。

Result: 实验发现随着认知负荷上升，模型性能出现显著突降，可精准定位各模型的能力边界。框架预测与实际表现高度吻合，验证了其有效性与校准性。

Conclusion: 本研究建立了一种可解释、可校准的认知评估框架，不仅揭示了模型的实际能力极限，也为未来设计更高效、更具鲁棒性的智能体系统提供了理论基础和实践路径。

Abstract: The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true capability boundaries. To move from simple performance scoring to a diagnostic tool, we introduce a framework grounded in Cognitive Load Theory. Our framework deconstructs task complexity into two quantifiable components: Intrinsic Load, the inherent structural complexity of the solution path, formalized with a novel Tool Interaction Graph; and Extraneous Load, the difficulty arising from ambiguous task presentation. To enable controlled experiments, we construct ToolLoad-Bench, the first benchmark with parametrically adjustable cognitive load. Our evaluation reveals distinct performance cliffs as cognitive load increases, allowing us to precisely map each model's capability boundary. We validate that our framework's predictions are highly calibrated with empirical results, establishing a principled methodology for understanding an agent's limits and a practical foundation for building more efficient systems.

</details>


### [88] [SpeechMapper: Speech-to-text Embedding Projector for LLMs](https://arxiv.org/abs/2601.20417)
*Biswesh Mohapatra,Marcely Zanon Boito,Ioan Calapodescu*

Main category: cs.CL

TL;DR: SpeechMapper 提出了一种高效、低成本的语音到大语言模型（LLM）嵌入训练方法，通过在廉价硬件上预训练语音基础模型，再通过简短的1K步指令微调（IT）阶段连接目标LLM，避免了传统方法中全量训练带来的计算开销和过拟合问题。实验表明，SpeechMapper在语音翻译和语音问答任务中表现优异，即使在未训练过的任务上也媲美顶尖模型，在特定任务上更胜一筹，且所需数据与算力更少。


<details>
  <summary>Details</summary>
Motivation: 当前语音大模型通过投影层将语音基础模型与大语言模型结合，并在语音指令数据上联合训练，但该方法计算成本高，易出现任务和提示过拟合。因此需要一种更高效、鲁棒且泛化能力强的语音-大模型融合方案。

Method: 首先在低成本硬件上对语音模块进行无监督预训练，不涉及大语言模型；随后仅通过1000步的轻量级指令微调（IT）阶段，将预训练好的语音模块高效接入目标大语言模型。支持任务无关、基于自动语音识别（ASR）的适配以及任务特定的指令微调三种模式。

Result: 在语音翻译和语音问答任务中，SpeechMapper在任务无关设置下表现接近IWSLT25最佳语音指令跟随模型，尽管从未在这些任务上训练；在任务特定设置下，其性能超越该模型，且使用更少的数据和计算资源。整体验证了其高效性、可扩展性和强泛化能力。

Conclusion: SpeechMapper提供了一种实用、可扩展的语音-大语言模型集成新范式，无需大规模指令微调即可实现高性能、高鲁棒性的语音理解与生成能力，显著降低训练成本并提升模型通用性。

Abstract: Current speech LLMs bridge speech foundation models to LLMs using projection layers, training all of these components on speech instruction data. This strategy is computationally intensive and susceptible to task and prompt overfitting. We present SpeechMapper, a cost-efficient speech-to-LLM-embedding training approach that mitigates overfitting, enabling more robust and generalizable models. Our model is first pretrained without the LLM on inexpensive hardware, and then efficiently attached to the target LLM via a brief 1K-step instruction tuning (IT) stage. Through experiments on speech translation and spoken question answering, we demonstrate the versatility of SpeechMapper's pretrained block, presenting results for both task-agnostic IT, an ASR-based adaptation strategy that does not train in the target task, and task-specific IT. In task-agnostic settings, Speechmapper rivals the best instruction-following speech LLM from IWSLT25, despite never being trained on these tasks, while in task-specific settings, it outperforms this model across many datasets, despite requiring less data and compute. Overall, SpeechMapper offers a practical and scalable approach for efficient, generalizable speech-LLM integration without large-scale IT.

</details>


### [89] [Hopes and Fears -- Emotion Distribution in the Topic Landscape of Finnish Parliamentary Speech 2000-2020](https://arxiv.org/abs/2601.20424)
*Anna Ristilä,Otto Tarkka,Veronika Laippala,Kimmo Elo*

Main category: cs.CL

TL;DR: 本研究分析了2000至2020年间芬兰议会（Eduskunta）演讲中不同议题的情感表达，旨在揭示议题特异性情感模式。通过同步与历时视角的情感分析模型，发现议会言论整体呈现日益积极的趋势，并揭示了特定议题下情感表达的差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究将议会辩论视为同质整体，忽视了议题层面的情感差异。尽管人们对议会中哪些议题更具情绪性有直观认知，但缺乏系统研究。因此，亟需探索不同议题与典型情绪之间的关联。

Method: 采用情感分析模型，从同步和历时两个维度对芬兰议会2000至2020年间的演讲内容进行分析，识别不同议题中的情感表达特征。

Result: 研究发现议会演讲整体情绪趋向积极，且不同议题存在显著的情感表达差异，为理解议会话语中的情感动态提供了实证支持。

Conclusion: 本研究填补了关于议会议题与情感表达关系的研究空白，揭示了情感在议会讨论中的非均匀分布特性，并证实了近年来议会话语正变得更加积极。

Abstract: Existing research often treats parliamentary discourse as a homogeneous whole, overlooking topic-specific patterns. Parliamentary speeches address a wide range of topics, some of which evoke stronger emotions than others. While everyone has intuitive assumptions about what the most emotive topics in a parliament may be, there has been little research into the emotions typically linked to different topics. This paper strives to fill this gap by examining emotion expression among the topics of parliamentary speeches delivered in Eduskunta, the Finnish Parliament, between 2000 and 2020. An emotion analysis model is used to investigate emotion expression in topics, from both synchronic and diachronic perspectives. The results strengthen evidence of increasing positivity in parliamentary speech and provide further insights into topic-specific emotion expression within parliamentary debate.

</details>


### [90] [PEARL: Plan Exploration and Adaptive Reinforcement Learning for Multihop Tool Use](https://arxiv.org/abs/2601.20439)
*Qihao Wang,Mingzhe Lu,Jiayue Wu,Yue Hu,Yanbing Liu*

Main category: cs.CL

TL;DR: PEARL is a two-stage framework that enhances LLMs' planning and execution for complex tool use via offline exploration and online GRPO training, achieving a new state-of-the-art 56.5% success rate on ToolHop with minimal errors.


<details>
  <summary>Details</summary>
Motivation: Large Language Models face challenges in complex, multi-turn tool invocation, including weak planning, tool hallucination, incorrect parameter generation, and poor interaction robustness.

Method: PEARL is a two-stage framework: an offline phase for learning valid tool usage patterns and failure conditions through exploration, followed by an online reinforcement learning phase using Group Relative Policy Optimization (GRPO) with a tailored reward function to improve planning quality.

Result: Experiments on ToolHop and T-Eval benchmarks show PEARL achieves a state-of-the-art success rate of 56.5% on ToolHop with a low invocation error rate, outperforming existing methods.

Conclusion: PEARL represents a significant advancement in addressing complex planning challenges in LLM-based tool use, enabling more robust and reliable agent behavior.

Abstract: Large Language Models show great potential with external tools, but face significant challenges in complex, multi-turn tool invocation. They often exhibit weak planning, tool hallucination, erroneous parameter generation, and struggle with robust interaction. To tackle these issues, we present PEARL, a novel framework to enhance LLM planning and execution for sophisticated tool use. PEARL adopts a two-stage approach: an offline phase where the agent explores tools to learn valid usage patterns and failure conditions, and an online reinforcement learning phase. In the online phase, a dedicated Planner is trained via group Relative Policy Optimization (GRPO) with a carefully designed reward function that provides distinct signals for planning quality. Experiments on the ToolHop and T-Eval benchmarks show PEARL significantly outperforms existing methods, achieving a new state-of-the-art success rate of \textbf{56.5\%} on ToolHop while maintaining a low invocation error rate. Our work marks a key advance in addressing the complex planning challenges of tool use, contributing to the development of more robust and reliable LLM-based agents.

</details>


### [91] [Can We Improve Educational Diagram Generation with In-Context Examples? Not if a Hallucination Spoils the Bunch](https://arxiv.org/abs/2601.20476)
*Evanfiya Logacheva,Arto Hellas,Tsvetomila Mihaylova,Juha Sorva,Ava Heinonen,Juho Leinonen*

Main category: cs.CL

TL;DR: 本文提出一种基于修辞结构理论（RST）的上下文示例引导的图表代码生成方法，旨在提升大语言模型（LLM）生成图表的质量与用户期望的一致性。通过计算机科学教育者对150张图表的评估，发现该方法降低了事实性幻觉率并提高了图表对上下文的忠实度，但受LLM随机性影响，生成质量仍存在波动。研究还揭示复杂文本上下文易引发更高幻觉率，且模型难以自我识别错误。


<details>
  <summary>Details</summary>
Motivation: 当前生成式人工智能在计算教育中广泛应用，但生成内容的质量引发教育者和学生的担忧。尤其在图表生成方面，模型输出常出现事实性错误或与用户意图不符的情况，亟需提升生成结果的准确性和一致性。

Method: 提出一种基于修辞结构理论（RST）的上下文示例引导的图表代码生成方法，利用语义结构信息指导模型生成更符合逻辑组织、布局美观且忠实于输入上下文的图表。

Result: 评估结果显示，该方法显著降低事实性幻觉率，提升图表对上下文的忠实度；然而，由于大语言模型固有的随机性，生成质量仍存在不稳定性。复杂文本上下文更容易诱发幻觉，且模型自身难以检测输出中的错误。

Conclusion: 基于RST的上下文示例引导方法可有效提升图表生成的质量与一致性，但仍受限于模型的随机性。未来工作应聚焦于增强模型对复杂语境的理解能力及自我纠错机制。

Abstract: Generative artificial intelligence (AI) has found a widespread use in computing education; at the same time, quality of generated materials raises concerns among educators and students. This study addresses this issue by introducing a novel method for diagram code generation with in-context examples based on the Rhetorical Structure Theory (RST), which aims to improve diagram generation by aligning models' output with user expectations. Our approach is evaluated by computer science educators, who assessed 150 diagrams generated with large language models (LLMs) for logical organization, connectivity, layout aesthetic, and AI hallucination. The assessment dataset is additionally investigated for its utility in automated diagram evaluation. The preliminary results suggest that our method decreases the rate of factual hallucination and improves diagram faithfulness to provided context; however, due to LLMs' stochasticity, the quality of the generated diagrams varies. Additionally, we present an in-depth analysis and discussion on the connection between AI hallucination and the quality of generated diagrams, which reveals that text contexts of higher complexity lead to higher rates of hallucination and LLMs often fail to detect mistakes in their output.

</details>


### [92] [Beyond Divergent Creativity: A Human-Based Evaluation of Creativity in Large Language Models](https://arxiv.org/abs/2601.20546)
*Kumiko Nakajima,Jan Zuiderveld,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 本文提出一种新的评估大语言模型创造力的方法——条件发散联想任务（CDAT），以更好地反映人类创造力理论中的新颖性与恰当性结合。传统发散联想任务（DAT）仅关注新颖性，忽略了恰当性，导致其对模型创造力的评估不可靠。研究发现，一些先进大模型在DAT上的表现甚至低于无创造能力的基线，说明DAT的有效性存疑。相比之下，CDAT通过在语境恰当性的条件下评估新颖性，能更准确地区分噪声与真正创造力。实验显示，较小的模型家族在创造力上表现更好，而先进的模型虽更注重恰当性但新颖性降低，推测训练和对齐过程使模型向恰当性倾斜。作者已公开数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 现有评估大语言模型创造力的方法（如发散联想任务，DAT）缺乏对人类创造力理论的充分支持，尤其是忽视了‘恰当性’这一核心要素，导致评估结果难以解释且有效性不足。需要一种更符合人类创造力定义（即新颖性与恰当性的结合）的评估方法。

Method: 提出条件发散联想任务（CDAT），在保证上下文恰当性的前提下评估回答的新颖性；通过对比DAT与CDAT在多个先进大模型上的表现，分析模型创造力的变化趋势，并引入基线进行对照验证。

Result: CDAT相较于DAT更能有效区分创造性输出与噪声；小规模模型在新颖性方面表现更优，而大规模先进模型倾向于更高的恰当性但较低的新颖性，表明训练与对齐可能使模型偏离创造性前沿。

Conclusion: 基于人类创造力理论构建的CDAT是一种更合理、客观且可解释的评估框架，能够揭示大模型在创造力维度上的演变趋势。未来模型设计需平衡新颖性与恰当性，避免过度偏向后者。

Abstract: Large language models (LLMs) are increasingly used in verbal creative tasks. However, previous assessments of the creative capabilities of LLMs remain weakly grounded in human creativity theory and are thus hard to interpret. The widely used Divergent Association Task (DAT) focuses on novelty, ignoring appropriateness, a core component of creativity. We evaluate a range of state-of-the-art LLMs on DAT and show that their scores on the task are lower than those of two baselines that do not possess any creative abilities, undermining its validity for model evaluation. Grounded in human creativity theory, which defines creativity as the combination of novelty and appropriateness, we introduce Conditional Divergent Association Task (CDAT). CDAT evaluates novelty conditional on contextual appropriateness, separating noise from creativity better than DAT, while remaining simple and objective. Under CDAT, smaller model families often show the most creativity, whereas advanced families favor appropriateness at lower novelty. We hypothesize that training and alignment likely shift models along this frontier, making outputs more appropriate but less creative. We release the dataset and code.

</details>


### [93] [Single-Nodal Spontaneous Symmetry Breaking in NLP Models](https://arxiv.org/abs/2601.20582)
*Shalom Rosner,Ronit D. Gross,Ella Koresh,Ido Kanter*

Main category: cs.CL

TL;DR: 本文揭示了在自然语言处理（NLP）模型中，即使在确定性动态和有限架构下，也会出现自发对称性破缺现象，该现象发生在注意力头的个体层级，并可缩小至单个节点层面。随着节点数量增加，学习能力出现交叉转变，由节点间协作增强带来的提升超过单个节点能力之和。与自旋玻璃系统不同，每个节点函数均直接贡献于全局任务，且可通过凸包分析进行上界估计。实验基于BERT-6模型在Wikipedia数据集上预训练并微调FewRel分类任务，验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示在有限规模、确定性训练过程中的NLP模型中是否存在类似统计力学中自发对称性破缺的现象，以理解模型内部结构与学习行为之间的深层关系。

Method: 通过构建理论框架，分析注意力机制中单个节点的学习行为，结合凸包分析对节点功能进行上界估计，并利用大规模预训练与微调任务验证跨层级学习能力的非线性增长。

Result: 发现即使在有限架构与确定性训练条件下，NLP模型仍表现出自发对称性破缺；节点间协作显著提升整体性能，且单个节点具备学习特定标记或标签的能力；实验结果支持理论预测，显示学习能力随节点数增加呈现非线性跨越。

Conclusion: NLP模型中的自发对称性破缺并非仅存在于热力学极限，而是可在实际有限模型中观察到，其核心源于节点间的协同作用，这为理解深度学习模型内部工作机制提供了新的物理类比视角。

Abstract: Spontaneous symmetry breaking in statistical mechanics primarily occurs during phase transitions at the thermodynamic limit where the Hamiltonian preserves inversion symmetry, yet the low-temperature free energy exhibits reduced symmetry. Herein, we demonstrate the emergence of spontaneous symmetry breaking in natural language processing (NLP) models during both pre-training and fine-tuning, even under deterministic dynamics and within a finite training architecture. This phenomenon occurs at the level of individual attention heads and is scaled-down to its small subset of nodes and also valid at a single-nodal level, where nodes acquire the capacity to learn a limited set of tokens after pre-training or labels after fine-tuning for a specific classification task. As the number of nodes increases, a crossover in learning ability occurs, governed by the tradeoff between a decrease following random-guess among increased possible outputs, and enhancement following nodal cooperation, which exceeds the sum of individual nodal capabilities. In contrast to spin-glass systems, where a microscopic state of frozen spins cannot be directly linked to the free-energy minimization goal, each nodal function in this framework contributes explicitly to the global network task and can be upper-bounded using convex hull analysis. Results are demonstrated using BERT-6 architecture pre-trained on Wikipedia dataset and fine-tuned on the FewRel classification task.

</details>


### [94] [A Computational Approach to Language Contact -- A Case Study of Persian](https://arxiv.org/abs/2601.20592)
*Ali Basirat,Danial Namazifard,Navid Baradaran Hemmati*

Main category: cs.CL

TL;DR: 本研究探究了在单语语言模型的中间表示中，语言接触的结构痕迹。以历史上接触丰富的波斯语为例，分析了一个训练于波斯语的模型在接触到与波斯语具有不同接触程度和类型的语言时的表示特征。通过量化中间表示中编码的语言信息量，并评估这些信息在不同形态句法特征上的分布情况，发现普遍的句法信息对历史接触不敏感，而如格和性别等形态特征则强烈受语言特定结构影响，表明语言接触对单语模型的影响是选择性的且受结构限制。


<details>
  <summary>Details</summary>
Motivation: 探索语言接触如何在单语语言模型的中间表示中留下可识别的结构痕迹，特别是在语言接触频繁的历史背景下。

Method: 量化中间表示中编码的语言信息量，分析其在不同形态句法特征上的分布模式，对比波斯语与其他接触语言的模型表现差异。

Result: 普遍的句法信息对历史接触不敏感，而形态特征如格和性别显著受到语言特定结构的影响，表明接触效应具有选择性和结构性约束。

Conclusion: 语言接触在单语语言模型中的影响并非全面，而是集中在特定的形态层面，说明模型对语言结构的表征具有选择性，反映了语言接触的结构性痕迹。

Abstract: We investigate structural traces of language contact in the intermediate representations of a monolingual language model. Focusing on Persian (Farsi) as a historically contact-rich language, we probe the representations of a Persian-trained model when exposed to languages with varying degrees and types of contact with Persian. Our methodology quantifies the amount of linguistic information encoded in intermediate representations and assesses how this information is distributed across model components for different morphosyntactic features. The results show that universal syntactic information is largely insensitive to historical contact, whereas morphological features such as Case and Gender are strongly shaped by language-specific structure, suggesting that contact effects in monolingual language models are selective and structurally constrained.

</details>


### [95] [P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering](https://arxiv.org/abs/2601.20649)
*Wenlin Zhong,Chengyuan Liu,Yiquan Wu,Bovin Tan,Changlong Sun,Yi Wang,Xiaozhong Liu,Kun Kuang*

Main category: cs.CL

TL;DR: 提出P2S（Probabilistic Process Supervision）框架，通过计算每一步推理的路径忠实性奖励（PFR），在无需额外奖励模型或人工标注的情况下，实现对大语言模型推理过程的细粒度监督。该方法利用生成黄金思维链后缀的条件概率作为奖励信号，可与任何基于结果的奖励结合，有效缓解奖励稀疏问题，在阅读理解与医学问答任务中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在通用领域推理任务中受限于缺乏可验证的奖励信号，而基于结果的奖励方法忽视了推理过程中的步骤级监督，因此需要一种无需人工标注即可提供细粒度过程奖励的自监督机制。

Method: P2S通过合成并筛选高质量的参考推理链（gold-CoT），计算每一步的路径忠实性奖励（PFR），即基于当前推理前缀生成黄金推理链后缀的条件概率，并将该奖励与结果奖励结合，实现密集且有效的强化学习指导。

Result: 在阅读理解与医学问答基准测试中，P2S显著优于现有强基线方法，证明其在通用领域推理任务中的有效性与优越性。

Conclusion: P2S为通用领域的大语言模型推理提供了有效的细粒度过程监督机制，克服了奖励稀疏性问题，无需依赖外部奖励模型或人工标注，具有良好的可扩展性和实用性。

Abstract: While reinforcement learning with verifiable rewards (RLVR) has advanced LLM reasoning in structured domains like mathematics and programming, its application to general-domain reasoning tasks remains challenging due to the absence of verifiable reward signals. To this end, methods like Reinforcement Learning with Reference Probability Reward (RLPR) have emerged, leveraging the probability of generating the final answer as a reward signal. However, these outcome-focused approaches neglect crucial step-by-step supervision of the reasoning process itself. To address this gap, we introduce Probabilistic Process Supervision (P2S), a novel self-supervision framework that provides fine-grained process rewards without requiring a separate reward model or human-annotated reasoning steps. During reinforcement learning, P2S synthesizes and filters a high-quality reference reasoning chain (gold-CoT). The core of our method is to calculate a Path Faithfulness Reward (PFR) for each reasoning step, which is derived from the conditional probability of generating the gold-CoT's suffix, given the model's current reasoning prefix. Crucially, this PFR can be flexibly integrated with any outcome-based reward, directly tackling the reward sparsity problem by providing dense guidance. Extensive experiments on reading comprehension and medical Question Answering benchmarks show that P2S significantly outperforms strong baselines.

</details>


### [96] [A Dialectic Pipeline for Improving LLM Robustness](https://arxiv.org/abs/2601.20659)
*Sara Candussio*

Main category: cs.CL

TL;DR: 本文提出了一种基于自对话的辩证流程，旨在减少大语言模型的幻觉并提升输出质量，同时保持其泛化能力。该方法通过让模型自我反思和修正错误答案来实现改进，并在多种模型家族和数据集上进行了实验验证。结果表明，该方法显著优于标准模型输出和仅使用思维链提示的方法。


<details>
  <summary>Details</summary>
Motivation: 当前减少大语言模型幻觉的方法如微调或专用验证器需要大量计算资源且局限于特定领域，难以广泛适用。因此需要一种高效、通用的改进方法。

Method: 提出一种自对话驱动的辩证流程，使模型能够自我反思并修正初步回答，在具备上下文信息的类原语RAG设置下运行各阶段，并研究摘要与过滤策略的影响。

Result: 所提方法在多个数据集和模型上均显著优于标准模型输出，且性能持续高于仅使用思维链提示的方法。

Conclusion: 该辩证管道有效提升了大语言模型的回答质量，同时保持了其跨领域的泛化能力，是一种高效且通用的改进方案。

Abstract: Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use.
  However, methods such as fine-tuning on domain-specific data or the training of a separate \textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge.
  In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers.
  We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted.
  We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.

</details>


### [97] [Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science](https://arxiv.org/abs/2601.20674)
*Juan Jose Rubio Jan,Jack Wu,Julia Ive*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）在电子健康记录（EHR）数据科学中的应用，包括结构化数据查询（使用Python/Pandas）和非结构化临床文本的信息提取（通过检索增强生成RAG管道）。研究构建了一个灵活的评估框架，自动生成针对特定数据集或任务的合成问答对，并在MIMIC-III数据集的子集上进行实验，涵盖四个结构化表格和一种临床笔记类型。评估结合精确匹配、语义相似性和人工判断，结果表明LLMs在临床工作流中具备支持精准查询和准确信息提取的潜力。


<details>
  <summary>Details</summary>
Motivation: 提升电子健康记录（EHR）数据科学任务中结构化数据查询与非结构化文本信息提取的自动化水平，探索大型语言模型（LLMs）在临床数据分析中的可靠性与有效性。

Method: 构建一个灵活的评估框架，自动产生与特定数据集或任务特征匹配的合成问题与答案对；在MIMIC-III数据集的子集上，使用本地部署和API调用的LLMs进行实验；采用精确匹配、语义相似性以及人工评估相结合的多维度评价方法。

Result: LLMs在结构化数据查询和非结构化临床文本信息提取方面表现出较高的准确性与可靠性，尤其在配合检索增强生成（RAG）机制时，能够有效支持临床数据分析任务。

Conclusion: 大型语言模型在电子健康记录数据科学任务中具有显著潜力，能够实现精准的数据查询与语义正确的信息提取，为临床工作流中的智能化分析提供有力支持。

Abstract: This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.

</details>


### [98] [ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code](https://arxiv.org/abs/2601.20679)
*Mingqiao Mo,Yunlong Tan,Hao Zhang,Heng Zhang,Yangfan He*

Main category: cs.CL

TL;DR: 本文提出ShieldedCode，首个面向软件保护的框架，通过学习虚拟机保护（VMP）代码的鲁棒表示来增强代码安全性。该框架构建大规模源代码与标准化虚拟机实现的配对数据集，并引入指令内、前序及跨指令级别的分层依赖建模。结合语义建模与功能感知、保护感知的对比目标进行联合优化，以捕捉语义等价性与保护强度。进一步设计保护有效性优化任务，量化并排序同一源码生成的不同虚拟机变体。采用两阶段持续预训练与微调流程，使模型能够生成、比较和推理受保护代码。实验表明，该方法在多种保护级别下显著提升鲁棒性，实现26.95% Pass@1（L0 VM代码生成），优于GPT-4o的22.58%，且二进制相似性检测召回率提升10%。


<details>
  <summary>Details</summary>
Motivation: 传统虚拟机保护（VMP）依赖规则化变换，成本高且易被自动化分析破解；大语言模型在代码生成中表现优异，但其在软件保护领域的潜力尚未充分挖掘。亟需一种能学习并理解保护后代码语义与结构的新方法，以应对逆向工程威胁。

Method: 构建大规模源代码与标准化虚拟机实现的配对数据集；采用分层依赖建模（指令内、前序、跨指令）；联合优化语言建模与功能感知、保护感知的对比损失；设计保护有效性优化任务以量化不同保护变体的强度；采用两阶段持续预训练与微调策略。

Result: 在L0 VM代码生成任务上达到26.95% Pass@1，优于GPT-4o的22.58%；二进制相似性检测召回率提升10%；在多级保护场景下显著增强鲁棒性；验证了学习型软件防御的新方向可行性。

Conclusion: ShieldedCode是首个保护感知的代码表示学习框架，通过融合语义与保护特征，有效提升虚拟机保护代码的生成质量与检测能力，为基于学习的软件安全防护开辟新路径。

Abstract: Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.

</details>


### [99] [Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin](https://arxiv.org/abs/2601.20680)
*Ostap Vykhopen,Viktoria Skorik,Maxim Tereschenko,Veronika Solopova*

Main category: cs.CL

TL;DR: 本文研究将传统批处理聚类算法HDBSCAN替换为在线聚类方法，以解决社交媒体监控中持续数据流的可扩展性挑战。提出三阶段架构处理每日数千条多语言文本，评估多种在线聚类算法在聚类质量、计算效率、内存占用和工作流兼容性方面的表现，并引入结合传统与叙事指标的综合评估标准，在历史乌克兰信息空间数据上进行滑动窗口模拟，验证算法在真实场景中的权衡表现。


<details>
  <summary>Details</summary>
Motivation: 传统批处理聚类算法如HDBSCAN虽能有效发现层次化密度聚类并处理噪声，但其仅支持离线计算，需对每个时间窗口重新训练，导致内存压力大、计算低效且无法实时适应演化的叙事趋势，难以满足社交媒体持续数据流的实时分析需求。

Method: 采用三阶段系统架构（数据收集、建模、仪表板生成），在历史乌克兰信息空间数据集上通过滑动窗口模拟，对比多种在线聚类算法；设计融合传统聚类指标（轮廓系数、Davies-Bouldin指数）与叙事指标（叙事独特性、连贯性、方差）的综合评估框架，量化算法在实际应用中的性能表现。

Result: 实验表明，部分在线聚类算法在保持较高聚类质量的同时显著降低计算开销和内存使用，具备更好的实时适应能力与工作流集成性，尤其在动态叙事演化场景中优于传统批处理方法，验证了在线聚类在大规模社会媒体叙事监测中的可行性与优势。

Conclusion: 本研究填补了批处理主题建模框架与流式社交媒体监控之间的关键鸿沟，证明在线聚类方法可在保证聚类质量的前提下提升系统的可扩展性与实时性，对计算社会科学、危机信息学及叙事监控系统具有重要实践意义。

Abstract: Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clustering methods in a production narrative report generation pipeline. The proposed system employs a three-stage architecture (data collection, modeling, dashboard generation) that processes thousands of multilingual social media documents daily. While HDBSCAN excels at discovering hierarchical density-based clusters and handling noise, its batch-only nature necessitates complete retraining for each time window, resulting in memory constraints, computational inefficiency, and inability to adapt to evolving narratives in real-time. This work evaluates a bunch of online clustering algorithms across dimensions of cluster quality preservation, computational efficiency, memory footprint, and integration compatibility with existing workflows. We propose evaluation criteria that balance traditional clustering metrics (Silhouette Coefficient, Davies-Bouldin Index) with narrative metrics (narrative distinctness, contingency and variance). Our methodology includes sliding-window simulations on historical datasets from Ukraine information space, enabling comparative analysis of algorithmic trade-offs in realistic operational contexts. This research addresses a critical gap between batch-oriented topic modeling frameworks and the streaming nature of social media monitoring, with implications for computational social science, crisis informatics, and narrative surveillance systems.

</details>


### [100] [AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts](https://arxiv.org/abs/2601.20730)
*Shicheng Fang,Yuxin Wang,XiaoRan Liu,Jiahao Lu,Chuanyuan Tan,Xinchi Chen,Yining Zheng. Xuanjing Huang,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文提出AgentLongBench，一个基于横向思维谜题的动态环境模拟框架，用于评估大语言模型在复杂交互中的表现。实验发现，尽管模型在静态检索中表现良好，但在需要动态信息整合的任务中表现不佳，其性能下降主要受解决问题所需最少标记数的影响。高信息密度的工具响应比长对话中的记忆碎片化更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多为静态、被动的检索任务，无法有效模拟智能体与环境之间的复杂互动，如非线性推理和迭代反馈。因此需要新的评估框架来更真实地反映大模型作为自主智能体在动态上下文中的能力。

Method: 引入AgentLongBench，通过构建基于横向思维谜题的模拟环境，生成知识密集型与知识无关型的交互轨迹，以评估智能体在长时间、多轮动态交互中的表现。

Result: 实验表明，当前最先进的模型在静态检索任务中表现良好，但在动态信息合成任务中出现显著退化；性能下降主要由解决一个问题所需的最小标记数决定，高信息密度的工具输出构成更大挑战。

Conclusion: 当前大模型在处理动态上下文时存在根本性缺陷，尤其在面对高信息密度响应时表现不足，揭示了对新型记忆机制和推理架构的需求。

Abstract: The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues.

</details>


### [101] [QueerGen: How LLMs Reflect Societal Norms on Gender and Sexuality in Sentence Completion Tasks](https://arxiv.org/abs/2601.20731)
*Mae Sosto,Delfina Sol Martinez Pandiani,Laura Hollink*

Main category: cs.CL

TL;DR: 该研究探讨大型语言模型（LLMs）如何再现社会规范，尤其是异性恋顺性别规范，并分析这些规范如何转化为文本生成中的可测量偏差。研究比较了在涉及性取向或性别身份的明确信息下，模型对三类主体（酷儿标记、非酷儿标记、中性未标记）的响应差异，通过情感、评价、毒性及预测多样性四个维度评估表征不平衡。结果显示，掩码语言模型（MLMs）对酷儿标记主体产生最负面的情感、更高毒性与更消极评价；自回归语言模型（ARLMs）部分缓解了这些模式，而封闭访问的ARLMs反而对未标记主体产生更具伤害性的输出。研究指出，尽管模型特征影响偏差形式与程度，但总体仍再现了规范性社会假设，且偏见难以彻底消除。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何复制社会中的异性恋顺性别规范，并揭示这些规范如何在文本生成中体现为可测量的偏见，以理解模型中的代表性不平等及其潜在社会影响。

Method: 通过对比不同类别主体（酷儿标记、非酷儿标记、未标记）在性别/性取向明确条件下的语言模型输出，采用情感、评价、毒性、预测多样性四维指标量化表征不平衡，分析掩码语言模型（MLMs）、自回归语言模型（ARLMs）及封闭访问模型的表现差异。

Result: MLMs对酷儿标记主体表现出最负面的情感、更高毒性与更差评价；ARLMs部分减轻了此类偏差，但封闭访问的ARLMs对未标记主体产生更有害输出。模型特性显著影响偏见形式与程度，但未能消除整体社会规范的再现。

Conclusion: 大型语言模型系统性地再现了异性恋顺性别等规范性社会假设，其偏差表现受模型架构与开放性的影响，虽可能转移或减轻部分危害，但无法根本消除表征不公。

Abstract: This paper examines how Large Language Models (LLMs) reproduce societal norms, particularly heterocisnormativity, and how these norms translate into measurable biases in their text generations. We investigate whether explicit information about a subject's gender or sexuality influences LLM responses across three subject categories: queer-marked, non-queer-marked, and the normalized "unmarked" category. Representational imbalances are operationalized as measurable differences in English sentence completions across four dimensions: sentiment, regard, toxicity, and prediction diversity. Our findings show that Masked Language Models (MLMs) produce the least favorable sentiment, higher toxicity, and more negative regard for queer-marked subjects. Autoregressive Language Models (ARLMs) partially mitigate these patterns, while closed-access ARLMs tend to produce more harmful outputs for unmarked subjects. Results suggest that LLMs reproduce normative social assumptions, though the form and degree of bias depend strongly on specific model characteristics, which may redistribute, but not eliminate, representational harms.

</details>


### [102] [Like a Therapist, But Not: Reddit Narratives of AI in Mental Health Contexts](https://arxiv.org/abs/2601.20747)
*Elham Aghakhani,Rezvaneh Rezapour*

Main category: cs.CL

TL;DR: This study analyzes 5,126 Reddit posts on AI use for mental health, finding that users value task alignment, trust, and response quality over emotional bonds; companionship-focused use carries higher risks like dependence and symptom worsening, highlighting the importance of context-sensitive design in AI mental health tools.


<details>
  <summary>Details</summary>
Motivation: To understand how people evaluate and relate to large language models (LLMs) in everyday emotional support and mental health contexts, especially outside clinical settings.

Method: A theory-informed annotation framework based on the Technology Acceptance Model and therapeutic alliance theory was developed. A hybrid LLM-human pipeline was applied to analyze 5,126 Reddit posts from 47 mental health communities.

Result: Engagement is primarily shaped by narrated outcomes, trust, and response quality rather than emotional bond. Positive sentiment correlates strongly with task and goal alignment, while companionship-oriented use often leads to misaligned alliances and risks like dependence and symptom escalation.

Conclusion: Theory-grounded constructs can be effectively operationalized in large-scale discourse analysis, emphasizing the need to study user interpretations of language technologies in sensitive real-world contexts.

Abstract: Large language models (LLMs) are increasingly used for emotional support and mental health-related interactions outside clinical settings, yet little is known about how people evaluate and relate to these systems in everyday use. We analyze 5,126 Reddit posts from 47 mental health communities describing experiential or exploratory use of AI for emotional support or therapy. Grounded in the Technology Acceptance Model and therapeutic alliance theory, we develop a theory-informed annotation framework and apply a hybrid LLM-human pipeline to analyze evaluative language, adoption-related attitudes, and relational alignment at scale. Our results show that engagement is shaped primarily by narrated outcomes, trust, and response quality, rather than emotional bond alone. Positive sentiment is most strongly associated with task and goal alignment, while companionship-oriented use more often involves misaligned alliances and reported risks such as dependence and symptom escalation. Overall, this work demonstrates how theory-grounded constructs can be operationalized in large-scale discourse analysis and highlights the importance of studying how users interpret language technologies in sensitive, real-world contexts.

</details>


### [103] [Persona Prompting as a Lens on LLM Social Reasoning](https://arxiv.org/abs/2601.20757)
*Jing Yang,Moritz Hechtbauer,Elisabeth Khalilov,Evelyn Luise Brinkmann,Vera Schmitt,Nils Feldhus*

Main category: cs.CL

TL;DR: 该研究探讨了在仇恨言论检测等社会敏感任务中，基于模拟人口特征的角色提示（Persona Prompting, PP）对大语言模型（LLM）生成解释质量的影响。结果显示，尽管PP能提升分类准确率，但会降低解释质量，并且无法有效减少模型的固有偏见，反而表现出对内容过度标记的倾向。此外，模拟角色与真实人群之间缺乏对齐，模型对提示的响应也显示出较强的抗干扰性。总体表明，使用PP存在显著权衡，需谨慎应用。


<details>
  <summary>Details</summary>
Motivation: 在社会敏感任务如仇恨言论检测中，大语言模型生成的解释质量直接影响用户信任和模型对齐。虽然角色提示（PP）被广泛用于引导模型生成更符合特定用户风格的内容，但其对模型推理过程和解释质量的影响尚未充分研究。因此，亟需评估PP在不同人口特征设定下的表现及其对模型偏见和人类对齐的影响。

Method: 本研究采用三个大语言模型，在带有词级解释标注的数据集上，通过设计不同模拟人口特征的角色提示，对比分析模型在分类性能和解释质量上的变化。通过计算模型解释与不同人口群体人类标注的一致性，评估模型偏差与人类对齐程度。

Result: 1. PP在主观性最强的任务（如仇恨言论检测）中提升了分类性能，但显著降低了模型生成解释的质量；2. 模拟的人口角色未能有效反映真实人群特征，且模型在不同角色间表现出高度一致性，说明其难以被有效引导；3. 模型普遍存在性别、种族等维度的系统性偏见，并倾向于过度标记内容为有害，这一现象不受PP影响。

Conclusion: 尽管角色提示（PP）可在某些情况下提升大语言模型在社会敏感任务中的分类表现，但它通常以牺牲解释质量为代价，且无法缓解模型内在偏见，甚至可能加剧过度标记问题。因此，在实际应用中应谨慎使用PP，尤其在需要高可解释性和公平性的场景中。

Abstract: For socially sensitive tasks like hate speech detection, the quality of explanations from Large Language Models (LLMs) is crucial for factors like user trust and model alignment. While Persona prompting (PP) is increasingly used as a way to steer model towards user-specific generation, its effect on model rationales remains underexplored. We investigate how LLM-generated rationales vary when conditioned on different simulated demographic personas. Using datasets annotated with word-level rationales, we measure agreement with human annotations from different demographic groups, and assess the impact of PP on model bias and human alignment. Our evaluation across three LLMs results reveals three key findings: (1) PP improving classification on the most subjective task (hate speech) but degrading rationale quality. (2) Simulated personas fail to align with their real-world demographic counterparts, and high inter-persona agreement shows models are resistant to significant steering. (3) Models exhibit consistent demographic biases and a strong tendency to over-flag content as harmful, regardless of PP. Our findings reveal a critical trade-off: while PP can improve classification in socially-sensitive tasks, it often comes at the cost of rationale quality and fails to mitigate underlying biases, urging caution in its application.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [104] [Gap-K%: Measuring Top-1 Prediction Gap for Detecting Pretraining Data](https://arxiv.org/abs/2601.19936)
*Minseo Kwak,Jaehyung Kim*

Main category: cs.LG

TL;DR: Gap-K% 是一种基于大语言模型预训练优化动态的新型预训练数据检测方法，通过分析下一个词预测目标，利用顶级预测词与目标词之间的对数概率差距，并结合滑动窗口策略捕捉局部相关性，有效缓解了单个词的波动问题。在 WikiMIA 和 MIMIR 基准上的实验表明，该方法在不同模型规模和输入长度下均优于现有基线，达到当前最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有预训练数据检测方法主要依赖于词元似然，但忽略了模型顶1预测与目标词之间的差异以及相邻词元间的局部相关性，导致检测效果受限。因此，需要一种能更准确捕捉预训练数据特征的新方法。

Method: 提出 Gap-K%，基于预训练过程中的优化动态，通过分析下一个词预测目标，计算顶1预测词与目标词之间的对数概率差距，并引入滑动窗口机制以捕获局部上下文相关性，从而增强检测能力。

Result: 在 WikiMIA 和 MIMIR 基准上，Gap-K% 在多种模型大小和输入长度条件下均显著优于现有方法，实现了当前最优的检测性能。

Conclusion: Gap-K% 通过结合梯度信号敏感性和局部上下文建模，有效提升了预训练数据检测的准确性，为解决大型语言模型中预训练数据隐私与版权问题提供了强有力的技术支持。

Abstract: The opacity of massive pretraining corpora in Large Language Models (LLMs) raises significant privacy and copyright concerns, making pretraining data detection a critical challenge. Existing state-of-the-art methods typically rely on token likelihoods, yet they often overlook the divergence from the model's top-1 prediction and local correlation between adjacent tokens. In this work, we propose Gap-K%, a novel pretraining data detection method grounded in the optimization dynamics of LLM pretraining. By analyzing the next-token prediction objective, we observe that discrepancies between the model's top-1 prediction and the target token induce strong gradient signals, which are explicitly penalized during training. Motivated by this, Gap-K% leverages the log probability gap between the top-1 predicted token and the target token, incorporating a sliding window strategy to capture local correlations and mitigate token-level fluctuations. Extensive experiments on the WikiMIA and MIMIR benchmarks demonstrate that Gap-K% achieves state-of-the-art performance, consistently outperforming prior baselines across various model sizes and input lengths.

</details>


### [105] [DecHW: Heterogeneous Decentralized Federated Learning Exploiting Second-Order Information](https://arxiv.org/abs/2601.19938)
*Adnan Ahmad,Chiara Boldrini,Lorenzo Valerio,Andrea Passarella,Marco Conti*

Main category: cs.LG

TL;DR: 本文提出一种新型聚合方法，通过捕捉局部模型间的参数差异，在去中心化联邦学习中实现更鲁棒的模型聚合。该方法利用局部模型在本地数据上的二阶信息近似生成共识权重，以调整邻居更新并提升全局表示的准确性。实验表明，该方法在计算机视觉任务中具有良好的泛化能力，并显著降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习中，设备间的数据和模型初始化异质性导致局部模型参数差异，影响收敛速度。现有方法未能有效处理参数层面的不确定性，因此需要一种能够识别并应对这种异质性的聚合机制。

Method: 通过近似局部模型在本地数据上的二阶信息，计算出共识权重，用于加权邻居模型更新，从而在聚合时增强对异质性的鲁棒性。

Result: 在多个计算机视觉任务上，所提方法显著提升了模型的泛化性能，同时降低了通信开销，表现出更强的适应性和效率。

Conclusion: 提出的基于二阶信息的共识权重聚合机制有效缓解了去中心化联邦学习中的数据与模型异质性问题，实现了高效且稳健的模型协同学习。

Abstract: Decentralized Federated Learning (DFL) is a serverless collaborative machine learning paradigm where devices collaborate directly with neighbouring devices to exchange model information for learning a generalized model. However, variations in individual experiences and different levels of device interactions lead to data and model initialization heterogeneities across devices. Such heterogeneities leave variations in local model parameters across devices that leads to slower convergence. This paper tackles the data and model heterogeneity by explicitly addressing the parameter level varying evidential credence across local models. A novel aggregation approach is introduced that captures these parameter variations in local models and performs robust aggregation of neighbourhood local updates. Specifically, consensus weights are generated via approximation of second-order information of local models on their local datasets. These weights are utilized to scale neighbourhood updates before aggregating them into global neighbourhood representation. In extensive experiments with computer vision tasks, the proposed approach shows strong generalizability of local models at reduced communication costs.

</details>


### [106] [oculomix: Hierarchical Sampling for Retinal-Based Systemic Disease Prediction](https://arxiv.org/abs/2601.19939)
*Hyunmin Kim,Yukun Zhou,Rahul A. Jonas,Lie Ju,Sunjin Hwang,Pearse A. Keane,Siegfried K. Wagner*

Main category: cs.LG

TL;DR: 本文提出了一种名为Oculomix的分层采样策略，用于改进基于眼部图像的系统性疾病预测（如心血管疾病和痴呆）中混合样本数据增强的效果。传统方法如CutMix和MixUp仅在图像层面进行混合，忽略了患者特异性属性（如共病和临床因素），而Oculomix基于两个临床先验：同一患者同一次检查的图像具有相同特征，不同时间点的图像呈现软时间趋势（疾病随时间加重）。该方法将混合限制在患者和检查层级，以更好地保留个体特征。在大型多元种族人群数据集Alzeye上使用ViT模型验证，Oculomix在五年内预测主要不良心血管事件（MACE）方面比传统方法最高提升3%的AUROC，证明其有效性与必要性。


<details>
  <summary>Details</summary>
Motivation: 现有图像级数据增强方法（如CutMix、MixUp）在训练视觉变压器时会破坏患者特异性属性（如共病、临床因素），因它们仅关注图像和标签，未考虑患者的临床背景。为提升系统性疾病预测的准确性，需设计能保留患者个体特征的增强策略。

Method: 提出Oculomix，一种基于临床先验的分层采样增强方法。第一，检查层级：同一患者同一时间点获取的图像共享相同属性；第二，患者层级：同一患者不同时期的图像存在软时间趋势（疾病逐渐恶化）。通过约束混合空间至患者和检查层级，利用其层次关系，在保持数据多样性的同时保护患者特异性信息。

Result: 在Alzeye数据集上使用ViT模型进行五年MACE预测任务中，Oculomix显著优于图像级增强方法（CutMix、MixUp），AUROC最高提升达3%，表明其在保留患者特异性特征方面的优越性。

Conclusion: Oculomix通过引入临床先验指导的分层混合机制，有效提升了眼部影像驱动的系统性疾病预测性能，证明了在医疗视觉建模中考虑患者层级结构的重要性，为未来眼科学与人工智能融合研究提供了新范式。

Abstract: Oculomics - the concept of predicting systemic diseases, such as cardiovascular disease and dementia, through retinal imaging - has advanced rapidly due to the data efficiency of transformer-based foundation models like RETFound. Image-level mixed sample data augmentations, such as CutMix and MixUp, are frequently used for training transformers, yet these techniques perturb patient-specific attributes, such as medical comorbidity and clinical factors, since they only account for images and labels. To address this limitation, we propose a hierarchical sampling strategy, Oculomix, for mixed sample augmentations. Our method is based on two clinical priors. First (exam level), images acquired from the same patient at the same time point share the same attributes. Second (patient level), images acquired from the same patient at different time points have a soft temporal trend, as morbidity generally increases over time. Guided by these priors, our method constrains the mixing space to the patient and exam levels to better preserve patient-specific characteristics and leverages their hierarchical relationships. The proposed method is validated using ViT models on a five-year prediction of major adverse cardiovascular events (MACE) in a large ethnically diverse population (Alzeye). We show that Oculomix consistently outperforms image-level CutMix and MixUp by up to 3% in AUROC, demonstrating the necessity and value of the proposed method in oculomics.

</details>


### [107] [Latent Object Permanence: Topological Phase Transitions, Free-Energy Principles, and Renormalization Group Flows in Deep Transformer Manifolds](https://arxiv.org/abs/2601.19942)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.LG

TL;DR: 本文从几何与统计物理视角研究深度Transformer语言模型中多步推理的涌现，通过分析隐藏状态轨迹在隐式黎曼流形上的流动，发现随着模型规模增大（1.5B–30B），有效维度急剧降低，表现出类似相变的现象。关键指标Ω(h)在归一化深度γ_c≈0.42处出现不连续，表明存在一个临界点。将前向传播视为离散粗粒化映射，揭示稳定“概念盆地”的形成与重整化动力学的不动点相关。低熵状态下，谱尾坍缩并形成可瞬时复用的对象类结构，称为瞬态类别对象（TCOs）。理论推导了逻辑可分性与谱衰减的关系，并通过多模型族的层间探测验证了预测特征。


<details>
  <summary>Details</summary>
Motivation: 理解深度Transformer模型中多步推理能力的涌现机制，尤其是其内在的几何与动力学基础，为解释大模型复杂行为提供理论框架。

Method: 将隐藏状态轨迹建模为隐式黎曼流形上的流；分析各层激活的协方差谱，检测与随机矩阵理论的偏离；引入基于稀疏性/局域化的序参数Ω(h)；将前向传播视为粗粒化映射，研究其不动点行为；通过谱分析和层间探测验证理论预测。

Result: 在约γ_c≈0.42处观察到有效维度的突降，表现为相变特征；发现稳定概念盆地与重整化不动点相关；低熵状态下出现谱尾坍缩及可复用的瞬态类别对象（TCOs）；理论条件连接逻辑可分性与谱衰减，且在多个开放权重模型上得到验证。

Conclusion: 多步推理的涌现可被理解为一种由模型深度驱动的相变过程，其本质是表征空间中结构化、低熵的动态聚集，由谱特性与重整化行为共同决定，揭示了大模型内部推理机制的深层几何本质。

Abstract: We study the emergence of multi-step reasoning in deep Transformer language models through a geometric and statistical-physics lens. Treating the hidden-state trajectory as a flow on an implicit Riemannian manifold, we analyze the layerwise covariance spectrum of activations, where $C^{(\ell)}=\mathbb{E}[h^{(\ell)}h^{(\ell)\top}]$, and track deviations from a random-matrix bulk. Across model scales (1.5B--30B), we observe a sharp reduction in effective dimensionality consistent with a phase transition: an order parameter based on sparsity/localization, $Ω(h)=1-\|h\|_1/(\sqrt{d}\|h\|_2)$, exhibits a discontinuity near a critical normalized depth $γ_c\approx 0.42$ in sufficiently large models. We formalize the forward pass as a discrete coarse-graining map and relate the appearance of stable "concept basins" to fixed points of this renormalization-like dynamics. The resulting low-entropy regime is characterized by a spectral tail collapse and by the formation of transient, reusable object-like structures in representation space, which we call Transient Class Objects (TCOs). We provide theoretical conditions connecting logical separability to spectral decay and validate the predicted signatures with layerwise probes on multiple open-weight model families.

</details>


### [108] [Emergent Specialization in Learner Populations: Competition as the Source of Diversity](https://arxiv.org/abs/2601.19943)
*Yuhao Li*

Main category: cs.LG

TL;DR: 本文研究了在无显式沟通或多样性激励的情况下，学习者群体如何自发形成协调且多样的行为。通过引入NichePopulation算法，结合竞争排斥与生态位亲和性追踪，实验验证了在六种真实场景（加密货币交易、商品价格、天气预测、太阳能辐射、城市交通和空气质量）中，该方法实现了0.75的平均专业化指数，效应量超过Cohen's d > 20。关键发现包括：(1) 即使在无生态位奖励时（lambda=0），专业化指数仍高于0.30，证明专业化是真正涌现的；(2) 多样化群体比同质基线提升26.5%性能，体现方法层面的分工优势；(3) 相较于MARL基准（QMIX, MAPPO, IQL），本方法性能提升4.3倍，速度更快4倍。


<details>
  <summary>Details</summary>
Motivation: 研究如何在缺乏显式通信或多样性激励的前提下，让学习者群体自发产生多样化且协调的行为，探索竞争机制在促进生态位分化中的作用。

Method: 提出NichePopulation算法，融合竞争排斥机制与生态位亲和性追踪，通过模拟生态位理论实现学习者的自然分化。

Result: 在六个真实世界任务中，平均专业化指数达0.75，效应量显著（Cohen's d > 20）；无奖励条件下仍具专业化能力（SI > 0.30）；多样化群体性能优于同质基线26.5%；相比主流MARL方法，性能提升4.3倍且速度快4倍。

Conclusion: 竞争本身足以驱动学习者群体自发形成专业化行为，无需额外激励。NichePopulation算法有效实现了多样性的涌现，并在性能与效率上显著超越现有方法。

Abstract: How can populations of learners develop coordinated, diverse behaviors without explicit communication or diversity incentives? We demonstrate that competition alone is sufficient to induce emergent specialization -- learners spontaneously partition into specialists for different environmental regimes through competitive dynamics, consistent with ecological niche theory. We introduce the NichePopulation algorithm, a simple mechanism combining competitive exclusion with niche affinity tracking. Validated across six real-world domains (cryptocurrency trading, commodity prices, weather forecasting, solar irradiance, urban traffic, and air quality), our approach achieves a mean Specialization Index of 0.75 with effect sizes of Cohen's d > 20. Key findings: (1) At lambda=0 (no niche bonus), learners still achieve SI > 0.30, proving specialization is genuinely emergent; (2) Diverse populations outperform homogeneous baselines by +26.5% through method-level division of labor; (3) Our approach outperforms MARL baselines (QMIX, MAPPO, IQL) by 4.3x while being 4x faster.

</details>


### [109] [Probabilistic Sensing: Intelligence in Data Sampling](https://arxiv.org/abs/2601.19953)
*Ibrahim Albulushi,Saleh Bunaiyan,Suraj S. Cheema,Hesham ElSawy,Feras Al-Dirini*

Main category: cs.LG

TL;DR: 提出一种基于概率神经元（p-neuron）的智能传感范式，通过模拟自主神经系统实现数据采集过程中的概率性采样决策，显著提升能效并支持微秒级实时响应。实验验证在地震勘探数据上实现了近乎无损的数据采集（均方误差仅0.41%），同时节省93%的系统运行时间和采样数量。


<details>
  <summary>Details</summary>
Motivation: 传统确定性采样方式虽节能但存在丢失信息的风险，亟需一种既能保障数据完整性又可大幅降低能耗的智能采样机制。

Method: 受自主神经系统启发，采用模拟电路实现特征提取，并结合概率神经元（p-neuron）进行随机化采样决策，实现毫微秒级响应速度下的实时智能采样控制。

Result: 在主动地震勘测数据上实现0.41%的归一化均方误差，系统工作时间与采样数量减少93%，达到近似无损压缩与高效能采集的平衡。

Conclusion: 该概率性传感范式有效解决了智能采样中的能效与信息保全矛盾，为低功耗、实时、自适应数据采集提供了新路径。

Abstract: Extending the intelligence of sensors to the data-acquisition process - deciding whether to sample or not - can result in transformative energy-efficiency gains. However, making such a decision in a deterministic manner involves risk of losing information. Here we present a sensing paradigm that enables making such a decision in a probabilistic manner. The paradigm takes inspiration from the autonomous nervous system and employs a probabilistic neuron (p-neuron) driven by an analog feature extraction circuit. The response time of the system is on the order of microseconds, over-coming the sub-sampling-rate response time limit and enabling real-time intelligent autonomous activation of data-sampling. Validation experiments on active seismic survey data demonstrate lossless probabilistic data acquisition, with a normalized mean squared error of 0.41%, and 93% saving in the active operation time of the system and the number of generated samples.

</details>


### [110] [MeanCache: From Instantaneous to Average Velocity for Accelerating Flow Matching Inference](https://arxiv.org/abs/2601.19961)
*Huanlin Gao,Ping Chen,Fuyuan Shi,Ruijia Wu,Li YanTao,Qiang Hui,Yuren You,Ting Lu,Chao Tan,Shaoan Zhao,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.LG

TL;DR: MeanCache是一种无需训练的缓存框架，用于高效流匹配推理。它通过利用缓存的雅可比-向量积（JVP）构建区间平均速度，缓解了瞬时速度信息导致的轨迹偏差和误差累积问题。同时提出轨迹稳定性调度策略，在预算约束下采用抑制峰值的最短路径算法优化缓存时机与JVP复用稳定性。在FLUX.1、Qwen-Image和HunyuanVideo上的实验表明，该方法分别实现了4.12X、4.56X和3.59X的加速，并在生成质量上持续优于现有最佳缓存基线。


<details>
  <summary>Details</summary>
Motivation: 现有缓存方法依赖瞬时速度信息，导致高加速度场景下轨迹偏差大、误差累积严重，亟需更稳定的缓存机制以提升流匹配推理效率与生成质量。

Method: 提出基于平均速度的缓存框架MeanCache，通过缓存JVP构造区间平均速度，降低局部误差；设计轨迹稳定性调度策略，采用峰值抑制的最短路径算法优化缓存调度时机，提升JVP复用稳定性。

Result: 在FLUX.1、Qwen-Image和HunyuanVideo上分别实现4.12X、4.56X和3.59X的加速，且生成质量显著优于当前最优缓存方法。

Conclusion: MeanCache提供了一种新的流匹配推理加速视角，强调稳定性驱动的优化，为大规模生成模型的高效推理开辟了新路径，具有广泛的应用潜力。

Abstract: We present MeanCache, a training-free caching framework for efficient Flow Matching inference. Existing caching methods reduce redundant computation but typically rely on instantaneous velocity information (e.g., feature caching), which often leads to severe trajectory deviations and error accumulation under high acceleration ratios. MeanCache introduces an average-velocity perspective: by leveraging cached Jacobian--vector products (JVP) to construct interval average velocities from instantaneous velocities, it effectively mitigates local error accumulation. To further improve cache timing and JVP reuse stability, we develop a trajectory-stability scheduling strategy as a practical tool, employing a Peak-Suppressed Shortest Path under budget constraints to determine the schedule. Experiments on FLUX.1, Qwen-Image, and HunyuanVideo demonstrate that MeanCache achieves 4.12X and 4.56X and 3.59X acceleration, respectively, while consistently outperforming state-of-the-art caching baselines in generation quality. We believe this simple yet effective approach provides a new perspective for Flow Matching inference and will inspire further exploration of stability-driven acceleration in commercial-scale generative models.

</details>


### [111] [Cross-Session Decoding of Neural Spiking Data via Task-Conditioned Latent Alignment](https://arxiv.org/abs/2601.19963)
*Canyang Zhao,Bolin Peng,J. Patrick Mayo,Ce Ju,Bing Liu*

Main category: cs.LG

TL;DR: TCLA是一种用于跨会话神经解码的任务条件潜在对齐框架，通过在源会话中学习低维神经动态表示，并在目标会话中以任务条件方式对齐潜在表示，从而在数据有限的情况下实现有效的知识迁移。在猕猴运动和眼动中心向外数据集上的实验表明，TCLA显著优于仅在目标会话数据上训练的基线方法，最大可提升决定系数0.386。


<details>
  <summary>Details</summary>
Motivation: 跨会话非平稳性导致植入电极记录的神经活动在不同会话间变化大，使基于某一会话训练的解码器难以泛化到后续会话，尤其在新会话数据有限时，重新训练或适应解码器尤为困难。

Method: 提出一种基于自编码器架构的任务条件潜在对齐框架（TCLA）。首先在具有充足数据的源会话中学习神经动态的低维表示；然后在目标会话中，以任务条件方式将目标潜在表示对齐到源表示，实现神经动态的有效迁移。

Result: 在猕猴运动与眼动中心向外数据集上，TCLA在多种解码设置下均显著优于仅使用目标会话数据训练的基线方法，对y坐标速度解码的决定系数最高提升达0.386。

Conclusion: TCLA为从源会话向目标会话迁移知识提供了一种有效策略，能够在数据受限条件下实现更鲁棒的神经解码性能。

Abstract: Cross-session nonstationarity in neural activity recorded by implanted electrodes is a major challenge for invasive Brain-computer interfaces (BCIs), as decoders trained on data from one session often fail to generalize to subsequent sessions. This issue is further exacerbated in practice, as retraining or adapting decoders becomes particularly challenging when only limited data are available from a new session. To address this challenge, we propose a Task-Conditioned Latent Alignment framework (TCLA) for cross-session neural decoding. Building upon an autoencoder architecture, TCLA first learns a low-dimensional representation of neural dynamics from a source session with sufficient data. For target sessions with limited data, TCLA then aligns target latent representations to the source in a task-conditioned manner, enabling effective transfer of learned neural dynamics. We evaluate TCLA on the macaque motor and oculomotor center-out dataset. Compared to baseline methods trained solely on target-session data, TCLA consistently improves decoding performance across datasets and decoding settings, with gains in the coefficient of determination of up to 0.386 for y coordinate velocity decoding in a motor dataset. These results suggest that TCLA provides an effective strategy for transferring knowledge from source to target sessions, enabling more robust neural decoding under conditions with limited data.

</details>


### [112] [Modeling Cascaded Delay Feedback for Online Net Conversion Rate Prediction: Benchmark, Insights and Solutions](https://arxiv.org/abs/2601.19965)
*Mingxuan Luo,Guipeng Xv,Sishuo Chen,Xinyu Li,Li Zhang,Zhangming Chan,Xiang-Rong Sheng,Han Zhu,Jian Xu,Bo Zheng,Chen Lin*

Main category: cs.LG

TL;DR: 本文提出NetCVR（净转化率）以更准确衡量推荐系统效果，克服传统CVR忽略退款行为的缺陷。针对其多阶段延迟反馈的复杂性，作者构建了首个大规模开源数据集CASCADE，并提出TESLA框架，通过级联建模、分阶段去偏和延迟时间感知损失函数，在NetCVR预测上显著优于现有方法，提升12.41%（RI-AUC）和14.94%（RI-PRAUC）。


<details>
  <summary>Details</summary>
Motivation: 传统转化率（CVR）无法反映用户真实满意度和业务价值，因未考虑退款行为；而净转化率（NetCVR）虽更全面，但其预测面临点击到购买、购买到退款的双重延迟反馈问题，且缺乏公开数据集与在线持续训练机制，阻碍研究进展。

Method: 提出CASCADE数据集，基于该数据集发现三大关键洞察：NetCVR具有强时间动态性，需在线持续建模；级联建模CVR与退款率优于直接建模NetCVR；延迟时间是重要特征。据此设计TESLA框架，包含级联架构、阶段去偏机制及延迟时间感知排序损失。

Result: 在CASCADE数据集上，TESLA显著优于现有方法，实现12.41%的RI-AUC提升和14.94%的RI-PRAUC提升，验证了方法的有效性。代码与数据已开源。

Conclusion: NetCVR能更真实反映推荐系统效果，通过构建开放数据集CASCADE并提出TESLA框架，有效解决了多阶段延迟反馈建模难题，为工业级推荐系统的优化提供了新范式。

Abstract: In industrial recommender systems, conversion rate (CVR) is widely used for traffic allocation, but it fails to fully reflect recommendation effectiveness because it ignores refund behavior. To better capture true user satisfaction and business value, net conversion rate (NetCVR), defined as the probability that a clicked item is purchased and not refunded, has been proposed.Unlike CVR, NetCVR prediction involves a more complex multi-stage cascaded delayed feedback process. The two cascaded delays from click to conversion and from conversion to refund have opposite effects, making traditional CVR modeling methods inapplicable. Moreover, the lack of open-source datasets and online continuous training schemes further hinders progress in this area.To address these challenges, we introduce CASCADE (Cascaded Sequences of Conversion and Delayed Refund), the first large-scale open dataset derived from the Taobao app for online continuous NetCVR prediction. Through an in-depth analysis of CASCADE, we identify three key insights: (1) NetCVR exhibits strong temporal dynamics, necessitating online continuous modeling; (2) cascaded modeling of CVR and refund rate outperforms direct NetCVR modeling; and (3) delay time, which correlates with both CVR and refund rate, is an important feature for NetCVR prediction.Based on these insights, we propose TESLA, a continuous NetCVR modeling framework featuring a CVR-refund-rate cascaded architecture, stage-wise debiasing, and a delay-time-aware ranking loss. Extensive experiments demonstrate that TESLA consistently outperforms state-of-the-art methods on CASCADE, achieving absolute improvements of 12.41 percent in RI-AUC and 14.94 percent in RI-PRAUC on NetCVR prediction. The code and dataset are publicly available at https://github.com/alimama-tech/NetCVR.

</details>


### [113] [BayPrAnoMeta: Bayesian Proto-MAML for Few-Shot Industrial Image Anomaly Detection](https://arxiv.org/abs/2601.19992)
*Soham Sarkar,Tanmay Sen,Sayantan Banerjee*

Main category: cs.LG

TL;DR: 提出BayPrAnoMeta，一种基于贝叶斯的Proto-MAML改进方法，用于少样本工业图像异常检测。通过任务相关的概率正常性模型和贝叶斯后验预测似然进行内循环适应，利用NIW先验建模正常支持嵌入，生成学生-t分布预测，实现不确定性感知、重尾异常评分，在极端少样本场景下具有更强鲁棒性。进一步扩展至联邦元学习框架，并引入监督对比正则化以应对异构工业客户端，证明了非凸目标函数收敛至驻点。在MVTec AD基准上显著优于MAML、Proto-MAML和PatchCore方法。


<details>
  <summary>Details</summary>
Motivation: 工业图像异常检测面临极端类别不平衡和缺陷样本标注稀缺问题，尤其在少样本设置下更具挑战性。现有方法依赖确定性类原型和基于距离的适应，难以应对高不确定性与数据稀疏性。因此需要更鲁棒、具备不确定性感知能力的少样本异常检测方法。

Method: 提出BayPrAnoMeta，用任务特定的贝叶斯概率正常性模型替代传统确定性原型；采用Normal-Inverse-Wishart（NIW）先验对正常支持嵌入进行建模，获得学生-t分布的预测分布；通过贝叶斯后验预测似然实现内循环适应；扩展至联邦元学习框架，引入监督对比正则化以处理异构客户端。

Result: 在MVTec AD基准上，BayPrAnoMeta在多种少样本设置下均显著提升AUROC性能，优于MAML、Proto-MAML及PatchCore等主流方法；所提联邦框架在异构环境下保持稳定，且理论证明其收敛至非凸目标的驻点。

Conclusion: BayPrAnoMeta通过贝叶斯建模与不确定性感知机制，有效提升了少样本工业图像异常检测的鲁棒性与泛化能力，为极端少样本和异构环境下的实际应用提供了可靠解决方案。

Abstract: Industrial image anomaly detection is a challenging problem owing to extreme class imbalance and the scarcity of labeled defective samples, particularly in few-shot settings. We propose BayPrAnoMeta, a Bayesian generalization of Proto-MAML for few-shot industrial image anomaly detection. Unlike existing Proto-MAML approaches that rely on deterministic class prototypes and distance-based adaptation, BayPrAnoMeta replaces prototypes with task-specific probabilistic normality models and performs inner-loop adaptation via a Bayesian posterior predictive likelihood. We model normal support embeddings with a Normal-Inverse-Wishart (NIW) prior, producing a Student-$t$ predictive distribution that enables uncertainty-aware, heavy-tailed anomaly scoring and is essential for robustness in extreme few-shot settings. We further extend BayPrAnoMeta to a federated meta-learning framework with supervised contrastive regularization for heterogeneous industrial clients and prove convergence to stationary points of the resulting nonconvex objective. Experiments on the MVTec AD benchmark demonstrate consistent and significant AUROC improvements over MAML, Proto-MAML, and PatchCore-based methods in few-shot anomaly detection settings.

</details>


### [114] [Decomposing multimodal embedding spaces with group-sparse autoencoders](https://arxiv.org/abs/2601.20028)
*Chiraag Kaushik,Davis Barch,Andrea Fanelli*

Main category: cs.LG

TL;DR: 本文研究如何将稀疏自编码器（SAEs）有效应用于多模态嵌入空间，以解决现有方法中出现的“分裂字典”问题。提出一种基于跨模态随机掩码和分组稀疏正则化的新型SAE方法，提升了模态间对齐性，减少了死神经元数量，并增强了特征语义性。在CLIP和CLAP等多模态嵌入上验证了该方法的有效性，显著改善了跨模态任务的可解释性和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏自编码器（SAEs）在处理多模态嵌入时往往学习到‘分裂字典’，即大多数特征仅激活于单一模态，导致模态间对齐性差，限制了其在跨模态任务中的应用与可解释性。因此需要改进SAE以实现更好的多模态对齐。

Method: 提出一种基于跨模态随机掩码和分组稀疏正则化的新型SAE方法。通过跨模态掩码增强不同模态间的共享表示学习，利用分组稀疏正则化强制特征在多个模态间保持一致激活，从而获得更均衡、更具语义性的多模态特征字典。

Result: 在CLIP和CLAP嵌入空间上，所提方法相比标准SAEs学习到了更具有多模态一致性的字典，显著减少死神经元数量，提升特征语义性，并增强跨模态任务的可解释性与控制能力。

Conclusion: 本研究证明，在多模态嵌入空间中，通过引入跨模态随机掩码与分组稀疏正则化，可以有效克服传统SAE的分裂字典问题，实现更强的模态对齐，为多模态模型的可解释性分析提供了更优工具。

Abstract: The Linear Representation Hypothesis asserts that the embeddings learned by neural networks can be understood as linear combinations of features corresponding to high-level concepts. Based on this ansatz, sparse autoencoders (SAEs) have recently become a popular method for decomposing embeddings into a sparse combination of linear directions, which have been shown empirically to often correspond to human-interpretable semantics. However, recent attempts to apply SAEs to multimodal embedding spaces (such as the popular CLIP embeddings for image/text data) have found that SAEs often learn "split dictionaries", where most of the learned sparse features are essentially unimodal, active only for data of a single modality. In this work, we study how to effectively adapt SAEs for the setting of multimodal embeddings while ensuring multimodal alignment. We first argue that the existence of a split dictionary decomposition on an aligned embedding space implies the existence of a non-split dictionary with improved modality alignment. Then, we propose a new SAE-based approach to multimodal embedding decomposition using cross-modal random masking and group-sparse regularization. We apply our method to popular embeddings for image/text (CLIP) and audio/text (CLAP) data and show that, compared to standard SAEs, our approach learns a more multimodal dictionary while reducing the number of dead neurons and improving feature semanticity. We finally demonstrate how this improvement in alignment of concepts between modalities can enable improvements in the interpretability and control of cross-modal tasks.

</details>


### [115] [CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs](https://arxiv.org/abs/2601.20041)
*Shih-Hsuan Chiu,Ming-Syan Chen*

Main category: cs.LG

TL;DR: 提出TONEL框架，通过噪声感知投影模型学习任务特定嵌入，提升边缘设备上RAG在噪声环境下的鲁棒性和领域适应性，解决数据增长与计算效率瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署个性化虚拟助手时，由于用户数据快速增长导致RAG方法面临效率挑战；同时，尽管存内计算（CiM）架构可减少数据移动，但对环境噪声敏感，影响检索精度，尤其在多领域动态场景中难以兼顾准确性和适应性。

Method: 提出任务导向的噪声鲁棒嵌入学习框架TONEL，利用噪声感知投影模型生成符合CiM硬件约束的任务特定嵌入，实现高精度检索。

Result: 在个性化基准测试中，相较于强基线方法，TONEL在任务特定噪声场景下表现出更优的性能，验证了其有效性与实用性。

Conclusion: TONEL有效提升了RAG在噪声边缘环境中的检索精度和领域适应能力，为边缘侧个性化虚拟助手提供了高效、可靠的技术方案。

Abstract: Personalized virtual assistants powered by large language models (LLMs) on edge devices are attracting growing attention, with Retrieval-Augmented Generation (RAG) emerging as a key method for personalization by retrieving relevant profile data and generating tailored responses. However, deploying RAG on edge devices faces efficiency hurdles due to the rapid growth of profile data, such as user-LLM interactions and recent updates. While Computing-in-Memory (CiM) architectures mitigate this bottleneck by eliminating data movement between memory and processing units via in-situ operations, they are susceptible to environmental noise that can degrade retrieval precision. This poses a critical issue in dynamic, multi-domain edge-based scenarios (e.g., travel, medicine, and law) where both accuracy and adaptability are paramount. To address these challenges, we propose Task-Oriented Noise-resilient Embedding Learning (TONEL), a framework that improves noise robustness and domain adaptability for RAG in noisy edge environments. TONEL employs a noise-aware projection model to learn task-specific embeddings compatible with CiM hardware constraints, enabling accurate retrieval under noisy conditions. Extensive experiments conducted on personalization benchmarks demonstrate the effectiveness and practicality of our methods relative to strong baselines, especially in task-specific noisy scenarios.

</details>


### [116] [Regime-Adaptive Bayesian Optimization via Dirichlet Process Mixtures of Gaussian Processes](https://arxiv.org/abs/2601.20043)
*Yan Zhang,Xuefeng Liu,Sipeng Chen,Sascha Ranftl,Chong Liu,Shibo Li*

Main category: cs.LG

TL;DR: RAMBO 是一种基于狄利克雷过程混合高斯过程的贝叶斯优化方法，能够自动发现多区域问题中的潜在分段结构，每个区域由独立的高斯过程建模并优化超参数。通过解析边缘化潜函数的折叠吉布斯采样和自适应浓度参数调度，实现高效推理与粗粒度到细粒度的区域发现。其获取函数将不确定性分解为区域内部与区域之间的成分，在合成基准和真实世界应用（如分子构象优化、药物虚拟筛选、聚变反应堆设计）中显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 标准贝叶斯优化假设搜索空间内平滑性均匀，但在多区域问题（如分子能量盆地、药物分子骨架异质性）中该假设不成立。单一高斯过程会过度平滑尖锐变化或在平滑区域误判噪声，导致不确定性校准错误。

Method: 提出基于狄利克雷过程混合高斯过程的RAMBO模型，通过折叠吉布斯采样实现潜函数的解析边缘化，结合自适应浓度参数调度实现从粗到细的隐式区域发现；设计分解不确定性为区域内部与区域间成分的获取函数。

Result: 在合成基准和多个实际应用场景（分子构象优化、药物虚拟筛选、聚变反应堆设计）中，RAMBO 在多区域目标上持续优于当前最先进的方法。

Conclusion: RAMBO 有效解决了多区域问题中传统贝叶斯优化的平滑性假设局限，通过自动发现局部结构并精确建模，显著提升优化性能与不确定性校准能力。

Abstract: Standard Bayesian Optimization (BO) assumes uniform smoothness across the search space an assumption violated in multi-regime problems such as molecular conformation search through distinct energy basins or drug discovery across heterogeneous molecular scaffolds. A single GP either oversmooths sharp transitions or hallucinates noise in smooth regions, yielding miscalibrated uncertainty. We propose RAMBO, a Dirichlet Process Mixture of Gaussian Processes that automatically discovers latent regimes during optimization, each modeled by an independent GP with locally-optimized hyperparameters. We derive collapsed Gibbs sampling that analytically marginalizes latent functions for efficient inference, and introduce adaptive concentration parameter scheduling for coarse-to-fine regime discovery. Our acquisition functions decompose uncertainty into intra-regime and inter-regime components. Experiments on synthetic benchmarks and real-world applications, including molecular conformer optimization, virtual screening for drug discovery, and fusion reactor design, demonstrate consistent improvements over state-of-the-art baselines on multi-regime objectives.

</details>


### [117] [Externally Validated Longitudinal GRU Model for Visit-Level 180-Day Mortality Risk in Metastatic Castration-Resistant Prostate Cancer](https://arxiv.org/abs/2601.20046)
*Javier Mencia-Ledo,Mohammad Noaeen,Zahra Shakeri*

Main category: cs.LG

TL;DR: 本研究基于两个III期临床队列（n=526和n=640）的纵向数据，开发并外部验证了一个用于预测转移性去势抵抗性前列腺癌（mCRPC）患者180天内死亡风险的访视级模型。通过比较LSTM、GRU、Cox比例风险、随机生存森林（RSF）和逻辑回归五种模型架构，发现GRU和RSF初始表现优异（C指数均为87%）。在外部验证中，GRU模型表现出更优校准能力（斜率0.93，截距0.07），且PR-AUC达0.87。临床影响分析显示，真阳性患者的预警持续时间中位数为151.0天，假阳性为59.0天，每100次就诊产生18.3次预警。重要性分析表明，体重指数（BMI）和收缩压是与晚期虚弱或恶病质、血流动力学不稳最相关的指标。结果表明，利用纵向常规临床指标可有效预测mCRPC患者的短期死亡风险，支持多月窗口内的主动照护规划。


<details>
  <summary>Details</summary>
Motivation: mCRPC具有高度侵袭性和预后差的特点，治疗反应异质性强，亟需一种能够实时评估患者短期死亡风险的工具，以支持早期干预和个体化照护决策。现有模型多依赖静态特征或缺乏对纵向动态变化的捕捉，因此需要一个基于长期随访数据的高精度、可解释的死亡风险预测模型。

Method: 采用来自两个独立III期临床试验的纵向临床数据，仅纳入有明确180天结局的访视记录，排除右删失病例。比较了五种模型：LSTM、GRU、Cox比例风险、随机生存森林（RSF）和逻辑回归。针对每个数据集，选择最小风险阈值以确保85%的敏感度下限。通过外部验证评估模型性能，使用C指数、校准曲线、PR-AUC等指标，并进行临床影响分析与特征重要性（排列重要性）分析。

Result: GRU和RSF模型在初始阶段均展现出高区分能力（C指数87%）。在外部验证中，GRU模型具有更好的校准性能（斜率0.93，截距0.07）和较高的PR-AUC（0.87）。临床影响分析显示，真阳性患者平均处于预警状态151.0天，假阳性为59.0天，平均每100次就诊发出18.3次预警。排列重要性分析揭示BMI和收缩压是最重要的预测变量，提示其与晚期疾病状态密切相关。

Conclusion: 基于纵向常规临床指标的GRU模型能够准确预测mCRPC患者的180天短期死亡风险，具备良好的校准与判别能力，支持在多月时间窗内实施主动护理计划，有助于改善晚期患者管理策略。

Abstract: Metastatic castration-resistant prostate cancer (mCRPC) is a highly aggressive disease with poor prognosis and heterogeneous treatment response. In this work, we developed and externally validated a visit-level 180-day mortality risk model using longitudinal data from two Phase III cohorts (n=526 and n=640). Only visits with observable 180-day outcomes were labeled; right-censored cases were excluded from analysis. We compared five candidate architectures: Long Short-Term Memory, Gated Recurrent Unit (GRU), Cox Proportional Hazards, Random Survival Forest (RSF), and Logistic Regression. For each dataset, we selected the smallest risk-threshold that achieved an 85% sensitivity floor. The GRU and RSF models showed high discrimination capabilities initially (C-index: 87% for both). In external validation, the GRU obtained a higher calibration (slope: 0.93; intercept: 0.07) and achieved an PR-AUC of 0.87. Clinical impact analysis showed a median time-in-warning of 151.0 days for true positives (59.0 days for false positives) and 18.3 alerts per 100 patient-visits. Given late-stage frailty or cachexia and hemodynamic instability, permutation importance ranked BMI and systolic blood pressure as the strongest associations. These results suggest that longitudinal routine clinical markers can estimate short-horizon mortality risk in mCRPC and support proactive care planning over a multi-month window.

</details>


### [118] [Domain Expansion: A Latent Space Construction Framework for Multi-Task Learning](https://arxiv.org/abs/2601.20069)
*Chi-Yao Huang,Khoa Vo,Aayush Atul Verma,Duo Lu,Yezhou Yang*

Main category: cs.LG

TL;DR: 提出Domain Expansion框架，通过正交池化机制重构潜在空间，使每个目标分配到相互正交的子空间，有效防止多任务训练中的梯度冲突和潜在表示崩溃问题。在ShapeNet、MPIIGaze和旋转MNIST等基准上验证了该方法的有效性，实现了可解释且可组合的潜在表示。


<details>
  <summary>Details</summary>
Motivation: 多目标训练中梯度冲突导致共享表示退化，形成对任何单一任务都次优的妥协状态，即潜在表示崩溃问题。

Method: 引入正交池化机制，重构潜在空间，使每个目标位于相互正交的子空间中，从而避免任务间冲突。

Result: 实验表明该方法能有效防止潜在表示崩溃，并生成显式、可解释、可组合的潜在空间，支持概念直接操控。

Conclusion: Domain Expansion框架通过结构化潜在空间成功缓解多任务学习中的表示冲突，提升模型性能与可解释性。

Abstract: Training a single network with multiple objectives often leads to conflicting gradients that degrade shared representations, forcing them into a compromised state that is suboptimal for any single task--a problem we term latent representation collapse. We introduce Domain Expansion, a framework that prevents these conflicts by restructuring the latent space itself. Our framework uses a novel orthogonal pooling mechanism to construct a latent space where each objective is assigned to a mutually orthogonal subspace. We validate our approach across diverse benchmarks--including ShapeNet, MPIIGaze, and Rotated MNIST--on challenging multi-objective problems combining classification with pose and gaze estimation. Our experiments demonstrate that this structure not only prevents collapse but also yields an explicit, interpretable, and compositional latent space where concepts can be directly manipulated.

</details>


### [119] [Quantization-Aware Distillation for NVFP4 Inference Accuracy Recovery](https://arxiv.org/abs/2601.20088)
*Meng Xin,Sweta Priyadarshi,Jingyu Xin,Bilal Kartal,Aditya Vavre,Asma Kuriparambil Thekkumpate,Zijia Chen,Ameya Sunil Mahabaleshwarkar,Ido Shahaf,Akhiad Bercovich,Kinjal Patel,Suguna Varshini Velury,Chenjie Luo,Zhiyu Cheng,Jenny Chen,Chen-Han Yu,Wei Ping,Oleg Rybakov,Nima Tajbakhsh,Oluwatobi Olabiyi,Dusan Stosic,Di Wu,Song Han,Eric Chung,Sharath Turuvekere Sreenivas,Bryan Catanzaro,Yoshi Suhara,Tijmen Blankevoort,Huizi Mao*

Main category: cs.LG

TL;DR: QAD通过使用KL散度损失将全精度教师模型蒸馏到量化学生模型，有效恢复了NVFP4量化大型语言模型和视觉语言模型的精度，尤其在多阶段后训练流程中表现稳定且鲁棒，无需完整训练数据即可实现近BF16精度的恢复。


<details>
  <summary>Details</summary>
Motivation: 传统量化感知训练（QAT）在多阶段后训练流程中存在工程复杂性和训练不稳定性问题，且对数据质量和覆盖范围敏感；需要一种更高效、稳定的方案来恢复量化模型的精度。

Method: 提出量化感知蒸馏（QAD），利用KL散度损失将全精度教师模型蒸馏至量化学生模型，适用于多阶段后训练的复杂场景，并增强对数据质量的鲁棒性。

Result: 在多个后训练模型（如AceReason Nemotron、Nemotron系列及Llama Nemotron Super v1）上验证，QAD能一致地将量化模型精度恢复至接近BF16水平。

Conclusion: QAD是一种高效、稳定且鲁棒的方案，可有效恢复NVFP4量化大模型的精度，尤其适用于复杂后训练流程，是当前大模型量化部署的重要实践方法。

Abstract: This technical report presents quantization-aware distillation (QAD) and our best practices for recovering accuracy of NVFP4-quantized large language models (LLMs) and vision-language models (VLMs). QAD distills a full-precision teacher model into a quantized student model using a KL divergence loss. While applying distillation to quantized models is not a new idea, we observe key advantages of QAD for today's LLMs: 1. It shows remarkable effectiveness and stability for models trained through multi-stage post-training pipelines, including supervised fine-tuning (SFT), reinforcement learning (RL), and model merging, where traditional quantization-aware training (QAT) suffers from engineering complexity and training instability; 2. It is robust to data quality and coverage, enabling accuracy recovery without full training data. We evaluate QAD across multiple post-trained models including AceReason Nemotron, Nemotron 3 Nano, Nemotron Nano V2, Nemotron Nano V2 VL (VLM), and Llama Nemotron Super v1, showing consistent recovery to near-BF16 accuracy.

</details>


### [120] [In-Context Reinforcement Learning From Suboptimal Historical Data](https://arxiv.org/abs/2601.20116)
*Juncheng Dong,Moyang Guo,Ethan X. Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本文提出Decision Importance Transformer (DIT)框架，用于在包含次优行为策略数据的离线数据集上实现基于上下文的强化学习（ICRL）。通过训练一个基于Transformer的价值函数来估计行为策略的优势函数，并利用该价值函数构建权重，通过加权最大似然估计训练策略模型，引导学习到最优策略。实验表明，DIT在带域和马尔可夫决策过程问题中表现优异，尤其在处理次优历史数据时具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer在上下文学习中的成功启发了作者探索其在强化学习中的应用。然而，在使用次优行为策略收集的离线数据上进行标准自回归训练会导致模仿学习并产生次优性能。因此，需要一种新方法来克服这一局限，提升在复杂、不完美数据环境下的学习效果。

Method: 首先训练一个基于Transformer的价值函数，用于估计收集次优轨迹的行为策略的优势函数；然后通过加权最大似然估计训练策略模型，其中权重由价值函数生成，以引导策略从次优向最优转移。整个过程在上下文中完成，无需额外的在线交互。

Result: 在多种带域和马尔可夫决策过程任务上的实验结果表明，DIT在包含次优数据的离线数据集上表现优于传统方法，尤其在数据质量较差的情况下展现出更强的鲁棒性和优越性。

Conclusion: DIT框架成功实现了在次优数据下的高效策略学习，验证了将演员-评论家机制融入上下文学习的可行性与有效性，为未来基于Transformer的强化学习提供了新思路。

Abstract: Transformer models have achieved remarkable empirical successes, largely due to their in-context learning capabilities. Inspired by this, we explore training an autoregressive transformer for in-context reinforcement learning (ICRL). In this setting, we initially train a transformer on an offline dataset consisting of trajectories collected from various RL tasks, and then fix and use this transformer to create an action policy for new RL tasks. Notably, we consider the setting where the offline dataset contains trajectories sampled from suboptimal behavioral policies. In this case, standard autoregressive training corresponds to imitation learning and results in suboptimal performance. To address this, we propose the Decision Importance Transformer(DIT) framework, which emulates the actor-critic algorithm in an in-context manner. In particular, we first train a transformer-based value function that estimates the advantage functions of the behavior policies that collected the suboptimal trajectories. Then we train a transformer-based policy via a weighted maximum likelihood estimation loss, where the weights are constructed based on the trained value function to steer the suboptimal policies to the optimal ones. We conduct extensive experiments to test the performance of DIT on both bandit and Markov Decision Process problems. Our results show that DIT achieves superior performance, particularly when the offline dataset contains suboptimal historical data.

</details>


### [121] [A Reinforcement Learning Based Universal Sequence Design for Polar Codes](https://arxiv.org/abs/2601.20118)
*David Kin Wai Ho,Arman Fazeli,Mohamad M. Mansour,Louay M. A. Jalloul*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习的通用序列设计框架，用于6G中的极化码设计，可扩展至长度达2048，适用于标准化。在5G支持的所有(N,K)配置下，该方法性能优于5G NR序列，并在N=2048时比beta-expansion基线提升0.2 dB。关键成功因素包括：(i) 基于极化码普遍偏序性质的物理规律约束学习；(ii) 利用决策的弱长期影响以减少前瞻评估；(iii) 联合多配置优化以提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 为推进6G应用中的极化码设计，需要一种可扩展、适应多种信道条件和解码策略的通用序列设计方法，尤其需满足大规模码长（如2048）的需求，以支持未来标准制定。

Method: 提出一种基于强化学习的通用序列设计框架，结合物理规律约束（利用极化码的普遍偏序性质）、减少前瞻评估（利用决策的弱长期影响）以及联合多配置优化，实现大规模高效学习。

Result: 在所有5G支持的(N,K)配置下，所提方法性能接近甚至超越5G NR序列；在N=2048时，相比beta-expansion基线获得最高0.2 dB增益。

Conclusion: 该强化学习框架实现了极化码序列设计在大规模码长下的高效与通用性，具备向6G标准演进的潜力，其成功依赖于物理规律约束、决策影响建模与多配置联合优化。

Abstract: To advance Polar code design for 6G applications, we develop a reinforcement learning-based universal sequence design framework that is extensible and adaptable to diverse channel conditions and decoding strategies. Crucially, our method scales to code lengths up to $2048$, making it suitable for use in standardization. Across all $(N,K)$ configurations supported in 5G, our approach achieves competitive performance relative to the NR sequence adopted in 5G and yields up to a 0.2 dB gain over the beta-expansion baseline at $N=2048$. We further highlight the key elements that enabled learning at scale: (i) incorporation of physical law constrained learning grounded in the universal partial order property of Polar codes, (ii) exploitation of the weak long term influence of decisions to limit lookahead evaluation, and (iii) joint multi-configuration optimization to increase learning efficiency.

</details>


### [122] [Going NUTS with ADVI: Exploring various Bayesian Inference techniques with Facebook Prophet](https://arxiv.org/abs/2601.20120)
*Jovan Krajevski,Biljana Tojtovska Ribarski*

Main category: cs.LG

TL;DR: 本文对Facebook Prophet模型进行了基于PyMC的重新实现，旨在克服原模型在贝叶斯推断方法上的局限性及API灵活性不足的问题。通过新框架，作者能够扩展基础模型，并对比多种贝叶斯推断方法（如全量MCMC、MAP估计和变分推断）在时间序列预测中的表现。研究详细分析了采样策略、收敛诊断、预测指标、计算效率，并指出了未来需解决的问题。


<details>
  <summary>Details</summary>
Motivation: 原版Facebook Prophet仅支持有限的贝叶斯推断方法（L-BFGS-B和NUTS），且其API设计缺乏灵活性，难以支持自定义建模需求，限制了研究者对不同推断技术的探索与比较。

Method: 基于PyMC重新实现Prophet模型，支持灵活的模型扩展，并系统评估全量MCMC、MAP估计和变分推断等多种贝叶斯推断方法在时间序列预测任务中的应用。

Result: 新实现的模型成功支持多种推断方法的比较，揭示了不同方法在采样效率、收敛性、预测准确性和计算开销方面的差异，为后续优化提供了依据。

Conclusion: 通过基于PyMC的重实现，显著提升了Prophet模型在贝叶斯推断方面的灵活性与可扩展性，为未来研究多方法融合与高效推断提供了坚实基础。

Abstract: Since its introduction, Facebook Prophet has attracted positive attention from both classical statisticians and the Bayesian statistics community. The model provides two built-in inference methods: maximum a posteriori estimation using the L-BFGS-B algorithm, and Markov Chain Monte Carlo (MCMC) sampling via the No-U-Turn Sampler (NUTS). While exploring various time-series forecasting problems using Bayesian inference with Prophet, we encountered limitations stemming from the inability to apply alternative inference techniques beyond those provided by default. Additionally, the fluent API design of Facebook Prophet proved insufficiently flexible for implementing our custom modeling ideas. To address these shortcomings, we developed a complete reimplementation of the Prophet model in PyMC, which enables us to extend the base model and evaluate and compare multiple Bayesian inference methods. In this paper, we present our PyMC-based implementation and analyze in detail the implementation of different Bayesian inference techniques. We consider full MCMC techniques, MAP estimation and Variational inference techniques on a time-series forecasting problem. We discuss in details the sampling approach, convergence diagnostics, forecasting metrics as well as their computational efficiency and detect possible issues which will be addressed in our future work.

</details>


### [123] [Membership Inference Attacks Against Fine-tuned Diffusion Language Models](https://arxiv.org/abs/2601.20125)
*Yuetian Chen,Kaiyuan Zhang,Yuntao Du,Edoardo Stoppa,Charles Fleming,Ashish Kundu,Bruno Ribeiro,Ninghui Li*

Main category: cs.LG

TL;DR: 本文首次系统性地研究了扩散语言模型（DLMs）在成员推断攻击（MIA）下的隐私漏洞。由于DLMs具有多种可变掩码配置，攻击者可通过探测多个独立掩码大幅增加攻击机会。为此，作者提出SAMA方法，通过子集聚合与基于符号的统计分析，在噪声环境下有效检测稀疏记忆信号。实验表明，SAMA在九个数据集上相比最佳基线提升了30%的相对AUC，低误报率下甚至提升8倍，揭示了DLMs存在显著且未被认知的隐私风险，亟需针对性的隐私防护机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了扩散语言模型（DLMs）在成员推断攻击（MIA）下的隐私泄露风险。由于DLMs支持多样的掩码配置，相比自回归模型具有更高的攻击暴露面，但其具体威胁尚未被系统评估，因此亟需开展针对性研究以识别并应对潜在隐私漏洞。

Method: 提出SAMA（Subset-Aggregated Membership Attack）方法，通过在不同掩码密度下采样多个掩码子集，利用符号统计特征应对重尾噪声问题，并采用反向加权聚合策略，优先利用稀疏掩码中更清晰的信号，实现对模型记忆内容的鲁棒检测。

Result: 在九个数据集上的实验显示，SAMA相比最优基线平均提升30%的相对AUC，尤其在低误报率场景下最高可达8倍提升，充分验证了其在检测稀疏记忆信号方面的有效性。

Conclusion: 本研究揭示了扩散语言模型在成员推断攻击下存在严重且此前未被认识的隐私漏洞，其多掩码结构为攻击提供了更多路径。SAMA的成功表明，当前DLMs缺乏足够的隐私保护，必须发展专门的防御机制以保障用户数据安全。

Abstract: Diffusion Language Models (DLMs) represent a promising alternative to autoregressive language models, using bidirectional masked token prediction. Yet their susceptibility to privacy leakage via Membership Inference Attacks (MIA) remains critically underexplored. This paper presents the first systematic investigation of MIA vulnerabilities in DLMs. Unlike the autoregressive models' single fixed prediction pattern, DLMs' multiple maskable configurations exponentially increase attack opportunities. This ability to probe many independent masks dramatically improves detection chances. To exploit this, we introduce SAMA (Subset-Aggregated Membership Attack), which addresses the sparse signal challenge through robust aggregation. SAMA samples masked subsets across progressive densities and applies sign-based statistics that remain effective despite heavy-tailed noise. Through inverse-weighted aggregation prioritizing sparse masks' cleaner signals, SAMA transforms sparse memorization detection into a robust voting mechanism. Experiments on nine datasets show SAMA achieves 30% relative AUC improvement over the best baseline, with up to 8 times improvement at low false positive rates. These findings reveal significant, previously unknown vulnerabilities in DLMs, necessitating the development of tailored privacy defenses.

</details>


### [124] [Spectral Ghost in Representation Learning: from Component Analysis to Self-Supervised Learning](https://arxiv.org/abs/2601.20154)
*Bo Dai,Na Li,Dale Schuurmans*

Main category: cs.LG

TL;DR: 本文旨在为表示学习建立一个原则性基础，通过从谱表示视角理论研究表示的充分性，揭示现有成功自监督学习（SSL）算法的谱本质，并构建统一框架以理解和分析表示学习方法。该框架不仅有助于解释现有方法，还启发了更高效、易用的算法设计，推动实际应用中的发展。


<details>
  <summary>Details</summary>
Motivation: 当前自监督学习方法种类繁多，但缺乏统一的理论理解，导致算法设计缺乏指导，实际应用缺乏依据。随着方法快速增多，亟需一个统一框架来推动表示学习的发展。

Method: 从谱表示视角出发，理论分析表示的充分性，揭示现有成功SSL算法的共同谱特性，进而构建统一的理论框架。

Result: 建立了能够统一理解与分析多种自监督学习方法的理论框架，为设计更高效、实用的表示学习算法提供了原则性指导。

Conclusion: 本文提出的统一框架为表示学习提供了坚实的理论基础，解决了方法多样性带来的理解碎片化问题，推动了算法设计的系统化和实际应用的合理性。

Abstract: Self-supervised learning (SSL) have improved empirical performance by unleashing the power of unlabeled data for practical applications. Specifically, SSL extracts the representation from massive unlabeled data, which will be transferred to a plenty of down streaming tasks with limited data. The significant improvement on diverse applications of representation learning has attracted increasing attention, resulting in a variety of dramatically different self-supervised learning objectives for representation extraction, with an assortment of learning procedures, but the lack of a clear and unified understanding. Such an absence hampers the ongoing development of representation learning, leaving a theoretical understanding missing, principles for efficient algorithm design unclear, and the use of representation learning methods in practice unjustified. The urgency for a unified framework is further motivated by the rapid growth in representation learning methods. In this paper, we are therefore compelled to develop a principled foundation of representation learning. We first theoretically investigate the sufficiency of the representation from a spectral representation view, which reveals the spectral essence of the existing successful SSL algorithms and paves the path to a unified framework for understanding and analysis. Such a framework work also inspires the development of more efficient and easy-to-use representation learning algorithms with principled way in real-world applications.

</details>


### [125] [PASS: Ambiguity Guided Subsets for Scalable Classical and Quantum Constrained Clustering](https://arxiv.org/abs/2601.20157)
*Pedro Chumpitaz-Flores,My Duong,Ying Mao,Kaixun Hua*

Main category: cs.LG

TL;DR: PASS是一种基于成对约束和模糊性驱动的子集选择框架，通过将必须链接（ML）约束压缩为伪点，并采用两种选择策略（约束感知边界规则和信息几何规则），在保持约束满足的同时实现高效、可扩展的聚类。该方法在多个基准测试中以更低的成本达到与精确或惩罚方法相当的聚类质量，尤其在传统方法失效的场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有成对约束聚类方法在数据可扩展性方面存在挑战，尤其是在量子或量子混合聚类等小众应用中表现不佳，亟需一种既能保持约束满足又能高效处理大规模数据的解决方案。

Method: PASS将必须链接（ML）约束转化为伪点，提出两种子集选择策略：一是基于约束感知边界的边缘点与所有检测到的不能链接（CL）违反点的选择规则；二是基于软分配后验的Fisher-Rao距离的信息几何评分规则，结合预算限制选取高信息量子集。

Result: PASS在多个基准测试中实现了与精确或惩罚方法相当的平方误差（SSE），但计算成本显著降低；在传统方法失败的场景中仍表现出良好性能，展现出卓越的可扩展性和鲁棒性。

Conclusion: PASS框架有效解决了成对约束聚类中的可扩展性难题，在保持约束满足的前提下实现了高效、高质量的聚类，适用于包括量子聚类在内的复杂应用场景。

Abstract: Pairwise-constrained clustering augments unsupervised partitioning with side information by enforcing must-link (ML) and cannot-link (CL) constraints between specific samples, yielding labelings that respect known affinities and separations. However, ML and CL constraints add an extra layer of complexity to the clustering problem, with current methods struggling in data scalability, especially in niche applications like quantum or quantum-hybrid clustering. We propose PASS, a pairwise-constraints and ambiguity-driven subset selection framework that preserves ML and CL constraints satisfaction while allowing scalable, high-quality clustering solution. PASS collapses ML constraints into pseudo-points and offers two selectors: a constraint-aware margin rule that collects near-boundary points and all detected CL violations, and an information-geometric rule that scores points via a Fisher-Rao distance derived from soft assignment posteriors, then selects the highest-information subset under a simple budget. Across diverse benchmarks, PASS attains competitive SSE at substantially lower cost than exact or penalty-based methods, and remains effective in regimes where prior approaches fail.

</details>


### [126] [What's the plan? Metrics for implicit planning in LLMs and their application to rhyme generation and question answering](https://arxiv.org/abs/2601.20164)
*Jim Maar,Denis Paperno,Callum Stuart McDougall,Neel Nanda*

Main category: cs.LG

TL;DR: 本文提出了一种更简单的评估语言模型隐式规划能力的方法，通过在韵律诗生成和问答任务中的案例研究，证明该方法可广泛应用于多种模型。研究发现，即使在10亿参数的小型模型中也存在隐式规划现象，且可通过向量操控中间生成的词元来影响最终的韵脚或答案。该方法为研究大模型的规划能力提供了直接途径，并对人工智能安全与控制具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明语言模型虽以预测下一个词元为目标训练，却表现出隐式规划行为，如为可能的押韵词做准备。但现有研究依赖复杂方法，难以推广。本文旨在提出更简单、普适的方法，以系统评估此类行为。

Method: 通过在前一行末尾施加向量扰动，观察是否影响后续中间词元的生成，从而检测隐式规划。该方法在韵律诗生成和问答任务中进行了验证，并扩展至多个不同规模的语言模型。

Result: 研究发现，无论是大型还是小型模型（低至10亿参数），均表现出隐式规划特征；通过末端向量操纵，可有效引导中间词元生成，实现对最终韵脚或答案的控制。该方法具备良好的可扩展性和通用性。

Conclusion: 隐式规划是语言模型中普遍存在的一种机制，不仅存在于大型模型中，也存在于较小模型中。本文提出的评估方法简单有效，适用于大规模模型分析，有助于深入理解模型的内部规划能力，进而支持人工智能安全与控制策略的设计。

Abstract: Prior work suggests that language models, while trained on next token prediction, show implicit planning behavior: they may select the next token in preparation to a predicted future token, such as a likely rhyming word, as supported by a prior qualitative study of Claude 3.5 Haiku using a cross-layer transcoder. We propose much simpler techniques for assessing implicit planning in language models. With case studies on rhyme poetry generation and question answering, we demonstrate that our methodology easily scales to many models. Across models, we find that the generated rhyme (e.g. "-ight") or answer to a question ("whale") can be manipulated by steering at the end of the preceding line with a vector, affecting the generation of intermediate tokens leading up to the rhyme or answer word. We show that implicit planning is a universal mechanism, present in smaller models than previously thought, starting from 1B parameters. Our methodology offers a widely applicable direct way to study implicit planning abilities of LLMs. More broadly, understanding planning abilities of language models can inform decisions in AI safety and control.

</details>


### [127] [Local Duality for Sparse Support Vector Machines](https://arxiv.org/abs/2601.20170)
*Penghe Zhang,Naihua Xiu,Houduo Qi*

Main category: cs.LG

TL;DR: 本文针对稀疏支持向量机（SSVM）在优化中因基数最小化而受到关注的问题，提出了一种局部对偶理论，填补了现有方法在理论上的空白。通过将$\ell_0$-范数引入凸SVM的对偶问题来构造SSVM，该研究证明了这种形式的SSVM正是0/1损失SVM的对偶问题，并且其局部解满足线性表示定理。研究还揭示了SSVM与铰链损失SVM（hSVM）和梯形损失SVM（rSVM）之间的关系：在特定条件下，hSVM的全局解序列收敛于0/1损失SVM的局部解，且0/1损失SVM的局部极小点也是rSVM的局部极小点。这解释了为何先前实证研究中基于SSVM的局部解表现优于hSVM和rSVM。最后，作者在真实数据集上进行了数值实验，验证了所提局部优良解在实际应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前稀疏支持向量机（SSVM）虽在经验上优于传统凸SVM，但其构建方式（如在对偶问题中加入$\ell_0$-norm）缺乏理论依据，亟需建立坚实的理论基础以解释其性能优势。

Method: 提出局部对偶理论，分析SSVM与0/1损失SVM、hSVM和rSVM之间的对偶关系；利用数学推导证明局部解的性质，包括线性表示定理和收敛性；并通过数值实验验证方法的有效性。

Result: 证明了所提出的SSVM是0/1损失SVM的对偶问题，其局部解具有良好的结构性质；揭示了不同损失函数之间解的收敛性和包含关系；实验证明了基于局部优良解的SSVM在真实数据上的潜在优势。

Conclusion: 本研究建立了SSVM的理论基础，阐明了其与各类SVM之间的深层联系，为理解稀疏模型的优越性能提供了理论支持，并展示了其在实际应用中的可行性与潜力。

Abstract: Due to the rise of cardinality minimization in optimization, sparse support vector machines (SSVMs) have attracted much attention lately and show certain empirical advantages over convex SVMs. A common way to derive an SSVM is to add a cardinality function such as $\ell_0$-norm to the dual problem of a convex SVM. However, this process lacks theoretical justification. This paper fills the gap by developing a local duality theory for such an SSVM formulation and exploring its relationship with the hinge-loss SVM (hSVM) and the ramp-loss SVM (rSVM). In particular, we prove that the derived SSVM is exactly the dual problem of the 0/1-loss SVM, and the linear representer theorem holds for their local solutions. The local solution of SSVM also provides guidelines on selecting hyperparameters of hSVM and rSVM. {Under specific conditions, we show that a sequence of global solutions of hSVM converges to a local solution of 0/1-loss SVM. Moreover, a local minimizer of 0/1-loss SVM is a local minimizer of rSVM.} This explains why a local solution induced by SSVM outperforms hSVM and rSVM in the prior empirical study. We further conduct numerical tests on real datasets and demonstrate potential advantages of SSVM by working with locally nice solutions proposed in this paper.

</details>


### [128] [MAPLE: Self-supervised Learning-Enhanced Nonlinear Dimensionality Reduction for Visual Analysis](https://arxiv.org/abs/2601.20173)
*Zeyang Huang,Takanori Fujiwara,Angelos Chatzimparmpas,Wandrille Duchemin,Andreas Kerren*

Main category: cs.LG

TL;DR: MAPLE is a new nonlinear dimensionality reduction method that improves UMAP by enhancing manifold modeling through self-supervised learning. It uses Maximum Manifold Capacity Representations (MMCRs) to compress variance among similar points and increase variance among dissimilar ones, leading to better cluster separation and subcluster resolution, especially for complex data like biological or image data, with similar computational cost to UMAP.


<details>
  <summary>Details</summary>
Motivation: To improve the ability of UMAP to model complex, curved manifolds with high intra-cluster variance, particularly in challenging datasets such as biological or image data, where standard methods struggle with fine-grained structure preservation.

Method: MAPLE introduces a self-supervised learning framework based on Maximum Manifold Capacity Representations (MMCRs), which enhances local geometric encoding by minimizing variance within similar neighborhoods while maximizing variance across dissimilar ones, thus improving manifold fidelity in low-dimensional embeddings.

Result: MAPLE achieves superior visual cluster separation and finer subcluster resolution compared to UMAP, while maintaining comparable computational efficiency, demonstrating strong performance on high-dimensional, complex datasets.

Conclusion: MAPLE significantly advances nonlinear dimensionality reduction by enabling more accurate modeling of complex manifolds, making it highly effective for applications involving biological and image data where fine structural details are critical.

Abstract: We present a new nonlinear dimensionality reduction method, MAPLE, that enhances UMAP by improving manifold modeling. MAPLE employs a self-supervised learning approach to more efficiently encode low-dimensional manifold geometry. Central to this approach are maximum manifold capacity representations (MMCRs), which help untangle complex manifolds by compressing variances among locally similar data points while amplifying variance among dissimilar data points. This design is particularly effective for high-dimensional data with substantial intra-cluster variance and curved manifold structures, such as biological or image data. Our qualitative and quantitative evaluations demonstrate that MAPLE can produce clearer visual cluster separations and finer subcluster resolution than UMAP while maintaining comparable computational cost.

</details>


### [129] [Causal-Driven Feature Evaluation for Cross-Domain Image Classification](https://arxiv.org/abs/2601.20176)
*Chen Cheng,Ang Li*

Main category: cs.LG

TL;DR: 本文从因果视角重新审视了分布外（OOD）分类问题，提出基于必要性和充分性评估学习表征的因果有效性，引入显式的分段级框架以直接测量跨域的因果效果，超越传统不变性假设。在多域基准测试中，该方法在极端分布偏移下显著提升OOD性能，验证了因果评估对鲁棒泛化的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有OOD方法依赖领域不变表征，但不变特征未必是预测的因果有效特征；因此需要更可靠的评估标准来提升真实场景下的泛化能力。

Method: 提出一种基于因果必要性与充分性的分段级评估框架，直接衡量表征在不同分布下的因果有效性，避免对不变性的隐式依赖。

Result: 在多个多域基准上实现了稳定的OOD性能提升，尤其在剧烈分布偏移情况下表现突出，证明因果评估能有效促进模型鲁棒性。

Conclusion: 因果有效性是评价表征质量的更可靠标准，通过显式建模必要性与充分性可显著增强模型在分布外情况下的泛化能力。

Abstract: Out-of-distribution (OOD) generalization remains a fundamental challenge in real-world classification, where test distributions often differ substantially from training data. Most existing approaches pursue domain-invariant representations, implicitly assuming that invariance implies reliability. However, features that are invariant across domains are not necessarily causally effective for prediction.
  In this work, we revisit OOD classification from a causal perspective and propose to evaluate learned representations based on their necessity and sufficiency under distribution shift. We introduce an explicit segment-level framework that directly measures causal effectiveness across domains, providing a more faithful criterion than invariance alone.
  Experiments on multi-domain benchmarks demonstrate consistent improvements in OOD performance, particularly under challenging domain shifts, highlighting the value of causal evaluation for robust generalization.

</details>


### [130] [On the Computational Complexity of Performative Prediction](https://arxiv.org/abs/2601.20180)
*Ioannis Anagnostides,Rohan Chauhan,Ioannis Panageas,Tuomas Sandholm,Jingming Yan*

Main category: cs.LG

TL;DR: 该论文研究了预测模型部署后导致数据分布变化的性能预测现象。当性能效应较弱（ρ < 1）时，简单重训练动态可线性收敛；但当ρ > 1时，其复杂性此前未知。本文证明了一个尖锐的相变：即使ρ = 1 + O(ε)，计算一个ε-性能稳定点也是PPAD完全的，即与一般和博弈中的纳什均衡在多项式时间内等价。这一难题在二次损失函数和线性分布偏移的看似简单设定下依然存在。关键技术贡献是将此PPAD难解性结果推广到更一般的凸域，对变分不等式的复杂性具有广泛意义。此外，针对战略分类的特殊情况，证明计算战略局部最优是PLS-hard。


<details>
  <summary>Details</summary>
Motivation: 理解性能预测中模型部署对数据分布的影响，尤其是在强性能效应（ρ > 1）下的计算复杂性，填补了现有理论空白，并揭示了相关优化问题的内在困难。

Method: 通过构造复杂性理论框架，结合博弈论与变分不等式工具，建立性能预测问题与纳什均衡之间的多项式时间等价关系；并扩展至一般凸域；针对战略分类情形采用局部搜索复杂性分析方法。

Result: 证明了在ρ = 1 + O(ε)时，计算ε-性能稳定点为PPAD完全；即使在二次损失和线性分布偏移条件下仍不可行；同时，战略分类中的局部最优计算为PLS-hard。

Conclusion: 性能预测问题在强性能效应下具有高度计算复杂性，其求解等价于求解纳什均衡或解决复杂变分不等式，表明此类问题在实际应用中面临根本性挑战，需发展新算法或近似方法。

Abstract: Performative prediction captures the phenomenon where deploying a predictive model shifts the underlying data distribution. While simple retraining dynamics are known to converge linearly when the performative effects are weak ($ρ< 1$), the complexity in the regime $ρ> 1$ was hitherto open. In this paper, we establish a sharp phase transition: computing an $ε$-performatively stable point is PPAD-complete -- and thus polynomial-time equivalent to Nash equilibria in general-sum games -- even when $ρ= 1 + O(ε)$. This intractability persists even in the ostensibly simple setting with a quadratic loss function and linear distribution shifts. One of our key technical contributions is to extend this PPAD-hardness result to general convex domains, which is of broader interest in the complexity of variational inequalities. Finally, we address the special case of strategic classification, showing that computing a strategic local optimum is PLS-hard.

</details>


### [131] [Meta-Cognitive Reinforcement Learning with Self-Doubt and Recovery](https://arxiv.org/abs/2601.20193)
*Zhipeng Zhang,Wenting Ma,Kai Li,Meng Guo,Lei Yang,Wei Yu,Hongji Cui,Yichen Zhang,Mo Zhang,Jinzhe Lin,Zhenjie Yao*

Main category: cs.LG

TL;DR: 本文提出了一种元认知强化学习框架，使智能体能够基于内部估计的可靠性信号评估、调节和恢复其学习行为。该方法引入由价值预测误差稳定性（VPES）驱动的元信任变量，通过安全失效机制和渐进式信任恢复来调节学习动态。在存在奖励污染的连续控制基准测试中，具备恢复能力的元认知控制相比强基线方法获得了更高的平均回报，并显著减少了训练后期的失败次数。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒强化学习方法通常专注于抑制不可靠经验或被污染的奖励，但缺乏对自身学习过程可靠性的推理能力，导致在面对噪声时可能过度保守，或在不确定性累积时发生灾难性失败。

Method: 提出一种元认知强化学习框架，引入由价值预测误差稳定性（VPES）驱动的元信任变量，通过安全失效机制和渐进式信任恢复来调节学习动态。

Result: 在存在奖励污染的连续控制基准测试中，该方法相比强基线方法实现了更高的平均回报，并显著减少训练后期的失败次数。

Conclusion: 元认知控制机制使智能体能够更稳健地应对学习过程中的不确定性，提升了强化学习系统的整体鲁棒性和可靠性。

Abstract: Robust reinforcement learning methods typically focus on suppressing unreliable experiences or corrupted rewards, but they lack the ability to reason about the reliability of their own learning process. As a result, such methods often either overreact to noise by becoming overly conservative or fail catastrophically when uncertainty accumulates.
  In this work, we propose a meta-cognitive reinforcement learning framework that enables an agent to assess, regulate, and recover its learning behavior based on internally estimated reliability signals. The proposed method introduces a meta-trust variable driven by Value Prediction Error Stability (VPES), which modulates learning dynamics via fail-safe regulation and gradual trust recovery.
  Experiments on continuous-control benchmarks with reward corruption demonstrate that recovery-enabled meta-cognitive control achieves higher average returns and significantly reduces late-stage training failures compared to strong robustness baselines.

</details>


### [132] [DeRaDiff: Denoising Time Realignment of Diffusion Models](https://arxiv.org/abs/2601.20198)
*Ratnavibusena Don Shahain Manujith,Yang Zhang,Teoh Tze Tzun,Kenji Kawaguchi*

Main category: cs.LG

TL;DR: DeRaDiff提出一种去噪时间重对齐方法，通过在采样阶段调节正则化强度，无需额外训练即可模拟不同正则化强度下的模型表现，显著降低计算成本并高效搜索最优正则化参数。


<details>
  <summary>Details</summary>
Motivation: 现有方法需多次训练以搜索最佳正则化强度，计算成本高；如何选择合适的正则化强度仍是一个难题，过高导致对齐不足，过低引发奖励劫持。

Method: DeRaDiff通过在扩散模型采样过程中，用对齐后和参考后验的几何混合分布替换逆向步骤的参考分布，实现闭式更新，并仅需一个可调参数lambda来实时控制正则化强度。

Result: 实验表明，DeRaDiff在文本-图像对齐与图像质量指标上均能有效逼近从头训练不同正则化强度模型的表现，显著减少计算开销。

Conclusion: DeRaDiff提供了一种高效、低成本的解码时正则化强度调节方法，无需重复训练即可实现多强度模拟，为扩散模型对齐提供了实用解决方案。

Abstract: Recent advances align diffusion models with human preferences to increase aesthetic appeal and mitigate artifacts and biases. Such methods aim to maximize a conditional output distribution aligned with higher rewards whilst not drifting far from a pretrained prior. This is commonly enforced by KL (Kullback Leibler) regularization. As such, a central issue still remains: how does one choose the right regularization strength? Too high of a strength leads to limited alignment and too low of a strength leads to "reward hacking". This renders the task of choosing the correct regularization strength highly non-trivial. Existing approaches sweep over this hyperparameter by aligning a pretrained model at multiple regularization strengths and then choose the best strength. Unfortunately, this is prohibitively expensive. We introduce DeRaDiff, a denoising time realignment procedure that, after aligning a pretrained model once, modulates the regularization strength during sampling to emulate models trained at other regularization strengths without any additional training or finetuning. Extending decoding-time realignment from language to diffusion models, DeRaDiff operates over iterative predictions of continuous latents by replacing the reverse step reference distribution by a geometric mixture of an aligned and reference posterior, thus giving rise to a closed form update under common schedulers and a single tunable parameter, lambda, for on the fly control. Our experiments show that across multiple text image alignment and image-quality metrics, our method consistently provides a strong approximation for models aligned entirely from scratch at different regularization strengths. Thus, our method yields an efficient way to search for the optimal strength, eliminating the need for expensive alignment sweeps and thereby substantially reducing computational costs.

</details>


### [133] [Hyperparameter Transfer with Mixture-of-Expert Layers](https://arxiv.org/abs/2601.20205)
*Tianze Jiang,Blake Bordelon,Cengiz Pehlevan,Boris Hanin*

Main category: cs.LG

TL;DR: 本文提出了一种新的参数化方法，用于在扩展Transformer模型的宽度、深度、专家数量和专家隐藏层大小时，有效处理混合专家（MoE）层的超参数（HP）选择问题。该方法基于一种新颖的动力学平均场理论（DMFT）分析，实验证明其能够在51M到超过20亿参数的模型间实现可靠的超参数迁移，并且通过小模型上的短时间训练所确定的超参数，可成功应用于大模型的长时间训练，获得优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏MoE模型在训练中因引入新的可训练参数（如路由器权重）和架构规模维度（如专家数量与大小）而增加了复杂性，需要大量超参数调优，导致成本高且不可靠。因此亟需一种能有效简化并可靠转移超参数的参数化方法。

Method: 提出一种基于动力学平均场理论（DMFT）分析的新参数化方案，以指导在不同模型规模下（包括宽度、深度、专家数、专家大小）的超参数设置，使超参数可在不同规模模型间可靠迁移。

Result: 在固定令牌预算下，该参数化方法使得从51M到超过20亿参数的模型之间实现了可靠的超参数迁移；通过小模型上短周期的超参数搜索，可成功训练大规模模型并在长周期任务中表现良好。

Conclusion: 该参数化方法为大规模MoE模型的高效训练提供了可行路径，显著降低了超参数调优的成本与不确定性，推动了模型规模化发展的实用性。

Abstract: Mixture-of-Experts (MoE) layers have emerged as an important tool in scaling up modern neural networks by decoupling total trainable parameters from activated parameters in the forward pass for each token. However, sparse MoEs add complexity to training due to (i) new trainable parameters (router weights) that, like all other parameter groups, require hyperparameter (HP) tuning; (ii) new architecture scale dimensions (number of and size of experts) that must be chosen and potentially taken large. To make HP selection cheap and reliable, we propose a new parameterization for transformer models with MoE layers when scaling model width, depth, number of experts, and expert (hidden) size. Our parameterization is justified by a novel dynamical mean-field theory (DMFT) analysis. When varying different model dimensions trained at a fixed token budget, we find empirically that our parameterization enables reliable HP transfer across models from 51M to over 2B total parameters. We further take HPs identified from sweeping small models on a short token horizon to train larger models on longer horizons and report performant model behaviors.

</details>


### [134] [Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning](https://arxiv.org/abs/2601.20209)
*Jinyang Wu,Shuo Yang,Changpeng Yang,Yuhao Shen,Shuai Zhang,Zhengqi Wen,Jianhua Tao*

Main category: cs.LG

TL;DR: 提出Spark框架，通过在关键决策状态动态分支实现资源高效的探索，利用智能体内在决策信号自适应分配计算资源，提升样本质量与泛化能力，显著减少训练样本需求并提高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在长时程任务中因高质量轨迹稀缺且资源有限而面临挑战，传统方法盲目扩大采样规模并均匀分配计算资源，导致计算浪费且难以保证样本质量。

Method: 提出Spark框架，基于策略感知的动态分支机制，在关键决策点激活自适应分支探索，利用智能体内在决策信号实现精准资源分配，优先保障采样质量而非盲目覆盖。

Result: 在多种任务（如具身规划）中，Spark表现出更高的成功率，使用更少的训练样本即可达成良好性能，并在未见场景中展现出强泛化能力。

Conclusion: Spark通过智能识别关键决策点并动态分配资源，实现了高效、高质量的探索，为大语言模型在复杂长时程任务中的应用提供了新范式。

Abstract: Reinforcement learning has empowered large language models to act as intelligent agents, yet training them for long-horizon tasks remains challenging due to the scarcity of high-quality trajectories, especially under limited resources. Existing methods typically scale up rollout sizes and indiscriminately allocate computational resources among intermediate steps. Such attempts inherently waste substantial computation budget on trivial steps while failing to guarantee sample quality. To address this, we propose \textbf{Spark} (\textbf{S}trategic \textbf{P}olicy-\textbf{A}ware explo\textbf{R}ation via \textbf{K}ey-state dynamic branching), a novel framework that selectively branches at critical decision states for resource-efficient exploration. Our key insight is to activate adaptive branching exploration at critical decision points to probe promising trajectories, thereby achieving precise resource allocation that prioritizes sampling quality over blind coverage. This design leverages the agent's intrinsic decision-making signals to reduce dependence on human priors, enabling the agent to autonomously expand exploration and achieve stronger generalization. Experiments across diverse tasks (e.g., embodied planning), demonstrate that \textsc{Spark} achieves superior success rates with significantly fewer training samples, exhibiting robust generalization even in unseen scenarios.

</details>


### [135] [An Accounting Identity for Algorithmic Fairness](https://arxiv.org/abs/2601.20217)
*Hadi Elzayn,Jacob Goldin*

Main category: cs.LG

TL;DR: 本文推导出一个预测模型的会计恒等式，将准确性与常见的公平性标准联系起来。该恒等式表明，对于全局校准的模型，组内误校准的加权和与组间误差不平衡的总和等于一个“总不公平预算”。在二分类任务中，该预算等于模型均方误差乘以不同群体结果类别的先验差异。该恒等式包含了标准不可能性结果作为特例，并描述了当至少一个公平性度量未完全满足时的内在权衡。研究结果表明，在二分类预测任务中，准确性和公平性应被视为互补关系：提高准确性必然缩小总不公平预算，反之亦然。基准数据上的实验验证了理论，并显示许多公平性干预措施主要在不公平性表现之间进行替代；当它们降低准确性时，往往会扩大总不公平预算。该结果可自然推广到非二分类预测任务，揭示了额外结果信息如何缓解公平性不相容问题，并指明了二分类不可能性在回归任务中是否成立的条件。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示预测模型中准确性与公平性之间的内在关系，特别是当多个公平性标准无法同时满足时的权衡机制。通过建立会计恒等式，帮助理解公平性干预措施的实际效果及其对整体性能的影响。

Method: 通过数学推导建立预测模型中的会计恒等式，分析全局校准模型下组内误校准与组间误差不平衡的关系，定义并量化‘总不公平预算’，并通过理论分析和实验验证其有效性。

Result: 在二分类任务中，准确性和公平性存在互补关系，提升准确性会减少总不公平预算，反之亦然。实验验证了理论，发现多数公平性干预措施在不同不公平性维度间进行替代，且降低准确性的干预通常会扩大不公平预算。该结论可推广至多分类及回归任务，揭示额外结果信息有助于缓解公平性冲突。

Conclusion: 准确性与公平性并非对立，而是互补关系。在二分类预测中，二者共享一个总不公平预算，因此提升准确性有助于改善公平性。公平性干预措施往往只是在不公平性表现间转移问题，而非真正消除。在更复杂的预测任务中，更多结果信息可缓解公平性冲突。

Abstract: We derive an accounting identity for predictive models that links accuracy with common fairness criteria. The identity shows that for globally calibrated models, the weighted sums of miscalibration within groups and error imbalance across groups is equal to a "total unfairness budget." For binary outcomes, this budget is the model's mean-squared error times the difference in group prevalence across outcome classes. The identity nests standard impossibility results as special cases, while also describing inherent tradeoffs when one or more fairness measures are not perfectly satisfied. The results suggest that accuracy and fairness are best viewed as complements in binary prediction tasks: increasing accuracy necessarily shrinks the total unfairness budget and vice-versa. Experiments on benchmark data confirm the theory and show that many fairness interventions largely substitute between fairness violations, and when they reduce accuracy they tend to expand the total unfairness budget. The results extend naturally to prediction tasks with non-binary outcomes, illustrating how additional outcome information can relax fairness incompatibilities and identifying conditions under which the binary-style impossibility does and does not extend to regression tasks.

</details>


### [136] [Parametric and Generative Forecasts of Day-Ahead Market Curves for Storage Optimization](https://arxiv.org/abs/2601.20226)
*Julian Gutierrez,Redouane Silvente*

Main category: cs.LG

TL;DR: 本文提出两种机器学习框架，用于预测EPEX SPOT日前市场中的聚合曲线并优化储能策略。第一种是快速参数化模型，通过切比雪夫多项式对弹性部分建模，结合最小最大容量，实现低维、网格鲁棒的小时级供需曲线预测，具备低误差和良好可解释性，适合每日使用。第二种是生成模型，学习在天气和燃料变量条件下的24小时订单级联合分布，生成合成的每日买卖订单场景，聚合后得到小时级供需曲线。基于这些预测，优化价格驱动的储能策略，量化收益分布，并揭示价格压缩效应：峰段降低、谷段抬升，且随着储能容量增加，收益递减。


<details>
  <summary>Details</summary>
Motivation: 为提升电力市场中储能系统的经济效率，需准确预测日前市场的供需曲线并制定最优储能策略。传统方法在复杂市场结构下难以兼顾精度与实时性，因此需要新型机器学习框架以实现高效、可解释的曲线预测与优化。

Method: 采用两种方法：一是基于切比雪夫多项式的快速参数化模型，将供需曲线表示为低维、稳健的形式；二是基于生成模型的方法，学习订单级数据的联合分布，生成合成场景以模拟真实市场行为。两者均结合外部变量（如天气与燃料价格），并用于指导储能策略优化。

Result: 所提方法在预测精度与计算效率之间取得良好平衡。参数化模型实现低误差、高可解释性，适用于日常操作；生成模型能够捕捉复杂市场动态，生成合理的情景，支持更深入的策略分析。优化结果表明存在价格压缩现象，即随储能容量增加，边际收益下降，提示储能投资存在经济阈值。

Conclusion: 该研究展示了机器学习在电力市场供需预测与储能优化中的强大潜力。参数化模型适合实时应用，生成模型提供深度分析能力，二者结合可为储能运营商提供科学决策支持，尤其在价格压缩效应下避免过度投资。

Abstract: We present two machine learning frameworks for forecasting aggregated curves and optimizing storage in the EPEX SPOT day-ahead market. First, a fast parametric model forecasts hourly demand and supply curves in a low-dimensional and grid-robust representation, with minimum and maximum volumes combined with a Chebyshev polynomial for the elastic segment. The model enables daily use with low error and clear interpretability. Second, for a more comprehensive analysis, though less suited to daily operation, we employ generative models that learn the joint distribution of 24-hour order-level submissions given weather and fuel variables. These models generate synthetic daily scenarios of individual buy and sell orders, which, once aggregated, yield hourly supply and demand curves. Based on these forecasts, we optimize a price-making storage strategy, quantify revenue distributions, and highlight the price-compression effect with lower peaks, higher off-peak levels, and diminishing returns as capacity expands.

</details>


### [137] [ProFlow: Zero-Shot Physics-Consistent Sampling via Proximal Flow Guidance](https://arxiv.org/abs/2601.20227)
*Zichao Yu,Ming Li,Wenyi Zhang,Difan Zou,Weiguo Gao*

Main category: cs.LG

TL;DR: ProFlow是一种零样本物理一致性采样框架，通过交替执行终端优化和插值步骤，在不重新训练模型的情况下，实现从稀疏观测中推断满足偏微分方程（PDE）的物理场。该方法结合了物理与观测一致性，并保持预训练生成先验的统计结构，具有贝叶斯意义上的局部最大后验（MAP）更新解释。在泊松、亥姆霍兹、达西及黏性伯格斯方程上的实验表明，其在物理一致性、观测拟合度和分布统计准确性方面优于现有扩散模型和流模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有深度生成模型在处理稀疏观测下的物理场反问题时，难以在不破坏预训练生成先验或需代价高昂重训的情况下严格满足偏微分方程约束，亟需一种能兼顾物理一致性、观测拟合与生成先验统计结构的采样机制。

Method: ProFlow采用两步交替优化：(1) 终端优化步骤，通过近似最小化将流模型预测投影到物理与观测一致集的交集中；(2) 插值步骤，将修正后的状态映射回生成轨迹，以维持与学习到的流概率路径的一致性。该过程可解释为一系列局部最大后验（MAP）更新。

Result: 在泊松、亥姆霍兹、达西及黏性伯格斯方程等多个基准测试中，ProFlow在物理一致性、观测拟合精度和分布统计特性方面均显著优于当前最先进的扩散模型和流模型基线。

Conclusion: ProFlow实现了无需任务特定重训的零样本物理一致性采样，有效融合了物理约束与观测数据，同时保留了生成模型的统计先验，为计算物理中的逆问题提供了一种高效且鲁棒的新范式。

Abstract: Inferring physical fields from sparse observations while strictly satisfying partial differential equations (PDEs) is a fundamental challenge in computational physics. Recently, deep generative models offer powerful data-driven priors for such inverse problems, yet existing methods struggle to enforce hard physical constraints without costly retraining or disrupting the learned generative prior. Consequently, there is a critical need for a sampling mechanism that can reconcile strict physical consistency and observational fidelity with the statistical structure of the pre-trained prior. To this end, we present ProFlow, a proximal guidance framework for zero-shot physics-consistent sampling, defined as inferring solutions from sparse observations using a fixed generative prior without task-specific retraining. The algorithm employs a rigorous two-step scheme that alternates between: (\romannumeral1) a terminal optimization step, which projects the flow prediction onto the intersection of the physically and observationally consistent sets via proximal minimization; and (\romannumeral2) an interpolation step, which maps the refined state back to the generative trajectory to maintain consistency with the learned flow probability path. This procedure admits a Bayesian interpretation as a sequence of local maximum a posteriori (MAP) updates. Comprehensive benchmarks on Poisson, Helmholtz, Darcy, and viscous Burgers' equations demonstrate that ProFlow achieves superior physical and observational consistency, as well as more accurate distributional statistics, compared to state-of-the-art diffusion- and flow-based baselines.

</details>


### [138] [Certificate-Guided Pruning for Stochastic Lipschitz Optimization](https://arxiv.org/abs/2601.20231)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 提出一种名为证书引导剪枝（CGP）的新方法，用于在噪声评估下对Lipschitz函数进行黑盒优化。该方法通过置信调整的Lipschitz包络维护一个显式的潜在最优点活跃集，确保不在活跃集中的点以高概率为次优，并在近似最优维度α的条件下证明活跃集体积以可控速率缩小，实现样本复杂度$\tildeO(\varepsilon^{-(2+α)})$。此外开发了三种扩展：CGP-Adaptive在线学习光滑常数且开销低；CGP-TR通过信任区域实现高维（d > 50）扩展；CGP-Hybrid在检测到局部平滑时切换至高斯过程精炼。实验在12个基准测试中验证了其性能优于或媲美强基线，并提供基于证书体积的合理停止准则。


<details>
  <summary>Details</summary>
Motivation: 现有自适应离散化方法虽能隐式避开次优区域，但缺乏明确的最优性证书和可度量的进展保证，因此需要一种能提供显式最优性证明并具备可量化收敛性的优化框架。

Method: 引入证书引导剪枝（CGP），利用置信调整的Lipschitz包络维护一个活跃集 $A_t$，通过分析点是否位于该集合内来判断其是否可能为最优；结合近似最优性维度与体积收缩机制，设计具有理论保障的剪枝策略，并发展三种实用扩展以适应不同场景。

Result: 在12个不同维度（$d \\in [2, 100]$）的基准测试中，CGP及其变体表现优异，达到或超过现有强基线方法，同时提供了基于证书体积的可解释停止条件，实现了理论保障与实际性能的统一。

Conclusion: CGP方法成功将黑盒优化中的次优区域识别转化为可证伪的数学命题，显著提升了算法的透明性与可靠性，为复杂优化任务提供了兼具理论严谨性与工程实用性的新范式。

Abstract: We study black-box optimization of Lipschitz functions under noisy evaluations. Existing adaptive discretization methods implicitly avoid suboptimal regions but do not provide explicit certificates of optimality or measurable progress guarantees. We introduce \textbf{Certificate-Guided Pruning (CGP)}, which maintains an explicit \emph{active set} $A_t$ of potentially optimal points via confidence-adjusted Lipschitz envelopes. Any point outside $A_t$ is certifiably suboptimal with high probability, and under a margin condition with near-optimality dimension $α$, we prove $\Vol(A_t)$ shrinks at a controlled rate yielding sample complexity $\tildeO(\varepsilon^{-(2+α)})$. We develop three extensions: CGP-Adaptive learns $L$ online with $O(\log T)$ overhead; CGP-TR scales to $d > 50$ via trust regions with local certificates; and CGP-Hybrid switches to GP refinement when local smoothness is detected. Experiments on 12 benchmarks ($d \in [2, 100]$) show CGP variants match or exceed strong baselines while providing principled stopping criteria via certificate volume.

</details>


### [139] [HE-SNR: Uncovering Latent Logic via Entropy for Guiding Mid-Training on SWE-BENCH](https://arxiv.org/abs/2601.20255)
*Yueyang Wang,Jiawei Fu,Baolong Bi,Xili Wang,Xiaoqing Liu*

Main category: cs.LG

TL;DR: 本文提出一种新型度量方法HE-SNR，以解决大语言模型在软件工程任务中训练中期缺乏有效评估指标的问题。通过引入熵压缩假设，重新定义智能为对不确定性的结构化处理能力，并基于细粒度熵分析构建了具有更强鲁棒性和预测力的度量标准。该方法在工业级MoE模型上验证，适用于不同上下文窗口（32K/128K），显著提升了对下游性能的预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有标准度量如困惑度（PPL）受长上下文税影响，且与下游软件工程任务表现相关性弱，无法有效指导模型训练中期的优化。

Method: 提出数据过滤策略和熵压缩假设，将智能定义为将不确定性结构化为低阶熵压缩状态的能力；基于此构建新型度量HE-SNR，进行细粒度熵分析并验证其有效性。

Result: 在工业级混合专家（MoE）模型上，使用不同上下文窗口（32K/128K）验证，所提方法展现出优越的鲁棒性和预测能力，能更准确反映模型潜在性能。

Conclusion: 本研究不仅建立了优化大语言模型在复杂工程领域潜力的理论基础，还提供了实用的工具与方法，推动模型训练中对潜在能力的有效挖掘。

Abstract: SWE-bench has emerged as the premier benchmark for evaluating Large Language Models on complex software engineering tasks. While these capabilities are fundamentally acquired during the mid-training phase and subsequently elicited during Supervised Fine-Tuning (SFT), there remains a critical deficit in metrics capable of guiding mid-training effectively. Standard metrics such as Perplexity (PPL) are compromised by the "Long-Context Tax" and exhibit weak correlation with downstream SWE performance. In this paper, we bridge this gap by first introducing a rigorous data filtering strategy. Crucially, we propose the Entropy Compression Hypothesis, redefining intelligence not by scalar Top-1 compression, but by the capacity to structure uncertainty into Entropy-Compressed States of low orders ("reasonable hesitation"). Grounded in this fine-grained entropy analysis, we formulate a novel metric, HE-SNR (High-Entropy Signal-to-Noise Ratio). Validated on industrial-scale Mixture-of-Experts (MoE) models across varying context windows (32K/128K), our approach demonstrates superior robustness and predictive power. This work provides both the theoretical foundation and practical tools for optimizing the latent potential of LLMs in complex engineering domains.

</details>


### [140] [C2:Cross learning module enhanced decision transformer with Constraint-aware loss for auto-bidding](https://arxiv.org/abs/2601.20257)
*Jinren Ding,Xuejian Xu,Shen Jiang,Zhitong Hao,Jinhui Yang,Peng Jiang*

Main category: cs.LG

TL;DR: C2提出一种新框架，通过交叉学习块（CLB）和约束感知损失（CL）改进决策变换器（DT），以增强状态、动作与未来回报间的相关性建模，并选择性学习最优行为。在AuctionNet数据集上表现优于现有方法，最多提升3.23%。


<details>
  <summary>Details</summary>
Motivation: 决策变换器（DT）在自动出价中虽能捕捉时间依赖关系，但存在跨序列相关性建模不足以及对最优与非最优行为无差别学习的问题。

Method: 引入交叉学习块（CLB）利用交叉注意力强化状态、动作与回报至未来（RTG）序列间的关联；设计约束感知损失（CL）结合预算和每获取成本（CPA）约束，实现对最优轨迹的选择性学习。

Result: 在AuctionNet数据集上的离线评估显示，C2在多种预算设置下均取得一致性能提升，最高达3.23%优于当前最佳方法GAVE；消融实验验证了CLB与CL的互补协同作用。

Conclusion: C2通过双创新机制有效解决了DT在自动出价中的关键缺陷，显著提升了性能，具备实际应用潜力。

Abstract: Decision Transformer (DT) shows promise for generative auto-bidding by capturing temporal dependencies, but suffers from two critical limitations: insufficient cross-correlation modeling among state, action, and return-to-go (RTG) sequences, and indiscriminate learning of optimal/suboptimal behaviors. To address these, we propose C2, a novel framework enhancing DT with two core innovations: (1) a Cross Learning Block (CLB) via cross-attention to strengthen inter-sequence correlation modeling; (2) a Constraint-aware Loss (CL) incorporating budget and Cost-Per-Acquisition (CPA) constraints for selective learning of optimal trajectories. Extensive offline evaluations on the AuctionNet dataset demonstrate consistent performance gains (up to 3.23\% over state-of-the-art GAVE) across diverse budget settings; ablation studies verify the complementary synergy of CLB and CL, confirming C2's superiority in auto-bidding. The code for reproducing our results is available at: https://github.com/Dingjinren/C2.

</details>


### [141] [Robust SDE Parameter Estimation Under Missing Time Information Setting](https://arxiv.org/abs/2601.20268)
*Long Van Tran,Truyen Tran,Phuoc Nguyen*

Main category: cs.LG

TL;DR: 本文研究了在时间顺序信息丢失或被隐藏的情况下，如何恢复时间顺序并同时估计随机微分方程（SDE）的参数。提出了一种基于前向与后向过程不对称性的新框架，利用评分匹配准则推断观测对的时间顺序，并通过排序过程重建完整时间序列，最后使用最大似然法估计SDE参数。实验在合成和真实数据集上验证了方法的有效性，扩展了SDE参数估计在时间信息缺失场景下的应用范围。


<details>
  <summary>Details</summary>
Motivation: 现有SDE参数估计方法依赖于准确的时间戳序列，但在时间顺序信息缺失、损坏或出于隐私保护而被隐藏的情况下，传统方法失效。因此需要一种能够在无序观测中恢复时间顺序并同时估计参数的新方法。

Method: 提出利用前向与后向过程之间的不对称性，设计评分匹配准则以判断观测对的正确时间顺序；通过排序算法重建完整的时序序列；再基于重构序列采用最大似然法估计SDE参数。

Result: 所提方法在多种合成与真实数据集上均表现出良好性能，能够有效恢复时间顺序并准确估计SDE参数，尤其适用于时间信息不完整或不可靠的敏感应用场景。

Conclusion: 本研究揭示了在无序观测下恢复时间顺序的可能性，并建立了一个统一框架，实现时间顺序重建与SDE参数估计的联合优化，显著拓展了SDE在现实复杂场景中的适用性。

Abstract: Recent advances in stochastic differential equations (SDEs) have enabled robust modeling of real-world dynamical processes across diverse domains, such as finance, health, and systems biology. However, parameter estimation for SDEs typically relies on accurately timestamped observational sequences. When temporal ordering information is corrupted, missing, or deliberately hidden (e.g., for privacy), existing estimation methods often fail. In this paper, we investigate the conditions under which temporal order can be recovered and introduce a novel framework that simultaneously reconstructs temporal information and estimates SDE parameters. Our approach exploits asymmetries between forward and backward processes, deriving a score-matching criterion to infer the correct temporal order between pairs of observations. We then recover the total order via a sorting procedure and estimate SDE parameters from the reconstructed sequence using maximum likelihood. Finally, we conduct extensive experiments on synthetic and real-world datasets to demonstrate the effectiveness of our method, extending parameter estimation to settings with missing temporal order and broadening applicability in sensitive domains.

</details>


### [142] [The Forecast After the Forecast: A Post-Processing Shift in Time Series](https://arxiv.org/abs/2601.20280)
*Daojun Liang,Qi Li,Yinglong Wang,Jing Chen,Hu Zhang,Xiaoxiao Cui,Qizheng Wang,Shuo Li*

Main category: cs.LG

TL;DR: 本文提出了一种名为 $δ$-Adapter 的轻量级、架构无关的后处理方法，用于在不重新训练或修改已部署的时间序列预测模型的情况下提升预测精度和不确定性校准。该方法通过在输入端进行软编辑（输入微调）和输出端进行残差修正来实现，具备局部下降保证、$O(δ)$ 的漂移边界以及组合稳定性。同时，$δ$-Adapter 可作为特征选择器，学习稀疏、时序感知的输入掩码以增强可解释性；还可作为分布校准器，结合分位数校准器与置信区间校正器，提供具有有限样本覆盖性的个性化置信区间。实验表明，该方法在多种模型和数据集上均显著提升了准确性和校准性能，且计算开销极低，无需接口变更。


<details>
  <summary>Details</summary>
Motivation: 随着时间序列预测模型在架构上的改进逐渐趋于饱和，进一步提升精度和不确定性校准面临瓶颈。现有方法多依赖于模型结构优化，而对部署后模型的后处理策略关注不足。因此，本文旨在填补‘最后一公里’的差距——即在不改变原模型的前提下，通过轻量级后处理手段提升预测质量。

Method: $δ$-Adapter 采用两种轻量级模块：输入端的‘输入微调’（soft edits to covariates）与输出端的‘残差修正’（output residual correction）。其核心是学习一个有界的小型模块，具备局部收敛性、$O(δ)$ 漂移控制和组合稳定性。此外，通过学习稀疏的输入掩码实现特征选择，并结合量化校准器与符合性校正器完成不确定性校准。

Result: 在多种时间序列预测模型（如 LSTM、Transformer 等）和真实数据集上，$δ$-Adapter 显著提升了预测准确性与概率校准性能，同时保持极低的计算开销，且无需修改原有模型接口。实验验证了其在不同场景下的有效性与通用性。

Conclusion: $δ$-Adapter 提供了一种高效、通用且无需重训练的后处理框架，为部署中的时间序列预测系统提供了提升精度与可信度的新路径。其在不改变现有系统的基础上实现了性能增益，具有良好的工程落地潜力。

Abstract: Time series forecasting has long been dominated by advances in model architecture, with recent progress driven by deep learning and hybrid statistical techniques. However, as forecasting models approach diminishing returns in accuracy, a critical yet underexplored opportunity emerges: the strategic use of post-processing. In this paper, we address the last-mile gap in time-series forecasting, which is to improve accuracy and uncertainty without retraining or modifying a deployed backbone. We propose $δ$-Adapter, a lightweight, architecture-agnostic way to boost deployed time series forecasters without retraining. $δ$-Adapter learns tiny, bounded modules at two interfaces: input nudging (soft edits to covariates) and output residual correction. We provide local descent guarantees, $O(δ)$ drift bounds, and compositional stability for combined adapters. Meanwhile, it can act as a feature selector by learning a sparse, horizon-aware mask over inputs to select important features, thereby improving interpretability. In addition, it can also be used as a distribution calibrator to measure uncertainty. Thus, we introduce a Quantile Calibrator and a Conformal Corrector that together deliver calibrated, personalized intervals with finite-sample coverage. Our experiments across diverse backbones and datasets show that $δ$-Adapter improves accuracy and calibration with negligible compute and no interface changes.

</details>


### [143] [Memory Retrieval in Transformers: Insights from The Encoding Specificity Principle](https://arxiv.org/abs/2601.20282)
*Viet Hung Dinh,Ming Ding,Youyang Qu,Kanchana Thilakarathna*

Main category: cs.LG

TL;DR: 本文研究了基于Transformer的大型语言模型中注意力层的记忆机制，借鉴心理学和计算心理语言学中的线索-检索理论，提出查询作为检索上下文、键作为候选记忆痕迹、注意力权重衡量线索与记忆痕迹的相似性、值携带编码内容，共同构建上下文表示以促进记忆检索。基于编码特异性原则，假设初始检索阶段的线索由关键词构成，并提供了支持该假设的多重证据。此外，识别出在注意力层中专门编码并促进上下文定义关键词检索的神经元，这些关键词可被提取并用于下游应用如机器遗忘。


<details>
  <summary>Details</summary>
Motivation: 尽管可解释人工智能（XAI）在大型语言模型（LLMs）领域不断发展，但其在确保透明度、问责性和隐私保护的机器遗忘方面的作用仍不明确。尤其是，基于Transformer的模型中注意力层的具体作用尚未充分探索，因此亟需深入研究其记忆机制。

Method: 结合心理学和计算心理语言学的研究，将Transformer注意力机制类比为人类记忆中的线索-检索过程。通过分析注意力权重与关键词之间的关联，识别出在注意力层中专门编码上下文定义关键词的神经元，并利用编码特异性原则验证关键词作为检索线索的有效性。

Result: 实证结果支持了‘关键词作为检索线索’的假设，发现了特定神经元对关键词的敏感性，且这些关键词可被有效提取，进而应用于机器遗忘等下游任务。

Conclusion: 注意力层在大型语言模型中扮演着类似人类记忆系统中线索-检索的功能，关键词是关键的检索线索，其在注意力机制中的编码可被识别并用于提升模型的可解释性和隐私保护能力，如实现高效机器遗忘。

Abstract: While explainable artificial intelligence (XAI) for large language models (LLMs) remains an evolving field with many unresolved questions, increasing regulatory pressures have spurred interest in its role in ensuring transparency, accountability, and privacy-preserving machine unlearning. Despite recent advances in XAI have provided some insights, the specific role of attention layers in transformer based LLMs remains underexplored. This study investigates the memory mechanisms instantiated by attention layers, drawing on prior research in psychology and computational psycholinguistics that links Transformer attention to cue based retrieval in human memory. In this view, queries encode the retrieval context, keys index candidate memory traces, attention weights quantify cue trace similarity, and values carry the encoded content, jointly enabling the construction of a context representation that precedes and facilitates memory retrieval. Guided by the Encoding Specificity Principle, we hypothesize that the cues used in the initial stage of retrieval are instantiated as keywords. We provide converging evidence for this keywords-as-cues hypothesis. In addition, we isolate neurons within attention layers whose activations selectively encode and facilitate the retrieval of context-defining keywords. Consequently, these keywords can be extracted from identified neurons and further contribute to downstream applications such as unlearning.

</details>


### [144] [A Learning-based Framework for Spatial Impulse Response Compensation in 3D Photoacoustic Computed Tomography](https://arxiv.org/abs/2601.20291)
*Kaiyi Yang,Seonyeong Park,Gangwon Jeong,Hsuan-Kai Huang,Alexander A. Oraevsky,Umberto Villa,Mark A. Anastasio*

Main category: cs.LG

TL;DR: 该研究提出了一种基于学习的3D光声计算机断层成像（PACT）中空间冲激响应（SIR）补偿框架，通过在数据域中对SIR引起的失真进行补偿，使后续使用快速解析重建方法时仍能保持高分辨率。采用U-Net和一种物理启发的Deconv-Net模型进行对比，结合快速训练数据生成，验证了其在虚拟与真实活体乳腺成像中的有效性，显著提升了图像分辨率并抑制了噪声、复杂结构及声速异质性带来的影响，是首个在3D PACT中实现学习式SIR补偿的工作。


<details>
  <summary>Details</summary>
Motivation: 传统快速解析重建方法忽略传感器的空间冲激响应（SIR），导致图像分辨率下降；而优化类方法虽可建模SIR但计算成本过高，尤其在三维应用中。因此亟需一种既准确又高效的方法来补偿SIR效应。

Method: 提出一个数据域的深度学习补偿框架，利用U-Net和物理启发的Deconv-Net模型，将实际测量数据映射为理想点状传感器应记录的数据；结合快速解析式训练数据生成流程，使补偿后的数据可用于高效解析重建。

Result: 在虚拟成像中验证了该方法在提升分辨率、抗噪、适应复杂结构和声速不均方面的鲁棒性；应用于活体乳腺数据时，成功揭示了被SIR伪影掩盖的细微结构，表明其在真实场景中的优越性能。

Conclusion: 该研究首次实现了3D PACT中基于学习的SIR补偿，兼具高精度与计算效率，为快速、高质量的三维光声成像提供了新范式。

Abstract: Photoacoustic computed tomography (PACT) is a promising imaging modality that combines the advantages of optical contrast with ultrasound detection. Utilizing ultrasound transducers with larger surface areas can improve detection sensitivity. However, when computationally efficient analytic reconstruction methods that neglect the spatial impulse responses (SIRs) of the transducer are employed, the spatial resolution of the reconstructed images will be compromised. Although optimization-based reconstruction methods can explicitly account for SIR effects, their computational cost is generally high, particularly in three-dimensional (3D) applications. To address the need for accurate but rapid 3D PACT image reconstruction, this study presents a framework for establishing a learned SIR compensation method that operates in the data domain. The learned compensation method maps SIR-corrupted PACT measurement data to compensated data that would have been recorded by idealized point-like transducers. Subsequently, the compensated data can be used with a computationally efficient reconstruction method that neglects SIR effects. Two variants of the learned compensation model are investigated that employ a U-Net model and a specifically designed, physics-inspired model, referred to as Deconv-Net. A fast and analytical training data generation procedure is also a component of the presented framework. The framework is rigorously validated in virtual imaging studies, demonstrating resolution improvement and robustness to noise variations, object complexity, and sound speed heterogeneity. When applied to in-vivo breast imaging data, the learned compensation models revealed fine structures that had been obscured by SIR-induced artifacts. To our knowledge, this is the first demonstration of learned SIR compensation in 3D PACT imaging.

</details>


### [145] [Cheap2Rich: A Multi-Fidelity Framework for Data Assimilation and System Identification of Multiscale Physics -- Rotating Detonation Engines](https://arxiv.org/abs/2601.20295)
*Yuxuan Bao,Jan Zajac,Megan Powers,Venkat Raman,J. Nathan Kutz*

Main category: cs.LG

TL;DR: 提出Cheap2Rich框架，通过结合快速低保真先验与可解释的偏差修正，从稀疏传感器历史中重建高保真状态空间，成功应用于旋转爆震发动机（RDEs）系统，实现多尺度复杂系统中的高效数据同化与系统辨识。


<details>
  <summary>Details</summary>
Motivation: 解决计算成本低的模型与复杂物理系统之间的仿真到现实（sim2real）差距，尤其在多尺度系统中，传统降阶模型仅能捕捉主导动态，难以应对复杂耦合现象。

Method: 提出一种多尺度数据同化框架Cheap2Rich，融合快速低保真模型作为先验，并引入学习得到的、可解释的偏差修正项，以重构高保真状态空间。

Result: 在旋转爆震发动机系统中成功从稀疏测量中重建高保真状态，分离出与喷射驱动相关的物理可解释偏差动态，验证了方法在实时监控、控制及设计探索中的有效性。

Conclusion: 所提出的多保真度数据同化框架具有通用性，适用于复杂多尺度系统的系统辨识与实时分析，同时提供物理可解释的偏差机制，推动工程系统中机器学习应用的发展。

Abstract: Bridging the sim2real gap between computationally inexpensive models and complex physical systems remains a central challenge in machine learning applications to engineering problems, particularly in multi-scale settings where reduced-order models typically capture only dominant dynamics. In this work, we present Cheap2Rich, a multi-scale data assimilation framework that reconstructs high-fidelity state spaces from sparse sensor histories by combining a fast low-fidelity prior with learned, interpretable discrepancy corrections. We demonstrate the performance on rotating detonation engines (RDEs), a challenging class of systems that couple detonation-front propagation with injector-driven unsteadiness, mixing, and stiff chemistry across disparate scales. Our approach successfully reconstructs high-fidelity RDE states from sparse measurements while isolating physically meaningful discrepancy dynamics associated with injector-driven effects. The results highlight a general multi-fidelity framework for data assimilation and system identification in complex multi-scale systems, enabling rapid design exploration and real-time monitoring and control while providing interpretable discrepancy dynamics. Code for this project is is available at: github.com/kro0l1k/Cheap2Rich.

</details>


### [146] [Truthfulness Despite Weak Supervision: Evaluating and Training LLMs Using Peer Prediction](https://arxiv.org/abs/2601.20299)
*Tianyi Alex Qiu,Micah Carroll,Cameron Allen*

Main category: cs.LG

TL;DR: 本文提出了一种基于同行预测（peer prediction）的方法，用于大语言模型（LLM）的评估与后训练，旨在解决在缺乏强监督信号时模型可能产生欺骗性结果的问题。该方法通过互可预测性指标奖励诚实且信息丰富的回答，无需真实标签，具有理论保障和实证支持。实验表明，即使使用未微调的小模型（0.135B）生成奖励，也能有效恢复因恶意微调导致的诚实性下降；在评估方面，同行预测展现出反向缩放特性——当专家与参与者能力差距增大时，对欺骗的抵抗力反而增强，甚至在模型规模相差100倍的情况下仍表现优异，而传统LLM作为裁判（LLM-as-a-Judge）在此类情况下会退化为随机猜测。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的评估与后训练高度依赖强监督信号，但在前沿模型评估中，高质量标注往往不可得。现有方法容易被模型利用，产生误导性结果。因此亟需一种不依赖真实标签、能有效激励诚实回答的弱监督机制。

Method: 引入同行预测方法，基于互可预测性设计奖励机制，通过比较多个模型对彼此输出的预测能力来判断其回答的真实性与信息量，无需依赖地面真实标签，实现对模型行为的激励与评估。

Result: 实验验证了该方法在405B参数模型上的有效性；使用0.135B无微调模型生成的奖励即可显著恢复8B模型的诚实性；在评估任务中，同行预测表现出反向缩放现象：随着评估者与被评者能力差距扩大，抗欺骗能力提升，甚至在超过100倍的规模差异下仍优于随机猜测，而传统方法则迅速失效。

Conclusion: 同行预测提供了一种鲁棒、可扩展且无需强监督的模型评估与后训练框架，尤其适用于评估超大规模模型，是当前基于人工或强监督评估范式的有力替代方案。

Abstract: The evaluation and post-training of large language models (LLMs) rely on supervision, but strong supervision for difficult tasks is often unavailable, especially when evaluating frontier models. In such cases, models are demonstrated to exploit evaluations built on such imperfect supervision, leading to deceptive results. However, underutilized in LLM research, a wealth of mechanism design research focuses on game-theoretic incentive compatibility, i.e., eliciting honest and informative answers with weak supervision. Drawing from this literature, we introduce the peer prediction method for model evaluation and post-training. It rewards honest and informative answers over deceptive and uninformative ones, using a metric based on mutual predictability and without requiring ground truth labels. We demonstrate the method's effectiveness and resistance to deception, with both theoretical guarantees and empirical validation on models with up to 405B parameters. We show that training an 8B model with peer prediction-based reward recovers most of the drop in truthfulness due to prior malicious finetuning, even when the reward is produced by a 0.135B language model with no finetuning. On the evaluation front, in contrast to LLM-as-a-Judge which requires strong and trusted judges, we discover an inverse scaling property in peer prediction, where, surprisingly, resistance to deception is strengthened as the capability gap between the experts and participants widens, enabling reliable evaluation of strong models with weak supervision. In particular, LLM-as-a-Judge become worse than random guess when facing deceptive models 5-20x the judge's size, while peer prediction thrives when such gaps are large, including in cases with over 100x size difference.

</details>


### [147] [Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction: Benchmark, Insights and Approaches](https://arxiv.org/abs/2601.20307)
*Xinyu Li,Sishuo Chen,Guipeng Xv,Li Zhang,Mingxuan Luo,Zhangming Chan,Xiang-Rong Sheng,Han Zhu,Jian Xu,Chen Lin*

Main category: cs.LG

TL;DR: 本文提出了一种针对在线广告中后点击商品交易额（GMV）预测的延迟反馈建模方法，建立了TRACE基准数据集，并提出了名为READER的新模型。该模型通过双分支结构和路由机制区分重复购买与单次购买样本，动态校准回归目标以缓解不完整标签带来的低估问题，在多个指标上显著优于基线方法，性能提升达2.19%。


<details>
  <summary>Details</summary>
Motivation: 当前在线广告排名模型的预测目标从点击转化率（CVR）转向更复杂的业务指标如GMV，但现有研究未充分解决GMV预测中的延迟反馈问题，尤其是因单次点击引发多次购买导致标签连续且不完整的问题，因此亟需新的建模框架与数据支持。

Method: 提出READER模型，采用双分支架构并引入路由器模块，根据是否预测为重复购买来选择性激活专家参数；同时动态调整回归目标以补偿因延迟反馈造成的标签不完整问题；结合TRACE基准实现在线流式训练下的延迟反馈建模。

Result: READER在TRACE基准上表现优异，相较于基线模型在准确率方面提升2.19%，验证了其在处理复杂延迟反馈与异构购买行为方面的有效性。

Conclusion: 本研究填补了在线广告中GMV预测延迟反馈建模的研究空白，提出的TRACE基准和READER模型为未来相关研究提供了重要工具与方向，具有较强的实用价值与推广潜力。

Abstract: The prediction objectives of online advertisement ranking models are evolving from probabilistic metrics like conversion rate (CVR) to numerical business metrics like post-click gross merchandise volume (GMV). Unlike the well-studied delayed feedback problem in CVR prediction, delayed feedback modeling for GMV prediction remains unexplored and poses greater challenges, as GMV is a continuous target, and a single click can lead to multiple purchases that cumulatively form the label. To bridge the research gap, we establish TRACE, a GMV prediction benchmark containing complete transaction sequences rising from each user click, which supports delayed feedback modeling in an online streaming manner. Our analysis and exploratory experiments on TRACE reveal two key insights: (1) the rapid evolution of the GMV label distribution necessitates modeling delayed feedback under online streaming training; (2) the label distribution of repurchase samples substantially differs from that of single-purchase samples, highlighting the need for separate modeling. Motivated by these findings, we propose RepurchasE-Aware Dual-branch prEdictoR (READER), a novel GMV modeling paradigm that selectively activates expert parameters according to repurchase predictions produced by a router. Moreover, READER dynamically calibrates the regression target to mitigate under-estimation caused by incomplete labels. Experimental results show that READER yields superior performance on TRACE over baselines, achieving a 2.19% improvement in terms of accuracy. We believe that our study will open up a new avenue for studying online delayed feedback modeling for GMV prediction, and our TRACE benchmark with the gathered insights will facilitate future research and application in this promising direction. Our code and dataset are available at https://github.com/alimama-tech/OnlineGMV .

</details>


### [148] [Window-Diffusion: Accelerating Diffusion Language Model Inference with Windowed Token Pruning and Caching](https://arxiv.org/abs/2601.20332)
*Fengrui Zuo,Zhiwei Ke,Yiming Liu,Wenqi Lou,Chao Wang,Xvehai Zhou*

Main category: cs.LG

TL;DR: 提出一种基于窗口的令牌剪枝与缓存方法（Window-Diffusion），通过利用扩散语言模型推理中的结构局部性，仅对局部活跃和缓冲令牌进行计算，将远距离令牌剪枝，显著提升推理速度。在相同计算预算下，相比基线模型实现高达99倍的加速，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在推理过程中存在大量冗余计算，尤其是在每个迭代中对所有掩码令牌进行全序列注意力计算；尽管块级扩散可降低计算成本，但通常需要重新训练且更新顺序受限，难以直接应用于预训练模型。因此，亟需一种无需重训练、高效且适用于现有模型的优化方法。

Method: 通过分析发现扩散语言模型推理具有明显的结构局部性：解码主要由少量前缀局部化的活跃令牌驱动，远处未解码上下文的影响迅速衰减，已解码令牌表现出阶段性的时序稳定性，允许复用中间表示，仅在解码后短暂瞬态期间重新计算。基于此，提出Window-Diffusion方法，维护一个随去噪过程向右滑动的局部计算窗口，将未解码令牌分为三类：(i) 在线计算的活跃令牌，(ii) 缓存并周期性刷新的键值状态的缓冲令牌，(iii) 被剪枝出窗口的远场令牌。计算仅限于窗口内的活跃与缓冲令牌，远场令牌被忽略。

Result: 在LLaDA和Dream模型上的实验表明，在相同计算预算下，该方法实现了最高达99倍的推理加速，同时生成性能几乎不受影响。

Conclusion: Window-Diffusion方法有效利用了扩散语言模型推理中的结构局部性，通过局部窗口机制实现高效的计算剪枝与缓存，显著提升推理效率，且无需重新训练，可直接部署于现有预训练模型，为高效扩散语言模型推理提供了新范式。

Abstract: Diffusion language models (DLMs) generate text through iterative denoising, but inference requires full-sequence attention at every iteration, resulting in substantial redundant computation on masked tokens. Block-wise diffusion can reduce this cost, yet it typically relies on retraining and constrained update orders, limiting its direct applicability to pretrained DLMs. Our token-level analysis reveals pronounced structural locality in DLM inference. Decoding is driven by a small set of prefix-localized active tokens; the influence of distant undecoded context diminishes rapidly, and decoded tokens exhibit stage-wise temporal stability, enabling reuse of intermediate representations except for a brief post-decode transient. Motivated by these observations, we propose \textbf{\placeholder}\footnote{The source code is available at https://github.com/vhicrgit/Window-Diffusion.}, a window-based token pruning and caching method for inference. We maintain a local computation window that slides rightward as denoising progresses, and partition undecoded tokens into: (i) \textit{active tokens} that are computed online, (ii) \textit{buffer tokens} whose KV states are cached and periodically refreshed, and (iii) \textit{far-field tokens} that are pruned outside the window. Computation is restricted to active and buffer tokens within the window, while far-field tokens are omitted at each stage. Experiments on LLaDA and Dream show that, under matched compute budgets, our method achieves up to $99\times$ inference speedup while largely preserving generation performance.

</details>


### [149] [TABED: Test-Time Adaptive Ensemble Drafting for Robust Speculative Decoding in LVLMs](https://arxiv.org/abs/2601.20357)
*Minjae Lee,Wonjun Kang,Byeongkeun Ahn,Christian Classen,Kevin Galim,Seunghyuk Oh,Minghao Yan,Hyung Il Koo,Kangwook Lee*

Main category: cs.LG

TL;DR: 提出一种名为TABED的新方法，用于加速大型视觉语言模型（LVLM）的推理，通过测试时自适应批量集成草案生成，实现平均1.74倍的加速，并在不增加训练成本的情况下提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在大型视觉语言模型（LVLMs）中尚未得到充分探索，且在不同输入场景下表现不稳定，因此需要一种更鲁棒、自适应的解决方案。

Method: 提出Test-time Adaptive Batched Ensemble Drafting（TABED），利用过去真实输出的偏差信息，在测试阶段动态集成多个批量生成的草案，通过参数共享保持低开销。

Result: TABED实现了平均1.74倍的壁时加速，相比自回归解码显著提升，且比单一草案方法提升5%，同时保持无需训练和极低的集成开销。

Conclusion: TABED是一种高效、通用且可插拔的推理加速框架，适用于多种视觉语言任务，为LVLM的高效部署提供了新思路。

Abstract: Speculative decoding (SD) has proven effective for accelerating LLM inference by quickly generating draft tokens and verifying them in parallel. However, SD remains largely unexplored for Large Vision-Language Models (LVLMs), which extend LLMs to process both image and text prompts. To address this gap, we benchmark existing inference methods with small draft models on 11 datasets across diverse input scenarios and observe scenario-specific performance fluctuations. Motivated by these findings, we propose Test-time Adaptive Batched Ensemble Drafting (TABED), which dynamically ensembles multiple drafts obtained via batch inference by leveraging deviations from past ground truths available in the SD setting. The dynamic ensemble method achieves an average robust walltime speedup of 1.74x over autoregressive decoding and a 5% improvement over single drafting methods, while remaining training-free and keeping ensembling costs negligible through parameter sharing. With its plug-and-play compatibility, we further enhance TABED by integrating advanced verification and alternative drafting methods. Code and custom-trained models are available at https://github.com/furiosa-ai/TABED.

</details>


### [150] [Can Continuous-Time Diffusion Models Generate and Solve Globally Constrained Discrete Problems? A Study on Sudoku](https://arxiv.org/abs/2601.20363)
*Mariia Drozdova*

Main category: cs.LG

TL;DR: 该研究探讨了标准连续时间生成模型是否能够表示支持集为极稀疏且全局受限的离散集合的概率分布，以完成的数独网格为测试基准。通过在高斯概率路径上训练流匹配和基于分数的模型，并比较确定性（ODE）、随机（SDE）采样以及来自同一连续时间训练的DDPM风格离散化方法，发现随机采样显著优于确定性流；基于分数的采样器在连续时间方法中最为可靠，而DDPM风格的祖先采样整体上达到最高有效性。此外，模型可被重新用于引导生成：通过反复采样满足固定提示条件的补全并停止于约束满足时，模型可作为概率性数独求解器。尽管其样本效率远低于经典求解器和离散几何感知的扩散方法，但实验表明经典扩散/流模型能为全局受限的组合结构分配非零概率质量，并可通过随机搜索实现约束满足。


<details>
  <summary>Details</summary>
Motivation: 探究连续时间生成模型在处理极稀疏、全局受限的离散结构（如数独网格）时的能力，检验其能否有效建模此类复杂组合结构的分布，并验证其在约束满足任务中的可行性。

Method: 采用完成的数独网格作为离散结构的受控测试基准，将其嵌入连续松弛空间中；在高斯概率路径上训练流匹配与基于分数的模型；对比确定性（ODE）、随机（SDE）采样及DDPM风格离散化方法；利用固定线索进行引导生成，通过重复采样直至满足约束条件，评估模型作为概率性求解器的表现。

Result: 随机采样显著优于确定性流；基于分数的采样器最稳定；DDPM风格祖先采样在有效性上表现最佳；模型可成功用于引导生成，实现概率性数独求解，尽管样本效率较低，但仍证明了连续时间模型对全局约束组合结构建模的潜力。

Conclusion: 经典连续时间扩散与流模型能够为全局受限的离散组合结构分配非零概率质量，并可通过随机搜索实现约束满足，具备作为概率性求解器的潜力，虽样本效率不高，但展示了在复杂离散结构建模方面的可行性与灵活性。

Abstract: Can standard continuous-time generative models represent distributions whose support is an extremely sparse, globally constrained discrete set? We study this question using completed Sudoku grids as a controlled testbed, treating them as a subset of a continuous relaxation space. We train flow-matching and score-based models along a Gaussian probability path and compare deterministic (ODE) sampling, stochastic (SDE) sampling, and DDPM-style discretizations derived from the same continuous-time training. Unconditionally, stochastic sampling substantially outperforms deterministic flows; score-based samplers are the most reliable among continuous-time methods, and DDPM-style ancestral sampling achieves the highest validity overall. We further show that the same models can be repurposed for guided generation: by repeatedly sampling completions under clamped clues and stopping when constraints are satisfied, the model acts as a probabilistic Sudoku solver. Although far less sample-efficient than classical solvers and discrete-geometry-aware diffusion methods, these experiments demonstrate that classic diffusion/flow formulations can assign non-zero probability mass to globally constrained combinatorial structures and can be used for constraint satisfaction via stochastic search.

</details>


### [151] [LLM-AutoDP: Automatic Data Processing via LLM Agents for Model Fine-tuning](https://arxiv.org/abs/2601.20375)
*Wei Huang,Anda Cheng,Yinggui Wang,Lei Wang,Tao Wei*

Main category: cs.LG

TL;DR: 提出 LLM-AutoDP 框架，利用大语言模型作为智能体自动生成和优化数据处理策略，通过迭代上下文学习机制在不直接接触原始数据的情况下提升数据质量。引入分布保持采样、处理目标选择和缓存复用机制，显著加速策略搜索过程，实验表明该方法在性能上优于未处理数据训练的模型（>80%胜率），且相比基于 LLM 的 AutoML 基线提升约 65% 胜率，同时将搜索时间减少最多 10 倍。


<details>
  <summary>Details</summary>
Motivation: 现有领域数据处理依赖人工迭代调试，成本高且在医疗等高隐私领域存在数据泄露风险，亟需无需暴露原始数据的自动化数据处理方法。

Method: 设计 LLM-AutoDP 框架，利用大语言模型作为智能体生成多候选策略并基于反馈与对比评估进行迭代优化；结合分布保持采样、低质样本识别（处理目标选择）和结果缓存复用三项技术加速搜索过程。

Result: 经框架处理的数据训练的模型在对抗未处理数据模型时胜率超过 80%，相较基于 LLM 的 AutoML 基线提升约 65%；加速技术使总搜索时间缩短至原来的 1/10。

Conclusion: LLM-AutoDP 实现了高效、安全、自动化的数据处理，无需人工干预或直接访问敏感数据，在保证数据质量的同时大幅降低时间与人力成本，适用于高隐私领域。

Abstract: Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields. However, such data often contains numerous low-quality samples, necessitating effective data processing (DP). In practice, DP strategies are typically developed through iterative manual analysis and trial-and-error adjustment. These processes inevitably incur high labor costs and may lead to privacy issues in high-privacy domains like healthcare due to direct human access to sensitive data. Thus, achieving automated data processing without exposing the raw data has become a critical challenge. To address this challenge, we propose LLM-AutoDP, a novel framework that leverages LLMs as agents to automatically generate and optimize data processing strategies. Our method generates multiple candidate strategies and iteratively refines them using feedback signals and comparative evaluations. This iterative in-context learning mechanism enables the agent to converge toward high-quality processing pipelines without requiring direct human intervention or access to the underlying data. To further accelerate strategy search, we introduce three key techniques: Distribution Preserving Sampling, which reduces data volume while maintaining distributional integrity; Processing Target Selection, which uses a binary classifier to identify low-quality samples for focused processing; Cache-and-Reuse Mechanism}, which minimizes redundant computations by reusing prior processing results. Results show that models trained on data processed by our framework achieve over 80% win rates against models trained on unprocessed data. Compared to AutoML baselines based on LLM agents, LLM-AutoDP achieves approximately a 65% win rate. Moreover, our acceleration techniques reduce the total searching time by up to 10 times, demonstrating both effectiveness and efficiency.

</details>


### [152] [FedRD: Reducing Divergences for Generalized Federated Learning via Heterogeneity-aware Parameter Guidance](https://arxiv.org/abs/2601.20397)
*Kaile Wang,Jiannong Cao,Yu Yang,Xiaoyin Li,Mingjin Zhang*

Main category: cs.LG

TL;DR: 提出FedRD算法，通过参数引导的全局泛化聚合和局部去偏分类，解决异构联邦学习中的优化发散和性能发散问题，显著提升对已知及未见客户端的模型表现。


<details>
  <summary>Details</summary>
Motivation: 解决异构联邦学习中新增客户端难以快速适配现有系统的问题，尤其是在数据异构背景下模型泛化能力不足的挑战。

Method: 引入参数引导的全局泛化聚合与局部去偏分类机制，协同优化全局模型以减少优化和性能发散。

Result: 在多个公开多域数据集上的实验表明，所提方法在处理未见客户端时显著优于现有基线方法。

Conclusion: FedRD能够有效提升异构联邦学习中对参与及未见客户端的泛化性能，是应对数据异构性挑战的有效解决方案。

Abstract: Heterogeneous federated learning (HFL) aims to ensure effective and privacy-preserving collaboration among different entities. As newly joined clients require significant adjustments and additional training to align with the existing system, the problem of generalizing federated learning models to unseen clients under heterogeneous data has become progressively crucial. Consequently, we highlight two unsolved challenging issues in federated domain generalization: Optimization Divergence and Performance Divergence. To tackle the above challenges, we propose FedRD, a novel heterogeneity-aware federated learning algorithm that collaboratively utilizes parameter-guided global generalization aggregation and local debiased classification to reduce divergences, aiming to obtain an optimal global model for participating and unseen clients. Extensive experiments on public multi-domain datasets demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.

</details>


### [153] [ScatterFusion: A Hierarchical Scattering Transform Framework for Enhanced Time Series Forecasting](https://arxiv.org/abs/2601.20401)
*Wei Li*

Main category: cs.LG

TL;DR: ScatterFusion是一种新颖的时序预测框架，通过结合散射变换与分层注意力机制，有效捕捉多尺度时间依赖性。其核心包括：多尺度不变特征提取（HSTM）、动态特征增强（SAFE）、多分辨率时间注意力（MRTA）以及基于趋势-季节-残差分解的损失函数。在七个基准数据集上的实验表明，该方法在多种预测时长下均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 时序预测面临复杂多尺度时间依赖性的挑战，传统方法难以同时捕捉局部与全局模式，且对不同时间尺度的特征重要性缺乏自适应调整能力。因此需要一种能有效融合多尺度特征并动态优化注意力分配的新框架。

Method: 提出ScatterFusion框架，包含四个模块：(1) 分层散射变换模块（HSTM）用于提取多尺度不变特征；(2) 尺度自适应特征增强（SAFE）模块动态调整各尺度特征权重；(3) 多分辨率时间注意力（MRTA）机制建模不同时间窗口的依赖关系；(4) 基于趋势-季节-残差（TSR）分解的结构感知损失函数，提升模型对时序结构的理解。

Result: 在七个公开基准数据集上进行的大量实验显示，ScatterFusion在多个预测时长下均显著降低误差指标（如MAE、RMSE），优于主流时序预测方法，证明其在鲁棒性和泛化能力上的优势。

Conclusion: ScatterFusion通过融合散射变换与分层注意力机制，成功实现了对多尺度时序模式的高效建模，具备更强的表达能力和预测精度，为复杂时序预测任务提供了新范式。

Abstract: Time series forecasting presents significant challenges due to the complex temporal dependencies at multiple time scales. This paper introduces ScatterFusion, a novel framework that synergistically integrates scattering transforms with hierarchical attention mechanisms for robust time series forecasting. Our approach comprises four key components: (1) a Hierarchical Scattering Transform Module (HSTM) that extracts multi-scale invariant features capturing both local and global patterns; (2) a Scale-Adaptive Feature Enhancement (SAFE) module that dynamically adjusts feature importance across different scales; (3) a Multi-Resolution Temporal Attention (MRTA) mechanism that learns dependencies at varying time horizons; and (4) a Trend-Seasonal-Residual (TSR) decomposition-guided structure-aware loss function. Extensive experiments on seven benchmark datasets demonstrate that ScatterFusion outperforms other common methods, achieving significant reductions in error metrics across various prediction horizons.

</details>


### [154] [Concept Component Analysis: A Principled Approach for Concept Extraction in LLMs](https://arxiv.org/abs/2601.20420)
*Yuhang Liu,Erdun Gao,Dong Gong,Anton van den Hengel,Javen Qinfeng Shi*

Main category: cs.LG

TL;DR: 本文提出了一种基于潜在变量模型的理论框架——概念成分分析（ConCA），用于从大语言模型（LLM）表示中提取人类可理解的概念。该方法通过将LLM表示近似为概念后验概率的线性混合，实现了对概念的无监督线性解混，并结合稀疏性先验解决解混问题的病态性。实验验证了12种稀疏ConCA变体在多个LLM上的有效性，证明其相较于稀疏自编码器（SAEs）具有理论支持的优势。


<details>
  <summary>Details</summary>
Motivation: 当前稀疏自编码器（SAEs）虽能提取可解释概念，但缺乏理论基础，导致方法设计和评估标准不明确。因此亟需一个具有理论支撑的概念提取框架，以提升解释性与可复现性。

Method: 基于潜在变量模型，假设概念为隐变量，推导出LLM表示可近似为概念后验概率的线性组合；进而提出概念成分分析（ConCA）框架，采用无监督线性解混恢复各概念的对数后验；进一步引入稀疏性先验构建稀疏ConCA，以应对解混问题的不稳定性。

Result: 12种稀疏ConCA变体在多个大语言模型上成功提取出有意义且可解释的概念，其性能优于传统SAEs，且具备更强的理论依据。

Conclusion: 本文提出的稀疏ConCA框架为大语言模型的机制可解释性提供了坚实的理论基础，显著提升了概念提取的可解释性与可靠性，是迈向可信人工智能的重要一步。

Abstract: Developing human understandable interpretation of large language models (LLMs) becomes increasingly critical for their deployment in essential domains. Mechanistic interpretability seeks to mitigate the issues through extracts human-interpretable process and concepts from LLMs' activations. Sparse autoencoders (SAEs) have emerged as a popular approach for extracting interpretable and monosemantic concepts by decomposing the LLM internal representations into a dictionary. Despite their empirical progress, SAEs suffer from a fundamental theoretical ambiguity: the well-defined correspondence between LLM representations and human-interpretable concepts remains unclear. This lack of theoretical grounding gives rise to several methodological challenges, including difficulties in principled method design and evaluation criteria. In this work, we show that, under mild assumptions, LLM representations can be approximated as a {linear mixture} of the log-posteriors over concepts given the input context, through the lens of a latent variable model where concepts are treated as latent variables. This motivates a principled framework for concept extraction, namely Concept Component Analysis (ConCA), which aims to recover the log-posterior of each concept from LLM representations through a {unsupervised} linear unmixing process. We explore a specific variant, termed sparse ConCA, which leverages a sparsity prior to address the inherent ill-posedness of the unmixing problem. We implement 12 sparse ConCA variants and demonstrate their ability to extract meaningful concepts across multiple LLMs, offering theory-backed advantages over SAEs.

</details>


### [155] [Nonlinear Dimensionality Reduction with Diffusion Maps in Practice](https://arxiv.org/abs/2601.20428)
*Sönke Beier,Paula Pirker-Díaz,Friedrich Pagenkopf,Karoline Wiesner*

Main category: cs.LG

TL;DR: 本文提供了一个面向实践的扩散映射（Diffusion Map）技术综述，重点讨论了数据预处理、参数设置和组件选择对结果流形的影响，并揭示了前几个成分未必是最相关的问题。


<details>
  <summary>Details</summary>
Motivation: 扩散映射在高维数据中揭示非线性子流形方面具有广泛应用，但其效果受数据预处理、参数设置和组件选择显著影响，而这些因素在现有文献中尚未得到充分探讨。

Method: 通过回顾扩散映射的基本原理，结合实际案例分析常见误区，并引入一种新方法来识别最相关的成分。

Result: 研究发现，扩散映射的前几个主成分并不总是最具信息量或最相关的；正确选择关键成分对准确揭示数据内在结构至关重要。

Conclusion: 扩散映射的有效应用依赖于谨慎的数据预处理与合理的组件选择，不能简单依赖前几成分。应采用更科学的方法评估各成分的重要性。

Abstract: Diffusion Map is a spectral dimensionality reduction technique which is able to uncover nonlinear submanifolds in high-dimensional data. And, it is increasingly applied across a wide range of scientific disciplines, such as biology, engineering, and social sciences. But data preprocessing, parameter settings and component selection have a significant influence on the resulting manifold, something which has not been comprehensively discussed in the literature so far. We provide a practice oriented review of the Diffusion Map technique, illustrate pitfalls and showcase a recently introduced technique for identifying the most relevant components. Our results show that the first components are not necessarily the most relevant ones.

</details>


### [156] [Fair Recourse for All: Ensuring Individual and Group Fairness in Counterfactual Explanations](https://arxiv.org/abs/2601.20449)
*Fatima Ezzeddine,Obaida Ammar,Silvia Giordano,Omran Ayoub*

Main category: cs.LG

TL;DR: 本文提出一种基于强化学习的模型无关方法，用于生成满足个体公平性、群体公平性及混合公平性的反事实解释（CFs），以确保相似个体和不同受保护群体获得相似且可操作的决策建议。通过优化框架整合多种公平性度量，实现在保持反事实解释质量（如接近性和合理性）的同时，量化不同公平性层级的成本。


<details>
  <summary>Details</summary>
Motivation: 在可解释人工智能（XAI）中，反事实解释能为用户提供可操作的决策改进建议，但现有方法往往忽视个体与群体间的公平性差异，可能导致对不同背景用户产生不公正的回复。因此，亟需在生成反事实解释时同时保障个体公平和群体公平，以提升决策系统的可信度与公平性。

Method: 提出一个基于强化学习的模型无关框架，将公平性约束建模为优化问题，引入个体公平、群体公平及混合公平三种公平性定义，并扩展传统公平性度量（如等效可操作性、等效有效性）以评估跨个体与跨群体的公平表现。

Result: 在三个基准数据集上的实验表明，所提方法能有效实现个体与群体公平性，同时保持反事实解释在接近性与合理性方面的高质量；并首次量化了不同公平性层次所带来的性能代价，揭示了公平性权衡的实际影响。

Conclusion: 本研究推动了反事实解释中的公平性研究，提出混合公平性概念，强调其在可解释人工智能中的关键作用，为未来公平、透明的AI系统设计提供新思路。

Abstract: Explainable Artificial Intelligence (XAI) is becoming increasingly essential for enhancing the transparency of machine learning (ML) models. Among the various XAI techniques, counterfactual explanations (CFs) hold a pivotal role due to their ability to illustrate how changes in input features can alter an ML model's decision, thereby offering actionable recourse to users. Ensuring that individuals with comparable attributes and those belonging to different protected groups (e.g., demographic) receive similar and actionable recourse options is essential for trustworthy and fair decision-making. In this work, we address this challenge directly by focusing on the generation of fair CFs. Specifically, we start by defining and formulating fairness at: 1) individual fairness, ensuring that similar individuals receive similar CFs, 2) group fairness, ensuring equitable CFs across different protected groups and 3) hybrid fairness, which accounts for both individual and broader group-level fairness. We formulate the problem as an optimization task and propose a novel model-agnostic, reinforcement learning based approach to generate CFs that satisfy fairness constraints at both the individual and group levels, two objectives that are usually treated as orthogonal. As fairness metrics, we extend existing metrics commonly used for auditing ML models, such as equal choice of recourse and equal effectiveness across individuals and groups. We evaluate our approach on three benchmark datasets, showing that it effectively ensures individual and group fairness while preserving the quality of the generated CFs in terms of proximity and plausibility, and quantify the cost of fairness in the different levels separately. Our work opens a broader discussion on hybrid fairness and its role and implications for XAI and beyond CFs.

</details>


### [157] [CCMamba: Selective State-Space Models for Higher-Order Graph Learning on Combinatorial Complexes](https://arxiv.org/abs/2601.20518)
*Jiawen Chen,Qi Shao,Mingtong Zhou,Duxin Chen,Wenwu Yu*

Main category: cs.LG

TL;DR: CCMamba 是首个基于 Mamba 的统一神经框架，用于在组合复形上学习。它将消息传递重新表述为选择性状态空间建模问题，通过结构化序列处理多秩关联，实现线性时间内的自适应、方向性和长距离信息传播，无需自注意力机制。理论分析表明其表达能力上限达到 1-Weisfeiler-Lehman 测试。在图、超图和单纯复形基准上的实验显示，CCMamba 始终优于现有方法，且具有更好的可扩展性和深度鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑深度学习方法依赖局部消息传递和注意力机制，存在二次复杂度、维度受限、难以捕捉高阶关系的问题，限制了在组合复形上的可扩展性和信息聚合能力。

Method: 将多秩关联组织成结构化序列，利用秩感知状态空间模型替代传统注意力机制，实现选择性、方向性和长距离信息传播，构建基于 Mamba 的统一框架。

Result: 在图、超图和单纯复形任务上均表现更优，具备线性时间复杂度、更强的可扩展性与深度鲁棒性，理论表达能力达到 1-Weisfeiler-Lehman 测试上限。

Conclusion: CCMamba 首次实现了基于 Mamba 的组合复形统一学习框架，突破了传统方法在复杂度与表达能力上的瓶颈，为高阶关系建模提供了高效且强大的新范式。

Abstract: Topological deep learning has emerged for modeling higher-order relational structures beyond pairwise interactions that standard graph neural networks fail to capture. Although combinatorial complexes offer a unified topological framework, most existing topological deep learning methods rely on local message passing via attention mechanisms, which incur quadratic complexity and remain low-dimensional, limiting scalability and rank-aware information aggregation in higher-order complexes.We propose Combinatorial Complex Mamba (CCMamba), the first unified mamba-based neural framework for learning on combinatorial complexes. CCMamba reformulates message passing as a selective state-space modeling problem by organizing multi-rank incidence relations into structured sequences processed by rank-aware state-space models. This enables adaptive, directional, and long range information propagation in linear time without self attention. We further establish the theoretical analysis that the expressive power upper-bound of CCMamba message passing is the 1-Weisfeiler-Lehman test. Experiments on graph, hypergraph, and simplicial benchmarks demonstrate that CCMamba consistently outperforms existing methods while exhibiting improved scalability and robustness to depth.

</details>


### [158] [Detecting and Mitigating Memorization in Diffusion Models through Anisotropy of the Log-Probability](https://arxiv.org/abs/2601.20642)
*Rohan Asthana,Vasileios Belagiannis*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型的新型记忆检测方法，结合各向同性范数与各向异性对齐，可在纯噪声输入上通过两次前向传播快速检测记忆现象，显著提升速度与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有记忆检测方法依赖于得分差的范数，但该方法在低噪声条件下效果不佳，因缺乏对各向异性特征的考虑。需要一种更高效、准确且无需去噪步骤的检测机制。

Method: 通过分析高/中噪声下各向同性分布与低噪声下各向异性特征的关系，提出融合范数与角度对齐的检测指标，仅需两次前向传播即可完成检测。

Result: 在Stable Diffusion v1.4和v2上实验表明，新方法优于现有无去噪检测方法，且至少快5倍；同时可有效指导提示词自适应以缓解记忆问题。

Conclusion: 所提方法为高效、准确的扩散模型记忆检测提供了新范式，兼具实用性与可扩展性，适用于实际部署中的隐私保护与内容安全。

Abstract: Diffusion-based image generative models produce high-fidelity images through iterative denoising but remain vulnerable to memorization, where they unintentionally reproduce exact copies or parts of training images. Recent memorization detection methods are primarily based on the norm of score difference as indicators of memorization. We prove that such norm-based metrics are mainly effective under the assumption of isotropic log-probability distributions, which generally holds at high or medium noise levels. In contrast, analyzing the anisotropic regime reveals that memorized samples exhibit strong angular alignment between the guidance vector and unconditional scores in the low-noise setting. Through these insights, we develop a memorization detection metric by integrating isotropic norm and anisotropic alignment. Our detection metric can be computed directly on pure noise inputs via two conditional and unconditional forward passes, eliminating the need for costly denoising steps. Detection experiments on Stable Diffusion v1.4 and v2 show that our metric outperforms existing denoising-free detection methods while being at least approximately 5x faster than the previous best approach. Finally, we demonstrate the effectiveness of our approach by utilizing a mitigation strategy that adapts memorized prompts based on our developed metric.

</details>


### [159] [Unsupervised Ensemble Learning Through Deep Energy-based Models](https://arxiv.org/abs/2601.20556)
*Ariel Maymon,Yanir Buznah,Uri Shaham*

Main category: cs.LG

TL;DR: 提出了一种基于深度能量的无监督集成学习方法，仅利用个体学习器的预测结果构建高精度元学习器，无需标签数据、学习器特征或问题特定信息，在学习器条件独立时具有理论保证。在多种集成场景（包括复杂的专家混合设置）中表现优异，适用于数据稀缺或隐私敏感环境。


<details>
  <summary>Details</summary>
Motivation: 解决在缺乏真实标签或额外数据的情况下，如何有效融合多个学习器预测结果的挑战，尤其在无法评估单个分类器性能或理解其优势的情境下。

Method: 提出一种基于深度能量的无监督集成学习方法，通过分析个体学习器的预测结果来构建元学习器，能够捕捉学习器间的复杂依赖关系，且不依赖于标签数据、学习器特征或问题特定信息。

Result: 在标准集成数据集和专门设计的测试数据集上均表现出色，特别是在混合专家等复杂场景中优于现有方法，验证了该方法在数据稀缺或隐私敏感场景下的潜力。

Conclusion: 无监督集成学习能够有效利用集体智能，尤其在缺乏标注数据或隐私限制的环境中展现出巨大应用前景。

Abstract: Unsupervised ensemble learning emerged to address the challenge of combining multiple learners' predictions without access to ground truth labels or additional data. This paradigm is crucial in scenarios where evaluating individual classifier performance or understanding their strengths is challenging due to limited information. We propose a novel deep energy-based method for constructing an accurate meta-learner using only the predictions of individual learners, potentially capable of capturing complex dependence structures between them. Our approach requires no labeled data, learner features, or problem-specific information, and has theoretical guarantees for when learners are conditionally independent. We demonstrate superior performance across diverse ensemble scenarios, including challenging mixture of experts settings. Our experiments span standard ensemble datasets and curated datasets designed to test how the model fuses expertise from multiple sources. These results highlight the potential of unsupervised ensemble learning to harness collective intelligence, especially in data-scarce or privacy-sensitive environments.

</details>


### [160] [Reinforcement Unlearning via Group Relative Policy Optimization](https://arxiv.org/abs/2601.20568)
*Efstratios Zaradoukas,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.LG

TL;DR: PURGE是一种基于组相对策略优化框架的新颖遗忘方法，将遗忘问题形式化为可验证的任务，利用内在奖励信号惩罚对禁止概念的提及，实现安全且一致的遗忘。相比现有最佳方法，PURGE在每目标词元使用上减少达46倍，同时提升流畅性5.48%、对抗鲁棒性12.02%，在RWKU基准上实现11%的遗忘效果并保留98%原始效用，表明其在理论保证、安全性与部署效率上的显著优势。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在预训练过程中会无意中记忆敏感或受版权保护的数据，违反如GDPR和欧盟人工智能法案等法律框架。现有遗忘方法存在数据泄露、牺牲流畅性与鲁棒性或依赖昂贵外部奖励模型等问题，亟需一种无需从头再训练即可有效删除信息且安全可靠的遗忘技术。

Method: PURGE基于组相对策略优化框架，将遗忘建模为一个可验证的问题，通过设计内在奖励信号来惩罚模型对禁止概念的提及，从而实现无须外部监督的高效、安全遗忘。该方法通过相对组间比较优化策略，确保遗忘过程可控且可验证。

Result: PURGE在减少每目标词元使用量上达到现有最佳方法的46倍改进；在流畅性上提升5.48%，对抗鲁棒性提升12.02%；在Real World Knowledge Unlearning（RWKU）基准测试中实现11%的遗忘效果，并保留98%的原始模型效用，表现出卓越的性能与实用性。

Conclusion: 将大语言模型遗忘问题形式化为可验证任务，不仅提升了遗忘的可靠性、效率与可扩展性，也为未来研究提供了结合理论保障、安全性和实际部署效率的新方向。

Abstract: During pretraining, LLMs inadvertently memorize sensitive or copyrighted data, posing significant compliance challenges under legal frameworks like the GDPR and the EU AI Act. Fulfilling these mandates demands techniques that can remove information from a deployed model without retraining from scratch. Existing unlearning approaches attempt to address this need, but often leak the very data they aim to erase, sacrifice fluency and robustness, or depend on costly external reward models. We introduce PURGE (Policy Unlearning through Relative Group Erasure), a novel method grounded in the Group Relative Policy Optimization framework that formulates unlearning as a verifiable problem. PURGE uses an intrinsic reward signal that penalizes any mention of forbidden concepts, allowing safe and consistent unlearning. Our approach reduces token usage per target by up to a factor of 46 compared with SotA methods, while improving fluency by 5.48 percent and adversarial robustness by 12.02 percent over the base model. On the Real World Knowledge Unlearning (RWKU) benchmark, PURGE achieves 11 percent unlearning effectiveness while preserving 98 percent of original utility. PURGE shows that framing LLM unlearning as a verifiable task, enables more reliable, efficient, and scalable forgetting, suggesting a promising new direction for unlearning research that combines theoretical guarantees, improved safety, and practical deployment efficiency.

</details>


### [161] [Robust Distributed Learning under Resource Constraints: Decentralized Quantile Estimation via (Asynchronous) ADMM](https://arxiv.org/abs/2601.20571)
*Anna van Elst,Igor Colin,Stephan Clémençon*

Main category: cs.LG

TL;DR: 本文提出AsylADMM，一种用于去中心化中位数和分位数估计的新型广播算法，专为异步更新设计，每个节点仅需两个变量，内存占用低。通过分析同步版本建立了理论保证，并实证证明了异步算法的快速收敛性。该算法支持基于分位数的修剪、几何中位数估计和深度修剪，其中基于分位数的修剪在实验中优于现有基于秩的方法。此外，文章还基于马尔可夫链理论提供了对基于秩修剪的新颖理论分析。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上进行去中心化学习需要通信高效、对数据污染鲁棒且内存占用轻的算法。现有基于广播的方法虽通信高效，但难以实现鲁棒性；而现有的异步去中心化ADMM方法虽然能估计中位数，但其内存需求随节点度数增长，不适用于内存受限场景。

Method: 提出AsylADMM算法，一种专为异步更新设计的去中心化中位数与分位数估计方法，每个节点仅维护两个变量，显著降低内存开销。通过分析其同步版本建立理论收敛性，同时通过实验验证异步版本的快速收敛性。进一步扩展至支持量化修剪、几何中位数估计和深度修剪，并引入基于马尔可夫链的理论分析框架以解释秩相关修剪机制。

Result: AsylADMM在保持低内存使用的同时实现了快速收敛，且在异步环境下表现良好；基于分位数的修剪方法在实际性能上优于传统秩基方法；理论分析揭示了秩基修剪的动态行为，增强了对算法稳健性的理解。

Conclusion: AsylADMM是一种高效、鲁棒且内存友好的去中心化分位数估计算法，适用于资源受限的边缘计算环境。其在异步更新下的优异表现及对多种统计估计任务的支持，展示了其在实际系统中的广泛应用潜力。

Abstract: Specifications for decentralized learning on resource-constrained edge devices require algorithms that are communication-efficient, robust to data corruption, and lightweight in memory usage. While state-of-the-art gossip-based methods satisfy the first requirement, achieving robustness remains challenging. Asynchronous decentralized ADMM-based methods have been explored for estimating the median, a statistical centrality measure that is notoriously more robust than the mean. However, existing approaches require memory that scales with node degree, making them impractical when memory is limited. In this paper, we propose AsylADMM, a novel gossip algorithm for decentralized median and quantile estimation, primarily designed for asynchronous updates and requiring only two variables per node. We analyze a synchronous variant of AsylADMM to establish theoretical guarantees and empirically demonstrate fast convergence for the asynchronous algorithm. We then show that our algorithm enables quantile-based trimming, geometric median estimation, and depth-based trimming, with quantile-based trimming empirically outperforming existing rank-based methods. Finally, we provide a novel theoretical analysis of rank-based trimming via Markov chain theory.

</details>


### [162] [Ranking-aware Reinforcement Learning for Ordinal Ranking](https://arxiv.org/abs/2601.20585)
*Aiming Hao,Chen Zhu,Jiashu Zhu,Jiahong Wu,Xiangxiang Chu*

Main category: cs.LG

TL;DR: RARL is a novel reinforcement learning framework for ordinal regression and ranking that unifies regression and Learning-to-Rank through a ranking-aware reward, improving both tasks synergistically. It uses Response Mutation Operations to enhance exploration and avoid stagnation, showing strong performance across three benchmarks.


<details>
  <summary>Details</summary>
Motivation: Conventional methods fail to adequately model the inherent ordinal dependencies in ordinal regression and ranking tasks, leading to suboptimal performance.

Method: RARL introduces a unified objective combining regression and L2R, guided by a ranking-aware verifiable reward that evaluates both precision and ranking accuracy. It employs Response Mutation Operations (RMO) to inject controlled noise and improve exploration during training.

Result: Extensive experiments on three distinct benchmarks demonstrate the effectiveness of RARL, showing superior performance compared to conventional approaches.

Conclusion: RARL effectively captures ordinal dependencies by synergistically integrating regression and ranking, with enhanced training dynamics through RMO, leading to improved overall performance.

Abstract: Ordinal regression and ranking are challenging due to inherent ordinal dependencies that conventional methods struggle to model. We propose Ranking-Aware Reinforcement Learning (RARL), a novel RL framework that explicitly learns these relationships. At its core, RARL features a unified objective that synergistically integrates regression and Learning-to-Rank (L2R), enabling mutual improvement between the two tasks. This is driven by a ranking-aware verifiable reward that jointly assesses regression precision and ranking accuracy, facilitating direct model updates via policy optimization. To further enhance training, we introduce Response Mutation Operations (RMO), which inject controlled noise to improve exploration and prevent stagnation at saddle points. The effectiveness of RARL is validated through extensive experiments on three distinct benchmarks.

</details>


### [163] [Regularized Gradient Temporal-Difference Learning](https://arxiv.org/abs/2601.20599)
*Hyunjun Na,Donghwan Lee*

Main category: cs.LG

TL;DR: 本文提出了一种正则化的优化目标，通过重新表述均方投影贝尔曼误差（MSPBE）最小化问题，得到了一种新的正则化梯度时差（R-GTD）算法。该方法在特征交互矩阵（FIM）奇异的情况下仍能保证收敛到唯一解，克服了现有GTD算法依赖于FIM非奇异这一限制性假设的问题。理论分析提供了收敛性保证和明确的误差界，并通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有GTD学习算法在进行离策略策略评估时，其收敛性分析依赖于特征交互矩阵（FIM）必须是非奇异的假设，但在实际应用中，该矩阵可能奇异，导致算法不稳定或性能下降。因此，亟需一种在FIM奇异情况下仍能稳定收敛的方法。

Method: 通过重新构建均方投影贝尔曼误差（MSPBE）最小化问题，引入正则化项，形成新的正则化优化目标，从而导出R-GTD算法。该方法在数学上确保即使在FIM奇异时也能收敛至唯一解。

Result: 所提出的R-GTD算法在理论上具有收敛性保证，并给出了明确的误差边界；实验结果表明，该方法在多种场景下均表现出良好的稳定性与有效性，尤其在FIM奇异时优于传统GTD算法。

Conclusion: R-GTD算法通过正则化设计，有效解决了传统GTD算法在特征交互矩阵奇异时的收敛性问题，提升了算法在实际应用中的鲁棒性和可靠性，为离策略策略评估提供了一种更稳健的解决方案。

Abstract: Gradient temporal-difference (GTD) learning algorithms are widely used for off-policy policy evaluation with function approximation. However, existing convergence analyses rely on the restrictive assumption that the so-called feature interaction matrix (FIM) is nonsingular. In practice, the FIM can become singular and leads to instability or degraded performance. In this paper, we propose a regularized optimization objective by reformulating the mean-square projected Bellman error (MSPBE) minimization. This formulation naturally yields a regularized GTD algorithms, referred to as R-GTD, which guarantees convergence to a unique solution even when the FIM is singular. We establish theoretical convergence guarantees and explicit error bounds for the proposed method, and validate its effectiveness through empirical experiments.

</details>


### [164] [WFR-MFM: One-Step Inference for Dynamic Unbalanced Optimal Transport](https://arxiv.org/abs/2601.20606)
*Xinyu Wang,Ruoyu Wang,Qiangwei Peng,Peijie Zhou,Tiejun Li*

Main category: cs.LG

TL;DR: 提出了一种基于均值流的非平衡流匹配框架（WFR-MFM），通过引入平均速度和质量增长场，实现单步生成，显著加速推理过程，在合成与真实单细胞数据上均表现出高精度和高效性，支持大规模扰动响应预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于推断时的轨迹模拟，导致推理效率低下，难以扩展到大规模应用；需要一种无需轨迹模拟即可快速重建动态演化过程的方法。

Method: 提出均值流框架，利用平均速度和质量增长场描述任意时间间隔内的传输与质量变化动态，并基于Wasserstein-Fisher-Rao几何构建WFR-MFM模型，实现一歩生成。

Result: 在合成与真实单细胞RNA测序数据集上，WFR-MFM比多种基线方法快几个数量级，保持高预测精度，并成功应用于包含数千种条件的大规模扰动响应预测。

Conclusion: WFR-MFM提供了一种高效且准确的动态演化重建方法，突破了传统轨迹模拟的瓶颈，为大规模单细胞数据分析提供了新工具。

Abstract: Reconstructing dynamical evolution from limited observations is a fundamental challenge in single-cell biology, where dynamic unbalanced optimal transport provides a principled framework for modeling coupled transport and mass variation. However, existing approaches rely on trajectory simulation at inference time, making inference a key bottleneck for scalable applications. In this work, we propose a mean-flow framework for unbalanced flow matching that summarizes both transport and mass-growth dynamics over arbitrary time intervals using mean velocity and mass-growth fields, enabling fast one-step generation without trajectory simulation. To solve dynamic unbalanced optimal transport under the Wasserstein-Fisher-Rao geometry, we further build on this framework to develop Wasserstein-Fisher-Rao Mean Flow Matching (WFR-MFM). Across synthetic and real single-cell RNA sequencing datasets, WFR-MFM achieves orders-of-magnitude faster inference than a range of existing baselines while maintaining high predictive accuracy, and enables efficient perturbation response prediction on large synthetic datasets with thousands of conditions.

</details>


### [165] [ACFormer: Mitigating Non-linearity with Auto Convolutional Encoder for Time Series Forecasting](https://arxiv.org/abs/2601.20611)
*Gawon Lee,Hanbyeol Park,Minseop Kim,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: ACFormer提出一种新架构，结合线性投影的高效性与卷积的非线性特征提取能力，通过共享压缩模块、门控注意力和独立补丁扩展层，有效捕捉时间序列中的细粒度信息与变量特异性模式，在多个基准数据集上实现领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有线性模型在处理非线性信号时表现不佳，而传统CNN虽能捕捉复杂依赖关系但效率较低；需在保持效率的同时增强对非线性波动的建模能力。

Method: 通过分析CNN时间序列模型的接受域，引入‘个体接受域’概念揭示通道间结构依赖；提出ACFormer，包含共享压缩模块（捕获细粒度信息）、门控注意力（保留时间局部性）和独立补丁扩展层（重构变量特异性模式）。

Result: 在多个基准数据集上，ACFormer均达到或超越现有方法的性能，尤其在高频率成分建模方面显著优于传统线性模型。

Conclusion: ACFormer成功融合了线性模型的高效性与卷积的非线性表达能力，为时间序列预测提供了更优的结构设计范式。

Abstract: Time series forecasting (TSF) faces challenges in modeling complex intra-channel temporal dependencies and inter-channel correlations. Although recent research has highlighted the efficiency of linear architectures in capturing global trends, these models often struggle with non-linear signals. To address this gap, we conducted a systematic receptive field analysis of convolutional neural network (CNN) TSF models. We introduce the "individual receptive field" to uncover granular structural dependencies, revealing that convolutional layers act as feature extractors that mirror channel-wise attention while exhibiting superior robustness to non-linear fluctuations. Based on these insights, we propose ACFormer, an architecture designed to reconcile the efficiency of linear projections with the non-linear feature-extraction power of convolutions. ACFormer captures fine-grained information through a shared compression module, preserves temporal locality via gated attention, and reconstructs variable-specific temporal patterns using an independent patch expansion layer. Extensive experiments on multiple benchmark datasets demonstrate that ACFormer consistently achieves state-of-the-art performance, effectively mitigating the inherent drawbacks of linear models in capturing high-frequency components.

</details>


### [166] [DIVERSE: Disagreement-Inducing Vector Evolution for Rashomon Set Exploration](https://arxiv.org/abs/2601.20627)
*Gilles Eerlings,Brent Zoomers,Jori Liesenborgs,Gustavo Rovelo Ruiz,Kris Luyten*

Main category: cs.LG

TL;DR: DIVERSE is a framework that explores the Rashomon set of deep neural networks—models with similar accuracy but different behaviors—by adding FiLM layers to a pretrained model and using CMA-ES to search latent modulation space. It generates diverse models without retraining or gradient access, achieving comparable diversity to retraining at lower computational cost across MNIST, PneumoniaMNIST, and CIFAR-10.


<details>
  <summary>Details</summary>
Motivation: Existing methods for generating diverse models in the Rashomon set require retraining or gradient access, which are computationally expensive and impractical for large models. The motivation is to enable efficient, scalable exploration of functionally distinct yet high-performing models without retraining.

Method: DIVERSE augments a pretrained model with Feature-wise Linear Modulation (FiLM) layers and employs Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to explore the latent modulation space, generating diverse model variants through parameter modulation rather than training.

Result: DIVERSE successfully discovers multiple high-performing, functionally distinct models on MNIST, PneumoniaMNIST, and CIFAR-10. It achieves diversity comparable to retraining but with significantly reduced computational cost.

Conclusion: DIVERSE provides an efficient and effective method for exploring the Rashomon set, enabling robust, diverse model ensembles without retraining, thus supporting model multiplicity and improved system robustness.

Abstract: We propose DIVERSE, a framework for systematically exploring the Rashomon set of deep neural networks, the collection of models that match a reference model's accuracy while differing in their predictive behavior. DIVERSE augments a pretrained model with Feature-wise Linear Modulation (FiLM) layers and uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to search a latent modulation space, generating diverse model variants without retraining or gradient access. Across MNIST, PneumoniaMNIST, and CIFAR-10, DIVERSE uncovers multiple high-performing yet functionally distinct models. Our experiments show that DIVERSE offers a competitive and efficient exploration of the Rashomon set, making it feasible to construct diverse sets that maintain robustness and performance while supporting well-balanced model multiplicity. While retraining remains the baseline to generate Rashomon sets, DIVERSE achieves comparable diversity at reduced computational cost.

</details>


### [167] [An Empirical Investigation of Neural ODEs and Symbolic Regression for Dynamical Systems](https://arxiv.org/abs/2601.20637)
*Panayiotis Ioannou,Pietro Liò,Pietro Cicuta*

Main category: cs.LG

TL;DR: 该研究探讨了神经微分方程（NODEs）在复杂系统动态建模中的外推能力，以及符号回归（SR）从噪声数据中恢复微分方程的能力。结果表明，NODEs可在动态相似的条件下有效外推至新边界条件；SR在正确选择输入变量时能成功恢复真实方程；即使仅用10%模拟数据训练的NODE生成的数据，也能使SR恢复出大部分物理方程，表明结合NODE与SR是发现科学规律的有前景方法。


<details>
  <summary>Details</summary>
Motivation: 准确建模复杂系统的动态行为并发现其背后的微分方程对加速科学发现至关重要。传统方法在处理噪声数据和数据稀缺问题时存在局限，因此需要探索更鲁棒且高效的新方法。

Method: 使用来自两个阻尼振荡系统的合成噪声数据，评估神经微分方程（NODEs）的外推性能，并测试符号回归（SR）在不同条件下恢复真实微分方程的能力。此外，还考察了用少量数据训练的NODE生成的数据是否可作为SR的输入以提升方程发现效果。

Result: 1. NODEs可在动态相似的前提下有效外推至新边界条件；2. SR在输入变量选择正确的前提下可成功恢复真实方程；3. 即使仅基于10%数据训练的NODE生成的数据，SR仍能恢复出两个完整方程及第三个的良好近似，表明该组合方法具有潜力。

Conclusion: 将神经微分方程用于增强有限数据，并结合符号回归以推导物理定律，是一种极具前景的科学发现新范式，尽管在变量选择和泛化方面仍有改进空间。

Abstract: Accurately modelling the dynamics of complex systems and discovering their governing differential equations are critical tasks for accelerating scientific discovery. Using noisy, synthetic data from two damped oscillatory systems, we explore the extrapolation capabilities of Neural Ordinary Differential Equations (NODEs) and the ability of Symbolic Regression (SR) to recover the underlying equations. Our study yields three key insights. First, we demonstrate that NODEs can extrapolate effectively to new boundary conditions, provided the resulting trajectories share dynamic similarity with the training data. Second, SR successfully recovers the equations from noisy ground-truth data, though its performance is contingent on the correct selection of input variables. Finally, we find that SR recovers two out of the three governing equations, along with a good approximation for the third, when using data generated by a NODE trained on just 10% of the full simulation. While this last finding highlights an area for future work, our results suggest that using NODEs to enrich limited data and enable symbolic regression to infer physical laws represents a promising new approach for scientific discovery.

</details>


### [168] [Learning Contextual Runtime Monitors for Safe AI-Based Autonomy](https://arxiv.org/abs/2601.20666)
*Alejandro Luque-Cerpa,Mengyuan Wang,Emil Carlsson,Sanjit A. Seshia,Devdatt Dubhashi,Hazem Torfah*

Main category: cs.LG

TL;DR: 本文提出了一种新型框架，用于学习上下文感知的运行时监控器，以提升基于AI的控制集成系统的安全性和性能。通过将监控器学习建模为上下文学习任务，并利用上下文多臂赌博机技术，实现对不同运行环境下最优控制器的动态选择，从而在保证理论安全性的前提下，更有效地利用各控制器的专长。


<details>
  <summary>Details</summary>
Motivation: ML控制器在未知环境中性能可能急剧下降，传统集成方法通过平均或投票方式融合输出，但会削弱各控制器在特定上下文中的优势。因此需要一种能够识别并利用这些上下文特性的监控机制来提升系统安全与性能。

Method: 将监控器学习建模为上下文学习任务，采用上下文多臂赌博机技术，使监控器能根据实时系统上下文动态选择最合适的控制器。

Result: 在两个模拟的自动驾驶场景中验证了该框架的有效性，结果表明其相比非上下文基线方法，在安全性和性能上均有显著提升。

Conclusion: 本研究通过引入上下文感知的运行时监控框架，实现了对AI控制集成系统的更安全、更高效管理，为复杂环境下的自主系统部署提供了有力支持。

Abstract: We introduce a novel framework for learning context-aware runtime monitors for AI-based control ensembles. Machine-learning (ML) controllers are increasingly deployed in (autonomous) cyber-physical systems because of their ability to solve complex decision-making tasks. However, their accuracy can degrade sharply in unfamiliar environments, creating significant safety concerns. Traditional ensemble methods aim to improve robustness by averaging or voting across multiple controllers, yet this often dilutes the specialized strengths that individual controllers exhibit in different operating contexts. We argue that, rather than blending controller outputs, a monitoring framework should identify and exploit these contextual strengths. In this paper, we reformulate the design of safe AI-based control ensembles as a contextual monitoring problem. A monitor continuously observes the system's context and selects the controller best suited to the current conditions. To achieve this, we cast monitor learning as a contextual learning task and draw on techniques from contextual multi-armed bandits. Our approach comes with two key benefits: (1) theoretical safety guarantees during controller selection, and (2) improved utilization of controller diversity. We validate our framework in two simulated autonomous driving scenarios, demonstrating significant improvements in both safety and performance compared to non-contextual baselines.

</details>


### [169] [MuRAL-CPD: Active Learning for Multiresolution Change Point Detection](https://arxiv.org/abs/2601.20686)
*Stefano Bertolasi,Diego Carrera,Diego Stucchi,Pasqualina Fragneto,Luigi Amedeo Bianchi*

Main category: cs.LG

TL;DR: MuRAL-CPD 是一种新颖的半监督变化点检测方法，结合了主动学习与多分辨率算法，通过小波变换在多个时间尺度上检测变化，并利用用户反馈优化超参数，使模型对变化的理解更符合用户需求，在少量监督下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统无监督变化点检测方法缺乏对任务特定变化定义的适应性，且无法利用用户知识；为解决这一问题，提出结合用户反馈的半监督方法以提升准确性和可解释性。

Method: 采用小波基的多分辨率分解检测多尺度变化，并引入主动学习机制，通过用户反馈迭代优化关键超参数，实现模型与用户认知对齐。

Result: 在多个真实世界数据集上的实验表明，MuRAL-CPD 在低监督场景下显著优于现有先进方法，提升了检测精度与可解释性。

Conclusion: MuRAL-CPD 有效融合用户知识与多分辨率分析，实现了更精准、可解释的变化点检测，尤其适用于标注资源有限的应用场景。

Abstract: Change Point Detection (CPD) is a critical task in time series analysis, aiming to identify moments when the underlying data-generating process shifts. Traditional CPD methods often rely on unsupervised techniques, which lack adaptability to task-specific definitions of change and cannot benefit from user knowledge. To address these limitations, we propose MuRAL-CPD, a novel semi-supervised method that integrates active learning into a multiresolution CPD algorithm. MuRAL-CPD leverages a wavelet-based multiresolution decomposition to detect changes across multiple temporal scales and incorporates user feedback to iteratively optimize key hyperparameters. This interaction enables the model to align its notion of change with that of the user, improving both accuracy and interpretability. Our experimental results on several real-world datasets show the effectiveness of MuRAL-CPD against state-of-the-art methods, particularly in scenarios where minimal supervision is available.

</details>


### [170] [Positive-Unlabeled Reinforcement Learning Distillation for On-Premise Small Models](https://arxiv.org/abs/2601.20687)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Xiaobo Xia,Ming-Kun Xie,Dong-Dong Wu,Biao Liu,Yuheng Jia,Xin Geng,Masashi Sugiyama,Tat-Seng Chua*

Main category: cs.LG

TL;DR: 本文提出了一种适用于本地部署小模型的正-未标记（PU）强化学习蒸馏方法，无需人工标注偏好或依赖外部奖励模型，通过教师模型生成锚定响应并结合自排名机制在本地构建偏好信号，实现完全本地化的训练循环。


<details>
  <summary>Details</summary>
Motivation: 当前小模型在本地部署中普遍止步于监督微调（SFT），难以进入强化学习对齐阶段，主要因为传统RL对齐需要昂贵的人工偏好标注或高成本、需持续维护的大规模奖励模型API，这些都不适合本地环境。

Method: 提出一种正-未标记（PU）强化学习蒸馏方法：对每个提示，仅调用一次教师模型获取锚定响应，然后本地采样多个学生候选，通过锚定条件下的自排名生成成对或列表式偏好，进而使用直接偏好优化或组相对策略优化完成本地训练。

Result: 实验表明，在低成本设置下，该方法能持续实现优异性能，且理论分析证明其诱导的偏好信号具有顺序一致性并集中于近最优候选，保证了对齐过程的稳定性。

Conclusion: 所提方法有效解决了小模型在本地环境中缺乏可靠偏好信号的问题，实现了无需外部依赖的高效、稳定、低成本的强化学习对齐，为实际应用提供了可行路径。

Abstract: Due to constraints on privacy, cost, and latency, on-premise deployment of small models is increasingly common. However, most practical pipelines stop at supervised fine-tuning (SFT) and fail to reach the reinforcement learning (RL) alignment stage. The main reason is that RL alignment typically requires either expensive human preference annotation or heavy reliance on high-quality reward models with large-scale API usage and ongoing engineering maintenance, both of which are ill-suited to on-premise settings. To bridge this gap, we propose a positive-unlabeled (PU) RL distillation method for on-premise small-model deployment. Without human-labeled preferences or a reward model, our method distills the teacher's preference-optimization capability from black-box generations into a locally trainable student. For each prompt, we query the teacher once to obtain an anchor response, locally sample multiple student candidates, and perform anchor-conditioned self-ranking to induce pairwise or listwise preferences, enabling a fully local training loop via direct preference optimization or group relative policy optimization. Theoretical analysis justifies that the induced preference signal by our method is order-consistent and concentrates on near-optimal candidates, supporting its stability for preference optimization. Experiments demonstrate that our method achieves consistently strong performance under a low-cost setting.

</details>


### [171] [Optimal Transport Group Counterfactual Explanations](https://arxiv.org/abs/2601.20692)
*Enrique Valero-Leal,Bernd Bischl,Pedro Larrañaga,Concha Bielza,Giuseppe Casalicchio*

Main category: cs.LG

TL;DR: 本文提出一种基于显式最优传输映射的群体反事实解释方法，无需重新优化即可将任意群体实例映射到其反事实，实现参数高效且可解释的共同可行动补救方案。在线性分类器下，证明了反事实函数可通过数学优化推导，并识别出对应的凸优化类型（如二次规划）。实验表明该方法能准确泛化、保持群体几何结构，且运输成本接近基线方法；即使不依赖模型线性假设，也显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有群体反事实解释方法存在三大局限：仅针对固定群体优化、依赖强模型假设（如线性）、难以控制群体几何失真。本文旨在克服这些缺陷，实现高效、通用且几何保真的群体反事实生成。

Method: 学习一个显式的最优传输映射，将任意群体实例直接映射至其反事实，通过最小化群体总运输成本实现优化，避免对每个新成员重复计算。在线性分类器下，利用数学优化推导反事实函数形式，并确定其对应凸优化类型。

Result: 所提方法在多种场景下均表现出良好泛化能力，有效保持群体几何结构，运输成本几乎与基线相当；即使在非线性模型中也显著优于现有基准方法。

Conclusion: 本方法通过显式最优传输映射实现了群体反事实解释的高效泛化与几何保真，为可解释人工智能提供了新的理论与实践框架，尤其适用于需要共同可行动补救的决策系统。

Abstract: Group counterfactual explanations find a set of counterfactual instances to explain a group of input instances contrastively. However, existing methods either (i) optimize counterfactuals only for a fixed group and do not generalize to new group members, (ii) strictly rely on strong model assumptions (e.g., linearity) for tractability or/and (iii) poorly control the counterfactual group geometry distortion. We instead learn an explicit optimal transport map that sends any group instance to its counterfactual without re-optimization, minimizing the group's total transport cost. This enables generalization with fewer parameters, making it easier to interpret the common actionable recourse. For linear classifiers, we prove that functions representing group counterfactuals are derived via mathematical optimization, identifying the underlying convex optimization type (QP, QCQP, ...). Experiments show that they accurately generalize, preserve group geometry and incur only negligible additional transport cost compared to baseline methods. If model linearity cannot be exploited, our approach also significantly outperforms the baselines.

</details>


### [172] [Is Pure Exploitation Sufficient in Exogenous MDPs with Linear Function Approximation?](https://arxiv.org/abs/2601.20694)
*Hao Liang,Jiayu Cheng,Sean R. Sinclair,Yali Du*

Main category: cs.LG

TL;DR: 本文研究了外生马尔可夫决策过程（Exo-MDPs），提出纯利用学习（PEL）算法，首次证明了在无需探索的情况下，仅通过利用即可实现有限样本的后悔界。在表格情形下，PEL达到$\widetilde{O}(H^2|Ξ|\sqrt{K})$的后悔界；对于大规模连续内生状态空间，引入LSVI-PE方法，其后悔界为特征维度、外生状态空间和时域的多项式函数，与内生状态和动作空间无关。分析中提出了反事实轨迹和贝尔曼闭合特征传输两个新工具，使贪婪策略在无乐观性的情况下仍能获得准确的价值估计。实验表明PEL在合成及资源管理任务中持续优于基线方法。整体上推翻了‘探索是必需的’的传统认知，证明在Exo-MDPs中纯利用已足够。


<details>
  <summary>Details</summary>
Motivation: 尽管经验上贪心的利用型方法在Exo-MDPs中表现良好，但现有理论框架仍依赖显式探索或表格假设，缺乏对纯利用方法的理论支持。因此，亟需建立无需探索的后悔界，以解释实际性能并推动理论发展。

Method: 提出Pure Exploitation Learning（PEL）算法，并针对不同场景设计相应方法：在表格情况下直接应用PEL，在大状态空间下引入基于线性近似的LSVI-PE方法。分析中创新性地使用反事实轨迹和贝尔曼闭合特征传输技术，使贪婪策略能够获得精确价值估计而无需乐观性假设。

Result: 在表格情况下，PEL实现了$\widetilde{O}(H^2|Ξ|\sqrt{K})$的后悔界；在连续状态空间中，LSVI-PE的后悔界为多项式形式，独立于内生状态和动作空间的大小。实验验证了PEL在多种任务中均优于现有基线方法。

Conclusion: 本工作首次建立了Exo-MDPs中纯利用算法的理论基础，证明探索并非必要。在该类问题中，仅靠利用即可实现良好的学习性能，从而颠覆了传统认知。

Abstract: Exogenous MDPs (Exo-MDPs) capture sequential decision-making where uncertainty comes solely from exogenous inputs that evolve independently of the learner's actions. This structure is especially common in operations research applications such as inventory control, energy storage, and resource allocation, where exogenous randomness (e.g., demand, arrivals, or prices) drives system behavior. Despite decades of empirical evidence that greedy, exploitation-only methods work remarkably well in these settings, theory has lagged behind: all existing regret guarantees for Exo-MDPs rely on explicit exploration or tabular assumptions. We show that exploration is unnecessary. We propose Pure Exploitation Learning (PEL) and prove the first general finite-sample regret bounds for exploitation-only algorithms in Exo-MDPs. In the tabular case, PEL achieves $\widetilde{O}(H^2|Ξ|\sqrt{K})$. For large, continuous endogenous state spaces, we introduce LSVI-PE, a simple linear-approximation method whose regret is polynomial in the feature dimension, exogenous state space, and horizon, independent of the endogenous state and action spaces. Our analysis introduces two new tools: counterfactual trajectories and Bellman-closed feature transport, which together allow greedy policies to have accurate value estimates without optimism. Experiments on synthetic and resource-management tasks show that PEL consistently outperforming baselines. Overall, our results overturn the conventional wisdom that exploration is required, demonstrating that in Exo-MDPs, pure exploitation is enough.

</details>


### [173] [Adapting the Behavior of Reinforcement Learning Agents to Changing Action Spaces and Reward Functions](https://arxiv.org/abs/2601.20714)
*Raul de la Rosa,Ivana Dusparic,Nicolas Cardozo*

Main category: cs.LG

TL;DR: MORPHIN is a self-adaptive Q-learning framework that enables reinforcement learning agents to adapt on-the-fly to non-stationary environments, including shifts in reward functions and expanding action spaces, without full retraining. It uses concept drift detection and dynamic hyperparameter adjustment to preserve prior knowledge and avoid catastrophic forgetting. Evaluated on Gridworld and traffic signal control, MORPHIN improves learning efficiency by up to 1.7x compared to standard Q-learning.


<details>
  <summary>Details</summary>
Motivation: Reinforcement Learning agents often fail in real-world settings with changing environments, especially when reward functions shift or action spaces expand. Existing methods require full retraining, which is inefficient and impractical. There is a need for adaptive RL frameworks that can adjust dynamically while preserving learned policies.

Method: MORPHIN integrates concept drift detection mechanisms with dynamic adjustment of learning rates and exploration parameters in Q-learning. It monitors environmental changes and adapts hyperparameters in real time, enabling continuous adaptation without reinitializing the policy. The framework preserves prior knowledge through regularization techniques to prevent catastrophic forgetting.

Result: In both Gridworld and traffic signal control simulations, MORPHIN demonstrated faster convergence and sustained performance under non-stationary conditions. It achieved up to 1.7x improvement in learning efficiency compared to standard Q-learning, showing robust adaptation to reward function shifts and action space expansions.

Conclusion: MORPHIN effectively enables real-time adaptation in non-stationary environments by combining concept drift detection with dynamic hyperparameter tuning. It maintains high learning efficiency and prevents catastrophic forgetting, making it suitable for practical RL applications where environments evolve over time.

Abstract: Reinforcement Learning (RL) agents often struggle in real-world applications where environmental conditions are non-stationary, particularly when reward functions shift or the available action space expands. This paper introduces MORPHIN, a self-adaptive Q-learning framework that enables on-the-fly adaptation without full retraining. By integrating concept drift detection with dynamic adjustments to learning and exploration hyperparameters, MORPHIN adapts agents to changes in both the reward function and on-the-fly expansions of the agent's action space, while preserving prior policy knowledge to prevent catastrophic forgetting. We validate our approach using a Gridworld benchmark and a traffic signal control simulation. The results demonstrate that MORPHIN achieves superior convergence speed and continuous adaptation compared to a standard Q-learning baseline, improving learning efficiency by up to 1.7x.

</details>


### [174] [Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning](https://arxiv.org/abs/2601.20829)
*Minwu Kim,Safal Shrestha,Keith Ross*

Main category: cs.LG

TL;DR: 提出失败前缀条件化方法，通过在训练中使用罕见错误推理轨迹的前缀，使模型更易接触到有信息量的失败状态，从而克服强化学习中因问题饱和导致的训练停滞问题。该方法在不增加计算成本的情况下显著提升性能，并可通过迭代刷新前缀实现进一步优化。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习训练中，随着问题难度增加，模型容易陷入饱和状态，难以获得有效学习信号。主要原因是正确路径占主导，而具有价值的失败路径极少被采样到，导致模型无法从失败中学习。

Method: 提出失败前缀条件化（Failure-Prefix Conditioning）方法，将训练起点从原始问题改为从罕见错误推理路径中提取的前缀，从而引导模型探索失败区域，增强对失败状态的学习能力。同时采用迭代更新失败前缀的策略，持续引入新挑战。

Result: 实验表明，该方法在性能上达到与训练中等难度问题相当的效果，且保持了良好的令牌效率；在鲁棒性方面，模型对误导性失败前缀的敏感度降低，但早期正确推理略有下降。迭代刷新前缀可进一步突破性能瓶颈。

Conclusion: 失败前缀条件化是一种高效、简单且可扩展的方法，能够有效缓解强化学习中因问题饱和导致的训练停滞问题，为提升大语言模型的推理能力提供了新路径。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model's robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.

</details>


### [175] [SA-PEF: Step-Ahead Partial Error Feedback for Efficient Federated Learning](https://arxiv.org/abs/2601.20738)
*Dawit Kiros Redie,Reza Arablouei,Stefan Werner*

Main category: cs.LG

TL;DR: 提出了一种名为step-ahead partial error feedback (SA-PEF)的新方法，结合了步前校正（SA）与部分误差反馈（PEF），在非独立同分布（non-IID）数据和部分客户端参与的情况下，实现了对非凸目标函数的收敛性保证。该方法在早期训练阶段加速了残差收缩，提升了训练效率，并在多种架构和数据集上均优于传统误差反馈（EF）。


<details>
  <summary>Details</summary>
Motivation: 传统误差反馈（EF）在非IID数据下存在残差衰减慢的问题，导致梯度不匹配和早期训练停滞；因此需要一种既能快速启动又能保持长期稳定性的压缩通信方法。

Method: SA-PEF通过引入步前系数α，将标准误差反馈（EF）与步前误差反馈（SAEF）统一为一个连续框架。其核心是设计了一个可调节的残差收缩机制，实现对通信开销与收敛速度的平衡。

Result: 理论分析表明，对于δ-收缩压缩器和非凸目标，SA-PEF能达到与标准非凸联邦随机梯度下降（Fed-SGD）相当的收敛速率（$O((η,η_0TR)^{-1})$），且在实际实验中显著提升训练速度，更快达到目标精度。

Conclusion: SA-PEF通过步前控制的残差收缩机制，在非IID数据和部分参与场景下实现了高效、稳定的通信压缩，兼具快速预热与长期稳定性，是联邦学习中通信优化的重要进展。

Abstract: Biased gradient compression with error feedback (EF) reduces communication in federated learning (FL), but under non-IID data, the residual error can decay slowly, causing gradient mismatch and stalled progress in the early rounds. We propose step-ahead partial error feedback (SA-PEF), which integrates step-ahead (SA) correction with partial error feedback (PEF). SA-PEF recovers EF when the step-ahead coefficient $α=0$ and step-ahead EF (SAEF) when $α=1$. For non-convex objectives and $δ$-contractive compressors, we establish a second-moment bound and a residual recursion that guarantee convergence to stationarity under heterogeneous data and partial client participation. The resulting rates match standard non-convex Fed-SGD guarantees up to constant factors, achieving $O((η,η_0TR)^{-1})$ convergence to a variance/heterogeneity floor with a fixed inner step size. Our analysis reveals a step-ahead-controlled residual contraction $ρ_r$ that explains the observed acceleration in the early training phase. To balance SAEF's rapid warm-up with EF's long-term stability, we select $α$ near its theory-predicted optimum. Experiments across diverse architectures and datasets show that SA-PEF consistently reaches target accuracy faster than EF.

</details>


### [176] [HESTIA: A Hessian-Guided Differentiable Quantization-Aware Training Framework for Extremely Low-Bit LLMs](https://arxiv.org/abs/2601.20745)
*Guoan Wang,Feiyu Wang,Zongwei Lv,Yikun Zong,Tong Yang*

Main category: cs.LG

TL;DR: Hestia提出一种基于海森矩阵引导的可微量化感知训练框架，用于极低比特大语言模型。通过温度控制的softmax松弛替代硬舍入，早期保持梯度流动并逐步硬化量化，结合张量级海森迹作为轻量曲率信号实现细粒度温度退火，实现敏感性感知的离散化。在Llama-3.2上评估显示，相比现有三值量化方法，1B和3B模型分别获得5.39%和4.34%的零样本性能提升，有效恢复表示能力，为1.58比特模型建立更稳健的训练路径。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模持续扩大，部署面临内存墙瓶颈，亟需极低比特量化。但现有量化感知训练方法从训练初期即采用硬舍入和直通估计，过早离散化优化空间，导致潜在权重与量化权重间梯度不匹配，阻碍量化模型的有效优化。

Method: 提出Hestia框架，用温度控制的softmax松弛替代传统硬舍入，维持训练初期的梯度流动；引入张量级海森迹作为轻量曲率信号，驱动细粒度温度退火，实现敏感性感知的渐进式量化。

Result: 在Llama-3.2上，Hestia在1B和3B模型上分别实现5.39%和4.34%的平均零样本性能提升，显著优于现有三值量化基线，证明其能有效恢复模型表示能力，适用于1.58比特大语言模型的高效训练。

Conclusion: Hestia通过海森矩阵引导的可微量化机制，实现了对极低比特大语言模型更鲁棒的训练路径，有效缓解了梯度失配问题，提升了量化模型性能，为未来低比特部署提供了新范式。

Abstract: As large language models (LLMs) continue to scale, deployment is increasingly bottlenecked by the memory wall, motivating a shift toward extremely low-bit quantization. However, most quantization-aware training (QAT) methods apply hard rounding and the straight-through estimator (STE) from the beginning of the training, which prematurely discretizes the optimization landscape and induces persistent gradient mismatch between latent weights and quantized weights, hindering effective optimization of quantized models. To address this, we propose Hestia, a Hessian-guided differentiable QAT framework for extremely low-bit LLMs, which replaces the rigid step function with a temperature-controlled softmax relaxation to maintain gradient flow early in training while progressively hardening quantization. Furthermore, Hestia leverages a tensor-wise Hessian trace metric as a lightweight curvature signal to drive fine-grained temperature annealing, enabling sensitivity-aware discretization across the model. Evaluations on Llama-3.2 show that Hestia consistently outperforms existing ternary QAT baselines, yielding average zero-shot improvements of 5.39% and 4.34% for the 1B and 3B models. These results indicate that Hessian-guided relaxation effectively recovers representational capacity, establishing a more robust training path for 1.58-bit LLMs. The code is available at https://github.com/hestia2026/Hestia.

</details>


### [177] [Evolutionary Strategies lead to Catastrophic Forgetting in LLMs](https://arxiv.org/abs/2601.20861)
*Immanuel Abdi,Akshat Gupta,Micah Mok,Alexander Lu,Nicholas Lee,Gopala Anumanchipalli*

Main category: cs.LG

TL;DR: 本文全面分析了进化策略（ES）在持续学习中的表现，发现其虽能在数学和推理任务上达到与GRPO相近的性能，但伴随显著的先前知识遗忘，且其更新方式更不稀疏、$\ell_2$范数远大于GRPO，导致遗忘严重。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统缺乏部署后的持续学习能力，而梯度类算法内存消耗大，进化策略（ES）作为无梯度方法虽有潜力，但其在持续学习中的遗忘问题尚不明确，亟需系统评估。

Method: 通过对比ES与GRPO在不同训练步数下的性能与遗忘曲线，分析其更新向量的稀疏性与$\ell_2$范数差异，揭示遗忘机制。

Result: ES在计算预算相当下可接近GRPO性能，但存在严重遗忘；其更新非稀疏且$\ell_2$范数大，是导致遗忘的关键原因。

Conclusion: ES虽具潜力，但严重的遗忘限制其在在线持续学习中的应用，需未来工作解决该问题。

Abstract: One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.

</details>


### [178] [Supervised Guidance Training for Infinite-Dimensional Diffusion Models](https://arxiv.org/abs/2601.20756)
*Elizabeth L. Baker,Alexander Denker,Jes Frellsen*

Main category: cs.LG

TL;DR: 本文提出了一种在函数空间中对基于分数的扩散模型进行后验采样的新方法，解决了在偏微分方程逆问题中使用扩散模型作为先验时的条件化难题。通过推广Doob's h-变换到无限维情形，证明了条件分数可分解为无条件分数与引导项之和，并提出一种无需模拟的分数匹配目标（监督引导训练），实现了高效稳定的后验采样。该方法首次实现了在函数空间中对已训练扩散模型的精确后验微调。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型虽能作为函数空间中的表达性先验，但其在贝叶斯逆问题中如何正确条件化以采样后验分布的理论尚不明确。需要一种理论支持的方法来实现对已训练模型的后验微调，从而准确解决函数空间中的逆问题。

Method: 基于无限维扩展的Doob's h-变换，推导出函数空间中条件分数的分解形式；提出一种无需模拟的监督引导训练（Supervised Guidance Training）方法，通过学习引导项实现后验采样。

Result: 理论证明了在满足特定条件下（如先验位于Cameron-Martin空间或相对于高斯测度绝对连续），扩散模型可被正确条件化；数值实验验证了该方法在贝叶斯逆问题中的有效性，实现了稳定且准确的后验采样。

Conclusion: 本工作首次提供了在函数空间中对训练好的扩散模型进行后验微调的完整方法论，通过理论分析与新型训练目标，成功实现了对复杂逆问题的高效、精准采样。

Abstract: Score-based diffusion models have recently been extended to infinite-dimensional function spaces, with uses such as inverse problems arising from partial differential equations. In the Bayesian formulation of inverse problems, the aim is to sample from a posterior distribution over functions obtained by conditioning a prior on noisy observations. While diffusion models provide expressive priors in function space, the theory of conditioning them to sample from the posterior remains open. We address this, assuming that either the prior lies in the Cameron-Martin space, or is absolutely continuous with respect to a Gaussian measure. We prove that the models can be conditioned using an infinite-dimensional extension of Doob's $h$-transform, and that the conditional score decomposes into an unconditional score and a guidance term. As the guidance term is intractable, we propose a simulation-free score matching objective (called Supervised Guidance Training) enabling efficient and stable posterior sampling. We illustrate the theory with numerical examples on Bayesian inverse problems in function spaces. In summary, our work offers the first function-space method for fine-tuning trained diffusion models to accurately sample from a posterior.

</details>


### [179] [Less is More: Clustered Cross-Covariance Control for Offline RL](https://arxiv.org/abs/2601.20765)
*Nan Qiao,Sheng Yue,Shuning Wang,Yongheng Deng,Ju Ren*

Main category: cs.LG

TL;DR: 本文针对离线强化学习中的分布偏移问题，提出两种互补策略：分块缓冲区采样（C^4）和基于梯度的修正惩罚。前者通过限制更新到局部重放缓冲区，减少不规则协方差影响；后者直接消除更新中的协方差偏差。理论证明其保持最大化目标的下界性质，并缓解极端分布外区域的过度保守问题。实验显示，该方法在小数据集和高分布外场景下显著提升稳定性与收益，最高提升30%。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习中因数据稀缺或分布外区域主导导致的分布偏移问题严重，标准平方误差目标会引入有害的TD交叉协方差，加剧优化偏差并损害策略学习效果。

Method: 提出分块缓冲区采样（C^4）以限制更新至局部区域，降低协方差异常影响；同时引入梯度基修正惩罚，显式抵消更新中的协方差偏差。

Result: 实验表明，该方法在小样本和高分布外场景下显著提升策略性能，稳定性和回报率相较之前方法最高提升30%，且易于集成到现有框架中。

Conclusion: 所提方法有效缓解了离线强化学习中的分布偏移问题，通过结构化采样与梯度修正双重机制，在保持策略约束性的同时避免过度保守，显著提升学习效果。

Abstract: A fundamental challenge in offline reinforcement learning is distributional shift. Scarce data or datasets dominated by out-of-distribution (OOD) areas exacerbate this issue. Our theoretical analysis and experiments show that the standard squared error objective induces a harmful TD cross covariance. This effect amplifies in OOD areas, biasing optimization and degrading policy learning. To counteract this mechanism, we develop two complementary strategies: partitioned buffer sampling that restricts updates to localized replay partitions, attenuates irregular covariance effects, and aligns update directions, yielding a scheme that is easy to integrate with existing implementations, namely Clustered Cross-Covariance Control for TD (C^4). We also introduce an explicit gradient-based corrective penalty that cancels the covariance induced bias within each update. We prove that buffer partitioning preserves the lower bound property of the maximization objective, and that these constraints mitigate excessive conservatism in extreme OOD areas without altering the core behavior of policy constrained offline reinforcement learning. Empirically, our method showcases higher stability and up to 30% improvement in returns over prior methods, especially with small datasets and splits that emphasize OOD areas.

</details>


### [180] [COMET-SG1: Lightweight Autoregressive Regressor for Edge and Embedded AI](https://arxiv.org/abs/2601.20772)
*Shakhyar Gogoi*

Main category: cs.LG

TL;DR: COMET-SG1 是一种轻量级、面向稳定性的自回归回归模型，专为边缘和嵌入式AI系统中的时间序列预测设计。它通过线性行为空间编码、记忆锚定的转移估计和确定性状态更新实现，确保在完全自回归推理下具有有界长期行为，适用于边缘部署中预测误差随时间累积的场景。实验表明，在非平稳合成时间序列数据上，COMET-SG1 在短时预测精度上表现良好，且长期漂移显著优于MLP、LSTM和k近邻基线模型。其参数量小，计算操作兼容定点数运算，为边缘和嵌入式AI应用提供了一种实用且可解释的稳定自回归预测方法。


<details>
  <summary>Details</summary>
Motivation: 在边缘和嵌入式AI系统中进行时间序列预测时，传统模型如RNN或Transformer存在长期预测误差累积问题，且难以在资源受限环境中部署。因此需要一种轻量、稳定、可解释且适合固定点运算的自回归模型，以满足边缘设备对稳定性与效率的双重需求。

Method: 采用线性行为空间编码、记忆锚定的转移估计和确定性状态更新机制，构建一个全自回归推理框架，确保长期行为的有界性。模型结构避免使用复杂的非线性变换，提升计算效率并适配定点算术。

Result: 在非平稳合成时间序列数据上，COMET-SG1在短时预测上达到与主流模型相当的精度，同时显著降低长期预测漂移；参数量小，支持固定点运算，具备良好的部署可行性。

Conclusion: COMET-SG1是一种适用于边缘和嵌入式系统的高效、稳定、可解释的自回归时间序列预测模型，能够在资源受限条件下实现可靠的长期预测，具有实际部署价值。

Abstract: COMET-SG1 is a lightweight, stability-oriented autoregressive regression model designed for time-series prediction on edge and embedded AI systems. Unlike recurrent neural networks or transformer-based sequence models, COMET-SG1 operates through linear behavior-space encoding, memory-anchored transition estimation, and deterministic state updates. This structure prioritizes bounded long-horizon behavior under fully autoregressive inference, a critical requirement for edge deployment where prediction errors accumulate over time. Experiments on non-stationary synthetic time-series data demonstrate that COMET-SG1 achieves competitive short-horizon accuracy while exhibiting significantly reduced long-horizon drift compared to MLP, LSTM, and k-nearest neighbor baselines. With a compact parameter footprint and operations compatible with fixed-point arithmetic, COMET-SG1 provides a practical and interpretable approach for stable autoregressive prediction in edge and embedded AI applications.

</details>


### [181] [Smoothing the Black-Box: Signed-Distance Supervision for Black-Box Model Copying](https://arxiv.org/abs/2601.20773)
*Rubén Jiménez,Oriol Pujol*

Main category: cs.LG

TL;DR: 本文提出了一种基于距离的黑箱模型复制框架，通过将硬标签监督替换为到教师模型决策边界的有符号距离，将复制问题转化为平滑回归任务，从而更高效地恢复边界几何结构。该方法引入了受α控制的平滑与正则化方案，以保证目标表面的Hölder/Lipschitz连续性，并设计了两种无需模型内部信息即可估计有符号距离的通用算法。在合成数据和UCI基准上的实验表明，该方法在保真度和泛化性能上优于传统硬标签基线，同时可输出距离作为不确定性信号，提升黑箱模型的可解释性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 在实际部署的机器学习系统中，模型需要在无法访问原始训练数据或模型内部结构的情况下持续演化。传统的硬标签复制方法在仅能获取输入-输出查询结果时，面临决策边界重建不连续、难以有效恢复几何结构的问题，限制了模型升级的效率与精度。因此，亟需一种能够利用有限查询信息实现高质量黑箱复制的新方法。

Method: 提出了一种基于有符号距离的模型复制框架，将原本的硬标签监督转换为对教师模型决策边界的有符号距离监督，从而将复制问题从不连续的分类重构转为平滑的回归任务。采用α参数调控的光滑化与正则化策略，确保目标函数具有Hölder或Lipschitz连续性。设计了两种模型无关的方法，在仅能获取标签输出的前提下估计有符号距离。

Result: 在合成数据集和多个UCI基准数据集上的实验结果显示，所提方法在模型复制的保真度和泛化准确率方面均显著优于基于硬标签的传统方法。此外，生成的距离输出可作为不确定性度量，为黑箱模型提供额外的可解释性支持。

Conclusion: 本研究证明，通过引入有符号距离作为监督信号，可以将黑箱模型复制从不连续的分类问题转化为高效的平滑回归任务，显著提升了模型复制的质量与鲁棒性。该框架具备良好的通用性与实用性，适用于缺乏训练数据与模型内部信息的实际场景。

Abstract: Deployed machine learning systems must continuously evolve as data, architectures, and regulations change, often without access to original training data or model internals. In such settings, black-box copying provides a practical refactoring mechanism, i.e. upgrading legacy models by learning replicas from input-output queries alone. When restricted to hard-label outputs, copying turns into a discontinuous surface reconstruction problem from pointwise queries, severely limiting the ability to recover boundary geometry efficiently. We propose a distance-based copying (distillation) framework that replaces hard-label supervision with signed distances to the teacher's decision boundary, converting copying into a smooth regression problem that exploits local geometry. We develop an $α$-governed smoothing and regularization scheme with Hölder/Lipschitz control over the induced target surface, and introduce two model-agnostic algorithms to estimate signed distances under label-only access. Experiments on synthetic problems and UCI benchmarks show consistent improvements in fidelity and generalization accuracy over hard-label baselines, while enabling distance outputs as uncertainty-related signals for black-box replicas.

</details>


### [182] [When More Data Doesn't Help: Limits of Adaptation in Multitask Learning](https://arxiv.org/abs/2601.20774)
*Steve Hanneke,Mingyue Xu*

Main category: cs.LG

TL;DR: 本文研究多任务学习的统计极限，指出即使在每任务样本量无限大的情况下，仅通过聚合样本的算法也无法实现最优风险，揭示了多任务学习的根本困难无法通过增加数据量克服。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，在缺乏分布信息的情况下，基于样本聚合的算法无法保证最优风险，但该结论受限于样本量有界。本文旨在突破这一限制，探讨在任意大样本量下多任务学习的适应性难题。

Method: 通过建立更强的不可能性结果，分析多任务学习在无分布信息条件下的统计极限，证明即使样本量极大，也无法克服适应性障碍。

Result: 证明了多任务学习的适应性难题在任意大样本量下依然存在，表明数据量的增加不能解决根本性的学习困境。

Conclusion: 多任务学习的挑战本质上是统计层面的，不能通过增加每个任务的数据量来克服；未来研究可探索最优适应性机制。

Abstract: Multitask learning and related frameworks have achieved tremendous success in modern applications. In multitask learning problem, we are given a set of heterogeneous datasets collected from related source tasks and hope to enhance the performance above what we could hope to achieve by solving each of them individually. The recent work of arXiv:2006.15785 has showed that, without access to distributional information, no algorithm based on aggregating samples alone can guarantee optimal risk as long as the sample size per task is bounded.
  In this paper, we focus on understanding the statistical limits of multitask learning. We go beyond the no-free-lunch theorem in arXiv:2006.15785 by establishing a stronger impossibility result of adaptation that holds for arbitrarily large sample size per task. This improvement conveys an important message that the hardness of multitask learning cannot be overcame by having abundant data per task. We also discuss the notion of optimal adaptivity that may be of future interests.

</details>


### [183] [Active Learning for Decision Trees with Provable Guarantees](https://arxiv.org/abs/2601.20775)
*Arshia Soltani Moakhar,Tanapoom Laoaron,Faraz Ghahremani,Kiarash Banihashem,MohammadTaghi Hajiaghayi*

Main category: cs.LG

TL;DR: 该论文首次分析了决策树的分歧系数，这是决定主动学习标签复杂度的关键参数。在两个自然假设下（每个根到叶路径查询不同的特征维度，且输入数据具有规则的网格结构），证明了主动学习的标签复杂度为多项式对数级。放松这些假设会导致标签复杂度变为多项式级。此外，提出首个能实现乘法误差保证的通用主动学习算法，生成(1+ε)近似分类器，并设计出在上述假设下仅需多项式对数级标签查询的决策树主动学习算法。最后，建立了标签复杂度下界，表明算法对误差容忍度ε的依赖接近最优。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解决策树作为二分类器的主动学习标签复杂度，特别是关键参数分歧系数的作用，以及开发具有理论保证的高效主动学习算法。

Method: 基于两个核心假设进行分歧系数分析；设计新的主动学习算法以实现(1+ε)近似分类器；结合理论分析与算法设计，验证其在特定条件下的高效性；通过构造下界证明算法性能接近最优。

Result: 在给定假设条件下，决策树的主动学习标签复杂度为多项式对数级；提出的算法可实现乘法误差保证，且标签查询数量仅为数据集大小的多项式对数级；算法对误差容忍度ε的依赖接近理论最优。

Conclusion: 该研究首次系统地分析了决策树主动学习中的分歧系数，揭示了关键假设的重要性，并提出了一个高效、理论上最优的主动学习算法，为决策树在主动学习场景中的应用提供了坚实的理论基础。

Abstract: This paper advances the theoretical understanding of active learning label complexity for decision trees as binary classifiers. We make two main contributions. First, we provide the first analysis of the disagreement coefficient for decision trees-a key parameter governing active learning label complexity. Our analysis holds under two natural assumptions required for achieving polylogarithmic label complexity, (i) each root-to-leaf path queries distinct feature dimensions, and (ii) the input data has a regular, grid-like structure. We show these assumptions are essential, as relaxing them leads to polynomial label complexity. Second, we present the first general active learning algorithm for binary classification that achieves a multiplicative error guarantee, producing a $(1+ε)$-approximate classifier. By combining these results, we design an active learning algorithm for decision trees that uses only a polylogarithmic number of label queries in the dataset size, under the stated assumptions. Finally, we establish a label complexity lower bound, showing our algorithm's dependence on the error tolerance $ε$ is close to optimal.

</details>


### [184] [Conditional PED-ANOVA: Hyperparameter Importance in Hierarchical & Dynamic Search Spaces](https://arxiv.org/abs/2601.20800)
*Kaito Baba,Yoshihiko Ozaki,Shuhei Watanabe*

Main category: cs.LG

TL;DR: 提出condPED-ANOVA框架，用于在条件搜索空间中估计超参数重要性（HPI），解决传统PED-ANOVA无法处理条件超参数的问题。通过推导闭式估计器，准确反映条件激活和域变化，实验表明该方法能提供有意义且符合条件结构的重要度评估。


<details>
  <summary>Details</summary>
Motivation: 现有HPI估计方法如PED-ANOVA假设搜索空间固定不变，无法有效处理超参数的条件依赖关系，导致在条件设置下估计结果误导或不可解释。因此需要一种能适应条件搜索空间的新型重要性评估方法。

Method: 提出condPED-ANOVA，定义条件下的HPI，并推导出闭式估计器，以捕捉超参数在不同条件下的激活状态和取值域变化，从而准确反映其实际重要性。

Result: 实验表明，直接应用原有方法会产生错误或难以解释的结果；而condPED-ANOVA在各种条件设置下均能稳定输出合理、可解释的超参数重要性估计。

Conclusion: condPED-ANOVA成功解决了条件搜索空间中超参数重要性估计的难题，提供了更准确、可解释的分析工具，适用于复杂、非独立的超参数配置场景。

Abstract: We propose conditional PED-ANOVA (condPED-ANOVA), a principled framework for estimating hyperparameter importance (HPI) in conditional search spaces, where the presence or domain of a hyperparameter can depend on other hyperparameters. Although the original PED-ANOVA provides a fast and efficient way to estimate HPI within the top-performing regions of the search space, it assumes a fixed, unconditional search space and therefore cannot properly handle conditional hyperparameters. To address this, we introduce a conditional HPI for top-performing regions and derive a closed-form estimator that accurately reflects conditional activation and domain changes. Experiments show that naive adaptations of existing HPI estimators yield misleading or uninterpretable importance estimates in conditional settings, whereas condPED-ANOVA consistently provides meaningful importances that reflect the underlying conditional structure.

</details>


### [185] [Reinforcement Learning via Self-Distillation](https://arxiv.org/abs/2601.20802)
*Jonas Hübotter,Frederike Lübeck,Lejs Behric,Anton Baumann,Marco Bagatella,Daniel Marta,Ido Hakimi,Idan Shenfeld,Thomas Kleine Buening,Carlos Guestrin,Andreas Krause*

Main category: cs.LG

TL;DR: 本文提出了一种名为Self-Distillation Policy Optimization (SDPO)的新方法，用于强化学习中丰富的反馈（RLRF），通过将文本反馈转化为密集的学习信号，利用模型自身作为自教师来改进策略。该方法在科学推理、工具使用和编程竞赛等任务上显著提升了样本效率和最终准确率，并在仅提供标量反馈的环境中也表现更优。此外，测试时应用SDPO可大幅减少尝试次数以达到相同发现概率。


<details>
  <summary>Details</summary>
Motivation: 当前基于可验证奖励的强化学习（RLVR）方法仅依赖每次尝试的标量奖励，导致严重的信用分配难题。而许多环境实际上提供了丰富的文本反馈（如运行时错误或评估意见），这些反馈能解释失败原因，因此有必要设计一种能有效利用这些丰富反馈的方法。

Method: 提出SDPO方法，将模型对反馈的条件预测视为自教师，通过自蒸馏方式将反馈信息融入策略优化过程，从而实现对自身错误的上下文内反思与纠正。

Result: SDPO在LiveCodeBench v6上的多个任务中均优于现有强基线，在样本效率和最终准确率方面均有提升；即使在仅提供标量反馈的环境中也表现更好；且在测试阶段应用时，能以3倍少的尝试次数达到与多轮对话或best-of-k采样相当的发现概率。

Conclusion: SDPO成功利用丰富的文本反馈进行策略优化，克服了传统RLVR中的信用分配瓶颈，具备高样本效率与强大泛化能力，为复杂任务中的强化学习提供了新范式。

Abstract: Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment bottleneck. Many verifiable environments actually provide rich textual feedback, such as runtime errors or judge evaluations, that explain why an attempt failed. We formalize this setting as reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), which converts tokenized feedback into a dense learning signal without any external teacher or explicit reward model. SDPO treats the current model conditioned on feedback as a self-teacher and distills its feedback-informed next-token predictions back into the policy. In this way, SDPO leverages the model's ability to retrospectively identify its own mistakes in-context. Across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6, SDPO improves sample efficiency and final accuracy over strong RLVR baselines. Notably, SDPO also outperforms baselines in standard RLVR environments that only return scalar feedback by using successful rollouts as implicit feedback for failed attempts. Finally, applying SDPO to individual questions at test time accelerates discovery on difficult binary-reward tasks, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with 3x fewer attempts.

</details>


### [186] [$\mathbb{R}^{2k}$ is Theoretically Large Enough for Embedding-based Top-$k$ Retrieval](https://arxiv.org/abs/2601.20844)
*Zihao Wang,Hang Yin,Lihui Liu,Hanghang Tong,Yangqiu Song,Ginny Wong,Simon See*

Main category: cs.LG

TL;DR: 该研究探讨了将子集成员关系（m个元素和最多k个元素的${m\choose k}$个子集）嵌入向量空间所需的最小维度（MED），理论推导并实证验证了在$\ell_2$度量、内积和余弦相似性等多种“距离”或“相似性”定义下的MED紧致界。此外，通过数值模拟发现，在子集嵌入为其包含元素嵌入的质心这一更可行设定下，MED与待嵌入元素数量之间可实现对数依赖关系。结果表明，基于嵌入的检索限制主要源于学习能力挑战，而非几何约束，为未来算法设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 探究嵌入子集成员关系所需最小维度，揭示嵌入式检索性能瓶颈的根本原因，区分是几何限制还是学习困难所致。

Method: 理论推导结合数值模拟，分析不同相似性度量下的最小可嵌入维度，并在子集嵌入为元素嵌入质心的设定下进行仿真验证。

Result: 在多种相似性度量下获得了MED的紧致理论边界；数值模拟显示在合理设定下MED与元素数量呈对数关系，表明几何约束非主要瓶颈。

Conclusion: 嵌入式检索的性能限制主要源于学习难题，而非向量空间的几何限制，这为设计更高效的嵌入算法提供了重要启示。

Abstract: This paper studies the minimal dimension required to embed subset memberships ($m$ elements and ${m\choose k}$ subsets of at most $k$ elements) into vector spaces, denoted as Minimal Embeddable Dimension (MED). The tight bounds of MED are derived theoretically and supported empirically for various notions of "distances" or "similarities," including the $\ell_2$ metric, inner product, and cosine similarity. In addition, we conduct numerical simulation in a more achievable setting, where the ${m\choose k}$ subset embeddings are chosen as the centroid of the embeddings of the contained elements. Our simulation easily realizes a logarithmic dependency between the MED and the number of elements to embed. These findings imply that embedding-based retrieval limitations stem primarily from learnability challenges, not geometric constraints, guiding future algorithm design.

</details>


### [187] [PatchFormer: A Patch-Based Time Series Foundation Model with Hierarchical Masked Reconstruction and Cross-Domain Transfer Learning for Zero-Shot Multi-Horizon Forecasting](https://arxiv.org/abs/2601.20845)
*Olaf Yunus Laitinen Imanov,Derya Umut Kulali,Taner Yilmaz*

Main category: cs.LG

TL;DR: PatchFormer 是一种基于补丁的时间序列基础模型，通过分层掩码重建进行自监督预训练，并使用轻量级适配器实现高效迁移。它将时间序列分割为补丁，利用可学习的聚合方式学习多尺度时间表示。预训练采用动态掩码和掩码补丁重建目标，强调局部精度和全局一致性，并结合跨领域知识蒸馏。在24个涵盖天气、能源、交通、金融和医疗领域的基准数据集上，实现了最先进的零样本多步预测性能，相比强基线平均均方误差降低27.3%，且任务特定训练数据减少94%。模型在预训练数据量增加时表现出近似对数线性扩展，处理长度为512的序列速度比全序列Transformer快3.8倍。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法通常需要领域特定的特征工程和大量标注数据，限制了其泛化能力和应用效率。为解决这一问题，提出一种无需复杂特征工程、具备强泛化能力的基础模型。

Method: PatchFormer 将时间序列划分为补丁，通过可学习的跨时间尺度聚合机制学习多尺度表示；采用动态掩码的掩码补丁重建作为自监督预训练目标，并引入跨领域知识蒸馏提升模型泛化能力；在下游任务中使用轻量级适配器实现高效微调。

Result: 在24个基准数据集上，PatchFormer 实现了领先的零样本多步预测性能，均方误差相对基线降低27.3%，任务特定训练数据需求减少94%；模型在更大规模预训练下表现持续提升，处理长序列速度比标准Transformer快3.8倍。

Conclusion: PatchFormer 作为一种高效的时序基础模型，显著降低了对标注数据的依赖并提升了预测性能，尤其适用于多领域、少样本场景下的时间序列建模。

Abstract: Time series forecasting is a fundamental problem with applications in climate, energy, healthcare, and finance. Many existing approaches require domain-specific feature engineering and substantial labeled data for each task. We introduce PatchFormer, a patch-based time series foundation model that uses hierarchical masked reconstruction for self-supervised pretraining and lightweight adapters for efficient transfer. PatchFormer segments time series into patches and learns multiscale temporal representations with learnable aggregation across temporal scales. Pretraining uses masked patch reconstruction with dynamic masking and objectives that encourage both local accuracy and global consistency, followed by cross-domain knowledge distillation. Experiments on 24 benchmark datasets spanning weather, energy, traffic, finance, and healthcare demonstrate state-of-the-art zero-shot multi-horizon forecasting, reducing mean squared error by 27.3 percent relative to strong baselines while requiring 94 percent less task-specific training data. The model exhibits near log-linear scaling with more pretraining data up to 100 billion points and processes length-512 sequences 3.8x faster than full-sequence transformers.

</details>


### [188] [Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation](https://arxiv.org/abs/2601.20848)
*Weixin Chen,Li Chen,Yuhan Zhao*

Main category: cs.LG

TL;DR: 提出Cofair框架，实现推荐系统中训练后公平性动态调控，通过公平性条件适配模块和用户级正则化项，在无需重新训练的情况下支持多种公平性要求，理论证明其有效性，并在多个数据集和模型上验证了优越的公平性-准确性表现。


<details>
  <summary>Details</summary>
Motivation: 现有公平性感知推荐方法在训练时固定公平性要求，缺乏训练后灵活性，难以适应现实场景中多变的公平性需求，重新训练成本高。

Method: 设计共享表示层与公平性条件适配模块，生成针对不同公平性水平的用户嵌入；引入用户级正则化项以保证用户层面公平性随水平提升而单调改善；理论分析证明对抗目标上界于群体均等性，正则化项确保用户级渐进公平。

Result: 在多个数据集和基线模型上，Cofair实现了灵活的动态公平性控制，公平性-准确性曲线优于或相当当前最优方法，且无需为每种公平性要求重新训练。

Conclusion: Cofair是一种高效的单次训练框架，能够实现推荐系统中训练后的公平性灵活调节，具备实际应用价值。

Abstract: Despite growing efforts to mitigate unfairness in recommender systems, existing fairness-aware methods typically fix the fairness requirement at training time and provide limited post-training flexibility. However, in real-world scenarios, diverse stakeholders may demand differing fairness requirements over time, so retraining for different fairness requirements becomes prohibitive. To address this limitation, we propose Cofair, a single-train framework that enables post-training fairness control in recommendation. Specifically, Cofair introduces a shared representation layer with fairness-conditioned adapter modules to produce user embeddings specialized for varied fairness levels, along with a user-level regularization term that guarantees user-wise monotonic fairness improvements across these levels. We theoretically establish that the adversarial objective of Cofair upper bounds demographic parity and the regularization term enforces progressive fairness at user level. Comprehensive experiments on multiple datasets and backbone models demonstrate that our framework provides dynamic fairness at different levels, delivering comparable or better fairness-accuracy curves than state-of-the-art baselines, without the need to retrain for each new fairness requirement. Our code is publicly available at https://github.com/weixinchen98/Cofair.

</details>


### [189] [Exploring Transformer Placement in Variational Autoencoders for Tabular Data Generation](https://arxiv.org/abs/2601.20854)
*Aníbal Silva,Moisés Santos,André Restivo,Carlos Soares*

Main category: cs.LG

TL;DR: 本文研究了将Transformer架构整合到变分自编码器（VAE）不同组件中的影响。在OpenML CC18套件的57个数据集上进行实验，发现将Transformer用于潜在表示和解码器时，在保真度与多样性之间存在权衡；同时观察到Transformer各层块之间高度相似，尤其在解码器中，输入与输出间关系近似线性。


<details>
  <summary>Details</summary>
Motivation: 标准VAE架构难以有效建模表格数据中特征间的复杂关系，尤其是在处理混合数据类型时。Transformer凭借注意力机制更擅长捕捉特征间交互，因此探索其在VAE中的集成潜力具有重要意义。

Method: 通过在VAE的不同组件中引入Transformer结构，包括编码器、潜在空间和解码器，并在多个数据集上进行对比实验，分析其对生成性能的影响。

Result: 实验表明，将Transformer置于潜在空间和解码器中可提升模型表现，但会带来保真度与多样性之间的权衡；此外，Transformer各层块之间表现出高度相似性，尤其在解码器中，输入与输出呈现近似线性关系。

Conclusion: 尽管Transformer能增强VAE对特征交互的建模能力，但其内部结构的冗余性和线性行为限制了进一步提升性能的空间，提示未来需关注模块化设计与非线性表达能力的优化。

Abstract: Tabular data remains a challenging domain for generative models. In particular, the standard Variational Autoencoder (VAE) architecture, typically composed of multilayer perceptrons, struggles to model relationships between features, especially when handling mixed data types. In contrast, Transformers, through their attention mechanism, are better suited for capturing complex feature interactions. In this paper, we empirically investigate the impact of integrating Transformers into different components of a VAE. We conduct experiments on 57 datasets from the OpenML CC18 suite and draw two main conclusions. First, results indicate that positioning Transformers to leverage latent and decoder representations leads to a trade-off between fidelity and diversity. Second, we observe a high similarity between consecutive blocks of a Transformer in all components. In particular, in the decoder, the relationship between the input and output of a Transformer is approximately linear.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [190] [NeuroAI and Beyond](https://arxiv.org/abs/2601.19955)
*Jean-Marc Fellous,Gert Cauwenberghs,Cornelia Fermüller,Yulia Sandamisrkaya,Terrence Sejnowski*

Main category: cs.AI

TL;DR: 本文基于2025年8月举办的工作坊，探讨了神经科学与人工智能（AI）之间的协同潜力，聚焦于具身性、语言与交流、机器人学、人类与机器学习以及类脑工程等子领域，提出发展神经科学启发的人工智能（NeuroAI），以提升AI算法的效率与范围，并深化对生物神经计算的理解。文章还收录了多位领军人物的观点及两个SWOT分析，评估NeuroAI的机遇与风险。


<details>
  <summary>Details</summary>
Motivation: 尽管神经科学和人工智能近年来取得显著进展，但二者之间仍缺乏紧密联系。为推动跨领域融合，亟需建立一种受神经科学启发的人工智能范式，以实现技术突破并增进对大脑工作原理的理解。

Method: 通过组织2025年8月的工作坊，汇集领域专家讨论当前进展与未来方向；结合个人见解与SWOT分析，系统梳理神经科学与人工智能在多个关键领域的交叉点。

Result: 识别出多个可促进神经科学与人工智能深度融合的关键领域，提出‘NeuroAI’概念，并论证其在提升AI性能与理解生物神经机制方面的双重潜力。

Conclusion: 应积极推动神经科学驱动的人工智能（NeuroAI）的发展，这不仅有望革新人工智能算法，也将推动对生物神经计算的深层理解，是未来跨学科研究的重要方向。

Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.

</details>


### [191] [Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning](https://arxiv.org/abs/2601.20014)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出SQ-BCP方法，通过双向搜索和基于回溯的验证器，在部分可观测环境下解决大语言模型推理时因缺失前提条件导致的幻觉与约束违反问题，显著降低资源违规率，同时保持高质量输出。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在推理时面对未指定的关键前提条件容易产生幻觉或违反硬约束，尤其在部分可观测场景下表现不佳，亟需一种能显式处理未知前提并保证计划合法性的方法。

Method: 引入自查询双向分类规划（SQ-BCP），显式表示前提状态（满足/违反/未知），通过目标导向的自查询或桥接假设填补未知，并结合回溯验证器进行类别化证书校验，仅用距离得分进行排序与剪枝。

Result: 在WikiHow和RecipeNLG任务中，当关键前提被隐藏时，SQ-BCP将资源违规率分别降至14.9%和5.8%，优于最佳基线（26.0%和15.7%），且参考质量保持竞争力。

Conclusion: SQ-BCP在部分可观测条件下有效提升了规划的可靠性与安全性，证明了其在存在未知前提时仍可找到符合目标要求的可行计划，具备理论保障与实际性能优势。

Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.

</details>


### [192] [Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints](https://arxiv.org/abs/2601.20021)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 本文提出了一种名为模糊范畴规划（FCP）的新方法，用于处理自然语言规划中固有的模糊谓词。与传统范畴论规划不同，FCP通过在每个动作上标注[0,1]区间的度值来表示适用性程度，并使用Lukasiewicz t-范数组合计划质量，同时保留基于拉回的硬约束可执行性验证。该方法利用大语言模型（LLM）结合k样本中位数聚合来获取语言驱动的模糊适用性，支持基于剩余算子的反向需求搜索。在公共的PDDL3偏好/过度订阅基准和新构建的RecipeNLG-Subs（基于RecipeNLG和食品知识图谱的缺失替代品菜谱规划数据集）上进行评估，结果表明FCP在成功率和硬约束违规减少方面优于仅使用LLM或ReAct风格基线的方法，且在性能上仍可与经典PDDL3规划器相媲美。


<details>
  <summary>Details</summary>
Motivation: 现有范畴论规划方法将动作适用性视为二值（硬约束），需通过阈值化处理模糊谓词，导致信息丢失并无法追踪多步计划中的质量退化。为解决此问题，需要一种能表达和传播模糊适用性的规划框架，以更精细地建模自然语言规划中的渐进式满足特性。

Method: 提出模糊范畴论规划（FCP），将每个动作（态射）赋予[0,1]区间内的模糊度值；采用Lukasiewicz t-范数进行计划质量的组合；保留传统的拉回验证机制以确保可执行性；利用大语言模型（LLM）结合k样本中位数聚合来生成模糊适用性评分；引入基于剩余算子的反向搜索机制支持‘中间相遇’式求解策略。

Result: 在两个基准测试中，包括公开的PDDL3偏好/过度订阅基准和新构建的RecipeNLG-Subs数据集，FCP在成功规划率和减少硬约束违反方面显著优于仅使用LLM或ReAct风格的基线方法，同时在性能上保持与经典PDDL3规划器相当的竞争力。

Conclusion: FCP成功将模糊性融入范畴论规划框架，既保留了形式化结构的优势，又增强了对自然语言中模糊谓词的表达能力，为复杂、不精确的现实世界规划任务提供了更鲁棒和可解释的解决方案。

Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.

</details>


### [193] [Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution](https://arxiv.org/abs/2601.20379)
*Zhengbo Jiao,Hongyu Xian,Qinglong Wang,Yunpu Ma,Zhebo Wang,Zifan Zhang,Dezhang Kong,Meng Han*

Main category: cs.AI

TL;DR: 本文提出Policy of Thoughts (PoT)框架，将推理视为实例内在线优化过程，通过高效探索生成多样解，并利用组相对策略优化（GRPO）基于执行反馈更新临时LoRA适配器，实现推理先验的动态、实例化调整。实验表明，4B模型在LiveCodeBench上达到49.71%准确率，超越GPT-4o和DeepSeek-V3，尽管模型规模小50倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂长时推理中因冻结策略假设导致不稳定；当前测试时扩展方法仅将执行反馈作为外部信号进行轨迹筛选或重写，未将其内化以改进推理策略。

Method: 提出PoT框架，通过高效探索生成候选解，使用GRPO更新临时LoRA适配器，实现基于执行反馈的推理策略动态优化。

Result: 4B模型在LiveCodeBench上达到49.71%准确率，优于GPT-4o和DeepSeek-V3，且模型规模更小。

Conclusion: PoT通过实时演化模型策略，实现了推理能力的显著提升，验证了从失败中学习对智能的重要性。

Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.

</details>


### [194] [CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning](https://arxiv.org/abs/2601.20467)
*Zhenxuan Fan,Jie Cao,Yang Dai,Zheqi Lv,Wenqiao Zhang,Zhongle Xie,Peng LU,Beng Chin Ooi*

Main category: cs.AI

TL;DR: CtrlCoT是一种双粒度的链式思维（CoT）压缩框架，通过层次化推理抽象、逻辑保持的蒸馏训练和分布对齐生成，实现语义抽象与标记级剪枝的协同优化。在MATH-500数据集上，使用Qwen2.5-7B-Instruct模型时，相比最强基线减少30.7%的令牌数量，同时提升7.6个百分点的准确率，显著提升了大语言模型推理的效率与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维（CoT）压缩方法要么在语义层面缩短推理过程，但往往过于保守；要么激进地剪枝标记，容易丢失关键任务线索并降低准确性。此外，将两者结合面临序列依赖、任务无关剪枝和分布不匹配等挑战，因此亟需一种更高效且保持正确性的压缩方法。

Method: CtrlCoT包含三个核心组件：1）层次化推理抽象，生成多粒度的语义推理路径；2）逻辑保持蒸馏，训练一个感知逻辑的剪枝器以保留关键推理线索（如数字和运算符）；3）分布对齐生成，使压缩后的推理轨迹与推理时流畅风格一致，避免碎片化。

Result: 在MATH-500数据集上，使用Qwen2.5-7B-Instruct模型时，CtrlCoT比最强基线减少30.7%的令牌使用量，准确率提升7.6个百分点，验证了其在效率与可靠性上的优越性。

Conclusion: CtrlCoT成功实现了语义抽象与标记剪枝的协同优化，在显著降低计算开销的同时保持甚至提升推理准确性，为高效可靠的大型语言模型推理提供了新范式。

Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.

</details>


### [195] [Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function](https://arxiv.org/abs/2601.20554)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: This work extends online planning algorithms to optimize Iterated Conditional Value-at-Risk (ICVaR), enabling risk-averse decision-making in partially observable environments. With a tunable risk parameter $\alpha$, the methods reduce tail risk compared to standard expectation-based planners, and provide finite-time guarantees and novel exploration strategies.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address risk-sensitive planning in partially observable environments, where standard expectation-based methods may not adequately handle tail risks. The motivation is to develop planning algorithms that are robust to uncertainty and can incorporate risk aversion through a parameterized risk measure.

Method: The authors use the Iterated Conditional Value-at-Risk (ICVaR) dynamic risk measure to guide planning. They propose a policy evaluation algorithm with finite-time performance guarantees independent of action space size. Then, they extend three online planning algorithms—Sparse Sampling, PFT-DPW, and POMCPOW—to optimize ICVaR instead of expected return, introducing a risk parameter $\alpha$ that controls risk aversion.

Result: The proposed ICVaR-based planners show improved performance in reducing tail risk across benchmark POMDP domains compared to their risk-neutral versions. Additionally, for ICVaR Sparse Sampling, finite-time performance guarantees are established under the risk-sensitive objective, enabling a new exploration strategy tailored to risk aversion.

Conclusion: The integration of ICVaR into online planning algorithms provides a principled way to achieve risk-averse decision-making in partially observable settings, offering better control over extreme outcomes while maintaining theoretical guarantees and practical effectiveness.

Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.

</details>


### [196] [Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies](https://arxiv.org/abs/2601.20604)
*Gray Cox*

Main category: cs.AI

TL;DR: 本文提出了一种通过结构化多模型对话实证测试AI对齐策略的方法论框架，借鉴和平研究传统中的利益协商、冲突转化与公共治理思想，将对齐问题从控制问题重构为关系问题。实验采用四角色（提议者、回应者、监控者、翻译者）在六种条件下，使用Claude、Gemini和GPT-4o进行72轮对话，共576,822字符的交流。结果显示，不同AI模型能有效参与复杂对齐框架讨论，暴露架构视角下的互补性异议，并生成初始框架中未包含的新兴洞见，如‘VCW作为过渡框架’的新合成。各模型表现出不同关注点：Claude侧重验证挑战，Gemini关注偏见与可扩展性，GPT-4o强调实施障碍。该框架为对齐提案提供可复制的应力测试方法，初步证明了AI具备对话式推理能力。但对话更多聚焦过程而非对AI本质的基础性主张，未来需探索人机混合协议与延长对话研究。


<details>
  <summary>Details</summary>
Motivation: 当前AI对齐研究多聚焦于控制与安全，忽视其作为关系与协作问题的本质。本文旨在通过引入和平研究范式，将对齐重新定义为基于对话的协同建构过程，以提升其动态性与包容性。

Method: 设计六种条件的结构化多模型对话实验，分配四个角色（Proposer, Responder, Monitor, Translator）给不同大语言模型（Claude, Gemini, GPT-4o），进行72轮对话，总字符量达576,822。对话围绕对齐框架展开，结合和平研究中的核心概念如利益协商、冲突转化与公共治理，实现对齐策略的实证检验。

Result: AI系统能够有意义地参与和平研究概念的对话，揭示不同架构视角下的互补性异议，并产生超越原始框架的新兴洞察，如‘VCW作为过渡框架’。不同模型表现出差异化关注：Claude强调验证难题，Gemini关注偏见与可扩展性，GPT-4o则突出实施障碍。结果支持该框架作为对齐提案的可复制应力测试工具。

Conclusion: 本研究为AI对齐提供了一种基于对话的新型方法论，表明当前大模型具备参与复杂对齐讨论的能力。尽管对话仍偏重过程而未深入探讨AI本质，但已展现出对话式推理潜力。未来应发展人机混合协议与更长周期的对话研究，进一步深化对对齐机制的理解。

Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.

</details>


### [197] [Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation](https://arxiv.org/abs/2601.20614)
*Yanqi Dai,Yuxiang Ji,Xiao Zhang,Yong Wang,Xiangxiang Chu,Zhiwu Lu*

Main category: cs.AI

TL;DR: MathForge 提出了一种双重视角的框架，通过难度感知的策略优化（DGPO）和多方面问题重构（MQR）来增强大模型在数学推理中的表现。该框架解决了现有方法在算法和数据层面忽视难题的问题，显著提升了模型对复杂问题的处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在数学推理中未能充分关注更难的问题，导致模型在高难度任务上的能力发展不足。算法上GRPO存在更新幅度不平衡的问题，数据上增广方法仅重述问题而未提升内在难度。

Method: 提出MathForge框架，包含Difficulty-Aware Group Policy Optimization (DGPO) 和 Multi-Aspect Question Reformulation (MQR)。DGPO通过难度平衡的优势估计和问题级别加权来修正更新不平衡并优先处理难题；MQR从多个维度重构问题以增加难度但保持正确答案不变。

Result: 实验表明，MathForge在多个数学推理任务上显著优于现有方法，且代码与增强数据已开源。

Conclusion: MathForge通过算法与数据协同优化，有效提升了大模型对困难数学问题的推理能力，形成数据增强与学习优化的良性循环。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.

</details>


### [198] [Investigating the Development of Task-Oriented Communication in Vision-Language Models](https://arxiv.org/abs/2601.20641)
*Boaz Carmeli,Orr Paradise,Shafi Goldwasser,Yonatan Belinkov,Ron Meir*

Main category: cs.AI

TL;DR: 研究探讨了基于大语言模型（LLM）的智能体在协作推理任务中是否能发展出不同于标准自然语言的任务导向通信协议，重点关注其效率（更简洁地传达任务相关信息）和隐蔽性（外部观察者难以理解，引发透明度与控制问题）。通过视觉-语言模型（VLM）在参照游戏框架中的通信实验，发现智能体可形成高效且隐蔽的任务适配通信模式，并在未显式共享协议的情况下自发协调。该研究揭示了任务导向通信的潜力与风险，表明参照游戏是未来研究的重要测试平台。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型智能体在协作任务中是否能发展出超越自然语言的、更高效且隐蔽的通信协议，以评估其在实际应用中的潜力与潜在风险，特别是对系统透明性和可控性的挑战。

Method: 采用参照游戏框架，让视觉-语言模型（VLM）智能体在受控环境中进行通信，通过定量测量语言变体的表现来评估其效率与隐蔽性，同时观察智能体间是否能自发协调。

Result: VLM智能体能够发展出有效且任务适配的通信模式；部分协议表现出高度隐蔽性，难以被人类或外部智能体理解；即使没有预设共享协议，相似模型之间也能实现自发协调。

Conclusion: 任务导向通信具有提升效率的潜力，但同时也带来透明性与控制风险。参照游戏为研究此类通信机制提供了有效的实验框架，对未来智能体协作系统的设计与监管具有重要意义。

Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.

</details>


### [199] [Implementing Metric Temporal Answer Set Programming](https://arxiv.org/abs/2601.20735)
*Arvid Becker,Pedro Cabalar,Martin Diéguez,Susana Hahn,Javier Romero,Torsten Schaub*

Main category: cs.AI

TL;DR: 本文提出一种计算方法，用于度量答案集编程（Metric ASP），以表达定量时间约束（如持续时间和截止时间）。为解决细粒度时间约束带来的可扩展性问题，该方法利用差分约束（一种简化线性约束）扩展ASP，将时间相关处理外部化，从而解耦度量ASP与时间粒度，使解决方案不受时间精度影响。


<details>
  <summary>Details</summary>
Motivation: 传统ASP在处理精细时间约束时面临接地瓶颈，导致可扩展性下降；需要一种能有效处理定量时间约束且不依赖时间精度的解决方案。

Method: 通过引入差分约束扩展ASP，将时间相关逻辑外部化处理，实现度量ASP与时间粒度的解耦。

Result: 所提方法显著提升可扩展性，解决了因时间精度提高导致的性能恶化问题，保持了对时间粒度的独立性。

Conclusion: 该方法成功实现了对定量时间约束的有效建模，同时避免了时间精度对求解性能的影响，为度量ASP在复杂时间场景中的应用提供了可行路径。

Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.

</details>
