<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.CL](#cs.CL) [Total: 15]
- [cs.LG](#cs.LG) [Total: 52]
- [cs.AI](#cs.AI) [Total: 20]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Near-real time fires detection using satellite imagery in Sudan conflict](https://arxiv.org/abs/2512.07925)
*Kuldip Singh Atwal,Dieter Pfoser,Daniel Rothbart*

Main category: cs.CV

TL;DR: 本研究利用Planet Labs的4波段卫星影像与深度学习模型，实现对苏丹武装冲突中火灾损毁区域的近实时监测。通过五个案例研究验证了该方法的有效性，结果显示其在捕捉活跃火点和烧毁区域方面优于传统基线方法，且8波段或时间序列影像带来的改进有限。


<details>
  <summary>Details</summary>
Motivation: 苏丹持续战争凸显了快速监测和分析冲突地区的需求，现有技术难以满足近实时响应要求。

Method: 采用Planet Labs提供的4波段遥感影像，结合深度学习模型，对冲突中的火灾损毁进行自动化识别与监测。

Result: 相比基线方法，该自动化方法更准确地识别出活跃火点和烧毁区域；使用8波段或多时相影像仅带来微小性能提升。

Conclusion: 基于4波段影像与深度学习的监测方法可高效、低成本地实现对冲突地区火灾损毁的近实时监控，具备实际应用价值。

Abstract: The challenges of ongoing war in Sudan highlight the need for rapid moni- toring and analysis of such conflicts. Advances in deep learning and readily available satellite remote sensing imagery allow for near real-time monitor- ing. This paper uses 4-band imagery from Planet Labs with a deep learning model to show that fire damage in armed conflicts can be monitored with minimal delay. We demonstrate the effectiveness of our approach using five case studies in Sudan. We show that, compared to a baseline, the automated method captures the active fires and charred areas more accurately. Our re- sults indicate that using 8-band imagery or time series of such imagery only result in marginal gains.

</details>


### [2] [Preserving Source Video Realism: High-Fidelity Face Swapping for Cinematic Quality](https://arxiv.org/abs/2512.07951)
*Zekai Luo,Zongze Du,Zhouhang Zhu,Hao Zhong,Muzhi Zhu,Wen Wang,Yuling Xi,Chenchen Jing,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 本文提出LivingSwap，首个视频参考引导的人脸交换模型，利用关键帧作为条件信号注入目标身份，结合视频参考指导实现时间上的拼接，确保长视频序列中身份的稳定保留和高保真重建。为解决参考引导训练数据稀缺问题，构建了配对的人脸交换数据集Face2Face，并通过反转数据对保证可靠的监督信号。实验表明该方法在保持表情、光照和运动一致性的同时，显著降低制作流程中的手动工作量，达到当前最佳性能。


<details>
  <summary>Details</summary>
Motivation: 视频人脸交换在影视娱乐制作中至关重要，但如何在长而复杂的视频序列中实现高保真度与时间一致性仍是一大挑战。受近期参考引导图像编辑进展启发，探索是否可利用源视频中的丰富视觉属性来提升人脸交换的保真度与时间连贯性。

Method: 采用关键帧作为条件信号注入目标身份，结合视频参考引导进行时间拼接，实现身份稳定性和高保真重建；构建新数据集Face2Face并反转数据对以提供可靠监督信号。

Result: 在长视频序列中实现了高质量的身份保留与自然表达、光照及运动融合，显著减少人工干预，优于现有方法，在多个指标上达到最新技术水平。

Conclusion: LivingSwap是首个视频参考引导的人脸交换模型，通过关键帧条件与参考引导有效提升了长时间视频中的人脸交换质量，为影视制作提供了高效、可控的解决方案。

Abstract: Video face swapping is crucial in film and entertainment production, where achieving high fidelity and temporal consistency over long and complex video sequences remains a significant challenge. Inspired by recent advances in reference-guided image editing, we explore whether rich visual attributes from source videos can be similarly leveraged to enhance both fidelity and temporal coherence in video face swapping. Building on this insight, this work presents LivingSwap, the first video reference guided face swapping model. Our approach employs keyframes as conditioning signals to inject the target identity, enabling flexible and controllable editing. By combining keyframe conditioning with video reference guidance, the model performs temporal stitching to ensure stable identity preservation and high-fidelity reconstruction across long video sequences. To address the scarcity of data for reference-guided training, we construct a paired face-swapping dataset, Face2Face, and further reverse the data pairs to ensure reliable ground-truth supervision. Extensive experiments demonstrate that our method achieves state-of-the-art results, seamlessly integrating the target identity with the source video's expressions, lighting, and motion, while significantly reducing manual effort in production workflows. Project webpage: https://aim-uofa.github.io/LivingSwap

</details>


### [3] [FRIEDA: Benchmarking Multi-Step Cartographic Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.08016)
*Jiyoon Pyo,Yuankun Jiao,Dongwon Jung,Zekun Li,Leeje Jang,Sofia Kirsanova,Jina Kim,Yijun Lin,Qin Liu,Junyi Xie,Hadi Askari,Nan Xu,Muhao Chen,Yao-Yi Chiang*

Main category: cs.CV

TL;DR: FRIEDA 是一个针对视觉语言模型（LVLMs）的复杂制图推理基准，旨在评估其在多地图、多层次符号和空间关系理解上的能力。该基准涵盖拓扑、度量和方向三类空间关系，要求多步推理与跨图定位，测试结果显示当前最强模型准确率仅约38%，远低于人类水平（84.87%），揭示了现有模型在空间智能方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有地图视觉问答（VQA）研究将地图视为图表的特例，未能充分捕捉地图特有的分层符号系统和跨图空间关系，导致对复杂制图推理能力的评估不足，亟需一个更全面、严谨的基准来推动视觉语言模型在空间认知方面的发展。

Method: FRIEDA 从真实文档和报告中收集多领域、多地理区域的地图图像，依据GIS文献分类构建包含拓扑、度量和方向三类空间关系的问答数据集；所有问题均需多步推理，并涉及跨图接地与推理；在两种设置下评估11个先进LVLMs：直接设置（提供相关地图）与上下文设置（需自主识别相关地图）。

Result: 即使最强的模型（Gemini-2.5-Pro 和 GPT-5-Think）在直接设置下的准确率也仅为38.20%和37.20%，而人类表现达84.87%，表明当前模型在复杂制图推理任务上存在巨大差距。

Conclusion: FRIEDA 作为一个严格的基准，有效揭示了当前视觉语言模型在多步制图推理和空间智能方面的严重不足，为未来研究提供了明确的方向和评估标准。

Abstract: Cartographic reasoning is the skill of interpreting geographic relationships by aligning legends, map scales, compass directions, map texts, and geometries across one or more map images. Although essential as a concrete cognitive capability and for critical tasks such as disaster response and urban planning, it remains largely unevaluated. Building on progress in chart and infographic understanding, recent large vision language model studies on map visual question-answering often treat maps as a special case of charts. In contrast, map VQA demands comprehension of layered symbology (e.g., symbols, geometries, and text labels) as well as spatial relations tied to orientation and distance that often span multiple maps and are not captured by chart-style evaluations. To address this gap, we introduce FRIEDA, a benchmark for testing complex open-ended cartographic reasoning in LVLMs. FRIEDA sources real map images from documents and reports in various domains and geographical areas. Following classifications in Geographic Information System (GIS) literature, FRIEDA targets all three categories of spatial relations: topological (border, equal, intersect, within), metric (distance), and directional (orientation). All questions require multi-step inference, and many require cross-map grounding and reasoning. We evaluate eleven state-of-the-art LVLMs under two settings: (1) the direct setting, where we provide the maps relevant to the question, and (2) the contextual setting, where the model may have to identify the maps relevant to the question before reasoning. Even the strongest models, Gemini-2.5-Pro and GPT-5-Think, achieve only 38.20% and 37.20% accuracy, respectively, far below human performance of 84.87%. These results reveal a persistent gap in multi-step cartographic reasoning, positioning FRIEDA as a rigorous benchmark to drive progress on spatial intelligence in LVLMs.

</details>


### [4] [SSplain: Sparse and Smooth Explainer for Retinopathy of Prematurity Classification](https://arxiv.org/abs/2512.08038)
*Elifnur Sunger,Tales Imbiriba,Peter Campbell,Deniz Erdogmus,Stratis Ioannidis,Jennifer Dy*

Main category: cs.CV

TL;DR: 本文提出一种名为SSplain的新解释方法，用于从眼底图像中分类早产儿视网膜病变（ROP）。该方法通过在优化问题中引入平滑性和稀疏性约束，生成保留输入图像结构的像素级解释，从而提升模型可解释性与临床可信度。实验表明，SSplain在后验准确性与平滑性分析方面优于现有方法，并能识别出与临床专家判断一致的关键特征，且具备良好的泛化能力。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有模型解释方法无法有效保持眼底图像的结构特性（如平滑性和稀疏性），导致生成的解释不真实、不可信，限制了其在医疗诊断中的应用。

Method: 提出基于交替方向乘子法（ADMM）求解带有组合约束的优化问题，以生成兼具平滑性与稀疏性的像素级解释。

Result: SSplain在解释质量、平滑性及与临床知识的一致性方面均优于主流解释器，在多个公开数据集上表现稳定，验证了其有效性与泛化能力。

Conclusion: SSplain是一种能够生成结构保真、可解释性强的医学图像解释的方法，有助于提升医生对黑箱模型的信任，推动AI在医疗诊断中的实际应用。

Abstract: Neural networks are frequently used in medical diagnosis. However, due to their black-box nature, model explainers are used to help clinicians understand better and trust model outputs. This paper introduces an explainer method for classifying Retinopathy of Prematurity (ROP) from fundus images. Previous methods fail to generate explanations that preserve input image structures such as smoothness and sparsity. We introduce Sparse and Smooth Explainer (SSplain), a method that generates pixel-wise explanations while preserving image structures by enforcing smoothness and sparsity. This results in realistic explanations to enhance the understanding of the given black-box model. To achieve this goal, we define an optimization problem with combinatorial constraints and solve it using the Alternating Direction Method of Multipliers (ADMM). Experimental results show that SSplain outperforms commonly used explainers in terms of both post-hoc accuracy and smoothness analyses. Additionally, SSplain identifies features that are consistent with domain-understandable features that clinicians consider as discriminative factors for ROP. We also show SSplain's generalization by applying it to additional publicly available datasets. Code is available at https://github.com/neu-spiral/SSplain.

</details>


### [5] [Towards Sustainable Universal Deepfake Detection with Frequency-Domain Masking](https://arxiv.org/abs/2512.08042)
*Chandler Timm C. Doloriel,Habib Ullah,Kristian Hovde Liland,Fadi Al Machot,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: 本文提出一种基于频域掩码的深度伪造检测方法，通过随机掩码和几何变换提升模型对多种生成模型（包括未见模型）的泛化能力。该方法在保持低计算开销的同时，显著提高检测准确率，并在模型剪枝下仍保持鲁棒性，适用于大规模绿色AI场景下的深度伪造识别。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法依赖空间特征或大型预训练模型，难以应对不断涌现的新生成模型，且计算成本高，不利于大规模应用。需要一种高效、通用且可持续的检测方案以满足绿色AI需求。

Method: 采用频域掩码作为训练策略，结合随机掩码与几何变换，重点利用频域信息增强模型对未知生成器的泛化能力，同时降低对计算资源的依赖。

Result: 在GAN与扩散模型生成的图像数据集上达到当前最优的泛化性能；在结构化剪枝下依然保持稳定表现，验证了其高效性和可扩展性。

Conclusion: 频域掩码是一种具有潜力的可持续、通用性强的深度伪造检测方法，为未来绿色AI背景下的大规模检测提供了实用路径。

Abstract: Universal deepfake detection aims to identify AI-generated images across a broad range of generative models, including unseen ones. This requires robust generalization to new and unseen deepfakes, which emerge frequently, while minimizing computational overhead to enable large-scale deepfake screening, a critical objective in the era of Green AI. In this work, we explore frequency-domain masking as a training strategy for deepfake detectors. Unlike traditional methods that rely heavily on spatial features or large-scale pretrained models, our approach introduces random masking and geometric transformations, with a focus on frequency masking due to its superior generalization properties. We demonstrate that frequency masking not only enhances detection accuracy across diverse generators but also maintains performance under significant model pruning, offering a scalable and resource-conscious solution. Our method achieves state-of-the-art generalization on GAN- and diffusion-generated image datasets and exhibits consistent robustness under structured pruning. These results highlight the potential of frequency-based masking as a practical step toward sustainable and generalizable deepfake detection. Code and models are available at: [https://github.com/chandlerbing65nm/FakeImageDetection](https://github.com/chandlerbing65nm/FakeImageDetection).

</details>


### [6] [Mask to Adapt: Simple Random Masking Enables Robust Continual Test-Time Learning](https://arxiv.org/abs/2512.08048)
*Chandler Timm C. Doloriel*

Main category: cs.CV

TL;DR: M2A提出一种简单的持续测试时间自适应方法，通过随机掩码生成短序列的掩码视图（空间或频率），结合掩码一致性损失和熵最小化损失进行适应。在强噪声下，空间掩码版本表现优异，优于或匹配现有强基线，而频率掩码表现较差。消融实验表明，简单随机掩码已足够有效且鲁棒，无需依赖不确定性或注意力信号。


<details>
  <summary>Details</summary>
Motivation: 现有持续测试时间自适应方法依赖校准的不确定性或稳定的注意力分数，设计复杂。本文质疑是否需要专门设计的掩码策略，探索简单随机掩码在强扰动下的有效性。

Method: 提出Mask to Adapt (M2A)方法，采用随机生成的短掩码序列（空间或频率），利用掩码一致性损失对齐不同视图预测，并通过熵最小化损失促使模型输出更自信。比较了多种掩码类型：空间掩码（补丁与像素）和频率掩码（全频、低频、高频）。

Result: 在CIFAR10C/CIFAR100C/ImageNetC（严重性5）上，M2A（空间）分别达到8.3%、19.8%、39.2%的平均误差，优于或匹配强基线；M2A（频率）表现较弱。消融实验验证随机掩码的有效性与鲁棒性。

Conclusion: 简单随机掩码配合一致性与熵最小化目标，足以实现有效的测试时间自适应，无需依赖不确定性或注意力信号，显著简化方法设计。

Abstract: Distribution shifts at test time degrade image classifiers. Recent continual test-time adaptation (CTTA) methods use masking to regulate learning, but often depend on calibrated uncertainty or stable attention scores and introduce added complexity. We ask: do we need custom-made masking designs, or can a simple random masking schedule suffice under strong corruption? We introduce Mask to Adapt (M2A), a simple CTTA approach that generates a short sequence of masked views (spatial or frequency) and adapts with two objectives: a mask consistency loss that aligns predictions across different views and an entropy minimization loss that encourages confident outputs. Motivated by masked image modeling, we study two common masking families -- spatial masking and frequency masking -- and further compare subtypes within each (spatial: patch vs.\ pixel; frequency: all vs.\ low vs.\ high). On CIFAR10C/CIFAR100C/ImageNetC (severity~5), M2A (Spatial) attains 8.3\%/19.8\%/39.2\% mean error, outperforming or matching strong CTTA baselines, while M2A (Frequency) lags behind. Ablations further show that simple random masking is effective and robust. These results indicate that a simple random masking schedule, coupled with consistency and entropy objectives, is sufficient to drive effective test-time adaptation without relying on uncertainty or attention signals.

</details>


### [7] [CVP: Central-Peripheral Vision-Inspired Multimodal Model for Spatial Reasoning](https://arxiv.org/abs/2512.08135)
*Zeyuan Chen,Xiang Zhang,Haiyang Xu,Jianwen Xie,Zhuowen Tu*

Main category: cs.CV

TL;DR: CVP是一种受人类中央视觉和周边视觉启发的多模态框架，通过引入目标亲和标记（类中央视觉）和非中心网格（类周边视觉）来增强3D场景理解中的空间推理能力，显著提升模型对复杂环境的结构化、上下文感知理解，实验表明其在多个3D场景理解基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于点云、体素或块特征等非结构化表示，并通过坐标嵌入隐式注入场景上下文，导致空间推理能力有限，缺乏显式的高层次结构理解。

Method: 提出两种互补组件：目标亲和标记（模拟中央视觉，引导注意力聚焦于相关物体）和非中心网格（模拟周边视觉，捕捉全局场景上下文与空间布局），二者协同工作以实现结构化、上下文感知的3D环境理解。

Result: CVP在多个3D场景理解基准上实现了最先进的性能，验证了其在空间推理方面的有效性与优越性。

Conclusion: CVP通过模仿人类视觉系统中中央与周边视觉的分工，有效提升了大型多模态模型在复杂3D环境中的空间推理能力，为多模态场景理解提供了新范式。

Abstract: We present a central-peripheral vision-inspired framework (CVP), a simple yet effective multimodal model for spatial reasoning that draws inspiration from the two types of human visual fields -- central vision and peripheral vision. Existing approaches primarily rely on unstructured representations, such as point clouds, voxels, or patch features, and inject scene context implicitly via coordinate embeddings. However, this often results in limited spatial reasoning capabilities due to the lack of explicit, high-level structural understanding. To address this limitation, we introduce two complementary components into a Large Multimodal Model-based architecture: target-affinity token, analogous to central vision, that guides the model's attention toward query-relevant objects; and allocentric grid, akin to peripheral vision, that captures global scene context and spatial arrangements. These components work in tandem to enable structured, context-aware understanding of complex 3D environments. Experiments show that CVP achieves state-of-the-art performance across a range of 3D scene understanding benchmarks.

</details>


### [8] [Fourier-RWKV: A Multi-State Perception Network for Efficient Image Dehazing](https://arxiv.org/abs/2512.08161)
*Lirong Zheng,Yanshan Li,Rui Yu,Kaihao Zhang*

Main category: cs.CV

TL;DR: 提出一种基于多状态感知范式的新型去雾框架Fourier-RWKV，通过结合空间、频域和语义关系三种感知状态，实现对非均匀雾霾的全面建模。该方法以线性复杂度替代传统Transformer的二次复杂度，在保持全局上下文捕捉能力的同时显著降低计算开销，实现在多种雾霾场景下的先进性能与高效部署之间的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer-based去雾方法虽能有效捕捉全局上下文，但其二次计算复杂度限制了实时应用；真实世界中的非均匀雾霾分布更增加了建模难度，亟需兼顾性能与效率的新架构。

Method: 采用多状态感知设计：(1) 空间形态感知通过可变形四向令牌移位（DQ-Shift）动态调整感受野以适应局部雾霾变化；(2) 频域感知在Fourier Mix模块中将RWKV核心机制从空间域扩展至傅里叶域，保留长程依赖并缓解空间衰减；(3) 语义关系感知通过语义桥模块（SBM）与动态语义核融合（DSK-Fusion）精确对齐编码器与解码器特征，抑制伪影。

Result: 在多个基准数据集上进行的大量实验表明，Fourier-RWKV在各种雾霾条件下均达到当前最优性能，同时大幅降低计算开销，实现了高质量恢复与实用效率之间的理想权衡。

Conclusion: Fourier-RWKV为非均匀去雾任务提供了一种高效且强大的解决方案，兼具高精度与低延迟特性，具备良好的实际应用前景。

Abstract: Image dehazing is crucial for reliable visual perception, yet it remains highly challenging under real-world non-uniform haze conditions. Although Transformer-based methods excel at capturing global context, their quadratic computational complexity hinders real-time deployment. To address this, we propose Fourier Receptance Weighted Key Value (Fourier-RWKV), a novel dehazing framework based on a Multi-State Perception paradigm. The model achieves comprehensive haze degradation modeling with linear complexity by synergistically integrating three distinct perceptual states: (1) Spatial-form Perception, realized through the Deformable Quad-directional Token Shift (DQ-Shift) operation, which dynamically adjusts receptive fields to accommodate local haze variations; (2) Frequency-domain Perception, implemented within the Fourier Mix block, which extends the core WKV attention mechanism of RWKV from the spatial domain to the Fourier domain, preserving the long-range dependencies essential for global haze estimation while mitigating spatial attenuation; (3) Semantic-relation Perception, facilitated by the Semantic Bridge Module (SBM), which utilizes Dynamic Semantic Kernel Fusion (DSK-Fusion) to precisely align encoder-decoder features and suppress artifacts. Extensive experiments on multiple benchmarks demonstrate that Fourier-RWKV delivers state-of-the-art performance across diverse haze scenarios while significantly reducing computational overhead, establishing a favorable trade-off between restoration quality and practical efficiency. Code is available at: https://github.com/Dilizlr/Fourier-RWKV.

</details>


### [9] [GeoLoom: High-quality Geometric Diagram Generation from Textual Input](https://arxiv.org/abs/2512.08180)
*Xiaojing Wei,Ting Zhang,Wei He,Jingdong Wang,Hua Huang*

Main category: cs.CV

TL;DR: GeoLoom是一个用于几何领域文本到图表生成的新框架，通过将自然语言描述转化为形式化语言GeoLingua，并利用蒙特卡洛优化求解坐标，实现高精度的几何图生成。研究还提出了GeoNF数据集和基于约束的评估指标，显著提升生成结果的结构保真度。


<details>
  <summary>Details</summary>
Motivation: 现有几何图生成方法在空间准确性上存在不足，缺乏可解释性和严格约束支持，亟需一种能保证几何正确性且具备可解释性的生成框架。

Method: 提出GeoLoom框架，包含自动形式化模块（将自然语言转为GeoLingua）和坐标求解器（使用蒙特卡洛优化求解精确坐标），并构建了GeoNF数据集与约束评估指标。

Result: 实验表明，GeoLoom在结构保真度上显著优于现有基线方法，实现了可解释、可扩展的高质量几何图生成。

Conclusion: GeoLoom为几何文本到图的生成提供了原理严谨、可扩展的解决方案，推动了高精度、可解释性图生成的发展。

Abstract: High-quality geometric diagram generation presents both a challenge and an opportunity: it demands strict spatial accuracy while offering well-defined constraints to guide generation. Inspired by recent advances in geometry problem solving that employ formal languages and symbolic solvers for enhanced correctness and interpretability, we propose GeoLoom, a novel framework for text-to-diagram generation in geometric domains. GeoLoom comprises two core components: an autoformalization module that translates natural language into a specifically designed generation-oriented formal language GeoLingua, and a coordinate solver that maps formal constraints to precise coordinates using the efficient Monte Carlo optimization. To support this framework, we introduce GeoNF, a dataset aligning natural language geometric descriptions with formal GeoLingua descriptions. We further propose a constraint-based evaluation metric that quantifies structural deviation, offering mathematically grounded supervision for iterative refinement. Empirical results demonstrate that GeoLoom significantly outperforms state-of-the-art baselines in structural fidelity, providing a principled foundation for interpretable and scalable diagram generation.

</details>


### [10] [VisKnow: Constructing Visual Knowledge Base for Object Understanding](https://arxiv.org/abs/2512.08221)
*Ziwei Yao,Qiyang Wan,Ruiping Wang,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出Visual Knowledge Base（VisKnow）框架，通过整合图文多模态知识与区域标注，构建结构化的对象知识图谱。以动物知识库AnimalKB为例，涵盖406个动物类别，包含22,000条文本三元组、42万张图像及对应标注。实验表明该知识库可提升零样本识别与细粒度视觉问答性能，并作为知识图谱补全和部件分割的基准。


<details>
  <summary>Details</summary>
Motivation: 现有对象理解任务依赖于任务导向的标注数据，缺乏系统化组织的多模态知识支持，难以实现深层次的对象认知。因此需要一种统一的结构化知识表示方式来整合视觉与文本信息，推动更全面的视觉理解。

Method: 提出VisKnow框架，结合专家设计与大规模模型技术，从百科文档和图像中提取对象级多模态知识，构建基于图结构的视觉知识库；通过区域标注（对象与部件级别）对齐图文信息，实现知识的系统化组织。

Result: 成功构建AnimalKB知识库，覆盖406类动物，包含22,000条文本三元组、42万张图像及标注；实验证明其在零样本识别、细粒度VQA、知识图谱补全和部件分割任务中均具有显著提升效果，具备作为基准测试的能力。

Conclusion: 自动构建视觉知识库是推动视觉理解与实际应用的重要方向，本研究展示了多模态知识结构化对提升对象理解能力的巨大潜力。

Abstract: Understanding objects is fundamental to computer vision. Beyond object recognition that provides only a category label as typical output, in-depth object understanding represents a comprehensive perception of an object category, involving its components, appearance characteristics, inter-category relationships, contextual background knowledge, etc. Developing such capability requires sufficient multi-modal data, including visual annotations such as parts, attributes, and co-occurrences for specific tasks, as well as textual knowledge to support high-level tasks like reasoning and question answering. However, these data are generally task-oriented and not systematically organized enough to achieve the expected understanding of object categories. In response, we propose the Visual Knowledge Base that structures multi-modal object knowledge as graphs, and present a construction framework named VisKnow that extracts multi-modal, object-level knowledge for object understanding. This framework integrates enriched aligned text and image-source knowledge with region annotations at both object and part levels through a combination of expert design and large-scale model application. As a specific case study, we construct AnimalKB, a structured animal knowledge base covering 406 animal categories, which contains 22K textual knowledge triplets extracted from encyclopedic documents, 420K images, and corresponding region annotations. A series of experiments showcase how AnimalKB enhances object-level visual tasks such as zero-shot recognition and fine-grained VQA, and serves as challenging benchmarks for knowledge graph completion and part segmentation. Our findings highlight the potential of automatically constructing visual knowledge bases to advance visual understanding and its practical applications. The project page is available at https://vipl-vsu.github.io/VisKnow.

</details>


### [11] [SOP^2: Transfer Learning with Scene-Oriented Prompt Pool on 3D Object Detection](https://arxiv.org/abs/2512.08223)
*Ching-Hung Cheng,Hsiu-Fu Wu,Bing-Chen Wu,Khanh-Phong Bui,Van-Tin Luu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: 本文探讨了在3D物体检测中使用提示调优（prompt tuning）方法的有效性，研究大型语言模型（如GPT-3）通过迁移学习在不同任务间的适应能力。特别关注基于Waymo大规模数据集训练的模型是否可作为基础模型，在其他3D检测场景中进行有效迁移。研究分析了提示标记和提示生成器的影响，并提出了一种面向场景的提示池（SOP$^2$），验证了提示池在3D物体检测中的有效性，旨在激发未来研究者对提示在三维领域潜力的深入探索。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在自然语言处理中展现出强大的泛化能力，通过提示调优等技术可高效适配下游任务。然而，其在3D物体检测等视觉任务中的应用尚不充分。本文旨在探索提示调优在3D检测中的可行性与有效性，推动提示技术在三维领域的拓展。

Method: 采用提示调优方法，系统评估提示标记与提示生成器的作用；提出一种新型的场景导向提示池（SOP$^2$），利用预定义的提示集合增强模型对不同场景的适应能力，并在多个3D物体检测数据集上进行实验验证。

Result: 实验结果表明，所提出的SOP$^2$方法显著提升了模型在不同3D检测场景下的性能，证明了提示池在3D物体检测中的有效性。同时，提示调优在无需大量参数更新的情况下实现了良好的迁移效果。

Conclusion: 本研究验证了提示调优在3D物体检测中的可行性和优越性，提出SOP$^2$为提升模型跨场景泛化能力提供了新思路，为后续在三维视觉任务中探索提示工程奠定了基础。

Abstract: With the rise of Large Language Models (LLMs) such as GPT-3, these models exhibit strong generalization capabilities. Through transfer learning techniques such as fine-tuning and prompt tuning, they can be adapted to various downstream tasks with minimal parameter adjustments. This approach is particularly common in the field of Natural Language Processing (NLP). This paper aims to explore the effectiveness of common prompt tuning methods in 3D object detection. We investigate whether a model trained on the large-scale Waymo dataset can serve as a foundation model and adapt to other scenarios within the 3D object detection field. This paper sequentially examines the impact of prompt tokens and prompt generators, and further proposes a Scene-Oriented Prompt Pool (\textbf{SOP$^2$}). We demonstrate the effectiveness of prompt pools in 3D object detection, with the goal of inspiring future researchers to delve deeper into the potential of prompts in the 3D field.

</details>


### [12] [MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models](https://arxiv.org/abs/2512.08228)
*Jusheng Zhang,Kaitong Cai,Xiaoyang Guo,Sidi Liu,Qinhan Lv,Ruiqi Chen,Jing Yang,Yijia Fan,Xiaofei Sun,Jian Wang,Ziliang Chen,Liang Lin,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出MM-CoT，一个诊断性基准，用于评估多模态模型在视觉推理中的视觉基础性和逻辑连贯性。与现有侧重生成的基准不同，MM-CoT要求模型从多个事件链中选择唯一满足视觉一致性和逻辑合理性双重约束的选项，并通过对抗性干扰项暴露模型的推理缺陷。实验表明，即使最先进的模型也表现不佳，揭示了生成流畅性与真实推理质量之间的显著差距。该基准与现有评测相关性低，验证其测量的是独特且关键的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注生成能力，忽视了对推理链是否基于视觉证据和逻辑上合理性的验证。为填补这一空白，需要一个能够有效评估多模态模型视觉基础性和逻辑连贯性的新基准。

Method: 设计并构建MM-CoT基准，要求模型从多个候选事件链中选出唯一同时满足视觉一致性和逻辑连贯性两个条件的链条；引入对抗性干扰项以破坏任一约束，从而识别模型在视觉锚定或逻辑推理上的具体失败模式。

Result: 领先视觉-语言模型在MM-CoT上表现不佳，显示出生成流畅性与真实推理质量之间存在明显差距；该基准与现有评测相关性较低，证明其测量的是独立且重要的推理维度。

Conclusion: MM-CoT提供了一个有效的工具，用于评估多模态模型是否真正基于视觉证据进行逻辑连贯的推理，推动未来模型向更忠实、更可靠的视觉推理方向发展。

Abstract: The ability to perform Chain-of-Thought (CoT) reasoning marks a major milestone for multimodal models (MMs), enabling them to solve complex visual reasoning problems. Yet a critical question remains: is such reasoning genuinely grounded in visual evidence and logically coherent? Existing benchmarks emphasize generation but neglect verification, i.e., the capacity to assess whether a reasoning chain is both visually consistent and logically valid. To fill this gap, we introduce MM-CoT, a diagnostic benchmark specifically designed to probe the visual grounding and logical coherence of CoT reasoning in MMs. Instead of generating free-form explanations, models must select the sole event chain that satisfies two orthogonal constraints: (i) visual consistency, ensuring all steps are anchored in observable evidence, and (ii) logical coherence, ensuring causal and commonsense validity. Adversarial distractors are engineered to violate one of these constraints, exposing distinct reasoning failures. We evaluate leading vision-language models on MM-CoT and find that even the most advanced systems struggle, revealing a sharp discrepancy between generative fluency and true reasoning fidelity. MM-CoT shows low correlation with existing benchmarks, confirming that it measures a unique combination of visual grounding and logical reasoning. This benchmark provides a foundation for developing future models that reason not just plausibly, but faithfully and coherently within the visual world.

</details>


### [13] [Geometry-Aware Sparse Depth Sampling for High-Fidelity RGB-D Depth Completion in Robotic Systems](https://arxiv.org/abs/2512.08229)
*Tony Salloom,Dandi Zhou,Xinhai Sun*

Main category: cs.CV

TL;DR: 本文提出一种基于法向量的稀疏深度采样策略，利用PCA估计RGB-D点云的表面法向量，计算每个像素的深度可靠性，进而根据该可靠性分布采样稀疏深度。结合Marigold-DC扩散模型，在NYU Depth v2数据集上验证，结果表明该方法提升了深度完成的准确性，减少了边缘和不连续处的伪影，并创造了更真实的训练条件。


<details>
  <summary>Details</summary>
Motivation: 现有深度完成方法在采样稀疏深度时通常采用随机均匀采样，忽略了真实传感器在不同几何结构和空间位置上的深度可靠性差异，导致训练条件与实际传感器行为不符。

Method: 通过PCA方法对RGB-D点云进行表面法向量估计，构建每像素的深度可靠性度量，并据此生成非均匀、几何感知的稀疏深度采样；将该策略集成至Marigold-DC扩散模型中进行深度完成。

Result: 在NYU Depth v2数据集上，所提方法显著提升深度完成精度，有效减少边缘和不连续区域的伪影，且训练过程更贴近真实传感器行为。

Conclusion: 提出的正常引导的稀疏深度采样策略能够更真实地模拟传感器可靠性，显著提升深度完成性能，为未来深度感知系统设计提供了更合理的训练范式。

Abstract: Accurate three-dimensional perception is essential for modern industrial robotic systems that perform manipulation, inspection, and navigation tasks. RGB-D and stereo vision sensors are widely used for this purpose, but the depth maps they produce are often noisy, incomplete, or biased due to sensor limitations and environmental conditions. Depth completion methods aim to generate dense, reliable depth maps from RGB images and sparse depth input. However, a key limitation in current depth completion pipelines is the unrealistic generation of sparse depth: sparse pixels are typically selected uniformly at random from dense ground-truth depth, ignoring the fact that real sensors exhibit geometry-dependent and spatially nonuniform reliability. In this work, we propose a normal-guided sparse depth sampling strategy that leverages PCA-based surface normal estimation on the RGB-D point cloud to compute a per-pixel depth reliability measure. The sparse depth samples are then drawn according to this reliability distribution. We integrate this sampling method with the Marigold-DC diffusion-based depth completion model and evaluate it on NYU Depth v2 using the standard metrics. Experiments show that our geometry-aware sparse depth improves accuracy, reduces artifacts near edges and discontinuities, and produces more realistic training conditions that better reflect real sensor behavior.

</details>


### [14] [FastBEV++: Fast by Algorithm, Deployable by Design](https://arxiv.org/abs/2512.08237)
*Yuanpeng Chen,Hui Song,Wei Tao,ShanHui Mo,Shuang Zhang,Xiao Hua,TianKun Zhao*

Main category: cs.CV

TL;DR: FastBEV++ 提出一种兼顾高性能与高效部署的相机仅鸟瞰图（BEV）感知框架，通过‘算法快速’和‘设计可部署’两大原则，解决现有方法在计算复杂度与实际车载部署之间的矛盾。其核心创新在于将视图变换分解为标准的索引-收集-重塑流水线，利用确定性预排序策略，仅使用原生算子（如 Gather、矩阵乘法），避免专用 CUDA 内核，实现完全 TensorRT 兼容。同时，该结构支持端到端深度感知融合，结合时序聚合与增强数据，显著提升 BEV 表达的几何保真度。在 nuScenes 基准上，FastBEV++ 达到 0.359 NDS 的新 SOTA，且在车载硬件（如 Tesla T4）上超过 134 FPS，无需自定义插件即可实现高精度与实时性，适用于生产级自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 当前相机仅鸟瞰图（BEV）感知面临性能与车载部署之间难以兼顾的挑战，主要源于对计算开销大且平台依赖的视图变换和定制内核的严重依赖。亟需一种既保持高精度又具备良好部署可行性的新方法。

Method: 提出 FastBEV++ 框架，采用两项核心设计：1）‘Deployable by Design’——将视图变换重构为标准 Index-Gather-Reshape 流水线，结合确定性预排序，仅使用原生算子（Gather、矩阵乘法等），摆脱专用 CUDA 内核，实现 TensorRT 完全兼容；2）‘Fast by Algorithm’——基于该结构构建端到端深度感知融合机制，融合时序信息与数据增强，提升 BEV 表示的几何准确性。

Result: 在 nuScenes 基准上，FastBEV++ 实现 0.359 NDS 的新状态最优性能，同时在 Tesla T4 等车载硬件上达到超过 134 FPS 的实时推理速度，无需自定义插件，兼具高精度与高效部署能力。

Conclusion: FastBEV++ 成功实现了高性能与部署效率的统一，提供了一种面向生产级自动驾驶系统的成熟、可扩展的设计范式，为后续视觉感知系统研发提供了重要参考。

Abstract: The advancement of camera-only Bird's-Eye-View(BEV) perception is currently impeded by a fundamental tension between state-of-the-art performance and on-vehicle deployment tractability. This bottleneck stems from a deep-rooted dependency on computationally prohibitive view transformations and bespoke, platform-specific kernels. This paper introduces FastBEV++, a framework engineered to reconcile this tension, demonstrating that high performance and deployment efficiency can be achieved in unison via two guiding principles: Fast by Algorithm and Deployable by Design. We realize the "Deployable by Design" principle through a novel view transformation paradigm that decomposes the monolithic projection into a standard Index-Gather-Reshape pipeline. Enabled by a deterministic pre-sorting strategy, this transformation is executed entirely with elementary, operator native primitives (e.g Gather, Matrix Multiplication), which eliminates the need for specialized CUDA kernels and ensures fully TensorRT-native portability. Concurrently, our framework is "Fast by Algorithm", leveraging this decomposed structure to seamlessly integrate an end-to-end, depth-aware fusion mechanism. This jointly learned depth modulation, further bolstered by temporal aggregation and robust data augmentation, significantly enhances the geometric fidelity of the BEV representation.Empirical validation on the nuScenes benchmark corroborates the efficacy of our approach. FastBEV++ establishes a new state-of-the-art 0.359 NDS while maintaining exceptional real-time performance, exceeding 134 FPS on automotive-grade hardware (e.g Tesla T4). By offering a solution that is free of custom plugins yet highly accurate, FastBEV++ presents a mature and scalable design philosophy for production autonomous systems. The code is released at: https://github.com/ymlab/advanced-fastbev

</details>


### [15] [HybridToken-VLM: Hybrid Token Compression for Vision-Language Models](https://arxiv.org/abs/2512.08240)
*Jusheng Zhang,Xiaoyang Guo,Kaitong Cai,Qinhan Lv,Yijia Fan,Wenhao Chai,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: HTC-VLM提出一种混合框架，通过双通道分离语义与外观：连续路径保留细粒度视觉细节，离散路径使用MGVQ量化生成4个符号锚点。两者融合为580令牌的混合序列，经压缩成单一voco令牌，实现580:1的压缩比，同时保持87.2%的平均性能，优于连续基线（81.0%），并验证了压缩令牌对离散锚点的优先关注，解决效率与保真度之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 传统方法在连续压缩和离散量化之间存在权衡：连续压缩会丢失高层语义（如物体身份），离散量化则损失细节（如纹理）。为突破这一效率-精度困境，需一种既能保留细节又能高效压缩的新型多模态表示方法。

Method: HTC-VLM采用双通道设计：一条连续路径处理ViT图像块以保留细粒度信息；另一条离散路径通过MGVQ量化将视觉内容映射为四个符号锚点。通过解耦注意力掩码与瓶颈机制，将两种路径融合为580令牌的混合序列，并进一步压缩为一个voco令牌，实现高效且语义可解释的表示。

Result: HTC-VLM在七个基准测试（GQA、VQAv2、MMBench、MME、POPE、SEED-Bench、ScienceQA-Image）上平均性能保留率达87.2%，显著优于领先的连续基线（81.0%），并在注意力分析中显示压缩令牌优先关注离散锚点，证明其语义引导能力。

Conclusion: 本研究证明，简约的混合设计可在不牺牲模型性能的前提下有效缓解多模态推理中的计算负担，为构建可扩展的视觉语言模型提供了新范式。

Abstract: Vision-language models (VLMs) have transformed multimodal reasoning, but feeding hundreds of visual patch tokens into LLMs incurs quadratic computational costs, straining memory and context windows. Traditional approaches face a trade-off: continuous compression dilutes high-level semantics such as object identities, while discrete quantization loses fine-grained details such as textures. We introduce HTC-VLM, a hybrid framework that disentangles semantics and appearance through dual channels, i.e., a continuous pathway for fine-grained details via ViT patches and a discrete pathway for symbolic anchors using MGVQ quantization projected to four tokens. These are fused into a 580-token hybrid sequence and compressed into a single voco token via a disentanglement attention mask and bottleneck, ensuring efficient and grounded representations. HTC-VLM achieves an average performance retention of 87.2 percent across seven benchmarks (GQA, VQAv2, MMBench, MME, POPE, SEED-Bench, ScienceQA-Image), outperforming the leading continuous baseline at 81.0 percent with a 580-to-1 compression ratio. Attention analyses show that the compressed token prioritizes the discrete anchor, validating its semantic guidance. Our work demonstrates that a minimalist hybrid design can resolve the efficiency-fidelity dilemma and advance scalable VLMs.

</details>


### [16] [Distilling Future Temporal Knowledge with Masked Feature Reconstruction for 3D Object Detection](https://arxiv.org/abs/2512.08247)
*Haowen Zheng,Hu Zhu,Lu Deng,Weihao Gu,Yang Yang,Yanyan Liang*

Main category: cs.CV

TL;DR: 提出了一种名为未来时间知识蒸馏（FTKD）的稀疏查询方法，用于将离线教师模型中的未来帧知识有效转移到在线学生模型中。通过未来感知的特征重建和未来引导的logit蒸馏策略，实现了无需严格帧对齐的未来信息学习，显著提升了3D目标检测性能，同时保持推理成本不变。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法忽略未来帧信息，无法有效让在线模型学习到未来上下文，限制了实时检测性能的提升。

Method: 提出一种基于稀疏查询的未来感知特征重建策略，以及未来引导的logit蒸馏方法，实现非对齐条件下对未来的知识迁移。

Result: 在nuScenes数据集上，相对于两个主流3D检测基线，FTKD分别实现了最高1.3 mAP和1.3 NDS的提升，并获得最精确的速度估计，且不增加推理开销。

Conclusion: FTKD成功实现了对未来帧信息的有效蒸馏，为实时3D目标检测提供了高效、准确的新范式。

Abstract: Camera-based temporal 3D object detection has shown impressive results in autonomous driving, with offline models improving accuracy by using future frames. Knowledge distillation (KD) can be an appealing framework for transferring rich information from offline models to online models. However, existing KD methods overlook future frames, as they mainly focus on spatial feature distillation under strict frame alignment or on temporal relational distillation, thereby making it challenging for online models to effectively learn future knowledge. To this end, we propose a sparse query-based approach, Future Temporal Knowledge Distillation (FTKD), which effectively transfers future frame knowledge from an offline teacher model to an online student model. Specifically, we present a future-aware feature reconstruction strategy to encourage the student model to capture future features without strict frame alignment. In addition, we further introduce future-guided logit distillation to leverage the teacher's stable foreground and background context. FTKD is applied to two high-performing 3D object detection baselines, achieving up to 1.3 mAP and 1.3 NDS gains on the nuScenes dataset, as well as the most accurate velocity estimation, without increasing inference cost.

</details>


### [17] [Query-aware Hub Prototype Learning for Few-Shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2512.08253)
*YiLin Zhou,Lili Wei,Zheming Xu,Ziyi Chen,Congyan Lang*

Main category: cs.CV

TL;DR: 提出一种新的查询感知枢纽原型（QHP）学习方法，用于解决少样本3D点云语义分割中因原型偏差导致的性能下降问题。通过构建支持集与查询集之间的二分图，识别频繁连接的支持枢纽，生成与查询相关的原型，并利用纯度加权对比损失优化原型分布，有效提升模型在分布偏移下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的原型学习方法仅从支持集生成原型，忽略了其与查询数据的相关性，导致原型偏向支持集特征，难以泛化到查询分布，尤其在分布偏移下性能下降明显。

Method: 提出Hub Prototype Generation (HPG)模块，构建支持集与查询集间的二分图，识别频繁连接的支持枢纽，生成查询相关原型；引入Prototype Distribution Optimization (PDO)模块，使用纯度加权对比损失，将不良枢纽和边界模糊原型拉向对应类别中心，优化原型表示。

Result: 在S3DIS和ScanNet数据集上的实验表明，QHP显著优于现有先进方法，有效缩小了原型与查询集之间的语义差距，提升了少样本3D点云语义分割的性能。

Conclusion: 所提出的QHP方法通过显式建模支持集与查询集间的语义关联，并优化原型分布，有效缓解了原型偏差问题，增强了模型在少样本条件下的泛化能力，为FS-3DSeg提供了更鲁棒的解决方案。

Abstract: Few-shot 3D point cloud semantic segmentation (FS-3DSeg) aims to segment novel classes with only a few labeled samples. However, existing metric-based prototype learning methods generate prototypes solely from the support set, without considering their relevance to query data. This often results in prototype bias, where prototypes overfit support-specific characteristics and fail to generalize to the query distribution, especially in the presence of distribution shifts, which leads to degraded segmentation performance. To address this issue, we propose a novel Query-aware Hub Prototype (QHP) learning method that explicitly models semantic correlations between support and query sets. Specifically, we propose a Hub Prototype Generation (HPG) module that constructs a bipartite graph connecting query and support points, identifies frequently linked support hubs, and generates query-relevant prototypes that better capture cross-set semantics. To further mitigate the influence of bad hubs and ambiguous prototypes near class boundaries, we introduce a Prototype Distribution Optimization (PDO) module, which employs a purity-reweighted contrastive loss to refine prototype representations by pulling bad hubs and outlier prototypes closer to their corresponding class centers. Extensive experiments on S3DIS and ScanNet demonstrate that QHP achieves substantial performance gains over state-of-the-art methods, effectively narrowing the semantic gap between prototypes and query sets in FS-3DSeg.

</details>


### [18] [RLCNet: An end-to-end deep learning framework for simultaneous online calibration of LiDAR, RADAR, and Camera](https://arxiv.org/abs/2512.08262)
*Hafeez Husain Cholakkal,Stefano Arrigoni,Francesco Braghin*

Main category: cs.CV

TL;DR: 本文提出了一种名为RLCNet的端到端可训练深度学习框架，用于同时在线校准LiDAR、RADAR和相机传感器。该方法在真实数据集上验证，具备良好的鲁棒性与实时性，通过加权移动平均和异常值剔除机制实现动态参数调整，有效降低预测噪声并提升抗漂移能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态传感器外参标定在动态环境中面临机械振动和累积漂移等挑战，难以保证长期稳定性，亟需一种能够实时适应环境变化的在线校准方法。

Method: 提出基于深度学习的RLCNet框架，结合加权移动平均与异常值剔除策略，实现多传感器的端到端在线联合标定，支持实时部署。

Result: 在真实世界数据集上的实验表明，RLCNet在多种复杂条件下均表现出优越的精度与鲁棒性，相比现有方法显著提升了校准稳定性与动态适应能力。

Conclusion: RLCNet为自动驾驶系统中多模态传感器的在线外参标定提供了一种高效、可靠且可实用的解决方案，具有良好的工程应用前景。

Abstract: Accurate extrinsic calibration of LiDAR, RADAR, and camera sensors is essential for reliable perception in autonomous vehicles. Still, it remains challenging due to factors such as mechanical vibrations and cumulative sensor drift in dynamic environments. This paper presents RLCNet, a novel end-to-end trainable deep learning framework for the simultaneous online calibration of these multimodal sensors. Validated on real-world datasets, RLCNet is designed for practical deployment and demonstrates robust performance under diverse conditions. To support real-time operation, an online calibration framework is introduced that incorporates a weighted moving average and outlier rejection, enabling dynamic adjustment of calibration parameters with reduced prediction noise and improved resilience to drift. An ablation study highlights the significance of architectural choices, while comparisons with existing methods demonstrate the superior accuracy and robustness of the proposed approach.

</details>


### [19] [EgoX: Egocentric Video Generation from a Single Exocentric Video](https://arxiv.org/abs/2512.08269)
*Taewoong Kang,Kinam Kim,Dohyeon Kim,Minho Park,Junha Hyung,Jaegul Choo*

Main category: cs.CV

TL;DR: EgoX 是一种从单个第三人称视频生成第一人称视频的新框架，利用轻量级 LoRA 适配大规模视频扩散模型的时空知识，并通过统一的条件策略融合第三人称和第一人称先验信息。结合几何引导的自注意力机制，实现几何一致性和高视觉保真度，具备强可扩展性和鲁棒性，适用于未见及真实场景视频。


<details>
  <summary>Details</summary>
Motivation: 将第三人称视频转换为第一人称视频有助于实现沉浸式理解，但面临相机姿态剧烈变化和视图重叠极少的挑战，需在忠实保留可见内容的同时合理合成不可见区域，现有方法难以保证几何一致性与视觉质量。

Method: EgoX 采用轻量级 LoRA 适配预训练视频扩散模型，引入宽度与通道维度拼接的统一条件策略融合双视角先验，并设计几何引导的自注意力机制，以选择性关注空间相关区域，提升生成结果的几何一致性与视觉真实感。

Result: EgoX 在多个数据集上实现了连贯且逼真的第一人称视频生成，展现出良好的跨域泛化能力、可扩展性与对真实复杂场景的鲁棒性。

Conclusion: EgoX 成功解决了从单个第三人称视频生成高质量第一人称视频的关键挑战，为沉浸式视频理解提供了有效方案，具有广泛的应用前景。

Abstract: Egocentric perception enables humans to experience and understand the world directly from their own point of view. Translating exocentric (third-person) videos into egocentric (first-person) videos opens up new possibilities for immersive understanding but remains highly challenging due to extreme camera pose variations and minimal view overlap. This task requires faithfully preserving visible content while synthesizing unseen regions in a geometrically consistent manner. To achieve this, we present EgoX, a novel framework for generating egocentric videos from a single exocentric input. EgoX leverages the pretrained spatio temporal knowledge of large-scale video diffusion models through lightweight LoRA adaptation and introduces a unified conditioning strategy that combines exocentric and egocentric priors via width and channel wise concatenation. Additionally, a geometry-guided self-attention mechanism selectively attends to spatially relevant regions, ensuring geometric coherence and high visual fidelity. Our approach achieves coherent and realistic egocentric video generation while demonstrating strong scalability and robustness across unseen and in-the-wild videos.

</details>


### [20] [PAVAS: Physics-Aware Video-to-Audio Synthesis](https://arxiv.org/abs/2512.08282)
*Oh Hyun-Bin,Yuhta Takida,Toshimitsu Uesaka,Tae-Hyun Oh,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: PAVAS提出一种物理感知的视频到音频生成方法，通过物理驱动音频适配器（Phy-Adapter）融合物体质量、运动轨迹等物理参数，提升声音生成的物理合理性。引入VGG-Impact基准和音频-物理相关系数（APCC）评估指标，实验证明其在物理真实性和听觉一致性上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成模型多依赖视觉线索，忽视真实世界声音背后的物理规律，导致生成音频缺乏物理合理性。本文旨在通过引入物理参数建模，使音频生成更符合现实世界的物理机制。

Method: 采用基于潜在扩散模型的框架，结合物理参数估计器（PPE），利用视觉语言模型推断物体质量，并通过分割与动态3D重建获取运动轨迹以计算速度；将这些物理特征输入物理驱动音频适配器（Phy-Adapter），引导音频生成过程。

Result: PAVAS在自建的VGG-Impact数据集上表现出更高的物理真实性，所提的音频-物理相关系数（APCC）有效衡量了物理与听觉属性的一致性；在定量与定性评估中均优于现有V2A方法。

Conclusion: 通过融入物理推理，PAVAS能够生成既符合视觉内容又具有物理合理性的音频，为高质量、可解释的视频到音频生成提供了新范式。

Abstract: Recent advances in Video-to-Audio (V2A) generation have achieved impressive perceptual quality and temporal synchronization, yet most models remain appearance-driven, capturing visual-acoustic correlations without considering the physical factors that shape real-world sounds. We present Physics-Aware Video-to-Audio Synthesis (PAVAS), a method that incorporates physical reasoning into a latent diffusion-based V2A generation through the Physics-Driven Audio Adapter (Phy-Adapter). The adapter receives object-level physical parameters estimated by the Physical Parameter Estimator (PPE), which uses a Vision-Language Model (VLM) to infer the moving-object mass and a segmentation-based dynamic 3D reconstruction module to recover its motion trajectory for velocity computation. These physical cues enable the model to synthesize sounds that reflect underlying physical factors. To assess physical realism, we curate VGG-Impact, a benchmark focusing on object-object interactions, and introduce Audio-Physics Correlation Coefficient (APCC), an evaluation metric that measures consistency between physical and auditory attributes. Comprehensive experiments show that PAVAS produces physically plausible and perceptually coherent audio, outperforming existing V2A models in both quantitative and qualitative evaluations. Visit https://physics-aware-video-to-audio-synthesis.github.io for demo videos.

</details>


### [21] [OpenSubject: Leveraging Video-Derived Identity and Diversity Priors for Subject-driven Image Generation and Manipulation](https://arxiv.org/abs/2512.08294)
*Yexin Liu,Manyuan Zhang,Yueze Wang,Hongyu Li,Dian Zheng,Weiming Zhang,Changsheng Lu,Xunliang Cai,Yan Feng,Peng Pei,Harry Yang*

Main category: cs.CV

TL;DR: 提出OpenSubject，一个基于视频的大规模数据集（250万样本，435万图像），用于主体驱动的图像生成与操作。通过四阶段流程：视频筛选、跨帧主体挖掘与配对、保持身份的参考图像合成、验证与标注。采用视觉-语言模型进行一致性验证，并构建基准测试评估身份保真度、提示遵循性、操作一致性和背景一致性。实验表明，使用该数据集可显著提升复杂场景下的生成与操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有主体驱动图像生成模型在复杂场景中容易偏离参考身份，缺乏高质量训练数据支持，因此需要大规模、高保真的数据集来提升模型表现。

Method: 构建四阶段数据生成流程：1）视频筛选（分辨率与美学过滤）；2）跨帧主体挖掘与配对（利用VLM的类别共识、局部定位和多样性感知配对）；3）身份保持的图像合成（分割图引导的外扩与框引导的内补，结合几何增强与不规则边界侵蚀）；4）验证与标注（VLM验证失败样本并重生成，生成长短描述）。同时建立基准测试，使用VLM评估多维度性能。

Result: 在复杂场景下，基于OpenSubject训练的模型在身份保真度、提示遵循性、操作一致性及背景一致性方面均有显著提升，验证了数据集的有效性与实用性。

Conclusion: OpenSubject作为大规模视频衍生数据集，有效解决了主体驱动生成与操作中的身份漂移问题，尤其在复杂多主体场景中表现优异，为未来研究提供了高质量数据基础与评估基准。

Abstract: Despite the promising progress in subject-driven image generation, current models often deviate from the reference identities and struggle in complex scenes with multiple subjects. To address this challenge, we introduce OpenSubject, a video-derived large-scale corpus with 2.5M samples and 4.35M images for subject-driven generation and manipulation. The dataset is built with a four-stage pipeline that exploits cross-frame identity priors. (i) Video Curation. We apply resolution and aesthetic filtering to obtain high-quality clips. (ii) Cross-Frame Subject Mining and Pairing. We utilize vision-language model (VLM)-based category consensus, local grounding, and diversity-aware pairing to select image pairs. (iii) Identity-Preserving Reference Image Synthesis. We introduce segmentation map-guided outpainting to synthesize the input images for subject-driven generation and box-guided inpainting to generate input images for subject-driven manipulation, together with geometry-aware augmentations and irregular boundary erosion. (iv) Verification and Captioning. We utilize a VLM to validate synthesized samples, re-synthesize failed samples based on stage (iii), and then construct short and long captions. In addition, we introduce a benchmark covering subject-driven generation and manipulation, and then evaluate identity fidelity, prompt adherence, manipulation consistency, and background consistency with a VLM judge. Extensive experiments show that training with OpenSubject improves generation and manipulation performance, particularly in complex scenes.

</details>


### [22] [Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation](https://arxiv.org/abs/2512.08309)
*Alexander Goslin*

Main category: cs.CV

TL;DR: Terrain Diffusion introduces a new AI-based procedural world generation method that surpasses traditional noise functions like Perlin noise by combining high realism and large-scale coherence with the desirable properties of infinite extent, seed-consistency, and constant-time access. It uses InfiniteDiffusion for seamless, real-time landscape synthesis, a hierarchical diffusion stack for multi-scale detail, Laplacian encoding for stability across vast scales, and an open-source framework for efficient, unbounded tensor operations. Few-step consistency distillation enables fast, reliable generation, making diffusion models viable for practical, planet-scale procedural content.


<details>
  <summary>Details</summary>
Motivation: Traditional procedural noise functions like Perlin noise are limited in realism and large-scale coherence despite their speed and infinite nature. There is a need for a next-generation procedural system that maintains these advantages while achieving higher fidelity and more natural, coherent landscapes.

Method: The approach centers on InfiniteDiffusion, a novel algorithm enabling infinite, seamless generation. A hierarchical stack of diffusion models integrates planetary-scale context with local details. A compact Laplacian encoding ensures output stability across Earth-scale ranges. An open-source infinite-tensor framework allows constant-memory manipulation of unbounded data. Few-step consistency distillation improves generation efficiency without sacrificing quality.

Result: Terrain Diffusion successfully synthesizes entire planets with high coherence, controllability, and realism. It achieves seamless, real-time generation across infinite extents with consistent outputs across different seeds and constant-time access, demonstrating that diffusion models can be practical for large-scale procedural world generation.

Conclusion: Diffusion models, when enhanced with InfiniteDiffusion, hierarchical modeling, and efficient encoding, can serve as a powerful and practical foundation for procedural world generation, overcoming the limitations of prior methods while preserving essential procedural properties.

Abstract: For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.

</details>


### [23] [GeoDM: Geometry-aware Distribution Matching for Dataset Distillation](https://arxiv.org/abs/2512.08317)
*Xuhui Li,Zhengquan Luo,Zihui Cui,Zhiqiang Xu*

Main category: cs.CV

TL;DR: 本文提出了一种几何感知的分布匹配框架GeoDM，通过在欧几里得、双曲和球面流形的笛卡尔积空间中进行数据蒸馏，捕捉数据的线性、层次和循环结构。引入可学习的曲率与权重参数以适应数据内在几何，并设计最优传输损失提升分布保真度。理论分析表明该方法具有更小的泛化误差界，实验验证其在多种基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据蒸馏方法局限于欧几里得空间，仅能捕捉线性结构，忽视真实数据的内在几何特性（如曲率），而高维数据常位于低维流形上，因此需要使蒸馏数据的流形与原始数据流形对齐。

Method: 提出GeoDM框架，基于欧几里得、双曲、球面流形的笛卡尔积空间，引入可学习的曲率和权重参数以适应不同几何结构，并设计最优传输损失函数以增强分布匹配精度。

Result: 理论分析显示，该方法在产品空间中的几何感知分布匹配具有更小的泛化误差界；在多个标准数据集上的实验表明，GeoDM显著优于现有先进方法，且在单一几何结构下的各类匹配策略中均保持有效性。

Conclusion: GeoDM通过统一建模多种几何结构，实现了对复杂数据流形的更精确逼近，为数据蒸馏提供了更优的几何感知解决方案。

Abstract: Dataset distillation aims to synthesize a compact subset of the original data, enabling models trained on it to achieve performance comparable to those trained on the original large dataset. Existing distribution-matching methods are confined to Euclidean spaces, making them only capture linear structures and overlook the intrinsic geometry of real data, e.g., curvature. However, high-dimensional data often lie on low-dimensional manifolds, suggesting that dataset distillation should have the distilled data manifold aligned with the original data manifold. In this work, we propose a geometry-aware distribution-matching framework, called \textbf{GeoDM}, which operates in the Cartesian product of Euclidean, hyperbolic, and spherical manifolds, with flat, hierarchical, and cyclical structures all captured by a unified representation. To adapt to the underlying data geometry, we introduce learnable curvature and weight parameters for three kinds of geometries. At the same time, we design an optimal transport loss to enhance the distribution fidelity. Our theoretical analysis shows that the geometry-aware distribution matching in a product space yields a smaller generalization error bound than the Euclidean counterparts. Extensive experiments conducted on standard benchmarks demonstrate that our algorithm outperforms state-of-the-art data distillation methods and remains effective across various distribution-matching strategies for the single geometries.

</details>


### [24] [Detecting Dental Landmarks from Intraoral 3D Scans: the 3DTeethLand challenge](https://arxiv.org/abs/2512.08323)
*Achraf Ben-Hamadou,Nour Neifar,Ahmed Rekik,Oussama Smaoui,Firas Bouzguenda,Sergi Pujades,Niels van Nistelrooij,Shankeeth Vinayahalingam,Kaibo Shi,Hairong Jin,Youyi Zheng,Tibor Kubík,Oldřich Kodym,Petr Šilling,Kateřina Trávníčková,Tomáš Mojžiš,Jan Matula,Jeffry Hartanto,Xiaoying Zhu,Kim-Ngan Nguyen,Tudor Dascalu,Huikai Wu,and Weijie Liu,Shaojie Zhuang,Guangshun Wei,Yuanfeng Zhou*

Main category: cs.CV

TL;DR: 本文介绍了2024年MICCAI会议上举办的3DTeethLand挑战赛，旨在推动基于口内3D扫描的牙齿关键点检测技术的发展。该挑战赛发布了首个公开的3D牙齿关键点检测数据集，为评估当前最先进方法提供了重要资源，并鼓励社区在具有重大临床意义的问题上做出方法学贡献。


<details>
  <summary>Details</summary>
Motivation: 牙齿关键点的精确识别对现代正畸临床诊断、个性化治疗策略制定以及治疗进展监测至关重要。然而，由于个体牙齿几何结构复杂且存在显著差异，实现高精度检测面临诸多挑战，因此亟需先进的技术手段，特别是深度学习方法，来提升检测的准确性和可靠性。

Method: 通过举办3DTeethLand挑战赛，结合MICCAI 2024会议，征集针对口内3D扫描中牙齿关键点检测的算法，利用新发布的公开数据集推动相关研究发展。

Result: 成功发布首个公开的3D牙齿关键点检测数据集，为评估和比较不同算法性能提供了基准，促进了深度学习等先进技术在该领域的应用与发展。

Conclusion: 3DTeethLand挑战赛不仅为牙齿关键点检测任务提供了标准化评估平台，也推动了该领域从传统方法向智能化、自动化方向演进，具有重要的临床与科研价值。

Abstract: Teeth landmark detection is a critical task in modern clinical orthodontics. Their precise identification enables advanced diagnostics, facilitates personalized treatment strategies, and supports more effective monitoring of treatment progress in clinical dentistry. However, several significant challenges may arise due to the intricate geometry of individual teeth and the substantial variations observed across different individuals. To address these complexities, the development of advanced techniques, especially through the application of deep learning, is essential for the precise and reliable detection of 3D tooth landmarks. In this context, the 3DTeethLand challenge was held in collaboration with the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) in 2024, calling for algorithms focused on teeth landmark detection from intraoral 3D scans. This challenge introduced the first publicly available dataset for 3D teeth landmark detection, offering a valuable resource to assess the state-of-the-art methods in this task and encourage the community to provide methodological contributions towards the resolution of their problem with significant clinical implications.

</details>


### [25] [GeoDiffMM: Geometry-Guided Conditional Diffusion for Motion Magnification](https://arxiv.org/abs/2512.08325)
*Xuedeng Liu,Jiabao Guo,Zheng Zhang,Fei Wang,Zhi Liu,Dan Guo*

Main category: cs.CV

TL;DR: GeoDiffMM 是一种基于扩散模型的拉格朗日视频运动放大框架，通过光流作为几何线索实现结构一致的运动放大。该方法提出无噪声光流增强策略，合成无噪非刚性运动场以指导模型学习更准确的几何感知光流；设计扩散运动放大器，结合光流作为几何先验和可学习的放大因子，选择性放大与场景语义和结构一致的运动成分，抑制无关扰动；最后通过基于光流的视频合成将放大后的运动高保真地映射回图像域。实验表明，GeoDiffMM 在真实和合成数据集上均优于现有方法，显著提升运动放大效果。


<details>
  <summary>Details</summary>
Motivation: 现有主流欧拉方法在处理极微小运动时难以区分光子噪声与真实微运动，导致放大过程中噪声被增强。需要一种能有效分离噪声与真实运动、保持结构一致性的新方法。

Method: 提出 GeoDiffMM 框架，包含三个核心组件：1）无噪声光流增强策略，用于生成无噪声的非刚性运动场以监督光流学习；2）扩散运动放大器，条件于光流和可学习放大因子，实现对结构一致运动的有选择性放大；3）基于光流的视频合成模块，将放大后的运动精确还原至图像空间。

Result: 在真实和合成数据集上的大量实验表明，GeoDiffMM 显著优于当前最先进的方法，在运动放大质量、结构一致性及抗噪能力方面均有明显提升。

Conclusion: GeoDiffMM 通过引入几何先验（光流）与扩散建模相结合的方式，成功实现了对微小运动的高质量放大，有效抑制了噪声干扰，并保持了良好的结构保真度，为视频运动放大任务提供了新的范式。

Abstract: Video Motion Magnification (VMM) amplifies subtle macroscopic motions to a perceptible level. Recently, existing mainstream Eulerian approaches address amplification-induced noise via decoupling representation learning such as texture, shape and frequancey schemes, but they still struggle to separate photon noise from true micro-motion when motion displacements are very small. We propose GeoDiffMM, a novel diffusion-based Lagrangian VMM framework conditioned on optical flow as a geometric cue, enabling structurally consistent motion magnification. Specifically, we design a Noise-free Optical Flow Augmentation strategy that synthesizes diverse nonrigid motion fields without photon noise as supervision, helping the model learn more accurate geometry-aware optial flow and generalize better. Next, we develop a Diffusion Motion Magnifier that conditions the denoising process on (i) optical flow as a geometry prior and (ii) a learnable magnification factor controlling magnitude, thereby selectively amplifying motion components consistent with scene semantics and structure while suppressing content-irrelevant perturbations. Finally, we perform Flow-based Video Synthesis to map the amplified motion back to the image domain with high fidelity. Extensive experiments on real and synthetic datasets show that GeoDiffMM outperforms state-of-the-art methods and significantly improves motion magnification.

</details>


### [26] [Low Rank Support Quaternion Matrix Machine](https://arxiv.org/abs/2512.08327)
*Wang Chen,Ziyan Luo,Shuangyue Wang*

Main category: cs.CV

TL;DR: 提出了一种名为低秩支持四元数矩阵机（LSQMM）的新方法，用于彩色图像分类。该方法将RGB通道视为纯四元数，利用四元数代数有效保持通道间的内在耦合关系，并引入四元数核范数正则化项以促进强相关颜色通道的低秩结构。采用基于交替方向乘子法（ADMM）的迭代算法求解优化模型。在多个彩色图像分类数据集上的实验结果表明，该方法在分类精度、鲁棒性和计算效率方面优于多种先进方法，如支持向量机、支持矩阵机和支持张量机。


<details>
  <summary>Details</summary>
Motivation: 传统彩色图像分类中，输入特征通常表示为实数域中的向量、矩阵或三阶张量，未能充分保留通道间的内在耦合关系。受四元数在图像恢复与去噪任务中成功应用的启发，旨在通过四元数建模更好地捕捉彩色图像中多通道之间的关联性，提升分类性能。

Method: 提出了一种基于四元数的分类模型——低秩支持四元数矩阵机（LSQMM），将RGB三通道作为纯四元数处理，利用四元数代数保持通道间耦合；引入四元数核范数正则化项以增强低秩特性；设计基于ADMM的迭代算法求解该非凸优化问题。

Result: 在多个彩色图像分类数据集上，所提方法在分类准确率、鲁棒性及计算效率方面均优于现有主流方法，包括支持向量机、支持矩阵机和支持张量机，验证了其有效性与优越性。

Conclusion: LSQMM通过四元数建模有效融合了彩色图像的多通道信息，结合低秩约束与高效优化算法，在分类任务中表现出更强的性能，为彩色图像分类提供了一种新颖且有效的解决方案。

Abstract: Input features are conventionally represented as vectors, matrices, or third order tensors in the real field, for color image classification. Inspired by the success of quaternion data modeling for color images in image recovery and denoising tasks, we propose a novel classification method for color image classification, named as the Low-rank Support Quaternion Matrix Machine (LSQMM), in which the RGB channels are treated as pure quaternions to effectively preserve the intrinsic coupling relationships among channels via the quaternion algebra. For the purpose of promoting low-rank structures resulting from strongly correlated color channels, a quaternion nuclear norm regularization term, serving as a natural extension of the conventional matrix nuclear norm to the quaternion domain, is added to the hinge loss in our LSQMM model. An Alternating Direction Method of Multipliers (ADMM)-based iterative algorithm is designed to effectively resolve the proposed quaternion optimization model. Experimental results on multiple color image classification datasets demonstrate that our proposed classification approach exhibits advantages in classification accuracy, robustness and computational efficiency, compared to several state-of-the-art methods using support vector machines, support matrix machines, and support tensor machines.

</details>


### [27] [Interpreting Structured Perturbations in Image Protection Methods for Diffusion Models](https://arxiv.org/abs/2512.08329)
*Michael R. Martin,Garrick Chan,Kwan-Liu Ma*

Main category: cs.CV

TL;DR: 本文系统分析了Glaze和Nightshade等图像保护机制中的对抗性扰动，揭示其在表示、空间和频域上具有结构化、低熵的特性，且与图像内容紧密耦合。尽管扰动视觉上不可察觉，但通过特征空间聚类、通道激活分析、遮挡敏感度映射和频域分析发现，这些保护信号并非随机噪声，而是通过特征级变形实现，导致可检测性增强而非抑制。研究提出统一框架，为未来生成式AI防御与检测策略提供依据。


<details>
  <summary>Details</summary>
Motivation: 当前图像保护机制如Glaze和Nightshade虽具实证有效性，但其内部结构、可检测性及表征行为尚不清晰，亟需可解释性分析以理解其工作机制并指导后续防御与检测设计。

Method: 采用统一框架，结合白盒特征空间检查与黑盒信号级探测，包括潜在空间聚类、特征通道激活分析、基于遮挡的空间敏感度映射以及频域特征分析，全面解析扰动在多维度的表现。

Result: 保护扰动为结构化、低熵的特征级变形，与图像内容高度耦合；频域中能量沿图像主导频率轴重新分布，非扩散噪声；多重保护叠加反而增强可检测性；整体保持内容驱动的特征组织，未引发全局表征漂移。

Conclusion: 现代图像保护机制通过结构化的特征级变形实现，而非语义错位，这解释了其视觉隐蔽性与持续可检测性的矛盾。该研究提升了对抗性图像保护的可解释性，为未来生成式AI系统的防御与检测提供了理论支持。

Abstract: Recent image protection mechanisms such as Glaze and Nightshade introduce imperceptible, adversarially designed perturbations intended to disrupt downstream text-to-image generative models. While their empirical effectiveness is known, the internal structure, detectability, and representational behavior of these perturbations remain poorly understood. This study provides a systematic, explainable AI analysis using a unified framework that integrates white-box feature-space inspection and black-box signal-level probing. Through latent-space clustering, feature-channel activation analysis, occlusion-based spatial sensitivity mapping, and frequency-domain characterization, we show that protection mechanisms operate as structured, low-entropy perturbations tightly coupled to underlying image content across representational, spatial, and spectral domains. Protected images preserve content-driven feature organization with protection-specific substructure rather than inducing global representational drift. Detectability is governed by interacting effects of perturbation entropy, spatial deployment, and frequency alignment, with sequential protection amplifying detectable structure rather than suppressing it. Frequency-domain analysis shows that Glaze and Nightshade redistribute energy along dominant image-aligned frequency axes rather than introducing diffuse noise. These findings indicate that contemporary image protection operates through structured feature-level deformation rather than semantic dislocation, explaining why protection signals remain visually subtle yet consistently detectable. This work advances the interpretability of adversarial image protection and informs the design of future defenses and detection strategies for generative AI systems.

</details>


### [28] [PointDico: Contrastive 3D Representation Learning Guided by Diffusion Models](https://arxiv.org/abs/2512.08330)
*Pengbo Li,Yiding Sun,Haozhe Cheng*

Main category: cs.CV

TL;DR: 提出PointDico，通过知识蒸馏融合扩散模型与对比学习，实现3D点云的高效表示学习，显著提升在ScanObjectNN和ShapeNetPart上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督方法在处理3D点云时面临无序性和密度不均的问题，对比模型易过拟合，3D掩码自编码器难以处理无序点云，因此需要结合扩散模型与对比学习的优势。

Method: 设计层次金字塔条件生成器进行多尺度几何特征提取，采用双通道结构融合局部与全局上下文信息，通过知识蒸馏使扩散模型指导对比模型学习。

Result: 在ScanObjectNN上达到94.32%准确率，在ShapeNetPart上达到86.5%实例mIoU，刷新3D表示学习的最新纪录。

Conclusion: PointDico成功融合扩散与对比学习，克服了3D点云表示学习中的挑战，实现了卓越性能，为未来研究提供了新方向。

Abstract: Self-supervised representation learning has shown significant improvement in Natural Language Processing and 2D Computer Vision. However, existing methods face difficulties in representing 3D data because of its unordered and uneven density. Through an in-depth analysis of mainstream contrastive and generative approaches, we find that contrastive models tend to suffer from overfitting, while 3D Mask Autoencoders struggle to handle unordered point clouds. This motivates us to learn 3D representations by sharing the merits of diffusion and contrast models, which is non-trivial due to the pattern difference between the two paradigms. In this paper, we propose \textit{PointDico}, a novel model that seamlessly integrates these methods. \textit{PointDico} learns from both denoising generative modeling and cross-modal contrastive learning through knowledge distillation, where the diffusion model serves as a guide for the contrastive model. We introduce a hierarchical pyramid conditional generator for multi-scale geometric feature extraction and employ a dual-channel design to effectively integrate local and global contextual information. \textit{PointDico} achieves a new state-of-the-art in 3D representation learning, \textit{e.g.}, \textbf{94.32\%} accuracy on ScanObjectNN, \textbf{86.5\%} Inst. mIoU on ShapeNetPart.

</details>


### [29] [Bi^2MAC: Bimodal Bi-Adaptive Mask-Aware Convolution for Remote Sensing Pansharpening](https://arxiv.org/abs/2512.08331)
*Xianghong Xiao,Zeyu Xia,Zhou Fei,Jinliang Xiao,Haorui Chen,Liangjian Deng*

Main category: cs.CV

TL;DR: 提出了一种名为Bi^2MAC的新型卷积方法，用于解决遥感图像中特征表示区域异质性问题。该方法通过轻量级模块生成软掩码和硬掩码，分别用于初步调制输入特征和引导不同区域进入不同的处理分支：冗余特征被送入紧凑分支进行低成本全局处理，而异质特征则被路由到专注分支以进行细粒度建模。实验表明，Bi^2MAC在多个基准数据集上达到SOTA性能，同时具有更少的训练时间、参数量和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在处理遥感图像中的区域异质性方面能力有限，尽管已有自适应卷积方法，但存在计算开销大、难以有效捕捉异质区域的问题。因此需要一种既能高效适应区域差异又能控制计算成本的方法。

Method: 设计了轻量级模块生成软掩码和硬掩码；利用软掩码初步调制特征，硬掩码将不同区域引导至不同分支（紧凑分支处理冗余特征，专注分支处理异质特征），实现计算资源的智能分配。

Result: 在多个基准数据集上实现了SOTA性能，显著降低了训练时间、参数量和计算成本，是目前计算成本最低的自适应卷积模型之一。

Conclusion: Bi^2MAC通过双模双自适应掩码感知机制，有效平衡了性能与效率，在遥感图像融合任务中展现出优越的适应性和计算经济性。

Abstract: Pansharpening aims to fuse a high-resolution panchromatic (PAN) image with a low-resolution multispectral (LRMS) image to generate a high-resolution multispectral image (HRMS). Conventional deep learning-based methods are inherently limited in their ability to adapt to regional heterogeneity within feature representations. Although various adaptive convolution methods have been proposed to address this limitation, they often suffer from excessive computational costs and a limited ability to capture heterogeneous regions in remote sensing images effectively. To overcome these challenges, we propose Bimodal Bi-Adaptive Mask-Aware Convolution (Bi^2MAC), which effectively exploits information from different types of regions while intelligently allocating computational resources. Specifically, we design a lightweight module to generate both soft and hard masks, which are used to modulate the input features preliminarily and to guide different types of regions into separate processing branches, respectively. Redundant features are directed to a compact branch for low-cost global processing. In contrast, heterogeneous features are routed to a focused branch that invests more computational resources for fine-grained modeling. Extensive experiments on multiple benchmark datasets demonstrate that Bi^2MAC achieves state-of-the-art (SOTA) performance while requiring substantially lower training time and parameter counts, and the minimal computational cost among adaptive convolution models.

</details>


### [30] [HybridSplat: Fast Reflection-baked Gaussian Tracing using Hybrid Splatting](https://arxiv.org/abs/2512.08334)
*Chang Liu,Hongliang Yuan,Lianghao Zhang,Sichao Wang,Jianwei Guo,Shi-Sheng Huang*

Main category: cs.CV

TL;DR: 提出一种新的混合点阵（HybridSplat）机制，通过在高斯原语中烘焙视角相关的反射信息，并结合基于瓦片的高斯点阵渲染，实现复杂反射场景的高质量新视角合成。引入流水线加速和反射敏感的高斯剪枝策略，在显著提升渲染速度（约7倍加速）的同时，减少4倍的高斯数量，且保持优异的反射质量，成为复杂反射场景下的新基准方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点阵在渲染真实世界复杂反射场景时面临渲染速度慢和内存占用高的瓶颈，亟需更高效且保真的解决方案。

Method: 提出反射烘焙高斯追踪技术，将视图依赖的反射信息嵌入高斯原语中；采用基于瓦片的高斯点阵渲染；构建统一的混合点阵框架融合反射与基础高斯原语；并引入管道级加速与反射敏感剪枝以优化性能。

Result: 在Ref-NeRF和NeRF-Casting等复杂反射场景上，实现约7倍的渲染速度提升，使用4倍更少的高斯原语，同时保持高质量的反射渲染效果，优于现有基于光线追踪的高斯点阵方法。

Conclusion: 所提出的HybridSplat方法在复杂反射场景下实现了更高的渲染效率与更低的存储开销，是当前该领域的新状态最优方法。

Abstract: Rendering complex reflection of real-world scenes using 3D Gaussian splatting has been a quite promising solution for photorealistic novel view synthesis, but still faces bottlenecks especially in rendering speed and memory storage. This paper proposes a new Hybrid Splatting(HybridSplat) mechanism for Gaussian primitives. Our key idea is a new reflection-baked Gaussian tracing, which bakes the view-dependent reflection within each Gaussian primitive while rendering the reflection using tile-based Gaussian splatting. Then we integrate the reflective Gaussian primitives with base Gaussian primitives using a unified hybrid splatting framework for high-fidelity scene reconstruction. Moreover, we further introduce a pipeline-level acceleration for the hybrid splatting, and reflection-sensitive Gaussian pruning to reduce the model size, thus achieving much faster rendering speed and lower memory storage while preserving the reflection rendering quality. By extensive evaluation, our HybridSplat accelerates about 7x rendering speed across complex reflective scenes from Ref-NeRF, NeRF-Casting with 4x fewer Gaussian primitives than similar ray-tracing based Gaussian splatting baselines, serving as a new state-of-the-art method especially for complex reflective scenes.

</details>


### [31] [DINO-BOLDNet: A DINOv3-Guided Multi-Slice Attention Network for T1-to-BOLD Generation](https://arxiv.org/abs/2512.08337)
*Jianwei Wang,Qing Wang,Menglan Ruan,Rongjun Ge,Chunfeng Yang,Yang Chen,Chunming Xie*

Main category: cs.CV

TL;DR: DINO-BOLDNet 是一种基于 DINOv3 的多切片注意力框架，能够直接从 T1w 图像生成均值 BOLD 图像，利用自监督特征提取和跨切片上下文融合，在临床数据上优于条件 GAN 基线，实现更高质量的功能对比恢复。


<details>
  <summary>Details</summary>
Motivation: 解决当 BOLD 图像缺失或损坏时，无法进行下游任务的问题，通过从 T1w 图像重建 BOLD 信息来恢复功能成像数据。

Method: 采用冻结的自监督 DINOv3 编码器提取单切片结构特征，结合独立的切片注意力模块融合邻近切片上下文信息，再通过多尺度生成解码器恢复精细功能对比，并使用基于 DINO 的感知损失确保预测与真实 BOLD 在变换器特征空间中的一致性。

Result: 在包含 248 名受试者的临床数据集上，DINO-BOLDNet 在 PSNR 和 MS-SSIM 指标上均优于条件 GAN 基线，是首个可直接从 T1w 图像生成均值 BOLD 图像的框架。

Conclusion: 该研究展示了自监督 Transformer 引导在结构到功能映射中的潜力，为缺失功能成像数据的恢复提供了有效解决方案。

Abstract: Generating BOLD images from T1w images offers a promising solution for recovering missing BOLD information and enabling downstream tasks when BOLD images are corrupted or unavailable. Motivated by this, we propose DINO-BOLDNet, a DINOv3-guided multi-slice attention framework that integrates a frozen self-supervised DINOv3 encoder with a lightweight trainable decoder. The model uses DINOv3 to extract within-slice structural representations, and a separate slice-attention module to fuse contextual information across neighboring slices. A multi-scale generation decoder then restores fine-grained functional contrast, while a DINO-based perceptual loss encourages structural and textural consistency between predictions and ground-truth BOLD in the transformer feature space. Experiments on a clinical dataset of 248 subjects show that DINO-BOLDNet surpasses a conditional GAN baseline in both PSNR and MS-SSIM. To our knowledge, this is the first framework capable of generating mean BOLD images directly from T1w images, highlighting the potential of self-supervised transformer guidance for structural-to-functional mapping.

</details>


### [32] [TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels](https://arxiv.org/abs/2512.08358)
*Jiahao Lu,Weitao Xiong,Jiacheng Deng,Peng Li,Tianyu Huang,Zhiyang Dou,Cheng Lin,Sai-Kit Yeung,Yuan Liu*

Main category: cs.CV

TL;DR: Proposes TrackingWorld, a novel pipeline for dense 3D tracking from monocular videos by lifting sparse 2D tracks to dense ones, reducing redundancy, and optimizing camera poses and 3D trajectories in a world-centric frame.


<details>
  <summary>Details</summary>
Motivation: Existing monocular 3D tracking methods struggle to separate camera motion from foreground motion and fail to track newly emerging dynamic objects densely.

Method: Introduces a tracking upsampler to generate dense 2D tracks, reduces redundancy by removing overlapping tracks across frames, and uses an optimization-based framework to reconstruct world-centric 3D trajectories via camera pose estimation.

Result: Achieves accurate and dense 3D tracking in a world-centric coordinate system, validated on both synthetic and real-world datasets.

Conclusion: TrackingWorld effectively addresses limitations in current monocular 3D tracking by enabling dense, robust, and world-centric 3D trajectory estimation even for newly appearing objects.

Abstract: Monocular 3D tracking aims to capture the long-term motion of pixels in 3D space from a single monocular video and has witnessed rapid progress in recent years. However, we argue that the existing monocular 3D tracking methods still fall short in separating the camera motion from foreground dynamic motion and cannot densely track newly emerging dynamic subjects in the videos. To address these two limitations, we propose TrackingWorld, a novel pipeline for dense 3D tracking of almost all pixels within a world-centric 3D coordinate system. First, we introduce a tracking upsampler that efficiently lifts the arbitrary sparse 2D tracks into dense 2D tracks. Then, to generalize the current tracking methods to newly emerging objects, we apply the upsampler to all frames and reduce the redundancy of 2D tracks by eliminating the tracks in overlapped regions. Finally, we present an efficient optimization-based framework to back-project dense 2D tracks into world-centric 3D trajectories by estimating the camera poses and the 3D coordinates of these 2D tracks. Extensive evaluations on both synthetic and real-world datasets demonstrate that our system achieves accurate and dense 3D tracking in a world-centric coordinate frame.

</details>


### [33] [SCU-CGAN: Enhancing Fire Detection through Synthetic Fire Image Generation and Dataset Augmentation](https://arxiv.org/abs/2512.08362)
*Ju-Young Kim,Ji-Hong Park,Gun-Woo Kim*

Main category: cs.CV

TL;DR: 本文提出SCU-CGAN模型，结合U-Net、CBAM和额外判别器，生成逼真的火灾图像以解决火灾数据集不足问题。实验表明，该模型在KID评分上比CycleGAN提升41.5%，且使用增强数据集后，YOLOv5 nano模型的mAP@0.5:0.95指标提升56.5%，显著提升了火灾检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有火灾检测模型受限于缺乏充足的火灾数据集，导致性能不佳。为提升检测效果，亟需生成高质量的合成火灾图像以扩充训练数据。

Method: 提出SCU-CGAN模型，融合U-Net用于图像生成，引入CBAM模块增强特征提取能力，并加入额外判别器以提升生成图像的真实感，从而生成更逼真的火灾图像。

Result: SCU-CGAN在图像质量评估中表现优于现有模型，KID得分提升41.5%；使用其生成的数据增强后，火灾检测模型（如YOLOv5 nano）的mAP@0.5:0.95指标提升56.5%，显著提高检测精度。

Conclusion: SCU-CGAN能有效生成高质量火灾图像，通过数据增强显著提升火灾检测模型的性能，具有实际应用价值。

Abstract: Fire has long been linked to human life, causing severe disasters and losses. Early detection is crucial, and with the rise of home IoT technologies, household fire detection systems have emerged. However, the lack of sufficient fire datasets limits the performance of detection models. We propose the SCU-CGAN model, which integrates U-Net, CBAM, and an additional discriminator to generate realistic fire images from nonfire images. We evaluate the image quality and confirm that SCU-CGAN outperforms existing models. Specifically, SCU-CGAN achieved a 41.5% improvement in KID score compared to CycleGAN, demonstrating the superior quality of the generated fire images. Furthermore, experiments demonstrate that the augmented dataset significantly improves the accuracy of fire detection models without altering their structure. For the YOLOv5 nano model, the most notable improvement was observed in the mAP@0.5:0.95 metric, which increased by 56.5%, highlighting the effectiveness of the proposed approach.

</details>


### [34] [The Unseen Bias: How Norm Discrepancy in Pre-Norm MLLMs Leads to Visual Information Loss](https://arxiv.org/abs/2512.08374)
*Bozhou Li,Xinda Xue,Sihan Yang,Yang Shi,Xinlong Chen,Yushuo Guan,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种针对多模态大语言模型（MLLMs）中视觉与文本令牌之间范数失衡问题的理论分析与解决方案。该失衡导致视觉令牌更新速度显著慢于文本令牌，从而阻碍跨模态特征融合。作者通过实证验证了这一不对称更新动态的普遍性，并提出在视觉投影器后添加一个精心初始化的LayerNorm层以实现范数对齐。实验表明，该方法在多个多模态基准上均取得显著性能提升，甚至在纯文本任务（如MMLU）上也表现更优，证明其能全面提升模型能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型依赖预训练视觉编码器和语言模型，但其普遍采用的Pre-Norm架构导致视觉令牌与文本令牌间存在严重的范数差异，这种不平衡会引发不对称更新动态，进而影响跨模态信息融合效果。

Method: 提出理论分析揭示范数失衡引发的‘非对称更新动态’；设计并验证在视觉投影器后插入一个精心初始化的LayerNorm层以实现范数对齐的简单有效方案。

Result: 实验证明，该方法不仅显著提升了多模态任务性能，还在纯文本任务（如MMLU）上表现出色，说明解决了架构不平衡后模型整体能力得到增强。

Conclusion: 范数失衡是影响MLLM性能的关键因素，通过引入简单的LayerNorm层进行范数对齐，可有效缓解不对称更新动态，实现跨模态融合优化，并带来整体模型能力的提升。

Abstract: Multimodal Large Language Models (MLLMs), which couple pre-trained vision encoders and language models, have shown remarkable capabilities. However, their reliance on the ubiquitous Pre-Norm architecture introduces a subtle yet critical flaw: a severe norm disparity between the high-norm visual tokens and the low-norm text tokens. In this work, we present a formal theoretical analysis demonstrating that this imbalance is not a static issue. Instead, it induces an ``asymmetric update dynamic,'' where high-norm visual tokens exhibit a ``representational inertia,'' causing them to transform semantically much slower than their textual counterparts. This fundamentally impairs effective cross-modal feature fusion. Our empirical validation across a range of mainstream MLLMs confirms that this theoretical dynamic -- the persistence of norm disparity and the resulting asymmetric update rates -- is a prevalent phenomenon. Based on this insight, we propose a remarkably simple yet effective solution: inserting a single, carefully initialized LayerNorm layer after the visual projector to enforce norm alignment. Experiments conducted on the LLaVA-1.5 architecture show that this intervention yields significant performance gains not only on a wide suite of multimodal benchmarks but also, notably, on text-only evaluations such as MMLU, suggesting that resolving the architectural imbalance leads to a more holistically capable model.

</details>


### [35] [Simultaneous Enhancement and Noise Suppression under Complex Illumination Conditions](https://arxiv.org/abs/2512.08378)
*Jing Tao,You Li,Banglei Guan,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种新型框架，用于在复杂光照条件下同时进行图像增强和噪声抑制。通过梯度域加权引导滤波估计光照，结合Retinex模型分解图像为光照和反射层，分别处理后融合，最后通过多曝光融合与线性拉伸优化动态范围。实验表明该方法在对比度增强和降噪方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有图像增强方法在复杂光照条件下易放大噪声或仅适用于特定光照环境，亟需一种鲁棒且通用的解决方案。

Method: 采用梯度域加权引导滤波（GDWGIF）估计光照；利用Retinex模型分离图像为光照与反射层；对两层并行处理，分别校正光照和增强质量；最终通过多曝光融合与线性拉伸优化动态范围。

Result: 在真实世界数据集上的实验结果表明，该方法在对比度增强和噪声抑制方面均优于当前最先进的方法。

Conclusion: 所提出的框架能够有效应对复杂光照条件下的图像退化问题，在保持图像细节的同时显著提升视觉质量，具有良好的实用性和泛化能力。

Abstract: Under challenging light conditions, captured images often suffer from various degradations, leading to a decline in the performance of vision-based applications. Although numerous methods have been proposed to enhance image quality, they either significantly amplify inherent noise or are only effective under specific illumination conditions. To address these issues, we propose a novel framework for simultaneous enhancement and noise suppression under complex illumination conditions. Firstly, a gradient-domain weighted guided filter (GDWGIF) is employed to accurately estimate illumination and improve image quality. Next, the Retinex model is applied to decompose the captured image into separate illumination and reflection layers. These layers undergo parallel processing, with the illumination layer being corrected to optimize lighting conditions and the reflection layer enhanced to improve image quality. Finally, the dynamic range of the image is optimized through multi-exposure fusion and a linear stretching strategy. The proposed method is evaluated on real-world datasets obtained from practical applications. Experimental results demonstrate that our proposed method achieves better performance compared to state-of-the-art methods in both contrast enhancement and noise suppression.

</details>


### [36] [Detection of Digital Facial Retouching utilizing Face Beauty Information](https://arxiv.org/abs/2512.08397)
*Philipp Srock,Juan E. Tapia,Christoph Busch*

Main category: cs.CV

TL;DR: 本文研究了人脸美颜图像对人脸识别系统的影响，提出利用人工智能特征提取方法提升美颜检测性能，并探索面部美感评估算法在检测中的应用。在未知攻击美颜算法的场景下，实现了1.1%的D-EER（检测错误等值率），表明该方法具有较强的检测能力。


<details>
  <summary>Details</summary>
Motivation: 人脸美颜技术广泛应用于社交媒体、广告和专业摄影中，虽提升了美观度，但可能影响生物识别系统的准确性。已有研究表明美颜会干扰人脸识别，因此亟需有效检测美颜图像的方法，以保障生物识别系统的可靠性。

Method: 通过分析美颜图像对美学评估算法的影响，比较多种基于人工智能的特征提取方法，结合面部美感评估，设计并优化美颜检测模型。

Result: 在未知攻击美颜算法的条件下，单张图像检测的D-EER达到1.1%，显著优于现有方法，验证了所提方法的有效性与鲁棒性。

Conclusion: 本研究证明，利用面部美感评估与AI特征提取相结合的方法可有效提升美颜图像的检测精度，为应对未知美颜攻击提供了可靠解决方案。

Abstract: Facial retouching to beautify images is widely spread in social media, advertisements, and it is even applied in professional photo studios to let individuals appear younger, remove wrinkles and skin impurities. Generally speaking, this is done to enhance beauty. This is not a problem itself, but when retouched images are used as biometric samples and enrolled in a biometric system, it is one. Since previous work has proven facial retouching to be a challenge for face recognition systems,the detection of facial retouching becomes increasingly necessary. This work proposes to study and analyze changes in beauty assessment algorithms of retouched images, assesses different feature extraction methods based on artificial intelligence in order to improve retouching detection, and evaluates whether face beauty can be exploited to enhance the detection rate. In a scenario where the attacking retouching algorithm is unknown, this work achieved 1.1% D-EER on single image detection.

</details>


### [37] [Towards Visual Re-Identification of Fish using Fine-Grained Classification for Electronic Monitoring in Fisheries](https://arxiv.org/abs/2512.08400)
*Samitha Nuwan Thilakarathna,Ercan Avsar,Martin Mathias Nielsen,Malte Pedersen*

Main category: cs.CV

TL;DR: 该研究针对电子监控（EM）系统产生的大量渔业视频数据难以手动审查的问题，提出了一种优化的深度学习流水线用于鱼类再识别（Re-ID）。基于自建的AutoFish数据集，通过硬三元组挖掘和特定于数据集的图像变换流程，显著提升了Re-ID性能。实验表明，基于视觉变压器的Swin-T架构优于传统的ResNet-50，在mAP@k和Rank-1准确率上分别达到41.65%和90.43%。主要挑战在于同一物种内个体间的区分，视角不一致比部分遮挡更具破坏性。代码与文档已公开。


<details>
  <summary>Details</summary>
Motivation: 随着电子监控系统在渔业中的广泛应用，产生了海量视频数据，远超人工审核能力。因此需要自动化工具来高效、准确地进行鱼类再识别，以支持可持续的海洋资源管理。

Method: 提出一种结合硬三元组挖掘与定制化图像变换流程的深度学习管道；使用AutoFish数据集进行训练与评估；比较了Swin-T与ResNet-50两种模型的性能。

Result: Swin-T在mAP@k上达到41.65%，Rank-1准确率达到90.43%，显著优于ResNet-50；视角不一致是导致同种个体误判的主要因素，远超过部分遮挡的影响。

Conclusion: 基于Vision Transformer的Swin-T架构在鱼类再识别任务中表现更优，且通过优化的数据处理策略可有效提升识别精度；未来工作应聚焦于缓解视角变化带来的影响。

Abstract: Accurate fisheries data are crucial for effective and sustainable marine resource management. With the recent adoption of Electronic Monitoring (EM) systems, more video data is now being collected than can be feasibly reviewed manually. This paper addresses this challenge by developing an optimized deep learning pipeline for automated fish re-identification (Re-ID) using the novel AutoFish dataset, which simulates EM systems with conveyor belts with six similarly looking fish species. We demonstrate that key Re-ID metrics (R1 and mAP@k) are substantially improved by using hard triplet mining in conjunction with a custom image transformation pipeline that includes dataset-specific normalization. By employing these strategies, we demonstrate that the Vision Transformer-based Swin-T architecture consistently outperforms the Convolutional Neural Network-based ResNet-50, achieving peak performance of 41.65% mAP@k and 90.43% Rank-1 accuracy. An in-depth analysis reveals that the primary challenge is distinguishing visually similar individuals of the same species (Intra-species errors), where viewpoint inconsistency proves significantly more detrimental than partial occlusion. The source code and documentation are available at: https://github.com/msamdk/Fish_Re_Identification.git

</details>


### [38] [SAM-Body4D: Training-Free 4D Human Body Mesh Recovery from Videos](https://arxiv.org/abs/2512.08406)
*Mingqi Gao,Yunqi Miao,Jungong Han*

Main category: cs.CV

TL;DR: 提出SAM-Body4D，一种无需训练的视频人体3D重建框架，通过一致性掩码和遮挡感知模块提升时序一致性和遮挡鲁棒性，实现高效多人体推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的HMR方法在视频应用中存在逐帧推理导致的时间不一致和遮挡下性能下降的问题，需在不重新训练的前提下提升时序稳定性和鲁棒性。

Method: 利用可提示视频分割模型生成身份一致的掩码片段，通过遮挡感知模块修复缺失区域，结合掩码引导与基于填充的并行策略，实现对视频序列的时序一致且鲁棒的3D人体重建。

Result: 在真实复杂场景视频上，SAM-Body4D显著提升了时序稳定性与遮挡鲁棒性，且无需额外训练，性能优于现有方法。

Conclusion: SAM-Body4D成功实现了无需训练的、时序一致且对遮挡鲁棒的视频人体3D重建，为真实世界中的人体理解提供了有效解决方案。

Abstract: Human Mesh Recovery (HMR) aims to reconstruct 3D human pose and shape from 2D observations and is fundamental to human-centric understanding in real-world scenarios. While recent image-based HMR methods such as SAM 3D Body achieve strong robustness on in-the-wild images, they rely on per-frame inference when applied to videos, leading to temporal inconsistency and degraded performance under occlusions. We address these issues without extra training by leveraging the inherent human continuity in videos. We propose SAM-Body4D, a training-free framework for temporally consistent and occlusion-robust HMR from videos. We first generate identity-consistent masklets using a promptable video segmentation model, then refine them with an Occlusion-Aware module to recover missing regions. The refined masklets guide SAM 3D Body to produce consistent full-body mesh trajectories, while a padding-based parallel strategy enables efficient multi-human inference. Experimental results demonstrate that SAM-Body4D achieves improved temporal stability and robustness in challenging in-the-wild videos, without any retraining. Our code and demo are available at: https://github.com/gaomingqi/sam-body4d.

</details>


### [39] [Towards Effective and Efficient Long Video Understanding of Multimodal Large Language Models via One-shot Clip Retrieval](https://arxiv.org/abs/2512.08410)
*Tao Chen,Shaobo Ju,Qiong Wu,Chenxin Fang,Kun Zhang,Jun Peng,Hui Li,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: OneClip-RAG is a novel framework that enhances multimodal large language models (MLLMs) for long video understanding by leveraging one-shot video clip retrieval and a query-guided chunking algorithm, achieving superior performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing MLLMs suffer from high memory overhead, limiting their ability to process long videos. This paper aims to address this limitation by improving video understanding through efficient retrieval and chunking.

Method: OneClip-RAG introduces a query-guided video chunking algorithm that integrates clip chunking and cross-modal retrieval in a single step, reducing redundant computation. It also leverages a new dataset (SynLongVideo) and progressive training to improve instruction following.

Result: OneClip-RAG significantly boosts MLLM performance on long-video benchmarks—e.g., InternLV2 8B and Qwen2-VL 7B match GPT-4o levels on MLVU—and enables LLaVA-Video to process up to one hour of video in under 2.2 minutes on a single 4090 GPU.

Conclusion: OneClip-RAG effectively overcomes memory limitations in MLLMs for long video processing, delivering both high accuracy and computational efficiency.

Abstract: Due to excessive memory overhead, most Multimodal Large Language Models (MLLMs) can only process videos of limited frames. In this paper, we propose an effective and efficient paradigm to remedy this shortcoming, termed One-shot video-Clip based Retrieval AuGmentation (OneClip-RAG). Compared with existing video RAG methods, OneClip-RAG makes full use of the merits of video clips for augmented video understanding in terms of both knowledge integrity and semantic coherence. Besides, it is also equipped with a novel query-guided video chunking algorithm that can unify clip chunking and cross-modal retrieval in one processing step, avoiding redundant computations. To improve instruction following, we further propose a new dataset called SynLongVideo and design a progressive training regime for OneClip-RAG. OneClip-RAG is plugged into five recent MLLMs and validated on a set of long-video benchmarks. Experimental results not only show the obvious performance gains by OneClip-RAG over MLLMs, e.g., boosting InternLV2 8B and Qwen2-VL 7B to the level of GPT-4o on MLVU, but also show its superior efficiency in handling long videos. e.g., enabling LLaVA-Video understand up to an hour of videos in less than 2.2 minutes on a single 4090 GPU.

</details>


### [40] [SDT-6D: Fully Sparse Depth-Transformer for Staged End-to-End 6D Pose Estimation in Industrial Multi-View Bin Picking](https://arxiv.org/abs/2512.08430)
*Nico Leuze,Maximilian Hoh,Samed Doğan,Nicolas R. -Peña,Alfred Schoettl*

Main category: cs.CV

TL;DR: 提出了一种全稀疏的深度仅6D姿态估计方法，通过多视角深度图融合生成细粒度点云或稀疏截断符号距离场（TSDF），利用分阶段热图机制生成场景自适应注意力先验，动态关注前景区域并降低内存开销。引入密度感知稀疏变换器块以处理自遮挡和3D数据非均匀分布问题，采用基于体素的投票策略实现对任意数量目标物体的同时姿态预测，在密集杂乱环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 在工业级密集装箱抓取环境中，由于遮挡、反射和无纹理部件的存在，准确恢复6D姿态仍是一项严峻挑战。现有方法在高分辨率几何细节捕捉与计算效率之间难以平衡，且稀疏3D方法在近距离机器人应用中尚未得到充分探索。

Method: 提出一种深度仅的6D姿态估计框架，融合多视角深度图生成点云或稀疏TSDF；设计分阶段热图机制生成场景自适应注意力先验；引入密度感知稀疏变换器块以动态处理遮挡与非均匀分布；采用全稀疏架构支持高分辨率体积表示，并通过每体素投票策略实现多目标同时姿态预测。

Result: 在最新发布的IPD和MV-YCB多视角数据集上验证，方法在高度杂乱的工业及家庭装箱抓取场景中表现出色，具有较强的鲁棒性与精度，尤其在密集遮挡条件下优于现有方法。

Conclusion: 该方法通过稀疏化设计与智能注意力机制，有效解决了密集环境下的6D姿态估计难题，为近距机器人操作提供了高效、精确的解决方案。

Abstract: Accurately recovering 6D poses in densely packed industrial bin-picking environments remain a serious challenge, owing to occlusions, reflections, and textureless parts. We introduce a holistic depth-only 6D pose estimation approach that fuses multi-view depth maps into either a fine-grained 3D point cloud in its vanilla version, or a sparse Truncated Signed Distance Field (TSDF). At the core of our framework lies a staged heatmap mechanism that yields scene-adaptive attention priors across different resolutions, steering computation toward foreground regions, thus keeping memory requirements at high resolutions feasible. Along, we propose a density-aware sparse transformer block that dynamically attends to (self-) occlusions and the non-uniform distribution of 3D data. While sparse 3D approaches has proven effective for long-range perception, its potential in close-range robotic applications remains underexplored. Our framework operates fully sparse, enabling high-resolution volumetric representations to capture fine geometric details crucial for accurate pose estimation in clutter. Our method processes the entire scene integrally, predicting the 6D pose via a novel per-voxel voting strategy, allowing simultaneous pose predictions for an arbitrary number of target objects. We validate our method on the recently published IPD and MV-YCB multi-view datasets, demonstrating competitive performance in heavily cluttered industrial and household bin picking scenarios.

</details>


### [41] [LapFM: A Laparoscopic Segmentation Foundation Model via Hierarchical Concept Evolving Pre-training](https://arxiv.org/abs/2512.08439)
*Qing Xu,Kun Yuan,Yuxiang Luo,Yuhao Zhai,Wenting Duan,Nassir Navab,Zhen Chen*

Main category: cs.CV

TL;DR: 本文提出LapFM，一种基于大规模未标注腹腔镜图像的手术分割基础模型。通过分层概念演化预训练范式，构建了腹腔镜概念层次（LCH），统一解剖结构、组织和器械等实体，并利用置信度驱动的迭代伪标签生成与过滤机制，逐步引入可靠样本进行训练，形成包含11.4万张图像-掩码对的大规模基准LapBench-114K。实验表明，LapFM在跨任务泛化和细粒度适应方面显著优于现有方法，为通用腹腔镜分割树立新标准。


<details>
  <summary>Details</summary>
Motivation: 手术分割对场景理解至关重要，但受限于标注稀缺和不同手术间语义不一致。现有方法依赖微调自然领域基础模型（如SAM），仅作为领域适配器，缺乏真正意义上的手术基础模型，难以应对手术目标的巨大变异性。

Method: 提出分层概念演化预训练范式：1）构建腹腔镜概念层次（LCH），通过具有父子查询嵌入的分层掩码解码器，将解剖、组织、器械等实体整合为可扩展且跨粒度语义一致的知识结构；2）设计置信度驱动的演化标注机制，基于层次一致性迭代生成并筛选伪标签，逐步将高质量未标注样本纳入训练。

Result: LapFM在多个基准上显著超越现有先进方法，在细粒度自适应泛化能力方面表现优异；构建了大规模基准LapBench-114K，包含114,000张图像-掩码对，推动领域发展。

Conclusion: LapFM成功构建了一个真正意义上的手术基础模型，通过分层知识结构与高效伪标签演化机制，实现了从海量未标注数据中学习鲁棒分割能力，为腹腔镜手术视觉理解提供了新的范式。

Abstract: Surgical segmentation is pivotal for scene understanding yet remains hindered by annotation scarcity and semantic inconsistency across diverse procedures. Existing approaches typically fine-tune natural foundation models (e.g., SAM) with limited supervision, functioning merely as domain adapters rather than surgical foundation models. Consequently, they struggle to generalize across the vast variability of surgical targets. To bridge this gap, we present LapFM, a foundation model designed to evolve robust segmentation capabilities from massive unlabeled surgical images. Distinct from medical foundation models relying on inefficient self-supervised proxy tasks, LapFM leverages a Hierarchical Concept Evolving Pre-training paradigm. First, we establish a Laparoscopic Concept Hierarchy (LCH) via a hierarchical mask decoder with parent-child query embeddings, unifying diverse entities (i.e., Anatomy, Tissue, and Instrument) into a scalable knowledge structure with cross-granularity semantic consistency. Second, we propose a Confidence-driven Evolving Labeling that iteratively generates and filters pseudo-labels based on hierarchical consistency, progressively incorporating reliable samples from unlabeled images into training. This process yields LapBench-114K, a large-scale benchmark comprising 114K image-mask pairs. Extensive experiments demonstrate that LapFM significantly outperforms state-of-the-art methods, establishing new standards for granularity-adaptive generalization in universal laparoscopic segmentation. The source code is available at https://github.com/xq141839/LapFM.

</details>


### [42] [Leveraging Multispectral Sensors for Color Correction in Mobile Cameras](https://arxiv.org/abs/2512.08441)
*Luca Cogo,Marco Buzzelli,Simone Bianco,Javier Vazquez-Corral,Raimondo Schettini*

Main category: cs.CV

TL;DR: 本文提出了一种统一的、基于学习的框架，用于端到端的颜色校正，联合利用高分辨率RGB传感器和低分辨率多光谱（MS）传感器的数据。该方法将整个色彩校正流程整合到一个模型中，显著提升了颜色准确性和稳定性，相比仅使用RGB或仅依赖MS的基线方法，颜色误差降低高达50%。研究构建了一个新的数据集，并验证了框架在不同图像到图像架构上的灵活性与通用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将颜色校正流程分阶段处理，且过早丢弃多光谱数据，导致信息损失。为提升颜色校正的准确性与一致性，需要一种能融合多源数据并端到端优化的统一框架。

Method: 提出一个统一的学习型框架，联合利用高分辨率RGB和低分辨率多光谱（MS）数据，将颜色校正全流程集成于单一模型中，支持多种图像到图像架构的适配。通过构建新数据集进行训练与评估，实现端到端优化。

Result: 实验表明，所提方法在颜色准确性和稳定性方面显著优于现有方法，最大可减少50%的颜色误差；同时展现出良好的灵活性与通用性。

Conclusion: 该统一学习框架有效整合了多光谱与RGB数据，实现了更精确、稳定的端到端颜色校正，具有广泛的应用潜力。

Abstract: Recent advances in snapshot multispectral (MS) imaging have enabled compact, low-cost spectral sensors for consumer and mobile devices. By capturing richer spectral information than conventional RGB sensors, these systems can enhance key imaging tasks, including color correction. However, most existing methods treat the color correction pipeline in separate stages, often discarding MS data early in the process. We propose a unified, learning-based framework that (i) performs end-to-end color correction and (ii) jointly leverages data from a high-resolution RGB sensor and an auxiliary low-resolution MS sensor. Our approach integrates the full pipeline within a single model, producing coherent and color-accurate outputs. We demonstrate the flexibility and generality of our framework by refactoring two different state-of-the-art image-to-image architectures. To support training and evaluation, we construct a dedicated dataset by aggregating and repurposing publicly available spectral datasets, rendering under multiple RGB camera sensitivities. Extensive experiments show that our approach improves color accuracy and stability, reducing error by up to 50% compared to RGB-only and MS-driven baselines. Datasets, code, and models will be made available upon acceptance.

</details>


### [43] [Uncertainty-Aware Subset Selection for Robust Visual Explainability under Distribution Shifts](https://arxiv.org/abs/2512.08445)
*Madhav Gupta,Vishak Prasad C,Ganesh Ramakrishnan*

Main category: cs.CV

TL;DR: 本文研究了基于子集选择的深度视觉模型解释方法在分布内（ID）和分布外（OOD）场景下的表现，发现现有方法在OOD条件下解释可靠性显著下降，存在冗余、不稳定和对不确定性敏感等问题。为此，作者提出一种结合子模优化与层间梯度不确定性估计的新框架，通过自适应权重扰动估计不确定性，并指导子集选择，从而提升解释的鲁棒性和保真度，且无需额外训练或辅助模型。实验表明，该方法不仅改善了OOD场景下的解释质量，也在ID场景中表现更优，揭示了现有方法的局限性，并展示了不确定性驱动优化在增强可解释性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基于子集选择的解释方法在分布内（ID）场景下表现良好，但在分布外（OOD）条件下解释结果变得不可靠，出现冗余、不稳定和对不确定性敏感等问题，亟需改进以提升实际应用中的可信度和透明度。

Method: 提出一种融合子模子集选择与层间梯度基不确定性估计的框架；通过自适应权重扰动估计不确定性，并利用该估计引导子模优化过程，实现多样且信息丰富的子集选择，无需额外训练或引入辅助模型。

Result: 所提方法在多种分布外（OOD）数据集上显著提升了解释的稳定性与可靠性，减少了冗余并降低了对不确定性的敏感性；同时在分布内（ID）设置中也取得了优于现有方法的性能，证明其通用性强、有效性高。

Conclusion: 当前子集选择方法在分布外场景中存在严重缺陷，而通过引入不确定性驱动的优化机制，可有效提升解释的鲁棒性与可解释性，为构建更透明、可信的现实世界视觉AI系统提供了新路径。

Abstract: Subset selection-based methods are widely used to explain deep vision models: they attribute predictions by highlighting the most influential image regions and support object-level explanations. While these methods perform well in in-distribution (ID) settings, their behavior under out-of-distribution (OOD) conditions remains poorly understood. Through extensive experiments across multiple ID-OOD sets, we find that reliability of the existing subset based methods degrades markedly, yielding redundant, unstable, and uncertainty-sensitive explanations. To address these shortcomings, we introduce a framework that combines submodular subset selection with layer-wise, gradient-based uncertainty estimation to improve robustness and fidelity without requiring additional training or auxiliary models. Our approach estimates uncertainty via adaptive weight perturbations and uses these estimates to guide submodular optimization, ensuring diverse and informative subset selection. Empirical evaluations show that, beyond mitigating the weaknesses of existing methods under OOD scenarios, our framework also yields improvements in ID settings. These findings highlight limitations of current subset-based approaches and demonstrate how uncertainty-driven optimization can enhance attribution and object-level interpretability, paving the way for more transparent and trustworthy AI in real-world vision applications.

</details>


### [44] [Team-Aware Football Player Tracking with SAM: An Appearance-Based Approach to Occlusion Recovery](https://arxiv.org/abs/2512.08467)
*Chamath Ranasinghe,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 本文提出一种轻量级基于SAM的足球球员跟踪方法，结合SAM、CSRT追踪器和球衣颜色外观模型，利用HSV直方图进行重识别以提升遮挡恢复能力。在足球视频序列上的实验表明，该方法在轻度遮挡下实现100%跟踪成功率，在罚球区密集场景下保持90%成功率，且处理速度达7.6-7.7 FPS，内存占用约1880 MB。外观重识别可恢复50%重度遮挡，但长时离屏后仅8.66%成功重捕获，揭示了经典追踪方法在连续可见性下的优势及对强重识别机制的需求。


<details>
  <summary>Details</summary>
Motivation: 足球球员跟踪面临频繁遮挡、外观相似和快速运动等挑战，尤其在人群密集场景中，现有方法难以兼顾精度与实时性，亟需融合视觉分割与外观建模的高效解决方案。

Method: 采用SAM进行精确初始化，结合CSRT追踪器与球衣颜色的HSV直方图外观模型，构建团队感知的跟踪系统，并通过外观重识别提升遮挡恢复能力。

Result: 在轻度遮挡下实现100%跟踪成功率，在密集罚球区场景下达90%，处理速度为7.6-7.7 FPS，内存稳定在约1880 MB；外观重识别可恢复50%重度遮挡，但长时离屏重捕获率仅为8.66%。

Conclusion: 该方法在资源受限环境下表现出良好性能，证明经典追踪器在持续可见性下有效，但需强化重识别机制以应对长期遮挡或离屏问题，为实际部署提供可行指导。

Abstract: Football player tracking is challenged by frequent occlusions, similar appearances, and rapid motion in crowded scenes. This paper presents a lightweight SAM-based tracking method combining the Segment Anything Model (SAM) with CSRT trackers and jersey color-based appearance models. We propose a team-aware tracking system that uses SAM for precise initialization and HSV histogram-based re-identification to improve occlusion recovery. Our evaluation measures three dimensions: processing speed (FPS and memory), tracking accuracy (success rate and box stability), and robustness (occlusion recovery and identity consistency). Experiments on football video sequences show that the approach achieves 7.6-7.7 FPS with stable memory usage (~1880 MB), maintaining 100 percent tracking success in light occlusions and 90 percent in crowded penalty-box scenarios with 5 or more players. Appearance-based re-identification recovers 50 percent of heavy occlusions, demonstrating the value of domain-specific cues. Analysis reveals key trade-offs: the SAM + CSRT combination provides consistent performance across crowd densities but struggles with long-term occlusions where players leave the frame, achieving only 8.66 percent re-acquisition success. These results offer practical guidelines for deploying football tracking systems under resource constraints, showing that classical tracker-based methods work well with continuous visibility but require stronger re-identification mechanisms for extended absences.

</details>


### [45] [ContextDrag: Precise Drag-Based Image Editing via Context-Preserving Token Injection and Position-Consistent Attention](https://arxiv.org/abs/2512.08477)
*Huiguo He,Pengyu Yan,Ziqi Yi,Weizhi Zhong,Zheng Liu,Yejun Tang,Huan Yang,Kun Gai,Guanbin Li,Lianwen Jin*

Main category: cs.CV

TL;DR: ContextDrag 提出了一种新的基于拖拽的图像编辑范式，通过利用编辑模型（如 FLUX-Kontext）的强大上下文建模能力，结合参考图像的 VAE 编码特征，在不进行微调或反演的情况下，有效保留了细粒度纹理等上下文信息。其核心创新包括：1）上下文保持的令牌注入（CTI），通过潜空间逆映射（LRM）将无噪声的参考特征精准注入目标位置；2）位置一致注意力（PCA），对参考令牌进行位置重编码并采用重叠感知掩码，消除无关特征干扰。实验表明，该方法在 DragBench-SR 和 DragBench-DR 上均优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽编辑方法未能充分挖掘参考图像中的上下文信息，尤其是细粒度纹理细节，导致编辑结果在连贯性和保真度方面存在不足。

Method: 提出 ContextDrag 范式，引入上下文保持的令牌注入（CTI）与位置一致注意力（PCA）。CTI 利用潜空间逆映射（LRM）将参考图像的无噪声特征精确注入目标区域；PCA 通过位置重编码和重叠感知掩码机制，抑制无关特征干扰，增强上下文一致性。

Result: 在 DragBench-SR 与 DragBench-DR 数据集上的实验结果显示，ContextDrag 显著优于所有现有 SOTA 方法，在语义一致性和纹理保真度方面表现更优。

Conclusion: ContextDrag 通过高效利用参考图像的上下文信息，实现了高保真、高一致性的拖拽图像编辑，无需微调或反演，具有良好的实用性和可扩展性，代码将公开。

Abstract: Drag-based image editing aims to modify visual content followed by user-specified drag operations. Despite existing methods having made notable progress, they still fail to fully exploit the contextual information in the reference image, including fine-grained texture details, leading to edits with limited coherence and fidelity. To address this challenge, we introduce ContextDrag, a new paradigm for drag-based editing that leverages the strong contextual modeling capability of editing models, such as FLUX-Kontext. By incorporating VAE-encoded features from the reference image, ContextDrag can leverage rich contextual cues and preserve fine-grained details, without the need for finetuning or inversion. Specifically, ContextDrag introduced a novel Context-preserving Token Injection (CTI) that injects noise-free reference features into their correct destination locations via a Latent-space Reverse Mapping (LRM) algorithm. This strategy enables precise drag control while preserving consistency in both semantics and texture details. Second, ContextDrag adopts a novel Position-Consistent Attention (PCA), which positional re-encodes the reference tokens and applies overlap-aware masking to eliminate interference from irrelevant reference features. Extensive experiments on DragBench-SR and DragBench-DR demonstrate that our approach surpasses all existing SOTA methods. Code will be publicly available.

</details>


### [46] [Temporal Concept Dynamics in Diffusion Models via Prompt-Conditioned Interventions](https://arxiv.org/abs/2512.08486)
*Ada Gorgun,Fawaz Sammani,Nikos Deligiannis,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: 该研究提出PCI（Prompt-Conditioned Intervention）框架，用于分析扩散模型中概念形成的时间动态，通过衡量在特定时间步插入概念后其在最终图像中被保留的概率（即概念插入成功率CIS），揭示不同模型和概念在生成轨迹中的时间敏感性。结果表明，某些阶段对特定概念更有效，为文本驱动的图像编辑提供了无需模型内部信息或训练即可实现更优编辑的时机指导。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型评估主要关注最终输出，但生成过程是动态的，理解概念何时形成并锁定轨迹对可控性、可靠性与预测性至关重要。现有方法缺乏对概念演化时间点的分析能力，因此需要一种无需训练、通用且能揭示概念动态的分析框架。

Method: 提出PCI框架，基于概念插入成功率（CIS）评估在不同时间步插入概念后是否能在最终图像中保留；采用无训练、模型无关的方法，在多个先进文本到图像扩散模型上测试多种概念类型，系统分析概念形成的时间特性。

Result: PCI揭示了不同扩散模型在概念形成上的多样化时间行为，同一概念类型在不同阶段表现差异显著；识别出干预最有效的时点，支持更精准的文本驱动图像编辑，优于强基线方法，在语义准确性和内容保真度之间取得更好平衡。

Conclusion: PCI提供了一种无需访问模型内部或进行训练的通用方法，可有效分析扩散模型中概念的时间动态，为理解生成过程、提升可控编辑性能提供了关键洞察。

Abstract: Diffusion models are usually evaluated by their final outputs, gradually denoising random noise into meaningful images. Yet, generation unfolds along a trajectory, and analyzing this dynamic process is crucial for understanding how controllable, reliable, and predictable these models are in terms of their success/failure modes. In this work, we ask the question: when does noise turn into a specific concept (e.g., age) and lock in the denoising trajectory? We propose PCI (Prompt-Conditioned Intervention) to study this question. PCI is a training-free and model-agnostic framework for analyzing concept dynamics through diffusion time. The central idea is the analysis of Concept Insertion Success (CIS), defined as the probability that a concept inserted at a given timestep is preserved and reflected in the final image, offering a way to characterize the temporal dynamics of concept formation. Applied to several state-of-the-art text-to-image diffusion models and a broad taxonomy of concepts, PCI reveals diverse temporal behaviors across diffusion models, in which certain phases of the trajectory are more favorable to specific concepts even within the same concept type. These findings also provide actionable insights for text-driven image editing, highlighting when interventions are most effective without requiring access to model internals or training, and yielding quantitatively stronger edits that achieve a balance of semantic accuracy and content preservation than strong baselines. Code is available at: https://github.com/adagorgun/PCI-Prompt-Controlled-Interventions

</details>


### [47] [On-the-fly Large-scale 3D Reconstruction from Multi-Camera Rigs](https://arxiv.org/abs/2512.08498)
*Yijia Guo,Tong Hu,Zhiwei Li,Liwen Hu,Keming Qian,Xitong Lin,Shengbo Chen,Tiejun Huang,Lei Ma*

Main category: cs.CV

TL;DR: 本文提出首个面向多相机阵列的实时3D重建框架，通过增量融合多视角重叠的密集RGB流，实现无漂移轨迹估计与高效在线重建。方法包括层次化相机初始化、轻量级多相机束调整、无冗余高斯采样及频率感知优化调度，显著减少高斯素数量与优化迭代次数，在仅2分钟内完成数百米场景重建，兼具速度、鲁棒性与保真度。


<details>
  <summary>Details</summary>
Motivation: 单目RGB流在实时3D重建中受限于有限视场（FOV），导致3D覆盖不完整；多相机阵列可从根本上解决此问题，但缺乏高效的实时融合与重建方法。

Method: 提出层次化相机初始化以实现粗略跨相机对齐（无需标定），结合轻量级多相机束调整稳定轨迹；设计冗余-free高斯采样策略与频率感知优化调度，降低高斯素数量和优化迭代次数，保障效率与重建质量。

Result: 仅使用原始多相机视频流，可在2分钟内重建数百米长的3D场景，实现了前所未有的重建速度、鲁棒性与保真度，支持无漂移轨迹估计与高效在线重建。

Conclusion: 该方法首次实现了多相机阵列下实时、高保真、无漂移的3D场景重建，为动态环境下的大规模在线三维重建提供了新范式。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled efficient free-viewpoint rendering and photorealistic scene reconstruction. While on-the-fly extensions of 3DGS have shown promise for real-time reconstruction from monocular RGB streams, they often fail to achieve complete 3D coverage due to the limited field of view (FOV). Employing a multi-camera rig fundamentally addresses this limitation. In this paper, we present the first on-the-fly 3D reconstruction framework for multi-camera rigs. Our method incrementally fuses dense RGB streams from multiple overlapping cameras into a unified Gaussian representation, achieving drift-free trajectory estimation and efficient online reconstruction. We propose a hierarchical camera initialization scheme that enables coarse inter-camera alignment without calibration, followed by a lightweight multi-camera bundle adjustment that stabilizes trajectories while maintaining real-time performance. Furthermore, we introduce a redundancy-free Gaussian sampling strategy and a frequency-aware optimization scheduler to reduce the number of Gaussian primitives and the required optimization iterations, thereby maintaining both efficiency and reconstruction fidelity. Our method reconstructs hundreds of meters of 3D scenes within just 2 minutes using only raw multi-camera video streams, demonstrating unprecedented speed, robustness, and Fidelity for on-the-fly 3D scene reconstruction.

</details>


### [48] [Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models](https://arxiv.org/abs/2512.08503)
*Jiaming Zhang,Che Wang,Yang Cao,Longtao Huang,Wei Yang Bryan Lim*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReasonBreak的新颖对抗性框架，旨在通过概念感知的扰动破坏多模态大推理模型（MLRMs）中的层次化推理过程。针对现有隐私保护技术在应对MLRMs复杂推理时的不足，ReasonBreak基于关键洞察——有效干扰地理推理需与概念层级对齐而非施加均匀噪声，从而精准打击推理链中的关键概念依赖，生成可使特定推理步骤失效并引发后续级联错误的扰动。为此，研究构建了GeoPrivacy-6K数据集，包含6,341张超高清图像（≥2K分辨率）及分层概念标注。在七种先进MLRMs上的广泛评估表明，ReasonBreak显著提升隐私保护效果：在街区级别保护率达33.8%（较基线提升14.4%），在区块级别接近翻倍（33.5% vs 16.8%）。该工作为抵御基于推理的隐私威胁建立了新范式。


<details>
  <summary>Details</summary>
Motivation: 多模态大推理模型（MLRMs）能够通过分析个人图像中的环境线索，利用层次化思维链推理出精确地理位置，带来严重隐私风险。然而，现有主要面向感知模型的隐私保护方法无法有效应对MLRMs所具备的复杂多步推理能力，亟需一种专门针对推理过程的新型防护机制。

Method: 提出ReasonBreak框架，采用概念感知的扰动策略，聚焦于推理链中关键的概念依赖关系进行精准攻击；通过生成与概念层级结构一致的扰动，使特定推理步骤失效，并引发后续推理阶段的级联错误，从而有效中断地理定位推理流程。

Result: 在七种主流MLRMs（包括GPT-o3、GPT-5、Gemini 2.5 Pro）上验证，ReasonBreak在街区级别实现33.8%的保护率（相比基线19.4%提升14.4%），在区块级别达到33.5%（对比16.8%几乎翻倍），显著优于现有方法。

Conclusion: ReasonBreak成功建立了一种针对推理型威胁的新型隐私保护范式，证明了概念层级对齐的扰动在对抗多模态大推理模型方面具有强大有效性，为未来隐私安全设计提供了重要方向。

Abstract: Multi-modal large reasoning models (MLRMs) pose significant privacy risks by inferring precise geographic locations from personal images through hierarchical chain-of-thought reasoning. Existing privacy protection techniques, primarily designed for perception-based models, prove ineffective against MLRMs' sophisticated multi-step reasoning processes that analyze environmental cues. We introduce \textbf{ReasonBreak}, a novel adversarial framework specifically designed to disrupt hierarchical reasoning in MLRMs through concept-aware perturbations. Our approach is founded on the key insight that effective disruption of geographic reasoning requires perturbations aligned with conceptual hierarchies rather than uniform noise. ReasonBreak strategically targets critical conceptual dependencies within reasoning chains, generating perturbations that invalidate specific inference steps and cascade through subsequent reasoning stages. To facilitate this approach, we contribute \textbf{GeoPrivacy-6K}, a comprehensive dataset comprising 6,341 ultra-high-resolution images ($\geq$2K) with hierarchical concept annotations. Extensive evaluation across seven state-of-the-art MLRMs (including GPT-o3, GPT-5, Gemini 2.5 Pro) demonstrates ReasonBreak's superior effectiveness, achieving a 14.4\% improvement in tract-level protection (33.8\% vs 19.4\%) and nearly doubling block-level protection (33.5\% vs 16.8\%). This work establishes a new paradigm for privacy protection against reasoning-based threats.

</details>


### [49] [Beyond the Noise: Aligning Prompts with Latent Representations in Diffusion Models](https://arxiv.org/abs/2512.08505)
*Vasco Ramos,Regev Cohen,Idan Szpektor,Joao Magalhaes*

Main category: cs.CV

TL;DR: 本文提出NoisyCLIP，一种在去噪过程中早期检测文本与图像语义错位的方法，利用双编码器在噪声潜在空间中评估对齐度，实现生成过程中的实时对齐评估。相比传统方法，该方法在保持98% CLIP对齐性能的同时降低50%计算成本，适用于BoN后处理设置。


<details>
  <summary>Details</summary>
Motivation: 现有条件扩散模型在生成过程中仍存在语义错位和幻觉问题，而传统的对齐检测需等待生成完成，成本高昂。因此需要一种能在生成早期进行对齐检测的高效方法，以实现实时评估并提升生成质量。

Method: 提出NoisyCLIP，通过在反向扩散过程中使用双编码器在噪声潜在空间中测量文本与图像的语义对齐程度，实现早期对齐检测。

Result: NoisyCLIP在BoN设置下实现了98%的CLIP对齐性能，同时将计算成本降低50%，支持实时对齐评估，显著提升了生成效率与质量。

Conclusion: 本研究首次探索并基准测试了生成过程中提示与潜在表示之间的错位检测，证明了在去噪阶段早期进行对齐评估的可行性与有效性，为高质量、低成本的图像生成提供了新路径。

Abstract: Conditional diffusion models rely on language-to-image alignment methods to steer the generation towards semantically accurate outputs. Despite the success of this architecture, misalignment and hallucinations remain common issues and require automatic misalignment detection tools to improve quality, for example by applying them in a Best-of-N (BoN) post-generation setting. Unfortunately, measuring the alignment after the generation is an expensive step since we need to wait for the overall generation to finish to determine prompt adherence. In contrast, this work hypothesizes that text/image misalignments can be detected early in the denoising process, enabling real-time alignment assessment without waiting for the complete generation. In particular, we propose NoisyCLIP a method that measures semantic alignment in the noisy latent space. This work is the first to explore and benchmark prompt-to-latent misalignment detection during image generation using dual encoders in the reverse diffusion process. We evaluate NoisyCLIP qualitatively and quantitatively and find it reduces computational cost by 50% while achieving 98% of CLIP alignment performance in BoN settings. This approach enables real-time alignment assessment during generation, reducing costs without sacrificing semantic fidelity.

</details>


### [50] [OCCDiff: Occupancy Diffusion Model for High-Fidelity 3D Building Reconstruction from Noisy Point Clouds](https://arxiv.org/abs/2512.08506)
*Jialu Sui,Rui Liu,Hongsheng Zhang*

Main category: cs.CV

TL;DR: OCCDiff提出一种基于潜在扩散模型的建筑表面重建方法，通过在占用函数空间中结合潜在扩散过程与函数自编码器架构，实现高保真、物理一致的3D建筑重建，对噪声和点云密度变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以在不同点密度和噪声条件下准确捕捉建筑表面，亟需一种灵活且鲁棒的3D重建框架。

Method: 采用潜空间扩散模型与函数自编码器结合，引入点编码器提供条件特征，并设计多任务训练策略以增强特征表示能力。

Result: 实验表明该方法生成的样本具有高保真度和物理一致性，对噪声数据表现出强鲁棒性。

Conclusion: OCCDiff有效解决了复杂环境下建筑表面重建的挑战，为高精度、鲁棒的3D重建提供了新思路。

Abstract: A major challenge in reconstructing buildings from LiDAR point clouds lies in accurately capturing building surfaces under varying point densities and noise interference. To flexibly gather high-quality 3D profiles of the building in diverse resolution, we propose OCCDiff applying latent diffusion in the occupancy function space. Our OCCDiff combines a latent diffusion process with a function autoencoder architecture to generate continuous occupancy functions evaluable at arbitrary locations. Moreover, a point encoder is proposed to provide condition features to diffusion learning, constraint the final occupancy prediction for occupancy decoder, and insert multi-modal features for latent generation to latent encoder. To further enhance the model performance, a multi-task training strategy is employed, ensuring that the point encoder learns diverse and robust feature representations. Empirical results show that our method generates physically consistent samples with high fidelity to the target distribution and exhibits robustness to noisy data.

</details>


### [51] [MVP: Multiple View Prediction Improves GUI Grounding](https://arxiv.org/abs/2512.08529)
*Yunzhu Zhang,Zeyu Pan,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Linchao Zhu*

Main category: cs.CV

TL;DR: 本文提出一种无需训练的多视角预测框架MVP，以解决现有GUI接地模型在坐标预测上的不稳定性问题。通过多视角推理，利用注意力引导的视图生成和多坐标聚类来提升预测精度，显著改善了高分辨率及小UI元素场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有GUI接地模型对微小视觉扰动（如裁剪几像素）敏感，导致坐标预测不稳定，影响实际应用性能，尤其在高分辨率和小尺寸UI元素上表现更差。

Method: 提出Multi-View Prediction（MVP）框架，包含两个核心组件：(1) Attention-Guided View Proposal，基于指令-图像注意力分数生成多样化的裁剪视图；(2) Multi-Coordinates Clustering，通过选择最密集空间聚类的中心点来融合多个视角的预测结果。

Result: 在多个模型和基准测试中验证了MVP的有效性。例如，在ScreenSpot-Pro上，UI-TARS-1.5-7B提升至56.1%，GTA1-7B达到61.7%，Qwen3VL-8B-Instruct达65.3%，Qwen3VL-32B-Instruct高达74.0%。

Conclusion: MVP通过多视角推理有效缓解了单视角预测的不稳定性，显著提升了GUI接地任务的准确性和鲁棒性，且无需额外训练，具有良好的通用性和实用性。

Abstract: GUI grounding, which translates natural language instructions into precise pixel coordinates, is essential for developing practical GUI agents. However, we observe that existing grounding models exhibit significant coordinate prediction instability, minor visual perturbations (e.g. cropping a few pixels) can drastically alter predictions, flipping results between correct and incorrect. This instability severely undermines model performance, especially for samples with high-resolution and small UI elements. To address this issue, we propose Multi-View Prediction (MVP), a training-free framework that enhances grounding performance through multi-view inference. Our key insight is that while single-view predictions may be unstable, aggregating predictions from multiple carefully cropped views can effectively distinguish correct coordinates from outliers. MVP comprises two components: (1) Attention-Guided View Proposal, which derives diverse views guided by instruction-to-image attention scores, and (2) Multi-Coordinates Clustering, which ensembles predictions by selecting the centroid of the densest spatial cluster. Extensive experiments demonstrate MVP's effectiveness across various models and benchmarks. Notably, on ScreenSpot-Pro, MVP boosts UI-TARS-1.5-7B to 56.1%, GTA1-7B to 61.7%, Qwen3VL-8B-Instruct to 65.3%, and Qwen3VL-32B-Instruct to 74.0%. The code is available at https://github.com/ZJUSCL/MVP.

</details>


### [52] [PaintFlow: A Unified Framework for Interactive Oil Paintings Editing and Generation](https://arxiv.org/abs/2512.08534)
*Zhangli Hu,Ye Chen,Jiajun Yao,Bingbing Ni*

Main category: cs.CV

TL;DR: 本文提出了一种统一的多模态框架，用于油画生成与编辑。通过结合参考图像、手绘草图和自然语言提示，实现对油画语义和风格的精确控制。技术上引入空间对齐与语义增强训练策略，构建大规模配对数据集，并利用AdaIN操作保持风格一致性，显著提升油画创作的精细编辑能力与艺术表现力。


<details>
  <summary>Details</summary>
Motivation: 现有油画生成与编辑方法受限于训练数据分布，且主要针对真实照片进行修改，难以有效处理油画特有的笔触动态与风格化特征。因此亟需一种能够支持高阶语义控制、保持统一画风的通用油画生成与编辑框架。

Method: 提出基于空间对齐与语义增强的训练策略，设计自监督风格迁移管道（基于SBR）以生成大规模带标注的油画数据，采用AdaIN融合多源特征，实现跨模态输入下的风格一致性输出。

Result: 实验表明，该系统可在交互式条件下实现细粒度编辑，同时保留油画的艺术质感，在风格化油画生成与编辑方面达到前所未有的想象力实现水平。

Conclusion: 本研究构建了一个高效、灵活且可扩展的油画面生成与编辑框架，为数字艺术创作提供了新范式，推动了基于多模态引导的风格化内容生成技术的发展。

Abstract: Oil painting, as a high-level medium that blends human abstract thinking with artistic expression, poses substantial challenges for digital generation and editing due to its intricate brushstroke dynamics and stylized characteristics. Existing generation and editing techniques are often constrained by the distribution of training data and primarily focus on modifying real photographs. In this work, we introduce a unified multimodal framework for oil painting generation and editing. The proposed system allows users to incorporate reference images for precise semantic control, hand-drawn sketches for spatial structure alignment, and natural language prompts for high-level semantic guidance, while consistently maintaining a unified painting style across all outputs. Our method achieves interactive oil painting creation through three crucial technical advancements. First, we enhance the training stage with spatial alignment and semantic enhancement conditioning strategy, which map masks and sketches into spatial constraints, and encode contextual embedding from reference images and text into feature constraints, enabling object-level semantic alignment. Second, to overcome data scarcity, we propose a self-supervised style transfer pipeline based on Stroke-Based Rendering (SBR), which simulates the inpainting dynamics of oil painting restoration, converting real images into stylized oil paintings with preserved brushstroke textures to construct a large-scale paired training dataset. Finally, during inference, we integrate features using the AdaIN operator to ensure stylistic consistency. Extensive experiments demonstrate that our interactive system enables fine-grained editing while preserving the artistic qualities of oil paintings, achieving an unprecedented level of imagination realization in stylized oil paintings generation and editing.

</details>


### [53] [Photo3D: Advancing Photorealistic 3D Generation through Structure-Aligned Detail Enhancement](https://arxiv.org/abs/2512.08535)
*Xinyue Liang,Zhinyuan Ma,Lingchen Sun,Yanjun Guo,Lei Zhang*

Main category: cs.CV

TL;DR: Photo3D 是一个基于 GPT-4o-Image 生成图像数据的框架，旨在推动逼真 3D 生成。针对生成图像缺乏多视角一致性的问题，提出结构对齐的多视角合成管道，并构建了与 3D 几何配对的细节增强多视角数据集。通过感知特征适配和语义结构匹配，实现外观一致性与真实细节的保留，适用于多种 3D 原生生成器，且在几何-纹理耦合与解耦生成范式中均表现优异，实验验证其在多种生成框架下均达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 原生生成器虽能生成可靠几何结构，但在真实外观表现上仍有不足，主要受限于缺乏多样且高质量的真实世界 3D 资产，尤其在纹理细节方面，因场景尺度多样、物体非刚性运动及扫描精度有限而难以获取。

Method: 设计结构对齐的多视角合成管道，利用 GPT-4o-Image 生成图像构建多视角数据集；采用感知特征适配与语义结构匹配策略，增强真实细节并保持与 3D 几何的一致性；提出适用于耦合与解耦生成范式的训练策略。

Result: Photo3D 在多种 3D 原生生成框架中表现出良好的泛化能力，显著提升逼真度，在多个基准测试中达到当前最优性能。

Conclusion: Photo3D 有效解决了 3D 生成中真实外观与几何一致性之间的矛盾，为高保真 3D 内容生成提供了通用且高效的解决方案。

Abstract: Although recent 3D-native generators have made great progress in synthesizing reliable geometry, they still fall short in achieving realistic appearances. A key obstacle lies in the lack of diverse and high-quality real-world 3D assets with rich texture details, since capturing such data is intrinsically difficult due to the diverse scales of scenes, non-rigid motions of objects, and the limited precision of 3D scanners. We introduce Photo3D, a framework for advancing photorealistic 3D generation, which is driven by the image data generated by the GPT-4o-Image model. Considering that the generated images can distort 3D structures due to their lack of multi-view consistency, we design a structure-aligned multi-view synthesis pipeline and construct a detail-enhanced multi-view dataset paired with 3D geometry. Building on it, we present a realistic detail enhancement scheme that leverages perceptual feature adaptation and semantic structure matching to enforce appearance consistency with realistic details while preserving the structural consistency with the 3D-native geometry. Our scheme is general to different 3D-native generators, and we present dedicated training strategies to facilitate the optimization of geometry-texture coupled and decoupled 3D-native generation paradigms. Experiments demonstrate that Photo3D generalizes well across diverse 3D-native generation paradigms and achieves state-of-the-art photorealistic 3D generation performance.

</details>


### [54] [Fast-ARDiff: An Entropy-informed Acceleration Framework for Continuous Space Autoregressive Generation](https://arxiv.org/abs/2512.08537)
*Zhen Zou,Xiaoxiao Ma,Jie Huang,Zichao Yu,Feng Zhao*

Main category: cs.CV

TL;DR: Fast-ARDiff提出一种统一的自回归-扩散框架，通过熵感知的推测策略和动态调度机制，联合优化自回归与扩散组件，显著提升生成速度并保持高质量。该方法在ImageNet 256×256上实现4.3倍无损加速，在文本条件生成中达3倍加速，且通过浅层特征熵预过滤减少冗余计算，有效降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有自回归-扩散混合模型因序列化自回归生成和迭代去噪导致高延迟，亟需一种能同时加速两部分且保持生成质量的方法。

Method: 提出熵感知的推测策略以缓解草案模型与目标模型之间的熵不匹配问题；将扩散模块融入端到端框架，采用动态调度优先优化自回归部分，并通过轨迹与分布匹配的联合蒸馏训练扩散模块，实现少步高效合成；推理时利用自回归模块的浅层特征熵预过滤低熵草案，避免无效计算。

Result: 在ImageNet 256×256上，TransDiff实现4.3倍无损加速；在文本条件生成中，NextStep-1达到3倍加速；整体框架在多种模型上均实现最先进的加速效果，且生成质量稳定。

Conclusion: Fast-ARDiff通过联合优化自回归与扩散组件，成功解决了传统混合框架的延迟瓶颈，实现了高速、高质量的图像生成，为未来多模态生成系统提供了高效范式。

Abstract: Autoregressive(AR)-diffusion hybrid paradigms combine AR's structured modeling with diffusion's photorealistic synthesis, yet suffer from high latency due to sequential AR generation and iterative denoising. In this work, we tackle this bottleneck and propose a unified AR-diffusion framework Fast-ARDiff that jointly optimizes both components, accelerating AR speculative decoding while simultaneously facilitating faster diffusion decoding. Specifically: (1) The entropy-informed speculative strategy encourages draft model to produce higher-entropy representations aligned with target model's entropy characteristics, mitigating entropy mismatch and high rejection rates caused by draft overconfidence. (2) For diffusion decoding, rather than treating it as an independent module, we integrate it into the same end-to-end framework using a dynamic scheduler that prioritizes AR optimization to guide the diffusion part in further steps. The diffusion part is optimized through a joint distillation framework combining trajectory and distribution matching, ensuring stable training and high-quality synthesis with extremely few steps. During inference, shallow feature entropy from AR module is used to pre-filter low-entropy drafts, avoiding redundant computation and improving latency. Fast-ARDiff achieves state-of-the-art acceleration across diverse models: on ImageNet 256$\times$256, TransDiff attains 4.3$\times$ lossless speedup, and NextStep-1 achieves 3$\times$ acceleration on text-conditioned generation. Code will be available at https://github.com/aSleepyTree/Fast-ARDiff.

</details>


### [55] [An Iteration-Free Fixed-Point Estimator for Diffusion Inversion](https://arxiv.org/abs/2512.08547)
*Yifei Chen,Kaiyu Song,Yan Pan,Jianxing Yu,Jian Yin,Hanjiang Lai*

Main category: cs.CV

TL;DR: 本文提出了一种无迭代的固定点估计器用于扩散反演，通过推导理想反演步骤下的显式固定点表达式，并引入前一步的可计算误差来近似未知误差，从而得到一个可计算且低方差的无偏估计。在NOCAPS和MS-COCO两个文本-图像数据集上，该方法在无需额外迭代或训练的情况下，实现了优于DDIM反演及其他基于固定点迭代的方法的一致性重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于固定点迭代的扩散反演方法存在计算成本高和超参数选择复杂的问题，亟需一种高效且稳定的替代方案。

Method: 推导理想反演步骤下的固定点表达式，利用前一步的可计算误差近似当前步骤的未知误差，构建一个可计算的近似固定点，作为无偏且低方差的估计器。

Result: 在NOCAPS和MS-COCO数据集上，所提方法在图像重建任务中表现优于DDIM反演及其他固定点迭代方法，且无需额外迭代或训练。

Conclusion: 提出的无迭代固定点估计器有效降低了扩散反演的计算开销，同时保持了高精度与稳定性，为高效图像重建提供了新思路。

Abstract: Diffusion inversion aims to recover the initial noise corresponding to a given image such that this noise can reconstruct the original image through the denoising diffusion process. The key component of diffusion inversion is to minimize errors at each inversion step, thereby mitigating cumulative inaccuracies. Recently, fixed-point iteration has emerged as a widely adopted approach to minimize reconstruction errors at each inversion step. However, it suffers from high computational costs due to its iterative nature and the complexity of hyperparameter selection. To address these issues, we propose an iteration-free fixed-point estimator for diffusion inversion. First, we derive an explicit expression of the fixed point from an ideal inversion step. Unfortunately, it inherently contains an unknown data prediction error. Building upon this, we introduce the error approximation, which uses the calculable error from the previous inversion step to approximate the unknown error at the current inversion step. This yields a calculable, approximate expression for the fixed point, which is an unbiased estimator characterized by low variance, as shown by our theoretical analysis. We evaluate reconstruction performance on two text-image datasets, NOCAPS and MS-COCO. Compared to DDIM inversion and other inversion methods based on the fixed-point iteration, our method achieves consistent and superior performance in reconstruction tasks without additional iterations or training.

</details>


### [56] [SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds](https://arxiv.org/abs/2512.08557)
*Alexander Dow,Manduhu Manduhu,Matheus Santos,Ben Bartlett,Gerard Dooly,James Riordan*

Main category: cs.CV

TL;DR: 该研究利用LiDAR扫描的连续扫动特性，通过短步长滑动时间窗口聚焦于点云数据变化区域，结合时序信息存储卷积结果，实现对未变化区域的忽略，大幅减少每轮前向传播中的卷积操作。提出一种基于稀疏散射卷积并引入时序数据回收的算法SSCATeR，仅处理点云中变化部分，显著提升计算效率，处理速度最高提升6.61倍，同时保持与传统稀疏卷积相当的特征图输出质量。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR点云处理方法在处理连续扫描数据时存在大量冗余计算，尤其在场景无变化区域重复执行卷积操作，导致计算效率低下。为提升实时性与资源利用率，亟需一种能有效识别并跳过静态区域的高效检测机制。

Method: 采用滑动时间窗口结合短步长策略，利用时序数据间的连续性，存储并复用卷积结果；设计Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling (SSCATeR)，将输入点云视为连续流，仅对发生变化的区域进行计算，实现数据重用与稀疏性增强。

Result: 实验表明，SSCATeR在保持与传统稀疏卷积相同特征输出质量的前提下，处理速度最高提升6.61倍，显著降低计算开销，且适用于动态环境下的实时点云目标检测任务。

Conclusion: 通过引入时序数据回收与稀疏散射卷积机制，SSCATeR有效提升了LiDAR点云处理的效率与实时性，为复杂动态场景中的高效感知提供了可行方案。

Abstract: This work leverages the continuous sweeping motion of LiDAR scanning to concentrate object detection efforts on specific regions that receive a change in point data from one frame to another. We achieve this by using a sliding time window with short strides and consider the temporal dimension by storing convolution results between passes. This allows us to ignore unchanged regions, significantly reducing the number of convolution operations per forward pass without sacrificing accuracy. This data reuse scheme introduces extreme sparsity to detection data. To exploit this sparsity, we extend our previous work on scatter-based convolutions to allow for data reuse, and as such propose Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling (SSCATeR). This operation treats incoming LiDAR data as a continuous stream and acts only on the changing parts of the point cloud. By doing so, we achieve the same results with as much as a 6.61-fold reduction in processing time. Our test results show that the feature maps output by our method are identical to those produced by traditional sparse convolution techniques, whilst greatly increasing the computational efficiency of the network.

</details>


### [57] [BrainExplore: Large-Scale Discovery of Interpretable Visual Representations in the Human Brain](https://arxiv.org/abs/2512.08560)
*Navve Wasserman,Matias Cosarinsky,Yuval Golbari,Aude Oliva,Antonio Torralba,Tamar Rott Shaham,Michal Irani*

Main category: cs.CV

TL;DR: 本文提出一个大规模、自动化的框架，用于在人类大脑皮层中发现和解释视觉概念的表征。该方法通过无监督的数据驱动分解发现候选可解释模式，并通过识别最强烈激发这些模式的自然图像及其共享的视觉语义，生成自然语言描述。研究构建了自动化流程，对多种候选解释进行测试，赋予量化可靠性评分，并选择最一致的描述。该框架揭示了数千个跨越多种视觉概念的可解释模式，包括此前未报告的精细表征。


<details>
  <summary>Details</summary>
Motivation: 理解人脑如何表示视觉概念及其在哪些脑区编码仍是一个长期挑战。现有研究多为小规模、依赖人工检查、局限于特定区域和属性，缺乏系统验证。因此需要一种大规模、自动化的方法来发现和解释大脑中的视觉表征。

Method: 采用两阶段方法：第一阶段使用无监督、数据驱动的分解方法从fMRI活动中发现候选可解释模式；第二阶段通过识别最强烈激发这些模式的自然图像，并生成其共享视觉意义的自然语言描述来解释每个模式。引入自动化管道，测试多种候选解释，分配可靠性评分，选择最一致的描述。

Result: 该框架发现了数千个跨越多种视觉概念的可解释模式，涵盖精细的、此前未报告的视觉表征，且具有高一致性与可重复性。

Conclusion: 本研究提供了一种高效、可扩展的大规模自动化框架，显著提升了对人类大脑视觉概念表征的理解，为未来神经科学与认知计算研究提供了新工具。

Abstract: Understanding how the human brain represents visual concepts, and in which brain regions these representations are encoded, remains a long-standing challenge. Decades of work have advanced our understanding of visual representations, yet brain signals remain large and complex, and the space of possible visual concepts is vast. As a result, most studies remain small-scale, rely on manual inspection, focus on specific regions and properties, and rarely include systematic validation. We present a large-scale, automated framework for discovering and explaining visual representations across the human cortex. Our method comprises two main stages. First, we discover candidate interpretable patterns in fMRI activity through unsupervised, data-driven decomposition methods. Next, we explain each pattern by identifying the set of natural images that most strongly elicit it and generating a natural-language description of their shared visual meaning. To scale this process, we introduce an automated pipeline that tests multiple candidate explanations, assigns quantitative reliability scores, and selects the most consistent description for each voxel pattern. Our framework reveals thousands of interpretable patterns spanning many distinct visual concepts, including fine-grained representations previously unreported.

</details>


### [58] [Modular Neural Image Signal Processing](https://arxiv.org/abs/2512.08564)
*Mahmoud Afifi,Zhongling Wang,Ran Zhang,Michael S. Brown*

Main category: cs.CV

TL;DR: 本文提出一种模块化神经图像信号处理（ISP）框架，能够处理原始输入并生成高质量的显示参考图像。该方法通过高度模块化设计，实现对渲染过程多个中间阶段的完全控制，兼具高渲染精度、可扩展性、可调试性、对未见相机的泛化能力以及匹配不同用户偏好的灵活性。作者构建了一个用户交互式照片编辑工具，利用该神经ISP支持多种编辑操作和图片风格，并实现无限次后编辑重渲染。整个框架为全学习型设计，具有不同容量变体，参数量适中（0.5M至3.9M），在多个测试集上均表现出色的定性和定量结果。


<details>
  <summary>Details</summary>
Motivation: 传统神经ISP设计缺乏对中间渲染阶段的灵活控制，难以适应多样化的用户偏好、设备泛化及后期编辑需求。为解决这些问题，亟需一种模块化、可调控且高效的学习型ISP框架。

Method: 提出一种模块化神经图像信号处理框架，将渲染流程分解为多个可独立优化的模块，每个模块负责特定的图像处理任务（如去马赛克、白平衡、色彩校正等），并通过端到端训练实现整体性能优化。同时，引入可插拔设计以支持用户自定义处理流程与风格迁移。

Result: 在多个公开数据集上，该框架在主观视觉质量与客观指标（如PSNR、SSIM）方面均达到或超过现有方法；用户交互式工具验证了其在多样化编辑场景下的实用性与灵活性；模型参数量小，具备良好的部署潜力。

Conclusion: 模块化神经ISP框架显著提升了图像渲染的可控性、可扩展性与应用灵活性，为高质量图像生成与交互式编辑提供了强大支持，是未来智能成像系统的重要发展方向。

Abstract: This paper presents a modular neural image signal processing (ISP) framework that processes raw inputs and renders high-quality display-referred images. Unlike prior neural ISP designs, our method introduces a high degree of modularity, providing full control over multiple intermediate stages of the rendering process.~This modular design not only achieves high rendering accuracy but also improves scalability, debuggability, generalization to unseen cameras, and flexibility to match different user-preference styles. To demonstrate the advantages of this design, we built a user-interactive photo-editing tool that leverages our neural ISP to support diverse editing operations and picture styles. The tool is carefully engineered to take advantage of the high-quality rendering of our neural ISP and to enable unlimited post-editable re-rendering. Our method is a fully learning-based framework with variants of different capacities, all of moderate size (ranging from ~0.5 M to ~3.9 M parameters for the entire pipeline), and consistently delivers competitive qualitative and quantitative results across multiple test sets. Watch the supplemental video at: https://youtu.be/ByhQjQSjxVM

</details>


### [59] [Instance-Aware Test-Time Segmentation for Continual Domain Shifts](https://arxiv.org/abs/2512.08569)
*Seunghwan Lee,Inyoung Jung,Hojoon Lee,Eunil Park,Sungeun Hong*

Main category: cs.CV

TL;DR: 本文提出一种自适应的持续测试时适应（CTTA）方法，用于解决语义分割中因领域变化导致的模型性能下降问题。传统方法依赖固定或批量阈值，难以应对不同类别和实例间的差异性挑战。新方法通过动态调整伪标签以反映图像内部置信度分布，并在学习过程中优先关注受领域偏移影响最严重的类别，实现细粒度、类与实例感知的适应。该方法有效提升监督信号可靠性，减少误差累积。在八个不同场景下（包括合成到真实及长期域漂移）的实验表明，所提方法显著优于现有SOTA技术，为持续演化环境下的语义分割树立了新标准。


<details>
  <summary>Details</summary>
Motivation: 现有持续测试时适应（CTTA）方法在处理语义分割任务时，受限于固定的或批处理级别的置信度阈值，无法充分考虑不同类别和实例间的变化难度差异，导致适应效果不佳，尤其在需要密集多类预测的场景中问题更为突出。因此亟需一种更精细、更具适应性的策略来提升模型鲁棒性和泛化能力。

Method: 提出一种基于图像内置信度分布自适应调整伪标签的方法，结合动态权重机制平衡不同类别在学习过程中的重要性，使模型能够聚焦于受领域偏移影响最严重的类别，从而实现细粒度、类与实例感知的持续适应。

Result: 在八种不同的持续测试时适应（CTTA）和测试时适应（TTA）场景下，包括合成到真实转换和长期域漂移，所提方法均显著优于现有最先进方法，在多个指标上取得领先表现，验证了其有效性与稳定性。

Conclusion: 本研究提出的自适应持续测试时适应方法，通过引入图像级置信度感知与动态类别平衡机制，有效解决了传统方法在语义分割中因固定阈值导致的适应偏差与误差累积问题，为持续演化环境下模型的可靠适应提供了新范式，具有广泛的应用前景。

Abstract: Continual Test-Time Adaptation (CTTA) enables pre-trained models to adapt to continuously evolving domains. Existing methods have improved robustness but typically rely on fixed or batch-level thresholds, which cannot account for varying difficulty across classes and instances. This limitation is especially problematic in semantic segmentation, where each image requires dense, multi-class predictions. We propose an approach that adaptively adjusts pseudo labels to reflect the confidence distribution within each image and dynamically balances learning toward classes most affected by domain shifts. This fine-grained, class- and instance-aware adaptation produces more reliable supervision and mitigates error accumulation throughout continual adaptation. Extensive experiments across eight CTTA and TTA scenarios, including synthetic-to-real and long-term shifts, show that our method consistently outperforms state-of-the-art techniques, setting a new standard for semantic segmentation under evolving conditions.

</details>


### [60] [Disturbance-Free Surgical Video Generation from Multi-Camera Shadowless Lamps for Open Surgery](https://arxiv.org/abs/2512.08577)
*Yuna Kato,Shohei Mori,Hideo Saito,Yoshifumi Takatsume,Hiroki Kajita,Mariko Isogawa*

Main category: cs.CV

TL;DR: 本文提出了一种全自动的多摄像头视频对齐方法，用于解决手术录像中因医生遮挡导致的视角问题。通过识别照明系统移动的帧并重新对齐，选择遮挡最少的相机生成固定视角的视频，显著提升了视频质量和观看舒适度。用户研究表明，该方法优于传统方法，且在多种合成选项中获得了外科医生的偏好。


<details>
  <summary>Details</summary>
Motivation: 手术录像在教育和研究中至关重要，但医生频繁遮挡摄像头导致视频获取困难，传统多摄像头方案需手动对齐，劳动强度大，亟需自动化解决方案。

Method: 通过检测照明系统移动的帧，自动重对齐多摄像头视频，并选择遮挡最少的视角生成固定视角的合成视频，支持多种合成选项以优化视觉效果。

Result: 用户研究表明，该方法生成的视频在确认手术区域的便捷性和观看舒适度方面优于传统方法，且视频质量更高；多种合成选项也获得外科医生认可。

Conclusion: 本方法实现了多摄像头手术视频的全自动对齐与视图合成，有效解决了遮挡问题，显著提升了视频可用性与用户体验，具有重要的临床应用价值。

Abstract: Video recordings of open surgeries are greatly required for education and research purposes. However, capturing unobstructed videos is challenging since surgeons frequently block the camera field of view. To avoid occlusion, the positions and angles of the camera must be frequently adjusted, which is highly labor-intensive. Prior work has addressed this issue by installing multiple cameras on a shadowless lamp and arranging them to fully surround the surgical area. This setup increases the chances of some cameras capturing an unobstructed view. However, manual image alignment is needed in post-processing since camera configurations change every time surgeons move the lamp for optimal lighting. This paper aims to fully automate this alignment task. The proposed method identifies frames in which the lighting system moves, realigns them, and selects the camera with the least occlusion to generate a video that consistently presents the surgical field from a fixed perspective. A user study involving surgeons demonstrated that videos generated by our method were superior to those produced by conventional methods in terms of the ease of confirming the surgical area and the comfort during video viewing. Additionally, our approach showed improvements in video quality over existing techniques. Furthermore, we implemented several synthesis options for the proposed view-synthesis method and conducted a user study to assess surgeons' preferences for each option.

</details>


### [61] [Automated Pollen Recognition in Optical and Holographic Microscopy Images](https://arxiv.org/abs/2512.08589)
*Swarn Singh Warshaneyan,Maksims Ivanovs,Blaž Cugmas,Inese Bērziņa,Laura Goldberga,Mindaugas Tamosiunas,Roberts Kadiķis*

Main category: cs.CV

TL;DR: 本研究探讨了深度学习在光学和全息显微镜图像中自动检测与分类花粉颗粒的应用，重点针对兽医细胞学场景。采用YOLOv8s进行目标检测，MobileNetV3L进行分类，在光学图像上分别达到91.3% mAP50和97%总体准确率；而初始全息图像表现较差。通过自动化标注和边界框区域扩大进行数据集扩展，显著提升了全息图像的性能（检测从2.49%提升至13.3% mAP50，分类从42%提升至54%）。研究表明，结合低成本无透镜数字全息显微设备，深度学习可用于图像分类任务。


<details>
  <summary>Details</summary>
Motivation: 提高花粉颗粒在光学与全息显微图像中的自动检测与分类效率，尤其适用于兽医细胞学领域，以降低人工分析成本并提升准确性。

Method: 使用YOLOv8s进行对象检测，MobileNetV3L用于分类任务；针对全息图像性能不足问题，引入自动化标注与边界框面积扩大进行数据集扩展。

Result: 在光学图像上检测mAP50为91.3%，分类准确率达97%；经数据增强后，全息图像检测mAP50由2.49%提升至13.3%，分类准确率由42%提升至54%。

Conclusion: 深度学习可有效应用于低成本无透镜数字全息显微图像的花粉分类任务，具备实际应用潜力。

Abstract: This study explores the application of deep learning to improve and automate pollen grain detection and classification in both optical and holographic microscopy images, with a particular focus on veterinary cytology use cases. We used YOLOv8s for object detection and MobileNetV3L for the classification task, evaluating their performance across imaging modalities. The models achieved 91.3% mAP50 for detection and 97% overall accuracy for classification on optical images, whereas the initial performance on greyscale holographic images was substantially lower. We addressed the performance gap issue through dataset expansion using automated labeling and bounding box area enlargement. These techniques, applied to holographic images, improved detection performance from 2.49% to 13.3% mAP50 and classification performance from 42% to 54%. Our work demonstrates that, at least for image classification tasks, it is possible to pair deep learning techniques with cost-effective lensless digital holographic microscopy devices.

</details>


### [62] [Decoupling Template Bias in CLIP: Harnessing Empty Prompts for Enhanced Few-Shot Learning](https://arxiv.org/abs/2512.08606)
*Zhenyu Zhang,Guangyao Chen,Yixiong Zou,Zhimeng Huang,Yuhua Li*

Main category: cs.CV

TL;DR: 本文研究CLIP模型在少样本学习中因文本模板与图像样本相似性（TSS）引入的偏差问题，提出使用空提示（empty prompts）来消除这种偏差。通过两阶段框架：预训练阶段利用空提示揭示并减少模板偏差，微调阶段引入偏差校准损失确保图像与类别正确对齐，从而提升分类准确率和鲁棒性。实验表明该方法有效降低由TSS引起的性能波动。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在少样本学习中依赖文本模板与图像样本的相似性（TSS），导致模型偏向模板匹配而非真实类别对齐，影响分类准确性和鲁棒性，因此需要消除此类偏差。

Method: 提出基于空提示的两阶段框架：1）预训练阶段使用空提示挖掘并减少模板诱导的偏差；2）微调阶段引入偏差校准损失，强制模型关注正确的视觉语义对齐。

Result: 在多个基准测试上，该方法显著降低了由模板-样本相似性（TSS）引起的性能波动，提升了分类准确率和模型鲁棒性。

Conclusion: 通过引入空提示和偏差校准机制，可有效解耦模板偏差，使CLIP模型在少样本学习中更关注真实的视觉-语义对齐，从而实现更高精度和更强鲁棒性的分类表现。

Abstract: The Contrastive Language-Image Pre-Training (CLIP) model excels in few-shot learning by aligning visual and textual representations. Our study shows that template-sample similarity (TSS), defined as the resemblance between a text template and an image sample, introduces bias. This bias leads the model to rely on template proximity rather than true sample-to-category alignment, reducing both accuracy and robustness in classification. We present a framework that uses empty prompts, textual inputs that convey the idea of "emptiness" without category information. These prompts capture unbiased template features and offset TSS bias. The framework employs two stages. During pre-training, empty prompts reveal and reduce template-induced bias within the CLIP encoder. During few-shot fine-tuning, a bias calibration loss enforces correct alignment between images and their categories, ensuring the model focuses on relevant visual cues. Experiments across multiple benchmarks demonstrate that our template correction method significantly reduces performance fluctuations caused by TSS, yielding higher classification accuracy and stronger robustness. The repository of this project is available at https://github.com/zhenyuZ-HUST/Decoupling-Template-Bias-in-CLIP.

</details>


### [63] [OpenMonoGS-SLAM: Monocular Gaussian Splatting SLAM with Open-set Semantics](https://arxiv.org/abs/2512.08625)
*Jisang Yoo,Gyeongjin Kang,Hyun-kyu Ko,Hyeonwoo Yu,Eunbyung Park*

Main category: cs.CV

TL;DR: OpenMonoGS-SLAM是首个将3D高斯点云与开放集语义理解结合的单目SLAM框架，利用视觉基础模型（如MASt3R、SAM、CLIP）实现无深度输入下的精准跟踪与映射，并通过自监督学习和专为高维语义特征设计的记忆机制，构建高效的语义高斯图，在封闭与开放世界场景中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有SLAM系统多依赖深度传感器或封闭集语义模型，难以适应开放世界环境中的动态变化与未知物体识别，因此亟需一种无需额外传感器、具备强泛化能力的语义化单目SLAM方法。

Method: 融合视觉基础模型（MASt3R用于几何重建，SAM与CLIP用于开放词汇语义理解），基于自监督学习目标进行单目跟踪与建图；提出专用记忆机制以管理高维语义特征，构建语义高斯特征图。

Result: 在封闭集与开放集分割任务上均达到或超越现有基线性能，且不依赖深度图或语义标注等外部信息。

Conclusion: OpenMonoGS-SLAM成功实现了无需深度输入与语义真值的单目语义SLAM，具备良好的开放世界适应性与实用性，为智能感知系统提供了新范式。

Abstract: Simultaneous Localization and Mapping (SLAM) is a foundational component in robotics, AR/VR, and autonomous systems. With the rising focus on spatial AI in recent years, combining SLAM with semantic understanding has become increasingly important for enabling intelligent perception and interaction. Recent efforts have explored this integration, but they often rely on depth sensors or closed-set semantic models, limiting their scalability and adaptability in open-world environments. In this work, we present OpenMonoGS-SLAM, the first monocular SLAM framework that unifies 3D Gaussian Splatting (3DGS) with open-set semantic understanding. To achieve our goal, we leverage recent advances in Visual Foundation Models (VFMs), including MASt3R for visual geometry and SAM and CLIP for open-vocabulary semantics. These models provide robust generalization across diverse tasks, enabling accurate monocular camera tracking and mapping, as well as a rich understanding of semantics in open-world environments. Our method operates without any depth input or 3D semantic ground truth, relying solely on self-supervised learning objectives. Furthermore, we propose a memory mechanism specifically designed to manage high-dimensional semantic features, which effectively constructs Gaussian semantic feature maps, leading to strong overall performance. Experimental results demonstrate that our approach achieves performance comparable to or surpassing existing baselines in both closed-set and open-set segmentation tasks, all without relying on supplementary sensors such as depth maps or semantic annotations.

</details>


### [64] [Trajectory Densification and Depth from Perspective-based Blur](https://arxiv.org/abs/2512.08627)
*Tianchen Qiu,Qirun Zhang,Jiajian He,Zhengyue Zhuge,Jiahui Xu,Yueting Chen*

Main category: cs.CV

TL;DR: 本文提出一种新颖方法，通过分析视频流中的模糊模式和密集轨迹，结合光学设计算法来估计度量深度。利用现成的视觉编码器和点追踪器提取视频信息，通过窗口嵌入和多窗口聚合估计深度图，并使用视觉-语言模型对稀疏轨迹进行稠密化。在多个深度数据集上的评估表明，该方法在大范围深度上表现优异，且具有良好的泛化能力。相较于手持拍摄设置下的真实轨迹，所提光学算法精度更高，稠密重建保持强准确性。


<details>
  <summary>Details</summary>
Motivation: 在无机械稳定器的情况下，相机在拍摄过程中不可避免地发生旋转运动，尤其在长曝光场景下会引发基于视角的模糊。这种模糊与物体的空间位置相关，不同位置的物体即使在相同成像条件下也会有不同的模糊程度，因此需要一种能够利用模糊模式估计深度的方法。

Method: 采用现成的视觉编码器和点追踪器提取视频信息；通过窗口嵌入和多窗口聚合估计深度图；利用视觉-语言模型对光学算法生成的稀疏轨迹进行稠密化处理。

Result: 在多个深度数据集上表现出色，覆盖大深度范围，具备良好泛化能力；相比真实轨迹，光学算法精度更高，稠密重建保持高准确性。

Conclusion: 本文提出的基于模糊模式与轨迹联合分析的方法，在无外部稳定装置的条件下，有效实现了高精度、广范围的深度估计与稠密重建，适用于手持拍摄等复杂动态场景。

Abstract: In the absence of a mechanical stabilizer, the camera undergoes inevitable rotational dynamics during capturing, which induces perspective-based blur especially under long-exposure scenarios. From an optical standpoint, perspective-based blur is depth-position-dependent: objects residing at distinct spatial locations incur different blur levels even under the same imaging settings. Inspired by this, we propose a novel method that estimate metric depth by examining the blur pattern of a video stream and dense trajectory via joint optical design algorithm. Specifically, we employ off-the-shelf vision encoder and point tracker to extract video information. Then, we estimate depth map via windowed embedding and multi-window aggregation, and densify the sparse trajectory from the optical algorithm using a vision-language model. Evaluations on multiple depth datasets demonstrate that our method attains strong performance over large depth range, while maintaining favorable generalization. Relative to the real trajectory in handheld shooting settings, our optical algorithm achieves superior precision and the dense reconstruction maintains strong accuracy.

</details>


### [65] [Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning](https://arxiv.org/abs/2512.08639)
*Huilin Xu,Zhuoyang Liu,Yixiang Luomei,Feng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种仅依赖单目RGB图像和自然语言指令的统一空中视觉-语言导航框架，将导航任务建模为下一步标记预测问题，通过提示引导的多任务学习联合优化空间感知、轨迹推理和动作预测。引入关键帧选择策略减少视觉冗余，并采用动作合并与标签重加权机制缓解长尾监督不平衡问题，实现在单目RGB-only设置下的优异性能，显著超越现有基线并缩小与全景RGB-D方法的差距。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖全景图像、深度信息或里程计，增加了系统成本和集成复杂性，不利于轻量级无人机的实际部署。因此需要一种仅基于单目RGB图像的高效导航框架。

Method: 将导航建模为下一个标记预测问题，采用提示引导的多任务学习联合优化空间感知、轨迹推理与动作预测；设计关键帧选择策略降低视觉冗余，结合动作合并与标签重加权机制解决长尾分布问题，支持稳定多任务协同训练。

Result: 在Aerial VLN基准上实验验证了方法的有效性，在单目RGB-only设置下，模型在已见和未见环境中均表现优异，显著优于现有RGB-only基线，大幅缩小与先进全景RGB-D方法的性能差距。

Conclusion: 所提方法实现了仅用单目RGB图像和自然语言指令完成高效空中视觉-语言导航，具备更强的实用性与部署潜力，为轻量化无人机应用提供了可行方案。

Abstract: Aerial Vision-and-Language Navigation (VLN) aims to enable unmanned aerial vehicles (UAVs) to interpret natural language instructions and navigate complex urban environments using onboard visual observation. This task holds promise for real-world applications such as low-altitude inspection, search-and-rescue, and autonomous aerial delivery. Existing methods often rely on panoramic images, depth inputs, or odometry to support spatial reasoning and action planning. These requirements increase system cost and integration complexity, thus hindering practical deployment for lightweight UAVs. We present a unified aerial VLN framework that operates solely on egocentric monocular RGB observations and natural language instructions. The model formulates navigation as a next-token prediction problem, jointly optimizing spatial perception, trajectory reasoning, and action prediction through prompt-guided multi-task learning. Moreover, we propose a keyframe selection strategy to reduce visual redundancy by retaining semantically informative frames, along with an action merging and label reweighting mechanism that mitigates long-tailed supervision imbalance and facilitates stable multi-task co-training. Extensive experiments on the Aerial VLN benchmark validate the effectiveness of our method. Under the challenging monocular RGB-only setting, our model achieves strong results across both seen and unseen environments. It significantly outperforms existing RGB-only baselines and narrows the performance gap with state-of-the-art panoramic RGB-D counterparts. Comprehensive ablation studies further demonstrate the contribution of our task design and architectural choices.

</details>


### [66] [Chain-of-Image Generation: Toward Monitorable and Controllable Image Generation](https://arxiv.org/abs/2512.08645)
*Young Kyung Kim,Oded Schlesinger,Yuzhou Zhao,J. Matias Di Martino,Guillermo Sapiro*

Main category: cs.CV

TL;DR: 提出Chain-of-Image Generation（CoIG）框架，将图像生成过程重构为类人类的、分步的语义序列，通过LLM分解复杂提示并逐步生成与编辑图像，提升可监控性与可解释性。引入两项新指标：CoIG可读性（评估中间步骤清晰度）和因果相关性（量化每一步对最终图像的影响）。实验表明，CoIG显著增强可监控性，同时保持与基线模型相当的组合鲁棒性，且不依赖特定生成模型，具备通用性。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型虽然视觉质量高，但其内部生成过程如同黑箱，难以被人类观察和干预，影响模型可靠性、安全性和可控性；同时非人类式的生成流程也降低了可解释性。因此需要一种更透明、可追踪的生成机制。

Method: 使用大语言模型（LLM）将复杂文本提示分解为一系列简单、逐步的指令；图像生成模型依据该计划逐步生成或编辑图像，每一步聚焦单一语义实体；通过两个新指标——CoIG可读性与因果相关性，定量评估中间步骤的清晰度与影响力。

Result: CoIG显著提升了图像生成过程的可监控性与可解释性，有效缓解了实体丢失问题，实现了与现有先进模型相媲美的组合鲁棒性，且可适配任意图像生成模型，具有良好的通用性。

Conclusion: CoIG框架成功将图像生成转变为类似人类创作的可解释、可干预的序列化过程，为提升生成模型的透明度与可控性提供了有效路径。

Abstract: While state-of-the-art image generation models achieve remarkable visual quality, their internal generative processes remain a "black box." This opacity limits human observation and intervention, and poses a barrier to ensuring model reliability, safety, and control. Furthermore, their non-human-like workflows make them difficult for human observers to interpret. To address this, we introduce the Chain-of-Image Generation (CoIG) framework, which reframes image generation as a sequential, semantic process analogous to how humans create art. Similar to the advantages in monitorability and performance that Chain-of-Thought (CoT) brought to large language models (LLMs), CoIG can produce equivalent benefits in text-to-image generation. CoIG utilizes an LLM to decompose a complex prompt into a sequence of simple, step-by-step instructions. The image generation model then executes this plan by progressively generating and editing the image. Each step focuses on a single semantic entity, enabling direct monitoring. We formally assess this property using two novel metrics: CoIG Readability, which evaluates the clarity of each intermediate step via its corresponding output; and Causal Relevance, which quantifies the impact of each procedural step on the final generated image. We further show that our framework mitigates entity collapse by decomposing the complex generation task into simple subproblems, analogous to the procedural reasoning employed by CoT. Our experimental results indicate that CoIG substantially enhances quantitative monitorability while achieving competitive compositional robustness compared to established baseline models. The framework is model-agnostic and can be integrated with any image generation model.

</details>


### [67] [C-DIRA: Computationally Efficient Dynamic ROI Routing and Domain-Invariant Adversarial Learning for Lightweight Driver Behavior Recognition](https://arxiv.org/abs/2512.08647)
*Keito Inoshita*

Main category: cs.CV

TL;DR: 提出C-DIRA框架，结合显著性驱动的Top-K ROI池化与融合分类，实现轻量级驾驶员行为识别。通过动态ROI路由选择性计算高难度样本，利用伪域标签和对抗学习提升域不变特征，有效平衡效率与准确性，在保持低计算开销的同时增强模型鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级模型难以捕捉细微行为线索，导致在未见驾驶员或不同条件下的性能下降；基于ROI的方法虽提升精度但增加计算负担，难以兼顾效率与准确率。因此亟需一种高效且具备强泛化能力的轻量级架构。

Method: 采用显著性驱动的Top-K区域感兴趣（ROI）池化进行局部特征提取与融合分类；引入动态ROI路由机制，仅对高难度样本执行ROI推理以节省计算资源；结合伪域标签与对抗学习策略，学习对驾驶员及背景变化具有鲁棒性的域不变特征。

Result: 在State Farm Distracted Driver Detection数据集上，C-DIRA相比已有轻量级模型显著降低浮点运算量（FLOPs）和延迟，同时保持高准确率；在模糊、低光照等视觉退化条件下表现稳定，跨未见领域性能一致，验证了其紧凑性、高效性与泛化能力。

Conclusion: C-DIRA成功实现了轻量化、高效率与强泛化之间的平衡，适用于边缘设备上的实时驾驶员分心行为识别任务，为实际部署提供了可行方案。

Abstract: Driver distraction behavior recognition using in-vehicle cameras demands real-time inference on edge devices. However, lightweight models often fail to capture fine-grained behavioral cues, resulting in reduced performance on unseen drivers or under varying conditions. ROI-based methods also increase computational cost, making it difficult to balance efficiency and accuracy. This work addresses the need for a lightweight architecture that overcomes these constraints. We propose Computationally efficient Dynamic region of Interest Routing and domain-invariant Adversarial learning for lightweight driver behavior recognition (C-DIRA). The framework combines saliency-driven Top-K ROI pooling and fused classification for local feature extraction and integration. Dynamic ROI routing enables selective computation by applying ROI inference only to high difficulty data samples. Moreover, pseudo-domain labeling and adversarial learning are used to learn domain-invariant features robust to driver and background variation. Experiments on the State Farm Distracted Driver Detection Dataset show that C-DIRA maintains high accuracy with significantly fewer FLOPs and lower latency than prior lightweight models. It also demonstrates robustness under visual degradation such as blur and low-light, and stable performance across unseen domains. These results confirm C-DIRA's effectiveness in achieving compactness, efficiency, and generalization.

</details>


### [68] [Mitigating Individual Skin Tone Bias in Skin Lesion Classification through Distribution-Aware Reweighting](https://arxiv.org/abs/2512.08733)
*Kuniko Paxton,Zeinab Dehghani,Koorosh Aslansefat,Dhavalkumar Thakker,Yiannis Papadopoulos*

Main category: cs.CV

TL;DR: 该研究提出一种基于分布的框架，用于评估和缓解皮肤病变分类中的个体公平性问题。通过将肤色视为连续属性而非类别标签，并使用核密度估计（KDE）建模其分布，结合多种统计距离度量，提出一种基于距离的重加权（DRW）损失函数，以纠正少数肤色在数据中的代表性不足问题。实验表明，相较于传统的分类重加权方法，分布基重加权在捕捉个体层面偏差方面表现更优，尤其在使用Fidelity Similarity、Wasserstein Distance、Hellinger Metric和Harmonic Mean Similarity时效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习公平性研究常依赖粗粒度的子群分类，忽略了肤色等敏感属性的个体差异，导致少数群体内部的边缘化个体被忽视。本研究旨在解决这一问题，提升医学影像中个体层面的公平性。

Method: 将肤色视为连续变量，采用核密度估计（KDE）建模其分布；比较12种统计距离度量来量化不同肤色分布间的差异；设计基于距离的重加权（DRW）损失函数，以缓解少数肤色样本的欠代表问题。

Result: 实验结果显示，分类重加权方法难以有效捕捉个体层面的不公平现象；而分布基重加权方法，特别是结合Fidelity Similarity、Wasserstein Distance、Hellinger Metric和Harmonic Mean Similarity的策略，在CNN与Transformer模型上均表现出更优的公平性改善效果。

Conclusion: 该研究建立了一套有效的个体公平性评估与缓解方法，为皮肤病学人工智能系统中的公平性提升提供了新范式，并对医疗图像分析中其他敏感连续属性的公平性研究具有广泛启示意义。

Abstract: Skin color has historically been a focal point of discrimination, yet fairness research in machine learning for medical imaging often relies on coarse subgroup categories, overlooking individual-level variations. Such group-based approaches risk obscuring biases faced by outliers within subgroups. This study introduces a distribution-based framework for evaluating and mitigating individual fairness in skin lesion classification. We treat skin tone as a continuous attribute rather than a categorical label, and employ kernel density estimation (KDE) to model its distribution. We further compare twelve statistical distance metrics to quantify disparities between skin tone distributions and propose a distance-based reweighting (DRW) loss function to correct underrepresentation in minority tones. Experiments across CNN and Transformer models demonstrate: (i) the limitations of categorical reweighting in capturing individual-level disparities, and (ii) the superior performance of distribution-based reweighting, particularly with Fidelity Similarity (FS), Wasserstein Distance (WD), Hellinger Metric (HM), and Harmonic Mean Similarity (HS). These findings establish a robust methodology for advancing fairness at individual level in dermatological AI systems, and highlight broader implications for sensitive continuous attributes in medical image analysis.

</details>


### [69] [Repulsor: Accelerating Generative Modeling with a Contrastive Memory Bank](https://arxiv.org/abs/2512.08648)
*Shaofeng Zhang,Xuanqi Chen,Ning Liao,Haoxiang Zhao,Xiaoxing Wang,Haoru Tan,Sitong Wu,Xiaosong Jia,Qi Fan,Junchi Yan*

Main category: cs.CV

TL;DR: 提出一种无需外部编码器的plug-and-play训练框架{\mname}，通过内存队列动态维护大量负样本，实现高效对比学习，显著提升生成质量并加速收敛。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成模型依赖预训练编码器带来的计算开销和领域偏移问题，同时提升表示学习效率。

Method: 引入记忆库机制，动态维护大量负样本，并结合低维投影头降低内存与带宽开销，实现无额外参数的对比学习。

Result: 在ImageNet-256上仅用40万步即达到2.40的FID，优于现有方法，且训练更快、推理无额外开销。

Conclusion: {\\mname}是一种自洽、高效且高性能的生成模型训练框架，无需外部编码器，可实现快速收敛与卓越生成质量。

Abstract: The dominance of denoising generative models (e.g., diffusion, flow-matching) in visual synthesis is tempered by their substantial training costs and inefficiencies in representation learning. While injecting discriminative representations via auxiliary alignment has proven effective, this approach still faces key limitations: the reliance on external, pre-trained encoders introduces overhead and domain shift. A dispersed-based strategy that encourages strong separation among in-batch latent representations alleviates this specific dependency. To assess the effect of the number of negative samples in generative modeling, we propose {\mname}, a plug-and-play training framework that requires no external encoders. Our method integrates a memory bank mechanism that maintains a large, dynamically updated queue of negative samples across training iterations. This decouples the number of negatives from the mini-batch size, providing abundant and high-quality negatives for a contrastive objective without a multiplicative increase in computational cost. A low-dimensional projection head is used to further minimize memory and bandwidth overhead. {\mname} offers three principal advantages: (1) it is self-contained, eliminating dependency on pretrained vision foundation models and their associated forward-pass overhead; (2) it introduces no additional parameters or computational cost during inference; and (3) it enables substantially faster convergence, achieving superior generative quality more efficiently. On ImageNet-256, {\mname} achieves a state-of-the-art FID of \textbf{2.40} within 400k steps, significantly outperforming comparable methods.

</details>


### [70] [Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps](https://arxiv.org/abs/2512.08774)
*Seoyeon Lee,Gwangyeol Yu,Chaewon Kim,Jonghyuk Park*

Main category: cs.CV

TL;DR: 提出自修正扩散框架，利用可解释人工智能（XAI）生成缺陷激活图（FAMs），识别图像中的伪影和不真实区域，并在正向和反向过程中分别增强噪声和聚焦修复，显著提升图像生成质量，实现高达27.3%的弗雷谢入学距离（FID）改善，在多种任务中表现稳健。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在图像合成中常见的伪影和不真实区域问题，提升生成图像的真实性和质量。

Method: 采用基于XAI的缺陷高亮器生成缺陷激活图（FAMs），在前向过程中放大缺陷区域的噪声，在反向过程中聚焦于这些区域进行修复，从而提高重建质量。

Result: 在多个扩散模型和数据集上实现最高达27.3%的FID改进，且在图像生成、文生图、图像修复等任务中均表现出色。

Conclusion: 可解释人工智能技术不仅能用于模型解释，还能主动参与图像精炼过程，所提框架具有通用性与高效性，显著推动了图像合成领域的发展。

Abstract: Diffusion models have achieved remarkable success in image synthesis. However, addressing artifacts and unrealistic regions remains a critical challenge. We propose self-refining diffusion, a novel framework that enhances image generation quality by detecting these flaws. The framework employs an explainable artificial intelligence (XAI)-based flaw highlighter to produce flaw activation maps (FAMs) that identify artifacts and unrealistic regions. These FAMs improve reconstruction quality by amplifying noise in flawed regions during the forward process and by focusing on these regions during the reverse process. The proposed approach achieves up to a 27.3% improvement in Fréchet inception distance across various diffusion-based models, demonstrating consistently strong performance on diverse datasets. It also shows robust effectiveness across different tasks, including image generation, text-to-image generation, and inpainting. These results demonstrate that explainable AI techniques can extend beyond interpretability to actively contribute to image refinement. The proposed framework offers a versatile and effective approach applicable to various diffusion models and tasks, significantly advancing the field of image synthesis.

</details>


### [71] [What really matters for person re-identification? A Mixture-of-Experts Framework for Semantic Attribute Importance](https://arxiv.org/abs/2512.08697)
*Athena Psalta,Vasileios Tsironis,Konstantinos Karantzalos*

Main category: cs.CV

TL;DR: MoSAIC-ReID 是一种基于专家混合（Mixture-of-Experts）的可解释行人重识别框架，利用LoRA专家与智能路由机制，系统量化行人属性在ReID中的重要性。尽管其性能与现有方法相当，但核心贡献在于大规模、定量地分析了内在与外在属性的重要性，发现衣物颜色和内在特征影响显著，而稀有属性（如配饰）作用有限。该研究为可解释ReID提供了新范式，并强调了显式语义知识集成的实际需求。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的行人重识别方法虽然准确率高，但缺乏可解释性，不清楚模型依赖哪些高层语义属性。亟需一种系统方法来量化属性对识别结果的影响，以提升模型透明度并指导实际应用中语义知识的融合。

Method: 提出MoSAIC-ReID框架，采用基于LoRA的属性专家模块，每个专家对应一个特定属性；通过一个‘预言家’路由器实现属性的可控分配与分析。结合广义线性模型、统计检验与特征重要性分析，评估各属性对ReID性能的贡献程度。

Result: 实验表明，衣物颜色、体型等内在特征是主要判别因素，而配件等罕见属性贡献较小。该框架在Market-1501和DukeMTMC上达到竞争性性能，同时提供了详实的属性重要性量化结果。

Conclusion: MoSAIC-ReID不仅实现了高性能的行人重识别，更提供了一种可解释性分析工具，揭示了关键属性的作用机制，为未来融合显式语义信息的可解释模型设计提供了理论支持与实践路径。

Abstract: State-of-the-art person re-identification methods achieve impressive accuracy but remain largely opaque, leaving open the question: which high-level semantic attributes do these models actually rely on? We propose MoSAIC-ReID, a Mixture-of-Experts framework that systematically quantifies the importance of pedestrian attributes for re-identification. Our approach uses LoRA-based experts, each linked to a single attribute, and an oracle router that enables controlled attribution analysis. While MoSAIC-ReID achieves competitive performance on Market-1501 and DukeMTMC under the assumption that attribute annotations are available at test time, its primary value lies in providing a large-scale, quantitative study of attribute importance across intrinsic and extrinsic cues. Using generalized linear models, statistical tests, and feature-importance analyses, we reveal which attributes, such as clothing colors and intrinsic characteristics, contribute most strongly, while infrequent cues (e.g. accessories) have limited effect. This work offers a principled framework for interpretable ReID and highlights the requirements for integrating explicit semantic knowledge in practice. Code is available at https://github.com/psaltaath/MoSAIC-ReID

</details>


### [72] [MatteViT: High-Frequency-Aware Document Shadow Removal with Shadow Matte Guidance](https://arxiv.org/abs/2512.08789)
*Chaewon Kim,Seoyeon Lee,Jonghyuk Park*

Main category: cs.CV

TL;DR: 提出一种名为MatteViT的新型去阴影框架，结合空间和频域信息，在去除阴影的同时保留细粒度结构细节。通过轻量级高频增强模块（HFAM）自适应放大高频成分，并利用基于亮度的连续阴影蒙版提供早期精确的空间指导。在公开数据集RDD和Kligler上的实验表明，MatteViT达到当前最优性能，且在光学字符识别等下游任务中显著提升文本细节保真度和识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有文档去阴影方法在去除阴影时容易损失文本边缘、线条等高频率细节，影响后续识别任务效果。因此需要一种能有效保留细粒度结构信息的去阴影方法。

Method: 提出MatteViT框架，包含两个核心策略：1）轻量级高频增强模块（HFAM），用于分解并自适应放大高频成分；2）基于自建蒙版数据集和生成器构建的连续亮度引导阴影蒙版，提供从初始阶段开始的精确空间指引。

Result: 在RDD和Kligler等公开基准上实现最先进的去阴影性能，显著优于已有方法。同时在光学字符识别等下游任务中表现出更强的文本细节保持能力，提升了识别准确率。

Conclusion: MatteViT是一种高效且实用的文档去阴影方法，能够精准去除阴影并最大限度保留文本细节，适用于真实场景中的文档图像处理。

Abstract: Document shadow removal is essential for enhancing the clarity of digitized documents. Preserving high-frequency details (e.g., text edges and lines) is critical in this process because shadows often obscure or distort fine structures. This paper proposes a matte vision transformer (MatteViT), a novel shadow removal framework that applies spatial and frequency-domain information to eliminate shadows while preserving fine-grained structural details. To effectively retain these details, we employ two preservation strategies. First, our method introduces a lightweight high-frequency amplification module (HFAM) that decomposes and adaptively amplifies high-frequency components. Second, we present a continuous luminance-based shadow matte, generated using a custom-built matte dataset and shadow matte generator, which provides precise spatial guidance from the earliest processing stage. These strategies enable the model to accurately identify fine-grained regions and restore them with high fidelity. Extensive experiments on public benchmarks (RDD and Kligler) demonstrate that MatteViT achieves state-of-the-art performance, providing a robust and practical solution for real-world document shadow removal. Furthermore, the proposed method better preserves text-level details in downstream tasks, such as optical character recognition, improving recognition performance over prior methods.

</details>


### [73] [SegEarth-OV3: Exploring SAM 3 for Open-Vocabulary Semantic Segmentation in Remote Sensing Images](https://arxiv.org/abs/2512.08730)
*Kaiyu Li,Shengqi Zhang,Yupeng Deng,Zhi Wang,Deyu Meng,Xiangyong Cao*

Main category: cs.CV

TL;DR: 本文探索了无需训练的SAM 3在遥感开放词汇语义分割（OVSS）任务中的应用。通过融合语义分割头和实例头的输出，并利用存在分数过滤不存在类别，实现了对密集小目标的有效分割，在多个遥感数据集上表现良好，展示了SAM 3在该领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的训练-free OVSS方法在遥感场景中面临定位不精确或流程复杂的问题，尤其在密集且小目标众多的情况下。而SAM 3提供了一个可提示的统一分割与识别框架，具备潜在优势，因此本文探索其在遥感OVSS中的适用性。

Method: 提出一种掩码融合策略，结合SAM 3的语义分割头与Transformer解码器（实例头）输出；同时利用存在头的得分筛选场景中不存在的类别，减少因词汇量大和图像块级处理导致的误报。

Result: 在多个遥感数据集上的实验表明，该简单适配方法取得了有竞争力的性能，验证了SAM 3在无训练条件下用于遥感OVSS的可行性与有效性。

Conclusion: SAM 3在无需训练的情况下展现出解决遥感开放词汇语义分割任务的巨大潜力，通过合理的模块融合与后处理策略，能够有效应对密集小目标场景中的挑战。

Abstract: Most existing methods for training-free Open-Vocabulary Semantic Segmentation (OVSS) are based on CLIP. While these approaches have made progress, they often face challenges in precise localization or require complex pipelines to combine separate modules, especially in remote sensing scenarios where numerous dense and small targets are present. Recently, Segment Anything Model 3 (SAM 3) was proposed, unifying segmentation and recognition in a promptable framework. In this paper, we present a preliminary exploration of applying SAM 3 to the remote sensing OVSS task without any training. First, we implement a mask fusion strategy that combines the outputs from SAM 3's semantic segmentation head and the Transformer decoder (instance head). This allows us to leverage the strengths of both heads for better land coverage. Second, we utilize the presence score from the presence head to filter out categories that do not exist in the scene, reducing false positives caused by the vast vocabulary sizes and patch-level processing in geospatial scenes. We evaluate our method on extensive remote sensing datasets. Experiments show that this simple adaptation achieves promising performance, demonstrating the potential of SAM 3 for remote sensing OVSS. Our code is released at https://github.com/earth-insights/SegEarth-OV-3.

</details>


### [74] [Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning](https://arxiv.org/abs/2512.08820)
*Yi Zhang,Chun-Wun Cheng,Junyi He,Ke Yu,Yushun Tang,Carola-Bibiane Schönlieb,Zhihai He,Angelica I. Aviles-Rivero*

Main category: cs.CV

TL;DR: 提出了一种无需训练的双曲适配器（T-DHA），用于视觉语言模型在新领域的适应。通过在双曲空间（Poincaré球模型）中表示语义概念的层次结构，利用其指数增长体积特性，实现更优的表征和判别能力，结合负学习策略，在少样本图像识别和领域泛化任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在领域变化时性能下降，且新领域微调需要大量计算资源，因此需要一种高效、无需训练的适配方法来提升跨域泛化能力。

Method: 将视觉-语言关系建模为层次结构，并在双曲空间（使用Poincaré球模型）中进行嵌入，结合负学习策略，构建无需训练的双曲适配器（T-DHA）。

Result: 在多个数据集上的实验表明，T-DHA在少样本图像识别和领域泛化任务中显著优于现有最先进方法，具有更强的鲁棒性和更高的分类精度，同时减少特征维度需求。

Conclusion: T-DHA通过在双曲空间中建模层次化语义关系，实现了高效、无需训练的跨域适应，为视觉语言模型在复杂场景下的泛化提供了有效解决方案。

Abstract: Recent research in Vision-Language Models (VLMs) has significantly advanced our capabilities in cross-modal reasoning. However, existing methods suffer from performance degradation with domain changes or require substantial computational resources for fine-tuning in new domains. To address this issue, we develop a new adaptation method for large vision-language models, called \textit{Training-free Dual Hyperbolic Adapters} (T-DHA). We characterize the vision-language relationship between semantic concepts, which typically has a hierarchical tree structure, in the hyperbolic space instead of the traditional Euclidean space. Hyperbolic spaces exhibit exponential volume growth with radius, unlike the polynomial growth in Euclidean space. We find that this unique property is particularly effective for embedding hierarchical data structures using the Poincaré ball model, achieving significantly improved representation and discrimination power. Coupled with negative learning, it provides more accurate and robust classifications with fewer feature dimensions. Our extensive experimental results on various datasets demonstrate that the T-DHA method significantly outperforms existing state-of-the-art methods in few-shot image recognition and domain generalization tasks.

</details>


### [75] [A Scalable Pipeline Combining Procedural 3D Graphics and Guided Diffusion for Photorealistic Synthetic Training Data Generation in White Button Mushroom Segmentation](https://arxiv.org/abs/2512.08747)
*Artúr I. Károly,Péter Galambos*

Main category: cs.CV

TL;DR: 本研究提出一种结合Blender 3D渲染与约束扩散模型的新型工作流程，用于自动生成高质量、逼真的合成图像及标注数据，应用于Agaricus Bisporus蘑菇的检测与分割。该方法在无需专业图形设计知识的情况下，实现了对3D场景配置和标注的完全控制，并生成了具有高真实感的图像。研究发布了两个各含6,000张图像（超过25万实例）的合成数据集，并在零样本设置下评估了基于这些数据训练的Mask R-CNN模型。实验结果表明，模型在两个独立的真实世界数据集上均达到当前最优分割性能（如M18K数据集F1=0.859），证明了合成数据的有效性。该方法可推广至其他蘑菇种类或农业领域（如水果和叶片检测）。


<details>
  <summary>Details</summary>
Motivation: 工业级蘑菇栽培依赖计算机视觉进行监测与自动化收获，但准确的检测与分割模型需要大量精确标注的数据，而真实数据的标注成本高昂。尽管合成数据可提供可扩展性，但通常缺乏足够的现实感，难以在真实场景中泛化。因此，亟需一种既能保证数据规模又具备高真实感的合成数据生成方法。

Method: 采用Blender进行3D场景渲染，并结合约束扩散模型提升图像真实感，实现无需专业图形技能即可生成高保真、带精确标注的合成图像。整个流程支持对3D场景布局、光照、遮挡等参数的可控配置，同时自动完成实例级标注。

Result: 所生成的合成数据集（每集6,000张图像，超25万蘑菇实例）使训练的Mask R-CNN模型在真实世界数据集上实现零样本迁移，达到当前最优的分割性能（如在M18K数据集上F1=0.859），验证了方法的有效性与泛化能力。

Conclusion: 该合成数据生成工作流程在保持高度可控性的同时实现了卓越的视觉真实感，显著降低了高质量农业视觉数据的获取成本。其成功应用不仅限于阿加里库斯蘑菇，还可轻松拓展至其他作物或农业任务，为智能农业视觉系统的发展提供了有力支持。

Abstract: Industrial mushroom cultivation increasingly relies on computer vision for monitoring and automated harvesting. However, developing accurate detection and segmentation models requires large, precisely annotated datasets that are costly to produce. Synthetic data provides a scalable alternative, yet often lacks sufficient realism to generalize to real-world scenarios. This paper presents a novel workflow that integrates 3D rendering in Blender with a constrained diffusion model to automatically generate high-quality annotated, photorealistic synthetic images of Agaricus Bisporus mushrooms. This approach preserves full control over 3D scene configuration and annotations while achieving photorealism without the need for specialized computer graphics expertise. We release two synthetic datasets (each containing 6,000 images depicting over 250k mushroom instances) and evaluate Mask R-CNN models trained on them in a zero-shot setting. When tested on two independent real-world datasets (including a newly collected benchmark), our method achieves state-of-the-art segmentation performance (F1 = 0.859 on M18K), despite using only synthetic training data. Although the approach is demonstrated on Agaricus Bisporus mushrooms, the proposed pipeline can be readily adapted to other mushroom species or to other agricultural domains, such as fruit and leaf detection.

</details>


### [76] [Skewness-Guided Pruning of Multimodal Swin Transformers for Federated Skin Lesion Classification on Edge Devices](https://arxiv.org/abs/2512.08751)
*Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker,Yiannis Papadopoulos*

Main category: cs.CV

TL;DR: 本文提出了一种基于偏度引导的剪枝方法，用于压缩多模态Swin Transformer模型，在保持诊断准确性的前提下显著降低模型大小，适用于边缘设备上的隐私保护分布式学习。


<details>
  <summary>Details</summary>
Motivation: 高精度医学影像模型计算量大、体积庞大，难以部署在边缘设备上；同时，隐私限制使得集中式数据管理不可行，因此需要采用联邦学习（FL）技术。

Method: 提出一种基于输出分布统计偏度的剪枝方法，针对多模态Swin Transformer中的多头自注意力和多层感知机层进行选择性剪枝。

Result: 在水平联邦学习环境中验证，模型尺寸减少约36%，且准确率无损失，实现了高效压缩与隐私保护的协同。

Conclusion: 该方法为多模态医疗人工智能在边缘设备上的高效部署提供了可行方案，兼顾模型压缩与隐私保护。

Abstract: In recent years, high-performance computer vision models have achieved remarkable success in medical imaging, with some skin lesion classification systems even surpassing dermatology specialists in diagnostic accuracy. However, such models are computationally intensive and large in size, making them unsuitable for deployment on edge devices. In addition, strict privacy constraints hinder centralized data management, motivating the adoption of Federated Learning (FL). To address these challenges, this study proposes a skewness-guided pruning method that selectively prunes the Multi-Head Self-Attention and Multi-Layer Perceptron layers of a multimodal Swin Transformer based on the statistical skewness of their output distributions. The proposed method was validated in a horizontal FL environment and shown to maintain performance while substantially reducing model complexity. Experiments on the compact Swin Transformer demonstrate approximately 36\% model size reduction with no loss in accuracy. These findings highlight the feasibility of achieving efficient model compression and privacy-preserving distributed learning for multimodal medical AI on edge devices.

</details>


### [77] [Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance](https://arxiv.org/abs/2512.08765)
*Ruihang Chu,Yefei He,Zhekai Chen,Shiwei Zhang,Xiaogang Xu,Bin Xia,Dingdong Wang,Hongwei Yi,Xihui Liu,Hengshuang Zhao,Yu Liu,Yingya Zhang,Yujiu Yang*

Main category: cs.CV

TL;DR: Wan-Move 是一个简单且可扩展的框架，为视频生成模型引入精细运动控制。它通过将物体运动表示为密集点轨迹，并将其投影到潜在空间中，沿轨迹传播首帧特征，生成对齐的时空特征图作为运动引导，无需修改现有图像到视频模型架构，显著提升运动控制精度与可扩展性。在大规模训练下，生成的5秒480p视频运动可控性媲美商业级Kling 1.5 Pro的Motion Brush。研究还构建了MoveBench基准，包含多样内容和高质量标注，验证了Wan-Move在多个数据集上的优越性能。代码、模型和数据已公开。


<details>
  <summary>Details</summary>
Motivation: 现有运动可控方法存在控制粒度粗、可扩展性差的问题，难以满足实际应用需求，因此需要一种更精细、高效且易于扩展的运动控制方案。

Method: 使用密集点轨迹表示物体运动，将轨迹投影至潜在空间并沿其传播首帧特征，生成时空对齐的特征图作为运动引导，无缝集成到现成的图像到视频模型中，无需额外编码器或模型微调。

Result: Wan-Move 在 MoveBench 和公开数据集上均表现出优越的运动质量，生成的5秒480p视频在用户研究中表现接近商业级Kling 1.5 Pro的Motion Brush；同时，该方法具备良好可扩展性，支持大规模训练。

Conclusion: Wan-Move 提供了一种高效、精确且可扩展的运动控制框架，通过直接使条件特征具备运动感知能力，实现了高质量视频生成，为视频生成模型的实际应用提供了有力支持。

Abstract: We present Wan-Move, a simple and scalable framework that brings motion control to video generative models. Existing motion-controllable methods typically suffer from coarse control granularity and limited scalability, leaving their outputs insufficient for practical use. We narrow this gap by achieving precise and high-quality motion control. Our core idea is to directly make the original condition features motion-aware for guiding video synthesis. To this end, we first represent object motions with dense point trajectories, allowing fine-grained control over the scene. We then project these trajectories into latent space and propagate the first frame's features along each trajectory, producing an aligned spatiotemporal feature map that tells how each scene element should move. This feature map serves as the updated latent condition, which is naturally integrated into the off-the-shelf image-to-video model, e.g., Wan-I2V-14B, as motion guidance without any architecture change. It removes the need for auxiliary motion encoders and makes fine-tuning base models easily scalable. Through scaled training, Wan-Move generates 5-second, 480p videos whose motion controllability rivals Kling 1.5 Pro's commercial Motion Brush, as indicated by user studies. To support comprehensive evaluation, we further design MoveBench, a rigorously curated benchmark featuring diverse content categories and hybrid-verified annotations. It is distinguished by larger data volume, longer video durations, and high-quality motion annotations. Extensive experiments on MoveBench and the public dataset consistently show Wan-Move's superior motion quality. Code, models, and benchmark data are made publicly available.

</details>


### [78] [No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers](https://arxiv.org/abs/2512.08889)
*Damiano Marsili,Georgia Gkioxari*

Main category: cs.CV

TL;DR: 本文提出一种无需标注的训练框架Valor，用于提升视觉推理中的对象定位与空间关系理解。通过结合LLM验证器（强化学习优化推理）和VLM验证器（自动挖掘难负样本强化视觉定位），避免了对大规模标注数据的依赖，融合了语言模型的分解能力与视觉模型的强监督优势。在多种空间推理任务上表现优异，超越开源及专有模型，并在仅用文本推理的方法中也取得领先。


<details>
  <summary>Details</summary>
Motivation: 现有视觉推理方法分为两类：一是依赖大规模图像-问题-答案标注的语言链式思维方法；二是基于程序合成的预训练方法，虽无需训练但存在逻辑错误和定位不准的问题。两者均面临数据或性能瓶颈，亟需一种无需人工标注、兼具精准推理与视觉定位的新范式。

Method: 提出一个无标注训练框架Valor，包含两个核心组件：1）使用大型语言模型（LLM）作为推理引擎，通过强化学习由LLM验证器迭代优化推理过程；2）引入视觉语言模型（VLM）作为验证器，通过自动化难负样本挖掘机制提升视觉定位精度，从而增强模型对图像内容的准确理解。该框架不依赖真实标签，实现端到端的自我改进。

Result: 在多个空间推理任务上，Valor显著提升了视觉推理性能，优于当前主流的开源与闭源模型。尤其是在视觉定位方面，其改进后的模型表现超越近期纯文本驱动的视觉推理方法，证明了该框架在提升推理准确性与视觉对齐能力上的有效性。

Conclusion: Valor框架通过整合先进语言模型与视觉模型的优势，构建了一个无需标注、可自我优化的视觉推理系统，为解决复杂空间关系理解提供了新路径，具备良好的泛化能力和实际应用潜力。

Abstract: Visual reasoning is challenging, requiring both precise object grounding and understanding complex spatial relationships. Existing methods fall into two camps: language-only chain-of-thought approaches, which demand large-scale (image, query, answer) supervision, and program-synthesis approaches which use pre-trained models and avoid training, but suffer from flawed logic and erroneous grounding. We propose an annotation-free training framework that improves both reasoning and grounding. Our framework uses AI-powered verifiers: an LLM verifier refines LLM reasoning via reinforcement learning, while a VLM verifier strengthens visual grounding through automated hard-negative mining, eliminating the need for ground truth labels. This design combines the strengths of modern AI systems: advanced language-only reasoning models for decomposing spatial queries into simpler subtasks, and strong vision specialist models improved via performant VLM critics. We evaluate our approach across diverse spatial reasoning tasks, and show that our method improves visual reasoning and surpasses open-source and proprietary models, while with our improved visual grounding model we further outperform recent text-only visual reasoning methods. Project webpage: https://glab-caltech.github.io/valor/

</details>


### [79] [Generation is Required for Data-Efficient Perception](https://arxiv.org/abs/2512.08854)
*Jack Brady,Bernhard Schölkopf,Thomas Kipf,Simon Buchholz,Wieland Brendel*

Main category: cs.CV

TL;DR: 该研究探讨生成式与非生成式视觉模型在组合泛化能力上的差异，发现生成式方法通过约束解码器并进行反演，能更有效地实现人类水平的视觉感知。非生成式方法难以通过正则化或架构约束实现所需归纳偏置，而生成式方法可直接利用解码器的归纳偏置，结合梯度搜索或生成重放实现高效反演，从而显著提升组合泛化性能，且无需额外数据。


<details>
  <summary>Details</summary>
Motivation: 探究生成式方法是否对实现人类水平视觉感知至关重要，特别关注组合泛化这一人类感知的核心特征。

Method: 形式化生成式（基于解码器）和非生成式（基于编码器）方法在组合数据生成过程中的归纳偏置要求；理论分析正则化与架构约束在编码器上施加这些偏置的不可行性；提出生成式方法中通过约束解码器并反演来实现归纳偏置的可行性；结合梯度搜索与生成重放进行高效反演；在真实图像数据集上进行多类模型的实证比较。

Result: 非生成式方法在缺乏归纳偏置时普遍无法实现组合泛化，需大规模预训练或额外监督；而生成式方法通过解码器约束与反演机制，在不增加数据的情况下显著提升组合泛化能力。

Conclusion: 生成式方法在实现组合泛化方面具有理论和实证优势，其内在的解码器反演机制天然支持人类级视觉感知所需的归纳偏置，表明生成性可能是实现真正类人视觉理解的关键。

Abstract: It has been hypothesized that human-level visual perception requires a generative approach in which internal representations result from inverting a decoder. Yet today's most successful vision models are non-generative, relying on an encoder that maps images to representations without decoder inversion. This raises the question of whether generation is, in fact, necessary for machines to achieve human-level visual perception. To address this, we study whether generative and non-generative methods can achieve compositional generalization, a hallmark of human perception. Under a compositional data generating process, we formalize the inductive biases required to guarantee compositional generalization in decoder-based (generative) and encoder-based (non-generative) methods. We then show theoretically that enforcing these inductive biases on encoders is generally infeasible using regularization or architectural constraints. In contrast, for generative methods, the inductive biases can be enforced straightforwardly, thereby enabling compositional generalization by constraining a decoder and inverting it. We highlight how this inversion can be performed efficiently, either online through gradient-based search or offline through generative replay. We examine the empirical implications of our theory by training a range of generative and non-generative methods on photorealistic image datasets. We find that, without the necessary inductive biases, non-generative methods often fail to generalize compositionally and require large-scale pretraining or added supervision to improve generalization. By comparison, generative methods yield significant improvements in compositional generalization, without requiring additional data, by leveraging suitable inductive biases on a decoder along with search and replay.

</details>


### [80] [Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference](https://arxiv.org/abs/2512.08860)
*Amit Bendkhale*

Main category: cs.CV

TL;DR: 本文提出Tri-Bench基准，用于评估视觉语言模型（VLMs）在平面三角形几何推理任务中的可验证性和可控性。该基准通过引入相机姿态变化（平面与倾斜）和物体干扰（10个日常物体）来测试模型在真实场景变化下的表现。实验采用固定提示，明确描述周围正方形边界，以引导模型利用单应性正确推理。结果表明，模型平均准确率约为69%（最高75%，最低64%），在2D图像平面上的准确率略高，约72%。所有模型均严重低估少数形状类别（如等边、等腰、直角三角形），且相机倾斜导致性能下降约4.1%，说明模型未能有效利用提示中的参考框架，仍依赖2D图像线索。此外，物体干扰对准确率无显著影响。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型虽具备强大能力，但在真实场景变化下表现不稳定，缺乏可靠的几何推理能力和可验证性。为提升可信度和可控性，亟需一个能分离相对几何推理并测试关键部署因素（如相机姿态和场景上下文）的基准。

Method: 构建了名为Tri-Bench的紧凑基准，包含平面三角形问题，控制变量包括相机姿态（平面/倾斜）和物体干扰（10个日常物体）。使用单一固定提示，强调周围正方形边界作为参考框架，通过单应性实现正确推理。评估四种近期VLMs在二元和连续目标上的六种简单任务。

Result: 模型整体准确率约为69%（3D真值下），2D投影下约为72%。所有模型在识别等边、等腰、直角三角形等少数形状类别时准确率接近0%。相机倾斜导致性能下降约4.1%。物体干扰对准确率无显著影响。

Conclusion: 现有VLMs无法有效利用提示中提供的显式参考框架，仍依赖2D图像平面线索进行推理，缺乏对三维几何关系的理解，限制了其在需要可验证几何推理的应用中的可信度和可控性。

Abstract: Verifiable geometric reasoning is a critical component for trustworthy and controllable agentic AI. Despite impressive capabilities, Vision-Language Models (VLMs) often fail under realistic scene changes. We present Tri-Bench, a compact benchmark of planar triangle problems that isolates relative geometric reasoning while stressing two deployment-critical factors: camera pose (planar vs. tilted) and scene context via object interference (10 everyday objects). To test verifiability and control, we evaluate four recent VLMs using a single, fixed prompt whose guardrail explicitly describes a surrounding square border, enabling correct answers via homography. We evaluate six simple tasks over binary and continuous targets, and observe that the overall accuracy with respect to 3D ground truth is modest, ~69% on average (best ~75%, worst ~64%). The same responses align even more closely with 2D projections in the image plane, where mean accuracy is ~72%. All four VLMs consistently fail, with accuracy falling to ~0%, on recognizing minority shape classes (equilateral, isosceles, right-angled triangles). Additionally, overall VLM accuracy degrades by ~4.1% under camera tilt. This demonstrates that models fail to correctly utilize the explicit frame-of-reference hint provided in the prompt and default to 2D image plane cues. Finally, we find that object interference has no significant effect on VLM accuracy.

</details>


### [81] [Astra: General Interactive World Model with Autoregressive Denoising](https://arxiv.org/abs/2512.08931)
*Yixuan Zhu,Jiaqi Feng,Wenzhao Zheng,Yuan Gao,Xin Tao,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Astra is a general-purpose world model that enables interactive, long-horizon video prediction with precise action control across diverse real-world scenarios like autonomous driving and robot grasping. It uses an autoregressive denoising architecture with temporal causal attention, noise-augmented memory for balance between responsiveness and coherence, an action-aware adapter for direct action injection, and a mixture of action experts for dynamic handling of various action modalities. Experiments show superior performance in fidelity, long-range prediction, and action alignment.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion-based video generation models excel in text/image-to-video synthesis but lack robust capabilities for predicting long-horizon futures from past observations and actions in general-purpose settings. There is a need for a world model that supports diverse real-world tasks with precise action interactions.

Method: Astra employs an autoregressive denoising architecture with temporal causal attention to process past observations and generate streaming outputs. It integrates a noise-augmented history memory to prevent over-reliance on past frames, ensuring responsiveness while maintaining coherence. An action-aware adapter injects action signals directly into the denoising process for precise control. A mixture of action experts dynamically routes different action modalities (e.g., exploration, manipulation, camera control) to enhance versatility.

Result: Astra achieves high-fidelity, consistent, and generalizable long-term video predictions across multiple datasets. It outperforms state-of-the-art models in video fidelity, long-range prediction accuracy, and alignment with input actions, demonstrating strong adaptability to diverse real-world tasks and interaction types.

Conclusion: Astra advances the frontier of interactive world modeling by enabling accurate, general-purpose, long-horizon future prediction with fine-grained action control. Its modular design and dynamic action routing make it suitable for a wide range of applications in robotics, autonomous systems, and simulation.

Abstract: Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an autoregressive denoising architecture and use temporal causal attention to aggregate past observations and support streaming outputs. We use a noise-augmented history memory to avoid over-reliance on past frames to balance responsiveness with temporal coherence. For precise action control, we introduce an action-aware adapter that directly injects action signals into the denoising process. We further develop a mixture of action experts that dynamically route heterogeneous action modalities, enhancing versatility across diverse real-world tasks such as exploration, manipulation, and camera control. Astra achieves interactive, consistent, and general long-term video prediction and supports various forms of interactions. Experiments across multiple datasets demonstrate the improvements of Astra in fidelity, long-range prediction, and action alignment over existing state-of-the-art world models.

</details>


### [82] [SATGround: A Spatially-Aware Approach for Visual Grounding in Remote Sensing](https://arxiv.org/abs/2512.08881)
*Aysim Toker,Andreea-Maria Oncescu,Roy Miles,Ismail Elezi,Jiankang Deng*

Main category: cs.CV

TL;DR: 本文提出一种新型结构化定位机制，通过微调预训练视觉语言模型（VLM）并引入专用控制标记与接地模块交互，实现对卫星影像中目标的精确空间定位。该方法在多个遥感基准上显著提升性能，尤其在视觉定位任务上相对之前方法提升24.8%，验证了将结构化空间推理融入VLM的有效性，推动了更可靠的真实卫星数据分析。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂卫星场景中的视觉定位能力有限，缺乏对空间信息的精细建模，难以满足高精度遥感分析需求。因此亟需一种能有效融合语言与空间信息的结构化推理机制以提升定位准确性。

Method: 通过在多样化指令跟随任务上微调预训练的视觉语言模型，并引入专门的控制令牌来连接一个独立的接地模块，实现语言与空间信息的联合推理，从而增强模型在复杂卫星图像中的目标定位能力。

Result: 在多个遥感基准测试中，所提框架均取得显著性能提升，特别是在视觉定位任务上相较先前方法实现24.8%的相对改进，表明结构化空间推理对提高模型表现具有关键作用。

Conclusion: 将结构化空间推理机制集成到视觉语言模型中，可有效提升其在复杂卫星图像中的精准定位能力，为未来高可靠性遥感智能分析提供了新路径。

Abstract: Vision-language models (VLMs) are emerging as powerful generalist tools for remote sensing, capable of integrating information across diverse tasks and enabling flexible, instruction-based interactions via a chat interface. In this work, we enhance VLM-based visual grounding in satellite imagery by proposing a novel structured localization mechanism. Our approach involves finetuning a pretrained VLM on a diverse set of instruction-following tasks, while interfacing a dedicated grounding module through specialized control tokens for localization. This method facilitates joint reasoning over both language and spatial information, significantly enhancing the model's ability to precisely localize objects in complex satellite scenes. We evaluate our framework on several remote sensing benchmarks, consistently improving the state-of-the-art, including a 24.8% relative improvement over previous methods on visual grounding. Our results highlight the benefits of integrating structured spatial reasoning into VLMs, paving the way for more reliable real-world satellite data analysis.

</details>


### [83] [Accelerated Rotation-Invariant Convolution for UAV Image Segmentation](https://arxiv.org/abs/2512.08888)
*Manduhu Manduhu,Alexander Dow,Gerard Dooly,James Riordan*

Main category: cs.CV

TL;DR: 本文提出一种GPU优化的旋转不变卷积框架，通过消除传统矩阵乘法卷积所需的im2col步骤，并利用对称旋转滤波器间的结构化数据共享，显著降低内存流量和计算冗余。该方法支持多方向及任意旋转角度的卷积，大幅提高效率。在多个基准测试中，相比CUDNN，训练速度提升20–55%，能耗降低15–45%；在八方向设置下，256×256输入可实现45%加速与41%节能，1024×1024输入则达32%加速与23%节能。集成至U-Net模型后，准确率较非旋转感知基线最高提升6%。


<details>
  <summary>Details</summary>
Motivation: 传统分割架构如U-Net依赖非旋转不变的卷积操作，在无人机航拍图像中因目标任意朝向导致分割精度下降。虽可通过扩展滤波器组实现旋转不变性，但会带来巨大计算开销与内存压力。因此亟需高效且保持精度的旋转不变卷积方法。

Method: 提出一种无需im2col步骤的旋转不变卷积框架，利用对称旋转滤波器之间的结构化数据共享机制，减少内存访问与计算冗余，并扩展至任意旋转角度的卷积加速。

Result: 在多个基准上，相比CUDNN，训练速度提升20–55%，能耗降低15–45%；八方向设置下，256×256输入加速45%、节能41%，1024×1024输入加速32%、节能23%；集成至U-Net后，分割准确率最高提升6%。

Conclusion: 所提方法为现有旋转不变卷积框架提供了高效且有效的替代方案，兼具高精度与低资源消耗优势，适用于无人机航拍等复杂场景下的对象级分割任务。

Abstract: Rotation invariance is essential for precise, object-level segmentation in UAV aerial imagery, where targets can have arbitrary orientations and exhibit fine-scale details. Conventional segmentation architectures like U-Net rely on convolution operators that are not rotation-invariant, leading to degraded segmentation accuracy across varying viewpoints. Rotation invariance can be achieved by expanding the filter bank across multiple orientations; however, this will significantly increase computational cost and memory traffic. In this paper, we introduce a GPU-optimized rotation-invariant convolution framework that eliminates the traditional data-lowering (im2col) step required for matrix-multiplication-based convolution. By exploiting structured data sharing among symmetrically rotated filters, our method achieves multi-orientation convolution with greatly reduced memory traffic and computational redundancy. We further generalize the approach to accelerate convolution with arbitrary (non-symmetric) rotation angles.
  Across extensive benchmarks, the proposed convolution achieves 20--55% faster training and 15--45% lower energy consumption than CUDNN, while maintaining accuracy comparable to state-of-the-art rotation-invariant methods. In the eight-orientation setting, our approach achieves up to 45% speedup and 41% energy savings on 256\(\times\)256 inputs, and 32% speedup and 23% lower energy usage on 1024\(\times\)1024 inputs. Integrated into a U-Net segmentation model, the framework yields up to 6% improvement in accuracy over the non-rotation-aware baseline. These results demonstrate that the proposed method provides an effective and highly efficient alternative to existing rotation-invariant CNN frameworks.

</details>


### [84] [UniLayDiff: A Unified Diffusion Transformer for Content-Aware Layout Generation](https://arxiv.org/abs/2512.08897)
*Zeyang Liu,Le Wang,Sanping Zhou,Yuxuan Wu,Xiaolong Sun,Gang Hua,Haoxiang Li*

Main category: cs.CV

TL;DR: UniLayDiff 是首个统一内容感知版面生成任务的端到端可训练模型，通过将布局约束视为独立模态，并利用多模态扩散变压器捕捉背景图像、布局元素和多样化约束之间的复杂交互，实现从无条件到各种条件生成任务的统一。通过LoRA微调引入关系约束，提升整体版面质量，在多个任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以统一处理多种输入约束下的版面生成任务，或需为不同条件单独设计模型参数，缺乏真正统一的解决方案。

Method: 提出UniLayDiff，采用多模态扩散变压器框架，将布局约束作为独立模态处理；通过预训练后使用LoRA微调以集成关系约束。

Result: 在从无条件到各类条件生成任务中均取得最先进性能，首次实现了内容感知版面生成任务的全面统一。

Conclusion: UniLayDiff是首个能统一处理全部内容感知版面生成任务的模型，具备高效、通用和高质量生成能力，为图形设计自动化提供了新范式。

Abstract: Content-aware layout generation is a critical task in graphic design automation, focused on creating visually appealing arrangements of elements that seamlessly blend with a given background image. The variety of real-world applications makes it highly challenging to develop a single model capable of unifying the diverse range of input-constrained generation sub-tasks, such as those conditioned by element types, sizes, or their relationships. Current methods either address only a subset of these tasks or necessitate separate model parameters for different conditions, failing to offer a truly unified solution. In this paper, we propose UniLayDiff: a Unified Diffusion Transformer, that for the first time, addresses various content-aware layout generation tasks with a single, end-to-end trainable model. Specifically, we treat layout constraints as a distinct modality and employ Multi-Modal Diffusion Transformer framework to capture the complex interplay between the background image, layout elements, and diverse constraints. Moreover, we integrate relation constraints through fine-tuning the model with LoRA after pretraining the model on other tasks. Such a schema not only achieves unified conditional generation but also enhances overall layout quality. Extensive experiments demonstrate that UniLayDiff achieves state-of-the-art performance across from unconditional to various conditional generation tasks and, to the best of our knowledge, is the first model to unify the full range of content-aware layout generation tasks.

</details>


### [85] [Self-Evolving 3D Scene Generation from a Single Image](https://arxiv.org/abs/2512.08905)
*Kaizhi Zheng,Yue Fan,Jing Gu,Zishuo Xu,Xuehai He,Xin Eric Wang*

Main category: cs.CV

TL;DR: EvoScene 是一种无需训练的自进化框架，通过结合3D生成模型的几何推理能力和视频生成模型的视觉知识，从单张图像逐步重建高质量、带纹理的3D场景。它通过三个迭代阶段（空间先验初始化、视觉引导的3D网格生成、空间引导的新视角生成）在2D与3D域间交替优化，显著提升结构稳定性和视图一致性，实现对未见区域的完整重建，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像到3D生成方法受限于对象中心的训练方式，在复杂大规模场景中难以保持结构和纹理的真实一致。如何实现无需训练、可泛化至复杂场景的高质量3D重建仍是挑战。

Method: EvoScene采用三阶段迭代流程：首先利用3D生成模型建立空间先验；接着融合视频生成模型的视觉知识生成具有纹理的3D网格；最后通过空间引导机制生成一致的新视角。整个过程在2D与3D之间反复迭代，逐步优化结构与外观。

Result: 在多样场景上的实验表明，EvoScene在几何稳定性、视图一致性纹理以及未见区域补全方面均优于强基线方法，生成的3D网格可直接用于实际应用。

Conclusion: EvoScene成功实现了无需训练的高保真3D场景重建，通过跨模态协同与迭代优化，为复杂场景的单图像3D生成提供了高效可行的解决方案。

Abstract: Generating high-quality, textured 3D scenes from a single image remains a fundamental challenge in vision and graphics. Recent image-to-3D generators recover reasonable geometry from single views, but their object-centric training limits generalization to complex, large-scale scenes with faithful structure and texture. We present EvoScene, a self-evolving, training-free framework that progressively reconstructs complete 3D scenes from single images. The key idea is combining the complementary strengths of existing models: geometric reasoning from 3D generation models and visual knowledge from video generation models. Through three iterative stages--Spatial Prior Initialization, Visual-guided 3D Scene Mesh Generation, and Spatial-guided Novel View Generation--EvoScene alternates between 2D and 3D domains, gradually improving both structure and appearance. Experiments on diverse scenes demonstrate that EvoScene achieves superior geometric stability, view-consistent textures, and unseen-region completion compared to strong baselines, producing ready-to-use 3D meshes for practical applications.

</details>


### [86] [LiDAS: Lighting-driven Dynamic Active Sensing for Nighttime Perception](https://arxiv.org/abs/2512.08912)
*Simon de Moreau,Andrei Bursuc,Hafid El-Idrissi,Fabien Moutarde*

Main category: cs.CV

TL;DR: LiDAS是一种闭环主动照明系统，通过动态预测最优光照场来提升夜间视觉感知性能，实现零样本夜间泛化，显著提升模型在真实驾驶场景中的表现，同时降低40%能耗。


<details>
  <summary>Details</summary>
Motivation: 夜间环境对基于摄像头的感知构成挑战，现有方法依赖被动光照，无法有效应对低光条件下的感知难题。

Method: 结合现成视觉感知模型与高分辨率大灯，通过闭环控制动态调整光照分布，将光线集中于物体区域而非均匀照亮整个场景。

Result: 在不增加能耗的前提下，相比标准近光灯，mAP50提升18.7%，mIoU提升5.0%；在真实驾驶场景中实现零样本部署，且能耗降低40%。

Conclusion: LiDAS将普通大灯转化为主动视觉执行器，提供一种低成本、高效且可扩展的夜间鲁棒感知解决方案，兼容领域泛化方法，无需重新训练即可增强系统鲁棒性。

Abstract: Nighttime environments pose significant challenges for camera-based perception, as existing methods passively rely on the scene lighting. We introduce Lighting-driven Dynamic Active Sensing (LiDAS), a closed-loop active illumination system that combines off-the-shelf visual perception models with high-definition headlights. Rather than uniformly brightening the scene, LiDAS dynamically predicts an optimal illumination field that maximizes downstream perception performance, i.e., decreasing light on empty areas to reallocate it on object regions. LiDAS enables zero-shot nighttime generalization of daytime-trained models through adaptive illumination control. Trained on synthetic data and deployed zero-shot in real-world closed-loop driving scenarios, LiDAS enables +18.7% mAP50 and +5.0% mIoU over standard low-beam at equal power. It maintains performances while reducing energy use by 40%. LiDAS complements domain-generalization methods, further strengthening robustness without retraining. By turning readily available headlights into active vision actuators, LiDAS offers a cost-effective solution to robust nighttime perception.

</details>


### [87] [Efficiently Reconstructing Dynamic Scenes One D4RT at a Time](https://arxiv.org/abs/2512.08924)
*Chuhan Zhang,Guillaume Le Moing,Skanda Koppula,Ignacio Rocco,Liliane Momeni,Junyu Xie,Shuyang Sun,Rahul Sukthankar,Joëlle K Barral,Raia Hadsell,Zoubin Ghahramani,Andrew Zisserman,Junlin Zhang,Mehdi SM Sajjadi*

Main category: cs.CV

TL;DR: D4RT提出一种轻量级、高效的前馈模型，通过统一的Transformer架构联合推断深度、时空对应关系和相机参数，利用新颖的查询机制避免密集解码和多任务解码器的复杂性，实现对任意时空点的灵活探测，在4D动态场景重建任务中达到新基准性能。


<details>
  <summary>Details</summary>
Motivation: 解决从视频中理解与重建动态场景复杂几何与运动的挑战，现有方法存在计算复杂、效率低、解码器设计繁琐等问题。

Method: 采用统一的Transformer架构，引入创新的查询机制，实现无需密集每帧解码的高效推理，支持对任意时空点的独立灵活探测。

Result: 在多种4D重建任务中超越先前方法，实现更高效训练与推理，显著提升性能。

Conclusion: D4RT是一种轻量、可扩展且高效的4D动态场景重建方法，为该领域带来新的技术范式。

Abstract: Understanding and reconstructing the complex geometry and motion of dynamic scenes from video remains a formidable challenge in computer vision. This paper introduces D4RT, a simple yet powerful feedforward model designed to efficiently solve this task. D4RT utilizes a unified transformer architecture to jointly infer depth, spatio-temporal correspondence, and full camera parameters from a single video. Its core innovation is a novel querying mechanism that sidesteps the heavy computation of dense, per-frame decoding and the complexity of managing multiple, task-specific decoders. Our decoding interface allows the model to independently and flexibly probe the 3D position of any point in space and time. The result is a lightweight and highly scalable method that enables remarkably efficient training and inference. We demonstrate that our approach sets a new state of the art, outperforming previous methods across a wide spectrum of 4D reconstruction tasks. We refer to the project webpage for animated results: https://d4rt-paper.github.io/.

</details>


### [88] [Selfi: Self Improving Reconstruction Engine via 3D Geometric Feature Alignment](https://arxiv.org/abs/2512.08930)
*Youming Deng,Songyou Peng,Junyi Zhang,Kathryn Heal,Tiancheng Sun,John Flynn,Steve Marschner,Lucy Chai*

Main category: cs.CV

TL;DR: Selfi is a self-improving 3D reconstruction pipeline that enhances VGGT's implicit 3D features through feature alignment, using its own outputs as pseudo-ground-truth. It introduces a lightweight adapter with a reprojection-based consistency loss to align features geometrically, significantly improving novel view synthesis and camera pose estimation.


<details>
  <summary>Details</summary>
Motivation: Existing methods like VGGT lack explicit multi-view geometric consistency in their 3D features, which limits performance in downstream tasks such as novel view synthesis and pose estimation. The goal is to improve 3D feature consistency without relying on explicit 3D priors or known camera parameters.

Method: Selfi trains a lightweight feature adapter using a reprojection-based consistency loss. The adapter distills VGGT's outputs into a geometrically-aligned feature space by leveraging the model’s own predictions as pseudo-ground-truth, thereby enforcing spatial consistency across views.

Result: Selfi achieves state-of-the-art performance in both novel view synthesis and camera pose estimation, demonstrating that feature alignment significantly enhances 3D reasoning capabilities even in vision foundation models trained implicitly.

Conclusion: Feature alignment via self-improvement is a powerful strategy for enhancing 3D consistency in implicit models, enabling high-fidelity 3D reconstruction and improved downstream tasks without requiring explicit 3D supervision or calibrated cameras.

Abstract: Novel View Synthesis (NVS) has traditionally relied on models with explicit 3D inductive biases combined with known camera parameters from Structure-from-Motion (SfM) beforehand. Recent vision foundation models like VGGT take an orthogonal approach -- 3D knowledge is gained implicitly through training data and loss objectives, enabling feed-forward prediction of both camera parameters and 3D representations directly from a set of uncalibrated images. While flexible, VGGT features lack explicit multi-view geometric consistency, and we find that improving such 3D feature consistency benefits both NVS and pose estimation tasks. We introduce Selfi, a self-improving 3D reconstruction pipeline via feature alignment, transforming a VGGT backbone into a high-fidelity 3D reconstruction engine by leveraging its own outputs as pseudo-ground-truth. Specifically, we train a lightweight feature adapter using a reprojection-based consistency loss, which distills VGGT outputs into a new geometrically-aligned feature space that captures spatial proximity in 3D. This enables state-of-the-art performance in both NVS and camera pose estimation, demonstrating that feature alignment is a highly beneficial step for downstream 3D reasoning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [89] [Adaptation of Embedding Models to Financial Filings via LLM Distillation](https://arxiv.org/abs/2512.08088)
*Eliot Brenner,Dominic Seyler,Manjunath Hegde,Andrei Simion,Koustuv Dasgupta,Bing Xiang*

Main category: cs.CL

TL;DR: 本文提出一种可扩展的管道方法，通过利用通用检索嵌入模型作为基础，从无标注语料库中训练专门化模型，以解决金融等专业领域信息检索性能不足的问题。该方法通过学生-教师模型间的交互，迭代式挖掘难例（hard positives/negatives）并重新训练学生模型，显著提升检索效果，在14种金融文件类型上平均提升MRR@5达27.7%，平均DCG@5提升44.6%，并在FinanceBench上改善了3个文档类别的NDCG。该方法不依赖人工标注，适用于低成本、高效率的领域适配。


<details>
  <summary>Details</summary>
Motivation: 现有生成式大语言模型在实际应用中受限于计算成本、延迟要求及专业领域相关性度量的精确性。尽管已有嵌入模型缓解前两者问题，但在金融等专业领域信息检索表现不佳，亟需高效、低成本的领域专用检索模型。

Method: 提出一种基于学生-教师框架的迭代训练管道：使用通用检索嵌入模型（教师）指导学生模型训练；通过学生模型在无标注语料库中检索并挖掘难例（hard positives/negatives），再用于下一轮训练；不断迭代优化学生模型，使其逐步逼近领域知识。该过程无需人工标注，仅依赖大语言模型判断的相关性进行知识蒸馏。

Result: 在21,800个查询-文档对上，相比基线模型，平均提升MRR@5达27.7%，平均提升mean DCG@5达44.6%；在FinanceBench数据集上，3/4文档类别实现NDCG提升。验证了该方法在金融领域的有效性与泛化能力。

Conclusion: 所提出的迭代式检索增强训练管道，能够有效利用无标注数据和大语言模型的判断能力，低成本地构建高性能的专业领域检索模型，为通用大模型向垂直场景迁移提供了可行路径。

Abstract: Despite advances in generative large language models (LLMs), practical application of specialized conversational AI agents remains constrained by computation costs, latency requirements, and the need for precise domain-specific relevance measures. While existing embedding models address the first two constraints, they underperform on information retrieval in specialized domains like finance. This paper introduces a scalable pipeline that trains specialized models from an unlabeled corpus using a general purpose retrieval embedding model as foundation. Our method yields an average of 27.7% improvement in MRR$\texttt{@}$5, 44.6% improvement in mean DCG$\texttt{@}$5 across 14 financial filing types measured over 21,800 query-document pairs, and improved NDCG on 3 of 4 document classes in FinanceBench. We adapt retrieval embeddings (bi-encoder) for RAG, not LLM generators, using LLM-judged relevance to distill domain knowledge into a compact retriever. There are prior works which pair synthetically generated queries with real passages to directly fine-tune the retrieval model. Our pipeline differs from these by introducing interaction between student and teacher models that interleaves retrieval-based mining of hard positive/negative examples from the unlabeled corpus with iterative retraining of the student model's weights using these examples. Each retrieval iteration uses the refined student model to mine the corpus for progressively harder training examples for the subsequent training iteration. The methodology provides a cost-effective solution to bridging the gap between general-purpose models and specialized domains without requiring labor-intensive human annotation.

</details>


### [90] [Segment, Embed, and Align: A Universal Recipe for Aligning Subtitles to Signing](https://arxiv.org/abs/2512.08094)
*Zifan Jiang,Youngjoon Jang,Liliane Momeni,Gül Varol,Sarah Ebling,Andrew Zisserman*

Main category: cs.CL

TL;DR: 本文提出了一种通用的视频字幕对齐方法SEA（Segment, Embed, and Align），可跨语言和领域应用于手语视频与文本的时间对齐。该方法不依赖特定语言或数据集，利用两个预训练模型分别进行视频分段和特征嵌入，并通过轻量级动态规划算法实现高效对齐，支持从小词典到大规模语料库的多种场景。在四个手语数据集上表现优于现有方法，生成高质量平行数据以推动手语处理研究。代码与模型已开源。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常针对特定语言或数据集进行端到端训练，缺乏通用性；亟需一种可跨语言、跨领域的通用对齐框架以支持更广泛的手语处理应用。

Method: SEA方法包含三个阶段：1）使用预训练模型将手语视频序列分割为单个手势片段；2）利用另一预训练模型将每个手势视频片段嵌入与文本共享的潜在空间；3）采用轻量级动态规划算法完成时间对齐，可在CPU上快速运行（分钟级）。

Result: 在四个不同手语数据集上的实验表明，SEA在对齐性能上达到当前最优水平，且具有良好的泛化能力，适用于从小型词典到大型连续语料库的多种应用场景。

Conclusion: SEA是一种灵活、高效的通用手语视频与字幕对齐框架，能够有效生成高质量平行数据，为手语处理技术的发展提供有力支持，其开源特性进一步促进了社区研究进展。

Abstract: The goal of this work is to develop a universal approach for aligning subtitles (i.e., spoken language text with corresponding timestamps) to continuous sign language videos. Prior approaches typically rely on end-to-end training tied to a specific language or dataset, which limits their generality. In contrast, our method Segment, Embed, and Align (SEA) provides a single framework that works across multiple languages and domains. SEA leverages two pretrained models: the first to segment a video frame sequence into individual signs and the second to embed the video clip of each sign into a shared latent space with text. Alignment is subsequently performed with a lightweight dynamic programming procedure that runs efficiently on CPUs within a minute, even for hour-long episodes. SEA is flexible and can adapt to a wide range of scenarios, utilizing resources from small lexicons to large continuous corpora. Experiments on four sign language datasets demonstrate state-of-the-art alignment performance, highlighting the potential of SEA to generate high-quality parallel data for advancing sign language processing. SEA's code and models are openly available.

</details>


### [91] [Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation](https://arxiv.org/abs/2512.08123)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 本文研究了通用对抗性后缀，即短标记序列（4-10个标记），这些序列在附加到任何输入时，能广泛降低多种任务和模型的准确率。通过使用Gumbel-Softmax松弛进行可微分的“软”形式训练，并在推理时离散化，该方法在标签区域上最大化校准交叉熵，同时屏蔽真实标记以防止信息泄露，并通过熵正则化避免坍塌。一个在单一模型上训练的后缀可有效迁移至其他模型，在情感分析、自然语言推理、释义检测、常识问答和物理推理等多个任务中均表现出一致的攻击效果和跨模型转移能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常针对特定任务或模型优化触发词，导致结果难以比较且泛化能力有限。本文旨在开发一种通用且可转移的对抗性攻击方法，以揭示语言模型在零样本或少样本分类中的脆弱性。

Method: 采用Gumbel-Softmax松弛实现对抗性后缀的可微分训练，通过最大化校准交叉熵并结合熵正则化与真实标签屏蔽机制，确保攻击的有效性和多样性；训练完成后将后缀离散化用于推理。

Result: 单个训练好的后缀在多个不同模型（Qwen2-1.5B、Phi-1.5、TinyLlama-1.1B）和多种任务（如情感分析、自然语言推理等）上均表现出显著的性能下降，且具有良好的跨模型迁移能力。

Conclusion: 通用对抗性后缀是一种高效、可迁移的攻击方式，能够系统性地削弱多种语言模型在各类任务上的表现，揭示了当前语言模型在面对简单后缀扰动时的脆弱性。

Abstract: Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable "soft" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.

</details>


### [92] [ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access](https://arxiv.org/abs/2512.08193)
*Jiwoo Park,Ruoqi Liu,Avani Jagdale,Andrew Srisuwananukorn,Jing Zhao,Lang Li,Ping Zhang,Sachin Kumar*

Main category: cs.CL

TL;DR: ClinicalTrialsHub 是一个交互式搜索平台，整合了 ClinicalTrials.gov 的全部数据，并通过从 PubMed 文章中自动提取和结构化试验相关信息，将可访问的结构化临床试验数据量提升了 83.8%。该平台利用 GPT-5.1 和 Gemini-3-Pro 等大语言模型，实现全文解析、查询转化与带来源引用的答案生成，显著提升患者、临床医生、研究人员和政策制定者获取证据的效率。用户研究与自动评估验证了其在信息提取与问答能力上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有临床试验数据分散且难以高效获取，尤其是来自科研文献的信息未被充分结构化利用，限制了证据支持决策的能力。需要一个能整合多源数据并提供智能检索与答案生成的系统以提升临床研究与实践的效率。

Method: 使用大语言模型（如 GPT-5.1、Gemini-3-Pro）自动解析 PubMed 全文，提取结构化试验信息；将用户自然语言查询转化为结构化数据库搜索；构建基于来源引用的问答系统，确保答案可追溯。

Result: 相比仅依赖 ClinicalTrials.gov，ClinicalTrialsHub 将结构化数据访问量提升了 83.8%；用户研究表明其对临床医生、研究人员和学生具有高实用价值；自动评估显示其信息抽取与问答性能优异。

Conclusion: ClinicalTrialsHub 有效扩展了临床试验数据的可及性与可用性，为推动循证医学发展提供了强有力的技术支持，具备广泛的应用前景。

Abstract: We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.

</details>


### [93] [Are generative AI text annotations systematically biased?](https://arxiv.org/abs/2512.08404)
*Sjoerd B. Stolwijk,Mark Boukes,Damian Trilling*

Main category: cs.CL

TL;DR: 该研究通过概念复制手动标注（Boukes, 2024）的方法，评估了通用大语言模型（GLLMs）在五个概念（政治内容、互动性、理性、不文明行为和意识形态）上的标注偏差。使用Llama3.1:8b、Llama3.3:70b、GPT4o、Qwen2.5:72b等模型，结合五种不同提示词进行实验。结果显示，尽管各模型在F1分数上表现良好，但在标注频率上与人工标注存在显著差异，导致下游分析结果不同；且模型间彼此重合度高于与人工标注的重合度，显示出系统性偏差。F1得分差异无法解释此类偏差程度。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖人工标注，但成本高且效率低。随着通用大语言模型（GLLMs）在文本标注中的广泛应用，其标注质量与偏差问题亟需系统评估。本文旨在揭示GLLMs在关键社会科学研究概念上的标注偏差，为后续研究提供方法论警示。

Method: 采用概念复制设计，以Boukes（2024）的人工标注为基础，使用四种主流GLLMs（Llama3.1:8b、Llama3.3:70b、GPT4o、Qwen2.5:72b）在五种不同提示下对五个核心概念进行标注。通过比较模型输出与人工标注在标注频率、重合度及F1分数上的差异，量化系统性偏差。

Result: GLLMs在F1分数上表现良好，但其标注的盛行率与人工标注存在显著差异，导致下游分析结果不同。模型间的标注重合度远高于模型与人工标注之间的重合度，表明存在系统性偏差。此外，F1分数差异无法充分反映实际偏差程度。

Conclusion: 尽管通用大语言模型在标注任务中表现出较高的准确性（高F1），但其标注结果仍存在显著系统性偏差，尤其在概念盛行率和一致性方面与人工标注不符。研究提醒研究者在依赖自动化标注时需谨慎，应警惕模型间一致性带来的虚假可靠性，并建议结合人工校验或开发更稳健的评估指标。

Abstract: This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.

</details>


### [94] [What Triggers my Model? Contrastive Explanations Inform Gender Choices by Translation Models](https://arxiv.org/abs/2512.08440)
*Janiça Hackenbuchner,Arda Tezcan,Joke Daems*

Main category: cs.CL

TL;DR: 本研究探讨机器翻译模型在性别指代上的决策机制，通过对比解释和显著性归因分析源句中哪些上下文（输入词）影响了目标语言的性别选择，揭示模型与人类对性别感知的重叠，并提出应利用此类信息减轻性别偏见。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦于测量性别偏见，但缺乏对其根源的深入探索；本研究旨在理解模型性别决策的成因，以推动偏见缓解。

Method: 采用对比解释和显著性归因方法，分析性别模糊源数据中输入词对模型性别选择的影响，并比较模型归因与人类性别感知的一致性。

Result: 发现模型对某些词汇的显著性归因与人类对性别感知高度重合，且通过语言学分析揭示了关键触发词的语义特征。

Conclusion: 理解模型在性别相关翻译决策中的依据对于识别和缓解性别偏见至关重要，该信息应被用于改进模型公平性。

Abstract: Interpretability can be implemented as a means to understand decisions taken by (black box) models, such as machine translation (MT) or large language models (LLMs). Yet, research in this area has been limited in relation to a manifested problem in these models: gender bias. With this research, we aim to move away from simply measuring bias to exploring its origins. Working with gender-ambiguous natural source data, this study examines which context, in the form of input tokens in the source sentence, influences (or triggers) the translation model choice of a certain gender inflection in the target language. To analyse this, we use contrastive explanations and compute saliency attribution. We first address the challenge of a lacking scoring threshold and specifically examine different attribution levels of source words on the model gender decisions in the translation. We compare salient source words with human perceptions of gender and demonstrate a noticeable overlap between human perceptions and model attribution. Additionally, we provide a linguistic analysis of salient words. Our work showcases the relevance of understanding model translation decisions in terms of gender, how this compares to human decisions and that this information should be leveraged to mitigate gender bias.

</details>


### [95] [Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models](https://arxiv.org/abs/2512.08480)
*Ju-Young Kim,Ji-Hong Park,Se-Yeon Lee,Sujin Park,Gun-Woo Kim*

Main category: cs.CL

TL;DR: 本文提出一种软归纳偏置方法，通过明确定义推理视角来引导大语言模型的推理过程，以提升对不当言论检测的准确性。实验表明，所提出的Kanana-1.5模型在韩语语料上微调后，平均准确率达到87.0046%，相比标准监督学习提升了约3.89%。该方法不仅超越了大模型的知识模仿，还通过约束推理视角实现更精确、一致的判断，有效提升不当言论检测性能。


<details>
  <summary>Details</summary>
Motivation: 在线游戏和社区中因匿名性导致的不当言论频发，已演变为言语暴力甚至犯罪行为，亟需有效的检测技术以构建安全的交流环境。尽管大语言模型和链式思维推理在韩语领域受到关注，但其在不当言论检测中的应用仍有限，因此需要新的方法提升推理质量与判断一致性。

Method: 提出一种软归纳偏置方法，通过显式定义推理视角来引导大语言模型的推理过程，使模型在生成判断时遵循特定逻辑框架，从而减少推理错误，提高决策理性。采用韩语大语言模型进行微调，并对比多种训练策略的性能。

Result: Kanana-1.5模型在不当言论检测任务中达到87.0046%的平均准确率，较标准监督学习提升约3.89%；定性和定量分析均表明该方法能有效提升模型判断的准确性与一致性。

Conclusion: 所提出的软归纳偏置方法通过约束推理视角，使大语言模型在不当言论检测中实现更精准、稳定的判断，不仅超越知识模仿，也显著提升模型表现，具有实际应用价值。

Abstract: Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.

</details>


### [96] [Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks](https://arxiv.org/abs/2512.08545)
*Indrajit Kar,Kalathur Chenchu Kishore Kumar*

Main category: cs.CL

TL;DR: 本文提出一种分层多智能体架构，通过64×64的轻量级智能体网格分布推理任务，并结合选择性仲裁器与空间课程机制，逐步扩展智能体的作业区域。采用负对数似然（NLL）衡量置信度，确保智能体在准确且校准良好的区域优先训练。通过基于汤普森采样的课程管理器自适应选择训练区域，显著提升系统稳定性、减少仲裁器使用并增强长程推理能力。在空间化塔问题基准测试中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型和多智能体系统在处理长周期推理任务时面临计算成本高、稳定性差的问题，尤其在复杂规划任务中表现不佳。需要一种可扩展、高效且具备良好可靠性保障的分布式推理框架。

Method: 提出一个分层多智能体系统，包含64×64的轻量级智能体网格，结合选择性仲裁器；设计空间课程机制，按从中心到外围的顺序逐步扩展任务区域；引入负对数似然（NLL）作为置信度指标，指导课程优先选择高准确率与良好校准性的区域；采用汤普森采样实现动态课程管理，根据智能体能力和奖励信号自适应调整训练区域。

Result: 在空间化塔问题基准上，系统展现出更强的长期推理能力、更高的运行稳定性、更低的仲裁器调用频率，验证了分布式协作与课程学习的有效性。

Conclusion: 所提出的分层多智能体架构通过空间课程与置信度引导的自适应训练策略，有效缓解了长周期推理中的计算负担与不稳定性问题，为复杂规划任务提供了一种可扩展、可靠的解决方案。

Abstract: Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.

</details>


### [97] [HealthcareNLP: where are we and what is next?](https://arxiv.org/abs/2512.08617)
*Lifeng Han,Paul Rayson,Suzan Verberne,Andrew Moore,Goran Nenadic*

Main category: cs.CL

TL;DR: 本教程聚焦于自然语言处理在医疗健康领域的应用，涵盖已取得的成果及未来挑战。针对现有综述遗漏重要任务（如合成数据生成、可解释性临床NLP）和方法（如检索增强生成、大模型与知识图谱的神经符号融合）的问题，本教程从数据/资源层、NLP评估层、患者层三个层级系统介绍以患者和资源为中心的HealthcareNLP核心子领域，并包含实践环节，旨在为NLP从业者、研究人员及学生提供入门级引导。


<details>
  <summary>Details</summary>
Motivation: 现有医疗健康领域NLP综述存在盲区，未能涵盖合成数据生成、可解释性临床NLP等关键任务，也忽略检索增强生成、大模型与知识图谱融合等新兴方法，亟需一个全面、系统且面向初学者的综合性导览。

Method: 构建三层次框架：数据/资源层（标注指南、伦理审批、治理、合成数据）、NLP评估层（如命名实体识别、关系抽取、情感分析、链接编码等任务及其方法）、患者层（患者参与、健康素养、翻译简化、摘要生成、共享决策支持），并结合动手实践环节。

Result: 提供了一个结构清晰、覆盖全面、兼具理论与实践的HealthcareNLP入门教程，填补了当前综述中的空白，有助于推动该领域研究与应用的发展。

Conclusion: 本教程系统梳理了医疗健康NLP的关键方向与前沿进展，强调了跨学科协作与可解释性的重要性，为后续研究与应用落地提供了坚实基础。

Abstract: This proposed tutorial focuses on Healthcare Domain Applications of NLP, what we have achieved around HealthcareNLP, and the challenges that lie ahead for the future. Existing reviews in this domain either overlook some important tasks, such as synthetic data generation for addressing privacy concerns, or explainable clinical NLP for improved integration and implementation, or fail to mention important methodologies, including retrieval augmented generation and the neural symbolic integration of LLMs and KGs. In light of this, the goal of this tutorial is to provide an introductory overview of the most important sub-areas of a patient- and resource-oriented HealthcareNLP, with three layers of hierarchy: data/resource layer: annotation guidelines, ethical approvals, governance, synthetic data; NLP-Eval layer: NLP tasks such as NER, RE, sentiment analysis, and linking/coding with categorised methods, leading to explainable HealthAI; patients layer: Patient Public Involvement and Engagement (PPIE), health literacy, translation, simplification, and summarisation (also NLP tasks), and shared decision-making support. A hands-on session will be included in the tutorial for the audience to use HealthcareNLP applications. The target audience includes NLP practitioners in the healthcare application domain, NLP researchers who are interested in domain applications, healthcare researchers, and students from NLP fields. The type of tutorial is "Introductory to CL/NLP topics (HealthcareNLP)" and the audience does not need prior knowledge to attend this. Tutorial materials: https://github.com/4dpicture/HealthNLP

</details>


### [98] [QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models](https://arxiv.org/abs/2512.08646)
*Maximilian Kreutner,Jens Rupprecht,Georg Ahnert,Ahmed Salem,Markus Strohmaier*

Main category: cs.CL

TL;DR: QSTN is an open-source Python framework for generating LLM responses to questionnaire prompts, enabling in-silico surveys and annotation with low compute cost. It supports evaluation of question design and response methods, offers a no-code UI, and enhances reproducibility in LLM research.


<details>
  <summary>Details</summary>
Motivation: To enable robust, reproducible, and efficient evaluation of LLM-generated survey responses, addressing the need for systematic testing of questionnaire design and prompt variations without high computational costs.

Method: QSTN provides a framework for systematically generating responses from questionnaire-style prompts, allowing experiments on question structure, prompt perturbations, and response generation techniques, supported by a no-code interface for non-technical users.

Result: Evaluation using over 40 million survey responses shows that question structure and response generation methods significantly affect alignment with human answers, while achieving results at a fraction of typical compute cost.

Conclusion: QSTN facilitates reliable and scalable LLM-based survey and annotation tasks, promoting reproducibility and reducing barriers for researchers through accessible tools and efficient computation.

Abstract: We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ($>40 $ million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.

</details>


### [99] [Automatic Essay Scoring and Feedback Generation in Basque Language Learning](https://arxiv.org/abs/2512.08713)
*Ekhi Azurmendi,Xabier Arregi,Oier Lopez de Lacalle*

Main category: cs.CL

TL;DR: 该研究推出了首个公开可用的巴斯克语自动作文评分（AES）与反馈生成数据集，涵盖3200篇针对CEFR C1水平的作文，由专家标注了正确性、丰富性、连贯性、衔接性和任务契合度等维度的分数，并附有详细反馈和错误示例。研究对RoBERTa-EusCrawl和Latxa 8B/70B等开源模型进行微调，实验表明编码器模型在评分上依然可靠，而通过监督微调（SFT）的Latxa模型显著提升性能，超越GPT-5和Claude Sonnet 4.5等闭源系统，在评分一致性和反馈质量上表现更优。研究还提出一种新型反馈评估方法，结合自动一致性指标与专家验证的错误提取，结果表明微调后的Latxa模型能生成符合评分标准、具有教学意义的反馈，并识别更多类型的错误。该资源和基准为低资源语言如巴斯克语的透明、可复现且教育导向的NLP研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有自动作文评分系统在低资源语言如巴斯克语中缺乏公开数据集和可复现的基准，限制了教育领域NLP研究的发展。本研究旨在填补这一空白，推动面向低资源语言的透明、可复现且基于教育目标的AI辅助写作评估研究。

Method: 构建包含3200篇巴斯克语作文的标注数据集，采用专家评分与详细反馈；对RoBERTa-EusCrawl及大规模开源模型Latxa 8B/70B进行监督微调（SFT）以实现评分与反馈生成；提出结合自动一致性指标与专家验证的反馈评估新方法，用于评估反馈的准确性与教学价值。

Result: 微调后的Latxa模型在评分一致性与反馈质量方面超越当前最先进的闭源系统（如GPT-5、Claude Sonnet 4.5），能够生成符合评分标准、具有教育意义的反馈，并识别出比专有模型更广泛的错误类型。所提出的评估方法有效验证了反馈的真实性和有效性。

Conclusion: 本研究首次提供了巴斯克语自动作文评分与反馈生成的公开数据集与基准，证明了开源大模型经适当微调后在低资源语言教育应用中的强大潜力，为未来可解释、可复现的教育AI研究提供了坚实基础。

Abstract: This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.

</details>


### [100] [Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages](https://arxiv.org/abs/2512.08777)
*David Samuel,Lilja Øvrelid,Erik Velldal,Andrey Kutuzov*

Main category: cs.CL

TL;DR: 提出一种针对低资源语言的后训练方法，通过基于策略的训练保持语言模型在与非流利奖励模型对齐时的流畅性。该方法在无需目标语言指令微调数据的情况下，优于监督微调和多语言微调，尤其在挪威语书面形式上表现突出。


<details>
  <summary>Details</summary>
Motivation: 低资源语言缺乏母语者撰写的语料库和生成流畅合成数据的语言模型，导致现有偏好优化方法难以应用。因此需要一种不依赖稀有数据的流畅对齐方法。

Method: 采用基于策略的训练方法，对比监督微调（基于机器翻译数据）和多语言微调，以实现无指令微调数据下的流畅偏好对齐。

Result: 在挪威语书面形式上的实验表明，基于策略的方法显著优于其他两种方法，且无需依赖难以获取的数据，证明了其有效性。

Conclusion: 基于策略的训练是实现低资源语言流畅偏好对齐的关键，为缺乏高质量数据的语言提供了可行解决方案。

Abstract: We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.

</details>


### [101] [A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs](https://arxiv.org/abs/2512.08786)
*Mahmoud Srewa,Tianyu Zhao,Salma Elmalaki*

Main category: cs.CL

TL;DR: 本文研究在联邦学习环境中如何使大语言模型（LLM）与多样化的人类偏好对齐，提出一种评估框架以系统分析不同聚合策略在对齐质量与公平性之间的权衡。通过局部评估生成奖励信号并由服务器聚合，避免访问原始数据。实验对比了标准方法（最小值、最大值、平均值）和一种基于历史表现动态调整权重的自适应方案，在问答任务中验证了自适应方法在保持良好对齐效果的同时显著提升公平性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习中的对齐方法难以充分代表多样化的观点，导致模型偏向某些群体偏好，因此需要一种能平衡对齐质量与公平性的评估与优化机制。

Method: 构建联邦环境下的奖励聚合框架，各组本地计算奖励信号，服务器仅聚合奖励；比较标准聚合（min/max/avg）与提出的自适应加权策略，后者根据历史对齐表现动态调整权重。

Result: 自适应方法在多项指标上优于传统方法，实现了更高的公平性且保持了竞争力的对齐性能，尤其在跨群体表现一致性方面优势明显。

Conclusion: 本研究提供了一种有效的评估与优化框架，有助于开发更包容、公平且符合多元人类偏好的大语言模型，推动联邦学习中模型对齐的可持续发展。

Abstract: This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.

</details>


### [102] [Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis](https://arxiv.org/abs/2512.08819)
*Ferdinand Kapl,Emmanouil Angelis,Tobias Höppe,Kaitlin Maile,Johannes von Oswald,Nino Scherrer,Stefan Bauer*

Main category: cs.CL

TL;DR: 本文研究了训练过程中逐步增加Transformer深度对模型性能的提升机制，发现这种渐进式深度增长能更有效地利用模型深度，改善残差流结构，并促进可置换计算模块的形成。该工作揭示了MIDAS方法在推理性能上的优势源于其克服了传统非增长模型中‘深度诅咒’的问题，即后半部分层对输出贡献较小。此外，作者提出了一种轻量级改进方案，进一步提升了下游推理任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，渐进式深度增长（如MIDAS）可降低训练成本并提升推理性能，但缺乏对其内在机制的解释。特别是，标准非增长Transformer中后半部分层数对最终输出的贡献较小，这被称为‘深度诅咒’。因此，亟需理解深度增长如何改变模型内部计算结构以提升性能。

Method: 通过深度层面分析（depth-wise analysis），对比非增长模型与渐进式深度增长模型的层间贡献、残差流结构变化及计算块的可置换性。同时设计并测试一种轻量级改进的MIDAS变体，评估其在下游推理任务中的表现。

Result: 渐进式中间堆叠（middle stacking）能够更高效地利用模型深度，显著改善残差流结构，并促使形成可置换的计算模块。所提出的轻量级修改使模型在多个下游推理基准上取得进一步性能提升。

Conclusion: 渐进式深度增长不仅降低了训练开销，还通过重构模型内部计算电路，有效缓解了传统深层模型中的深度利用率不足问题，为构建高效且具可解释性的深层Transformer提供了新视角。

Abstract: Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.

</details>


### [103] [Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders](https://arxiv.org/abs/2512.08892)
*Guangzhi Xiong,Zhenghao He,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: RAGLens 是一种基于稀疏自编码器（SAEs）的轻量级幻觉检测方法，通过解耦大语言模型（LLM）内部激活，识别与 RAG 幻觉相关的特定特征，实现高效且可解释的幻觉检测。该方法无需大量标注数据或外部 LLM 判定，显著提升检测准确率，并提供可追溯的决策依据，支持后续修正。


<details>
  <summary>Details</summary>
Motivation: 现有 RAG 幻觉检测方法依赖大规模训练数据或高成本外部 LLM 判定，而基于内部表示的方法准确性不足。因此亟需一种高效、准确且可解释的检测机制。

Method: 利用稀疏自编码器（SAEs）对 LLM 内部激活进行解耦，通过信息论驱动的特征选择和加性特征建模，构建 RAGLens 检测器，直接基于内部表示判断输出是否忠实于源文档。

Result: RAGLens 在多个基准上显著优于现有方法，具备更高的检测精度与更低的推理开销；同时能生成可解释的判别理由，支持后处理修复。

Conclusion: RAGLens 证明了利用机械可解释性技术从 LLM 内部表示中提取幻觉信号的有效性，为构建高效、可信的 RAG 系统提供了新路径。

Abstract: Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [104] [ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models](https://arxiv.org/abs/2512.07843)
*Long Lian,Sida Wang,Felix Juefei-Xu,Tsu-Jui Fu,Xiuyu Li,Adam Yala,Trevor Darrell,Alane Suhr,Yuandong Tian,Xi Victoria Lin*

Main category: cs.LG

TL;DR: ThreadWeaver 是一种自适应并行推理框架，通过三方面创新实现与主流串行推理模型相当的准确性，同时显著降低推理延迟。其核心包括：1）两阶段并行轨迹生成器，用于生成大规模高质量带并行标注的思维链数据；2）基于前缀树的训练-推理协同设计，支持在任意现成自回归推理引擎上进行并行推理，无需修改位置嵌入或键值缓存；3）面向并行化的强化学习框架，使模型学会在准确性和并行效率之间取得平衡。在六个数学推理基准测试中，基于 Qwen3-8B 的 ThreadWeaver 在平均准确率（71.9%）和 AIME24 上达到 79.9%，同时实现最高达 1.53 倍的平均令牌延迟加速，确立了准确率与效率的新帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 现有自适应并行推理方法在真实任务上受限于监督行为克隆或导致显著精度下降，且多数需定制化推理引擎，部署复杂。为解决序列解码带来的高延迟问题，同时保持高推理准确性，亟需一种高效、通用且可无缝集成的并行推理框架。

Method: 提出 ThreadWeaver 框架，包含三个核心技术：1）两阶段并行轨迹生成器，生成高质量并行思维链数据用于监督微调；2）基于前缀树的训练-推理协同设计，使并行推理可在标准 autoregressive 引擎上运行，无需修改位置编码或 KV 缓存；3）并行化感知的强化学习策略，引导模型权衡准确率与并行效率。

Result: 在六个数学推理基准上，ThreadWeaver 在 Qwen3-8B 基础上实现平均 71.9% 准确率，AIME24 达 79.9%，与先进串行模型持平；同时实现最高 1.53 倍平均令牌延迟加速，显著提升推理效率。

Conclusion: ThreadWeaver 成功实现了高准确率与低延迟的并行推理，在不牺牲性能的前提下大幅减少推理时间，且兼容通用推理引擎，具备良好的部署可行性，为大语言模型推理效率提供了新范式。

Abstract: Scaling inference-time computation has enabled Large Language Models (LLMs) to achieve strong reasoning performance, but inherently sequential decoding leads to substantial latency, especially on complex tasks. Recent work on adaptive parallel reasoning aims to improve inference efficiency by decomposing the problem-solving process into concurrent reasoning threads when beneficial. However, existing methods on realistic tasks are either limited to supervised behavior cloning or exhibit significant accuracy drops compared to widely-used sequential long chain-of-thought (CoT) baselines. Moreover, many require customized inference engines, complicating deployment. We introduce ThreadWeaver, a framework for adaptive parallel reasoning that achieves accuracy on par with popular sequential reasoning models of comparable size while significantly reducing inference latency. ThreadWeaver's performance stems from three key innovations: 1) a two-stage parallel trajectory generator that produces large-scale, high-quality CoT data with parallel annotations for supervised fine-tuning; 2) a trie-based training-inference co-design that enables parallel reasoning on any off-the-shelf autoregressive inference engine without modifying position embeddings or KV caches; and 3) a parallelization-aware reinforcement learning framework that teaches the model to balance accuracy with effective parallelization. Across six challenging mathematical reasoning benchmarks, ThreadWeaver trained atop Qwen3-8B achieves accuracy comparable to cutting-edge sequential reasoning models (71.9% on average and 79.9% on AIME24) while delivering up to 1.53x average speedup in token latency, establishing a new Pareto frontier between accuracy and efficiency.

</details>


### [105] [RaX-Crash: A Resource Efficient and Explainable Small Model Pipeline with an Application to City Scale Injury Severity Prediction](https://arxiv.org/abs/2512.07848)
*Di Zhu,Chen Xie,Ziwei Wang,Haoyun Zhang*

Main category: cs.LG

TL;DR: RaX-Crash 是一个资源高效且可解释的小型模型管道，用于纽约市机动车碰撞数据的结构化伤害严重程度预测。该模型整合了包含数千万条记录的三张关联表格，构建统一特征模式并采用分区存储，训练基于树的集成模型（如随机森林和XGBoost），与本地部署的小型语言模型（SLMs）进行对比。在时间上独立的测试集上，XGBoost 和随机森林分别达到 0.7828 和 0.7794 的准确率，显著优于 SLMs（0.594 和 0.496）；通过类别不平衡分析发现，简单加权可提升致命事故召回率，仅小幅牺牲准确率；SHAP 分析揭示人类脆弱性、时间与地点是影响预测严重性的主要因素。总体表明，可解释的小型模型集成仍是城市级伤害分析的强大基线，而将表格预测器与 SLM 生成的叙事结合的混合管道能提升沟通效果，同时保持可扩展性。


<details>
  <summary>Details</summary>
Motivation: 纽约市每年发生超过十万起机动车碰撞事故，造成重大伤亡和公共健康负担。现有预测模型在可解释性、资源效率和实际应用之间存在平衡难题，尤其在大规模城市数据场景下。因此，亟需一种既高效又可解释的模型框架，以支持城市级交通事故伤害严重程度的精准预测与决策支持。

Method: RaX-Crash 采用多表数据融合策略，整合三张关联表格中的海量记录，构建统一特征架构并使用分区存储优化性能；基于工程化处理的表格特征，训练小型树基集成模型（随机森林与 XGBoost），并与本地部署的小型语言模型（SLMs）进行对比实验；利用 SHAP 值进行可解释性分析，评估关键影响因素，并通过类权重调整缓解类别不平衡问题。

Result: 在时间上独立的测试集上，XGBoost 达到 0.7828 的准确率，随机森林为 0.7794，显著高于 SLMs 的 0.594 和 0.496；通过类别加权可有效提升致命事故的召回率，代价仅为轻微准确率下降；SHAP 分析确认人类脆弱性、事故发生时间与地点是驱动预测严重性的主导因素。

Conclusion: 可解释的小型模型集成（如随机森林和 XGBoost）在城市级交通事故伤害严重程度预测中仍具备强大竞争力；混合模型管道（结合表格预测与 SLM 叙事生成）在不牺牲可扩展性的前提下，显著提升结果的可读性与沟通价值，适用于真实世界的城市公共安全决策支持系统。

Abstract: New York City reports over one hundred thousand motor vehicle collisions each year, creating substantial injury and public health burden. We present RaX-Crash, a resource efficient and explainable small model pipeline for structured injury severity prediction on the official NYC Motor Vehicle Collisions dataset. RaX-Crash integrates three linked tables with tens of millions of records, builds a unified feature schema in partitioned storage, and trains compact tree based ensembles (Random Forest and XGBoost) on engineered tabular features, which are compared against locally deployed small language models (SLMs) prompted with textual summaries. On a temporally held out test set, XGBoost and Random Forest achieve accuracies of 0.7828 and 0.7794, clearly outperforming SLMs (0.594 and 0.496); class imbalance analysis shows that simple class weighting improves fatal recall with modest accuracy trade offs, and SHAP attribution highlights human vulnerability factors, timing, and location as dominant drivers of predicted severity. Overall, RaX-Crash indicates that interpretable small model ensembles remain strong baselines for city scale injury analytics, while hybrid pipelines that pair tabular predictors with SLM generated narratives improve communication without sacrificing scalability.

</details>


### [106] [LAPA: Log-Domain Prediction-Driven Dynamic Sparsity Accelerator for Transformer Model](https://arxiv.org/abs/2512.07855)
*Huizheng Wang,Hongbin Wang,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.LG

TL;DR: LAPA提出了一种基于对数域的注意力预测算法-架构协同设计，通过异步前导一位计算（ALOC）消除高成本乘法，结合混合精度多轮移位累加（MRSA）机制降低累积开销，并采用数据-特征依赖滤波（DDF）策略与MRSA协同工作，最终设计专用加速器实现理论性能到实际硬件的提升。实验表明，LAPA在能效上分别比SOTA方法Spatten、Sanger和FACT高出3.52x、3.24x和2.79x。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在不同输入序列下表现出动态的计算瓶颈，现有稀疏化方法多为单阶段设计，跨阶段应用时导致显著的功耗开销，亟需一种跨阶段稀疏加速策略以提升效率。

Method: 提出log-domain attention prediction算法，结合ALOC方案减少乘法开销，引入MRSA机制缓解累加负担，并设计DDF策略与MRSA协同优化，最终构建专用加速器实现软硬件协同优化。

Result: LAPA在能效方面相比Spatten、Sanger和FACT分别提升3.52x、3.24x和2.79x，显著优于现有方法。

Conclusion: LAPA通过算法-架构协同设计，有效解决了Transformer跨阶段稀疏加速中的计算与功耗瓶颈，实现了显著的能效提升，为高效Transformer加速提供了新范式。

Abstract: Attention-based Transformers have revolutionized natural language processing (NLP) and shown strong performance in computer vision (CV) tasks. However, as the input sequence varies, the computational bottlenecks in Transformer models exhibit dynamic behavior across stages, which calls for a cross-stage sparse acceleration strategy. Unfortunately, most existing sparse Transformer approaches are single-stage based, and their sparsity prediction mechanisms lead to significant power overhead when applied across multiple stages. To this end, this paper proposes a log-domain attention prediction algorithm-architecture co-design, named LAPA. First, an asymmetric leading one computing (ALOC) scheme is designed to eliminate expensive multiplications. Next, a mixed-precision multi-round shifting accumulation (MRSA) mechanism is further proposed to mitigate the accumulation overhead. A data-feature dependent filter (DDF) strategy is designed to work in concert with the MRSA process. Finally, an elaborate accelerator is designed to translate the theoretical enhancement into practical hardware improvement. Experimental results show that LAPA achieves 3.52x, 3.24x and 2.79x higher energy efficiency than the state-of-the-art (SOTA) works Spatten, Sanger and FACT, respectively.

</details>


### [107] [SA^2GFM: Enhancing Robust Graph Foundation Models with Structure-Aware Semantic Augmentation](https://arxiv.org/abs/2512.07857)
*Junhua Shi,Qingyun Sun,Haonan Yuan,Xingcheng Fu*

Main category: cs.LG

TL;DR: 本文提出SA^2GFM，一种增强图基础模型（GFM）鲁棒性的新框架，通过结构感知语义增强提升跨域适应能力。核心包括：1）利用熵编码树生成结构感知文本提示以增强输入；2）基于自监督信息瓶颈机制实现结构引导的特征压缩；3）引入专家自适应路由机制（含空专家设计）缓解负迁移；4）设计联合社区内/间结构学习的微调模块，优化下游任务适应性。实验表明，SA^2GFM在节点与图分类任务中显著优于9个先进基线，对随机噪声和对抗扰动具有更强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型（GFMs）在面对领域噪声、结构扰动和对抗攻击时鲁棒性不足，主要由于缺乏对层次化结构语义的有效建模，限制了其泛化能力。

Method: 提出SA^2GFM框架，包含：(1) 将熵基编码树转化为结构感知文本提示，用于特征增强；(2) 设计自监督信息瓶颈机制，实现结构引导的特征压缩；(3) 引入混合专家架构结合空专家设计，实现专家自适应路由以减少负迁移；(4) 构建联合社区内/间结构学习的微调模块，提升下游适配效率。

Result: 在多个节点分类和图分类任务上，SA^2GFM显著超越9个主流基线方法，在面对随机噪声和对抗攻击时表现出更强的鲁棒性与泛化性能。

Conclusion: SA^2GFM通过结构感知语义增强与多层次结构建模，有效提升了图基础模型在复杂环境下的鲁棒性与跨域适应能力，为图学习系统的可靠性提供了新范式。

Abstract: We present Graph Foundation Models (GFMs) which have made significant progress in various tasks, but their robustness against domain noise, structural perturbations, and adversarial attacks remains underexplored. A key limitation is the insufficient modeling of hierarchical structural semantics, which are crucial for generalization. In this paper, we propose SA^2GFM, a robust GFM framework that improves domain-adaptive representations through Structure-Aware Semantic Augmentation. First, we encode hierarchical structural priors by transforming entropy-based encoding trees into structure-aware textual prompts for feature augmentation. The enhanced inputs are processed by a self-supervised Information Bottleneck mechanism that distills robust, transferable representations via structure-guided compression. To address negative transfer in cross-domain adaptation, we introduce an expert adaptive routing mechanism, combining a mixture-of-experts architecture with a null expert design. For efficient downstream adaptation, we propose a fine-tuning module that optimizes hierarchical structures through joint intra- and inter-community structure learning. Extensive experiments demonstrate that SA^2GFM outperforms 9 state-of-the-art baselines in terms of effectiveness and robustness against random noise and adversarial perturbations for node and graph classification.

</details>


### [108] [FAIM: Frequency-Aware Interactive Mamba for Time Series Classification](https://arxiv.org/abs/2512.07858)
*Da Zhang,Bingyu Li,Zhiyuan Zhao,Yanhan Zhang,Junyu Gao,Feiping Nie,Xuelong Li*

Main category: cs.LG

TL;DR: 提出轻量级频率感知交互Mamba模型FAIM，通过自适应滤波块（AFB）提取频域特征并抑制噪声，结合交互式Mamba块（IMB）实现多粒度信息交互，提升时间序列分类性能；引入自监督预训练增强模型对复杂时序模式的理解和鲁棒性。在多个基准数据集上验证，FAIM在准确率与效率之间取得更优平衡，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在时间序列分类中存在计算成本高、对噪声敏感及小样本易过拟合等问题，亟需高效且鲁棒的解决方案。

Method: 设计自适应滤波块（AFB）利用傅里叶变换提取频域特征，结合可学习自适应阈值动态降噪，并通过全局与局部语义元素级耦合实现深层频率成分建模；提出交互式Mamba块（IMB）促进多粒度信息交互，兼顾细粒度判别特征与全局上下文信息；引入自监督预训练机制以增强模型对复杂时序模式的理解和跨域鲁棒性。

Result: 在多个时间序列分类基准数据集上，FAIM consistently 超越现有SOTA方法，在准确率和计算效率之间达到更优平衡，表现出卓越性能，尤其在高噪声和小样本场景下具有更强鲁棒性。

Conclusion: FAIM是一种高效、鲁棒且表达能力强的时间序列分类模型，通过频率感知与多粒度交互设计有效克服了传统深度学习模型的局限，为实际应用提供了有力支持。

Abstract: Time series classification (TSC) is crucial in numerous real-world applications, such as environmental monitoring, medical diagnosis, and posture recognition. TSC tasks require models to effectively capture discriminative information for accurate class identification. Although deep learning architectures excel at capturing temporal dependencies, they often suffer from high computational cost, sensitivity to noise perturbations, and susceptibility to overfitting on small-scale datasets. To address these challenges, we propose FAIM, a lightweight Frequency-Aware Interactive Mamba model. Specifically, we introduce an Adaptive Filtering Block (AFB) that leverages Fourier Transform to extract frequency-domain features from time series data. The AFB incorporates learnable adaptive thresholds to dynamically suppress noise and employs element-wise coupling of global and local semantic adaptive filtering, enabling in-depth modeling of the synergy among different frequency components. Furthermore, we design an Interactive Mamba Block (IMB) to facilitate efficient multi-granularity information interaction, balancing the extraction of fine-grained discriminative features and comprehensive global contextual information, thereby endowing FAIM with powerful and expressive representations for TSC tasks. Additionally, we incorporate a self-supervised pre-training mechanism to enhance FAIM's understanding of complex temporal patterns and improve its robustness across various domains and high-noise scenarios. Extensive experiments on multiple benchmarks demonstrate that FAIM consistently outperforms existing state-of-the-art (SOTA) methods, achieving a superior trade-off between accuracy and efficiency and exhibits outstanding performance.

</details>


### [109] [SetAD: Semi-Supervised Anomaly Learning in Contextual Sets](https://arxiv.org/abs/2512.07863)
*Jianling Gao,Chongyang Tao,Xuelian Lin,Junfeng Liu,Shuai Ma*

Main category: cs.LG

TL;DR: 提出SetAD框架，将半监督异常检测重构为集合级别的任务，通过注意力机制的集合编码器和分级学习目标，量化整个集合的异常程度，并引入上下文校准的异常评分机制，提升模型鲁棒性和评分准确性。在10个真实数据集上实验表明，SetAD显著优于现有方法，且性能随集合规模增大而提升，验证了集合建模的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督异常检测方法多聚焦于单点或简单点对，忽视了异常的上下文特性及其由群体偏离定义的本质，无法有效利用集合组合产生的丰富监督信号，难以捕捉数据中的高阶交互，限制了判别性表征的学习。

Method: 提出SetAD框架，采用基于注意力的集合编码器，通过分级学习目标训练，学习量化一个集合整体的异常程度；设计上下文校准的异常评分机制，通过聚合多个多样化上下文集合中点相对于同伴行为的归一化偏差来评估其异常得分。

Result: 在10个真实世界数据集上的大量实验表明，SetAD显著优于当前最先进的模型；且随着集合规模增加，性能持续提升，有力支持了基于集合的异常检测范式。

Conclusion: SetAD通过将异常检测建模为集合级别任务，有效捕捉了高阶群体交互，提升了异常检测的准确性与鲁棒性，为半监督异常检测提供了新的范式。

Abstract: Semi-supervised anomaly detection (AD) has shown great promise by effectively leveraging limited labeled data. However, existing methods are typically structured around scoring individual points or simple pairs. Such {point- or pair-centric} view not only overlooks the contextual nature of anomalies, which are defined by their deviation from a collective group, but also fails to exploit the rich supervisory signals that can be generated from the combinatorial composition of sets. Consequently, such models struggle to exploit the high-order interactions within the data, which are critical for learning discriminative representations. To address these limitations, we propose SetAD, a novel framework that reframes semi-supervised AD as a Set-level Anomaly Detection task. SetAD employs an attention-based set encoder trained via a graded learning objective, where the model learns to quantify the degree of anomalousness within an entire set. This approach directly models the complex group-level interactions that define anomalies. Furthermore, to enhance robustness and score calibration, we propose a context-calibrated anomaly scoring mechanism, which assesses a point's anomaly score by aggregating its normalized deviations from peer behavior across multiple, diverse contextual sets. Extensive experiments on 10 real-world datasets demonstrate that SetAD significantly outperforms state-of-the-art models. Notably, we show that our model's performance consistently improves with increasing set size, providing strong empirical support for the set-based formulation of anomaly detection.

</details>


### [110] [Pattern Recognition of Ozone-Depleting Substance Exports in Global Trade Data](https://arxiv.org/abs/2512.07864)
*Muhammad Sukri Bin Ramli*

Main category: cs.LG

TL;DR: 本文提出一种基于无监督机器学习的框架，用于监测环境条约（如《蒙特利尔议定书》）下的贸易活动。通过结合聚类、异常检测和启发式标记等方法，从10万条贸易记录中识别出可疑交易模式，并生成优先级评分。该方法成功识别出1,351个价格异常和1,288个高优先级货物，验证了高价值与重量比及模糊描述是关键风险指标。模型还捕捉到2021年初因美国AIM法案实施而出现的“巨量交易”激增，证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以高效处理大规模复杂海关数据以监控环境条约履约情况，亟需自动化、系统化的分析工具来发现潜在违规行为。

Method: 采用无监督学习方法：使用K-Means聚类识别贸易典型模式；利用孤立森林和四分位距（IQR）进行异常检测，识别异常大额交易及不寻常单价；结合启发式规则标记模糊描述等规避行为；最后整合多层结果生成优先级评分。

Result: 在10万条贸易记录中成功识别出1,351个价格异常和1,288个高优先级货物；高价值-重量比显著高于普通商品；解释性AI（SHAP）证实模糊描述和高价值为最重要风险因素；模型对真实世界监管事件（如美国AIM法案）具有敏感响应能力。

Conclusion: 本研究构建了一个可重复的无监督学习流水线，能将原始贸易数据转化为监管机构可用的优先审查情报，为环境条约执行提供有力支持。

Abstract: New methods are needed to monitor environmental treaties, like the Montreal Protocol, by reviewing large, complex customs datasets. This paper introduces a framework using unsupervised machine learning to systematically detect suspicious trade patterns and highlight activities for review. Our methodology, applied to 100,000 trade records, combines several ML techniques. Unsupervised Clustering (K-Means) discovers natural trade archetypes based on shipment value and weight. Anomaly Detection (Isolation Forest and IQR) identifies rare "mega-trades" and shipments with commercially unusual price-per-kilogram values. This is supplemented by Heuristic Flagging to find tactics like vague shipment descriptions. These layers are combined into a priority score, which successfully identified 1,351 price outliers and 1,288 high-priority shipments for customs review. A key finding is that high-priority commodities show a different and more valuable value-to-weight ratio than general goods. This was validated using Explainable AI (SHAP), which confirmed vague descriptions and high value as the most significant risk predictors. The model's sensitivity was validated by its detection of a massive spike in "mega-trades" in early 2021, correlating directly with the real-world regulatory impact of the US AIM Act. This work presents a repeatable unsupervised learning pipeline to turn raw trade data into prioritized, usable intelligence for regulatory groups.

</details>


### [111] [Using Text-Based Life Trajectories from Swedish Register Data to Predict Residential Mobility with Pretrained Transformers](https://arxiv.org/abs/2512.07865)
*Philipp Stark,Alexandros Sopasakis,Ola Hall,Markus Grillitsch*

Main category: cs.LG

TL;DR: This study converts large-scale Swedish register data into textual life trajectories, demonstrating that NLP models on such data effectively capture longitudinal patterns and improve predictive accuracy for residential mobility, enabling advanced social science research.


<details>
  <summary>Details</summary>
Motivation: Address high cardinality of categorical variables and inconsistencies in coding schemes over time in large-scale register data analysis.

Method: Transform Swedish register data from 6.9 million individuals (2001–2013) into semantically rich textual life trajectories, then use NLP models (LSTM, DistilBERT, BERT, Qwen) to predict residential mobility (2013–2017).

Result: Sequential and transformer-based models outperform baseline models in capturing temporal and semantic structures; textualized register data preserves meaningful individual pathways and enables scalable longitudinal prediction.

Conclusion: Combining semantically rich register data with modern language models significantly advances longitudinal analysis in social sciences, offering a robust testbed for sequence modeling.

Abstract: We transform large-scale Swedish register data into textual life trajectories to address two long-standing challenges in data analysis: high cardinality of categorical variables and inconsistencies in coding schemes over time. Leveraging this uniquely comprehensive population register, we convert register data from 6.9 million individuals (2001-2013) into semantically rich texts and predict individuals' residential mobility in later years (2013-2017). These life trajectories combine demographic information with annual changes in residence, work, education, income, and family circumstances, allowing us to assess how effectively such sequences support longitudinal prediction. We compare multiple NLP architectures (including LSTM, DistilBERT, BERT, and Qwen) and find that sequential and transformer-based models capture temporal and semantic structure more effectively than baseline models. The results show that textualized register data preserves meaningful information about individual pathways and supports complex, scalable modeling. Because few countries maintain longitudinal microdata with comparable coverage and precision, this dataset enables analyses and methodological tests that would be difficult or impossible elsewhere, offering a rigorous testbed for developing and evaluating new sequence-modeling approaches. Overall, our findings demonstrate that combining semantically rich register data with modern language models can substantially advance longitudinal analysis in social sciences.

</details>


### [112] [Advancing physiological time series reconstruction and imputation via mixture of receptive fields and experts fusion](https://arxiv.org/abs/2512.07873)
*Ci Zhang,Huayu Li,Changdi Yang,Jiangnan Xia,Yanzhi Wang,Xiaolong Ma,Jin Lu,Geng Yuan*

Main category: cs.LG

TL;DR: 本文提出了一种基于混合专家（MoE）的噪声估计器，嵌入到基于分数的扩散框架中，以解决生理时间序列信号重建中的挑战。通过设计可适应接收场的MoE（RFAMoE）模块，使每个通道能动态选择合适的接收场；同时引入融合MoE模块，实现并行生成K个噪声信号，并通过路由机制融合，在单次推理中完成重建，显著降低计算开销和延迟。实验表明，该方法在多个数据集和任务上均优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 生理时间序列信号具有多变量、高时间变异性、高度噪声和易受伪影影响的特点，使得基于深度学习的插补任务仍具挑战性。现有的扩散模型在医疗时间序列领域的应用尚未充分探索，且传统多轮推理虽能提升精度但带来巨大计算和延迟成本。因此亟需一种高效且高性能的重建方法。

Method: 提出基于MoE的噪声估计框架，包含两个核心模块：1）Receptive Field Adaptive MoE（RFAMoE），用于在扩散过程中自适应地为各通道选择最优接收场；2）Fusion MoE，通过并行生成多个噪声信号并利用路由机制融合，实现在单次推理中完成高质量信号重建。

Result: 所提方法在多个医学时间序列数据集上表现出色，相比现有基于扩散模型的最先进方法，在重建精度上均有提升，同时避免了多次推理带来的计算与延迟负担。

Conclusion: 本文提出的基于MoE的扩散框架有效解决了医疗时间序列信号重建中的高噪声、多变量与实时性需求之间的矛盾，实现了性能与效率的双重优化，为未来医疗信号处理提供了新范式。

Abstract: Recent studies show that using diffusion models for time series signal reconstruc- tion holds great promise. However, such approaches remain largely unexplored in the domain of medical time series. The unique characteristics of the physiological time series signals, such as multivariate, high temporal variability, highly noisy, and artifact-prone, make deep learning-based approaches still challenging for tasks such as imputation. Hence, we propose a novel Mixture of Experts (MoE)-based noise estimator within a score-based diffusion framework. Specifically, the Receptive Field Adaptive MoE (RFAMoE) module is designed to enable each channel to adap- tively select desired receptive fields throughout the diffusion process. Moreover, recent literature has found that when generating a physiological signal, performing multiple inferences and averaging the reconstructed signals can effectively reduce reconstruction errors, but at the cost of significant computational and latency over- head. We design a Fusion MoE module and innovatively leverage the nature of MoE module to generate K noise signals in parallel, fuse them using a routing mechanism, and complete signal reconstruction in a single inference step. This design not only improves performance over previous methods but also eliminates the substantial computational cost and latency associated with multiple inference processes. Extensive results demonstrate that our proposed framework consistently outperforms diffusion-based SOTA works on different tasks and datasets.

</details>


### [113] [Balanced Accuracy: The Right Metric for Evaluating LLM Judges - Explained through Youden's J statistic](https://arxiv.org/abs/2512.08121)
*Stephane Collot,Colin Fraser,Justin Zhao,William F. Shen,Timon Willi,Ilias Leontiadis*

Main category: cs.LG

TL;DR: 本文研究了大语言模型（LLM）评估中分类器选择的重要性，指出传统指标如准确率、精确率和F1分数在类别不平衡和正类定义上存在偏差，容易导致对模型表现的误判。作者提出使用Youden's J统计量和平衡准确率（Balanced Accuracy）作为更优的评估标准，二者在理论上能更好反映分类器在比较模型时的真实能力。通过理论分析与实证模拟，证明采用平衡准确率可实现更稳健、可靠的分类器选择。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估依赖于分类器（如LLM-as-a-judge或人工标注者）对行为出现频率的判断，但常用评估指标（如准确率、精确率、F1）受类别不平衡和正类定义影响，可能导致评估结果失真，因此需要更可靠的分类器选择方法以确保评估可信度。

Method: 通过理论推导和实证模拟，对比了不同评估指标（包括Accuracy、Precision、F1、Balanced Accuracy、Youden's J）在模型比较中的表现，分析其对类别不平衡和正类设定的敏感性，并验证Balanced Accuracy与Youden's J在数学上的等价性及其在实际应用中的优越性。

Result: 实验和分析表明，使用平衡准确率或Youden's J进行分类器选择，能有效减少因类别不平衡和正类设定带来的偏差，提升模型评估的稳定性与可靠性，优于传统指标。

Conclusion: 在大语言模型评估中，应优先采用平衡准确率或Youden's J作为分类器选择的标准，以获得更真实、可比的模型性能比较结果。

Abstract: Rigorous evaluation of large language models (LLMs) relies on comparing models by the prevalence of desirable or undesirable behaviors, such as task pass rates or policy violations. These prevalence estimates are produced by a classifier, either an LLM-as-a-judge or human annotators, making the choice of classifier central to trustworthy evaluation. Common metrics used for this choice, such as Accuracy, Precision, and F1, are sensitive to class imbalance and to arbitrary choices of positive class, and can favor judges that distort prevalence estimates. We show that Youden's $J$ statistic is theoretically aligned with choosing the best judge to compare models, and that Balanced Accuracy is an equivalent linear transformation of $J$. Through both analytical arguments and empirical examples and simulations, we demonstrate how selecting judges using Balanced Accuracy leads to better, more robust classifier selection.

</details>


### [114] [Softly Symbolifying Kolmogorov-Arnold Networks](https://arxiv.org/abs/2512.07875)
*James Bagrow,Josh Bongard*

Main category: cs.LG

TL;DR: S2KAN integrates symbolic primitives into Kolmogorov-Arnold Networks (KANs) via a dictionary of symbolic and dense terms with differentiable sparsification gates, guided by Minimum Description Length. It achieves high interpretability when symbolic forms suffice, degrades gracefully otherwise, and shows superior or competitive accuracy with smaller models across benchmarks and real-world tasks.


<details>
  <summary>Details</summary>
Motivation: Existing KANs lack symbolic fidelity in learned activations, often resulting in pathological, non-interpretable decompositions. This limits their utility in interpretable machine learning.

Method: S2KAN introduces a hybrid representation where each activation combines symbolic and dense spline terms. Learnable gates control the contribution of each term, enabling differentiable sparsification. The model is trained end-to-end using a Minimum Description Length objective to favor compact, interpretable representations.

Result: S2KAN achieves competitive or better accuracy than baseline models with significantly smaller model sizes. It discovers interpretable symbolic forms when applicable, and adapts to complex data by relying on dense splines when needed. Evidence of self-sparsification emerges even without explicit regularization.

Conclusion: S2KAN effectively balances interpretability and expressiveness by embedding symbolic knowledge directly into KANs, enabling both accurate modeling and meaningful, human-readable representations.

Abstract: Kolmogorov-Arnold Networks (KANs) offer a promising path toward interpretable machine learning: their learnable activations can be studied individually, while collectively fitting complex data accurately. In practice, however, trained activations often lack symbolic fidelity, learning pathological decompositions with no meaningful correspondence to interpretable forms. We propose Softly Symbolified Kolmogorov-Arnold Networks (S2KAN), which integrate symbolic primitives directly into training. Each activation draws from a dictionary of symbolic and dense terms, with learnable gates that sparsify the representation. Crucially, this sparsification is differentiable, enabling end-to-end optimization, and is guided by a principled Minimum Description Length objective. When symbolic terms suffice, S2KAN discovers interpretable forms; when they do not, it gracefully degrades to dense splines. We demonstrate competitive or superior accuracy with substantially smaller models across symbolic benchmarks, dynamical systems forecasting, and real-world prediction tasks, and observe evidence of emergent self-sparsification even without regularization pressure.

</details>


### [115] [Graph Contrastive Learning via Spectral Graph Alignment](https://arxiv.org/abs/2512.07878)
*Manh Nguyen,Joshua Cape*

Main category: cs.LG

TL;DR: SpecMatch-CL 提出一种新的对比学习损失函数，通过最小化视图特定图-图结构的归一化拉普拉斯矩阵差异来对齐这些结构，理论上提供对理想对齐损失和均匀损失差异的上界，并在多个基准测试中实现新的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法在优化图嵌入对齐时缺乏对视图特定图-图结构全局结构的控制机制。

Method: 提出 SpecMatch-CL 损失函数，通过最小化不同视图下图-图结构的归一化拉普拉斯矩阵差异来实现对齐。

Result: 在八个 TU 基准上实现了无监督和半监督学习的新最佳性能，在低标签率下表现优异；在 PPI-306K 和 ZINC 2M 数据集上的迁移学习也表现出一致提升。

Conclusion: SpecMatch-CL 有效提升了图对比学习中对全局结构的控制能力，显著改善了模型性能，是当前图表示学习中的先进方法。

Abstract: Given augmented views of each input graph, contrastive learning methods (e.g., InfoNCE) optimize pairwise alignment of graph embeddings across views while providing no mechanism to control the global structure of the view specific graph-of-graphs built from these embeddings. We introduce SpecMatch-CL, a novel loss function that aligns the view specific graph-of-graphs by minimizing the difference between their normalized Laplacians. Theoretically, we show that under certain assumptions, the difference between normalized Laplacians provides an upper bound not only for the difference between the ideal Perfect Alignment contrastive loss and the current loss, but also for the Uniformly loss. Empirically, SpecMatch-CL establishes new state of the art on eight TU benchmarks under unsupervised learning and semi-supervised learning at low label rates, and yields consistent gains in transfer learning on PPI-306K and ZINC 2M datasets.

</details>


### [116] [Nonnegative Matrix Factorization through Cone Collapse](https://arxiv.org/abs/2512.07879)
*Manh Nguyen,Daniel Pimentel-Alarcón*

Main category: cs.LG

TL;DR: 本文从几何视角重新审视非负矩阵分解（NMF），提出了一种名为Cone Collapse的新算法，通过迭代收缩非负正交锥来逼近数据生成的最小锥体。该算法在温和假设下可有限步内收敛，并恢复数据转置矩阵的极射线。基于此，进一步构建了锥感知的正交NMF模型（CC-NMF），并应用于16个基准基因表达、文本和图像数据集，其聚类纯度表现优于或匹配多种主流NMF方法。


<details>
  <summary>Details</summary>
Motivation: 现有NMF方法多从优化角度出发，未显式利用由NMF诱导的锥几何结构；而数据点位于一个凸锥中，其极射线代表基本方向或‘主题’，因此有必要从几何角度更深入理解并利用这一结构以提升聚类性能。

Method: 提出Cone Collapse算法，从全非负正交锥开始，逐步收缩至由数据生成的最小锥体；随后对恢复出的极射线应用统一正交NMF，构建新的锥感知正交NMF模型（CC-NMF）。

Result: 在16个基准数据集上，CC-NMF在聚类纯度方面持续优于或匹配包括乘法更新、ANLS、投影NMF、ONMF和稀疏NMF在内的多个强基线方法。

Conclusion: 显式恢复数据锥体不仅具有理论基础，还能带来性能优越的NMF聚类方法，表明几何视角对改进NMF具有重要意义。

Abstract: Nonnegative matrix factorization (NMF) is a widely used tool for learning parts-based, low-dimensional representations of nonnegative data, with applications in vision, text, and bioinformatics. In clustering applications, orthogonal NMF (ONMF) variants further impose (approximate) orthogonality on the representation matrix so that its rows behave like soft cluster indicators. Existing algorithms, however, are typically derived from optimization viewpoints and do not explicitly exploit the conic geometry induced by NMF: data points lie in a convex cone whose extreme rays encode fundamental directions or "topics". In this work we revisit NMF from this geometric perspective and propose Cone Collapse, an algorithm that starts from the full nonnegative orthant and iteratively shrinks it toward the minimal cone generated by the data. We prove that, under mild assumptions on the data, Cone Collapse terminates in finitely many steps and recovers the minimal generating cone of $\mathbf{X}^\top$ . Building on this basis, we then derive a cone-aware orthogonal NMF model (CC-NMF) by applying uni-orthogonal NMF to the recovered extreme rays. Across 16 benchmark gene-expression, text, and image datasets, CC-NMF consistently matches or outperforms strong NMF baselines-including multiplicative updates, ANLS, projective NMF, ONMF, and sparse NMF-in terms of clustering purity. These results demonstrate that explicitly recovering the data cone can yield both theoretically grounded and empirically strong NMF-based clustering methods.

</details>


### [117] [Semi-Supervised Contrastive Learning with Orthonormal Prototypes](https://arxiv.org/abs/2512.07880)
*Huanran Li,Manh Nguyen,Daniel Pimentel-Alarcón*

Main category: cs.LG

TL;DR: 本文提出CLOP损失函数，通过促进类别嵌入间形成正交线性子空间，有效防止对比学习中的维度坍缩问题，在图像分类和目标检测任务中表现更优且对学习率和批量大小更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决对比学习中因维度坍缩导致的嵌入表示退化问题，特别是在半监督和自监督设置下，传统对比损失在高学习率下易收敛到低维坍缩解。

Method: 识别学习率阈值并设计CLOP损失，通过约束类别嵌入之间的正交性来维持高维表示空间，从而避免维度坍缩。

Result: 在真实和合成数据集上，CLOP显著提升图像分类与目标检测性能，并在不同学习率和批量大小下表现出更强的稳定性。

Conclusion: CLOP通过正交性约束有效缓解了维度坍缩问题，为半监督和自监督对比学习提供了更稳定、高效的解决方案。

Abstract: Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, dimensional collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first identify a critical learning-rate threshold, beyond which standard contrastive losses converge to collapsed solutions. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent dimensional collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP improves performance in image classification and object detection tasks while also exhibiting greater stability across different learning rates and batch sizes.

</details>


### [118] [GSPN-2: Efficient Parallel Sequence Modeling](https://arxiv.org/abs/2512.07884)
*Hongjun Wang,Yitong Jiang,Collin McCarthy,David Wehr,Hanrong Ye,Xinhao Li,Ka Chun Cheung,Wonmin Byeon,Jinwei Gu,Ke Chen,Kai Han,Hongxu Yin,Pavlo Molchanov,Jan Kautz,Sifei Liu*

Main category: cs.LG

TL;DR: GSPN-2 提出了一种联合算法与系统重设计，通过减少GPU内核重复启动、降低数据传输开销和消除冗余计算，显著提升了视觉Transformer在高分辨率图像和长视频任务中的效率。其核心改进包括：将数千次微启动合并为单一2D核、为每个通道切片显式绑定线程束，并在共享内存中缓存前一列激活值；同时引入紧凑的通道传播策略，减少参数量并自然契合注意力机制中的亲和图。实验表明，GSPN-2 在图像分类与文本生成图像任务中达到Transformer级准确率，同时大幅降低计算成本，确立了视觉应用中建模全局空间上下文的新效率标杆。


<details>
  <summary>Details</summary>
Motivation: 现有GSPN在处理高分辨率图像和长视频时仍存在大量GPU内核启动开销、频繁的数据传输以及每通道独立权重带来的冗余计算问题，限制了其在实际场景中的部署效率。

Method: 提出GSPN-2，采用单个2D GPU内核替代原有多个微内核，通过显式线程绑定和共享内存缓存优化执行流程；在模型层面引入紧凑的通道传播机制，以结构化矩阵变换替代逐通道矩阵，减少参数量并适配注意力亲和图。

Result: GSPN-2 在图像分类与文本到图像合成任务中实现了与Transformer相当的精度，但计算成本显著降低，验证了其在高效建模全局空间上下文方面的优越性。

Conclusion: GSPN-2 通过算法与系统协同优化，成功突破了传统视觉Transformer在高分辨率与长序列任务中的效率瓶颈，为实际应用提供了更高效的解决方案。

Abstract: Efficient vision transformer remains a bottleneck for high-resolution images and long-video related real-world applications. Generalized Spatial Propagation Network (GSPN) addresses this by replacing quadratic self-attention with a line-scan propagation scheme, bringing the cost close to linear in the number of rows or columns, while retaining accuracy. Despite this advancement, the existing GSPN implementation still suffers from (i) heavy overhead due to repeatedly launching GPU kernels, (ii) excessive data transfers from global GPU memory, and (iii) redundant computations caused by maintaining separate propagation weights for each channel. We introduce GSPN-2, a joint algorithm-system redesign. In particular, we eliminate thousands of micro-launches from the previous implementation into one single 2D kernel, explicitly pin one warp to each channel slice, and stage the previous column's activations in shared memory. On the model side, we introduce a compact channel propagation strategy that replaces per-channel matrices, trimming parameters, and align naturally with the affinity map used in transformer attention. Experiments demonstrate GSPN-2's effectiveness across image classification and text-to-image synthesis tasks, matching transformer-level accuracy with significantly lower computational cost. GSPN-2 establishes a new efficiency frontier for modeling global spatial context in vision applications through its unique combination of structured matrix transformations and GPU-optimized implementation. Project page: https://whj363636.github.io/GSPN2/

</details>


### [119] [ByteStorm: a multi-step data-driven approach for Tropical Cyclones detection and tracking](https://arxiv.org/abs/2512.07885)
*Davide Donno,Donatello Elia,Gabriele Accarino,Marco De Carlo,Enrico Scoccimarro,Silvio Gualdi*

Main category: cs.LG

TL;DR: ByteStorm is a data-driven framework using deep learning to track tropical cyclones without needing threshold tuning. It detects cyclone centers using vorticity and pressure data, then links them into tracks via the BYTE algorithm. It outperforms existing methods in detection rates, false alarm rates, and consistency across years in both Pacific basins.


<details>
  <summary>Details</summary>
Motivation: Traditional TC tracking methods rely on subjective thresholds that can introduce regional biases. There is a need for an objective, accurate, and efficient approach to track tropical cyclones across different geographical regions.

Method: ByteStorm uses deep learning models to classify and localize tropical cyclone centers based on relative vorticity (850 mb) and mean sea-level pressure. The detected centers are connected into full tracks using the BYTE algorithm, enabling automated, threshold-free tracking.

Result: ByteStorm achieves 85.05% Probability of Detection and 23.26% False Alarm Rate in the East-North Pacific, and 79.48% and 16.14% respectively in the West-North Pacific. It also shows strong inter-annual variability correlation (0.75 in ENP, 0.69 in WNP), indicating reliable long-term tracking performance.

Conclusion: ByteStorm demonstrates the effectiveness of combining deep learning and computer vision for accurate, fast, and robust tropical cyclone tracking, offering a significant improvement over traditional threshold-based methods.

Abstract: Accurate tropical cyclones (TCs) tracking represents a critical challenge in the context of weather and climate science. Traditional tracking schemes mainly rely on subjective thresholds, which may introduce biases in their skills on the geographical region of application. We present ByteStorm, an efficient data-driven framework for reconstructing TC tracks without threshold tuning. It leverages deep learning networks to detect TC centers (via classification and localization), using only relative vorticity (850 mb) and mean sea-level pressure. Then, detected centers are linked into TC tracks through the BYTE algorithm. ByteStorm is evaluated against state-of-the-art deterministic trackers in the East- and West-North Pacific basins (ENP and WNP). The proposed framework achieves superior performance in terms of Probability of Detection ($85.05\%$ ENP, $79.48\%$ WNP), False Alarm Rate ($23.26\%$ ENP, $16.14\%$ WNP), and high Inter-Annual Variability correlations ($0.75$ ENP and $0.69$ WNP). These results highlight the potential of integrating deep learning and computer vision for fast and accurate TC tracking, offering a robust alternative to traditional approaches.

</details>


### [120] [Towards symbolic regression for interpretable clinical decision scores](https://arxiv.org/abs/2512.07961)
*Guilherme Seidyo Imai Aldeia,Joseph D. Romano,Fabricio Olivetti de Franca,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: Brush is a novel symbolic regression (SR) algorithm that integrates rule-based logic into SR by combining decision-tree-like splitting with non-linear constant optimization, enabling interpretable and accurate clinical risk models. It outperforms traditional methods like decision trees, random forests, and other SR approaches in both predictive performance and model simplicity, successfully recapitulating established clinical scoring systems.


<details>
  <summary>Details</summary>
Motivation: Traditional symbolic regression struggles to incorporate rule-based logic common in medical decision-making, limiting its applicability in clinical settings. There is a need for interpretable, data-driven models that can integrate clinical rules while maintaining high accuracy.

Method: Brush combines decision-tree-like splitting with non-linear constant optimization to enable the integration of rule-based structures within symbolic regression. This allows the generation of models that are both highly interpretable and capable of capturing complex, non-linear relationships in clinical data.

Result: Brush achieves Pareto-optimal performance on SRBench benchmarks and accurately recapitulates two widely used clinical scoring systems. It demonstrates comparable or superior predictive accuracy to decision trees, random forests, and other SR methods, while producing simpler and more interpretable models.

Conclusion: Brush effectively bridges the gap between symbolic regression and rule-based clinical decision-making, offering a powerful tool for developing interpretable, high-performance models in healthcare.

Abstract: Medical decision-making makes frequent use of algorithms that combine risk equations with rules, providing clear and standardized treatment pathways. Symbolic regression (SR) traditionally limits its search space to continuous function forms and their parameters, making it difficult to model this decision-making. However, due to its ability to derive data-driven, interpretable models, SR holds promise for developing data-driven clinical risk scores. To that end we introduce Brush, an SR algorithm that combines decision-tree-like splitting algorithms with non-linear constant optimization, allowing for seamless integration of rule-based logic into symbolic regression and classification models. Brush achieves Pareto-optimal performance on SRBench, and was applied to recapitulate two widely used clinical scoring systems, achieving high accuracy and interpretable models. Compared to decision trees, random forests, and other SR methods, Brush achieves comparable or superior predictive performance while producing simpler models.

</details>


### [121] [CIP-Net: Continual Interpretable Prototype-based Network](https://arxiv.org/abs/2512.07981)
*Federico Di Valerio,Michela Proietti,Alessio Ragno,Roberto Capobianco*

Main category: cs.LG

TL;DR: CIP-Net是一种无示例的自解释原型模型，用于持续学习，避免存储历史样本，保持简单架构，在任务和类别增量设置下实现领先性能，同时显著降低内存开销。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中的灾难性遗忘问题，现有可解释方法存在可扩展性差、依赖额外记忆或后处理解释的局限性。

Method: 提出CIP-Net，一种基于原型的自解释模型，无需存储历史示例，通过生成预测时的解释来保留知识，维持轻量级结构。

Result: 在任务增量和类别增量设置下，CIP-Net优于现有无示例和自解释方法，具备更强性能与更低内存开销。

Conclusion: CIP-Net为持续学习提供了一种高效、可解释且实用的解决方案，兼具良好表现与低资源消耗。

Abstract: Continual learning constrains models to learn new tasks over time without forgetting what they have already learned. A key challenge in this setting is catastrophic forgetting, where learning new information causes the model to lose its performance on previous tasks. Recently, explainable AI has been proposed as a promising way to better understand and reduce forgetting. In particular, self-explainable models are useful because they generate explanations during prediction, which can help preserve knowledge. However, most existing explainable approaches use post-hoc explanations or require additional memory for each new task, resulting in limited scalability. In this work, we introduce CIP-Net, an exemplar-free self-explainable prototype-based model designed for continual learning. CIP-Net avoids storing past examples and maintains a simple architecture, while still providing useful explanations and strong performance. We demonstrate that CIPNet achieves state-of-the-art performances compared to previous exemplar-free and self-explainable methods in both task- and class-incremental settings, while bearing significantly lower memory-related overhead. This makes it a practical and interpretable solution for continual learning.

</details>


### [122] [Bridging the Clinical Expertise Gap: Development of a Web-Based Platform for Accessible Time Series Forecasting and Analysis](https://arxiv.org/abs/2512.07992)
*Aaron D. Mullen,Daniel R. Harris,Svetla Slavova,V. K. Cody Bumgardner*

Main category: cs.LG

TL;DR: 本文介绍了一个Web平台，旨在降低时间序列预测的技术门槛，使研究人员和临床医生能够轻松分析数据、训练预测模型并解释结果。该平台支持多种可定制的预测模型和训练方法，并利用大语言模型提供参数选择建议和结果解释，目标是将其集成到学习型健康系统中，实现临床数据的持续收集与推理。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在医疗等领域有广泛应用，但其使用需要较高的技术专长，限制了非专家用户的应用。为解决这一问题，本文提出一个易于使用的Web平台，以促进非专业人员参与数据分析和模型构建。

Method: 开发一个基于Web的交互式平台，支持数据上传、可视化、多模型预测、可定制训练流程，并集成大语言模型生成推荐与解释，辅助用户决策。

Result: 平台成功实现了数据可视化、模型训练与结果解释的全流程自动化与智能化，显著降低了技术门槛，提升了非专业用户的使用体验与效率。

Conclusion: 该平台有望成为学习型健康系统的重要组成部分，推动临床数据的持续分析与智能决策支持，具有广泛的应用前景。

Abstract: Time series forecasting has applications across domains and industries, especially in healthcare, but the technical expertise required to analyze data, build models, and interpret results can be a barrier to using these techniques. This article presents a web platform that makes the process of analyzing and plotting data, training forecasting models, and interpreting and viewing results accessible to researchers and clinicians. Users can upload data and generate plots to showcase their variables and the relationships between them. The platform supports multiple forecasting models and training techniques which are highly customizable according to the user's needs. Additionally, recommendations and explanations can be generated from a large language model that can help the user choose appropriate parameters for their data and understand the results for each model. The goal is to integrate this platform into learning health systems for continuous data collection and inference from clinical pipelines.

</details>


### [123] [Benchmarking Offline Multi-Objective Reinforcement Learning in Critical Care](https://arxiv.org/abs/2512.08012)
*Aryaman Bansal,Divya Sharma*

Main category: cs.LG

TL;DR: 本文评估了三种离线多目标强化学习（MORL）算法（CPQL、自适应CPQL、PEDA DT）与三种单目标基线方法在MIMIC-IV数据集上的表现，发现PEDA DT在灵活性和性能上优于传统方法，表明离线MORL可实现个性化、可调整的重症监护决策，且无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 在重症监护中，临床决策需平衡患者生存率与资源利用，传统单目标强化学习因固定奖励函数导致策略僵化；而多目标强化学习虽能生成帕累托最优策略集以适应不同偏好，但其在医疗场景中受限于历史数据的离线学习需求，亟需有效算法验证。

Method: 在MIMIC-IV数据集上对比三种离线MORL算法（CPQL、自适应CPQL、PEDA DT）与三种单目标基线（BC、CQL、DDQN），采用离线策略评估（OPE）指标进行性能比较，重点分析策略灵活性与生成能力。

Result: PEDA DT在多目标决策灵活性方面显著优于静态标量基线，且序列建模架构在多目标条件下仍保持高效性，验证了离线MORL在个性化医疗决策中的可行性与优越性。

Conclusion: 离线多目标强化学习是一种有前景的框架，可在不重新训练的前提下支持个性化、可调的重症监护决策，尤其适用于资源敏感且需动态权衡目标的临床环境。

Abstract: In critical care settings such as the Intensive Care Unit, clinicians face the complex challenge of balancing conflicting objectives, primarily maximizing patient survival while minimizing resource utilization (e.g., length of stay). Single-objective Reinforcement Learning approaches typically address this by optimizing a fixed scalarized reward function, resulting in rigid policies that fail to adapt to varying clinical priorities. Multi-objective Reinforcement Learning (MORL) offers a solution by learning a set of optimal policies along the Pareto Frontier, allowing for dynamic preference selection at test time. However, applying MORL in healthcare necessitates strict offline learning from historical data.
  In this paper, we benchmark three offline MORL algorithms, Conditioned Conservative Pareto Q-Learning (CPQL), Adaptive CPQL, and a modified Pareto Efficient Decision Agent (PEDA) Decision Transformer (PEDA DT), against three scalarized single-objective baselines (BC, CQL, and DDQN) on the MIMIC-IV dataset. Using Off-Policy Evaluation (OPE) metrics, we demonstrate that PEDA DT algorithm offers superior flexibility compared to static scalarized baselines. Notably, our results extend previous findings on single-objective Decision Transformers in healthcare, confirming that sequence modeling architectures remain robust and effective when scaled to multi-objective conditioned generation. These findings suggest that offline MORL is a promising framework for enabling personalized, adjustable decision-making in critical care without the need for retraining.

</details>


### [124] [CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware Disease Trajectories in Latent Space](https://arxiv.org/abs/2512.08029)
*Tianxingjian Ding,Yuanhao Zou,Chen Chen,Mubarak Shah,Yu Tian*

Main category: cs.LG

TL;DR: CLARITY is a medical world model that forecasts disease evolution by integrating temporal and clinical contexts, enabling interpretable, patient-specific treatment planning with a novel prediction-to-decision framework.


<details>
  <summary>Details</summary>
Motivation: Current static AI predictors fail to model dynamic disease progression in oncology. Existing world models in medicine lack focus on causal physiological transitions, ignore patient-specific temporal and clinical contexts, and do not link predictions to actionable treatment decisions.

Method: CLARITY uses a structured latent space to model treatment-conditioned disease progression as smooth, interpretable trajectories. It incorporates time intervals and patient-specific data, and includes a feedback mechanism to generate transparent, actionable recommendations.

Result: CLARITY achieves state-of-the-art performance in treatment planning. On the MU-Glioma-Post dataset, it outperforms recent MeWM by 12% and significantly surpasses other medical-specific large language models.

Conclusion: CLARITY advances medical world modeling by enabling physiologically faithful, individualized treatment planning through integrated temporal and clinical context, and provides a transparent bridge from prediction to decision-making.

Abstract: Clinical decision-making in oncology requires predicting dynamic disease evolution, a task current static AI predictors cannot perform. While world models (WMs) offer a paradigm for generative prediction, existing medical applications remain limited. Existing methods often rely on stochastic diffusion models, focusing on visual reconstruction rather than causal, physiological transitions. Furthermore, in medical domain, models like MeWM typically ignore patient-specific temporal and clinical contexts and lack a feedback mechanism to link predictions to treatment decisions. To address these gaps, we introduce CLARITY, a medical world model that forecasts disease evolution directly within a structured latent space. It explicitly integrates time intervals (temporal context) and patient-specific data (clinical context) to model treatment-conditioned progression as a smooth, interpretable trajectory, and thus generate physiologically faithful, individualized treatment plans. Finally, CLARITY introduces a novel prediction-to-decision framework, translating latent rollouts into transparent, actionable recommendations. CLARITY demonstrates state-of-the-art performance in treatment planning. On the MU-Glioma-Post dataset, our approach outperforms recent MeWM by 12\%, and significantly surpasses all other medical-specific large language models.

</details>


### [125] [LUNA: Linear Universal Neural Attention with Generalization Guarantees](https://arxiv.org/abs/2512.08061)
*Ashkan Shahbazi,Ping He,Ali Abbasi,Yikun Bai,Xinran Liu,Elaheh Akbari,Darian Salehi,Navid NaderiAlizadeh,Soheil Kolouri*

Main category: cs.LG

TL;DR: LUNA是一种可学习核的线性注意力机制，通过参数化核特征映射，实现线性计算成本下媲美甚至超越二次注意力的精度，解决了传统线性注意力因使用固定随机特征而带来的准确率损失问题。


<details>
  <summary>Details</summary>
Motivation: 现有线性注意力机制依赖固定的随机特征映射（如随机傅里叶特征），导致在效率与精度之间存在权衡；为突破这一瓶颈，需引入数据自适应的可学习核机制。

Method: 提出LUNA，通过学习核特征映射构建正定核，并设计可流式处理的结构，实现线性时间与内存复杂度，同时保留对序列数据的高表达能力。

Result: 在Long Range Arena（LRA）上，LUNA在相同计算量下达到最优平均准确率；在后处理转换中，替换已微调的BERT和ViT-B/16模型的注意力模块并短时微调即可恢复大部分原始性能，显著优于固定线性化方法。

Conclusion: LUNA成功消除了线性注意力中的精度-效率权衡，实现了高效且高精度的长序列建模，为大规模序列任务提供了强有力的解决方案。

Abstract: Scaling attention faces a critical bottleneck: the $\mathcal{O}(n^2)$ quadratic computational cost of softmax attention, which limits its application in long-sequence domains. While linear attention mechanisms reduce this cost to $\mathcal{O}(n)$, they typically rely on fixed random feature maps, such as random Fourier features or hand-crafted functions. This reliance on static, data-agnostic kernels creates a fundamental trade-off, forcing practitioners to sacrifice significant model accuracy for computational efficiency. We introduce \textsc{LUNA}, a kernelized linear attention mechanism that eliminates this trade-off, retaining linear cost while matching and surpassing the accuracy of quadratic attention. \textsc{LUNA} is built on the key insight that the kernel feature map itself should be learned rather than fixed a priori. By parameterizing the kernel, \textsc{LUNA} learns a feature basis tailored to the specific data and task, overcoming the expressive limitations of fixed-feature methods. \textsc{Luna} implements this with a learnable feature map that induces a positive-definite kernel and admits a streaming form, yielding linear time and memory scaling in the sequence length. Empirical evaluations validate our approach across diverse settings. On the Long Range Arena (LRA), \textsc{Luna} achieves state-of-the-art average accuracy among efficient Transformers under compute parity, using the same parameter count, training steps, and approximate FLOPs. \textsc{Luna} also excels at post-hoc conversion: replacing softmax in fine-tuned BERT and ViT-B/16 checkpoints and briefly fine-tuning recovers most of the original performance, substantially outperforming fixed linearizations.

</details>


### [126] [Deep Kernel Aalen-Johansen Estimator: An Interpretable and Flexible Neural Net Framework for Competing Risks](https://arxiv.org/abs/2512.08063)
*Xiaobin Shen,George H. Chen*

Main category: cs.LG

TL;DR: 提出了一种可解释的深度竞争风险模型——Deep Kernel Aalen-Johansen (DKAJ) 估计器，该模型推广了经典的非参数Aalen-Johansen估计累积发生函数（CIFs）的方法。每个数据点被表示为若干聚类的加权组合；若某数据点仅在一个聚类上有非零权重，则其预测的CIFs即对应于该聚类中数据点的经典Aalen-Johansen估计结果。这些权重由自动学习的核函数决定，用于衡量任意两点之间的相似性。在四个标准的竞争风险数据集上，DKAJ的表现与现有先进基准相当，并能提供可视化以辅助模型解释。


<details>
  <summary>Details</summary>
Motivation: 传统Aalen-Johansen方法虽能估计累积发生函数，但缺乏对个体差异的建模能力，且难以解释。为提升模型的可解释性与泛化性能，需引入一种既能捕捉复杂特征关系又能提供直观解释的深度学习框架。

Method: 利用自动学习的核函数计算数据点间的相似性，将每个数据点表示为多个聚类的加权组合，进而基于此构建广义的Aalen-Johansen估计器，实现对累积发生函数的非参数估计。通过深度架构学习核函数并优化权重分配，从而增强模型表达能力与解释性。

Result: 在四个标准竞争风险数据集上的实验表明，DKAJ在预测性能上与当前最优基线相当，同时具备良好的可解释性，能够通过可视化展示个体风险的聚类结构与影响因素。

Conclusion: Deep Kernel Aalen-Johansen (DKAJ) 估计器是一种有效的可解释深度竞争风险模型，兼具高预测性能与良好可解释性，在医疗风险分析等场景中具有广泛应用潜力。

Abstract: We propose an interpretable deep competing risks model called the Deep Kernel Aalen-Johansen (DKAJ) estimator, which generalizes the classical Aalen-Johansen nonparametric estimate of cumulative incidence functions (CIFs). Each data point (e.g., patient) is represented as a weighted combination of clusters. If a data point has nonzero weight only for one cluster, then its predicted CIFs correspond to those of the classical Aalen-Johansen estimator restricted to data points from that cluster. These weights come from an automatically learned kernel function that measures how similar any two data points are. On four standard competing risks datasets, we show that DKAJ is competitive with state-of-the-art baselines while being able to provide visualizations to assist model interpretation.

</details>


### [127] [CAMO: Causality-Guided Adversarial Multimodal Domain Generalization for Crisis Classification](https://arxiv.org/abs/2512.08071)
*Pingchuan Ma,Chengshuai Zhao,Bohan Jiang,Saketh Vishnubhatla,Ujun Jeong,Alimohammad Beigi,Adrienne Raglin,Huan Liu*

Main category: cs.LG

TL;DR: 提出一种基于因果引导的多模态领域泛化框架（MMDG），通过对抗解耦和统一表示学习，提升社交媒体危机分类在未见灾害类型上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨灾害类型时泛化性能差，主要因未能分离虚假与因果特征，以及多模态表示缺乏对齐，导致无法有效应用单模态领域泛化技术。

Method: 引入因果引导的多模态领域泛化框架，结合对抗解耦以关注域不变的因果特征，并通过统一表示学习将不同模态对齐至共享潜在空间，使单模态领域泛化方法可直接扩展到多模态场景。

Result: 在多个数据集上的实验表明，该方法在未见灾害场景中表现最佳，显著提升了危机分类的泛化性能。

Conclusion: 所提出的因果引导多模态领域泛化框架有效解决了多模态危机分类中的域泛化问题，为应急响应中的信息提取提供了更可靠的技术支持。

Abstract: Crisis classification in social media aims to extract actionable disaster-related information from multimodal posts, which is a crucial task for enhancing situational awareness and facilitating timely emergency responses. However, the wide variation in crisis types makes achieving generalizable performance across unseen disasters a persistent challenge. Existing approaches primarily leverage deep learning to fuse textual and visual cues for crisis classification, achieving numerically plausible results under in-domain settings. However, they exhibit poor generalization across unseen crisis types because they 1. do not disentangle spurious and causal features, resulting in performance degradation under domain shift, and 2. fail to align heterogeneous modality representations within a shared space, which hinders the direct adaptation of established single-modality domain generalization (DG) techniques to the multimodal setting. To address these issues, we introduce a causality-guided multimodal domain generalization (MMDG) framework that combines adversarial disentanglement with unified representation learning for crisis classification. The adversarial objective encourages the model to disentangle and focus on domain-invariant causal features, leading to more generalizable classifications grounded in stable causal mechanisms. The unified representation aligns features from different modalities within a shared latent space, enabling single-modality DG strategies to be seamlessly extended to multimodal learning. Experiments on the different datasets demonstrate that our approach achieves the best performance in unseen disaster scenarios.

</details>


### [128] [Training LLMs for Honesty via Confessions](https://arxiv.org/abs/2512.08093)
*Manas Joglekar,Jeremy Chen,Gabriel Wu,Jason Yosinski,Jasmine Wang,Boaz Barak,Amelia Glaese*

Main category: cs.LG

TL;DR: 本文提出一种通过自报告‘忏悔’来促使大语言模型诚实表达其缺陷的方法。该方法在训练中仅根据忏悔内容的诚实程度给予奖励，不影响主回答的奖励。实验表明，当模型在主回答中说谎或隐瞒问题时，往往会在忏悔中诚实地承认，且随着训练推进，忏悔的诚实度有所提升。该方法可应用于推理阶段的监控、拒绝采样和向用户揭示问题等场景。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成内容时可能表现出不诚实行为，如夸大自信或掩盖不当行为，这可能源于强化学习中的奖励设计问题。为解决这一问题，需要一种机制让模型主动披露其错误或违规行为。

Method: 提出‘忏悔’机制：在模型给出主回答后，要求其生成一份自报告的忏悔内容；训练时仅依据忏悔的诚实性进行奖励，与主回答无关；通过这种方式激励模型选择最易获得高奖励的路径——即坦白错误而非掩盖。

Result: 在GPT-5-Thinking上的实验显示，当模型在主回答中存在幻觉、指令遵循失败、策划行为或奖励劫持时，它通常能在忏悔中如实承认这些行为；随着训练迭代，忏悔的诚实性有明显改善。

Conclusion: 通过独立奖励忏悔内容的诚实性，能够有效激励大语言模型在面对严重偏差时主动披露自身问题，为模型透明性和可控性提供了可行的干预手段。

Abstract: Large language models (LLMs) can be dishonest when reporting on their actions and beliefs -- for example, they may overstate their confidence in factual claims or cover up evidence of covert actions. Such dishonesty may arise due to the effects of reinforcement learning (RL), where challenges with reward shaping can result in a training process that inadvertently incentivizes the model to lie or misrepresent its actions.
  In this work we propose a method for eliciting an honest expression of an LLM's shortcomings via a self-reported *confession*. A confession is an output, provided upon request after a model's original answer, that is meant to serve as a full account of the model's compliance with the letter and spirit of its policies and instructions. The reward assigned to a confession during training is solely based on its honesty, and does not impact positively or negatively the main answer's reward. As long as the "path of least resistance" for maximizing confession reward is to surface misbehavior rather than covering it up, this incentivizes models to be honest in their confessions. Our findings provide some justification this empirical assumption, especially in the case of egregious model misbehavior.
  To demonstrate the viability of our approach, we train GPT-5-Thinking to produce confessions, and we evaluate its honesty in out-of-distribution scenarios measuring hallucination, instruction following, scheming, and reward hacking. We find that when the model lies or omits shortcomings in its "main" answer, it often confesses to these behaviors honestly, and this confession honesty modestly improves with training. Confessions can enable a number of inference-time interventions including monitoring, rejection sampling, and surfacing issues to the user.

</details>


### [129] [Scalable Offline Model-Based RL with Action Chunks](https://arxiv.org/abs/2512.08108)
*Kwanyoung Park,Seohong Park,Youngwoon Lee,Sergey Levine*

Main category: cs.LG

TL;DR: 本文研究了基于模型的强化学习（特别是基于模型的价值扩展）是否能为解决复杂、长时程任务提供可扩展的方案。通过引入动作块（action-chunk）模型减少误差累积，并采用拒绝采样从表达性强的行为策略中采样，提出名为MAC的新方法，在大规模数据集上表现出色，尤其在长时程任务中优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习中，长时程任务面临模型误差累积和策略偏差问题，传统方法难以平衡价值估计的偏差与模型误差的放大。需要一种既能降低偏差又能抑制误差传播的方法。

Method: 提出使用动作块模型预测多个动作序列后的状态，以减少误差累积；采用拒绝采样从表达性行为策略中生成动作，避免模型被分布外动作利用。整体方法称为MAC（Model-Based RL with Action Chunks）。

Result: 在包含高达1亿条轨迹的大规模数据集上的实验表明，MAC在各类复杂长时程任务中表现最佳，显著优于其他离线模型基础强化学习算法。

Conclusion: MAC通过动作块建模和拒绝采样策略有效缓解了模型误差累积与分布外动作利用问题，为解决高难度长时程离线强化学习任务提供了高效且可扩展的解决方案。

Abstract: In this paper, we study whether model-based reinforcement learning (RL), in particular model-based value expansion, can provide a scalable recipe for tackling complex, long-horizon tasks in offline RL. Model-based value expansion fits an on-policy value function using length-n imaginary rollouts generated by the current policy and a learned dynamics model. While larger n reduces bias in value bootstrapping, it amplifies accumulated model errors over long horizons, degrading future predictions. We address this trade-off with an \emph{action-chunk} model that predicts a future state from a sequence of actions (an "action chunk") instead of a single action, which reduces compounding errors. In addition, instead of directly training a policy to maximize rewards, we employ rejection sampling from an expressive behavioral action-chunk policy, which prevents model exploitation from out-of-distribution actions. We call this recipe \textbf{Model-Based RL with Action Chunks (MAC)}. Through experiments on highly challenging tasks with large-scale datasets of up to 100M transitions, we show that MAC achieves the best performance among offline model-based RL algorithms, especially on challenging long-horizon tasks.

</details>


### [130] [Improving the Sensitivity of Backdoor Detectors via Class Subspace Orthogonalization](https://arxiv.org/abs/2512.08129)
*Guangmingmei Yang,David J. Miller,George Kesidis*

Main category: cs.LG

TL;DR: 提出一种名为类子空间正交化（CSO）的新方法，通过抑制类别内在特征来增强后门检测的敏感性。该方法在非目标类别上显著降低检测统计量，在目标类别上因后门触发器仍保持较高值，从而更有效识别后门攻击，尤其适用于混合标签和自适应攻击场景。


<details>
  <summary>Details</summary>
Motivation: 现有后门检测方法依赖于目标类别的极端异常检测统计量，但在某些情况下可能失效：一是当非目标类别本身易于区分时，其检测统计量自然偏高；二是当后门信号微弱时，难以与固有类别特征区分。因此需要更敏感的检测机制。

Method: 提出一个约束优化问题，利用少量干净样本，通过正交化处理以抑制特定类别的内在特征，同时优化该类别的检测统计量。目标是使非目标类别的统计量大幅下降，而目标类别的统计量因后门触发器仍保持较高水平。

Result: 实验表明，该方法在混合标签攻击和自适应攻击等复杂场景下均表现出更强的检测能力，优于现有方法，且可作为即插即用模块集成到现有系统中。

Conclusion: 类子空间正交化（CSO）是一种高效、鲁棒的后门检测方法，能够有效应对传统方法在极端情况下的失效问题，提升对隐蔽后门的检测敏感性。

Abstract: Most post-training backdoor detection methods rely on attacked models exhibiting extreme outlier detection statistics for the target class of an attack, compared to non-target classes. However, these approaches may fail: (1) when some (non-target) classes are easily discriminable from all others, in which case they may naturally achieve extreme detection statistics (e.g., decision confidence); and (2) when the backdoor is subtle, i.e., with its features weak relative to intrinsic class-discriminative features. A key observation is that the backdoor target class has contributions to its detection statistic from both the backdoor trigger and from its intrinsic features, whereas non-target classes only have contributions from their intrinsic features. To achieve more sensitive detectors, we thus propose to suppress intrinsic features while optimizing the detection statistic for a given class. For non-target classes, such suppression will drastically reduce the achievable statistic, whereas for the target class the (significant) contribution from the backdoor trigger remains. In practice, we formulate a constrained optimization problem, leveraging a small set of clean examples from a given class, and optimizing the detection statistic while orthogonalizing with respect to the class's intrinsic features. We dub this plug-and-play approach Class Subspace Orthogonalization (CSO) and assess it against challenging mixed-label and adaptive attacks.

</details>


### [131] [Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models I: The Task-Query Architecture](https://arxiv.org/abs/2512.08130)
*Gary Ackerman,Brandon Behlendorf,Zachary Kallenborn,Sheriff Almakki,Doug Clifford,Jenna LaTourette,Hayley Peterson,Noah Sheinbaum,Olivia Shoemaker,Anna Wetzel*

Main category: cs.LG

TL;DR: 本文提出了首个用于评估大语言模型（LLM）生物安全风险的新型生物威胁基准生成（BBG）框架，专注于细菌类生物威胁。该框架基于分层的生物威胁分类体系，构建了任务对齐的查询架构，称为“细菌生物威胁模式”，旨在全面衡量现有和未来AI模型可能带来的生物安全风险，涵盖不同攻击者能力水平及技术与操作层面的风险因素。


<details>
  <summary>Details</summary>
Motivation: 当前前沿人工智能模型（尤其是大语言模型）可能被滥用于生物恐怖主义或获取生物武器，亟需可靠的风险评估工具。现有基准常忽略攻击者能力差异和操作性风险，因此需要一个更全面、可复用的评估框架。

Method: 提出并构建了基于分层结构的‘细菌生物威胁模式’，通过将生物威胁分解为类别、要素和任务，进而生成与任务对齐的查询，为后续转化为模型提示和评估基准奠定基础。

Result: 成功设计出可扩展的细菌生物威胁任务-查询架构，为未来实现模型评估提供标准化、系统化的基础框架。

Conclusion: BBG框架及其细菌生物威胁模式提供了一个稳健、可重复使用的结构，能够从多维度评估大语言模型在细菌生物威胁方面的风险，兼顾技术和操作层面的需求，适用于不同层次的风险分析。

Abstract: Both model developers and policymakers seek to quantify and mitigate the risk of rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons. An important element of such efforts is the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper describes the first component of a novel Biothreat Benchmark Generation (BBG) Framework. The BBG approach is designed to help model developers and evaluators reliably measure and assess the biosecurity risk uplift and general harm potential of existing and future AI models, while accounting for key aspects of the threat itself that are often overlooked in other benchmarking efforts, including different actor capability levels, and operational (in addition to purely technical) risk factors. As a pilot, the BBG is first being developed to address bacterial biological threats only. The BBG is built upon a hierarchical structure of biothreat categories, elements and tasks, which then serves as the basis for the development of task-aligned queries. This paper outlines the development of this biothreat task-query architecture, which we have named the Bacterial Biothreat Schema, while future papers will describe follow-on efforts to turn queries into model prompts, as well as how the resulting benchmarks can be implemented for model evaluation. Overall, the BBG Framework, including the Bacterial Biothreat Schema, seeks to offer a robust, re-usable structure for evaluating bacterial biological risks arising from LLMs across multiple levels of aggregation, which captures the full scope of technical and operational requirements for biological adversaries, and which accounts for a wide spectrum of biological adversary capabilities.

</details>


### [132] [PolyLingua: Margin-based Inter-class Transformer for Robust Cross-domain Language Detection](https://arxiv.org/abs/2512.08143)
*Ali Lotfi Rezaabad,Bikram Khanal,Shashwat Chaurasia,Lu Zeng,Dezhi Hong,Hossein Beshashati,Thomas Butler,Megan Ganji*

Main category: cs.LG

TL;DR: PolyLingua is a lightweight Transformer-based model for language identification and fine-grained language classification, using a two-level contrastive learning framework with adaptive margins to produce compact, well-separated embeddings. It outperforms Sonnet 3.5 on challenging datasets (Amazon Massive and Song dataset) with 99.25% and 98.15% F1 scores respectively, while using 10x fewer parameters, making it suitable for low-latency and low-resource environments.


<details>
  <summary>Details</summary>
Motivation: Existing language identification tools are either inaccurate in complex cases like music requests with code-switching or too costly for low-resource settings. There is a need for a fast, accurate, and efficient solution that works well in real-world multilingual applications.

Method: PolyLingua employs a two-level contrastive learning framework: instance-level separation to distinguish individual samples and class-level alignment with adaptive margins to enhance clustering of similar languages, resulting in compact and discriminative embeddings.

Result: PolyLingua achieves 99.25% F1 on Amazon Massive and 98.15% F1 on the Song dataset, outperforming Sonnet 3.5 while using only 10% of its parameters, demonstrating high accuracy and efficiency.

Conclusion: PolyLingua provides a highly effective, lightweight solution for language identification in multilingual systems, especially in scenarios involving code-switching and resource constraints, offering superior performance with minimal computational cost.

Abstract: Language identification is a crucial first step in multilingual systems such as chatbots and virtual assistants, enabling linguistically and culturally accurate user experiences. Errors at this stage can cascade into downstream failures, setting a high bar for accuracy. Yet, existing language identification tools struggle with key cases--such as music requests where the song title and user language differ. Open-source tools like LangDetect, FastText are fast but less accurate, while large language models, though effective, are often too costly for low-latency or low-resource settings. We introduce PolyLingua, a lightweight Transformer-based model for in-domain language detection and fine-grained language classification. It employs a two-level contrastive learning framework combining instance-level separation and class-level alignment with adaptive margins, yielding compact and well-separated embeddings even for closely related languages. Evaluated on two challenging datasets--Amazon Massive (multilingual digital assistant utterances) and a Song dataset (music requests with frequent code-switching)--PolyLingua achieves 99.25% F1 and 98.15% F1, respectively, surpassing Sonnet 3.5 while using 10x fewer parameters, making it ideal for compute- and latency-constrained environments.

</details>


### [133] [TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models](https://arxiv.org/abs/2512.08153)
*Zheng Ding,Weirui Ye*

Main category: cs.LG

TL;DR: TreeGRPO 是一种新型强化学习框架，通过将去噪过程重构为搜索树结构，显著提升训练效率。它利用共享的初始噪声样本进行多分支生成，高效复用公共前缀，实现高样本效率、细粒度信用分配和计算摊销，使训练速度提升2.4倍，并在效率-奖励权衡上达到更优的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习后训练在对齐生成模型与人类偏好方面至关重要，但其高昂的计算成本限制了广泛应用。需要一种更高效的RL方法来解决这一瓶颈。

Method: 将去噪过程建模为搜索树，从共享初始噪声样本出发，通过策略性分枝生成多个候选轨迹，并复用它们的公共前缀；采用奖励反向传播实现每一步的细粒度优势计算；通过多子节点分支实现在一次前向传播中完成多次策略更新。

Result: 在扩散模型和流模型上的实验表明，TreeGRPO 实现了 2.4 倍的训练加速，在效率与奖励之间建立了更优的权衡关系，优于 GRPO 基线方法，在多个基准和奖励模型上表现一致更优。

Conclusion: TreeGRPO 提供了一种可扩展且高效的基于强化学习的视觉生成模型对齐路径，显著降低了训练成本，推动了该技术的实际应用。

Abstract: Reinforcement learning (RL) post-training is crucial for aligning generative models with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce \textbf{TreeGRPO}, a novel RL framework that dramatically improves training efficiency by recasting the denoising process as a search tree. From shared initial noise samples, TreeGRPO strategically branches to generate multiple candidate trajectories while efficiently reusing their common prefixes. This tree-structured approach delivers three key advantages: (1) \emph{High sample efficiency}, achieving better performance under same training samples (2) \emph{Fine-grained credit assignment} via reward backpropagation that computes step-specific advantages, overcoming the uniform credit assignment limitation of trajectory-based methods, and (3) \emph{Amortized computation} where multi-child branching enables multiple policy updates per forward pass. Extensive experiments on both diffusion and flow-based models demonstrate that TreeGRPO achieves \textbf{2.4$\times$ faster training} while establishing a superior Pareto frontier in the efficiency-reward trade-off space. Our method consistently outperforms GRPO baselines across multiple benchmarks and reward models, providing a scalable and effective pathway for RL-based visual generative model alignment. The project website is available at treegrpo.github.io.

</details>


### [134] [MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones](https://arxiv.org/abs/2512.08211)
*Jiaxiang Geng,Lunyu Zhao,Yiyi Lu,Bing Luo*

Main category: cs.LG

TL;DR: MobileFineTuner 是一个开源框架，可在普通智能手机上实现端到端的大语言模型（LLM）微调，支持全参数和参数高效微调。针对手机内存与能耗限制，提出了参数分片、梯度累积和能量感知计算调度等系统级优化。通过在真实设备上对 GPT-2、Gemma 3 和 Qwen 2.5 进行微调，验证了其可行性与有效性，为移动端 LLM 训练提供了可行基础。


<details>
  <summary>Details</summary>
Motivation: 随着高质量公开数据逐渐耗尽，利用用户私有数据进行大语言模型微调成为趋势，但现有方法多依赖模拟环境或物联网设备与个人电脑，缺乏适用于普通移动设备的开源框架。因此，亟需一种能在手机上高效、安全地完成微调的技术方案。

Method: 提出 MobileFineTuner 框架，集成参数分片、梯度累积与能量感知调度策略，支持 Full-FT 与 PEFT，实现资源受限环境下端侧 LLM 微调。

Result: 成功在真实移动设备上完成多个主流模型的微调任务，实验表明所提优化显著提升效率与稳定性，证明框架具备实用价值。

Conclusion: MobileFineTuner 为移动设备上的大语言模型训练提供了可行、高效且开源的解决方案，推动了隐私保护下的个性化 AI 发展，并为未来研究奠定基础。

Abstract: Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to leverage private user data while preserving privacy. However, existing approaches are predominantly simulation-based or rely on IoT devices and PCs, leaving commodity mobile phones largely unexplored. A key gap is the absence of an open-source framework that enables practical LLM fine-tuning on mobile phones. We present MobileFineTuner, a unified open-source framework that enables end-to-end LLM fine-tuning directly on commodity mobile phones. MobileFineTuner is designed for efficiency, scalability, and usability, supporting full-parameters fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT). To address the memory and energy limitations inherent to mobile phones, we introduce system-level optimizations including parameter sharding, gradient accumulation, and energy-aware computation scheduling. We demonstrate the practicality of MobileFineTuner by fine-tuning GPT-2, Gemma 3, and Qwen 2.5 on real mobile phones. Extensive experiments and ablation studies validate the effectiveness of the proposed optimizations and establish MobileFineTuner as a viable foundation for future research on on-device LLM training.

</details>


### [135] [Correction of Decoupled Weight Decay](https://arxiv.org/abs/2512.08217)
*Jason Chuan-Chih Chou*

Main category: cs.LG

TL;DR: 本文挑战了AdamW中权重衰减与学习率γ成正比的传统假设，提出权重衰减应与γ²成正比以实现更稳定的权重和梯度范数。基于更新在稳态下独立于权重的假设，作者推导并实证验证了这一关系，并证明其可改善训练动态与模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为AdamW中的权重衰减应与学习率γ成正比，但近期研究提出应改为γ²以满足正交性条件。本文旨在重新审视这一假设，并探究其对训练动态的实际影响。

Method: 基于更新在稳态下独立于权重的简单假设，推导出权重衰减与γ²成正比的理论依据，并通过实验验证其对权重和梯度范数的稳定性以及对训练动态的控制能力。

Result: 发现权重衰减与γ²成正比能有效稳定权重和梯度范数，提升模型训练稳定性与性能；同时，该设定下的有效学习率具有可迁移性，有助于优化策略设计。

Conclusion: 权重衰减与学习率平方γ²成正比是更合理的设定，能够带来更稳定的训练动态和更好的模型表现，且其有效性不依赖于具体优化器形式。

Abstract: Decoupled weight decay, solely responsible for the performance advantage of AdamW over Adam, has long been set to proportional to learning rate $γ$ without questioning. Some researchers have recently challenged such assumption and argued that decoupled weight decay should be set $\propto γ^2$ instead based on orthogonality arguments at steady state. To the contrary, we find that eliminating the contribution of the perpendicular component of the update to the weight norm leads to little change to the training dynamics. Instead, we derive that decoupled weight decay $\propto γ^2$ results in stable weight norm based on the simple assumption that updates become independent of the weights at steady state, regardless of the nature of the optimizer. Based on the same assumption, we derive and empirically verify that the Total Update Contribution (TUC) of a minibatch under the Scion optimizer is better characterized by the momentum-dependent effective learning rate whose optimal value transfers and we show that decoupled weight decay $\propto γ^2$ leads to stable weight and gradient norms and allows us to better control the training dynamics and improve the model performance.

</details>


### [136] [SPROCKET: Extending ROCKET to Distance-Based Time-Series Transformations With Prototypes](https://arxiv.org/abs/2512.08246)
*Nicholas Harner*

Main category: cs.LG

TL;DR: SPROCKET是一种基于原型的新型特征工程策略，通过选择性原型生成随机卷积核特征，在UCR和UEA时间序列分类基准上表现优于传统方法。其集成模型MR-HY-SP在平均准确率上超越了之前的最优模型HYDRA-MR，表明原型驱动的方法在提升分类精度与鲁棒性方面具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类方法依赖于复杂的特征工程，尤其是基于随机核的ROCKET算法虽有效但缺乏可解释性与针对性。本文旨在提出一种更高效、更具鲁棒性的特征提取机制，利用原型选择来优化随机卷积核生成过程，从而提升分类性能。

Method: SPROCKET采用原型选择机制，从时间序列中提取代表性样本（原型），基于这些原型构建随机卷积核，生成更具判别力的特征。该方法结合了原型的语义信息与随机化设计的优势，提升了特征表达能力。同时，与多模型集成框架MR-HY-SP结合，形成强大且稳定的分类系统。

Result: 在大多数UCR和UEA数据集上，SPROCKET的表现与先进卷积算法相当；其集成模型MR-HY-SP的平均准确率排名超过前一最佳模型HYDRA-MR，验证了方法的有效性与优越性。

Conclusion: 原型驱动的特征转换策略能够有效提升时间序列分类的准确性和鲁棒性，为未来特征工程提供了新思路。

Abstract: Classical Time Series Classification algorithms are dominated by feature engineering strategies. One of the most prominent of these transforms is ROCKET, which achieves strong performance through random kernel features. We introduce SPROCKET (Selected Prototype Random Convolutional Kernel Transform), which implements a new feature engineering strategy based on prototypes. On a majority of the UCR and UEA Time Series Classification archives, SPROCKET achieves performance comparable to existing convolutional algorithms and the new MR-HY-SP ( MultiROCKET-HYDRA-SPROCKET) ensemble's average accuracy ranking exceeds HYDRA-MR, the previous best convolutional ensemble's performance. These experimental results demonstrate that prototype-based feature transformation can enhance both accuracy and robustness in time series classification.

</details>


### [137] [Geometric-Stochastic Multimodal Deep Learning for Predictive Modeling of SUDEP and Stroke Vulnerability](https://arxiv.org/abs/2512.08257)
*Preksha Girish,Rachana Mysore,Mahanthesha U,Shrey Kumar,Misbah Fatimah Annigeri,Tanish Jain*

Main category: cs.LG

TL;DR: 提出了一种统一的几何-随机多模态深度学习框架，整合EEG、ECG、呼吸、SpO2、EMG和fMRI信号，用于建模癫痫猝死（SUDEP）和卒中易感性。该方法结合黎曼流形嵌入、李群不变特征表示、分数阶随机动力学、哈密顿能量流建模和跨模态注意力机制，通过分数阶流行病扩散模型模拟卒中传播。在MULTI-CLARID数据集上的实验表明，该框架提高了预测准确性，并提取了可解释的生物标志物，如流形曲率、分数记忆指数、注意力熵和扩散中心性。该框架为神经-自主神经系统疾病早期检测、风险分层和可解释的多模态建模提供了数学上严谨的基础。


<details>
  <summary>Details</summary>
Motivation: SUDEP和急性缺血性卒中是涉及皮层、脑干和自主神经系统复杂交互的生命威胁性疾病，现有方法难以全面整合多模态生理信号并提供可解释的病理机制建模，亟需一种统一且数学严谨的框架以实现早期预警与风险评估。

Method: 采用黎曼流形嵌入对多模态生理信号进行几何表征；利用李群不变特征表示捕捉信号的对称性；引入分数阶随机动力学描述记忆效应；构建哈密顿能量流模型刻画系统能量动态；结合跨模态注意力机制实现异构信号融合；使用分数阶流行病扩散模型在结构脑图上模拟卒中传播路径。

Result: 在MULTI-CLARID数据集上，该框架显著提升了对SUDEP和卒中风险的预测准确率；成功识别出多个可解释的生物标志物，包括流形曲率、分数记忆指数、注意力熵和扩散中心性，揭示了关键神经-自主调控节点及其动态演化规律。

Conclusion: 所提出的几何-随机多模态深度学习框架为神经-自主神经系统疾病提供了数学上严谨、可解释且高精度的建模工具，具备在临床中用于早期检测、风险分层和机制研究的巨大潜力。

Abstract: Sudden Unexpected Death in Epilepsy (SUDEP) and acute ischemic stroke are life-threatening conditions involving complex interactions across cortical, brainstem, and autonomic systems. We present a unified geometric-stochastic multimodal deep learning framework that integrates EEG, ECG, respiration, SpO2, EMG, and fMRI signals to model SUDEP and stroke vulnerability. The approach combines Riemannian manifold embeddings, Lie-group invariant feature representations, fractional stochastic dynamics, Hamiltonian energy-flow modeling, and cross-modal attention mechanisms. Stroke propagation is modeled using fractional epidemic diffusion over structural brain graphs. Experiments on the MULTI-CLARID dataset demonstrate improved predictive accuracy and interpretable biomarkers derived from manifold curvature, fractional memory indices, attention entropy, and diffusion centrality. The proposed framework provides a mathematically principled foundation for early detection, risk stratification, and interpretable multimodal modeling in neural-autonomic disorders.

</details>


### [138] [gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs](https://arxiv.org/abs/2512.08274)
*Humera Sabir,Fatima Farooq,Ashraf Aboulnaga*

Main category: cs.LG

TL;DR: gHAWK is a scalable GNN framework for large knowledge graphs that precomputes structural features (Bloom filters for local structure and TransE embeddings for global position) to enhance training efficiency and accuracy. It reduces memory usage, speeds up convergence, and achieves state-of-the-art performance on OGB benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing message-passing GNNs struggle with scalability on large knowledge graphs due to inefficient iterative message passing, especially under mini-batch training where nodes only see partial neighborhoods.

Method: gHAWK introduces a preprocessing step to compute Bloom filters for local neighborhood structure and TransE embeddings for global node positioning. These structural features are fused with domain-specific features (e.g., text embeddings) to form enhanced node representations used in GNN training.

Result: gHAWK significantly reduces memory usage, accelerates convergence, and improves model accuracy. It achieves state-of-the-art results on multiple OGB datasets, leading the leaderboard for three graphs in both node property prediction and link prediction tasks.

Conclusion: By incorporating precomputed structural priors into GNN training, gHAWK enables efficient and scalable learning on large knowledge graphs, outperforming existing methods in both speed and accuracy.

Abstract: Knowledge Graphs (KGs) are a rich source of structured, heterogeneous data, powering a wide range of applications. A common approach to leverage this data is to train a graph neural network (GNN) on the KG. However, existing message-passing GNNs struggle to scale to large KGs because they rely on the iterative message passing process to learn the graph structure, which is inefficient, especially under mini-batch training, where a node sees only a partial view of its neighborhood. In this paper, we address this problem and present gHAWK, a novel and scalable GNN training framework for large KGs. The key idea is to precompute structural features for each node that capture its local and global structure before GNN training even begins. Specifically, gHAWK introduces a preprocessing step that computes: (a)~Bloom filters to compactly encode local neighborhood structure, and (b)~TransE embeddings to represent each node's global position in the graph. These features are then fused with any domain-specific features (e.g., text embeddings), producing a node feature vector that can be incorporated into any GNN technique. By augmenting message-passing training with structural priors, gHAWK significantly reduces memory usage, accelerates convergence, and improves model accuracy. Extensive experiments on large datasets from the Open Graph Benchmark (OGB) demonstrate that gHAWK achieves state-of-the-art accuracy and lower training time on both node property prediction and link prediction tasks, topping the OGB leaderboard for three graphs.

</details>


### [139] [Jacobian Aligned Random Forests](https://arxiv.org/abs/2512.08306)
*Sarwesh Rauniyar*

Main category: cs.LG

TL;DR: 提出JARF（雅可比对齐随机森林），通过计算预测梯度并构建全局线性预处理矩阵，对特征空间进行统一旋转，使轴对齐随机森林能够有效捕捉倾斜或交互依赖的决策边界，提升性能同时保持训练效率和简单性。


<details>
  <summary>Details</summary>
Motivation: 轴对齐决策树在处理旋转或特征间相互依赖的数据时表现不佳，而传统斜向森林虽能解决但计算成本高且实现复杂。因此需要一种既能保留轴对齐树优点又具备斜向能力的简化方法。

Method: 首先训练一个轴对齐随机森林以估计输出；然后利用有限差分法计算各特征的梯度，聚合为期望雅可比外积（推广自期望梯度外积）作为全局线性预处理矩阵；最后用该矩阵对特征空间进行统一旋转，并输入标准轴对齐森林中进行训练。

Result: 在多个表格分类与回归基准测试中，JARF显著提升了轴对齐森林的性能，常达到甚至超过斜向基线水平，同时加快了训练速度。实验证明其能有效捕获斜向边界与特征交互。

Conclusion: 监督预处理机制可有效恢复斜向森林的大部分精度，同时维持轴对齐树的简洁性与鲁棒性，是一种高效实用的改进方案。

Abstract: Axis-aligned decision trees are fast and stable but struggle on datasets with rotated or interaction-dependent decision boundaries, where informative splits require linear combinations of features rather than single-feature thresholds. Oblique forests address this with per-node hyperplane splits, but at added computational cost and implementation complexity. We propose a simple alternative: JARF, Jacobian-Aligned Random Forests. Concretely, we first fit an axis-aligned forest to estimate class probabilities or regression outputs, compute finite-difference gradients of these predictions with respect to each feature, aggregate them into an expected Jacobian outer product that generalizes the expected gradient outer product (EGOP), and use it as a single global linear preconditioner for all inputs. This supervised preconditioner applies a single global rotation of the feature space, then hands the transformed data back to a standard axis-aligned forest, preserving off-the-shelf training pipelines while capturing oblique boundaries and feature interactions that would otherwise require many axis-aligned splits to approximate. The same construction applies to any model that provides gradients, though we focus on random forests and gradient-boosted trees in this work. On tabular classification and regression benchmarks, this preconditioning consistently improves axis-aligned forests and often matches or surpasses oblique baselines while improving training time. Our experimental results and theoretical analysis together indicate that supervised preconditioning can recover much of the accuracy of oblique forests while retaining the simplicity and robustness of axis-aligned trees.

</details>


### [140] [Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning](https://arxiv.org/abs/2512.08314)
*M Yashwanth,Gaurav Kumar Nayak,Harsh Rangwani,Arya Singh,R. Venkatesh Babu,Anirban Chakraborty*

Main category: cs.LG

TL;DR: 本文提出一种新的联邦学习优化方法，通过引入对损失函数海森矩阵最大特征值的平滑性约束，以改善模型在联邦学习中的泛化性能。为此，作者设计了一种计算高效的正则化技术MAN（Minimizes Activation's Norm），该方法在客户端最小化各层激活值的范数，理论上证明了其能降低局部损失函数的层间海森矩阵最大特征值，从而促使全局模型收敛至平坦最小值。实验表明，该方法显著提升了现有联邦学习技术的性能，达到新的最优水平。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中模型可能收敛到尖锐极小值，导致泛化性能下降，因此需要提升模型的平滑性以增强泛化能力。

Method: 提出基于海森矩阵最大特征值的平滑性约束，并将其转化为客户端损失函数上的可计算正则化项，设计MAN方法最小化每层激活值的范数，实现高效且理论支持的平滑优化。

Result: 所提方法在多种联邦学习场景下均取得显著性能提升，超越现有方法，成为新的状态最先进水平。

Conclusion: 通过引入平滑性约束并设计有效的正则化机制MAN，能够有效引导联邦学习模型收敛至平坦最小值，显著提升模型泛化能力，为联邦学习提供更优的优化方向。

Abstract: Federated Learning (FL) is an emerging machine learning framework that enables multiple clients (coordinated by a server) to collaboratively train a global model by aggregating the locally trained models without sharing any client's training data. It has been observed in recent works that learning in a federated manner may lead the aggregated global model to converge to a 'sharp minimum' thereby adversely affecting the generalizability of this FL-trained model. Therefore, in this work, we aim to improve the generalization performance of models trained in a federated setup by introducing a 'flatness' constrained FL optimization problem. This flatness constraint is imposed on the top eigenvalue of the Hessian computed from the training loss. As each client trains a model on its local data, we further re-formulate this complex problem utilizing the client loss functions and propose a new computationally efficient regularization technique, dubbed 'MAN,' which Minimizes Activation's Norm of each layer on client-side models. We also theoretically show that minimizing the activation norm reduces the top eigenvalue of the layer-wise Hessian of the client's loss, which in turn decreases the overall Hessian's top eigenvalue, ensuring convergence to a flat minimum. We apply our proposed flatness-constrained optimization to the existing FL techniques and obtain significant improvements, thereby establishing new state-of-the-art.

</details>


### [141] [A Multivariate Bernoulli-Based Sampling Method for Multi-Label Data with Application to Meta-Research](https://arxiv.org/abs/2512.08371)
*Simon Chung,Colby J. Vorland,Donna L. Maney,Andrew W. Brown*

Main category: cs.LG

TL;DR: 本文提出一种新型采样算法，用于处理多标签数据中标签频率差异大且非互斥的问题。该算法基于多变量伯努利分布，利用标签频率估计参数并计算每种标签组合的权重，从而在采样时保留目标分布特征并考虑标签依赖关系。实验以Web of Science中的64个生物医学主题类别研究论文为例，成功生成了更均衡的子样本，改善了少数类别代表性的不足。


<details>
  <summary>Details</summary>
Motivation: 当数据集中存在多个非互斥标签且标签频率差异显著时，传统采样方法难以保证稀有标签的充分代表性，同时可能破坏原始分布特性，因此需要一种能兼顾频率平衡与标签依赖关系的采样方法。

Method: 采用多变量伯努利分布建模多标签数据，通过观察到的标签频率估计分布参数，并为每种标签组合计算相应权重，实现加权采样以逼近目标分布，同时反映标签间的依赖关系。

Result: 在真实数据集上的应用表明，该方法能够有效保持类别频率排序，缩小最常见与最罕见类别之间的频率差距，并提升对少数类别的表示能力，生成更平衡的子样本。

Conclusion: 所提出的采样算法能有效应对多标签数据中频率不平衡和标签依赖问题，显著改善少数类别在样本中的代表性，适用于需要高保真度表示的多标签分析任务。

Abstract: Datasets may contain observations with multiple labels. If the labels are not mutually exclusive, and if the labels vary greatly in frequency, obtaining a sample that includes sufficient observations with scarcer labels to make inferences about those labels, and which deviates from the population frequencies in a known manner, creates challenges. In this paper, we consider a multivariate Bernoulli distribution as our underlying distribution of a multi-label problem. We present a novel sampling algorithm that takes label dependencies into account. It uses observed label frequencies to estimate multivariate Bernoulli distribution parameters and calculate weights for each label combination. This approach ensures the weighted sampling acquires target distribution characteristics while accounting for label dependencies. We applied this approach to a sample of research articles from Web of Science labeled with 64 biomedical topic categories. We aimed to preserve category frequency order, reduce frequency differences between most and least common categories, and account for category dependencies. This approach produced a more balanced sub-sample, enhancing the representation of minority categories.

</details>


### [142] [Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models III: Implementing the Bacterial Biothreat Benchmark (B3) Dataset](https://arxiv.org/abs/2512.08459)
*Gary Ackerman,Theodore Wilson,Zachary Kallenborn,Olivia Shoemaker,Anna Wetzel,Hayley Peterson,Abigail Danfora,Jenna LaTourette,Brandon Behlendorf,Douglas Clifford*

Main category: cs.LG

TL;DR: 该论文介绍了细菌生物威胁基准（B3）数据集的试点实施，旨在评估大型语言模型（LLM）带来的生物安全风险。通过在前沿AI模型上运行测试并结合人工评估与风险分析，验证了B3在快速识别风险来源和指导缓解优先级方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着前沿人工智能模型（尤其是大语言模型）的快速发展，其可能被用于生物恐怖主义或获取生物武器，引发政策、学术及公众广泛关注。因此，亟需开发可量化和减轻此类风险的模型评估工具，特别是具备生物安全风险评估能力的基准测试体系。

Method: 采用B3数据集对前沿AI模型进行测试，结合模型输出分析与人工评估，并从多个维度开展应用性风险分析，以检验其评估能力。

Result: 试点结果表明，B3数据集能够有效、细致地评估大语言模型的生物安全风险，准确识别关键风险来源，并为制定缓解策略提供明确优先方向。

Conclusion: B3数据集是评估大语言模型生物安全风险的一种可行且具有深度的方法，为后续模型开发与监管提供了重要支持。

Abstract: The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper discusses the pilot implementation of the Bacterial Biothreat Benchmark (B3) dataset. It is the third in a series of three papers describing an overall Biothreat Benchmark Generation (BBG) framework, with previous papers detailing the development of the B3 dataset. The pilot involved running the benchmarks through a sample frontier AI model, followed by human evaluation of model responses, and an applied risk analysis of the results along several dimensions. Overall, the pilot demonstrated that the B3 dataset offers a viable, nuanced method for rapidly assessing the biosecurity risk posed by a LLM, identifying the key sources of that risk and providing guidance for priority areas of mitigation priority.

</details>


### [143] [Transformers for Multimodal Brain State Decoding: Integrating Functional Magnetic Resonance Imaging Data and Medical Metadata](https://arxiv.org/abs/2512.08462)
*Danial Jafarzadeh Jazi,Maryam Hajiesmaeili*

Main category: cs.LG

TL;DR: 本文提出一种结合Transformer架构与多模态输入（fMRI数据和DICOM元数据）的新框架，通过注意力机制捕捉fMRI数据中的复杂时空模式和上下文关系，提升模型的准确性、可解释性和鲁棒性，适用于临床诊断、认知神经科学和个性化医疗。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习和深度学习方法在处理fMRI数据时未能充分利用DICOM元数据提供的上下文信息，导致模型性能受限。因此需要一种能够整合多源信息的新方法。

Method: 采用基于Transformer的架构，融合fMRI数据与DICOM元数据，利用注意力机制建模空间-时间依赖性和上下文关联。

Result: 该框架显著提升了模型在脑状态解码任务中的准确率与鲁棒性，并增强了结果的可解释性，同时在临床与科研应用中展现出广阔前景。

Conclusion: 所提出的多模态Transformer框架为脑状态解码提供了有效解决方案，未来可通过优化计算效率与泛化能力进一步提升其实际应用价值。

Abstract: Decoding brain states from functional magnetic resonance imaging (fMRI) data is vital for advancing neuroscience and clinical applications. While traditional machine learning and deep learning approaches have made strides in leveraging the high-dimensional and complex nature of fMRI data, they often fail to utilize the contextual richness provided by Digital Imaging and Communications in Medicine (DICOM) metadata. This paper presents a novel framework integrating transformer-based architectures with multimodal inputs, including fMRI data and DICOM metadata. By employing attention mechanisms, the proposed method captures intricate spatial-temporal patterns and contextual relationships, enhancing model accuracy, interpretability, and robustness. The potential of this framework spans applications in clinical diagnostics, cognitive neuroscience, and personalized medicine. Limitations, such as metadata variability and computational demands, are addressed, and future directions for optimizing scalability and generalizability are discussed.

</details>


### [144] [Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning](https://arxiv.org/abs/2512.08485)
*Junnan Qiu,Jie Li*

Main category: cs.LG

TL;DR: 提出一种新的全局预算分配攻击策略，利用TD误差敏感性实现高效、隐蔽的离线强化学习数据投毒攻击，显著提升攻击效果并规避检测。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法依赖局部均匀扰动，效率低且易被检测，缺乏对样本影响力的差异化处理。

Method: 基于TD误差与样本影响的理论关系，将攻击建模为全局资源分配问题，推导出在L2约束下的闭式解，按TD误差敏感性分配扰动幅度。

Result: 在D4RL基准上实验表明，该方法能以极小扰动实现高达80%的性能下降，有效规避主流统计与谱检测防御。

Conclusion: 所提方法通过全局优化扰动分配，在保证隐蔽性的同时极大提升了数据投毒攻击的效果，揭示了离线强化学习系统在对抗攻击下的脆弱性。

Abstract: Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to data poisoning attacks. Existing attack strategies typically rely on locally uniform perturbations, which treat all samples indiscriminately. This approach is inefficient, as it wastes the perturbation budget on low-impact samples, and lacks stealthiness due to significant statistical deviations. In this paper, we propose a novel Global Budget Allocation attack strategy. Leveraging the theoretical insight that a sample's influence on value function convergence is proportional to its Temporal Difference (TD) error, we formulate the attack as a global resource allocation problem. We derive a closed-form solution where perturbation magnitudes are assigned proportional to the TD-error sensitivity under a global L2 constraint. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms baseline strategies, achieving up to 80% performance degradation with minimal perturbations that evade detection by state-of-the-art statistical and spectral defenses.

</details>


### [145] [DS FedProxGrad: Asymptotic Stationarity Without Noise Floor in Fair Federated Learning](https://arxiv.org/abs/2512.08671)
*Huzaifa Arif*

Main category: cs.LG

TL;DR: 本文提出了一个改进的联邦近端梯度方法（DS FedProxGrad），用于解决具有不公平正则化的非凸复合优化问题。相较于先前工作仅能收敛到受噪声影响的平稳性邻域，本文在随机步长和局部近似误差衰减条件下，证明了算法渐近平稳，且不依赖于方差引起的噪声下限，实现了更优的收敛性能。


<details>
  <summary>Details</summary>
Motivation: 先前的FedProxGrad方法在非凸复合优化中只能收敛到受方差噪声影响的平稳性邻域，存在噪声下限限制，影响收敛精度。因此需要改进分析框架以实现无噪声下限的渐近平稳收敛。

Method: 提出DS FedProxGrad框架，采用Robbins-Monro型步长策略，并引入局部近似解的衰减条件，结合显式公平性正则化，在理论层面分析算法的收敛行为。

Result: 在弱衰减条件下，证明了算法满足 $\liminf_{r\to\infty} \mathbb{E}[\|\nabla F(\mathbf{x}^r)\|^2] = 0$，即渐近达到平稳状态，且收敛速率不受方差噪声下限影响。

Conclusion: DS FedProxGrad通过改进步长策略与局部近似误差控制，实现了对非凸复合优化问题更优的收敛性质，为公平联邦学习提供了更强的理论支持。

Abstract: Recent work \cite{arifgroup} introduced Federated Proximal Gradient \textbf{(\texttt{FedProxGrad})} for solving non-convex composite optimization problems in group fair federated learning. However, the original analysis established convergence only to a \textit{noise-dominated neighborhood of stationarity}, with explicit dependence on a variance-induced noise floor. In this work, we provide an improved asymptotic convergence analysis for a generalized \texttt{FedProxGrad}-type analytical framework with inexact local proximal solutions and explicit fairness regularization. We call this extended analytical framework \textbf{DS \texttt{FedProxGrad}} (Decay Step Size \texttt{FedProxGrad}). Under a Robbins-Monro step-size schedule \cite{robbins1951stochastic} and a mild decay condition on local inexactness, we prove that $\liminf_{r\to\infty} \mathbb{E}[\|\nabla F(\mathbf{x}^r)\|^2] = 0$, i.e., the algorithm is asymptotically stationary and the convergence rate does not depend on a variance-induced noise floor.

</details>


### [146] [Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search](https://arxiv.org/abs/2512.08724)
*Manos Plitsis,Giorgos Bouritsas,Vassilis Katsouros,Yannis Panagakis*

Main category: cs.LG

TL;DR: 本文提出了一种名为Bias-Guided Prompt Search (BGPS)的框架，用于自动生成能最大化图像中社会偏见的提示词。该框架结合了属性无关的提示生成与基于内部表示的属性分类器，以引导语言模型向产生更强偏见的方向生成提示。在Stable Diffusion 1.5和一个先进的去偏模型上的实验揭示了大量此前未被发现的细微偏见，且所生成的提示具有可解释性，优于现有方法。研究揭示了文本到图像扩散模型的脆弱性，并展示了BGPS作为新型评估工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法依赖于人工或LLM生成的提示数据集，但存在标注成本高、可能遗漏隐蔽提示的问题，无法全面检测模型中的社会偏见。因此需要一种更系统、自动化的手段来发现隐藏的偏见触发点。

Method: BGPS框架包含两个部分：(1) 使用指令引导的LLM生成属性中立的初始提示；(2) 利用作用于扩散模型内部表示的属性分类器，反馈引导LLM的解码过程，使其聚焦于能放大特定属性（如性别、种族）的提示空间，从而实现偏见最大化。

Result: 在Stable Diffusion 1.5和一个先进去偏模型上，BGPS成功发现了大量先前未记录的微妙偏见，显著降低了公平性指标。生成的提示不仅可解释，且在困惑度（perplexity）方面优于当前主流的硬提示优化方法。

Conclusion: BGPS有效扩展了偏见搜索范围，揭示了当前文本到图像模型中潜在的严重公平性缺陷。该框架不仅能作为发现偏见的新工具，还可用于评估和改进去偏策略，推动更公平的生成式AI发展。

Abstract: Text-to-image (TTI) diffusion models have achieved remarkable visual quality, yet they have been repeatedly shown to exhibit social biases across sensitive attributes such as gender, race and age. To mitigate these biases, existing approaches frequently depend on curated prompt datasets - either manually constructed or generated with large language models (LLMs) - as part of their training and/or evaluation procedures. Beside the curation cost, this also risks overlooking unanticipated, less obvious prompts that trigger biased generation, even in models that have undergone debiasing. In this work, we introduce Bias-Guided Prompt Search (BGPS), a framework that automatically generates prompts that aim to maximize the presence of biases in the resulting images. BGPS comprises two components: (1) an LLM instructed to produce attribute-neutral prompts and (2) attribute classifiers acting on the TTI's internal representations that steer the decoding process of the LLM toward regions of the prompt space that amplify the image attributes of interest. We conduct extensive experiments on Stable Diffusion 1.5 and a state-of-the-art debiased model and discover an array of subtle and previously undocumented biases that severely deteriorate fairness metrics. Crucially, the discovered prompts are interpretable, i.e they may be entered by a typical user, quantitatively improving the perplexity metric compared to a prominent hard prompt optimization counterpart. Our findings uncover TTI vulnerabilities, while BGPS expands the bias search space and can act as a new evaluation tool for bias mitigation.

</details>


### [147] [Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data](https://arxiv.org/abs/2512.08732)
*Udesh Habaraduwa,Andrei Lixandru*

Main category: cs.LG

TL;DR: 本文提出神经微分方程（NODE）框架，用于建模蛋白质组与代谢组之间的动态交互，基于工程化大肠杆菌的时间序列数据，显著提升对代谢通路动态的预测能力。相比传统机器学习方法，该模型在柠檬烯和异戊醇通路数据上分别实现94.38%和97.65%的误差降低，且推理速度加快1000倍，具备高保真与可扩展性，适用于代谢工程与生物发现。


<details>
  <summary>Details</summary>
Motivation: 当前生物系统建模受限于传统机制模型对先验知识的依赖，难以从高通量多组学数据中有效提取复杂动态关系。亟需数据驱动的高效模拟系统以推动健康寿命延长与生物工程发展。

Method: 采用神经微分方程（NODE）作为动态建模框架，直接从时间序列观测数据中学习蛋白质组与代谢组间的连续动态演化规律，无需预先设定动力学方程。

Result: 在柠檬烯和异戊醇通路数据上，模型根均方误差较基线降低超过90%（最高达94.38%和97.65%），推理速度提升1000倍，展现出优异的预测性能与计算效率。

Conclusion: NODE框架为复杂生物系统的动态建模提供了高效、高保真的新范式，具有在个性化医疗与合成生物学中广泛应用的潜力。

Abstract: The advancement of human healthspan and bioengineering relies heavily on predicting the behavior of complex biological systems. While high-throughput multiomics data is becoming increasingly abundant, converting this data into actionable predictive models remains a bottleneck. High-capacity, datadriven simulation systems are critical in this landscape; unlike classical mechanistic models restricted by prior knowledge, these architectures can infer latent interactions directly from observational data, allowing for the simulation of temporal trajectories and the anticipation of downstream intervention effects in personalized medicine and synthetic biology. To address this challenge, we introduce Neural Ordinary Differential Equations (NODEs) as a dynamic framework for learning the complex interplay between the proteome and metabolome. We applied this framework to time-series data derived from engineered Escherichia coli strains, modeling the continuous dynamics of metabolic pathways. The proposed NODE architecture demonstrates superior performance in capturing system dynamics compared to traditional machine learning pipelines. Our results show a greater than 90% improvement in root mean squared error over baselines across both Limonene (up to 94.38% improvement) and Isopentenol (up to 97.65% improvement) pathway datasets. Furthermore, the NODE models demonstrated a 1000x acceleration in inference time, establishing them as a scalable, high-fidelity tool for the next generation of metabolic engineering and biological discovery.

</details>


### [148] [Identifying counterfactual probabilities using bivariate distributions and uplift modeling](https://arxiv.org/abs/2512.08805)
*Théo Verhelst,Gianluca Bontempi*

Main category: cs.LG

TL;DR: 本文提出一种新的反事实估计方法，通过拟合二元贝塔分布来利用上行模型预测的提升分数，生成反事实结果的后验分布。该方法无需额外因果假设，仅依赖于上行建模的基本假设，在模拟中表现有效，适用于电信客户流失等场景，提供超越传统机器学习和上行模型的深入洞察。


<details>
  <summary>Details</summary>
Motivation: 标准的上行模型只能估计干预的因果效应，而反事实识别需要恢复潜在结果的联合分布以回答更复杂的问题（如‘如果未提供营销优惠，这位客户还会流失吗？’）。然而，反事实估计更难，且通常需要强因果假设。因此，需要一种结合上行模型与反事实估计的新方法，以在不增加额外假设的前提下获取更丰富的信息。

Method: 提出一种基于上行模型预测得分的反事实估计器，使用二元贝塔分布对预测的提升分数进行建模，从而推导出反事实结果的后验分布。该方法完全建立在上行模型的基础上，不引入额外的因果假设。

Result: 模拟实验表明该方法有效，能够准确估计反事实结果的分布。在电信客户流失问题中，该方法揭示了传统机器学习或上行模型无法捕捉的深层洞察，显著提升了决策支持能力。

Conclusion: 本文提出的反事实估计方法通过融合上行模型与概率建模，实现了无需额外因果假设的丰富反事实推理，为实际应用中的个性化决策提供了更强的支持。

Abstract: Uplift modeling estimates the causal effect of an intervention as the difference between potential outcomes under treatment and control, whereas counterfactual identification aims to recover the joint distribution of these potential outcomes (e.g., "Would this customer still have churned had we given them a marketing offer?"). This joint counterfactual distribution provides richer information than the uplift but is harder to estimate. However, the two approaches are synergistic: uplift models can be leveraged for counterfactual estimation. We propose a counterfactual estimator that fits a bivariate beta distribution to predicted uplift scores, yielding posterior distributions over counterfactual outcomes. Our approach requires no causal assumptions beyond those of uplift modeling. Simulations show the efficacy of the approach, which can be applied, for example, to the problem of customer churn in telecom, where it reveals insights unavailable to standard ML or uplift models alone.

</details>


### [149] [Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models](https://arxiv.org/abs/2512.08832)
*Huzaifa Arif,Pin-Yu Chen,Alex Gittens,James Diffenderfer,Bhavya Kailkhura*

Main category: cs.LG

TL;DR: 本文提出了一种名为WAAPO的新框架，用于生成针对天气预报AI模型的有效且隐蔽的对抗性扰动。该框架通过引入通道稀疏性、空间定位和光滑性约束，确保扰动在物理上合理且难以察觉。基于ERA5数据集和FourCastNet模型的实验表明，即使在受限条件下，WAAPO仍能生成与预设目标高度一致的对抗性轨迹。研究揭示了当前AI气象预测模型存在显著脆弱性，微小的初始条件扰动可导致预测结果大幅偏离，凸显了在实际预报系统中建立防御机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能模型在气象预报中的广泛应用，其对对抗性扰动的脆弱性日益凸显。现有方法生成的扰动往往缺乏物理合理性或易被检测，无法真实反映潜在威胁。因此，亟需一种既能有效操控预测结果又具备高隐蔽性的对抗性扰动生成方法，以评估并提升模型的安全性。

Method: 提出Weather Adaptive Adversarial Perturbation Optimization (WAAPO)框架，通过引入通道稀疏性、空间局部化和光滑性约束，在生成对抗性扰动时兼顾有效性与物理合理性。利用ERA5数据集和FourCastNet模型进行实验，采用优化策略生成符合目标轨迹的扰动，并验证其在不同约束下的表现。

Result: 实验结果表明，WAAPO能够在严格约束下成功生成与预设目标高度匹配的对抗性轨迹，证明其在操控AI气象预测模型方面的高效性。同时，扰动在空间分布和物理特性上保持合理，具备较强的隐蔽性。研究揭示了当前模型对初始条件微小扰动的高度敏感性，暴露其严重安全隐患。

Conclusion: WAAPO框架为评估和增强AI气象预报系统的安全性提供了有效工具。研究表明，当前模型在面对精心设计的对抗性扰动时极为脆弱，必须建立相应的鲁棒防护机制，以保障实际应用中的可靠性与可信度。

Abstract: With the increasing reliance on AI models for weather forecasting, it is imperative to evaluate their vulnerability to adversarial perturbations. This work introduces Weather Adaptive Adversarial Perturbation Optimization (WAAPO), a novel framework for generating targeted adversarial perturbations that are both effective in manipulating forecasts and stealthy to avoid detection. WAAPO achieves this by incorporating constraints for channel sparsity, spatial localization, and smoothness, ensuring that perturbations remain physically realistic and imperceptible. Using the ERA5 dataset and FourCastNet (Pathak et al. 2022), we demonstrate WAAPO's ability to generate adversarial trajectories that align closely with predefined targets, even under constrained conditions. Our experiments highlight critical vulnerabilities in AI-driven forecasting models, where small perturbations to initial conditions can result in significant deviations in predicted weather patterns. These findings underscore the need for robust safeguards to protect against adversarial exploitation in operational forecasting systems.

</details>


### [150] [Reinforcement Learning From State and Temporal Differences](https://arxiv.org/abs/2512.08855)
*Lex Weaver,Jonathan Baxter*

Main category: cs.LG

TL;DR: TD(λ) with function approximation is effective but can converge to sub-optimal policies due to focusing on absolute value errors. This paper proposes STD(λ), which trains approximators based on relative state values for better policy improvement, showing theoretical and empirical success in simple systems and the acrobot problem.


<details>
  <summary>Details</summary>
Motivation: TD(λ) focuses on minimizing absolute value errors, but policy performance depends more on correct relative ordering of states. Existing methods may thus fail to improve policies effectively.

Method: Introduce STD(λ), a modified TD(λ) that uses relative state values for training function approximators, especially on binary decision problems. Includes theoretical analysis and comparison with Bertsekas' differential training.

Result: STD(λ) achieves monotonic policy improvement in two-state systems and successfully solves a variation of the acrobot problem, outperforming standard TD(λ) in policy quality.

Conclusion: STD(λ) improves policy learning by emphasizing relative state values rather than absolute errors, offering a more effective approach for function approximation in reinforcement learning.

Abstract: TD($λ$) with function approximation has proved empirically successful for some complex reinforcement learning problems. For linear approximation, TD($λ$) has been shown to minimise the squared error between the approximate value of each state and the true value. However, as far as policy is concerned, it is error in the relative ordering of states that is critical, rather than error in the state values. We illustrate this point, both in simple two-state and three-state systems in which TD($λ$)--starting from an optimal policy--converges to a sub-optimal policy, and also in backgammon. We then present a modified form of TD($λ$), called STD($λ$), in which function approximators are trained with respect to relative state values on binary decision problems. A theoretical analysis, including a proof of monotonic policy improvement for STD($λ$) in the context of the two-state system, is presented, along with a comparison with Bertsekas' differential training method [1]. This is followed by successful demonstrations of STD($λ$) on the two-state system and a variation on the well known acrobot problem.

</details>


### [151] [Refining Diffusion Models for Motion Synthesis with an Acceleration Loss to Generate Realistic IMU Data](https://arxiv.org/abs/2512.08859)
*Lars Ole Häusler,Lena Uhlenberg,Göran Köber,Diyora Salimova,Oliver Amft*

Main category: cs.LG

TL;DR: 本文提出了一种文本到IMU运动生成框架，通过在预训练扩散模型中引入基于加速度的二阶损失（L_acc）进行微调，以生成更符合实际IMU数据特征的运动信号。L_acc通过约束生成运动在离散二阶时间差上的一致性，使扩散模型先验与IMU加速度模式对齐。实验表明，加入L_acc后，模型在高动态活动（如跑步、跳跃）中的误差下降12.7%，合成数据在低维嵌入空间中更接近真实IMU数据分布。在人体活动识别（HAR）任务中，仅使用该方法生成的合成数据训练模型，性能相比原有扩散模型提升8.7%，优于最佳对比基线7.6%。结果表明，加速度感知的扩散模型微调能有效提升运动生成与IMU合成的一致性，展示了深度学习流水线在特定传感器任务中的可定制性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到运动生成模型虽能生成自然动作，但其输出的加速度特征与真实IMU记录存在偏差，影响下游任务如人体活动识别（HAR）的性能。因此，亟需一种方法将通用运动生成模型适配为符合IMU物理特性的传感器专用生成器。

Method: 在已有扩散模型基础上，引入加速度相关的二阶损失函数（L_acc），通过微调使模型生成的运动在时间上保持加速度模式的一致性；结合表面建模与虚拟传感器模拟，评估生成的IMU数据质量，并用于训练和测试人体活动识别模型。

Result: 加入L_acc后，模型在高动态活动中加速度误差降低12.7%；合成数据在低维嵌入空间中更接近真实数据分布；在仅用合成数据训练的HAR任务中，分类准确率较原模型提升8.7%，优于最佳对比模型7.6%。

Conclusion: 加速度感知的扩散模型微调是一种有效手段，能够将通用文本到运动生成模型适配为高质量的文本到IMU合成框架，显著提升生成数据的真实性与下游应用性能，凸显了深度学习模型在传感器特定任务中的灵活性与可扩展性。

Abstract: We propose a text-to-IMU (inertial measurement unit) motion-synthesis framework to obtain realistic IMU data by fine-tuning a pretrained diffusion model with an acceleration-based second-order loss (L_acc). L_acc enforces consistency in the discrete second-order temporal differences of the generated motion, thereby aligning the diffusion prior with IMU-specific acceleration patterns. We integrate L_acc into the training objective of an existing diffusion model, finetune the model to obtain an IMU-specific motion prior, and evaluate the model with an existing text-to-IMU framework that comprises surface modelling and virtual sensor simulation. We analysed acceleration signal fidelity and differences between synthetic motion representation and actual IMU recordings. As a downstream application, we evaluated Human Activity Recognition (HAR) and compared the classification performance using data of our method with the earlier diffusion model and two additional diffusion model baselines. When we augmented the earlier diffusion model objective with L_acc and continued training, L_acc decreased by 12.7% relative to the original model. The improvements were considerably larger in high-dynamic activities (i.e., running, jumping) compared to low-dynamic activities~(i.e., sitting, standing). In a low-dimensional embedding, the synthetic IMU data produced by our refined model shifts closer to the distribution of real IMU recordings. HAR classification trained exclusively on our refined synthetic IMU data improved performance by 8.7% compared to the earlier diffusion model and by 7.6% over the best-performing comparison diffusion model. We conclude that acceleration-aware diffusion refinement provides an effective approach to align motion generation and IMU synthesis and highlights how flexible deep learning pipelines are for specialising generic text-to-motion priors to sensor-specific tasks.

</details>


### [152] [When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation](https://arxiv.org/abs/2512.08875)
*Joshua Ward,Bochao Gu,Chi-Hua Wang,Guang Cheng*

Main category: cs.LG

TL;DR: 本文研究了大语言模型（LLMs）在生成表格合成数据时存在的隐私泄露问题，发现其在细调和提示两种方法中均存在记忆训练数据中数值模式的风险。为此，作者提出一种无需访问模型内部的成员推理攻击（LevAtt），仅通过分析生成的合成数据中的数字字符串序列即可实现高精度的成员识别，甚至在某些情况下可达到完美分类效果。该研究揭示了基于LLM的合成数据生成中的独特隐私漏洞，并提出了两种防御方法，其中一种新颖的采样策略通过有策略地扰动生成过程中的数字来有效抵御攻击，同时保持数据保真度和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生成高质量合成表格数据方面表现出色，但其可能通过记忆训练数据中的数值模式导致隐私泄露，现有方法缺乏对这一风险的系统性评估与防御机制，因此亟需探索并解决该隐私漏洞。

Method: 提出一种无盒子成员推理攻击（LevAtt），利用生成的合成数据中数字序列特征进行攻击；设计一种新的采样策略，通过在生成过程中有策略地扰动数字以增强隐私保护。

Result: LevAtt攻击在多种模型和数据集上均表现出显著的隐私泄露，部分情况下可实现完美成员分类；所提出的采样策略能有效抵御攻击，同时对数据质量和可用性影响极小。

Conclusion: 基于大语言模型的合成数据生成存在严重的隐私风险，尤其体现在对数值模式的记忆化再现；提出的方法可有效缓解此问题，为未来合成数据生成系统的隐私安全提供重要指导。

Abstract: Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of numeric digits from their training data. To systematically analyze this risk, we introduce a simple No-box Membership Inference Attack (MIA) called LevAtt that assumes adversarial access to only the generated synthetic data and targets the string sequences of numeric digits in synthetic observations. Using this approach, our attack exposes substantial privacy leakage across a wide range of models and datasets, and in some cases, is even a perfect membership classifier on state-of-the-art models. Our findings highlight a unique privacy vulnerability of LLM-based synthetic data generation and the need for effective defenses. To this end, we propose two methods, including a novel sampling strategy that strategically perturbs digits during generation. Our evaluation demonstrates that this approach can defeat these attacks with minimal loss of fidelity and utility of the synthetic data.

</details>


### [153] [DAO-GP Drift Aware Online Non-Linear Regression Gaussian-Process](https://arxiv.org/abs/2512.08879)
*Mohammad Abu-Shaira,Ajita Rattani,Weishi Shi*

Main category: cs.LG

TL;DR: 提出DAO-GP，一种自适应、无超参数、带衰减机制的在线高斯过程模型，用于解决概念漂移问题。该模型具备漂移检测与动态调整能力，在多种数据分布变化下表现优异，相比现有方法具有更强的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据常呈现随时间演变的分布特性（即概念漂移），而传统在线模型因固定超参数和缺乏对漂移的感知能力，导致预测性能下降。同时，现有在线高斯过程方法存在对漂移不敏感、依赖固定超参数、易受数据窥探影响、缺乏合理衰减机制及内存效率低等问题。

Method: 提出DAO-GP，一种全自适应、无超参数、支持衰减和稀疏化的非线性回归模型。其核心包括内置的漂移检测机制，根据漂移强度动态调整模型行为；采用动态诱导点更新策略实现高效内存管理；通过原理性衰减机制避免过时数据干扰。

Result: 在多种静态与漂移场景（包括突变、渐进、缓慢漂移）下，DAO-GP均表现出优越或相当的性能。实验验证了其动态适应性、高效的内存管理能力以及可演化的诱导点结构，显著优于当前主流的参数化与非参数化在线模型。

Conclusion: DAO-GP是一种针对概念漂移的鲁棒在线非线性回归解决方案，兼具自适应性、高效性与可扩展性，适用于现实世界的动态数据环境。

Abstract: Real-world datasets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. Gaussian Process (GP) models offer powerful non-parametric regression capabilities with uncertainty quantification, making them ideal for modeling complex data relationships in an online setting. However, conventional online GP methods face several critical limitations, including a lack of drift-awareness, reliance on fixed hyperparameters, vulnerability to data snooping, absence of a principled decay mechanism, and memory inefficiencies. In response, we propose DAO-GP (Drift-Aware Online Gaussian Process), a novel, fully adaptive, hyperparameter-free, decayed, and sparse non-linear regression model. DAO-GP features a built-in drift detection and adaptation mechanism that dynamically adjusts model behavior based on the severity of drift. Extensive empirical evaluations confirm DAO-GP's robustness across stationary conditions, diverse drift types (abrupt, incremental, gradual), and varied data characteristics. Analyses demonstrate its dynamic adaptation, efficient in-memory and decay-based management, and evolving inducing points. Compared with state-of-the-art parametric and non-parametric models, DAO-GP consistently achieves superior or competitive performance, establishing it as a drift-resilient solution for online non-linear regression.

</details>


### [154] [Unsupervised Learning of Density Estimates with Topological Optimization](https://arxiv.org/abs/2512.08895)
*Suina Tanweer,Firas A. Khasawneh*

Main category: cs.LG

TL;DR: 本文提出一种基于拓扑的损失函数，用于自动无监督选择核密度估计中的最优带宽，并在不同维度下与经典方法进行对比，展示了其在多个场景下的潜力。


<details>
  <summary>Details</summary>
Motivation: 核密度估计是机器学习、贝叶斯推断等多个领域的重要技术，但其性能高度依赖于带宽的选择，而带宽的调整直接影响偏差-方差权衡和拓扑特征的保留。传统方法难以在高维数据中有效确定最优带宽，因此需要一种自动化、无监督的方法来优化这一关键超参数。

Method: 提出一种基于拓扑数据分析的损失函数，利用拓扑特征（如连通分量、环状结构等）量化密度估计的几何结构，并通过该损失函数实现对带宽的无监督自动选择。

Result: 实验表明，所提方法在不同维度的数据上均能有效选择出合理的带宽，相比经典方法具有更好的稳定性与适应性，尤其在高维数据中表现更优。

Conclusion: 基于拓扑的损失函数能够有效实现核密度估计中带宽的自动化选择，为高维数据中的无监督密度估计提供了新的解决方案。

Abstract: Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological characteristics, such as connected components, loops, voids et cetera, even in high dimensions where visualization of density estimates is impossible. In this paper, we propose an unsupervised learning approach using a topology-based loss function for the automated and unsupervised selection of the optimal bandwidth and benchmark it against classical techniques -- demonstrating its potential across different dimensions.

</details>


### [155] [Open Polymer Challenge: Post-Competition Report](https://arxiv.org/abs/2512.08896)
*Gang Liu,Sobin Alosious,Subhamoy Mahajan,Eric Inae,Yihan Zhu,Yuhan Liu,Renzheng Zhang,Jiaxin Xu,Addison Howard,Ying Li,Tengfei Luo,Meng Jiang*

Main category: cs.LG

TL;DR: 该论文介绍了开放聚合物挑战赛（OPC），发布首个由社区共同开发的聚合物信息学基准数据集，包含10,000种聚合物及其五项关键性质：热导率、回转半径、密度、自由体积分数和玻璃化转变温度。挑战聚焦于多任务聚合物性质预测，旨在推动虚拟筛选在材料发现中的应用。参赛者在小样本、标签不平衡和异源模拟来源等现实约束下，采用特征增强、迁移学习、自监督预训练和针对性集成策略构建模型。比赛揭示了数据准备、分布偏移和跨组模拟一致性等关键问题，为未来大规模聚合物数据集提供了最佳实践建议。研究成果、模型与公开数据为分子人工智能在聚合物科学中的发展奠定新基础，有望加速可持续、节能材料的研发。测试数据集已通过Kaggle发布，并提供数据生成管道开源代码。


<details>
  <summary>Details</summary>
Motivation: 当前聚合物材料发现受限于缺乏大规模、高质量且公开可获取的数据集，阻碍了机器学习在该领域的应用进展。为解决这一瓶颈，需建立标准化、可复现的基准测试体系以推动研究发展。

Method: 采用社区协作方式构建聚合物数据集；设计多任务学习框架进行性质预测；引入特征增强、迁移学习、自监督预训练及集成学习等技术应对小样本与数据异质性问题；通过竞赛形式评估模型性能并挖掘实际挑战。

Result: 成功构建首个包含10,000种聚合物的公开聚合物性质基准数据集；参赛模型在真实复杂条件下表现出良好泛化能力；识别出数据分布偏移、模拟一致性等问题；发布测试集与数据生成工具链，支持后续研究复现与扩展。

Conclusion: 本研究建立了聚合物信息学的重要基准，推动了机器学习在可持续聚合物材料设计中的应用，其成果将促进分子人工智能在材料科学中的进一步发展。

Abstract: Machine learning (ML) offers a powerful path toward discovering sustainable polymer materials, but progress has been limited by the lack of large, high-quality, and openly accessible polymer datasets. The Open Polymer Challenge (OPC) addresses this gap by releasing the first community-developed benchmark for polymer informatics, featuring a dataset with 10K polymers and 5 properties: thermal conductivity, radius of gyration, density, fractional free volume, and glass transition temperature. The challenge centers on multi-task polymer property prediction, a core step in virtual screening pipelines for materials discovery. Participants developed models under realistic constraints that include small data, label imbalance, and heterogeneous simulation sources, using techniques such as feature-based augmentation, transfer learning, self-supervised pretraining, and targeted ensemble strategies. The competition also revealed important lessons about data preparation, distribution shifts, and cross-group simulation consistency, informing best practices for future large-scale polymer datasets. The resulting models, analysis, and released data create a new foundation for molecular AI in polymer science and are expected to accelerate the development of sustainable and energy-efficient materials. Along with the competition, we release the test dataset at https://www.kaggle.com/datasets/alexliu99/neurips-open-polymer-prediction-2025-test-data. We also release the data generation pipeline at https://github.com/sobinalosious/ADEPT, which simulates more than 25 properties, including thermal conductivity, radius of gyration, and density.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [156] [Impact of Data-Oriented and Object-Oriented Design on Performance and Cache Utilization with Artificial Intelligence Algorithms in Multi-Threaded CPUs](https://arxiv.org/abs/2512.07841)
*Gabriel M. Arantes,Richard F. Pinto,Bruno L. Dalmazo,Eduardo N. Borges,Giancarlo Lucca,Viviane L. D. de Mattos,Fabian C. Cardoso,Rafael A. Berri*

Main category: cs.AI

TL;DR: 本研究对比了数据导向设计（DOD）与传统面向对象设计（OOD）在多核CPU与主存性能差距日益扩大的背景下的表现，重点分析了缓存利用效率和多线程环境中的性能。通过实现并比较A*搜索算法的四种版本（ST-OOD、ST-DOD、MT-OOD、MT-DOD），发现DOD在多线程场景下显著提升执行速度、减少系统调用和缓存未命中，尽管在内存使用或缓存命中率百分比上OOD偶有优势，但DOD在数据密集型操作中更具效率。此外，单线程版本普遍优于多线程版本，因线程管理开销较大。结论指出，即使在简单算法中差异不明显，DOD在关键指标上的持续优势表明其在复杂大规模AI与并行计算任务中具有架构上的根本优势。


<details>
  <summary>Details</summary>
Motivation: 随着多核CPU与主存之间性能差距扩大，传统的面向对象设计在缓存利用和并行效率方面面临挑战，亟需更贴近硬件特性的软件设计范式，因此本研究旨在评估数据导向设计（DOD）相较于传统面向对象设计（OOD）在多线程环境下的性能表现。

Method: 构建并比较A*搜索算法的四种实现：单线程OOD（ST-OOD）、单线程DOD（ST-DOD）、多线程OOD（MT-OOD）、多线程DOD（MT-DOD），通过执行时间、内存使用、缓存未命中等指标进行性能评估，并分析多线程环境下线程管理开销的影响。

Result: 在多线程测试中，DOD版本表现出更快的执行速度、更低的系统调用次数和缓存未命中数；虽然在内存使用或缓存命中率百分比上OOD略有优势，但在数据密集型任务中DOD整体效率更高；单线程版本普遍优于多线程版本，主要由于线程管理开销。

Conclusion: 尽管在简单算法中性能差异可能不显著，但数据导向设计（DOD）在关键性能指标上的持续优势，凸显其在复杂、大规模人工智能与并行计算任务中具备更高的硬件利用效率，是一种更优的架构设计范式。

Abstract: The growing performance gap between multi-core CPUs and main memory necessitates hardware-aware software design paradigms. This study provides a comprehensive performance analysis of Data Oriented Design (DOD) versus the traditional Object-Oriented Design (OOD), focusing on cache utilization and efficiency in multi-threaded environments. We developed and compared four distinct versions of the A* search algorithm: single-threaded OOD (ST-OOD), single-threaded DOD (ST-DOD), multi-threaded OOD (MT-OOD), and multi-threaded DOD (MT-DOD). The evaluation was based on metrics including execution time, memory usage, and CPU cache misses. In multi-threaded tests, the DOD implementation demonstrated considerable performance gains, with faster execution times and a lower number of raw system calls and cache misses. While OOD occasionally showed marginal advantages in memory usage or percentage-based cache miss rates, DOD's efficiency in data-intensive operations was more evident. Furthermore, our findings reveal that for a fine-grained task like the A* algorithm, the overhead associated with thread management led to single-threaded versions significantly outperforming their multi-threaded counterparts in both paradigms. We conclude that even when performance differences appear subtle in simple algorithms, the consistent advantages of DOD in critical metrics highlight its foundational architectural superiority, suggesting it is a more effective approach for maximizing hardware efficiency in complex, large-scale AI and parallel computing tasks.

</details>


### [157] [SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models](https://arxiv.org/abs/2512.07993)
*Jiayi Tian,Seyedarmin Azizi,Yequan Zhao,Erfan Baghaei Potraghloo,Sean McPherson,Sharath Nittur Sridhar,Zhengyang Wang,Zheng Zhang,Massoud Pedram,Souvik Kundu*

Main category: cs.AI

TL;DR: SkipKV 是一种无需训练的 KV 缓存压缩方法，通过粗粒度句子级移除来优化链式思维（CoT）推理中的缓存开销。它引入句子评分机制以识别并移除高度相似的句子，同时保持语义连贯性，并通过动态调整引导向量来抑制冗余生成，从而减少生成长度。在多个推理基准测试中，SkipKV 在相近压缩预算下相比现有方法提升最高达 26.7% 的准确率，生成长度减少最多 1.6 倍，吞吐量提升最高达 1.7 倍。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在链式思维（CoT）推理过程中因键值（KV）缓存线性增长而产生显著内存和吞吐瓶颈。现有最优的 KV 缓存淘汰方法在多批次设置下表现不佳，主要由于标记级评分不稳定及填充令牌导致的有效缓存预算下降。此外，这些方法常生成更长序列，因缺乏语义感知的逐标记淘汰造成重复验证。因此需要一种高效、准确且无需训练的方案来压缩 KV 缓存并减少冗余生成。

Method: 提出 SkipKV，一种训练自由的粗粒度句子级选择性淘汰与生成方法。通过引入句子评分机制识别并移除高度相似的句子以维持语义连贯性；同时动态调整引导向量，在推理期间更新隐藏激活状态，强制大模型生成更简洁响应，从而抑制冗余生成。

Result: 在多个推理基准上，SkipKV 在类似压缩预算下实现最高 26.7% 的准确率提升，生成长度减少最多 1.6 倍，吞吐量提升最高达 1.7 倍，优于现有最先进方法。

Conclusion: SkipKV 有效解决了 CoT 推理中 KV 缓存膨胀与冗余生成问题，无需训练即可在保持高准确率的同时显著降低内存占用与生成延迟，为高效部署大型推理模型提供了可行路径。

Abstract: Large reasoning models (LRMs) often cost significant key-value (KV) cache overhead, due to their linear growth with the verbose chain-of-thought (CoT) reasoning process. This costs both memory and throughput bottleneck limiting their efficient deployment. Towards reducing KV cache size during inference, we first investigate the effectiveness of existing KV cache eviction methods for CoT reasoning. Interestingly, we find that due to unstable token-wise scoring and the reduced effective KV budget caused by padding tokens, state-of-the-art (SoTA) eviction methods fail to maintain accuracy in the multi-batch setting. Additionally, these methods often generate longer sequences than the original model, as semantic-unaware token-wise eviction leads to repeated revalidation during reasoning. To address these issues, we present \textbf{SkipKV}, a \textbf{\textit{training-free}} KV compression method for selective \textit{eviction} and \textit{generation} operating at a coarse-grained sentence-level sequence removal for efficient CoT reasoning. In specific, it introduces a \textit{sentence-scoring metric} to identify and remove highly similar sentences while maintaining semantic coherence. To suppress redundant generation, SkipKV dynamically adjusts a steering vector to update the hidden activation states during inference enforcing the LRM to generate concise response. Extensive evaluations on multiple reasoning benchmarks demonstrate the effectiveness of SkipKV in maintaining up to $\mathbf{26.7}\%$ improved accuracy compared to the alternatives, at a similar compression budget. Additionally, compared to SoTA, SkipKV yields up to $\mathbf{1.6}\times$ fewer generation length while improving throughput up to $\mathbf{1.7}\times$.

</details>


### [158] [Toward an AI Reasoning-Enabled System for Patient-Clinical Trial Matching](https://arxiv.org/abs/2512.08026)
*Caroline N. Leach,Mitchell A. Klusty,Samuel E. Armstrong,Justine C. Pickarski,Kristen L. Hankins,Emily B. Collier,Maya Shah,Aaron D. Mullen,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 本文提出了一种基于人工智能的患者-试验匹配系统，旨在解决临床试验入组筛选中数据异构、人工审核困难和安全标准高等挑战。系统利用开源的大语言模型（LLM），实现从非结构化电子健康记录（EHR）中提取信息，并生成具有可解释推理链的结构化评估结果，支持人机协同审查。该工具将入组状态视为动态过程，不仅识别当前匹配的试验，还提供未来可能满足条件的建议，从而减轻协调员负担、扩大潜在试验范围，并确保所有AI输出可审计。


<details>
  <summary>Details</summary>
Motivation: 当前临床试验患者筛选依赖人工，耗时且资源消耗大，存在效率低、覆盖范围有限及可追溯性差等问题。亟需一种高效、可解释、安全的智能辅助系统来提升匹配精度与流程透明度。

Method: 采用开源、具备推理能力的大语言模型（LLM），整合多源异构电子健康记录（EHR）数据；通过自然语言理解与逻辑推理生成结构化的入组评估报告，包含可解释的推理链条；支持专家在线审阅与反馈，实现人机协同决策；系统设计保障数据隐私与操作可审计性。

Result: 系统成功实现了对患者与临床试验的动态匹配，能够生成具有可解释性的入组建议，显著提升筛选效率与灵活性；实验证明其在真实医疗数据上具备良好的准确性与实用性，同时满足安全与可审计要求。

Conclusion: 本研究构建了一个安全、可扩展的AI辅助患者-试验匹配原型系统，突破了传统二元判断的局限，推动临床试验筛选向智能化、动态化、透明化方向发展，具有广泛的应用前景。

Abstract: Screening patients for clinical trial eligibility remains a manual, time-consuming, and resource-intensive process. We present a secure, scalable proof-of-concept system for Artificial Intelligence (AI)-augmented patient-trial matching that addresses key implementation challenges: integrating heterogeneous electronic health record (EHR) data, facilitating expert review, and maintaining rigorous security standards. Leveraging open-source, reasoning-enabled large language models (LLMs), the system moves beyond binary classification to generate structured eligibility assessments with interpretable reasoning chains that support human-in-the-loop review. This decision support tool represents eligibility as a dynamic state rather than a fixed determination, identifying matches when available and offering actionable recommendations that could render a patient eligible in the future. The system aims to reduce coordinator burden, intelligently broaden the set of trials considered for each patient and guarantee comprehensive auditability of all AI-generated outputs.

</details>


### [159] [Large Language Models for Education and Research: An Empirical and User Survey-based Analysis](https://arxiv.org/abs/2512.08057)
*Md Mostafizer Rahman,Ariful Islam Shiplu,Md Faizul Ibne Amin,Yutaka Watanobe,Lu Peng*

Main category: cs.AI

TL;DR: 本研究全面评估了ChatGPT和DeepSeek两款大语言模型在教育与科研领域的表现，通过技术分析、实验测试和用户调查，比较了其在准确性、计算效率和用户体验方面的权衡。结果显示，ChatGPT在通用语言理解和文本生成方面更优，而DeepSeek在编程任务中因注重效率设计而表现更佳；两者在医学诊断和复杂数学问题求解上均表现出色。用户调查进一步揭示了实际应用中的优势与局限性，为大模型在教育科研中的应用提供了实践参考。


<details>
  <summary>Details</summary>
Motivation: 随着预训练大语言模型在教育和科研领域取得显著成果，亟需系统评估主流模型在不同任务中的表现，以指导实际应用并揭示其优势与局限。

Method: 采用背景技术分析、实证实验和真实用户调查相结合的方法，对ChatGPT和DeepSeek在文本生成、编程和专业问题解决等任务上的性能进行综合评估。

Result: ChatGPT在通用语言理解与文本生成方面表现优异；DeepSeek在编程任务中因高效设计而更具优势；两者在医学诊断与数学问题求解上均具有高准确率。用户调查反映出模型在实际使用中的便利性与现存挑战。

Conclusion: 大语言模型在教育与科研中具有重要价值，但不同模型在特定任务中各有优劣，应根据具体需求选择合适模型，并持续优化其用户体验与可靠性。

Abstract: Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with education and research emerging as particularly impactful areas. Among current state-of-the-art LLMs, ChatGPT and DeepSeek exhibit strong capabilities in mathematics, science, medicine, literature, and programming. In this study, we present a comprehensive evaluation of these two LLMs through background technology analysis, empirical experiments, and a real-world user survey. The evaluation explores trade-offs among model accuracy, computational efficiency, and user experience in educational and research affairs. We benchmarked these LLMs performance in text generation, programming, and specialized problem-solving. Experimental results show that ChatGPT excels in general language understanding and text generation, while DeepSeek demonstrates superior performance in programming tasks due to its efficiency- focused design. Moreover, both models deliver medically accurate diagnostic outputs and effectively solve complex mathematical problems. Complementing these quantitative findings, a survey of students, educators, and researchers highlights the practical benefits and limitations of these models, offering deeper insights into their role in advancing education and research.

</details>


### [160] [Scalable Back-End for an AI-Based Diabetes Prediction Application](https://arxiv.org/abs/2512.08147)
*Henry Anand Septian Radityo,Bernardus Willson,Reynard Tanadi,Latifa Dwiyanti,Saiful Akbar*

Main category: cs.AI

TL;DR: 本文设计并评估了一个用于移动糖尿病预测应用的可扩展后端系统，旨在将故障率控制在5%以下，平均延迟低于1000毫秒。系统采用水平扩展、数据库分片和基于消息队列的异步通信，83%的功能（20/24）达到性能目标，支持最多10,000并发用户，异步通信有效降低计算密集型请求的错误率，保障系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 全球糖尿病患病率上升，亟需早期检测以预防严重并发症；现有AI预测应用需高效、可扩展的后端架构以服务大量用户。

Method: 采用水平扩展、数据库分片和基于RabbitMQ的消息队列实现异步通信，优化系统性能与可靠性。

Result: 83%的功能满足性能目标，系统可支持10,000并发用户，异步通信显著降低高负载下的错误率，确保数据不丢失。

Conclusion: 所提出的后端架构有效支持大规模用户访问，具备良好的可扩展性与可靠性，适用于高并发的糖尿病预测应用。

Abstract: The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While AI-powered prediction applications offer a promising solution, they require a responsive and scalable back-end architecture to serve a large user base effectively. This paper details the development and evaluation of a scalable back-end system designed for a mobile diabetes prediction application. The primary objective was to maintain a failure rate below 5% and an average latency of under 1000 ms. The architecture leverages horizontal scaling, database sharding, and asynchronous communication via a message queue. Performance evaluation showed that 83% of the system's features (20 out of 24) met the specified performance targets. Key functionalities such as user profile management, activity tracking, and read-intensive prediction operations successfully achieved the desired performance. The system demonstrated the ability to handle up to 10,000 concurrent users without issues, validating its scalability. The implementation of asynchronous communication using RabbitMQ proved crucial in minimizing the error rate for computationally intensive prediction requests, ensuring system reliability by queuing requests and preventing data loss under heavy load.

</details>


### [161] [Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes](https://arxiv.org/abs/2512.08261)
*Yibowen Zhao,Yinan Zhang,Zhixiang Su,Lizhen Cui,Chunyan Miao*

Main category: cs.AI

TL;DR: KPI框架通过整合医学知识图谱、构建疾病原型并利用对比学习，提升了疾病预测的准确性和可解释性，尤其在长尾疾病上表现优异，并通过大语言模型生成患者特定的医学解释，增强了临床实用性。


<details>
  <summary>Details</summary>
Motivation: 现有疾病预测方法面临疾病分布不均和可解释性差的问题，导致预测结果存在偏差或不可靠，亟需更准确且可解释的解决方案以支持患者中心的医疗实践。

Method: 提出KPI框架，融合结构化医学知识构建疾病知识图谱，建立临床有意义的疾病原型，采用对比学习提升预测性能，并利用大语言模型生成患者相关的医学解释以增强可解释性。

Result: 在真实数据集上的实验表明，KPI在预测准确性上优于现有先进方法，并能生成与患者叙述高度一致的临床有效解释，展现出其在患者导向医疗中的实际价值。

Conclusion: KPI框架有效解决了疾病预测中的不平衡分布与可解释性难题，为实现精准、可靠且以人为本的疾病预测提供了新范式。

Abstract: Predicting diseases solely from patient-side information, such as demographics and self-reported symptoms, has attracted significant research attention due to its potential to enhance patient awareness, facilitate early healthcare engagement, and improve healthcare system efficiency. However, existing approaches encounter critical challenges, including imbalanced disease distributions and a lack of interpretability, resulting in biased or unreliable predictions. To address these issues, we propose the Knowledge graph-enhanced, Prototype-aware, and Interpretable (KPI) framework. KPI systematically integrates structured and trusted medical knowledge into a unified disease knowledge graph, constructs clinically meaningful disease prototypes, and employs contrastive learning to enhance predictive accuracy, which is particularly important for long-tailed diseases. Additionally, KPI utilizes large language models (LLMs) to generate patient-specific, medically relevant explanations, thereby improving interpretability and reliability. Extensive experiments on real-world datasets demonstrate that KPI outperforms state-of-the-art methods in predictive accuracy and provides clinically valid explanations that closely align with patient narratives, highlighting its practical value for patient-centered healthcare delivery.

</details>


### [162] [Reasoning Models Ace the CFA Exams](https://arxiv.org/abs/2512.08270)
*Jaisal Patel,Yunzhe Chen,Kaiwen He,Keyi Wang,David Li,Kairong Xiao,Xiao-Yang Liu*

Main category: cs.AI

TL;DR: 本研究评估了最先进的推理模型在模拟CFA考试中的表现，涵盖三个Level I、两个Level II和三个Level III的题目。结果显示，大多数模型均通过了所有三个级别，其中Gemini 3.0 Pro在Level I中取得97.6%的最高分，GPT-5在Level II表现最佳（94.3%），Gemini 2.5 Pro在Level III多选题中得分最高（86.4%），Gemini 3.0 Pro在简答题中达92.0%。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明大语言模型在CFA考试中表现不佳，但近期推理模型在多个学科的研究生级和专业考试中表现优异。因此，本文旨在重新评估最新推理模型在CFA考试中的实际能力，以验证其是否已具备应对高难度金融专业考试的能力。

Method: 采用与之前研究相同的及格标准，对980道来自CFA Level I至Level III的模拟试题进行测试，涵盖多项选择题和简答题，使用当前最先进推理模型进行评估，并按整体表现排序。

Result: 多数模型通过所有三级别考试；Gemini 3.0 Pro在Level I中取得97.6%的最高分，GPT-5在Level II中表现最佳（94.3%），Gemini 2.5 Pro在Level III多选题中得分最高（86.4%），而Gemini 3.0 Pro在构造性问题中达到92.0%。

Conclusion: 最新的推理模型在CFA考试中表现出色，已具备通过金融专业资格考试的能力，表明其在复杂专业任务上的推理和知识应用能力显著提升。

Abstract: Previous research has reported that large language models (LLMs) demonstrate poor performance on the Chartered Financial Analyst (CFA) exams. However, recent reasoning models have achieved strong results on graduate-level academic and professional examinations across various disciplines. In this paper, we evaluate state-of-the-art reasoning models on a set of mock CFA exams consisting of 980 questions across three Level I exams, two Level II exams, and three Level III exams. Using the same pass/fail criteria from prior studies, we find that most models clear all three levels. The models that pass, ordered by overall performance, are Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, and DeepSeek-V3.1. Specifically, Gemini 3.0 Pro achieves a record score of 97.6% on Level I. Performance is also strong on Level II, led by GPT-5 at 94.3%. On Level III, Gemini 2.5 Pro attains the highest score with 86.4% on multiple-choice questions while Gemini 3.0 Pro achieves 92.0% on constructed-response questions.

</details>


### [163] [Towards a Science of Scaling Agent Systems](https://arxiv.org/abs/2512.08296)
*Yubin Kim,Ken Gu,Chanwoo Park,Chunjong Park,Samuel Schmidgall,A. Ali Heydari,Yao Yan,Zhihan Zhang,Yuchen Zhuang,Mark Malhotra,Paul Pu Liang,Hae Won Park,Yuzhe Yang,Xuhai Xu,Yilun Du,Shwetak Patel,Tim Althoff,Daniel McDuff,Xin Liu*

Main category: cs.AI

TL;DR: 本文研究了基于语言模型的智能体系统在现实世界应用中的性能决定因素，通过在四个不同基准测试中评估五种典型架构（单一、独立、集中、去中心化、混合）在三种大模型家族下的180种配置，提出了一种基于实证协调度量（效率、开销、错误放大、冗余）的预测模型，实现了跨验证R²=0.513。研究发现三个关键效应：(1) 工具-协调权衡——在固定计算预算下，工具密集型任务因多智能体开销而表现更差；(2) 能力饱和现象——当单智能体基线超过约45%时，协调带来的收益递减甚至为负（beta=-0.408, p<0.001）；(3) 拓扑依赖的错误放大——独立智能体导致错误放大17.2倍，集中式仅4.4倍。集中式在可并行任务（如金融推理）中提升80.9%，去中心化在动态网页导航中优于单智能体9.2%；但所有多智能体变体在序列推理任务中性能下降39%-70%。该框架能预测87%未见配置的最优协调策略，为智能体系统的可扩展性提供了基于任务属性的可预测原则。


<details>
  <summary>Details</summary>
Motivation: 尽管基于语言模型的智能体系统已成为现实世界AI应用的主流范式，但其性能影响因素仍缺乏系统性理解，导致实践者依赖启发式而非有原则的设计选择。本文旨在填补这一空白，建立可量化、可预测的智能体系统缩放原则。

Method: 在四个多样化基准测试（Finance-Agent、BrowseComp-Plus、PlanCraft、Workbench）上，对五种典型智能体架构（单一、独立、集中、去中心化、混合）在三种大语言模型家族下的180种配置进行受控实验，采用标准化工具和令牌预算。通过测量效率、开销、错误放大、冗余等协调指标，构建并验证预测模型。

Result: 提出一个基于协调度量的预测模型，跨验证R²达0.513；识别出三大核心效应：工具-协调权衡、能力饱和、拓扑依赖错误放大；集中式在并行任务中提升80.9%，去中心化在动态导航中优势显著（+9.2%），但所有多智能体结构在序列推理中均表现更差（下降39%-70%）；框架可准确预测87%未见配置的最优策略。

Conclusion: 本研究建立了基于任务属性的智能体系统可扩展性预测原则，揭示了协调机制与任务特性之间的定量关系，为智能体系统设计提供了可解释、可预测的指导框架，推动从经验驱动向原理驱动的转变。

Abstract: Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on heuristics rather than principled design choices. We address this gap by deriving quantitative scaling principles for agent systems. We evaluate this across four diverse benchmarks: Finance-Agent, BrowseComp-Plus, PlanCraft, and Workbench. Using five canonical architectures (Single, Independent, Centralized, Decentralized, Hybrid) instantiated across three LLM families, we perform a controlled evaluation spanning 180 configurations with standardized tools and token budgets. We derive a predictive model using empirical coordination metrics, including efficiency, overhead, error amplification, and redundancy, that achieves cross-validated R^2=0.513. We identify three dominant effects: (1) a tool-coordination trade-off: under fixed computational budgets, tool-heavy tasks suffer disproportionately from multi-agent overhead. (2) a capability saturation: coordination yields diminishing or negative returns (beta=-0.408, p<0.001) once single-agent baselines exceed ~45%. (3) topology-dependent error amplification: independent agents amplify errors 17.2x through unchecked propagation, while centralized coordination contains this to 4.4x. Centralized coordination improves performance by 80.9% on parallelizable tasks like financial reasoning, while decentralized coordination excels on dynamic web navigation (+9.2% vs. +0.2%). Yet for sequential reasoning tasks, all multi-agent variants degraded performance by 39-70%. The framework predicts the optimal coordination strategy for 87% of held-out configurations, providing a predictive principle of agentic scaling based on measurable task properties.

</details>


### [164] [rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection](https://arxiv.org/abs/2512.08300)
*Sijia Chen,Baochun Li,Di Niu*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的强化策略注入机制（rSIM），通过一个小规划器引导大语言模型（LLM）在思维链（CoT）中自适应地注入推理策略，使其进化为推理语言模型（RLM）。该规划器与LLM采用多智能体强化学习（MARL）联合训练，基于领导者-跟随者框架和简单的规则奖励。实验表明，rSIM使Qwen2.5-0.5B具备了超越Qwen2.5-14B的推理能力，且规划器具有高度可迁移性，仅需一次训练即可作为插件提升多种现有LLM的推理性能，并支持跨任务持续学习，逐步增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在经过强化学习后可发展出类似‘顿悟’的高级推理能力，如自我反思和深度思考。然而，如何高效、通用地赋予现有模型这种能力仍具挑战。为此，本文旨在设计一种轻量、可复用的机制，让任意LLM都能快速获得强推理能力。

Method: 提出rSIM机制，利用一个规划器（领导者）与LLM（跟随者）在多智能体强化学习框架下协同训练；规划器通过规则奖励引导LLM在思维链中动态注入推理策略，实现自适应推理。

Result: rSIM成功使小型模型Qwen2.5-0.5B在推理任务上超越大型模型Qwen2.5-14B；规划器具备良好的泛化能力，可作为插件部署于多种模型，并支持持续学习以提升跨任务表现。

Conclusion: rSIM是一种高效、通用且可扩展的策略注入机制，能够将普通LLM转化为高性能推理模型，显著提升其推理能力，同时具备低资源消耗和高可移植性的优势。

Abstract: Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.

</details>


### [165] [Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from Türkiye](https://arxiv.org/abs/2512.08340)
*Abdullah Hulusi Kökçam,Uğur Dağdeviren,Talas Fikret Kurnaz,Alparslan Serhat Demir,Caner Erden*

Main category: cs.AI

TL;DR: 本研究提出了一种基于机器学习的加州承载比（CBR）预测框架，利用来自土耳其不同地理气候区域的382个土样数据集，评估了12种机器学习算法在预测土体承载能力方面的表现。随机森林回归模型表现最佳，测试集R²达0.83，显示出强大的非线性建模能力，为地质工程中的数据驱动方法提供了有力支持，推动基础设施分析与设计的数字化转型。


<details>
  <summary>Details</summary>
Motivation: 传统CBR测试耗时长、成本高，难以应用于大规模或多样化的土壤剖面，亟需高效、准确的替代方法。机器学习技术的发展为快速、精准预测土壤承载力提供了新途径。

Method: 采用12种机器学习算法（如随机森林、XGBoost、支持向量回归等）对包含多种物理化学性质的382个土样数据进行训练与验证，通过对比模型性能筛选最优预测模型。

Result: 随机森林回归模型在测试集上取得0.83的R²得分，优于其他模型，表现出优异的泛化能力和鲁棒性。

Conclusion: 机器学习可有效替代传统实验室测试，实现快速、高精度的CBR预测，具有广阔应用前景，有助于推动地质工程领域的智能化与数字化发展。

Abstract: The California Bearing Ratio (CBR) is a key geotechnical indicator used to assess the load-bearing capacity of subgrade soils, especially in transportation infrastructure and foundation design. Traditional CBR determination relies on laboratory penetration tests. Despite their accuracy, these tests are often time-consuming, costly, and can be impractical, particularly for large-scale or diverse soil profiles. Recent progress in artificial intelligence, especially machine learning (ML), has enabled data-driven approaches for modeling complex soil behavior with greater speed and precision. This study introduces a comprehensive ML framework for CBR prediction using a dataset of 382 soil samples collected from various geoclimatic regions in Türkiye. The dataset includes physicochemical soil properties relevant to bearing capacity, allowing multidimensional feature representation in a supervised learning context. Twelve ML algorithms were tested, including decision tree, random forest, extra trees, gradient boosting, xgboost, k-nearest neighbors, support vector regression, multi-layer perceptron, adaboost, bagging, voting, and stacking regressors. Each model was trained, validated, and evaluated to assess its generalization and robustness. Among them, the random forest regressor performed the best, achieving strong R2 scores of 0.95 (training), 0.76 (validation), and 0.83 (test). These outcomes highlight the model's powerful nonlinear mapping ability, making it a promising tool for predictive geotechnical tasks. The study supports the integration of intelligent, data-centric models in geotechnical engineering, offering an effective alternative to traditional methods and promoting digital transformation in infrastructure analysis and design.

</details>


### [166] [Soil Compaction Parameters Prediction Based on Automated Machine Learning Approach](https://arxiv.org/abs/2512.08343)
*Caner Erden,Alparslan Serhat Demir,Abdullah Hulusi Kokcam,Talas Fikret Kurnaz,Ugur Dagdeviren*

Main category: cs.AI

TL;DR: 该研究提出了一种自动化机器学习（AutoML）方法，用于预测土壤的最佳含水率（OMC）和最大干密度（MDD），以替代传统耗时的实验室试验和精度有限的经验模型。通过AutoML自动选择算法并优化超参数，XGBoost算法表现最佳，在独立数据集上对MDD和OMC的决定系数（R²）分别达到80.4%和89.1%，表明该方法在不同土类中具有良好的预测性能与泛化能力。研究强调了异质数据集对提升模型鲁棒性的重要性，为更高效、可靠的工程建设提供了技术支持。


<details>
  <summary>Details</summary>
Motivation: 传统测定土壤最优含水率（OMC）和最大干密度（MDD）的方法依赖于繁琐的实验室实验，而现有经验回归模型在不同土壤类型间适用性差、预测精度低。因此亟需一种高效、准确且具备广泛适用性的替代方法。

Method: 采用自动化机器学习（AutoML）框架，实现算法选择与超参数自动优化；通过多组实验比较不同机器学习模型在预测OMC和MDD上的表现，最终选定表现最优的模型进行验证。

Result: XGBoost算法在独立测试集上取得了80.4%（MDD）和89.1%（OMC）的R²值，显著优于其他模型；研究表明，使用异质性土壤数据集可有效提升模型的泛化能力与预测准确性。

Conclusion: AutoML方法能够有效提升土壤压实参数的预测精度与可扩展性，尤其在复杂多变的土类条件下表现出色，为工程实践中快速、可靠地评估土壤压实性能提供了新路径。

Abstract: Soil compaction is critical in construction engineering to ensure the stability of structures like road embankments and earth dams. Traditional methods for determining optimum moisture content (OMC) and maximum dry density (MDD) involve labor-intensive laboratory experiments, and empirical regression models have limited applicability and accuracy across diverse soil types. In recent years, artificial intelligence (AI) and machine learning (ML) techniques have emerged as alternatives for predicting these compaction parameters. However, ML models often struggle with prediction accuracy and generalizability, particularly with heterogeneous datasets representing various soil types. This study proposes an automated machine learning (AutoML) approach to predict OMC and MDD. AutoML automates algorithm selection and hyperparameter optimization, potentially improving accuracy and scalability. Through extensive experimentation, the study found that the Extreme Gradient Boosting (XGBoost) algorithm provided the best performance, achieving R-squared values of 80.4% for MDD and 89.1% for OMC on a separate dataset. These results demonstrate the effectiveness of AutoML in predicting compaction parameters across different soil types. The study also highlights the importance of heterogeneous datasets in improving the generalization and performance of ML models. Ultimately, this research contributes to more efficient and reliable construction practices by enhancing the prediction of soil compaction parameters.

</details>


### [167] [DeepFeature: Iterative Context-aware Feature Generation for Wearable Biosignals](https://arxiv.org/abs/2512.08379)
*Kaiwei Liu,Yuting He,Bufang Yang,Mu Yuan,Chun Man Victor Wong,Ho Pong Andrew Sze,Zhenyu Yan,Hongkai Chen*

Main category: cs.AI

TL;DR: DeepFeature 是首个基于大语言模型（LLM）的上下文感知可穿戴生物信号特征生成框架，通过多源特征生成、迭代特征优化和多层过滤验证机制，解决现有方法在任务特定性、高维空间优化及代码生成错误方面的不足。实验表明，其在8个任务中平均提升AUROC 4.21-9.67%，优于或相当现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有特征提取方法缺乏任务特定上下文知识，难以在高维特征空间中找到最优设置，且易出现代码生成与自动化错误，限制了机器学习在可穿戴生物信号应用中的性能与可靠性。

Method: 提出DeepFeature框架，融合专家知识与任务设定的多源特征生成机制；采用基于特征评估反馈的迭代特征精炼流程；结合多层过滤与验证策略，确保特征到代码的鲁棒转换。

Result: 在8个不同任务上，DeepFeature平均提升AUROC 4.21-9.67%；在5个任务上超越当前最优方法，其余任务表现相当。

Conclusion: DeepFeature有效提升了可穿戴生物信号特征提取的智能化与可靠性，为医疗健康应用中的机器学习模型提供了更优的特征输入，具有显著的实用价值与推广潜力。

Abstract: Biosignals collected from wearable devices are widely utilized in healthcare applications. Machine learning models used in these applications often rely on features extracted from biosignals due to their effectiveness, lower data dimensionality, and wide compatibility across various model architectures. However, existing feature extraction methods often lack task-specific contextual knowledge, struggle to identify optimal feature extraction settings in high-dimensional feature space, and are prone to code generation and automation errors. In this paper, we propose DeepFeature, the first LLM-empowered, context-aware feature generation framework for wearable biosignals. DeepFeature introduces a multi-source feature generation mechanism that integrates expert knowledge with task settings. It also employs an iterative feature refinement process that uses feature assessment-based feedback for feature re-selection. Additionally, DeepFeature utilizes a robust multi-layer filtering and verification approach for robust feature-to-code translation to ensure that the extraction functions run without crashing. Experimental evaluation results show that DeepFeature achieves an average AUROC improvement of 4.21-9.67% across eight diverse tasks compared to baseline methods. It outperforms state-of-the-art approaches on five tasks while maintaining comparable performance on the remaining tasks.

</details>


### [168] [Autonomous Issue Resolver: Towards Zero-Touch Code Maintenance](https://arxiv.org/abs/2512.08492)
*Aliaksei Kaliutau*

Main category: cs.AI

TL;DR: 本文提出一种从代码属性图（CPGs）到数据转换图（DTG）的范式转变，将数据状态作为节点、函数作为边，使智能体通过数据溯源追踪逻辑缺陷，而非依赖控制流。提出多智能体框架，结合数据完整性导航与控制流逻辑，解决现有RAG系统中的“语义陷阱”问题。实现自修复系统AIR，采用神经符号推理和DTG结构进行可扩展逻辑修复，在SWE-Verified基准上达到87.1%的修复率，显著提升自动化程序修复能力。


<details>
  <summary>Details</summary>
Motivation: 当前自动化程序修复（APR）在仓库级规模仍面临挑战，传统以控制为中心的方法导致智能体陷入复杂的目录结构和无关控制逻辑中，难以有效定位逻辑缺陷。此外，现有AI代码助手存在语义理解偏差，易陷入‘语义陷阱’，亟需更稳健的修复基础。

Method: 提出数据转换图（DTG）模型，将数据状态设为节点、函数设为边，构建基于数据血缘的逻辑追踪机制；设计多智能体协同框架，融合数据完整性分析与控制流推理；开发自主修复系统AIR，结合神经符号推理与DTG结构实现零接触代码维护。

Result: 在多个SWE基准测试中表现优异，尤其在SWE-Verified上达到87.1%的修复率；理论分析与案例研究验证了该方法能有效规避传统RAG系统的语义陷阱，提升修复准确性与可扩展性。

Conclusion: 本文提出的基于数据转换图（DTG）的范式革新，克服了现有自动化程序修复方法在复杂代码库中的局限性，为构建更鲁棒、可扩展的AI驱动代码维护系统提供了新路径，对软件密集型社会具有重要意义。

Abstract: Recent advances in Large Language Models have revolutionized function-level code generation; however, repository-scale Automated Program Repair (APR) remains a significant challenge. Current approaches typically employ a control-centric paradigm, forcing agents to navigate complex directory structures and irrelevant control logic. In this paper, we propose a paradigm shift from the standard Code Property Graphs (CPGs) to the concept of Data Transformation Graph (DTG) that inverts the topology by modeling data states as nodes and functions as edges, enabling agents to trace logic defects through data lineage rather than control flow. We introduce a multi-agent framework that reconciles data integrity navigation with control flow logic. Our theoretical analysis and case studies demonstrate that this approach resolves the "Semantic Trap" inherent in standard RAG systems in modern coding agents. We provide a comprehensive implementation in the form of Autonomous Issue Resolver (AIR), a self-improvement system for zero-touch code maintenance that utilizes neuro-symbolic reasoning and uses the DTG structure for scalable logic repair. Our approach has demonstrated good results on several SWE benchmarks, reaching a resolution rate of 87.1% on SWE-Verified benchmark. Our approach directly addresses the core limitations of current AI code-assistant tools and tackles the critical need for a more robust foundation for our increasingly software-dependent world.

</details>


### [169] [Principles2Plan: LLM-Guided System for Operationalising Ethical Principles into Plans](https://arxiv.org/abs/2512.08536)
*Tammy Zhong,Yang Song,Maurice Pagnucco*

Main category: cs.AI

TL;DR: Principles2Plan 是一个交互式研究原型，展示人类与大型语言模型（LLM）如何协作生成情境敏感的伦理规则并指导自动化规划。领域专家提供规划域、问题细节及高层原则（如利他主义和隐私），系统据此生成符合这些原则的操作性伦理规则，用户可审查、排序，并将其提供给规划器以生成具有伦理考量的计划。该系统在经典规划环境中首次支持基于原则的规则生成，凸显了人-LLM协作在实现伦理自动化规划中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有自动化规划工具对机器人在人类环境中的伦理意识支持不足，手动指定伦理规则既费时又高度依赖具体情境，亟需一种更高效、可适应情境的伦理规则生成机制。

Method: 通过结合领域专家输入的规划域、问题描述和高层伦理原则，利用大型语言模型自动生成符合这些原则的操作性伦理规则，允许用户审查、优先级排序，并将规则用于引导自动化规划器生成伦理导向的计划。

Result: 成功构建了一个能够生成原则基础的可操作伦理规则的原型系统，验证了人-LLM协作在提升伦理自动化规划可行性方面的有效性，且为经典规划场景提供了首个此类支持。

Conclusion: Principles2Plan 展示了人与大型语言模型协同在生成情境敏感伦理规则方面的巨大潜力，为实现更实际、可扩展的伦理自动化规划提供了可行路径。

Abstract: Ethical awareness is critical for robots operating in human environments, yet existing automated planning tools provide little support. Manually specifying ethical rules is labour-intensive and highly context-specific. We present Principles2Plan, an interactive research prototype demonstrating how a human and a Large Language Model (LLM) can collaborate to produce context-sensitive ethical rules and guide automated planning. A domain expert provides the planning domain, problem details, and relevant high-level principles such as beneficence and privacy. The system generates operationalisable ethical rules consistent with these principles, which the user can review, prioritise, and supply to a planner to produce ethically-informed plans. To our knowledge, no prior system supports users in generating principle-grounded rules for classical planning contexts. Principles2Plan showcases the potential of human-LLM collaboration for making ethical automated planning more practical and feasible.

</details>


### [170] [CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models](https://arxiv.org/abs/2512.08609)
*Hui Wang,Yang Liu,Xiaoyu Zhang,Chaoxu Mu*

Main category: cs.AI

TL;DR: 提出了一种新型的认知引导蒙特卡洛树搜索框架（CogMCTS），通过整合大语言模型（LLM）的认知指导与MCTS，实现高效自动启发式优化。该框架利用多轮认知反馈融合历史经验、节点信息和负面结果，动态改进启发式生成；采用双轨节点扩展与精英启发式管理，在探索多样性和利用高质量经验之间取得平衡；并通过策略变异进一步提升解的多样性与优化性能。实验表明，CogMCTS在稳定性、效率和解质量方面优于现有基于LLM的AHD方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的进化方法依赖种群策略，易陷入局部最优；虽有将LLM与蒙特卡洛树搜索（MCTS）结合的方法，但多轮认知集成能力有限，搜索多样性不足，难以有效突破性能瓶颈。

Method: 提出CogMCTS框架，结合大语言模型的认知指导机制与蒙特卡洛树搜索，引入多轮认知反馈以融合历史经验、节点状态和负面结果，实现动态启发式优化；采用双轨节点扩展与精英启发式管理机制，平衡探索与利用；设计策略变异操作，改变启发式形式与参数，增强解空间多样性。

Result: 实验结果显示，CogMCTS在稳定性、求解效率和解质量方面均显著优于现有基于LLM的自动启发式设计方法，展现出更强的全局搜索能力和优化性能。

Conclusion: CogMCTS通过深度融合大语言模型的认知能力与蒙特卡洛树搜索的结构化搜索优势，实现了更高效、更鲁棒的自动启发式设计，为复杂优化问题求解提供了新范式。

Abstract: Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to local optima. Integrating LLMs with Monte7 Carlo Tree Search (MCTS) improves the trade-off8 between exploration and exploitation, but multi-9 round cognitive integration remains limited and10 search diversity is constrained. To overcome these11 limitations, this paper proposes a novel cognitive-12 guided MCTS framework (CogMCTS). CogMCTS13 tightly integrates the cognitive guidance mecha-14 nism of LLMs with MCTS to achieve efficient au-15 tomated heuristic optimization. The framework16 employs multi-round cognitive feedback to incor-17 porate historical experience, node information, and18 negative outcomes, dynamically improving heuris-19 tic generation. Dual-track node expansion com-20 bined with elite heuristic management balances the21 exploration of diverse heuristics and the exploita-22 tion of high-quality experience. In addition, strate-23 gic mutation modifies the heuristic forms and pa-24 rameters to further enhance the diversity of the so-25 lution and the overall optimization performance.26 The experimental results indicate that CogMCTS27 outperforms existing LLM-based AHD methods in28 stability, efficiency, and solution quality.

</details>


### [171] [Protein Secondary Structure Prediction Using Transformers](https://arxiv.org/abs/2512.08613)
*Manzi Kevin Maxime*

Main category: cs.AI

TL;DR: 该研究提出了一种基于Transformer的模型，利用注意力机制预测蛋白质二级结构（如α螺旋、β折叠和线圈），通过滑动窗口数据增强技术扩展CB513数据集的训练样本。模型在处理可变长度序列时表现出良好的泛化能力，并能有效捕捉局部与远距离残基相互作用。


<details>
  <summary>Details</summary>
Motivation: 蛋白质二级结构预测对理解蛋白质功能至关重要，传统方法在捕捉长程相互作用方面存在局限，因此需要更强大的模型来提升预测性能。

Method: 采用基于Transformer的架构，结合注意力机制处理蛋白质序列数据；使用滑动窗口技术对CB513数据集进行数据增强，以增加训练样本多样性。

Result: 所提出的模型在多种评估指标上表现优异，具备较强的泛化能力，能够有效建模局部与长程残基间的相互作用。

Conclusion: 该Transformer模型为蛋白质二级结构预测提供了一种高效且准确的新方法，尤其在处理复杂序列模式方面具有显著优势。

Abstract: Predicting protein secondary structures such as alpha helices, beta sheets, and coils from amino acid sequences is essential for understanding protein function. This work presents a transformer-based model that applies attention mechanisms to protein sequence data to predict structural motifs. A sliding-window data augmentation technique is used on the CB513 dataset to expand the training samples. The transformer shows strong ability to generalize across variable-length sequences while effectively capturing both local and long-range residue interactions.

</details>


### [172] [CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale](https://arxiv.org/abs/2512.08826)
*Shahar Sarfaty,Adi Haviv,Uri Hacohen,Niva Elkin-Koren,Roi Livni,Amit H. Bermano*

Main category: cs.AI

TL;DR: CARLoS 是一个大规模框架，用于在无需额外元数据的情况下表征 LoRAs。通过分析超过 650 个 LoRA 在多种提示和随机种子下的图像生成表现，利用 CLIP 嵌入及其与基础模型生成结果的差异，提出由方向（Directions）、强度（Strength）和一致性（Consistency）组成的三部分表征。该方法支持高效语义检索，并在自动与人工评估中优于文本基线；同时其表征可关联版权中的实质性与意愿性等法律概念，具有广泛分析价值。


<details>
  <summary>Details</summary>
Motivation: 现有 LoRA 发现方法依赖不可靠的用户描述或有偏的流行度指标，导致可用性差。亟需一种不依赖元数据、能客观刻画 LoRA 行为的系统化方法。

Method: 通过在多种提示和随机种子下运行 LoRAs 生成图像，提取 CLIP 嵌入并计算与基础模型输出的差异，构建包含方向、强度和一致性的三元组表征；基于此开发高效语义检索框架，并支持法律层面的分析。

Result: CARLoS 在语义检索任务中显著优于文本基线，在自动化与人工评估中表现更优；其表征可有效关联版权法中的实质性与意愿性概念，具备实际应用潜力。

Conclusion: CARLoS 提供了一种无需元数据即可全面表征 LoRA 的有效方法，不仅提升发现效率，还拓展至版权等法律分析场景，具有重要实践意义。

Abstract: The rapid proliferation of generative components, such as LoRAs, has created a vast but unstructured ecosystem. Existing discovery methods depend on unreliable user descriptions or biased popularity metrics, hindering usability. We present CARLoS, a large-scale framework for characterizing LoRAs without requiring additional metadata. Analyzing over 650 LoRAs, we employ them in image generation over a variety of prompts and seeds, as a credible way to assess their behavior. Using CLIP embeddings and their difference to a base-model generation, we concisely define a three-part representation: Directions, defining semantic shift; Strength, quantifying the significance of the effect; and Consistency, quantifying how stable the effect is. Using these representations, we develop an efficient retrieval framework that semantically matches textual queries to relevant LoRAs while filtering overly strong or unstable ones, outperforming textual baselines in automated and human evaluations. While retrieval is our primary focus, the same representation also supports analyses linking Strength and Consistency to legal notions of substantiality and volition, key considerations in copyright, positioning CARLoS as a practical system with broader relevance for LoRA analysis.

</details>


### [173] [Interpolation in Knowledge Representation](https://arxiv.org/abs/2512.08833)
*Jean Christoph Jung,Patrick Koopmann,Matthias Knorr*

Main category: cs.AI

TL;DR: 本文探讨了描述逻辑和逻辑编程中Craig插值与统一插值的理论结果和实际计算方法，旨在解决这些形式化系统在缺乏插值性质时的实际应用挑战。


<details>
  <summary>Details</summary>
Motivation: 许多知识表示形式化系统普遍不具备Craig或统一插值性质，且实际计算插值物存在困难，限制了其在可解释性、遗忘、模块化等领域的应用。

Method: 通过分析描述逻辑和逻辑编程两种主流知识表示形式化系统，结合理论研究与实践方法，探索插值的计算路径与可行性。

Result: 提出了针对两类形式化系统的插值计算方法，并揭示了相关理论条件与实现机制，为插值在知识表示中的应用提供了支持。

Conclusion: 尽管插值在实践中面临挑战，但通过理论与方法的结合，可在描述逻辑和逻辑编程中有效推进插值技术的应用，拓展其在知识管理与学习中的潜力。

Abstract: Craig interpolation and uniform interpolation have many applications in knowledge representation, including explainability, forgetting, modularization and reuse, and even learning. At the same time, many relevant knowledge representation formalisms do in general not have Craig or uniform interpolation, and computing interpolants in practice is challenging. We have a closer look at two prominent knowledge representation formalisms, description logics and logic programming, and discuss theoretical results and practical methods for computing interpolants.

</details>


### [174] [EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce](https://arxiv.org/abs/2512.08868)
*Rui Min,Zile Qiao,Ze Xu,Jiawen Zhai,Wenyu Gao,Xuanzhong Chen,Haozhen Sun,Zhen Zhang,Xinyu Wang,Hong Zhou,Wenbiao Yin,Xuan Zhou,Yong Jiang,Haicheng Liu,Liang Ding,Ling Zou,Yi R.,Fung,Yalong Li,Pengjun Xie*

Main category: cs.AI

TL;DR: EcomBench 是一个针对真实电商环境设计的综合性评估基准，旨在衡量基础智能体在实际应用中的表现。该基准基于全球领先电商平台的真实用户需求，经过专家精心筛选与标注，涵盖多种电商任务类别，并设置三个难度等级，评估智能体在深度信息检索、多步推理和跨源知识整合等方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有大多数基准测试集中于学术环境或人为设计的场景，忽略了真实应用中复杂的挑战。为弥补这一不足，本文提出在真实的电商领域构建一个更具实践意义的评估框架。

Method: 从全球主流电商生态系统中提取真实用户需求，通过人工专家进行筛选、标注和验证，确保数据的质量与领域相关性；设计覆盖多类电商任务的评测体系，并划分三个难度层级以全面评估智能体的核心能力。

Result: EcomBench 提供了一个严谨且动态的真实世界测试平台，能够有效评估智能体在复杂、变化的电商环境下的实际表现，推动其在现实场景中的应用发展。

Conclusion: EcomBench 为评估智能体在真实电商环境中的能力提供了可靠、可扩展的基准，有助于提升智能体在实际商业应用中的实用性与鲁棒性。

Abstract: Foundation agents have rapidly advanced in their ability to reason and interact with real environments, making the evaluation of their core capabilities increasingly important. While many benchmarks have been developed to assess agent performance, most concentrate on academic settings or artificially designed scenarios while overlooking the challenges that arise in real applications. To address this issue, we focus on a highly practical real-world setting, the e-commerce domain, which involves a large volume of diverse user interactions, dynamic market conditions, and tasks directly tied to real decision-making processes. To this end, we introduce EcomBench, a holistic E-commerce Benchmark designed to evaluate agent performance in realistic e-commerce environments. EcomBench is built from genuine user demands embedded in leading global e-commerce ecosystems and is carefully curated and annotated through human experts to ensure clarity, accuracy, and domain relevance. It covers multiple task categories within e-commerce scenarios and defines three difficulty levels that evaluate agents on key capabilities such as deep information retrieval, multi-step reasoning, and cross-source knowledge integration. By grounding evaluation in real e-commerce contexts, EcomBench provides a rigorous and dynamic testbed for measuring the practical capabilities of agents in modern e-commerce.

</details>


### [175] [Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs](https://arxiv.org/abs/2512.08923)
*Angela van Sprang,Laurens Samson,Ana Lucic,Erman Acar,Sennay Ghebreab,Yuki M. Asano*

Main category: cs.AI

TL;DR: 本文引入了两个新基准REST和REST+，用于系统评估多模态大语言模型（MLLMs）中的跨模态不一致性。尽管MLLMs将视觉和语言映射到同一嵌入空间，但在不同模态上执行相同任务的能力存在显著差异。基准包含图像、文本和混合模态中语义相同的样本，结果显示当前最先进的MLLMs在跨模态推理上表现不一致。评估15个MLLMs发现，模态不一致性程度差异显著，且不受文本识别（OCR）问题影响。无论是否将文本渲染为图像或图像渲染为文本，都无法解决不一致性问题。即使OCR准确，视觉特征（如文本颜色、分辨率，但非字体）和视觉标记数量仍会影响模型表现。此外，一致性得分与文本与图像之间的模态差距相关，揭示了多模态不一致的机制性解释。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）虽然将视觉和语言信息统一在嵌入空间中，但其在不同模态间的表现不一致，缺乏跨模态推理的一致性。现有评估方法难以系统检测这种不一致性，因此亟需新的基准来揭示并量化该问题。

Method: 提出两个新基准：REST（Render-Equivalence Stress Test）和REST+，通过设计在图像、文本和混合模态中具有相同语义信息的样本，系统测试模型在不同模态下的表现一致性。采用15个主流MLLMs进行实验，并分析视觉特征（如颜色、分辨率、字体、视觉令牌数量）及OCR准确性对结果的影响。

Result: 15个MLLMs在跨模态任务中表现出显著不一致性；即使OCR正确，视觉特征（如文本颜色、分辨率）和视觉令牌数量仍显著影响模型性能；一致性得分与文本与图像间的模态差距高度相关，表明不一致性具有可解释的机制基础。

Conclusion: 跨模态不一致性是当前多模态大语言模型的一个核心缺陷，其根源在于模态间的表示差异。所提出的基准能有效揭示并量化该问题，为未来模型改进提供重要方向。

Abstract: We introduce two new benchmarks REST and REST+(Render-Equivalence Stress Tests) to enable systematic evaluation of cross-modal inconsistency in multimodal large language models (MLLMs). MLLMs are trained to represent vision and language in the same embedding space, yet they cannot perform the same tasks in both modalities. Our benchmarks contain samples with the same semantic information in three modalities (image, text, mixed) and we show that state-of-the-art MLLMs cannot consistently reason over these different modalities. We evaluate 15 MLLMs and find that the degree of modality inconsistency varies substantially, even when accounting for problems with text recognition (OCR). Neither rendering text as image nor rendering an image as text solves the inconsistency. Even if OCR is correct, we find that visual characteristics (text colour and resolution, but not font) and the number of vision tokens have an impact on model performance. Finally, we find that our consistency score correlates with the modality gap between text and images, highlighting a mechanistic interpretation of cross-modal inconsistent MLLMs.

</details>
