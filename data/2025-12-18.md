<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 62]
- [cs.CL](#cs.CL) [Total: 36]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.LG](#cs.LG) [Total: 63]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SkyCap: Bitemporal VHR Optical-SAR Quartets for Amplitude Change Detection and Foundation-Model Evaluation](https://arxiv.org/abs/2512.14755)
*Paul Weinmann,Ferdinand Schenck,Martin Šiklar*

Main category: cs.CV

TL;DR: 本文提出SkyCap数据集，结合光学与SAR影像实现高分辨率线性基础设施变化检测。通过光学到SAR的标签迁移技术，避免了对专业标注的需求，并在预训练基础上评估多种模型在不同预处理策略下的表现。结果显示，基于光学基础模型（MTP(ViT-B+RVSA)）配合dB+Z-score预处理取得最佳性能（F1$_c$ = 45.06），优于直接在Capella SAR数据上微调的专用模型。研究揭示预处理与预训练统计的一致性至关重要，且光学模型在光学变化检测中的表现无法直接映射到SAR变化检测。这是首个针对VHR SAR幅度变化检测的基础模型评估工作。


<details>
  <summary>Details</summary>
Motivation: 现有线性基础设施监测依赖高分辨率、高频次的数据，但光学影像受云层干扰，而SAR影像虽可全天候获取，却难以标注。为解决这一矛盾，需构建兼具高分辨率与可标注性的光学-SAR联合数据集，并探索适用于SAR变化检测的基础模型性能。

Method: 构建SkyCap数据集，通过档案匹配与配准整合SkySat（光学）与Capella Space（SAR）影像；采用光学到SAR的标签迁移方法生成SAR幅度变化检测标签；对SARATR-X进行持续预训练，并在不同预处理条件下对比光学与SAR专用基础模型在SkyCap上的表现。

Result: MTP(ViT-B+RVSA)模型在使用dB+Z-score预处理时达到最高F1$_c$ = 45.06，优于直接在Capella数据上微调的SAR专用模型；预处理与预训练统计的对齐极为关键；光学模型在光学任务中的排序不适用于SAR任务。

Conclusion: 本研究首次系统评估了基础模型在高分辨率SAR幅度变化检测中的表现，证明了光学预训练模型经适当预处理后可在SAR任务中超越专用模型，强调了预处理一致性的重要性，为未来多模态遥感变化检测提供了新范式。

Abstract: Change detection for linear infrastructure monitoring requires reliable high-resolution data and regular acquisition cadence. Optical very-high-resolution (VHR) imagery is interpretable and straightforward to label, but clouds break this cadence. Synthetic Aperture Radar (SAR) enables all-weather acquisitions, yet is difficult to annotate. We introduce SkyCap, a bitemporal VHR optical-SAR dataset constructed by archive matching and co-registration of (optical) SkySat and Capella Space (SAR) scenes. We utilize optical-to-SAR label transfer to obtain SAR amplitude change detection (ACD) labels without requiring SAR-expert annotations. We perform continued pretraining of SARATR-X on our SAR data and benchmark the resulting SAR-specific foundation models (FMs) together with SARATR-X against optical FMs on SkyCap under different preprocessing choices. Among evaluated models, MTP(ViT-B+RVSA), an optical FM, with dB+Z-score preprocessing attains the best result (F1$_c$ = 45.06), outperforming SAR-specific FMs further pretrained directly on Capella data. We observe strong sensitivity to preprocessing alignment with pretraining statistics, and the ranking of optical models on optical change detection does not transfer one-to-one to SAR ACD. To our knowledge, this is the first evaluation of foundation models on VHR SAR ACD.

</details>


### [2] [SocialNav-MoE: A Mixture-of-Experts Vision Language Model for Socially Compliant Navigation with Reinforcement Fine-Tuning](https://arxiv.org/abs/2512.14757)
*Tomohito Kawabata,Xinyu Zhang,Ling Xiao*

Main category: cs.CV

TL;DR: 本文提出一种高效的小型视觉语言模型（SocialNav-MoE），用于实现机器人在人类环境中的社会合规导航，通过强化学习微调（RFT）和语义相似性奖励（SSR）提升决策能力。实验表明该方法在导航准确性和效率之间取得良好平衡，且优于传统奖励设计。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注机器人导航的安全性，而忽视了社会合规性，如人类舒适度、社交规范和情境适宜性。虽然视觉语言模型（VLMs）有潜力解决此问题，但大型模型计算开销大，难以在资源受限的机器人平台上实时部署。因此需要更高效的小型VLM方案。

Method: 提出SocialNav-MoE，一种基于Mixture-of-Experts架构的小型视觉语言模型，结合强化学习微调（RFT）与语义相似性奖励（SSR）机制，优化导航决策。系统评估不同小型语言模型（Phi、Qwen、StableLM）、路由策略及视觉编码器（CLIP vs. SigLIP，冻结或微调）的影响。

Result: 在SNEI数据集上的实验表明，SocialNav-MoE在保持高导航准确性的同时显著降低推理延迟与能耗，实现了效率与性能的平衡；语义相似性奖励（SSR）相比硬级别和字符级别奖励更具优势。

Conclusion: 本研究验证了小型VLM在社会合规导航中的可行性与有效性，提出的SocialNav-MoE框架结合RFT与SSR，为资源受限平台提供了一种高效、可扩展的解决方案。源代码将在论文接受后公开。

Abstract: For robots navigating in human-populated environments, safety and social compliance are equally critical, yet prior work has mostly emphasized safety. Socially compliant navigation that accounts for human comfort, social norms, and contextual appropriateness remains underexplored. Vision language models (VLMs) show promise for this task; however, large-scale models incur substantial computational overhead, leading to higher inference latency and energy consumption, which makes them unsuitable for real-time deployment on resource-constrained robotic platforms. To address this issue, we investigate the effectiveness of small VLM and propose SocialNav-MoE, an efficient Mixture-of-Experts vision language model for socially compliant navigation with reinforcement fine-tuning (RFT). We further introduce a semantic similarity reward (SSR) to effectively leverage RFT for enhancing the decision-making capabilities. Additionally, we study the effectiveness of different small language model types (Phi, Qwen, and StableLM), routing strategies, and vision encoders (CLIP vs. SigLIP, frozen vs. fine-tuned). Experiments on the SNEI dataset demonstrate that SocialNav-MoE achieves an excellent balance between navigation accuracy and efficiency. The proposed SSR function is more effective than hard-level and character-level rewards. Source code will be released upon acceptance.

</details>


### [3] [The Renaissance of Expert Systems: Optical Recognition of Printed Chinese Jianpu Musical Scores with Lyrics](https://arxiv.org/abs/2512.14758)
*Fan Bu,Rongfeng Li,Zijin Li,Ya Li,Linfeng Fan,Pei Huang*

Main category: cs.CV

TL;DR: 本文提出了一种模块化的专家系统流水线，用于将印刷版的中国简谱（Jianpu）乐谱及其歌词转换为可机器读取的MusicXML和MIDI格式，无需大量标注训练数据。该方法结合了传统计算机视觉技术与无监督深度学习模块，实现了高精度的旋律和歌词识别，在超过5000首歌曲的旋律识别中达到0.951的注释级F1分数，在含歌词的1400余首歌曲中实现0.931的字符级F1分数。


<details>
  <summary>Details</summary>
Motivation: 目前大规模光学音乐识别研究主要集中在西方五线谱，而中国简谱及其丰富的歌词资源尚未得到充分探索，因此需要一种高效、无需大量标注数据的自动化处理方法。

Method: 采用自上而下的专家系统设计，结合传统计算机视觉技术（如小节相关性分析、骨架分析）和无监督深度学习模块进行图像特征嵌入，形成混合策略以兼顾可解释性与准确性。

Result: 在《中国民歌集》数据集上，系统成功大规模数字化了超过5000首仅含旋律的歌曲（超30万音符）和超过1400首含歌词的歌曲（超10万音符），在旋律识别上达到0.951的注释级F1分数，在歌词对齐上达到0.931的字符级F1分数。

Conclusion: 本方法有效解决了中文简谱自动识别难题，为中文音乐文化遗产的数字化提供了可行路径，具备良好的可扩展性和实际应用价值。

Abstract: Large-scale optical music recognition (OMR) research has focused mainly on Western staff notation, leaving Chinese Jianpu (numbered notation) and its rich lyric resources underexplored. We present a modular expert-system pipeline that converts printed Jianpu scores with lyrics into machine-readable MusicXML and MIDI, without requiring massive annotated training data. Our approach adopts a top-down expert-system design, leveraging traditional computer-vision techniques (e.g., phrase correlation, skeleton analysis) to capitalize on prior knowledge, while integrating unsupervised deep-learning modules for image feature embeddings. This hybrid strategy strikes a balance between interpretability and accuracy. Evaluated on The Anthology of Chinese Folk Songs, our system massively digitizes (i) a melody-only collection of more than 5,000 songs (> 300,000 notes) and (ii) a curated subset with lyrics comprising over 1,400 songs (> 100,000 notes). The system achieves high-precision recognition on both melody (note-wise F1 = 0.951) and aligned lyrics (character-wise F1 = 0.931).

</details>


### [4] [HERBench: A Benchmark for Multi-Evidence Integration in Video Question Answering](https://arxiv.org/abs/2512.14870)
*Dan Ben-Ami,Gabriele Serussi,Kobi Cohen,Chaim Baskin*

Main category: cs.CV

TL;DR: HERBench is a new VideoQA benchmark designed to evaluate multi-evidence integration across time, requiring models to aggregate at least three non-overlapping visual cues from distinct video segments. It introduces the Minimum Required Frame-Set (MRFS) to quantify evidential demand, showing significantly higher demands than prior datasets (mean MRFS 5.5 vs. 2.6–4.2). Evaluation of 13 state-of-the-art Video-LLMs reveals poor performance (31–42% accuracy), only slightly above random guess (20%), due to two key bottlenecks: retrieval deficit (missing key frames) and fusion deficit (inability to integrate evidence). HERBench provides a rigorous, measurable standard for advancing compositional video understanding.


<details>
  <summary>Details</summary>
Motivation: Current VideoQA benchmarks allow answers based on single salient cues, underestimating models' ability to reason over multiple, temporally separated pieces of evidence. This limits progress in developing models capable of robust, compositional video understanding.

Method: HERBench consists of 26K five-way multiple-choice questions across twelve compositional tasks assessing identity binding, cross-entity relations, temporal ordering, co-occurrence verification, and counting. Each question requires integrating at least three non-overlapping evidential cues from different video segments. The Minimum Required Frame-Set (MRFS) metric quantifies the minimal number of frames needed for correct answers, enabling precise measurement of evidential demand.

Result: HERBench imposes substantially higher evidential demands than prior datasets (mean MRFS 5.5 vs. 2.6–4.2). Evaluations show that 13 state-of-the-art Video-LLMs achieve accuracies between 31% and 42%, barely surpassing the 20% random-guess baseline. Analysis reveals two major failure modes: retrieval deficit and fusion deficit.

Conclusion: By making cross-time evidence both unavoidable and quantifiable, HERBench establishes a principled benchmark for advancing robust, compositional video understanding in Video-LLMs.

Abstract: Video Large Language Models (Video-LLMs) are rapidly improving, yet current Video Question Answering (VideoQA) benchmarks often allow questions to be answered from a single salient cue, under-testing reasoning that must aggregate multiple, temporally separated visual evidence. We present HERBench, a VideoQA benchmark purpose-built to assess multi-evidence integration across time. Each question requires aggregating at least three non-overlapping evidential cues across distinct video segments, so neither language priors nor a single snapshot can suffice. HERBench comprises 26K five-way multiple-choice questions organized into twelve compositional tasks that probe identity binding, cross-entity relations, temporal ordering, co-occurrence verification, and counting. To make evidential demand measurable, we introduce the Minimum Required Frame-Set (MRFS), the smallest number of frames a model must fuse to answer correctly, and show that HERBench imposes substantially higher demand than prior datasets (mean MRFS 5.5 vs. 2.6-4.2). Evaluating 13 state-of-the-art Video-LLMs on HERBench reveals pervasive failures: accuracies of 31-42% are only slightly above the 20% random-guess baseline. We disentangle this failure into two critical bottlenecks: (1) a retrieval deficit, where frame selectors overlook key evidence, and (2) a fusion deficit, where models fail to integrate information even when all necessary evidence is provided. By making cross-time evidence both unavoidable and quantifiable, HERBench establishes a principled target for advancing robust, compositional video understanding.

</details>


### [5] [Visual-textual Dermatoglyphic Animal Biometrics: A First Case Study on Panthera tigris](https://arxiv.org/abs/2512.14878)
*Wenshuo Li,Majid Mirmehdi,Tilo Burghardt*

Main category: cs.CV

TL;DR: 本文提出将法医级皮肤纹路文本描述引入生态学中的动物重识别（Re-ID），结合视觉与文本信息，利用84,264个手动标注的细节特征，构建跨模态身份检索方法。通过文本-图像协同生成虚拟个体，显著提升AI在数据稀缺条件下的识别准确率，实现可解释、人类可验证的文本到视觉的身份恢复，推动生态监测中多模态描述的统一与可解释性发展。


<details>
  <summary>Details</summary>
Motivation: 传统动物重识别依赖视觉特征，难以处理相似外观个体；现有AI方法多为纯图像驱动，缺乏可解释性与跨模态能力。为克服视觉局限并增强可解释性，引入法医领域成熟的皮肤纹路文本描述，拓展生态学中的身份识别范式。

Method: 采用人工标注的皮肤纹路细节（minutiae）生成人类可读的语言标签，构建视觉-文本联合表征；设计文本-图像协同合成管道，生成大量逼真的虚拟个体图像及其对应文本描述，用于训练和增强模型性能。

Result: 所提方法在跨模态重识别任务中表现优异，尤其在小样本和数据稀缺场景下显著优于纯视觉模型；实现了从文本描述准确还原视觉身份的能力，且匹配过程具备人类可验证性。

Conclusion: 基于皮肤纹路语言引导的生物特征识别技术，突破了仅依赖视觉的局限，实现了可解释、可验证的跨模态身份恢复，为生态监测提供了语言驱动的多模态统一新范式。

Abstract: Biologists have long combined visuals with textual field notes to re-identify (Re-ID) animals. Contemporary AI tools automate this for species with distinctive morphological features but remain largely image-based. Here, we extend Re-ID methodologies by incorporating precise dermatoglyphic textual descriptors-an approach used in forensics but new to ecology. We demonstrate that these specialist semantics abstract and encode animal coat topology using human-interpretable language tags. Drawing on 84,264 manually labelled minutiae across 3,355 images of 185 tigers (Panthera tigris), we evaluate this visual-textual methodology, revealing novel capabilities for cross-modal identity retrieval. To optimise performance, we developed a text-image co-synthesis pipeline to generate 'virtual individuals', each comprising dozens of life-like visuals paired with dermatoglyphic text. Benchmarking against real-world scenarios shows this augmentation significantly boosts AI accuracy in cross-modal retrieval while alleviating data scarcity. We conclude that dermatoglyphic language-guided biometrics can overcome vision-only limitations, enabling textual-to-visual identity recovery underpinned by human-verifiable matchings. This represents a significant advance towards explainability in Re-ID and a language-driven unification of descriptive modalities in ecological monitoring.

</details>


### [6] [Vibe Spaces for Creatively Connecting and Expressing Visual Concepts](https://arxiv.org/abs/2512.14884)
*Huzheng Yang,Katherine Xu,Andrew Lu,Michael D. Grossberg,Yutong Bai,Jianbo Shi*

Main category: cs.CV

TL;DR: 提出Vibe Blending任务，通过Vibe Space在CLIP特征空间中学习低维测地线，实现概念间平滑、语义一致的混合生成；采用认知启发式评估框架，结合人类判断、大模型推理和几何路径难度评分，验证其生成结果更具创意与连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在潜在空间中识别并穿越远距离概念间的非线性路径，导致生成的视觉混合不连贯或缺乏意义，因此需要一种能揭示概念间共享属性（vibe）的新方法。

Method: 构建Vibe Space——一个分层图流形，学习CLIP等特征空间中的低维测地线，支持概念间平滑且语义一致的过渡；设计融合人类评价、LLM推理与几何路径难度的综合评估体系。

Result: Vibe Space生成的混合图像在人类评估中被一致评为更具创意性和连贯性，优于现有方法。

Conclusion: Vibe Blending通过Vibe Space有效捕捉概念间的深层共享属性，实现了高质量、有意义的视觉概念融合，为创造性图像生成提供了新范式。

Abstract: Creating new visual concepts often requires connecting distinct ideas through their most relevant shared attributes -- their vibe. We introduce Vibe Blending, a novel task for generating coherent and meaningful hybrids that reveals these shared attributes between images. Achieving such blends is challenging for current methods, which struggle to identify and traverse nonlinear paths linking distant concepts in latent space. We propose Vibe Space, a hierarchical graph manifold that learns low-dimensional geodesics in feature spaces like CLIP, enabling smooth and semantically consistent transitions between concepts. To evaluate creative quality, we design a cognitively inspired framework combining human judgments, LLM reasoning, and a geometric path-based difficulty score. We find that Vibe Space produces blends that humans consistently rate as more creative and coherent than current methods.

</details>


### [7] [PANDA-PLUS-Bench: A Clinical Benchmark for Evaluating Robustness of AI Foundation Models in Prostate Cancer Diagnosis](https://arxiv.org/abs/2512.14922)
*Joshua L. Ebbert,Dennis Della Corte*

Main category: cs.CV

TL;DR: 该研究提出PANDA-PLUS-Bench，一个专为评估人工智能基础模型在前列腺癌Gleason分级中鲁棒性而设计的基准数据集。通过九个患者样本的全切片图像，结合多分辨率和多种增强条件，系统测试了七种模型在跨幻灯片与同幻灯片任务中的表现。结果显示，尽管部分模型（如HistoEncoder）在生物特征捕捉和幻灯片特异性编码方面表现更优，但所有模型均存在显著的跨幻灯片性能下降问题，表明当前模型可能依赖于幻灯片级伪影而非可泛化的生物学特征。研究提供了开源Colab笔记本，支持后续模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在前列腺癌Gleason分级中虽表现出高验证准确率，但可能学习到的是特定样本的伪影而非真实生物特征，导致临床应用受限。亟需一种能有效检测此类失败模式的评估工具。

Method: 构建包含9例患者、多种组织模式的全切片图像数据集，提取512x512与224x224像素的非重叠组织块，并施加8种图像增强，形成多维度测试环境；使用该基准评估7个基础模型在跨幻灯片与同幻灯片任务中的表现，量化其对幻灯片级混杂因素的鲁棒性。

Result: 各模型在跨幻灯片准确率上差异显著，最低为47.2%（Virchow2），最高为59.7%（HistoEncoder）。所有模型均存在明显的性能差距（19.9–26.9个百分点），表明普遍依赖幻灯片特异性信号。其中HistoEncoder在滑片编码强度（90.3%）和跨滑片准确率上表现最佳，提示针对特定组织训练可提升模型鲁棒性。

Conclusion: PANDA-PLUS-Bench为评估基础模型在前列腺癌分级中的临床可靠性提供了一个关键工具，强调了在模型开发中纳入组织特异性训练和鲁棒性评估的重要性，推动更可信的AI辅助诊断系统发展。

Abstract: Artificial intelligence foundation models are increasingly deployed for prostate cancer Gleason grading, where GP3/GP4 distinction directly impacts treatment decisions. However, these models may achieve high validation accuracy by learning specimen-specific artifacts rather than generalizable biological features, limiting real-world clinical utility. We introduce PANDA-PLUS-Bench, a curated benchmark dataset derived from expert-annotated prostate biopsies designed specifically to quantify this failure mode. The benchmark comprises nine carefully selected whole slide images from nine unique patients containing diverse Gleason patterns, with non-overlapping tissue patches extracted at both 512x512 and 224x224 pixel resolutions across eight augmentation conditions. Using this benchmark, we evaluate seven foundation models on their ability to separate biological signal from slide-level confounders. Our results reveal substantial variation in robustness across models: Virchow2 achieved the lowest slide-level encoding among large-scale models (81.0%) yet exhibited the second-lowest cross-slide accuracy (47.2%). HistoEncoder, trained specifically on prostate tissue, demonstrated the highest cross-slide accuracy (59.7%) and the strongest slide-level encoding (90.3%), suggesting tissue-specific training may enhance both biological feature capture and slide-specific signatures. All models exhibited measurable within-slide vs. cross-slide accuracy gaps, though the magnitude varied from 19.9 percentage points to 26.9 percentage points. We provide an open-source Google Colab notebook enabling researchers to evaluate additional foundation models against our benchmark using standardized metrics. PANDA-PLUS-Bench addresses a critical gap in foundation model evaluation by providing a purpose-built resource for robustness assessment in the clinically important context of Gleason grading.

</details>


### [8] [Improving Pre-trained Segmentation Models using Post-Processing](https://arxiv.org/abs/2512.14937)
*Abhijeet Parida,Daniel Capellán-Martín,Zhifan Jiang,Nishad Kulkarni,Krithika Iyer,Austin Tapp,Syed Muhammad Anwar,María J. Ledesma-Carbayo,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文提出了一种自适应后处理技术，用于改进大型预训练模型在胶质瘤多参数MRI分割中的表现。该方法在BraTS 2025挑战赛中显著提升了分割精度，尤其在撒哈拉以南非洲挑战赛中性能提升14.9%，在成人胶质瘤挑战赛中提升0.9%。研究强调从复杂模型架构转向高效、临床契合的后处理策略，具有更高的准确性、计算公平性和可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有大型预训练深度学习模型在胶质瘤分割中存在泛化能力差、系统性错误（如假阳性、标签混淆、切片不连续）等问题，且受GPU资源不均和训练环境成本制约。亟需一种更高效、公平且可持续的解决方案来提升分割质量。

Method: 提出自适应后处理技术，对大型预训练模型生成的初始分割结果进行优化，通过精细化修正减少系统性误差，提升分割一致性与准确性。该方法适用于多种肿瘤类型，可在不同挑战任务中灵活应用。

Result: 在BraTS 2025挑战赛中，该方法使撒哈拉以南非洲挑战赛的排名指标提升14.9%，成人胶质瘤挑战赛提升0.9%。证明了其在提升分割质量方面的有效性与广泛适用性。

Conclusion: 本研究推动脑肿瘤分割研究范式转变：从追求复杂模型架构转向高效、精准、计算公平且环境可持续的后处理策略，为临床应用提供了实用且可推广的技术路径。

Abstract: Gliomas are the most common malignant brain tumors in adults and are among the most lethal. Despite aggressive treatment, the median survival rate is less than 15 months. Accurate multiparametric MRI (mpMRI) tumor segmentation is critical for surgical planning, radiotherapy, and disease monitoring. While deep learning models have improved the accuracy of automated segmentation, large-scale pre-trained models generalize poorly and often underperform, producing systematic errors such as false positives, label swaps, and slice discontinuities in slices. These limitations are further compounded by unequal access to GPU resources and the growing environmental cost of large-scale model training. In this work, we propose adaptive post-processing techniques to refine the quality of glioma segmentations produced by large-scale pretrained models developed for various types of tumors. We demonstrated the techniques in multiple BraTS 2025 segmentation challenge tasks, with the ranking metric improving by 14.9 % for the sub-Saharan Africa challenge and 0.9% for the adult glioma challenge. This approach promotes a shift in brain tumor segmentation research from increasingly complex model architectures to efficient, clinically aligned post-processing strategies that are precise, computationally fair, and sustainable.

</details>


### [9] [TalkVerse: Democratizing Minute-Long Audio-Driven Video Generation](https://arxiv.org/abs/2512.14938)
*Zhenzhi Wang,Jian Wang,Ke Ma,Dahua Lin,Bing Zhou*

Main category: cs.CV

TL;DR: TalkVerse是一个大规模、开源的单人音频驱动说话视频生成语料库，包含230万条高分辨率（720p/1080p）音视频同步片段，总计6.3小时。该数据集通过透明的处理流程构建，涵盖场景切割检测、美学评估、严格的音视频同步检查及丰富标注（如2D骨骼和结构化视觉/音频风格描述）。基于此，研究提出一个50亿参数的可复现DiT基线模型，采用高下采样比视频VAE与滑动窗口机制，实现分钟级生成且低漂移。其在唇形同步与视觉质量上媲美140亿参数的Wan-S2V模型，但推理成本降低10倍。模型还集成多模态大模型导演以增强长视频叙事能力，并支持零样本视频配音。所有数据、训练方案与模型权重均开源，推动音频驱动人类视频生成研究。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的音频驱动说话视频生成系统依赖封闭数据或计算密集型模型，缺乏公平、可复现的比较基准。为解决这一问题，研究提出一个大规模、透明、可复现的数据集与模型框架，以降低研究门槛并推动领域发展。

Method: 构建透明的数据处理管道，包括场景切割检测、美学评估、音视频同步验证与多维度标注；设计基于Wan2.2-5B的50亿参数DiT基线模型，结合高下采样比视频VAE与滑动窗口机制实现长视频生成；引入多模态大模型（MLLM）作为导演，根据音频与视觉线索重写提示词；通过可控潜在噪声注入实现零样本视频配音。

Result: 所提模型在分钟级生成中表现出低漂移，唇形同步与视觉质量接近140亿参数的Wan-S2V模型，但推理成本降低10倍；支持零样本视频配音与增强叙事能力；数据集与模型全部开源，促进社区复现与研究创新。

Conclusion: TalkVerse及其配套模型为音频驱动人类视频生成提供了首个大规模、透明、可复现的基准，显著降低了研究门槛，推动了高效、高质量长视频生成技术的发展。

Abstract: We introduce TalkVerse, a large-scale, open corpus for single-person, audio-driven talking video generation designed to enable fair, reproducible comparison across methods. While current state-of-the-art systems rely on closed data or compute-heavy models, TalkVerse offers 2.3 million high-resolution (720p/1080p) audio-video synchronized clips totaling 6.3k hours. These are curated from over 60k hours of video via a transparent pipeline that includes scene-cut detection, aesthetic assessment, strict audio-visual synchronization checks, and comprehensive annotations including 2D skeletons and structured visual/audio-style captions. Leveraging TalkVerse, we present a reproducible 5B DiT baseline built on Wan2.2-5B. By utilizing a video VAE with a high downsampling ratio and a sliding window mechanism with motion-frame context, our model achieves minute-long generation with low drift. It delivers comparable lip-sync and visual quality to the 14B Wan-S2V model but with 10$\times$ lower inference cost. To enhance storytelling in long videos, we integrate an MLLM director to rewrite prompts based on audio and visual cues. Furthermore, our model supports zero-shot video dubbing via controlled latent noise injection. We open-source the dataset, training recipes, and 5B checkpoints to lower barriers for research in audio-driven human video generation. Project Page: https://zhenzhiwang.github.io/talkverse/

</details>


### [10] [Puzzle Curriculum GRPO for Vision-Centric Reasoning](https://arxiv.org/abs/2512.14944)
*Ahmadreza Jeddi,Hakki Can Karaimer,Hue Nguyen,Zhongling Wang,Ke Zhao,Javad Rajabi,Ran Zhang,Raghav Goyal,Babak Taati,Radek Grzeszczuk*

Main category: cs.CV

TL;DR: PC-GRPO提出一种无监督的强化学习方法，通过自监督拼图环境（PatchFit、Rotation、Jigsaw）替代人工标注，缓解奖励稀疏性与逻辑不一致问题。引入难度感知课程学习动态调整样本权重，并通过监控推理-答案一致性（RAC）提升模型稳定性与准确性。在多个基准测试中显著提升视觉语言模型的推理能力与任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法依赖昂贵且易错的人工标注或外部验证器，且面临奖励稀疏、逻辑不一致等问题，限制了视觉语言模型的可扩展性和可靠性。

Method: 采用自监督拼图环境生成可验证奖励，设计难度感知课程学习以优化样本权重，结合推理-答案一致性（RAC）监测与奖励增强机制，实现无需外部标注的强化学习后训练。

Result: 在Qwen-7B和Qwen-3B模型上，PC-GRPO显著提升推理质量、训练稳定性和下游任务准确率，且RAC与任务性能正相关，验证了其有效性与可扩展性。

Conclusion: PC-GRPO提供了一种无需标注、可验证、可解释的强化学习后训练路径，为大规模视觉语言模型的可靠推理提供了实用解决方案。

Abstract: Recent reinforcement learning (RL) approaches like outcome-supervised GRPO have advanced chain-of-thought reasoning in Vision Language Models (VLMs), yet key issues linger: (i) reliance on costly and noisy hand-curated annotations or external verifiers; (ii) flat and sparse reward schemes in GRPO; and (iii) logical inconsistency between a chain's reasoning and its final answer. We present Puzzle Curriculum GRPO (PC-GRPO), a supervision-free recipe for RL with Verifiable Rewards (RLVR) that strengthens visual reasoning in VLMs without annotations or external verifiers. PC-GRPO replaces labels with three self-supervised puzzle environments: PatchFit, Rotation (with binary rewards) and Jigsaw (with graded partial credit mitigating reward sparsity). To counter flat rewards and vanishing group-relative advantages, we introduce a difficulty-aware curriculum that dynamically weights samples and peaks at medium difficulty. We further monitor Reasoning-Answer Consistency (RAC) during post-training: mirroring reports for vanilla GRPO in LLMs, RAC typically rises early then degrades; our curriculum delays this decline, and consistency-enforcing reward schemes further boost RAC. RAC correlates with downstream accuracy. Across diverse benchmarks and on Qwen-7B and Qwen-3B backbones, PC-GRPO improves reasoning quality, training stability, and end-task accuracy, offering a practical path to scalable, verifiable, and interpretable RL post-training for VLMs.

</details>


### [11] [Adaptive Multimodal Person Recognition: A Robust Framework for Handling Missing Modalities](https://arxiv.org/abs/2512.14961)
*Aref Farhadipour,Teodora Vukovic,Volker Dellwo,Petr Motlicek,Srikanth Madikeri*

Main category: cs.CV

TL;DR: 提出了一种三模态（语音、人脸、手势）人识别框架，通过多任务学习和交叉注意力与门控融合机制实现模态间交互，并采用置信度加权融合策略应对模态缺失或质量下降问题。在新提出的CANDOR数据集上达到99.18%的Top-1准确率，在VoxCeleb1上达99.92%的双模态准确率，且在单模态或双模态场景下仍保持高精度，具备强鲁棒性。代码与数据已公开。


<details>
  <summary>Details</summary>
Motivation: 真实世界中人识别常面临音频、视觉或行为模态缺失或退化的问题，现有方法在模态不全时性能显著下降，亟需一种能有效融合多模态信息并适应模态缺失的鲁棒识别系统。

Method: 采用多任务学习分别处理语音、人脸和手势模态；利用交叉注意力与门控融合机制促进模态间信息交互；引入置信度加权融合策略，动态调整各模态贡献，以应对模态缺失或低质量情况。

Result: 在CANDOR数据集上实现99.18%的Top-1准确率，优于传统单模态与后融合方法；在VoxCeleb1数据集的双模态模式下达到99.92%准确率；即使在缺少一或两个模态的情况下，系统仍保持高识别准确率，表现出优异的鲁棒性。

Conclusion: 所提出的三模态人识别框架在多种模态配置下均表现优异，尤其在模态缺失场景中展现出强大适应能力，为真实应用场景下的可靠身份识别提供了有效解决方案。

Abstract: Person recognition systems often rely on audio, visual, or behavioral cues, but real-world conditions frequently result in missing or degraded modalities. To address this challenge, we propose a Trimodal person identification framework that integrates voice, face, and gesture modalities, while remaining robust to modality loss. Our approach leverages multi-task learning to process each modality independently, followed by a cross-attention and gated fusion mechanisms to facilitate interaction across modalities. Moreover, a confidence-weighted fusion strategy dynamically adapts to missing and low-quality data, ensuring optimal classification even in Unimodal or Bimodal scenarios. We evaluate our method on CANDOR, a newly introduced interview-based multimodal dataset, which we benchmark for the first time. Our results demonstrate that the proposed Trimodal system achieves 99.18% Top-1 accuracy on person identification tasks, outperforming conventional Unimodal and late-fusion approaches. In addition, we evaluate our model on the VoxCeleb1 dataset as a benchmark and reach 99.92% accuracy in Bimodal mode. Moreover, we show that our system maintains high accuracy even when one or two modalities are unavailable, making it a robust solution for real-world person recognition applications. The code and data for this work are publicly available.

</details>


### [12] [Where is the Watermark? Interpretable Watermark Detection at the Block Level](https://arxiv.org/abs/2512.14994)
*Maria Bulychev,Neil G. Marchant,Benjamin I. P. Rubinstein*

Main category: cs.CV

TL;DR: 本文提出一种后处理图像水印方法，结合局部嵌入与区域级可解释性，在离散小波变换域中采用统计块级策略嵌入水印信号，生成可揭示水印或篡改区域的检测图。该方法在保持高度不可感知性的同时，对常见图像变换具有强鲁棒性，并能敏感检测语义篡改，优于现有后处理方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像水印方案多为黑箱操作，仅提供全局检测分数，缺乏对水印位置和状态的解释能力，影响用户信任并难以评估篡改影响。因此需要更具可解释性的水印技术以增强透明度和可信度。

Method: 在离散小波变换域中使用统计块级策略进行局部水印信号嵌入，生成区域级检测图，实现水印位置与篡改区域的可视化。

Result: 所提方法在抵抗裁剪（最多50%）等常见图像变换方面表现出强鲁棒性，同时对语义篡改敏感，水印不可感知，且检测结果具有较高可解释性，优于现有后处理方法。

Conclusion: 本文提出的后处理水印方法通过区域级可解释性与强鲁棒性相结合，有效提升了数字内容溯源的透明度与可靠性，为真实世界应用提供了更可信的解决方案。

Abstract: Recent advances in generative AI have enabled the creation of highly realistic digital content, raising concerns around authenticity, ownership, and misuse. While watermarking has become an increasingly important mechanism to trace and protect digital media, most existing image watermarking schemes operate as black boxes, producing global detection scores without offering any insight into how or where the watermark is present. This lack of transparency impacts user trust and makes it difficult to interpret the impact of tampering. In this paper, we present a post-hoc image watermarking method that combines localised embedding with region-level interpretability. Our approach embeds watermark signals in the discrete wavelet transform domain using a statistical block-wise strategy. This allows us to generate detection maps that reveal which regions of an image are likely watermarked or altered. We show that our method achieves strong robustness against common image transformations while remaining sensitive to semantic manipulations. At the same time, the watermark remains highly imperceptible. Compared to prior post-hoc methods, our approach offers more interpretable detection while retaining competitive robustness. For example, our watermarks are robust to cropping up to half the image.

</details>


### [13] [Evaluating the Capability of Video Question Generation for Expert Knowledge Elicitation](https://arxiv.org/abs/2512.15006)
*Huaying Zhang,Atsushi Hashimoto,Tosho Hirasawa*

Main category: cs.CV

TL;DR: 本文提出了一种评估视频问题生成（VQG）模型生成问题质量的新协议，通过模拟与专家的问答交流，利用问题到答案的检索来衡量问题能否激发专家未提及的知识。为此，研究构建了EgoExoAsk数据集，包含27,666个由专家注释生成的问答对，并基于该数据集训练检索器。实验表明，该评估方法能合理反映模型在更丰富上下文中的表现，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有VQG模型评估多关注问题的回答能力，而忽视了问题本身的质量，尤其是其能否有效引导专家提供新知识。因此，亟需一种能够量化评估问题质量的方法，以推动VQG模型持续改进。

Method: 提出一种基于问题-答案检索的评估协议，通过构建EgoExoAsk数据集（27,666个QA对），使用训练集训练检索器，并在验证集上构建基准测试，模拟与专家的交互过程以评估问题质量。

Result: 实验结果表明，该评估协议能合理区分不同模型的表现：能够访问更丰富上下文的模型获得更高评分，说明该方法能有效衡量问题质量。

Conclusion: 所提出的评估协议能够有效衡量VQG模型生成问题的质量，尤其在激发专家未知知识方面表现良好，为未来模型优化提供了可靠评估工具。

Abstract: Skilled human interviewers can extract valuable information from experts. This raises a fundamental question: what makes some questions more effective than others? To address this, a quantitative evaluation of question-generation models is essential. Video question generation (VQG) is a topic for video question answering (VideoQA), where questions are generated for given answers. Their evaluation typically focuses on the ability to answer questions, rather than the quality of generated questions. In contrast, we focus on the question quality in eliciting unseen knowledge from human experts. For a continuous improvement of VQG models, we propose a protocol that evaluates the ability by simulating question-answering communication with experts using a question-to-answer retrieval. We obtain the retriever by constructing a novel dataset, EgoExoAsk, which comprises 27,666 QA pairs generated from Ego-Exo4D's expert commentary annotation. The EgoExoAsk training set is used to obtain the retriever, and the benchmark is constructed on the validation set with Ego-Exo4D video segments. Experimental results demonstrate our metric reasonably aligns with question generation settings: models accessing richer context are evaluated better, supporting that our protocol works as intended. The EgoExoAsk dataset is available in https://github.com/omron-sinicx/VQG4ExpertKnowledge .

</details>


### [14] [MVGSR: Multi-View Consistent 3D Gaussian Super-Resolution via Epipolar Guidance](https://arxiv.org/abs/2512.15048)
*Kaizhe Zhang,Shinan Chen,Qian Zhao,Weizhan Zhang,Caixia Yan,Yudeng Xin*

Main category: cs.CV

TL;DR: 本文提出MVGSR，一种用于3D高斯点阵超分辨率的新方法，通过引入基于相机位姿的辅助视图选择和新的对极约束多视图注意力机制，实现跨视图信息融合与几何一致性增强，适用于任意组织的多视角数据集，在物体级和场景级基准上均达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS超分辨率方法在处理低分辨率输入时，难以保持高分辨率渲染下的跨视图一致性和细节保真度；单图像超分辨率方法缺乏视图间一致性，而视频基方法依赖严格顺序帧，不适用于非结构化多视角数据集。

Method: 提出基于相机位姿的辅助视图选择方法，使模型可适应任意组织的多视角数据；设计首个应用于3DGS超分辨率的对极约束多视图注意力机制，以选择性聚合来自辅助视图的一致信息，提升几何一致性和细节质量。

Result: 在物体级和场景级3DGS超分辨率基准上均取得当前最优性能，显著提升了重建结果的高频细节表现与跨视图一致性。

Conclusion: MVGSR成功解决了多视角3DGS超分辨率中的信息融合与一致性难题，为非结构化多视角数据提供了高效、鲁棒的超分辨率解决方案。

Abstract: Scenes reconstructed by 3D Gaussian Splatting (3DGS) trained on low-resolution (LR) images are unsuitable for high-resolution (HR) rendering. Consequently, a 3DGS super-resolution (SR) method is needed to bridge LR inputs and HR rendering. Early 3DGS SR methods rely on single-image SR networks, which lack cross-view consistency and fail to fuse complementary information across views. More recent video-based SR approaches attempt to address this limitation but require strictly sequential frames, limiting their applicability to unstructured multi-view datasets. In this work, we introduce Multi-View Consistent 3D Gaussian Splatting Super-Resolution (MVGSR), a framework that focuses on integrating multi-view information for 3DGS rendering with high-frequency details and enhanced consistency. We first propose an Auxiliary View Selection Method based on camera poses, making our method adaptable for arbitrarily organized multi-view datasets without the need of temporal continuity or data reordering. Furthermore, we introduce, for the first time, an epipolar-constrained multi-view attention mechanism into 3DGS SR, which serves as the core of our proposed multi-view SR network. This design enables the model to selectively aggregate consistent information from auxiliary views, enhancing the geometric consistency and detail fidelity of 3DGS representations. Extensive experiments demonstrate that our method achieves state-of-the-art performance on both object-centric and scene-level 3DGS SR benchmarks.

</details>


### [15] [Asynchronous Event Stream Noise Filtering for High-frequency Structure Deformation Measurement](https://arxiv.org/abs/2512.15055)
*Yifei Bian,Banglei Guan,Zibin Liu,Ang Su,Shiyao Zhu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出一种基于事件相机和LED标记的高频率变形测量方法，通过滤除观测噪声并区分运动引起的事件与LED闪烁事件，实现对高速移动LED标记的提取，最终利用单目事件相机测量高频率平面变形。实验验证了该方法在测量高频率平面变形方面的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统高速相机测量方法受限于恶劣光照条件和高昂设备成本，难以应用于大规模结构的高频变形测量。

Method: 利用事件相机捕捉LED标记的闪烁信号，结合事件流特征与时空相关性滤除观测噪声，并区分运动事件与LED闪烁事件，从而提取高速移动的LED标记，进而通过单目事件相机测量高频率平面变形。

Result: 实验结果表明，该方法能够准确测量高频率平面变形，有效克服了传统方法在复杂光照和高成本方面的局限性。

Conclusion: 所提出的基于事件相机和LED标记的方法可有效实现高频率平面变形的精确测量，具有良好的应用前景。

Abstract: Large-scale structures suffer high-frequency deformations due to complex loads. However, harsh lighting conditions and high equipment costs limit measurement methods based on traditional high-speed cameras. This paper proposes a method to measure high-frequency deformations by exploiting an event camera and LED markers. Firstly, observation noise is filtered based on the characteristics of the event stream generated by LED markers blinking and spatiotemporal correlation. Then, LED markers are extracted from the event stream after differentiating between motion-induced events and events from LED blinking, which enables the extraction of high-speed moving LED markers. Ultimately, high-frequency planar deformations are measured by a monocular event camera. Experimental results confirm the accuracy of our method in measuring high-frequency planar deformations.

</details>


### [16] [PMMD: A pose-guided multi-view multi-modal diffusion for person generation](https://arxiv.org/abs/2512.15069)
*Ziyu Shang,Haoran Liu,Rongchao Zhang,Zhiqian Wei,Tongtong Feng*

Main category: cs.CV

TL;DR: PMMD是一种基于扩散模型的多视角多模态框架，用于生成姿势和外观可控的逼真人像，解决了遮挡、服装风格漂移和姿态错位等问题。通过联合建模多视图图像、姿态特征和语义描述，提升身份保真度，并引入ResCVA和跨模态融合模块以增强局部细节和全局结构一致性。在DeepFashion MultiModal数据集上表现优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成一致的人像时存在遮挡、服装风格漂移和姿态对齐问题，难以实现高保真度和可控性。需要一种能够同时控制姿态与外观且保持身份一致性的新方法。

Method: 提出Pose-guided Multi-view Multimodal Diffusion (PMMD)框架，采用多模态编码器联合建模多视角图像、姿态图和文本提示；设计ResCVA模块增强局部细节并保持全局结构；引入跨模态融合模块在去噪过程中整合图像语义与文本信息。

Result: 在DeepFashion MultiModal数据集上的实验表明，PMMD在一致性、细节保留和可控性方面均优于现有代表性方法。

Conclusion: PMMD通过多模态融合与精细化模块设计，有效提升了人像生成的质量与可控性，适用于虚拟试衣、图像编辑和数字人创建等应用。

Abstract: Generating consistent human images with controllable pose and appearance is essential for applications in virtual try on, image editing, and digital human creation. Current methods often suffer from occlusions, garment style drift, and pose misalignment. We propose Pose-guided Multi-view Multimodal Diffusion (PMMD), a diffusion framework that synthesizes photorealistic person images conditioned on multi-view references, pose maps, and text prompts. A multimodal encoder jointly models visual views, pose features, and semantic descriptions, which reduces cross modal discrepancy and improves identity fidelity. We further design a ResCVA module to enhance local detail while preserving global structure, and a cross modal fusion module that integrates image semantics with text throughout the denoising pipeline. Experiments on the DeepFashion MultiModal dataset show that PMMD outperforms representative baselines in consistency, detail preservation, and controllability. Project page and code are available at https://github.com/ZANMANGLOOPYE/PMMD.

</details>


### [17] [Uni-Parser Technical Report](https://arxiv.org/abs/2512.15098)
*Xi Fang,Haoyi Tao,Shuwen Yang,Suyang Zhong,Haocheng Lu,Han Lyu,Chaozheng Huang,Xinyu Li,Linfeng Zhang,Guolin Ke*

Main category: cs.CV

TL;DR: Uni-Parser 是一个面向科学文献和专利的工业级文档解析引擎，采用松耦合多专家架构，支持文本、公式、表格、图表和化学结构等多模态细粒度对齐，具备高吞吐、高精度和低成本优势。通过自适应GPU负载均衡、分布式推理和动态模块调度，可在8块NVIDIA RTX 4090D GPU上实现每秒20页的处理速度，适用于大规模云部署，广泛支持文献检索、摘要生成、化学结构提取及AI4Science模型训练等应用。


<details>
  <summary>Details</summary>
Motivation: 传统基于流水线的文档解析方法在多模态对齐、扩展性和可伸缩性方面存在局限，难以满足科学文献与专利等复杂文档的大规模高效解析需求，亟需一种更灵活、鲁棒且可扩展的解析框架。

Method: 提出一种模块化、松耦合的多专家架构，集成自适应GPU负载均衡、分布式推理、动态模块编排和可配置解析模式（全息或模态特定），支持跨模态细粒度对齐，并针对大规模云环境进行优化。

Result: 在8 x NVIDIA RTX 4090D GPU环境下，达到每秒20页的处理速率，具备极高的可扩展性与成本效益，支持百亿级文档处理，显著提升文献检索、化学结构提取、生物活性数据抽取及大模型训练效率。

Conclusion: Uni-Parser 通过创新的多专家架构与系统级优化，实现了对复杂科学文档的高效、精准、可扩展解析，为AI4Science与大规模知识工程提供了坚实的技术基础。

Abstract: This technical report introduces Uni-Parser, an industrial-grade document parsing engine tailored for scientific literature and patents, delivering high throughput, robust accuracy, and cost efficiency. Unlike pipeline-based document parsing methods, Uni-Parser employs a modular, loosely coupled multi-expert architecture that preserves fine-grained cross-modal alignments across text, equations, tables, figures, and chemical structures, while remaining easily extensible to emerging modalities. The system incorporates adaptive GPU load balancing, distributed inference, dynamic module orchestration, and configurable modes that support either holistic or modality-specific parsing. Optimized for large-scale cloud deployment, Uni-Parser achieves a processing rate of up to 20 PDF pages per second on 8 x NVIDIA RTX 4090D GPUs, enabling cost-efficient inference across billions of pages. This level of scalability facilitates a broad spectrum of downstream applications, ranging from literature retrieval and summarization to the extraction of chemical structures, reaction schemes, and bioactivity data, as well as the curation of large-scale corpora for training next-generation large language models and AI4Science models.

</details>


### [18] [Is Nano Banana Pro a Low-Level Vision All-Rounder? A Comprehensive Evaluation on 14 Tasks and 40 Datasets](https://arxiv.org/abs/2512.15110)
*Jialong Zuo,Haoyou Deng,Hanyu Zhou,Jiaxin Zhu,Yicheng Zhang,Yiwei Zhang,Yongxin Yan,Kaixing Huang,Weisen Chen,Yongtai Deng,Rui Jin,Nong Sang,Changxin Gao*

Main category: cs.CV

TL;DR: Nano Banana Pro shows strong subjective visual quality in zero-shot low-level vision tasks but underperforms in quantitative metrics due to stochasticity, making it a promising generalist yet not a replacement for domain specialists.


<details>
  <summary>Details</summary>
Motivation: To evaluate whether text-to-image models like Nano Banana Pro can serve as generalist solvers for low-level vision tasks, despite their dominance in creative applications.

Method: Zero-shot evaluation across 14 low-level vision tasks using 40 datasets with simple textual prompts, without fine-tuning, compared against specialist models.

Result: Nano Banana Pro excels in subjective visual quality and hallucinates plausible high-frequency details, but performs poorly on reference-based quantitative metrics due to inherent stochasticity.

Conclusion: Nano Banana Pro is a capable zero-shot generalist for low-level vision tasks, but achieving the pixel-level fidelity of specialist models remains challenging.

Abstract: The rapid evolution of text-to-image generation models has revolutionized visual content creation. While commercial products like Nano Banana Pro have garnered significant attention, their potential as generalist solvers for traditional low-level vision challenges remains largely underexplored. In this study, we investigate the critical question: Is Nano Banana Pro a Low-Level Vision All-Rounder? We conducted a comprehensive zero-shot evaluation across 14 distinct low-level tasks spanning 40 diverse datasets. By utilizing simple textual prompts without fine-tuning, we benchmarked Nano Banana Pro against state-of-the-art specialist models. Our extensive analysis reveals a distinct performance dichotomy: while \textbf{Nano Banana Pro demonstrates superior subjective visual quality}, often hallucinating plausible high-frequency details that surpass specialist models, it lags behind in traditional reference-based quantitative metrics. We attribute this discrepancy to the inherent stochasticity of generative models, which struggle to maintain the strict pixel-level consistency required by conventional metrics. This report identifies Nano Banana Pro as a capable zero-shot contender for low-level vision tasks, while highlighting that achieving the high fidelity of domain specialists remains a significant hurdle.

</details>


### [19] [Explainable Action Form Assessment by Exploiting Multimodal Chain-of-Thoughts Reasoning](https://arxiv.org/abs/2512.15153)
*Mengshi Qi,Yeteng Wu,Xianlin Zhang,Huadong Ma*

Main category: cs.CV

TL;DR: 本文提出了一项新的动作形式评估（AFA）任务，并构建了大规模的CoT-AFA数据集，涵盖健身与武术视频，包含多层级标注。通过引入链式思维（Chain-of-Thought）解释范式，提供从动作识别到结果分析再到解决方案的完整推理过程。提出可解释的健身评估框架Explainable Fitness Assessor，结合视觉与语义信息的双流结构和动态门控机制，在动作分类、质量评估及解释生成上均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法难以评估动作标准性，且缺乏对动作质量的可解释反馈；现有数据集缺少动作标准化程度标签，且解释性不足，无法支持高质量反馈生成。

Method: 提出基于链式思维的解释范式，设计可解释健身评估框架，采用双并行处理流与动态门控机制融合视觉与语义信息，实现动作判断与可解释反馈生成。

Result: 在动作分类准确率上提升2.7%，质量评估准确率提升2.1%，解释生成指标CIDEr提升16.0%，验证了方法的有效性与潜力。

Conclusion: CoT-AFA数据集与提出的框架为动作标准化评估与可解释反馈提供了有力支持，具备推动未来研究的潜力。

Abstract: Evaluating whether human action is standard or not and providing reasonable feedback to improve action standardization is very crucial but challenging in real-world scenarios. However, current video understanding methods are mainly concerned with what and where the action is, which is unable to meet the requirements. Meanwhile, most of the existing datasets lack the labels indicating the degree of action standardization, and the action quality assessment datasets lack explainability and detailed feedback. Therefore, we define a new Human Action Form Assessment (AFA) task, and introduce a new diverse dataset CoT-AFA, which contains a large scale of fitness and martial arts videos with multi-level annotations for comprehensive video analysis. We enrich the CoT-AFA dataset with a novel Chain-of-Thought explanation paradigm. Instead of offering isolated feedback, our explanations provide a complete reasoning process--from identifying an action step to analyzing its outcome and proposing a concrete solution. Furthermore, we propose a framework named Explainable Fitness Assessor, which can not only judge an action but also explain why and provide a solution. This framework employs two parallel processing streams and a dynamic gating mechanism to fuse visual and semantic information, thereby boosting its analytical capabilities. The experimental results demonstrate that our method has achieved improvements in explanation generation (e.g., +16.0% in CIDEr), action classification (+2.7% in accuracy) and quality assessment (+2.1% in accuracy), revealing great potential of CoT-AFA for future studies. Our dataset and source code is available at https://github.com/MICLAB-BUPT/EFA.

</details>


### [20] [Criticality Metrics for Relevance Classification in Safety Evaluation of Object Detection in Automated Driving](https://arxiv.org/abs/2512.15181)
*Jörg Gamerdinger,Sven Teufel,Stephan Amann,Oliver Bringmann*

Main category: cs.CV

TL;DR: 本文首次深入分析了用于自动驾驶中物体检测系统安全评估的临界性度量，通过文献综述识别并评估多种适用度量，并在DeepAccident数据集上进行实证验证。为提升评估准确性，提出双向临界性评分和多度量聚合两种新策略，使临界性分类准确率最高提升100%，显著推动了自动驾驶中物体检测系统安全评估的发展。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶的安全性需要对环境进行全面且准确的感知，现有性能评估指标虽多，但缺乏专门针对安全性的度量，尤其在区分相关与非相关物体方面存在挑战，因此亟需引入临界性或相关性度量以提升安全评估的可靠性。

Method: 通过文献综述识别并评估多种临界性度量；基于DeepAccident数据集进行实证分析；提出双向临界性评分和多度量聚合两种新型应用策略以增强评估准确性。

Result: 所提方法在临界性分类准确率上实现最高达100%的提升，验证了其在提升自动驾驶物体检测系统安全评估能力方面的有效性。

Conclusion: 该研究为自动驾驶中物体检测系统的安全评估提供了有效的临界性度量分析框架和改进策略，显著提升了评估精度，具有重要应用价值。

Abstract: Ensuring safety is the primary objective of automated driving, which necessitates a comprehensive and accurate perception of the environment. While numerous performance evaluation metrics exist for assessing perception capabilities, incorporating safety-specific metrics is essential to reliably evaluate object detection systems. A key component for safety evaluation is the ability to distinguish between relevant and non-relevant objects - a challenge addressed by criticality or relevance metrics. This paper presents the first in-depth analysis of criticality metrics for safety evaluation of object detection systems. Through a comprehensive review of existing literature, we identify and assess a range of applicable metrics. Their effectiveness is empirically validated using the DeepAccident dataset, which features a variety of safety-critical scenarios. To enhance evaluation accuracy, we propose two novel application strategies: bidirectional criticality rating and multi-metric aggregation. Our approach demonstrates up to a 100% improvement in terms of criticality classification accuracy, highlighting its potential to significantly advance the safety evaluation of object detection systems in automated vehicles.

</details>


### [21] [Robust and Calibrated Detection of Authentic Multimedia Content](https://arxiv.org/abs/2512.15182)
*Sarim Hashmi,Abdelrahman Elsayed,Mohammed Talha Alam,Samuele Poppi,Nils Lukas*

Main category: cs.CV

TL;DR: 本文提出一种重合成框架，用于判断样本是否真实或其真实性是否可被合理否认。针对高效（计算资源受限）攻击者，该方法在高精度、低召回率设置下表现出可靠性和鲁棒性，有效控制误报率并抵御对抗性攻击，适用于多种模态且基于先进的反演技术。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测方法存在两大缺陷：一是事后辨别不真实内容往往不可行（如记忆样本），导致误报率无界；二是检测缺乏鲁棒性，攻击者可用极少计算资源绕过已知检测器。因此亟需一种更可靠的验证机制。

Method: 提出基于校准重合成的方法，利用先进的反演技术，实现对样本真实性的高精度验证，并在计算资源受限条件下保持低误报率与对抗鲁棒性。

Result: 所提方法在高精度、低召回场景下显著优于现有方法，能有效控制误报率，且对高效攻击者具备强鲁棒性，而现有方法易被规避。

Conclusion: 该重合成框架为深度伪造内容的真实性验证提供了可靠且高效的解决方案，尤其适用于对抗性环境下的安全验证任务。

Abstract: Generative models can synthesize highly realistic content, so-called deepfakes, that are already being misused at scale to undermine digital media authenticity. Current deepfake detection methods are unreliable for two reasons: (i) distinguishing inauthentic content post-hoc is often impossible (e.g., with memorized samples), leading to an unbounded false positive rate (FPR); and (ii) detection lacks robustness, as adversaries can adapt to known detectors with near-perfect accuracy using minimal computational resources. To address these limitations, we propose a resynthesis framework to determine if a sample is authentic or if its authenticity can be plausibly denied. We make two key contributions focusing on the high-precision, low-recall setting against efficient (i.e., compute-restricted) adversaries. First, we demonstrate that our calibrated resynthesis method is the most reliable approach for verifying authentic samples while maintaining controllable, low FPRs. Second, we show that our method achieves adversarial robustness against efficient adversaries, whereas prior methods are easily evaded under identical compute budgets. Our approach supports multiple modalities and leverages state-of-the-art inversion techniques.

</details>


### [22] [TBC: A Target-Background Contrast Metric for Low-Altitude Infrared and Visible Image Fusion](https://arxiv.org/abs/2512.15211)
*Yufeng Xie*

Main category: cs.CV

TL;DR: 针对低空无人机侦察中红外与可见光图像融合的挑战，本文提出一种新的无参考评估指标TBC（目标-背景对比度），以解决传统指标在复杂低光照环境下因误将高频传感器噪声当作有效细节而导致评分失真的问题。TBC基于Weber定律，关注显著目标相对于背景的相对对比度，有效抑制背景噪声并提升对目标可见性的评价，实验表明其更符合人类感知，在DroneVehicle数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统无参考图像质量评估指标（如熵EN和平均梯度AG）在复杂低光照环境下容易将传感器噪声误判为有效细节，导致'噪声陷阱'现象，即高噪声图像获得更高评分，误导融合算法优化方向。因此需要一种更符合人类视觉感知、能准确区分真实细节与噪声的新指标。

Method: 提出基于Weber定律的Target-Background Contrast (TBC)指标，通过计算目标区域与背景区域之间的相对对比度来评估图像融合质量，强调对显著目标的可见性增强，同时对背景噪声进行惩罚，避免被噪声干扰。

Result: 在DroneVehicle数据集上的实验结果表明，TBC指标与人类主观评价具有更高的相关性，能够有效避免传统指标的噪声陷阱问题，为低空无人机场景下的图像融合提供了可靠的评估标准。

Conclusion: TBC是一种针对低空无人机红外与可见光图像融合任务设计的新型无参考评估指标，能够更准确地反映真实目标可见性，抑制噪声干扰，显著提升融合效果评估的可靠性。

Abstract: Infrared and visible image fusion is a pivotal technology in low-altitude UAV reconnaissance missions, providing high-quality data support for downstream tasks such as target detection and tracking by integrating thermal saliency with background texture details.However, traditional no-reference metrics fail(Specifically,like Entropy (EN) and Average Gradient (AG)) in complex low-light environments. They often misinterpret high-frequency sensor noise as valid detail. This creates a "Noise Trap," paradoxically assigning higher scores to noisy images and misguiding fusion algorithms.To address this, we propose the Target-Background Contrast (TBC) metric. Inspired by Weber's Law, TBC focuses on the relative contrast of salient targets rather than global statistics. Unlike traditional metrics, TBC penalizes background noise and rewards target visibility. Experiments on the DroneVehicle dataset demonstrate that TBC aligns better with human perception and provides a reliable standard for low-altitude scenarios.

</details>


### [23] [From Camera to World: A Plug-and-Play Module for Human Mesh Transformation](https://arxiv.org/abs/2512.15212)
*Changhai Ma,Ziyu Wu,Yunkang Zhang,Qijun Ying,Boyan Liu,Xiaohui Cai*

Main category: cs.CV

TL;DR: 本文提出Mesh-Plug模块，解决从野外图像中重建世界坐标系下精确3D人体网格的挑战。通过结合RGB图像和初始网格渲染的深度图，利用人体中心方法估计相机旋转参数，避免依赖环境线索。首先训练一个关注人体空间配置的相机俯仰角预测模块；然后结合预测参数与初始网格，设计网格调整模块同步优化根关节方向与身体姿态。实验表明该方法在SPEC-SYN和SPEC-MTP基准数据集上优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 从野外图像中重建3D人体网格时，由于缺乏相机旋转信息，现有方法通常假设相机无旋转，导致在转换到世界坐标系时产生显著误差。因此需要一种无需依赖环境线索即可准确估计相机旋转并实现坐标转换的方法。

Method: 提出Mesh-Plug模块，包含两个部分：1）基于人体空间配置的相机旋转预测模块，用于估计相机俯仰角；2）融合预测参数与初始网格的网格调整模块，同时优化根关节方向和身体姿态。利用RGB图像与深度图联合建模，实现从相机坐标系到世界坐标系的精准变换。

Result: 在SPEC-SYN和SPEC-MTP两个基准数据集上，所提方法显著优于当前最先进的3D人体重建方法，在世界坐标系下的重建精度明显提升。

Conclusion: Mesh-Plug是一种有效的插件式模块，能够准确将3D人体网格从相机坐标系转换至世界坐标系，克服了传统方法对零相机旋转假设的依赖，提升了真实场景下3D人体重建的准确性与鲁棒性。

Abstract: Reconstructing accurate 3D human meshes in the world coordinate system from in-the-wild images remains challenging due to the lack of camera rotation information. While existing methods achieve promising results in the camera coordinate system by assuming zero camera rotation, this simplification leads to significant errors when transforming the reconstructed mesh to the world coordinate system. To address this challenge, we propose Mesh-Plug, a plug-and-play module that accurately transforms human meshes from camera coordinates to world coordinates. Our key innovation lies in a human-centered approach that leverages both RGB images and depth maps rendered from the initial mesh to estimate camera rotation parameters, eliminating the dependency on environmental cues. Specifically, we first train a camera rotation prediction module that focuses on the human body's spatial configuration to estimate camera pitch angle. Then, by integrating the predicted camera parameters with the initial mesh, we design a mesh adjustment module that simultaneously refines the root joint orientation and body pose. Extensive experiments demonstrate that our framework outperforms state-of-the-art methods on the benchmark datasets SPEC-SYN and SPEC-MTP.

</details>


### [24] [Null-LoRA: Low-Rank Adaptation on Null Space](https://arxiv.org/abs/2512.15233)
*Yi Zhang,Yulei Kang,Haoxuan Chen,Jinxuan Li,ian-Fang Hu*

Main category: cs.CV

TL;DR: Null-LoRA是一种基于零空间的低秩适应方法，通过冻结部分低秩矩阵来减少冗余并提高有效秩，同时将增量更新限制在零空间内以最大化其对新任务的适应性，从而在图像-文本检索和视觉问答等任务中以更少参数超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 预训练模型存在非平凡的零空间，现有低秩微调方法在全参数空间上进行，但子空间微调可达到相当效果，因此需要一种更高效的方法来减少冗余并提升参数利用效率。

Method: 提出Null-LoRA，通过冻结部分低秩矩阵减少冗余，并将整个增量更新约束在零空间内，以增强有效秩和参数效率。

Result: 在图像-文本检索和视觉问答任务中，Null-LoRA以更少参数实现优于当前最优方法的性能。

Conclusion: Null-LoRA通过利用模型的零空间特性，实现了更高的参数效率和更强的适应能力，是当前参数高效微调方法的先进代表。

Abstract: Parameter-efficient fine-tuning methods have gained considerable popularity for adapting large-scale models to downstream tasks, particularly LoRA and its variants. Existing methods perform low-rank adaptation over the full parameter space. However, fine-tuning within a subspace can achieve comparable effectiveness. Inspired by the observation that pre-trained models possess non-trivial null spaces, we propose Null-space based Low-Rank Adaptation (Null-LoRA). Null-LoRA effectively reduces redundancy and enhances effective rank by freezing portions of the low-rank matrices. To further improve parameter efficiency, Null-LoRA constrains the entire incremental update within the null space, maximizing the utilization of incremental updates to adapt to new task paradigms. Null-LoRA surpasses the state of the art with fewer parameters in extensive experiments across image-text retrieval and visual question answering tasks.

</details>


### [25] [Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification](https://arxiv.org/abs/2512.15249)
*Yupeng Zhang,Adam G. Dunn,Usman Naseem,Jinman Kim*

Main category: cs.CV

TL;DR: 本文提出了一种名为交叉模态对齐一致性（CMAC-MMD）的训练框架，旨在减少医疗人工智能系统中因人口统计学特征交叉导致的诊断信心偏差。该方法在不使用敏感个人信息的情况下，提升模型在不同年龄、性别和种族群体间的诊断公平性，同时提高整体诊断性能。在皮肤病变和青光眼筛查任务中，该方法显著降低了误诊率差异（ΔTPR），并提升了模型的AUC表现，证明了其在高风险临床决策支持系统中的有效性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI模型存在交叉性偏见，即在边缘化患者群体中诊断置信度较低，导致误诊和漏诊率升高。现有公平性干预措施往往无法有效解决此类问题，或以牺牲整体性能为代价。因此亟需一种既能提升公平性又不损害准确性的新方法。

Method: 提出交叉模态对齐一致性（CMAC-MMD）训练框架，通过跨模态对齐与分布一致性约束，在训练阶段标准化不同人口子组的诊断置信度，避免依赖敏感信息进行推理，实现无隐私风险的公平性优化。

Result: 在皮肤病变数据集（HAM10000）上，ΔTPR从0.50降至0.26，AUC从0.94提升至0.97；在青光眼数据集（Harvard-FairVLMed）上，ΔTPR从0.41降至0.31，AUC从0.71提升至0.72，表明该方法在提升公平性的同时保持甚至增强了模型性能。

Conclusion: CMAC-MMD提供了一个高效且可扩展的框架，可在不增加隐私风险的前提下，实现医疗AI系统在多样化人群中的公平、准确诊断，适用于高风险临床决策支持场景。

Abstract: Medical artificial intelligence (AI) systems, particularly multimodal vision-language models (VLM), often exhibit intersectional biases where models are systematically less confident in diagnosing marginalised patient subgroups. Such bias can lead to higher rates of inaccurate and missed diagnoses due to demographically skewed data and divergent distributions of diagnostic certainty. Current fairness interventions frequently fail to address these gaps or compromise overall diagnostic performance to achieve statistical parity among the subgroups. In this study, we developed Cross-Modal Alignment Consistency (CMAC-MMD), a training framework that standardises diagnostic certainty across intersectional patient subgroups. Unlike traditional debiasing methods, this approach equalises the model's decision confidence without requiring sensitive demographic data during clinical inference. We evaluated this approach using 10,015 skin lesion images (HAM10000) with external validation on 12,000 images (BCN20000), and 10,000 fundus images for glaucoma detection (Harvard-FairVLMed), stratifying performance by intersectional age, gender, and race attributes. In the dermatology cohort, the proposed method reduced the overall intersectional missed diagnosis gap (difference in True Positive Rate, $Δ$TPR) from 0.50 to 0.26 while improving the overall Area Under the Curve (AUC) from 0.94 to 0.97 compared to standard training. Similarly, for glaucoma screening, the method reduced $Δ$TPR from 0.41 to 0.31, achieving a better AUC of 0.72 (vs. 0.71 baseline). This establishes a scalable framework for developing high-stakes clinical decision support systems that are both accurate and can perform equitably across diverse patient subgroups, ensuring reliable performance without increasing privacy risks.

</details>


### [26] [MMMamba: A Versatile Cross-Modal In Context Fusion Framework for Pan-Sharpening and Zero-Shot Image Enhancement](https://arxiv.org/abs/2512.15261)
*Yingying Wang,Xuanhua He,Chen Wu,Jialing Huang,Suiyun Zhang,Rui Liu,Xinghao Ding,Haoxuan Che*

Main category: cs.CV

TL;DR: 本文提出了一种名为MMMamba的跨模态上下文融合框架，用于全色锐化任务，能够以线性计算复杂度实现高效的跨模态信息交互。该方法基于Mamba架构，并引入了新颖的多模态交错扫描机制，有效促进全色（PAN）与多光谱（MS）图像之间的信息交换。相比传统CNN方法和依赖交叉注意力的模型，该方法在保持高效性的同时提升了对空间与光谱变化的适应能力。实验表明，该方法在多个基准测试中均优于现有最先进技术，且具备零样本支持图像超分辨率的能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的全色锐化方法依赖固定的通道拼接和卷积操作，难以适应复杂的空间与光谱变化；而现有的交叉注意力机制虽能实现全局交互，但存在计算开销大、细粒度对应关系被稀释的问题。因此，亟需一种既能高效建模跨模态关系又具备强适应性的新方法。

Method: 提出MMMamba框架，基于Mamba架构实现线性复杂度下的长序列建模，结合多模态交错扫描（MI）机制，通过上下文条件化方式实现PAN与MS图像间的直接、高效信息交换，无需依赖昂贵的交叉注意力模块。

Result: 在多个公开数据集上的实验结果表明，该方法在全色锐化任务中显著优于现有SOTA方法，在视觉质量、定量指标（如PSNR、SSIM）以及零样本超分辨率能力方面均表现出优越性能。

Conclusion: MMMamba通过融合Mamba的高效序列建模能力和创新的多模态交错扫描机制，实现了高性能、低复杂度的跨模态信息融合，为全色锐化提供了新的解决方案，并具备扩展至其他多模态任务的潜力。

Abstract: Pan-sharpening aims to generate high-resolution multispectral (HRMS) images by integrating a high-resolution panchromatic (PAN) image with its corresponding low-resolution multispectral (MS) image. To achieve effective fusion, it is crucial to fully exploit the complementary information between the two modalities. Traditional CNN-based methods typically rely on channel-wise concatenation with fixed convolutional operators, which limits their adaptability to diverse spatial and spectral variations. While cross-attention mechanisms enable global interactions, they are computationally inefficient and may dilute fine-grained correspondences, making it difficult to capture complex semantic relationships. Recent advances in the Multimodal Diffusion Transformer (MMDiT) architecture have demonstrated impressive success in image generation and editing tasks. Unlike cross-attention, MMDiT employs in-context conditioning to facilitate more direct and efficient cross-modal information exchange. In this paper, we propose MMMamba, a cross-modal in-context fusion framework for pan-sharpening, with the flexibility to support image super-resolution in a zero-shot manner. Built upon the Mamba architecture, our design ensures linear computational complexity while maintaining strong cross-modal interaction capacity. Furthermore, we introduce a novel multimodal interleaved (MI) scanning mechanism that facilitates effective information exchange between the PAN and MS modalities. Extensive experiments demonstrate the superior performance of our method compared to existing state-of-the-art (SOTA) techniques across multiple tasks and benchmarks.

</details>


### [27] [Automated Motion Artifact Check for MRI (AutoMAC-MRI): An Interpretable Framework for Motion Artifact Detection and Severity Assessment](https://arxiv.org/abs/2512.15315)
*Antony Jerald,Dattesh Shanbhag,Sudhanya Chatterjee*

Main category: cs.CV

TL;DR: AutoMAC-MRI is an explainable framework for grading motion artifacts in MRI using supervised contrastive learning to create discriminative features. It computes grade-specific affinity scores to make decisions transparent and interpretable, showing strong alignment with expert judgments across 5000+ brain MRI slices.


<details>
  <summary>Details</summary>
Motivation: Motion artifacts degrade MRI quality and lead to patient recalls; existing methods lack interpretability and are limited to binary assessments.

Method: Supervised contrastive learning is used to learn discriminative representations of motion severity, followed by computing grade-specific affinity scores to quantify proximity to each motion grade.

Result: Affinity scores strongly align with expert labels, enabling accurate, interpretable motion grading and supporting inline MRI quality control.

Conclusion: AutoMAC-MRI enhances MRI quality assessment by combining accurate grading with interpretable scoring, reducing unnecessary rescans and improving workflow efficiency.

Abstract: Motion artifacts degrade MRI image quality and increase patient recalls. Existing automated quality assessment methods are largely limited to binary decisions and provide little interpretability. We introduce AutoMAC-MRI, an explainable framework for grading motion artifacts across heterogeneous MR contrasts and orientations. The approach uses supervised contrastive learning to learn a discriminative representation of motion severity. Within this feature space, we compute grade-specific affinity scores that quantify an image's proximity to each motion grade, thereby making grade assignments transparent and interpretable. We evaluate AutoMAC-MRI on more than 5000 expert-annotated brain MRI slices spanning multiple contrasts and views. Experiments assessing affinity scores against expert labels show that the scores align well with expert judgment, supporting their use as an interpretable measure of motion severity. By coupling accurate grade detection with per-grade affinity scoring, AutoMAC-MRI enables inline MRI quality control, with the potential to reduce unnecessary rescans and improve workflow efficiency.

</details>


### [28] [MECAD: A multi-expert architecture for continual anomaly detection](https://arxiv.org/abs/2512.15323)
*Malihe Dahmardeh,Francesco Setti*

Main category: cs.CV

TL;DR: MECAD提出一种基于多专家架构的持续异常检测方法，通过特征相似性动态分配专家，并结合优化的压缩核心选择和专用回放缓冲机制，实现增量学习而无需完整重训练。在MVTec AD数据集上的实验表明，5专家配置平均AUROC达0.8259，显著减少知识退化，兼顾计算效率与适应性，适用于工业中不断变化的产品类型。


<details>
  <summary>Details</summary>
Motivation: 现有持续异常检测方法在面对新类别时易出现知识退化，且缺乏高效的知识保留与动态分配机制，难以满足工业场景中产品类型持续演进的需求。

Method: 采用多专家架构，根据特征相似性动态分配专家；利用优化的压缩核心选择和专门设计的回放缓冲机制进行高效记忆管理，支持增量学习而不需全量重训练。

Result: 在MVTec AD数据集上，5专家配置实现平均AUROC 0.8259，优于单专家方法，在多个对象类别上表现出更强的稳定性与适应性。

Conclusion: MECAD通过多专家动态分配与高效记忆管理，有效缓解了持续学习中的知识退化问题，具备良好的计算效率与可扩展性，适合部署于工业环境中不断更新的产品检测任务。

Abstract: In this paper we propose MECAD, a novel approach for continual anomaly detection using a multi-expert architecture. Our system dynamically assigns experts to object classes based on feature similarity and employs efficient memory management to preserve the knowledge of previously seen classes. By leveraging an optimized coreset selection and a specialized replay buffer mechanism, we enable incremental learning without requiring full model retraining. Our experimental evaluation on the MVTec AD dataset demonstrates that the optimal 5-expert configuration achieves an average AUROC of 0.8259 across 15 diverse object categories while significantly reducing knowledge degradation compared to single-expert approaches. This framework balances computational efficiency, specialized knowledge retention, and adaptability, making it well-suited for industrial environments with evolving product types.

</details>


### [29] [A Masked Reverse Knowledge Distillation Method Incorporating Global and Local Information for Image Anomaly Detection](https://arxiv.org/abs/2512.15326)
*Yuxin Jiang,Yunkang Can,Weiming Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为掩码反向知识蒸馏（MRKD）的新技术，通过图像级掩码（ILM）和特征级掩码（FLM）将图像重建任务转化为图像恢复任务，以缓解知识蒸馏在图像异常检测中过度泛化的缺陷。ILM捕捉全局信息，FLM引入合成的局部异常特征，增强模型对局部细节的感知能力。实验表明，MRKD在MVTec数据集上取得了优异性能：图像级98.9% AU-ROC，像素级98.4% AU-ROC，AU-PRO达95.3%。消融实验验证了其在抑制过泛化方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法在图像异常检测中易因输入与监督信号过于相似而产生过度泛化问题，导致对局部异常敏感度不足。

Method: 提出掩码反向知识蒸馏（MRKD），结合图像级掩码（ILM）与特征级掩码（FLM）。ILM使输入与监督信号差异化，增强全局上下文建模；FLM引入合成异常特征，提升局部表示能力，将原重建任务转为恢复任务。

Result: 在MVTec数据集上，图像级AU-ROC达98.9%，像素级达98.4%，AU-PRO达95.3%；消融实验验证了方法在缓解过泛化方面的优势。

Conclusion: MRKD通过双重掩码机制有效提升了模型对图像上下文的捕捉能力，显著降低过度泛化风险，在异常检测与定位任务中表现卓越。

Abstract: Knowledge distillation is an effective image anomaly detection and localization scheme. However, a major drawback of this scheme is its tendency to overly generalize, primarily due to the similarities between input and supervisory signals. In order to address this issue, this paper introduces a novel technique called masked reverse knowledge distillation (MRKD). By employing image-level masking (ILM) and feature-level masking (FLM), MRKD transforms the task of image reconstruction into image restoration. Specifically, ILM helps to capture global information by differentiating input signals from supervisory signals. On the other hand, FLM incorporates synthetic feature-level anomalies to ensure that the learned representations contain sufficient local information. With these two strategies, MRKD is endowed with stronger image context capture capacity and is less likely to be overgeneralized. Experiments on the widely-used MVTec anomaly detection dataset demonstrate that MRKD achieves impressive performance: image-level 98.9% AU-ROC, pixel-level 98.4% AU-ROC, and 95.3% AU-PRO. In addition, extensive ablation experiments have validated the superiority of MRKD in mitigating the overgeneralization problem.

</details>


### [30] [Vision-based module for accurately reading linear scales in a laboratory](https://arxiv.org/abs/2512.15327)
*Parvesh Saini,Soumyadipta Maiti,Beena Rai*

Main category: cs.CV

TL;DR: 本文提出了一种模拟人类读取线性刻度测量值的方法，用于从注射器和量筒中准确读取液位。通过图像旋转校正、兴趣区域裁剪以及关键特征（如刻度标记、数字和液位指示器）的提取，实现了对随机朝向物体的鲁棒读取。系统输出与人工读数高度一致，验证了其准确性与实用性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型在目标检测、图像分类等任务上表现优异，但在从图像中进行精确定量测量方面仍显不足。为实现机器人在实验室环境中的完全自主操作，需具备像人类一样读取仪器刻度的能力，尤其在无结构环境中完成样本制备、导航和物体操作等任务。因此，本研究旨在开发一种可准确读取线性刻度（如注射器、量筒）液位的视觉系统。

Method: 针对随机朝向的注射器，首先进行图像变换以校正姿态；随后聚焦于线性刻度区域，缩小感兴趣区域；接着提取主要刻度标记、对应数字及液位指示器位置等特征；最后基于这些特征计算出液位读数。

Result: 该系统能够准确读取注射器和量筒中的液位，且与人工读数具有高度一致性，验证了方法的有效性和鲁棒性。

Conclusion: 本研究成功构建了一个仿人读数的视觉系统，能够在复杂条件下准确获取线性刻度上的定量测量值，为机器人在实验室环境中的自主操作提供了关键技术支撑。

Abstract: Capabilities and the number of vision-based models are increasing rapidly. And these vision models are now able to do more tasks like object detection, image classification, instance segmentation etc. with great accuracy. But models which can take accurate quantitative measurements form an image, as a human can do by just looking at it, are rare. For a robot to work with complete autonomy in a Laboratory environment, it needs to have some basic skills like navigation, handling objects, preparing samples etc. to match human-like capabilities in an unstructured environment. Another important capability is to read measurements from instruments and apparatus. Here, we tried to mimic a human inspired approach to read measurements from a linear scale. As a test case we have picked reading level from a syringe and a measuring cylinder. For a randomly oriented syringe we carry out transformations to correct the orientation. To make the system efficient and robust, the area of interest is reduced to just the linear scale containing part of the image. After that, a series of features were extracted like the major makers, the corresponding digits, and the level indicator location, from which the final reading was calculated. Readings obtained using this system were also compared against human read values of the same instances and an accurate correspondence was observed.

</details>


### [31] [Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics](https://arxiv.org/abs/2512.15340)
*Junjie Chen,Fei Wang,Zhihao Huang,Qing Zhou,Kun Li,Dan Guo,Linfeng Zhang,Xun Yang*

Main category: cs.CV

TL;DR: TIMAR是一种用于3D对话头部生成的因果框架，通过融合多模态信息并利用逐轮因果注意力累积对话历史，实现更连贯的对话动态建模。其轻量级扩散头可预测连续的3D头部动作，捕捉协调性与表现力变化。在DualTalk基准测试中，相比现有方法，其Fréchet距离和MSE降低15-30%，且在分布外数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有对话建模框架常将说话与倾听视为独立过程，或依赖非因果的全序列建模，导致跨轮次的时间不连贯性。为提升3D对话头生成的自然性和一致性，亟需一种能有效建模双向交互、保持时序因果性的方法。

Method: TIMAR采用逐轮交错的掩码自回归机制，融合每一轮中的多模态（音频与视觉）上下文，并通过转轮级因果注意力逐步累积对话历史；同时引入轻量级扩散模型头，以生成具有表达多样性和协调性的连续3D头部动作。

Result: 在DualTalk数据集上，TIMAR显著降低15-30%的Fréchet距离与均方误差，在分布外数据上也表现出色，验证了其泛化能力与生成质量。

Conclusion: TIMAR通过因果建模与多模态融合，实现了高质量、连贯且富有表现力的3D对话头部生成，为构建自然交互的虚拟角色与机器人提供了有效解决方案。

Abstract: Human conversation involves continuous exchanges of speech and nonverbal cues such as head nods, gaze shifts, and facial expressions that convey attention and emotion. Modeling these bidirectional dynamics in 3D is essential for building expressive avatars and interactive robots. However, existing frameworks often treat talking and listening as independent processes or rely on non-causal full-sequence modeling, hindering temporal coherence across turns. We present TIMAR (Turn-level Interleaved Masked AutoRegression), a causal framework for 3D conversational head generation that models dialogue as interleaved audio-visual contexts. It fuses multimodal information within each turn and applies turn-level causal attention to accumulate conversational history, while a lightweight diffusion head predicts continuous 3D head dynamics that captures both coordination and expressive variability. Experiments on the DualTalk benchmark show that TIMAR reduces Fréchet Distance and MSE by 15-30% on the test set, and achieves similar gains on out-of-distribution data. The source code will be released in the GitHub repository https://github.com/CoderChen01/towards-seamleass-interaction.

</details>


### [32] [Expand and Prune: Maximizing Trajectory Diversity for Effective GRPO in Generative Models](https://arxiv.org/abs/2512.15347)
*Shiran Ge,Chenyi Huang,Yuang Ai,Qihang Fan,Huaibo Huang,Ran He*

Main category: cs.CV

TL;DR: Pro-GRPO 提出一种动态框架，通过在采样过程中集成基于潜在特征的轨迹剪枝，有效减少计算开销。其核心在于利用 'Expand-and-Prune' 策略，在扩大初始采样组以增强多样性后，通过多步最优方差过滤（OVF）避免高成本计算，显著提升 Group Relative Policy Optimization (GRPO) 的效率与性能。


<details>
  <summary>Details</summary>
Motivation: GRPO 在对齐生成模型时受限于大组规模带来的高昂计算成本，尤其因大量轨迹趋同于组均奖励而产生低优化价值，亟需更高效的采样与筛选机制。

Method: 提出 Pro-GRPO 框架，结合潜在特征的动态轨迹剪枝，引入 'Expand-and-Prune' 策略：先扩大采样组以提升多样性，再通过多步 OVF 对潜在表示进行筛选，实现早期终止奖励聚集轨迹，降低计算负担。

Result: 在基于扩散和流模型的广泛实验中，Pro-GRPO 展现出良好的通用性与有效性，相比传统 GRPO 显著降低计算开销并提升优化性能。

Conclusion: Pro-GRPO 通过动态剪枝与高效采样策略，成功缓解了 GRPO 中因大规模采样导致的计算瓶颈，为生成模型对齐提供了更高效、可扩展的解决方案。

Abstract: Group Relative Policy Optimization (GRPO) is a powerful technique for aligning generative models, but its effectiveness is bottlenecked by the conflict between large group sizes and prohibitive computational costs. In this work, we investigate the trade-off through empirical studies, yielding two key observations. First, we discover the reward clustering phenomenon in which many trajectories collapse toward the group-mean reward, offering limited optimization value. Second, we design a heuristic strategy named Optimal Variance Filtering (OVF), and verify that a high-variance subset of trajectories, selected by OVF can outperform the larger, unfiltered group. However, this static, post-sampling OVF approach still necessitates critical computational overhead, as it performs unnecessary sampling for trajectories that are ultimately discarded. To resolve this, we propose Pro-GRPO (Proactive GRPO), a novel dynamic framework that integrates latent feature-based trajectory pruning into the sampling process. Through the early termination of reward-clustered trajectories, Pro-GRPO reduces computational overhead. Leveraging its efficiency, Pro-GRPO employs an "Expand-and-Prune" strategy. This strategy first expands the size of initial sampling group to maximize trajectory diversity, then it applies multi-step OVF to the latents, avoiding prohibitive computational costs. Extensive experiments on both diffusion-based and flow-based models demonstrate the generality and effectiveness of our Pro-GRPO framework.

</details>


### [33] [VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?](https://arxiv.org/abs/2512.15649)
*Hongbo Zhao,Meng Wang,Fei Zhu,Wenzhuo Liu,Bolin Ni,Fanhu Zeng,Gaofeng Meng,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 本文提出首个针对视觉-文本压缩（VTC）的基准测试VTCBench，系统评估视觉语言模型（VLMs）在长上下文理解任务中的表现，涵盖信息检索、推理和记忆三大场景。尽管多数VLM能良好解码文本，但在处理高密度压缩信息时，普遍表现出对长距离依赖关系捕捉能力差的问题。研究揭示了当前VTC方法在保持长程理解方面的局限性，并为未来高效可扩展的VLM设计提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-文本压缩（VTC）技术虽能显著降低大模型的计算与内存开销，但其对长上下文理解能力的影响尚未被充分研究。尤其在高信息密度压缩下，模型是否仍能有效捕捉长距离依赖和关联仍不明确，亟需系统评估工具以推动该领域发展。

Method: 构建VTCBench基准，包含三个核心任务：VTC-Retrieval（信息检索）、VTC-Reasoning（逻辑推理）和VTC-Memory（长期记忆问答），并引入VTCBench-Wild模拟多样化真实输入场景；对主流开源与闭源模型进行综合评估。

Result: 实验表明，尽管大多数VLM能准确识别压缩后的文本内容（如OCR），但在处理需要长距离语义关联的任务中表现不佳，难以有效建模上下文中的深层依赖关系，说明当前VTC压缩方式可能削弱模型的长程理解能力。

Conclusion: 本研究首次系统揭示了视觉-文本压缩在提升效率的同时，可能损害模型的长上下文理解能力。建立的VTCBench为评估与优化未来高效、可扩展的视觉语言模型提供了重要基准与方向。

Abstract: The computational and memory overheads associated with expanding the context window of LLMs severely limit their scalability. A noteworthy solution is vision-text compression (VTC), exemplified by frameworks like DeepSeek-OCR and Glyph, which convert long texts into dense 2D visual representations, thereby achieving token compression ratios of 3x-20x. However, the impact of this high information density on the core long-context capabilities of vision-language models (VLMs) remains under-investigated. To address this gap, we introduce the first benchmark for VTC and systematically assess the performance of VLMs across three long-context understanding settings: VTC-Retrieval, which evaluates the model's ability to retrieve and aggregate information; VTC-Reasoning, which requires models to infer latent associations to locate facts with minimal lexical overlap; and VTC-Memory, which measures comprehensive question answering within long-term dialogue memory. Furthermore, we establish the VTCBench-Wild to simulate diverse input scenarios.We comprehensively evaluate leading open-source and proprietary models on our benchmarks. The results indicate that, despite being able to decode textual information (e.g., OCR) well, most VLMs exhibit a surprisingly poor long-context understanding ability with VTC-compressed information, failing to capture long associations or dependencies in the context.This study provides a deep understanding of VTC and serves as a foundation for designing more efficient and scalable VLMs.

</details>


### [34] [SemanticBridge -- A Dataset for 3D Semantic Segmentation of Bridges and Domain Gap Analysis](https://arxiv.org/abs/2512.15369)
*Maximilian Kellner,Mariana Ferrandon Cervantes,Yuandong Pan,Ruodan Lu,Ioannis Brilakis,Alexander Reiterer*

Main category: cs.CV

TL;DR: 本文提出了一种专为桥梁3D语义分割及传感器引起的域差异分析设计的新数据集，包含来自不同国家的多样化桥梁高分辨率3D扫描数据，并提供详细语义标签。研究旨在推动桥梁结构健康监测的自动化与精准化。通过评估三种先进的3D深度学习模型，发现其在该数据集上表现良好，但传感器差异导致的域差距可能使mIoU下降高达11.4%。


<details>
  <summary>Details</summary>
Motivation: 现有基础设施检测与维护中缺乏针对桥梁3D语义分割的专用数据集，且传感器差异带来的域差距影响模型泛化能力，亟需系统性研究以提升自动化监测水平。

Method: 构建涵盖多国多样桥梁结构的高分辨率3D扫描数据集，标注精细语义信息；采用三种主流3D深度学习模型进行性能评估，并利用多源传感器数据量化域差距。

Result: 所有模型在新数据集上均表现出较强鲁棒性，但传感器差异导致的域差距可使模型性能下降最高达11.4% mIoU。

Conclusion: 所提出的数据集有效支持桥梁3D语义分割任务，揭示了传感器差异对模型性能的重要影响，为未来跨域迁移学习与智能巡检系统设计提供了关键基准。

Abstract: We propose a novel dataset that has been specifically designed for 3D semantic segmentation of bridges and the domain gap analysis caused by varying sensors. This addresses a critical need in the field of infrastructure inspection and maintenance, which is essential for modern society. The dataset comprises high-resolution 3D scans of a diverse range of bridge structures from various countries, with detailed semantic labels provided for each. Our initial objective is to facilitate accurate and automated segmentation of bridge components, thereby advancing the structural health monitoring practice. To evaluate the effectiveness of existing 3D deep learning models on this novel dataset, we conduct a comprehensive analysis of three distinct state-of-the-art architectures. Furthermore, we present data acquired through diverse sensors to quantify the domain gap resulting from sensor variations. Our findings indicate that all architectures demonstrate robust performance on the specified task. However, the domain gap can potentially lead to a decline in the performance of up to 11.4% mIoU.

</details>


### [35] [See It Before You Grab It: Deep Learning-based Action Anticipation in Basketball](https://arxiv.org/abs/2512.15386)
*Arnau Barrera Roy,Albert Clapés Sintes*

Main category: cs.CV

TL;DR: 本文提出在篮球广播视频中进行动作预测的任务，重点是预测投篮后哪个队伍将获得球权。为此构建了一个包含10万段视频片段、超过300小时的视频和2000多个手动标注的篮板事件的新自建数据集。通过使用先进的动作预测方法进行基准测试，首次将深度学习技术应用于篮球篮板预测。同时探索了篮板分类和定位两个互补任务，证明该数据集支持广泛的篮球视频理解应用。实验结果表明，提前预测篮板虽具可行性但也面临挑战，为动态多智能体体育场景中的预测建模提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机视觉和视频理解在体育分析中取得了显著进展，但在动作发生前进行预测的研究相对较少。本文旨在填补这一空白，特别是在篮球比赛中预测投篮后的球权归属，以支持实时自动转播和赛后分析等应用。

Method: 提出了一项新的动作预测任务——在篮球广播视频中预测投篮后哪一队将获得篮板球。构建了一个大规模自建数据集，包含10万段视频、超过300小时的录像和2000多个手动标注的篮板事件。采用当前最先进的动作预测模型作为基线，并进一步研究篮板分类与定位任务，验证数据集的多功能性。

Result: 实验表明，利用深度学习方法可在篮球视频中实现对篮板归属的初步预测，具备一定可行性；但受复杂运动行为影响，仍存在显著挑战。该数据集可支持多种视频理解任务，为未来研究提供坚实基础。

Conclusion: 本文首次系统地研究了篮球比赛中篮板归属的动作预测问题，提出了一个高质量、大规模的数据集和评估框架，展示了深度学习在预测动态多智能体体育行为中的潜力，也为实时体育分析工具的发展奠定了基础。

Abstract: Computer vision and video understanding have transformed sports analytics by enabling large-scale, automated analysis of game dynamics from broadcast footage. Despite significant advances in player and ball tracking, pose estimation, action localization, and automatic foul recognition, anticipating actions before they occur in sports videos has received comparatively little attention. This work introduces the task of action anticipation in basketball broadcast videos, focusing on predicting which team will gain possession of the ball following a shot attempt. To benchmark this task, a new self-curated dataset comprising 100,000 basketball video clips, over 300 hours of footage, and more than 2,000 manually annotated rebound events is presented. Comprehensive baseline results are reported using state-of-the-art action anticipation methods, representing the first application of deep learning techniques to basketball rebound prediction. Additionally, two complementary tasks, rebound classification and rebound spotting, are explored, demonstrating that this dataset supports a wide range of video understanding applications in basketball, for which no comparable datasets currently exist. Experimental results highlight both the feasibility and inherent challenges of anticipating rebounds, providing valuable insights into predictive modeling for dynamic multi-agent sports scenarios. By forecasting team possession before rebounds occur, this work enables applications in real-time automated broadcasting and post-game analysis tools to support decision-making.

</details>


### [36] [Photorealistic Phantom Roads in Real Scenes: Disentangling 3D Hallucinations from Physical Geometry](https://arxiv.org/abs/2512.15423)
*Hoang Nguyen,Xiaohao Xu,Xiaonan Huang*

Main category: cs.CV

TL;DR: 本文提出首个端到端框架，用于探测、量化和缓解单目深度基础模型在感知模糊输入下产生的3D幻觉（称为3D Mirage）问题。通过构建首个真实世界幻觉基准3D-Mirage，引入基于拉普拉斯的评估指标DCS与CCS，实现对非平面性与上下文不稳定性量化，并提出参数高效且可避免灾难性遗忘的Grounded Self-Distillation方法以强制恢复平面性。


<details>
  <summary>Details</summary>
Motivation: 单目深度基础模型因依赖大规模语义先验而具备强泛化能力，但易在几何平面但感知模糊的输入上产生虚假3D结构，形成3D Mirage现象，该安全风险尚未被量化与有效应对。

Method: 提出3D-Mirage基准，包含真实世界幻觉图像及精确平面区域标注；设计基于拉普拉斯的评估框架，引入DCS与CCS两个指标；提出Grounded Self-Distillation方法，利用冻结教师模型保持背景知识的同时，对幻觉区域进行平面性约束。

Result: 所提方法能有效探测并量化3D Mirage现象，显著降低虚假3D结构生成率，在保留背景知识前提下实现对幻觉区域的精准修正，验证了方法在结构与上下文鲁棒性上的优越性。

Conclusion: 本研究为单目深度估计中的结构性与上下文鲁棒性评估提供了必要工具，推动评价范式从像素级精度向结构可靠性转变，呼吁重视深度模型的安全性与真实性。代码与基准将公开，促进该方向发展。

Abstract: Monocular depth foundation models achieve remarkable generalization by learning large-scale semantic priors, but this creates a critical vulnerability: they hallucinate illusory 3D structures from geometrically planar but perceptually ambiguous inputs. We term this failure the 3D Mirage. This paper introduces the first end-to-end framework to probe, quantify, and tame this unquantified safety risk. To probe, we present 3D-Mirage, the first benchmark of real-world illusions (e.g., street art) with precise planar-region annotations and context-restricted crops. To quantify, we propose a Laplacian-based evaluation framework with two metrics: the Deviation Composite Score (DCS) for spurious non-planarity and the Confusion Composite Score (CCS) for contextual instability. To tame this failure, we introduce Grounded Self-Distillation, a parameter-efficient strategy that surgically enforces planarity on illusion ROIs while using a frozen teacher to preserve background knowledge, thus avoiding catastrophic forgetting. Our work provides the essential tools to diagnose and mitigate this phenomenon, urging a necessary shift in MDE evaluation from pixel-wise accuracy to structural and contextual robustness. Our code and benchmark will be publicly available to foster this exciting research direction.

</details>


### [37] [Evaluation of deep learning architectures for wildlife object detection: A comparative study of ResNet and Inception](https://arxiv.org/abs/2512.15480)
*Malach Obisa Amonga,Benard Osero,Edna Too*

Main category: cs.CV

TL;DR: 本研究评估了ResNet-101和Inception v3两种深度学习模型在复杂环境下的野生动物目标检测性能。两者在标准化预处理和70:30训练验证分割下表现良好，分别达到94%与95%的分类准确率及0.91与0.92的mAP。Inception v3因多尺度特征提取略优。但两者在视觉相似物种、弱光或遮挡条件下仍存在挑战。结果表明，二者均适用于野生动物检测，为保护性计算机视觉应用提供可靠基础。


<details>
  <summary>Details</summary>
Motivation: 野生动物目标检测对生物多样性保护、生态监测和栖息地保护至关重要，但受环境变化、物种间视觉相似性及类内差异影响，面临显著挑战。需有效模型应对这些复杂条件。

Method: 采用标准化图像预处理（最大尺寸800像素、转为RGB、转换为PyTorch张量），使用70:30比例划分训练与验证集，对ResNet-101和Inception v3进行训练与评估。

Result: ResNet-101分类准确率94%，mAP 0.91；Inception v3表现更优，分类准确率95%，mAP 0.92，归因于其并行卷积实现的高效多尺度特征提取。

Conclusion: ResNet-101与Inception v3在野生动物目标检测任务中表现优异，具备较强的特征提取能力，虽在视觉相似或低质量图像中仍有局限，但整体可作为生态保护领域计算机视觉应用的可靠基础。

Abstract: Wildlife object detection plays a vital role in biodiversity conservation, ecological monitoring, and habitat protection. However, this task is often challenged by environmental variability, visual similarities among species, and intra-class diversity. This study investigates the effectiveness of two individual deep learning architectures ResNet-101 and Inception v3 for wildlife object detection under such complex conditions. The models were trained and evaluated on a wildlife image dataset using a standardized preprocessing approach, which included resizing images to a maximum dimension of 800 pixels, converting them to RGB format, and transforming them into PyTorch tensors. A ratio of 70:30 training and validation split was used for model development. The ResNet-101 model achieved a classification accuracy of 94% and a mean Average Precision (mAP) of 0.91, showing strong performance in extracting deep hierarchical features. The Inception v3 model performed slightly better, attaining a classification accuracy of 95% and a mAP of 0.92, attributed to its efficient multi-scale feature extraction through parallel convolutions. Despite the strong results, both models exhibited challenges when detecting species with similar visual characteristics or those captured under poor lighting and occlusion. Nonetheless, the findings confirm that both ResNet-101 and Inception v3 are effective models for wildlife object detection tasks and provide a reliable foundation for conservation-focused computer vision applications.

</details>


### [38] [RUMPL: Ray-Based Transformers for Universal Multi-View 2D to 3D Human Pose Lifting](https://arxiv.org/abs/2512.15488)
*Seyed Abolfazl Ghasemzadeh,Alexandre Alahi,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: RUMPL是一种基于Transformer的3D姿态提升框架，利用3D射线表示2D关键点，实现无需相机标定和视图数量依赖的通用多视角部署。通过引入视图融合Transformer增强射线方向的信息聚合，显著提升多视角一致性。在多个基准测试中，相比传统三角化方法降低53%的MPJPE，相比基于图像表示的Transformer基线降低60%以上。该框架在真实世界多视角和多人数据集上表现鲁棒且可扩展，源代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模多视角3D标注数据，难以泛化到真实场景；而合成数据训练的2D-to-3D提升方法受限于对相机参数和视图数量的依赖，缺乏通用性。因此需要一种不依赖相机标定、适应任意多视角配置的3D姿态估计方法。

Method: 提出RUMPL框架，采用3D射线表示2D关键点，使模型对相机参数和视图数量无关；设计视图融合Transformer，通过学习的融合射线令牌沿射线方向聚合多视角信息，提升一致性与精度。

Result: 在多个基准测试中，相比三角化方法减少53%的MPJPE，相比基于图像表示的Transformer基线减少60%以上；在真实世界多视角和多人数据集上表现优异，具备强鲁棒性与可扩展性。

Conclusion: RUMPL通过3D射线表示与视图融合Transformer，实现了无需重训练或微调的通用多视角3D姿态估计，显著优于现有方法，适用于广泛真实场景。

Abstract: Estimating 3D human poses from 2D images remains challenging due to occlusions and projective ambiguity. Multi-view learning-based approaches mitigate these issues but often fail to generalize to real-world scenarios, as large-scale multi-view datasets with 3D ground truth are scarce and captured under constrained conditions. To overcome this limitation, recent methods rely on 2D pose estimation combined with 2D-to-3D pose lifting trained on synthetic data. Building on our previous MPL framework, we propose RUMPL, a transformer-based 3D pose lifter that introduces a 3D ray-based representation of 2D keypoints. This formulation makes the model independent of camera calibration and the number of views, enabling universal deployment across arbitrary multi-view configurations without retraining or fine-tuning. A new View Fusion Transformer leverages learned fused-ray tokens to aggregate information along rays, further improving multi-view consistency. Extensive experiments demonstrate that RUMPL reduces MPJPE by up to 53% compared to triangulation and over 60% compared to transformer-based image-representation baselines. Results on new benchmarks, including in-the-wild multi-view and multi-person datasets, confirm its robustness and scalability. The framework's source code is available at https://github.com/aghasemzadeh/OpenRUMPL

</details>


### [39] [The LUMirage: An independent evaluation of zero-shot performance in the LUMIR challenge](https://arxiv.org/abs/2512.15505)
*Rohit Jena,Pratik Chaudhari,James C. Gee*

Main category: cs.CV

TL;DR: 本文对LUMIR挑战中深度学习方法在神经影像变形图像配准中的零样本泛化能力进行了独立再评估，发现其在分布内数据上表现良好，但在跨对比度（如T2、T2*、FLAIR）和高分辨率数据上性能显著下降，且对预处理敏感，表明其零样本优势被夸大，强调应采用更贴近临床实际的评估协议。


<details>
  <summary>Details</summary>
Motivation: 质疑LUMIR挑战中声称的深度学习方法具有普遍零样本泛化能力，因该说法与深度学习领域中关于域偏移的已有认识相矛盾，需通过严谨评估验证其真实性。

Method: 采用严格的评估协议，系统测试深度学习方法在不同数据分布（包括不同成像对比度、分辨率及物种）下的表现，同时控制预处理变量，对比迭代优化方法，识别潜在的仪器偏差来源。

Result: 深度学习方法在同分布的T1w图像和灵长类动物数据上表现良好，但在异分布对比度（如T2、T2*、FLAIR）下性能明显下降（Cohen's d 0.7–1.5），在0.6 mm高分辨率图像上无法运行，且对预处理高度敏感。

Conclusion: 深度学习方法并未展现出宣称的通用零样本优势，其性能受限于域偏移和数据尺度，应建立更符合实际科研与临床流程的评估标准，避免对特定方法类别的非公平偏好。

Abstract: The LUMIR challenge represents an important benchmark for evaluating deformable image registration methods on large-scale neuroimaging data. While the challenge demonstrates that modern deep learning methods achieve competitive accuracy on T1-weighted MRI, it also claims exceptional zero-shot generalization to unseen contrasts and resolutions, assertions that contradict established understanding of domain shift in deep learning. In this paper, we perform an independent re-evaluation of these zero-shot claims using rigorous evaluation protocols while addressing potential sources of instrumentation bias. Our findings reveal a more nuanced picture: (1) deep learning methods perform comparably to iterative optimization on in-distribution T1w images and even on human-adjacent species (macaque), demonstrating improved task understanding; (2) however, performance degrades significantly on out-of-distribution contrasts (T2, T2*, FLAIR), with Cohen's d scores ranging from 0.7-1.5, indicating substantial practical impact on downstream clinical workflows; (3) deep learning methods face scalability limitations on high-resolution data, failing to run on 0.6 mm isotropic images, while iterative methods benefit from increased resolution; and (4) deep methods exhibit high sensitivity to preprocessing choices. These results align with the well-established literature on domain shift and suggest that claims of universal zero-shot superiority require careful scrutiny. We advocate for evaluation protocols that reflect practical clinical and research workflows rather than conditions that may inadvertently favor particular method classes.

</details>


### [40] [VAAS: Vision-Attention Anomaly Scoring for Image Manipulation Detection in Digital Forensics](https://arxiv.org/abs/2512.15512)
*Opeyemi Bamigbade,Mark Scanlon,John Sheppard*

Main category: cs.CV

TL;DR: 本文提出一种名为视觉注意力异常评分（VAAS）的新框架，结合视觉变换器（ViT）的全局注意力机制与SegFormer嵌入的局部自一致性评分，实现对图像伪造的连续、可解释的异常评分。该方法在DF2023和CASIA v2.0数据集上表现优异，兼具高检测性能与可视化解释性，支持透明可靠的图像真实性评估。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造检测方法依赖像素或压缩伪影，难以应对现代生成模型产生的高度逼真伪造图像；同时缺乏对异常强度的量化能力，限制了其在司法取证中的应用。

Method: VAAS采用双模块设计：第一模块利用Vision Transformer（ViT）进行全局注意力分析，识别潜在异常区域；第二模块基于SegFormer提取的特征计算局部patch级自一致性得分，融合两者形成连续且可解释的异常评分。

Result: 在DF2023和CASIA v2.0数据集上，VAAS在F1和IoU指标上达到竞争力水平，并生成清晰的注意力引导异常图，显著提升检测结果的可解释性。

Conclusion: VAAS成功实现了从检测到可解释推理的跨越，为数字图像取证提供了更透明、可靠且可复现的解决方案，具备实际应用潜力。

Abstract: Recent advances in AI-driven image generation have introduced new challenges for verifying the authenticity of digital evidence in forensic investigations. Modern generative models can produce visually consistent forgeries that evade traditional detectors based on pixel or compression artefacts. Most existing approaches also lack an explicit measure of anomaly intensity, which limits their ability to quantify the severity of manipulation. This paper introduces Vision-Attention Anomaly Scoring (VAAS), a novel dual-module framework that integrates global attention-based anomaly estimation using Vision Transformers (ViT) with patch-level self-consistency scoring derived from SegFormer embeddings. The hybrid formulation provides a continuous and interpretable anomaly score that reflects both the location and degree of manipulation. Evaluations on the DF2023 and CASIA v2.0 datasets demonstrate that VAAS achieves competitive F1 and IoU performance, while enhancing visual explainability through attention-guided anomaly maps. The framework bridges quantitative detection with human-understandable reasoning, supporting transparent and reliable image integrity assessment. The source code for all experiments and corresponding materials for reproducing the results are available open source.

</details>


### [41] [DeX-Portrait: Disentangled and Expressive Portrait Animation via Explicit and Latent Motion Representations](https://arxiv.org/abs/2512.15524)
*Yuxiang Shi,Zhe Li,Yanwen Wang,Hao Zhu,Xun Cao,Ligang Liu*

Main category: cs.CV

TL;DR: 提出DeX-Portrait，一种基于扩散模型的肖像动画生成方法，实现头位姿与面部表情的高保真解耦控制，通过显式全局变换表示姿态、隐式潜在码表示表情，并采用双分支条件机制和交叉注意力注入驱动信号，结合渐进式混合无分类器引导以保持身份一致性，实验表明在动画质量和解耦可控性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的肖像动画方法无法实现头位姿与面部表情的高保真解耦控制，限制了仅修改表情或仅修改姿态等应用的可行性。

Method: 设计运动训练器学习姿态与表情编码器以提取精确分解的驱动信号；通过双分支条件机制将姿态变换注入扩散模型，通过交叉注意力注入表情潜在码；采用渐进式混合无分类器引导以增强身份一致性。

Result: 实验结果表明，该方法在动画质量与解耦可控性方面均优于当前最先进的基线方法。

Conclusion: DeX-Portrait实现了对肖像动画中头位姿与面部表情的高保真解耦控制，为表达或姿态独立编辑提供了有效解决方案，具有良好的应用前景。

Abstract: Portrait animation from a single source image and a driving video is a long-standing problem. Recent approaches tend to adopt diffusion-based image/video generation models for realistic and expressive animation. However, none of these diffusion models realizes high-fidelity disentangled control between the head pose and facial expression, hindering applications like expression-only or pose-only editing and animation. To address this, we propose DeX-Portrait, a novel approach capable of generating expressive portrait animation driven by disentangled pose and expression signals. Specifically, we represent the pose as an explicit global transformation and the expression as an implicit latent code. First, we design a powerful motion trainer to learn both pose and expression encoders for extracting precise and decomposed driving signals. Then we propose to inject the pose transformation into the diffusion model through a dual-branch conditioning mechanism, and the expression latent through cross attention. Finally, we design a progressive hybrid classifier-free guidance for more faithful identity consistency. Experiments show that our method outperforms state-of-the-art baselines on both animation quality and disentangled controllability.

</details>


### [42] [EmoCaliber: Advancing Reliable Visual Emotion Comprehension via Confidence Verbalization and Calibration](https://arxiv.org/abs/2512.15528)
*Daiqing Wu,Dongbao Yang,Can Ma. Yu Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉情绪理解（VEC）方法EmoCaliber，通过让多模态大语言模型（MLLMs）能够表达其情绪预测的置信度，以应对传统方法忽视情绪感知主观性的问题。该方法采用三阶段训练框架，逐步引入结构化推理、置信度表述和置信度校准能力，显著提升了情绪预测与置信度估计的可靠性。在统一基准VECBench上的实验表明，EmoCaliber优于现有方法，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的视觉情绪理解方法通常将任务视为确定性问题，仅输出单一情绪标签，忽略了情绪感知的主观性和多种合理解释的可能性。这种忽略导致系统缺乏对预测不确定性的表达能力，影响实际应用中的可信度。因此，需要让模型不仅能给出情绪判断，还能提供对其判断的信心水平，从而增强系统的可解释性和可靠性。

Method: 提出一个三阶段训练框架：第一阶段引入结构化推理机制，使模型能分析图像中的情感线索；第二阶段训练模型用自然语言描述其对预测结果的置信程度；第三阶段进行置信度校准，确保模型的自评信心与真实准确性一致。最终构建出名为EmoCaliber的自信感知型MLLM。

Result: 在统一基准VECBench上，EmoCaliber在情绪分类准确率和置信度估计方面均优于现有方法，证明了其在提升情绪理解系统可靠性方面的有效性。同时，模型生成的置信度描述有助于用户理解预测的合理性及潜在替代解释。

Conclusion: 通过赋予MLLM表达置信度的能力，EmoCaliber实现了更贴近人类认知过程的视觉情绪理解，为构建更具可解释性与可信度的AI情绪分析系统提供了可行路径。

Abstract: Visual Emotion Comprehension (VEC) aims to infer sentiment polarities or emotion categories from affective cues embedded in images. In recent years, Multimodal Large Language Models (MLLMs) have established a popular paradigm in VEC, leveraging their generalizability to unify VEC tasks defined under diverse emotion taxonomies. While this paradigm achieves notable success, it typically formulates VEC as a deterministic task, requiring the model to output a single, definitive emotion label for each image. Such a formulation insufficiently accounts for the inherent subjectivity of emotion perception, overlooking alternative interpretations that may be equally plausible to different viewers. To address this limitation, we propose equipping MLLMs with capabilities to verbalize their confidence in emotion predictions. This additional signal provides users with an estimate of both the plausibility of alternative interpretations and the MLLMs' self-assessed competence, thereby enhancing reliability in practice. Building on this insight, we introduce a three-stage training framework that progressively endows with structured reasoning, teaches to verbalize confidence, and calibrates confidence expression, culminating in EmoCaliber, a confidence-aware MLLM for VEC. Through fair and comprehensive evaluations on the unified benchmark VECBench, EmoCaliber demonstrates overall superiority against existing methods in both emotion prediction and confidence estimation. These results validate the effectiveness of our approach and mark a feasible step toward more reliable VEC systems. Project page: https://github.com/wdqqdw/EmoCaliber.

</details>


### [43] [An Efficient and Effective Encoder Model for Vision and Language Tasks in the Remote Sensing Domain](https://arxiv.org/abs/2512.15531)
*João Daniel Silva,Joao Magalhaes,Devis Tuia,Bruno Martins*

Main category: cs.CV

TL;DR: 本文提出了一种名为GeoMELT的轻量级多任务学习框架，利用编码器-only架构，在保持参数量少的同时，有效处理遥感图像文本生成与跨模态检索等复杂任务。实验表明该模型在多个基准测试中表现出高效且性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有基于大视觉-语言模型（LVLMs）的方法虽能处理多种遥感任务，但因参数量庞大导致训练和推理成本过高，限制了其广泛应用。因此，亟需一种参数高效、计算成本低的模型来实现多任务学习。

Method: 采用编码器-only架构设计轻量化模型GeoMELT，通过参数高效适配技术，统一建模遥感图像到文本的生成与跨模态检索任务，实现紧凑高效的多任务学习。

Result: GeoMELT在多个标准遥感基准数据集上表现优异，验证了其在任务泛化性、参数效率和计算成本控制方面的有效性。

Conclusion: GeoMELT成功实现了在低资源消耗下对多遥感任务的高效统一建模，为大规模遥感智能分析提供了可行且高效的解决方案。

Abstract: The remote sensing community has recently seen the emergence of methods based on Large Vision and Language Models (LVLMs) that can address multiple tasks at the intersection of computer vision and natural language processing. To fully exploit the potential of such models, a significant focus has been given to the collection of large amounts of training data that cover multiple remote sensing-specific tasks, such as image captioning or visual question answering. However, the cost of using and training LVLMs is high, due to the large number of parameters. While multiple parameter-efficient adaptation techniques have been explored, the computational costs of training and inference with these models can remain prohibitive for most institutions. In this work, we explore the use of encoder-only architectures and propose a model that can effectively address multi-task learning while remaining compact in terms of the number of parameters. In particular, our model tackles combinations of tasks that are not typically explored in a unified model: the generation of text from remote sensing images and cross-modal retrieval. The results of our GeoMELT model - named from Multi-task Efficient Learning Transformer - in established benchmarks confirm the efficacy and efficiency of the proposed approach.

</details>


### [44] [BLANKET: Anonymizing Faces in Infant Video Recordings](https://arxiv.org/abs/2512.15542)
*Ditmar Hadera,Jan Cech,Miroslav Purkrabek,Matej Hoffmann*

Main category: cs.CV

TL;DR: BLANKET是一种用于婴儿视频中面部匿名化的新型方法，通过扩散模型生成新面孔并实现时序一致的面部替换与表情传递，有效保护身份同时保留关键面部特征。相比DeepPrivacy2，其在去标识化、属性保留、下游任务性能及伪影控制方面均表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有婴儿视频数据匿名化方法难以在保护隐私的同时保持面部关键特征，尤其在涉及表情和动作分析等下游任务时存在性能下降问题，因此需要一种既能有效去标识又能保留重要视觉信息的方法。

Method: BLANKET包含两个阶段：1）利用扩散模型进行图像修复生成与原身份兼容的新面孔；2）通过时序一致的面部替换与真实表情迁移，将新面孔无缝融入每一帧视频中。

Result: 在婴儿视频数据集上的评估显示，尽管两种方法均成功改变身份，但BLANKET在去标识程度、面部属性保留、人体姿态估计准确性以及视觉伪影控制方面全面优于DeepPrivacy2。

Conclusion: BLANKET提供了一种高效且可靠的婴儿面部匿名化方案，在保障隐私的同时显著提升了面部特征的保真度和下游任务适用性，具备实际应用潜力。

Abstract: Ensuring the ethical use of video data involving human subjects, particularly infants, requires robust anonymization methods. We propose BLANKET (Baby-face Landmark-preserving ANonymization with Keypoint dEtection consisTency), a novel approach designed to anonymize infant faces in video recordings while preserving essential facial attributes. Our method comprises two stages. First, a new random face, compatible with the original identity, is generated via inpainting using a diffusion model. Second, the new identity is seamlessly incorporated into each video frame through temporally consistent face swapping with authentic expression transfer. The method is evaluated on a dataset of short video recordings of babies and is compared to the popular anonymization method, DeepPrivacy2. Key metrics assessed include the level of de-identification, preservation of facial attributes, impact on human pose estimation (as an example of a downstream task), and presence of artifacts. Both methods alter the identity, and our method outperforms DeepPrivacy2 in all other respects. The code is available as an easy-to-use anonymization demo at https://github.com/ctu-vras/blanket-infant-face-anonym.

</details>


### [45] [GRAN-TED: Generating Robust, Aligned, and Nuanced Text Embedding for Diffusion Models](https://arxiv.org/abs/2512.15560)
*Bozhou Li,Sihan Yang,Yushuo Guan,Ruichuan An,Xinlong Chen,Yang Shi,Pengfei Wan,Wentao Zhang,Yuanxing zhang*

Main category: cs.CV

TL;DR: 提出GRAN-TED框架，通过TED-6K基准和两阶段训练提升文本编码器在文生图/视频任务中的表现，显著增强语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有文本编码器在文生图/视频扩散模型中受限于缺乏高效的评估框架和预训练语言模型难以适配视觉合成的问题。

Method: 设计TED-6K文本基准以无成本评估编码器质量，并采用两阶段训练：先在多模态大模型上微调以获得更好视觉表征，再通过逐层加权提取更精细的文本特征。

Result: GRAN-TED编码器在TED-6K上达到顶尖性能，并在文生图/视频生成任务中实现显著提升，验证了其有效性与鲁棒性。

Conclusion: GRAN-TED提供了一种高效、可扩展的文本编码器构建范式，为高质量视觉生成提供了坚实基础。

Abstract: The text encoder is a critical component of text-to-image and text-to-video diffusion models, fundamentally determining the semantic fidelity of the generated content. However, its development has been hindered by two major challenges: the lack of an efficient evaluation framework that reliably predicts downstream generation performance, and the difficulty of effectively adapting pretrained language models for visual synthesis. To address these issues, we introduce GRAN-TED, a paradigm to Generate Robust, Aligned, and Nuanced Text Embeddings for Diffusion models. Our contribution is twofold. First, we propose TED-6K, a novel text-only benchmark that enables efficient and robust assessment of an encoder's representational quality without requiring costly end-to-end model training. We demonstrate that performance on TED-6K, standardized via a lightweight, unified adapter, strongly correlates with an encoder's effectiveness in downstream generation tasks. Second, guided by this validated framework, we develop a superior text encoder using a novel two-stage training paradigm. This process involves an initial fine-tuning stage on a Multimodal Large Language Model for better visual representation, followed by a layer-wise weighting method to extract more nuanced and potent text features. Our experiments show that the resulting GRAN-TED encoder not only achieves state-of-the-art performance on TED-6K but also leads to demonstrable performance gains in text-to-image and text-to-video generation. Our code is available at the following link: https://anonymous.4open.science/r/GRAN-TED-4FCC/.

</details>


### [46] [On the Effectiveness of Textual Prompting with Lightweight Fine-Tuning for SAM3 Remote Sensing Segmentation](https://arxiv.org/abs/2512.15564)
*Roni Blushtein-Livnon,Osher Rafaeli,David Ioffe,Amir Boger,Karen Sandberg Esquenazi,Tal Svoray*

Main category: cs.CV

TL;DR: 该研究探讨了在有限标注数据下，利用SAM3框架对遥感图像进行分割的适应性。通过对比文本、几何及混合提示策略，在不同微调规模和零样本推理条件下评估性能。结果显示，结合语义与几何线索的混合提示表现最佳；纯文本提示效果最差，尤其在不规则目标上存在显著差距，反映文本表示与航拍图像之间语义对齐不足。轻量级微调可实现良好性能-努力权衡，尤其适用于几何规则且视觉显著的目标。随着标注量增加，性能提升呈递减趋势，表明少量几何标注即可有效适应。精度与交并比之间的持续差距说明，欠分割和边界不准确仍是遥感任务中的主要错误模式，尤其针对不规则和少见目标。


<details>
  <summary>Details</summary>
Motivation: 遥感图像分割受限于标注数据稀缺以及航拍图像与自然图像在训练基础模型时存在的差异，亟需在有限监督下实现有效适应。

Method: 采用SAM3概念驱动框架，通过文本、几何及混合提示策略，在不同微调规模（从零样本到轻量级微调）下评估其在遥感图像上的表现。

Result: 混合提示（语义+几何）在所有目标类型和指标上表现最优；纯文本提示在不规则目标上表现差，存在显著得分差距；轻量级微调带来显著性能提升，但随标注量增加收益递减；精度与IoU间存在持续差距，反映出欠分割和边界误差仍普遍存在，尤其在不规则或罕见目标上。

Conclusion: 结合语义与几何提示可最大化遥感图像分割性能；少量几何标注即足以实现有效适应；当前方法仍面临边界精度和欠分割挑战，需进一步改进。

Abstract: Remote sensing (RS) image segmentation is constrained by the limited availability of annotated data and a gap between overhead imagery and natural images used to train foundational models. This motivates effective adaptation under limited supervision. SAM3 concept-driven framework generates masks from textual prompts without requiring task-specific modifications, which may enable this adaptation. We evaluate SAM3 for RS imagery across four target types, comparing textual, geometric, and hybrid prompting strategies, under lightweight fine-tuning scales with increasing supervision, alongside zero-shot inference. Results show that combining semantic and geometric cues yields the highest performance across targets and metrics. Text-only prompting exhibits the lowest performance, with marked score gaps for irregularly shaped targets, reflecting limited semantic alignment between SAM3 textual representations and their overhead appearances. Nevertheless, textual prompting with light fine-tuning offers a practical performance-effort trade-off for geometrically regular and visually salient targets. Across targets, performance improves between zero-shot inference and fine-tuning, followed by diminishing returns as the supervision scale increases. Namely, a modest geometric annotation effort is sufficient for effective adaptation. A persistent gap between Precision and IoU further indicates that under-segmentation and boundary inaccuracies remain prevalent error patterns in RS tasks, particularly for irregular and less prevalent targets.

</details>


### [47] [MoonSeg3R: Monocular Online Zero-Shot Segment Anything in 3D with Reconstructive Foundation Priors](https://arxiv.org/abs/2512.15577)
*Zhipeng Du,Duolikun Danier,Jan Eric Lenssen,Hakan Bilen*

Main category: cs.CV

TL;DR: MoonSeg3R是首个实现在线单目3D实例分割的方法，利用CUT3R基础模型从单个RGB流中提供可靠的几何先验，通过自监督查询优化、3D查询索引记忆和状态分布标记增强跨帧融合，在ScanNet200和SceneNN上达到与基于RGB-D的先进系统相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖带姿态的RGB-D序列，在无深度信息的单目在线设置下表现不佳，亟需一种无需深度输入即可实现鲁棒3D实例分割的新方法。

Method: 提出MoonSeg3R，包含三个核心组件：1）基于空间-语义蒸馏的自监督查询优化模块，将2D视觉基础模型的分割掩码转化为判别性3D查询；2）3D查询索引记忆，通过检索上下文查询实现时间一致性；3）来自CUT3R的状态分布标记，作为掩码身份描述符以强化跨帧融合。

Result: 在ScanNet200和SceneNN数据集上，MoonSeg3R首次实现了在线单目3D实例分割，性能媲美当前最先进的基于RGB-D的方法。

Conclusion: MoonSeg3R成功突破了传统方法对深度信息的依赖，为单目在线3D实例分割提供了可行解决方案，具备良好的实用前景，并将公开代码与模型。

Abstract: In this paper, we focus on online zero-shot monocular 3D instance segmentation, a novel practical setting where existing approaches fail to perform because they rely on posed RGB-D sequences. To overcome this limitation, we leverage CUT3R, a recent Reconstructive Foundation Model (RFM), to provide reliable geometric priors from a single RGB stream. We propose MoonSeg3R, which introduces three key components: (1) a self-supervised query refinement module with spatial-semantic distillation that transforms segmentation masks from 2D visual foundation models (VFMs) into discriminative 3D queries; (2) a 3D query index memory that provides temporal consistency by retrieving contextual queries; and (3) a state-distribution token from CUT3R that acts as a mask identity descriptor to strengthen cross-frame fusion. Experiments on ScanNet200 and SceneNN show that MoonSeg3R is the first method to enable online monocular 3D segmentation and achieves performance competitive with state-of-the-art RGB-D-based systems. Code and models will be released.

</details>


### [48] [IMKD: Intensity-Aware Multi-Level Knowledge Distillation for Camera-Radar Fusion](https://arxiv.org/abs/2512.15581)
*Shashank Mishra,Karan Patil,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: IMKD提出一种基于多级知识蒸馏的雷达-相机融合框架，通过强度感知策略在不同阶段增强雷达与相机特征，保留各传感器固有特性并强化互补性，显著提升3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法直接传递模态特异性特征，导致传感器独特性被破坏，削弱其优势。为解决此问题，需设计能保留各传感器特性并增强互补性的融合框架。

Method: IMKD采用三阶段强度感知知识蒸馏：(1) LiDAR到雷达的强度感知特征蒸馏，以细粒度结构线索增强雷达表示；(2) LiDAR到融合特征的强度引导蒸馏，选择性突出融合层级中的几何与深度信息，促进模态间互补而非强制对齐；(3) 相机-雷达的强度引导融合机制，实现有效特征对齐与校准。

Result: 在nuScenes基准上，IMKD达到67.0% NDS和61.0% mAP，优于所有先前基于蒸馏的雷达-相机融合方法。

Conclusion: IMKD通过多级强度感知蒸馏策略，在不依赖LiDAR推理的前提下，有效保留了雷达与相机的内在特性，并增强了它们的互补优势，显著提升了雷达-相机融合3D检测性能。

Abstract: High-performance Radar-Camera 3D object detection can be achieved by leveraging knowledge distillation without using LiDAR at inference time. However, existing distillation methods typically transfer modality-specific features directly to each sensor, which can distort their unique characteristics and degrade their individual strengths. To address this, we introduce IMKD, a radar-camera fusion framework based on multi-level knowledge distillation that preserves each sensor's intrinsic characteristics while amplifying their complementary strengths. IMKD applies a three-stage, intensity-aware distillation strategy to enrich the fused representation across the architecture: (1) LiDAR-to-Radar intensity-aware feature distillation to enhance radar representations with fine-grained structural cues, (2) LiDAR-to-Fused feature intensity-guided distillation to selectively highlight useful geometry and depth information at the fusion level, fostering complementarity between the modalities rather than forcing them to align, and (3) Camera-Radar intensity-guided fusion mechanism that facilitates effective feature alignment and calibration. Extensive experiments on the nuScenes benchmark show that IMKD reaches 67.0% NDS and 61.0% mAP, outperforming all prior distillation-based radar-camera fusion methods. Our code and models are available at https://github.com/dfki-av/IMKD/.

</details>


### [49] [FlexAvatar: Learning Complete 3D Head Avatars with Partial Supervision](https://arxiv.org/abs/2512.15599)
*Tobias Kirschstein,Simon Giebenhain,Matthias Nießner*

Main category: cs.CV

TL;DR: FlexAvatar 是一种从单张图像生成高质量、完整 3D 头部虚拟形象的方法，通过引入可学习的数据源标记（偏置汇点）的 Transformer 模型，统一训练单视角和多视角数据，在推理时结合单视角的泛化能力与多视角的完整性，实现逼真的面部动画和完整的 3D 重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在仅使用单视角图像时，由于缺乏多视角数据，容易导致 3D 头部重建不完整；而其根本原因在于单视角训练中驱动信号与目标视角之间的纠缠问题。

Method: 提出基于 Transformer 的 3D 人像动画模型，引入可学习的数据源令牌（即偏置汇点），使模型能统一处理单视角和多视角数据，从而在训练中融合两者优势，并在推理阶段灵活利用不同数据源的优点。

Result: 在单视角、少样本及单视角头像生成任务中表现优异，有效解决视图外推问题，生成完整且逼真的 3D 头部虚拟形象，同时支持身份插值与灵活拟合任意数量输入观测。

Conclusion: FlexAvatar 通过创新的训练机制与模型设计，实现了高质量、完整且高度灵活的 3D 头部虚拟形象生成，显著提升了单视角 3D 重建的质量与泛化能力。

Abstract: We introduce FlexAvatar, a method for creating high-quality and complete 3D head avatars from a single image. A core challenge lies in the limited availability of multi-view data and the tendency of monocular training to yield incomplete 3D head reconstructions. We identify the root cause of this issue as the entanglement between driving signal and target viewpoint when learning from monocular videos. To address this, we propose a transformer-based 3D portrait animation model with learnable data source tokens, so-called bias sinks, which enables unified training across monocular and multi-view datasets. This design leverages the strengths of both data sources during inference: strong generalization from monocular data and full 3D completeness from multi-view supervision. Furthermore, our training procedure yields a smooth latent avatar space that facilitates identity interpolation and flexible fitting to an arbitrary number of input observations. In extensive evaluations on single-view, few-shot, and monocular avatar creation tasks, we verify the efficacy of FlexAvatar. Many existing methods struggle with view extrapolation while FlexAvatar generates complete 3D head avatars with realistic facial animations. Website: https://tobias-kirschstein.github.io/flexavatar/

</details>


### [50] [Qwen-Image-Layered: Towards Inherent Editability via Layer Decomposition](https://arxiv.org/abs/2512.15603)
*Shengming Yin,Zekai Zhang,Zecheng Tang,Kaiyuan Gao,Xiao Xu,Kun Yan,Jiahao Li,Yilei Chen,Yuxiang Chen,Heung-Yeung Shum,Lionel M. Ni,Jingren Zhou,Junyang Lin,Chenfei Wu*

Main category: cs.CV

TL;DR: 提出Qwen-Image-Layered，一种端到端扩散模型，可将单张RGB图像分解为多个语义解耦的RGBA图层，实现内在可编辑性，支持变量长度分解，并通过三阶段训练策略与自建多图层数据集提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型在图像编辑中因光栅图像的纠缠特性而难以保持一致性；专业设计工具使用分层表示可实现独立编辑，因此提出基于分层结构的图像分解方法以解决一致性问题。

Method: 引入RGBA-VAE统一RGB与RGBA图像的潜在表示；采用可变层数分解的VLD-MMDiT架构；设计多阶段训练策略，将预训练图像生成模型转化为多层图像分解器；构建从PSD文件中提取并标注多图层图像的数据管道。

Result: 实验表明该方法在分解质量上显著优于现有方法，建立了图像一致编辑的新范式。

Conclusion: Qwen-Image-Layered实现了高保真、可独立编辑的多层图像分解，为后续图像编辑任务提供了强大基础，具有良好的应用前景。

Abstract: Recent visual generative models often struggle with consistency during image editing due to the entangled nature of raster images, where all visual content is fused into a single canvas. In contrast, professional design tools employ layered representations, allowing isolated edits while preserving consistency. Motivated by this, we propose \textbf{Qwen-Image-Layered}, an end-to-end diffusion model that decomposes a single RGB image into multiple semantically disentangled RGBA layers, enabling \textbf{inherent editability}, where each RGBA layer can be independently manipulated without affecting other content. To support variable-length decomposition, we introduce three key components: (1) an RGBA-VAE to unify the latent representations of RGB and RGBA images; (2) a VLD-MMDiT (Variable Layers Decomposition MMDiT) architecture capable of decomposing a variable number of image layers; and (3) a Multi-stage Training strategy to adapt a pretrained image generation model into a multilayer image decomposer. Furthermore, to address the scarcity of high-quality multilayer training images, we build a pipeline to extract and annotate multilayer images from Photoshop documents (PSD). Experiments demonstrate that our method significantly surpasses existing approaches in decomposition quality and establishes a new paradigm for consistent image editing. Our code and models are released on \href{https://github.com/QwenLM/Qwen-Image-Layered}{https://github.com/QwenLM/Qwen-Image-Layered}

</details>


### [51] [Robust Multi-view Camera Calibration from Dense Matches](https://arxiv.org/abs/2512.15608)
*Johannes Hägerlind,Bao-Long Tran,Urs Waldmann,Per-Erik Forssén*

Main category: cs.CV

TL;DR: 本文提出了一种鲁棒的位姿估计与标定方法，针对多相机系统在动物行为研究和监控视频法医分析中的应用。通过分析SfM流程中的关键组件，研究了对应点的子采样策略和视图增量添加的选择标准，并在定量评估中验证了其有效性，尤其在存在强径向畸变的情况下表现显著优于基线方法（79.9% vs. 40.4%）。


<details>
  <summary>Details</summary>
Motivation: 当前结构从运动（SfM）方法虽有进步，但在相机内参与外参估计方面仍面临挑战，尤其是在存在强烈径向畸变的多相机设置下。为提升精度与鲁棒性，需优化对应点处理与视图添加策略。

Method: 研究了密集匹配器生成的对应点子采样方式，以及视图增量添加的选择准则；结合VGGT初始化，在全局SfM框架中实现改进的位姿估计与相机标定。

Result: 在具有强径向畸变的场景中，所提方法显著优于基线（79.9% vs. 40.4%），且在多种相机配置下具有良好泛化能力。

Conclusion: 所提出的SfM流程改进方案有效提升了多相机系统下的位姿估计与标定精度，适用于动物行为分析与法医监控分析等实际应用场景。

Abstract: Estimating camera intrinsics and extrinsics is a fundamental problem in computer vision, and while advances in structure-from-motion (SfM) have improved accuracy and robustness, open challenges remain. In this paper, we introduce a robust method for pose estimation and calibration. We consider a set of rigid cameras, each observing the scene from a different perspective, which is a typical camera setup in animal behavior studies and forensic analysis of surveillance footage. Specifically, we analyse the individual components in a structure-from-motion (SfM) pipeline, and identify design choices that improve accuracy. Our main contributions are: (1) we investigate how to best subsample the predicted correspondences from a dense matcher to leverage them in the estimation process. (2) We investigate selection criteria for how to add the views incrementally. In a rigorous quantitative evaluation, we show the effectiveness of our changes, especially for cameras with strong radial distortion (79.9% ours vs. 40.4 vanilla VGGT). Finally, we demonstrate our correspondence subsampling in a global SfM setting where we initialize the poses using VGGT. The proposed pipeline generalizes across a wide range of camera setups, and could thus become a useful tool for animal behavior and forensic analysis.

</details>


### [52] [Persistent feature reconstruction of resident space objects (RSOs) within inverse synthetic aperture radar (ISAR) images](https://arxiv.org/abs/2512.15618)
*Morgan Coe,Gruffudd Jones,Leah-Nani Alconcel,Marina Gashinova*

Main category: cs.CV

TL;DR: 本文研究了基于亚太赫兹逆合成孔径雷达（ISAR）成像与传感系统在近地空间环境中对空间物体的识别方法。通过序列特征检测与跟踪，利用霍夫变换检测线性特征，并结合梯度比边缘检测和双权重霍夫变换提高检测精度。通过对多帧图像序列中特征演化分析，验证了该方法可显著提升特征检测与分类的置信度，展示了阴影特征鲁棒检测的应用实例。


<details>
  <summary>Details</summary>
Motivation: 随着近地空间中轨道物体数量迅速增长，需要更详细的条件与能力信息以实现空间态势感知（SDA）。传统观测受限于大气影响且视角有限，因此需发展更先进的空间基探测技术。亚太赫兹ISAR系统可提供高分辨率成像，支持对卫星外部结构的精细识别，为提升空间态势感知能力提供关键技术支持。

Method: 采用元启发式模拟器生成不同部署场景下的ISAR图像序列；通过仿射变换完成初始帧间配准；使用梯度比方法进行边缘检测，提取边缘幅值与方向；结合双权重霍夫变换检测线性特征；通过特征在序列中的演化分析实现跟踪与识别。

Result: 所提方法在多帧序列中实现了高精度的线性特征检测与跟踪，显著提升了特征识别的可靠性；成功演示了阴影等复杂特征的鲁棒检测，验证了其在空间物体结构识别中的有效性。

Conclusion: 基于亚太赫兹ISAR图像序列的特征检测与跟踪方法能够有效提升空间物体外部结构识别的准确性与可信度，为未来空间态势感知系统提供了有力的技术支撑。

Abstract: With the rapidly growing population of resident space objects (RSOs) in the near-Earth space environment, detailed information about their condition and capabilities is needed to provide Space Domain Awareness (SDA). Space-based sensing will enable inspection of RSOs at shorter ranges, independent of atmospheric effects, and from all aspects. The use of a sub-THz inverse synthetic aperture radar (ISAR) imaging and sensing system for SDA has been proposed in previous work, demonstrating the achievement of sub-cm image resolution at ranges of up to 100 km. This work focuses on recognition of external structures by use of sequential feature detection and tracking throughout the aligned ISAR images of the satellites. The Hough transform is employed to detect linear features, which are tracked throughout the sequence. ISAR imagery is generated via a metaheuristic simulator capable of modelling encounters for a variety of deployment scenarios. Initial frame-to-frame alignment is achieved through a series of affine transformations to facilitate later association between image features. A gradient-by-ratio method is used for edge detection within individual ISAR images, and edge magnitude and direction are subsequently used to inform a double-weighted Hough transform to detect features with high accuracy. Feature evolution during sequences of frames is analysed. It is shown that the use of feature tracking within sequences with the proposed approach will increase confidence in feature detection and classification, and an example use-case of robust detection of shadowing as a feature is presented.

</details>


### [53] [OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence](https://arxiv.org/abs/2512.15621)
*Yu Zheng,Jie Hu,Kailun Yang,Jiaming Zhang*

Main category: cs.CV

TL;DR: 本文提出4D Occupancy Spatio-Temporal Persistence（OccSTeP）概念，旨在实现自动驾驶中对3D场景的持续理解，涵盖反应式预测（未来将发生什么）和主动式预测（给定未来动作后会发生什么）。为此，作者构建了首个挑战性基准数据集OccSTeP，包含错误语义标签、帧丢失等复杂场景。提出无需分词器的世界模型OccSTeP-WM，采用密集体素化场景状态，通过线性复杂度注意力与递归状态空间模块融合时空上下文，并利用自车运动补偿持续更新场景记忆，支持在线推理且在历史输入缺失或噪声情况下仍表现鲁棒。实验表明，该方法在语义mIoU上提升6.56%（达23.70%），占据率IoU提升9.26%（达35.89%），代码与数据将开源。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要对三维场景具备持续、鲁棒的理解能力，以应对时间扰动并预判潜在未来行为。现有方法在处理动态变化、传感器异常或信息缺失时表现不足，尤其缺乏统一框架来同时支持反应式与主动式未来预测。因此，亟需一种能长期维持场景状态并融合时空信息的新范式。

Method: 提出OccSTeP-WM世界模型，采用无分词器设计，维护基于体素的密集场景状态；通过线性复杂度注意力捕捉长程空间依赖；结合递归状态空间模块实现持续场景记忆更新；引入自车运动补偿机制，增强对时间扰动的鲁棒性；支持增量式融合与在线推理。

Result: 在自建的OccSTeP基准上，模型在语义mIoU上达到23.70%（相比基线+6.56%），占据率IoU达到35.89%（+9.26%），显著优于现有方法。即使在存在错误语义标签、帧丢失等挑战性条件下，仍保持稳定性能，验证了其鲁棒性和实用性。

Conclusion: 本文首次提出4D Occupancy Spatio-Temporal Persistence（OccSTeP）概念，构建了首个针对未来预测任务的综合性基准，提出高效的OccSTeP-WM世界模型，在反应式与主动式预测任务中均取得显著性能提升。该工作为自动驾驶中的持续场景理解提供了新思路，具有重要理论价值与应用前景。

Abstract: Autonomous driving requires a persistent understanding of 3D scenes that is robust to temporal disturbances and accounts for potential future actions. We introduce a new concept of 4D Occupancy Spatio-Temporal Persistence (OccSTeP), which aims to address two tasks: (1) reactive forecasting: ''what will happen next'' and (2) proactive forecasting: "what would happen given a specific future action". For the first time, we create a new OccSTeP benchmark with challenging scenarios (e.g., erroneous semantic labels and dropped frames). To address this task, we propose OccSTeP-WM, a tokenizer-free world model that maintains a dense voxel-based scene state and incrementally fuses spatio-temporal context over time. OccSTeP-WM leverages a linear-complexity attention backbone and a recurrent state-space module to capture long-range spatial dependencies while continually updating the scene memory with ego-motion compensation. This design enables online inference and robust performance even when historical sensor input is missing or noisy. Extensive experiments prove the effectiveness of the OccSTeP concept and our OccSTeP-WM, yielding an average semantic mIoU of 23.70% (+6.56% gain) and occupancy IoU of 35.89% (+9.26% gain). The data and code will be open source at https://github.com/FaterYU/OccSTeP.

</details>


### [54] [Towards Physically-Based Sky-Modeling For Image Based Lighting](https://arxiv.org/abs/2512.15632)
*Ian J. Maquignaz*

Main category: cs.CV

TL;DR: 本文提出AllSky，一种从物理捕获的HDRI直接学习的灵活全天气天空模型，支持用户对太阳位置和云层分布的直观控制，实现最先进的天空建模性能。研究揭示现有DNN天空模型在真实感与全动态范围（FDR）22 f-stop支持方面存在不足，无法替代物理捕获的HDRI或参数化天空模型，限制了下游应用中的光照准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有DNN生成的HDR环境图虽视觉质量提升显著，但在再现自然天空的真实光照、阴影和色调方面仍不理想，尤其无法满足户外照明所需的22 f-stop全动态范围，导致其在实际应用中难以替代物理捕获的HDRI或传统参数化模型。

Method: 提出AllSky模型，基于真实物理捕获的HDRI数据进行训练，系统研究输入模态、色调映射、条件控制与评估方法，通过用户可控的太阳位置和云层配置实现高保真天空模拟。

Result: AllSky在光照真实感和动态范围覆盖上均优于现有方法，首次实现对22 f-stop FDR的完整支持；实验表明当前DNN天空模型不可互换使用，其局限性严重制约了下游应用的准确性与可扩展性。

Conclusion: 本工作揭示了当前天空建模研究在真实感与动态范围支持上的根本缺陷，提出并验证了基于物理捕获数据的全天气天空模型AllSky的有效性，为未来高保真渲染与真实光照重建提供了新范式。

Abstract: Accurate environment maps are a key component for rendering photorealistic outdoor scenes with coherent illumination. They enable captivating visual arts, immersive virtual reality, and a wide range of engineering and scientific applications. Recent works have extended sky-models to be more comprehensive and inclusive of cloud formations but, as we demonstrate, existing methods fall short in faithfully recreating natural skies. Though in recent years the visual quality of DNN-generated High Dynamic Range Imagery (HDRI) has greatly improved, the environment maps generated by DNN sky-models do not re-light scenes with the same tones, shadows, and illumination as physically captured HDR imagery. In this work, we demonstrate progress in HDR literature to be tangential to sky-modelling as current works cannot support both photorealism and the 22 f-stops required for the Full Dynamic Range (FDR) of outdoor illumination. We achieve this by proposing AllSky, a flexible all-weather sky-model learned directly from physically captured HDRI which we leverage to study the input modalities, tonemapping, conditioning, and evaluation of sky-models. Per user-controlled positioning of the sun and cloud formations, AllSky expands on current functionality by allowing for intuitive user control over environment maps and achieves state-of-the-art sky-model performance. Through our proposed evaluation, we demonstrate existing DNN sky-models are not interchangeable with physically captured HDRI or parametric sky-models, with current limitations being prohibitive of scalability and accurate illumination in downstream applications

</details>


### [55] [IC-Effect: Precise and Efficient Video Effects Editing via In-Context Learning](https://arxiv.org/abs/2512.15635)
*Yuanhang Li,Yiren Song,Junzhe Bai,Xinran Liang,Hu Yang,Libiao Jin,Qi Mao*

Main category: cs.CV

TL;DR: IC-Effect 是一种基于 DiT 的指令引导框架，用于少样本视频视觉特效（VFX）编辑，能够合成复杂效果（如火焰、粒子和卡通角色），同时严格保持时空一致性。该方法利用源视频作为干净的上下文条件，通过 DiT 模型的上下文学习能力实现精确的背景保留和自然特效注入。采用两阶段训练策略（通用编辑适配 + 特效特定的 Effect-LoRA 学习），确保强指令遵循和稳健的特效建模。引入时空稀疏标记化以提升效率，实现高保真度的同时显著降低计算量。还发布了包含 15 种高质量视觉风格的成对 VFX 编辑数据集。大量实验表明，IC-Effect 能够实现高质量、可控且时间一致的 VFX 编辑，为视频创作开辟新可能。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑模型难以同时满足特效与背景无缝融合、背景完全不变以及从有限成对数据中高效学习效果模式的要求，因此亟需一种能精确控制并保持时空一致性的少样本视频特效编辑方法。

Method: IC-Effect 采用基于 DiT 的框架，利用源视频作为上下文条件，结合两阶段训练策略：首先进行通用编辑适应，再通过 Effect-LoRA 实现特效特定学习；引入时空稀疏标记化以提升计算效率，从而在低计算成本下实现高保真输出。

Result: IC-Effect 在多个视觉风格上实现了高质量、可控且时间一致的视频特效编辑，显著优于现有方法，在少样本条件下仍表现出强泛化能力，并支持复杂特效生成。

Conclusion: IC-Effect 成功构建了一种高效、可控且时空一致的少样本视频特效编辑框架，具备强大的指令遵循能力和泛化性能，为未来视频创作提供了新的技术路径。

Abstract: We propose \textbf{IC-Effect}, an instruction-guided, DiT-based framework for few-shot video VFX editing that synthesizes complex effects (\eg flames, particles and cartoon characters) while strictly preserving spatial and temporal consistency. Video VFX editing is highly challenging because injected effects must blend seamlessly with the background, the background must remain entirely unchanged, and effect patterns must be learned efficiently from limited paired data. However, existing video editing models fail to satisfy these requirements. IC-Effect leverages the source video as clean contextual conditions, exploiting the contextual learning capability of DiT models to achieve precise background preservation and natural effect injection. A two-stage training strategy, consisting of general editing adaptation followed by effect-specific learning via Effect-LoRA, ensures strong instruction following and robust effect modeling. To further improve efficiency, we introduce spatiotemporal sparse tokenization, enabling high fidelity with substantially reduced computation. We also release a paired VFX editing dataset spanning $15$ high-quality visual styles. Extensive experiments show that IC-Effect delivers high-quality, controllable, and temporally consistent VFX editing, opening new possibilities for video creation.

</details>


### [56] [InpaintDPO: Mitigating Spatial Relationship Hallucinations in Foreground-conditioned Inpainting via Diverse Preference Optimization](https://arxiv.org/abs/2512.15644)
*Qirui Li,Yizhe Tang,Ran Yi,Guangben Lu,Fangyuan Zou,Peng Shu,Huan Yu,Jie Jiang*

Main category: cs.CV

TL;DR: 本文提出InpaintDPO，首个基于直接偏好优化（DPO）的框架，用于解决前景条件修复中的空间关系幻觉问题。通过MaskDPO、条件非对称偏好优化和共享共性偏好优化等方法，提升背景空间合理性与前景-背景边界一致性，增强模型对合理空间关系的理解。


<details>
  <summary>Details</summary>
Motivation: 当前前景条件修复方法常出现前景与背景之间不合理的尺度、位置关系和视角问题，而空间合理性具有主观性，难以量化，传统基于奖励的RLHF方法难以适用。

Method: 提出MaskDPO，仅在背景区域进行偏好优化以避免梯度冲突；引入条件非对称偏好优化，通过不同裁剪策略增强上下文感知与边界一致性；设计共享共性偏好优化，挖掘高质量胜出样本中的共同空间规律，强化模型对空间合理性的理解。

Result: 实验表明，InpaintDPO显著提升了生成图像中前景与背景之间的空间合理性，改善了边界一致性，并在多个评估指标上优于现有方法。

Conclusion: InpaintDPO为前景条件修复中的空间合理性建模提供了新范式，通过创新的偏好优化机制有效缓解了空间关系幻觉问题，推动可控图像生成向更自然、合理方向发展。

Abstract: Foreground-conditioned inpainting, which aims at generating a harmonious background for a given foreground subject based on the text prompt, is an important subfield in controllable image generation. A common challenge in current methods, however, is the occurrence of Spatial Relationship Hallucinations between the foreground subject and the generated background, including inappropriate scale, positional relationships, and viewpoints. Critically, the subjective nature of spatial rationality makes it challenging to quantify, hindering the use of traditional reward-based RLHF methods. To address this issue, we propose InpaintDPO, the first Direct Preference Optimization (DPO) based framework dedicated to spatial rationality in foreground-conditioned inpainting, ensuring plausible spatial relationships between foreground and background elements. To resolve the gradient conflicts in standard DPO caused by identical foreground in win-lose pairs, we propose MaskDPO, which confines preference optimization exclusively to the background to enhance background spatial relationships, while retaining the inpainting loss in the foreground region for robust foreground preservation. To enhance coherence at the foreground-background boundary, we propose Conditional Asymmetric Preference Optimization, which samples pairs with differentiated cropping operations and applies global preference optimization to promote contextual awareness and enhance boundary coherence. Finally, based on the observation that winning samples share a commonality in plausible spatial relationships, we propose Shared Commonality Preference Optimization to enhance the model's understanding of spatial commonality across high-quality winning samples, further promoting shared spatial rationality.

</details>


### [57] [Hard Labels In! Rethinking the Role of Hard Labels in Mitigating Local Semantic Drift](https://arxiv.org/abs/2512.15647)
*Jiacheng Cui,Bingkui Tong,Xinyue Bi,Xiaohan Zhao,Jiacheng Liu,Zhiqiang shen*

Main category: cs.CV

TL;DR: 本文研究了在少量图像裁剪情况下，教师模型生成的软标签容易出现局部语义漂移的问题，即局部视觉内容与全局语义不一致，导致训练与测试分布错位。作者提出将硬标签作为内容无关的锚点，与软标签混合使用，以校正语义漂移。为此，提出了HALD训练范式，理论分析并实验证明该方法能有效恢复视觉内容与语义监督的一致性。在数据集蒸馏和大规模分类任务上均取得显著提升，在ImageNet-1K上仅用285M存储即达到42.7%准确率，优于现有最优方法LPLD 9.0%。研究重新强调了硬标签在软标签主导训练中的互补价值，呼吁重新思考其作用。


<details>
  <summary>Details</summary>
Motivation: 当仅使用少量图像裁剪时，软标签容易因局部视觉内容与全局语义不一致而产生语义漂移，导致训练与测试分布错位，影响模型泛化性能。

Method: 提出HALD（Hard Label for Alleviating Local Semantic Drift）训练范式，利用硬标签作为内容无关的锚点，对软标签进行校正，实现视觉内容与语义监督的对齐。结合理论分析与实验验证，探索软硬标签的混合机制。

Result: 在图像数据集蒸馏和大规模分类任务中，所提方法显著提升模型泛化能力；在ImageNet-1K上，仅用285M存储的软标签即可达到42.7%准确率，超越LPLD 9.0%。

Conclusion: 硬标签在软标签主导的训练中具有重要且被忽视的校正作用，应作为互补工具重新纳入知识迁移框架，有助于缓解局部语义漂移问题，提升模型鲁棒性与泛化性能。

Abstract: Soft labels generated by teacher models have become a dominant paradigm for knowledge transfer and recent large-scale dataset distillation such as SRe2L, RDED, LPLD, offering richer supervision than conventional hard labels. However, we observe that when only a limited number of crops per image are used, soft labels are prone to local semantic drift: a crop may visually resemble another class, causing its soft embedding to deviate from the ground-truth semantics of the original image. This mismatch between local visual content and global semantic meaning introduces systematic errors and distribution misalignment between training and testing. In this work, we revisit the overlooked role of hard labels and show that, when appropriately integrated, they provide a powerful content-agnostic anchor to calibrate semantic drift. We theoretically characterize the emergence of drift under few soft-label supervision and demonstrate that hybridizing soft and hard labels restores alignment between visual content and semantic supervision. Building on this insight, we propose a new training paradigm, Hard Label for Alleviating Local Semantic Drift (HALD), which leverages hard labels as intermediate corrective signals while retaining the fine-grained advantages of soft labels. Extensive experiments on dataset distillation and large-scale conventional classification benchmarks validate our approach, showing consistent improvements in generalization. On ImageNet-1K, we achieve 42.7% with only 285M storage for soft labels, outperforming prior state-of-the-art LPLD by 9.0%. Our findings re-establish the importance of hard labels as a complementary tool, and call for a rethinking of their role in soft-label-dominated training.

</details>


### [58] [Stylized Synthetic Augmentation further improves Corruption Robustness](https://arxiv.org/abs/2512.15675)
*Georg Siedel,Rojan Regmi,Abhirami Anand,Weijia Shao,Silvia Vock,Andrey Morozov*

Main category: cs.CV

TL;DR: 本文提出了一种结合合成图像数据与神经风格迁移的训练数据增强流程，以提升深度视觉模型对常见干扰的鲁棒性。尽管风格迁移会降低合成图像在FID指标下的质量，但这些图像在模型训练中表现出显著优势。通过系统性实证分析，发现风格化与合成数据能有效互补，并可与TrivialAugment等规则增强方法协同使用，但不适用于其他方法。该方法在多个小型图像分类基准上达到当前最优的抗干扰性能，在CIFAR-10-C、CIFAR-100-C和TinyImageNet-C上的鲁棒准确率分别达到93.54%、74.9%和50.86%。


<details>
  <summary>Details</summary>
Motivation: 现有深度视觉模型对常见图像干扰（如噪声、模糊）敏感，而传统数据增强方法在应对复杂干扰时效果有限。为提升模型鲁棒性，需要更有效的数据增强策略，尤其在小规模数据集上。合成数据与风格迁移的结合提供了一种新颖且高效的解决方案。

Method: 提出一种训练数据增强管道，将合成图像与神经风格迁移相结合，生成具有多样性和干扰特征的训练样本。通过调整关键超参数进行系统性实验，评估不同增强组合对图像分类器性能的影响。

Result: 风格化与合成数据的结合显著提升了模型在多种常见干扰下的鲁棒性；在CIFAR-10-C、CIFAR-100-C和TinyImageNet-C上分别取得93.54%、74.9%和50.86%的鲁棒准确率，优于现有方法。

Conclusion: 合成数据与神经风格迁移的结合是一种高效且互补的数据增强策略，能够显著提升深度学习模型在面对常见图像干扰时的鲁棒性，尤其适用于小规模图像分类任务。

Abstract: This paper proposes a training data augmentation pipeline that combines synthetic image data with neural style transfer in order to address the vulnerability of deep vision models to common corruptions. We show that although applying style transfer on synthetic images degrades their quality with respect to the common FID metric, these images are surprisingly beneficial for model training. We conduct a systematic empirical analysis of the effects of both augmentations and their key hyperparameters on the performance of image classifiers. Our results demonstrate that stylization and synthetic data complement each other well and can be combined with popular rule-based data augmentation techniques such as TrivialAugment, while not working with others. Our method achieves state-of-the-art corruption robustness on several small-scale image classification benchmarks, reaching 93.54%, 74.9% and 50.86% robust accuracy on CIFAR-10-C, CIFAR-100-C and TinyImageNet-C, respectively

</details>


### [59] [Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning](https://arxiv.org/abs/2512.15693)
*Yifei Li,Wenzhao Zheng,Yanran Zhang,Runze Sun,Yu Zheng,Lei Chen,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Skyra是一种专门用于检测AI生成视频的多模态大语言模型，通过识别人类可感知的视觉伪影并提供可解释的证据来实现检测与解释。研究构建了首个大规模、细粒度标注的AI生成视频伪影数据集ViF-CoT-4K，并提出两阶段训练策略以提升模型在时空伪影感知、解释能力与检测精度方面的能力。为评估性能，提出了包含3000个高质量样本的ViF-Bench基准。实验表明，Skyra在多个基准上优于现有方法，且为可解释AI视频检测提供了重要洞见。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成视频技术的滥用引发社会担忧，亟需可靠且具备解释能力的检测工具；但现有方法多局限于二分类任务，缺乏对检测结果的人类可理解解释，限制了其实际应用价值。

Method: 构建大规模细粒度标注数据集ViF-CoT-4K，采用两阶段训练策略增强模型对时空伪影的感知能力与解释能力，结合多模态大语言模型（MLLM）实现基于视觉伪影的检测与可解释性输出。

Result: Skyra在多个基准测试中表现优于现有方法，尤其在检测精度与解释能力方面显著提升；所提出的ViF-Bench基准为后续研究提供了高质量评估平台，同时揭示了可解释性检测的关键挑战与发展方向。

Conclusion: Skyra成功实现了高精度、可解释的AI生成视频检测，其核心在于将人类可感知的视觉伪影作为检测与解释的依据。该研究不仅推动了可解释AI检测的发展，也为未来对抗深度伪造技术提供了坚实的技术基础。

Abstract: The misuse of AI-driven video generation technologies has raised serious social concerns, highlighting the urgent need for reliable AI-generated video detectors. However, most existing methods are limited to binary classification and lack the necessary explanations for human interpretation. In this paper, we present Skyra, a specialized multimodal large language model (MLLM) that identifies human-perceivable visual artifacts in AI-generated videos and leverages them as grounded evidence for both detection and explanation. To support this objective, we construct ViF-CoT-4K for Supervised Fine-Tuning (SFT), which represents the first large-scale AI-generated video artifact dataset with fine-grained human annotations. We then develop a two-stage training strategy that systematically enhances our model's spatio-temporal artifact perception, explanation capability, and detection accuracy. To comprehensively evaluate Skyra, we introduce ViF-Bench, a benchmark comprising 3K high-quality samples generated by over ten state-of-the-art video generators. Extensive experiments demonstrate that Skyra surpasses existing methods across multiple benchmarks, while our evaluation yields valuable insights for advancing explainable AI-generated video detection.

</details>


### [60] [End-to-End Training for Autoregressive Video Diffusion via Self-Resampling](https://arxiv.org/abs/2512.15702)
*Yuwei Guo,Ceyuan Yang,Hao He,Yang Zhao,Meng Wei,Zhenheng Yang,Weilin Huang,Dahua Lin*

Main category: cs.CV

TL;DR: 提出Resampling Forcing框架，通过自重采样模拟推理时的错误，实现无需教师模型的端到端训练，结合稀疏因果掩码和历史路由机制，提升长视频生成的时序一致性与效率。


<details>
  <summary>Details</summary>
Motivation: 解决自回归视频扩散模型在训练-测试阶段因暴露偏差导致的性能下降问题，现有方法依赖双向教师模型或在线判别器，难以实现端到端训练。

Method: 引入自重采样机制模拟推理误差，使用稀疏因果掩码保证时间因果性并支持帧级并行训练，结合参数无须的历史路由机制动态选择相关历史帧。

Result: 实验表明该方法性能接近基于蒸馏的基线，且在长视频生成中表现出更优的时序一致性，得益于原生长度训练。

Conclusion: Resampling Forcing提供了一种无需教师模型的端到端训练方案，有效缓解暴露偏差，适用于大规模自回归视频建模，显著提升长序列生成质量。

Abstract: Autoregressive video diffusion models hold promise for world simulation but are vulnerable to exposure bias arising from the train-test mismatch. While recent works address this via post-training, they typically rely on a bidirectional teacher model or online discriminator. To achieve an end-to-end solution, we introduce Resampling Forcing, a teacher-free framework that enables training autoregressive video models from scratch and at scale. Central to our approach is a self-resampling scheme that simulates inference-time model errors on history frames during training. Conditioned on these degraded histories, a sparse causal mask enforces temporal causality while enabling parallel training with frame-level diffusion loss. To facilitate efficient long-horizon generation, we further introduce history routing, a parameter-free mechanism that dynamically retrieves the top-k most relevant history frames for each query. Experiments demonstrate that our approach achieves performance comparable to distillation-based baselines while exhibiting superior temporal consistency on longer videos owing to native-length training.

</details>


### [61] [Multi-View Foundation Models](https://arxiv.org/abs/2512.15708)
*Leo Segre,Or Hirschorn,Shai Avidan*

Main category: cs.CV

TL;DR: 本文提出将基础模型转化为多视角基础模型，通过引入3D感知注意力层，使同一3D点在不同视角下的特征保持一致性，无需构建显式3D模型，直接在图像空间中操作。实验表明该方法在特征匹配方面显著优于现有基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在处理多视角图像时，对同一3D点的特征表示不一致，缺乏跨视角一致性，限制了其在三维视觉任务中的应用。

Method: 在基于Transformer的基础模型（如DINO、SAM、CLIP）中引入中间3D感知注意力层，以增强不同视角间对应点的特征匹配能力。

Result: 定量实验显示，所提方法在表面法线估计和多视角分割任务中显著提升了特征一致性与匹配性能。

Conclusion: 该方法成功将基础模型扩展为多视角一致的模型，避免了复杂3D建模过程，实现了高效且准确的跨视角特征对齐。

Abstract: Foundation models are vital tools in various Computer Vision applications. They take as input a single RGB image and output a deep feature representation that is useful for various applications. However, in case we have multiple views of the same 3D scene, they operate on each image independently and do not always produce consistent features for the same 3D point. We propose a way to convert a Foundation Model into a Multi-View Foundation Model. Such a model takes as input a set of images and outputs a feature map for each image such that the features of corresponding points are as consistent as possible. This approach bypasses the need to build a consistent 3D model of the features and allows direct manipulation in the image space. Specifically, we show how to augment Transformers-based foundation models (i.e., DINO, SAM, CLIP) with intermediate 3D-aware attention layers that help match features across different views. As leading examples, we show surface normal estimation and multi-view segmentation tasks. Quantitative experiments show that our method improves feature matching considerably compared to current foundation models.

</details>


### [62] [DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models](https://arxiv.org/abs/2512.15713)
*Lunbin Zeng,Jingfeng Yao,Bencheng Liao,Hongyuan Tao,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionVL提出了一种从现有强大的自回归（AR）模型转换为扩散视觉语言模型（dVLM）的方法，通过简单微调即可实现性能媲美主流模型的dVLM。该方法在仅使用不到5%训练数据的情况下，显著提升了多模态任务表现（如MMMU-Pro提升34.4%，MME提升37.5%），并实现2倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 当前扩散视觉语言模型（dVLM）受限于基础扩散语言模型的能力，性能远落后于主流自回归（AR）模型。因此，研究是否可基于现有强大AR模型构建高效dVLM，成为关键问题。

Method: 提出DiffusionVL家族模型，通过微调将预训练的AR模型转化为扩散模型，并引入块解码设计以支持任意长度生成和KV缓存复用，从而提升推理效率。

Result: 在仅使用不足5%训练数据条件下，模型在MMMU-Pro和MME基准上分别取得34.4%和37.5%的性能提升，并实现2倍推理加速，性能与LLaVA风格模型相当。

Conclusion: DiffusionVL证明了从强大AR模型迁移至扩散范式是可行且高效的，为构建高性能、高效率的dVLM提供了新路径。

Abstract: In recent multimodal research, the diffusion paradigm has emerged as a promising alternative to the autoregressive paradigm (AR), owing to its unique decoding advantages. However, due to the capability limitations of the base diffusion language model, the performance of the diffusion vision language model (dVLM) still lags significantly behind that of mainstream models. This leads to a simple yet fundamental question: Is it possible to construct dVLMs based on existing powerful AR models? In response, we propose DiffusionVL, a dVLM family that could be translated from any powerful AR models. Through simple fine-tuning, we successfully adapt AR pre-trained models into the diffusion paradigm. This approach yields two key observations: (1) The paradigm shift from AR-based multimodal models to diffusion is remarkably effective. (2) Direct conversion of an AR language model to a dVLM is also feasible, achieving performance competitive with LLaVA-style visual-instruction-tuning. Further, we introduce a block-decoding design into dVLMs that supports arbitrary-length generation and KV cache reuse, achieving a significant inference speedup. We conduct a large number of experiments. Despite training with less than 5% of the data required by prior methods, DiffusionVL achieves a comprehensive performance improvement-a 34.4% gain on the MMMU-Pro (vision) bench and 37.5% gain on the MME (Cog.) bench-alongside a 2x inference speedup. The model and code are released at https://github.com/hustvl/DiffusionVL.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [63] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: 本文挑战了OpenAI关于大语言模型幻觉源于评估激励错配的观点，认为幻觉是Transformer架构的结构性必然结果，而非可通过优化奖励机制解决的偶然现象。由于Transformer仅建模词元间的统计关联而非世界真实结构，其在数据稀疏或不一致区域必须进行虚构性补全以维持连贯性，因此任何激励调整、提示工程或微调都无法消除幻觉。实验证明，唯有通过外部真值验证与弃权模块（如Licensing Oracle）才能实现完全可靠的输出。结论是幻觉是生成式架构的本质属性，可靠AI需依赖混合系统，区分语言流畅性与认知责任。


<details>
  <summary>Details</summary>
Motivation: 现有观点认为幻觉是因评估激励不当导致的可修正行为问题，但本文质疑这一解释，旨在揭示幻觉背后的深层架构根源，推动对可信AI系统的重新设计。

Method: 基于对结构性幻觉的理论分析，并通过Licensing Oracle实验验证不同干预手段的效果，对比激励调整、提示工程、微调与外部真值验证在抑制幻觉方面的有效性。

Result: 实验表明，仅靠改进激励或训练方法无法消除幻觉；而引入外部真值验证和弃权机制（如Licensing Oracle）可实现对幻觉的完全抑制，证明幻觉根植于模型架构本身。

Conclusion: 幻觉并非可修复的优化缺陷，而是生成式模型（尤其是Transformer）的结构性特征；构建可靠AI系统必须采用混合架构，将语言生成能力与真值校验机制分离，以实现真正的认知责任。

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [64] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: T5Gemma 2 是 T5Gemma 系列的下一代轻量级开源编码器-解码器模型，具备强大的多语言、多模态和长上下文能力。它基于 Gemma 3 模型，通过 UL2 适配策略将预训练的解码器模型转化为编码器-解码器架构，并扩展至多模态场景。提出两种效率优化方法：共享词嵌入（tie word embeddings）和合并注意力（merged attention），显著提升效率。实验表明该策略在不同架构和模态上具有通用性，且在长文本建模方面表现优异。性能优于或相当甚至超过其 Gemma 3 对应模型，已发布 270M-270M、1B-1B、4B-4B 三个版本供社区使用。


<details>
  <summary>Details</summary>
Motivation: 提升轻量级模型在多语言、多模态及长上下文任务中的表现，同时优化计算效率，推动高效、通用的编码器-解码器模型发展。

Method: 采用 UL2 适配策略，将 Decoder-only 的 Gemma 3 模型转化为编码器-解码器架构；引入共享词嵌入与合并注意力机制以提高效率；支持文本与多模态输入。

Result: T5Gemma 2 在多种任务中表现出色，预训练性能与 Gemma 3 相当或更优，后训练性能显著提升；在长上下文建模方面优势明显；模型效率更高，适合实际部署。

Conclusion: T5Gemma 2 成功实现了轻量级、高效、多模态和长上下文能力的统一，其适配策略具有广泛适用性，为后续研究提供了强大基础工具。

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [65] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: 本文改进了先前的新闻观点分析管道，通过微调大语言模型（LLMs）进行观点分类，并利用Wikidata中的语义描述丰富主张的表示。在英国移民议题的基准测试中，两项改进均提升了分类性能，两者结合效果最佳，尤其当使用能处理长输入的LLM时。


<details>
  <summary>Details</summary>
Motivation: 新闻媒体在民主社会中对政治与社会话语具有重要影响，理解其观点表达机制有助于评估媒体报道的平衡性与公正性。现有方法在识别观点和分类主张方面存在局限，亟需更精准的技术手段。

Method: 采用混合人机方法识别话题下的观点范围；通过微调大语言模型进行观点分类；利用Wikidata提取相关行动者的语义信息以增强主张表征。

Result: 实验表明，微调LLM和引入Wikidata语义描述均独立提升分类性能，二者结合效果最优，尤其在使用长文本处理能力强的LLM时表现突出。

Conclusion: 融合大语言模型与外部知识源（如Wikidata）的策略显著提升了新闻观点分类的准确性，为构建更全面、公正的媒体分析工具提供了有效路径。

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [66] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: 本研究评估了不同规模的大语言模型（LLM）在药剂师执照风格问答任务中的表现，并提出了一种名为DrugRAG的外部知识集成方法，通过检索结构化药物知识并增强模型提示来提升准确性。实验使用141道题目测试了11个参数量从80亿到700亿以上的LLM，结果显示基线准确率在46%至92%之间，其中GPT-5和o3表现最佳。DrugRAG在所有模型上均显著提升性能，准确率提升达7至21个百分点，例如Gemma 3 27B从61%提升至71%，Llama 3.1 8B从46%提升至67%。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在药剂师执照风格问答任务中的表现，并解决其在专业医学知识应用中因缺乏准确、结构化知识而产生的错误问题，从而提高AI系统在医药领域的可靠性与实用性。

Method: 采用11个不同参数规模的大语言模型进行基准测试，使用141题的药学数据集评估其原始表现；随后开发一种三步式外部检索增强生成（RAG）流程DrugRAG，从权威来源检索结构化药物知识并将其作为证据上下文注入模型提示中，不修改模型架构或参数。

Result: 基线准确率范围为46%至92%，其中GPT-5（92%）和o3（89%）表现最佳，而参数少于80亿的模型准确率低于50%。DrugRAG在所有模型上均有效提升准确率，增幅为7至21个百分点，尤其对小模型效果显著。

Conclusion: 外部结构化药物知识的集成，通过DrugRAG方法，可显著提升大语言模型在药学任务中的准确性，且无需修改模型本身，为构建基于循证医学的药学人工智能应用提供了一种实用、可扩展的解决方案。

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [67] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: 本研究致力于缩小罗马尼亚语在多模态自然语言处理方面的资源差距，通过将Flickr30k数据集翻译为罗马尼亚语，并利用开源大语言模型扩展其用于视觉问答任务。实验表明，基于LoRA方法微调的多模态模型在罗马尼亚语视觉问答和图像描述生成任务上表现优异，其中七亿参数的Qwen2-VL-RoVQA模型在两项任务中均取得最高得分，相比原始版本分别提升6.05%和2.61%的BERTScore F1值，且语法错误显著减少，表明模型在语言理解与表达流畅性方面均有提升。


<details>
  <summary>Details</summary>
Motivation: 降低低资源语言在生成式AI中的资源差距，推动多模态自然语言处理的普惠化，尤其针对罗马尼亚语这一低资源语言。

Method: 将Flickr30k数据集翻译为罗马尼亚语，并利用开源大语言模型扩展其用于视觉问答；采用参数高效微调方法LoRA，对来自LLaMA 3.2、LLaVA 1.6和Qwen2三个主流模型家族的视觉语言模型进行训练。

Result: 所提出的模型在罗马尼亚语视觉问答和图像描述生成任务上均表现优异，其中七亿参数的Qwen2-VL-RoVQA在两项任务中均取得最佳性能，相较于原始版本，BERTScore F1分别提升6.05%和2.61%；同时，模型在罗马尼亚语语法准确性方面有明显改善，显示出更强的语言流利度。

Conclusion: 本研究有效提升了低资源语言罗马尼亚语在多模态任务中的能力，证明了通过数据构建与参数高效微调可显著增强模型对低资源语言的理解与生成能力，为多模态AI的跨语言普及提供了可行路径。

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [68] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: 本文系统评估了40种专有和开源的多模态大模型（MLLMs），涵盖GPT-5、o3、Gemini-2.5-Pro和Qwen2.5-VL等，在基于美国国家化学奥林匹克竞赛（USNCO）题目的多模态化学推理基准上的表现。研究发现，多数模型在模态融合方面存在严重问题，甚至出现移除图像后准确率反而提升的现象，表明视觉-语言对齐不佳。链式思维（Chain-of-Thought）提示显著提升准确率与视觉理解能力，通过消融实验和遮挡可解释性分析得到验证。结果揭示当前MLLMs在科学推理方面存在关键局限，并提出改进策略，为领域特定多模态AI的发展提供基准与方向。


<details>
  <summary>Details</summary>
Motivation: 多模态科学推理，尤其是化学领域，依赖于符号图、分子结构和结构化视觉数据，但现有大语言模型在整合视觉与文本信息方面表现不佳，亟需系统评估与改进。

Method: 选取超过二十年的美国国家化学奥林匹克竞赛题目构建多模态推理基准，评估40种主流多模态大模型，采用链式思维提示、消融实验与遮挡可解释性分析，考察模型在视觉-语言融合与推理能力方面的表现。

Result: 多数模型在模态融合上表现差，部分情况下移除图像反而提高准确率；链式思维提示显著提升性能与视觉感知能力；模型在复杂化学推理任务中仍存在明显局限。

Conclusion: 当前多模态大模型在化学科学推理方面仍存在重大缺陷，需加强视觉-语言对齐与可解释性设计。本研究提供了一个可靠的领域特定基准，推动更鲁棒、可解释的多模态人工智能系统发展。

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [69] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: 提出DASH-DTS框架，利用大模型实现对话主题分割，通过握手识别检测主题转移，结合相似性引导的示例选择增强上下文，生成正负样本提升模型判别力。发布首个公开的海上VHF通信数据集VHF-Dial，实验表明该方法在多个基准上达到SOTA性能，具备可解释性和置信度评分。


<details>
  <summary>Details</summary>
Motivation: 传统方法在非正式、隐式转换的对话中表现不佳，尤其在任务导向的公共渠道通信如海上VHF对话中存在局限性，亟需更鲁棒和可解释的主题分割方法。

Method: 基于大语言模型的DASH-DTS框架，核心包括：1）通过对话握手识别检测主题转移；2）采用相似性引导的示例选择进行上下文增强；3）生成选择性的正负样本以提升模型判别力与鲁棒性。

Result: 在VHF-Dial和标准基准上均取得多项领先性能，显著提升主题分割准确率，且支持可解释推理与置信度输出，适用于实际操作中的稳定监控与决策支持。

Conclusion: DASH-DTS为任务导向型对话的主题分割提供了高效、可靠且可解释的新范式，其提出的公开数据集推动了该领域研究发展。

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [70] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: SGM是一种白盒神经元级多模态干预方法，通过专家加权软抑制重新校准少量有毒专家神经元，以中和有害的跨模态激活，无需参数更新。该方法在标准和对抗性条件下均有效降低毒性，将有害率从48.2%降至2.5%，同时保持语言流畅性和多模态推理能力。其扩展版本SGM*可与现有去毒方法结合，提供可解释、低成本的多模态生成安全解决方案。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）继承了弱标注预训练语料中的有毒、偏见和不适宜内容，导致安全风险，尤其在对抗性触发下，现有无参训练的去毒方法难以应对。需要一种高效、可解释且无需重训练的安全干预机制。

Method: 提出SGM方法，通过识别并选择性地对少数有毒专家神经元进行专家加权软抑制，实现对跨模态有害激活的精准中和，整个过程不修改模型参数。同时构建MM-TOXIC-QA评估框架以系统评测去毒效果。

Result: 在开源多模态大模型上实验表明，SGM在标准和对抗场景下均显著降低毒性，有害率由48.2%降至2.5%，同时保持语言流畅性和多模态推理性能；SGM*集成多种防御策略后表现更优，具备可扩展性与实用性。

Conclusion: SGM为多模态生成提供了可解释、低开销、高效的中毒神经元干预方案，是实现可控多模态生成的重要进展。

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [71] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 提出Meta-Prompting协议，通过生成器、审计器和优化器构成的对抗三元组，将自然语言指令视为可微变量，利用文本批评作为梯度，实现大模型的确定性控制与自优化，为概率计算时代的可观测软件工程奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前基于启发式提示工程的方法无法为关键任务应用提供确定性保障，需重新设计大模型的交互范式以实现可靠软件组件化。

Method: 引入Meta-Prompting协议，构建Adversarial Trinity架构，结合声明式编程（DSPy）与自动文本微分（TextGrad），将自然语言指令建模为可微变量，用文本批判作为梯度进行优化。

Result: 验证了该方法在理论上的可行性，有效缓解幻觉与模型崩溃问题，为构建可编程、自优化的大模型系统提供了新范式。

Conclusion: Meta-Prompting协议为大语言模型从随机对话接口向可靠软件组件演进提供了理论支撑，标志着可观测软件工程在概率计算时代的重要进展。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [72] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: SCOPE提出了一种结合模型置信度和动态子组划分的逐步置信加权伪标签估计方法，通过优先考虑高质量推理路径并促进多样化探索，有效缓解了多数投票策略中的确认偏差和稀疏奖励问题，在AIME 2025和AMC等基准上分别实现13.1%和8.1%的相对提升。


<details>
  <summary>Details</summary>
Motivation: 现有测试时强化学习方法依赖多数投票生成伪标签，但易引发确认偏差且面临稀疏奖励问题，限制了大语言模型推理能力的提升。

Method: SCOPE引入逐步置信度机制，动态划分候选输出为独立子组，基于重复采样在各子组内获取局部共识，以提供多样化的监督信号，从而增强探索能力。

Result: 在多个模型和基准上，SCOPE均显著优于现有基线，尤其在AIME 2025和AMC上分别取得13.1%和8.1%的相对性能提升。

Conclusion: SCOPE通过融合置信度与动态子组划分，有效提升了测试时强化学习中伪标签的质量与多样性，为增强大语言模型推理能力提供了高效新范式。

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [73] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: 本文介绍了一个大规模的Rakuten Travel评论语料库，包含2009至2024年共730万条客户评论。数据集涵盖评论文本、住宿方回复、匿名用户ID、评论日期、住宿ID、计划ID、计划标题、房型、房间名称、出行目的、同行人员、各维度评分及总体评分。文章提供了语料库的统计信息，并通过统计方法分析了2019至2024年间数据漂移的驱动因素。


<details>
  <summary>Details</summary>
Motivation: 构建一个大规模、多维度的旅游评论数据集，以支持自然语言处理与用户行为研究，并揭示长期数据变化趋势和影响因素。

Method: 收集并整理2009至2024年间来自Rakuten Travel平台的730万条客户评论，对数据进行清洗与结构化处理，利用统计分析方法探究数据漂移现象。

Result: 成功构建了包含丰富元信息的大规模旅游评论语料库；识别出2019至2024年间评论内容、评分模式及用户行为的变化趋势，揭示了数据漂移的关键驱动因素。

Conclusion: 该语料库为旅游领域自然语言处理与用户行为分析提供了重要资源，其长期演化特征有助于理解用户偏好变迁与平台反馈机制。

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [74] [MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163)
*Xuanjun Zong,Zhiqi Shen,Lei Wang,Yunshi Lan,Chao Yang*

Main category: cs.CL

TL;DR: MCP-SafetyBench 是一个基于真实 MCP 服务器的综合性基准，用于评估大语言模型在多轮、跨服务器任务中的安全性。它覆盖五个现实场景，涵盖20类攻击类型，揭示了开源与闭源模型在安全性能上的显著差异，并强调了在复杂交互中加强防御的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 现有安全基准无法充分覆盖 MCP 开放架构和多服务器工作流带来的新型安全风险，尤其缺乏对真实世界场景和多步骤协作任务的评估能力。

Method: 构建基于真实 MCP 服务器的多领域基准，设计统一的攻击分类体系，支持多轮交互与跨服务器协调任务，进行系统性评估。

Result: 评估发现模型安全表现差异显著，随着任务复杂度和服务器交互增加，漏洞风险急剧上升。

Conclusion: 亟需强化针对 MCP 系统的安全防御机制，MCP-SafetyBench 可作为诊断和缓解真实部署中安全风险的基础工具。

Abstract: Large language models (LLMs) are evolving into agentic systems that reason, plan, and operate external tools. The Model Context Protocol (MCP) is a key enabler of this transition, offering a standardized interface for connecting LLMs with heterogeneous tools and services. Yet MCP's openness and multi-server workflows introduce new safety risks that existing benchmarks fail to capture, as they focus on isolated attacks or lack real-world coverage. We present MCP-SafetyBench, a comprehensive benchmark built on real MCP servers that supports realistic multi-turn evaluation across five domains: browser automation, financial analysis, location navigation, repository management, and web search. It incorporates a unified taxonomy of 20 MCP attack types spanning server, host, and user sides, and includes tasks requiring multi-step reasoning and cross-server coordination under uncertainty. Using MCP-SafetyBench, we systematically evaluate leading open- and closed-source LLMs, revealing large disparities in safety performance and escalating vulnerabilities as task horizons and server interactions grow. Our results highlight the urgent need for stronger defenses and establish MCP-SafetyBench as a foundation for diagnosing and mitigating safety risks in real-world MCP deployments.

</details>


### [75] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: 本文探讨了自然语言生成（NLG）评估与芬兰大学学生评分之间的日益增长的认识论平行关系，指出两个领域都面临‘重大错配问题’。随着学生越来越多地使用ChatGPT等工具生成高质量内容，仅关注最终成果的传统评估方法已失去有效性。为此，本文提出基于过程的、多证据的‘教学多因素评估’（P-MFA）模型，该模型借鉴多因素认证逻辑，强调学习过程而非结果。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法过于关注最终产出，忽视学习过程，而当前学生广泛使用AI工具生成内容，导致评估失效，亟需一种能够反映真实学习过程的新评估范式。

Method: 提出并构建了教学多因素评估（P-MFA）模型，该模型采用过程导向、多证据融合的方式，类比于多因素认证机制，综合考察学生在生成过程中的多种行为与证据。

Result: P-MFA模型能够有效识别学生的真实学习行为，克服因使用AI工具带来的评估偏差，提升评估的公平性与真实性。

Conclusion: 本研究证明，将评估重心从结果转向过程，并引入多维度证据支持，是应对当前教育评估与NLG评价中‘重大错配问题’的关键路径。

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [76] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: RFKG-CoT 提出一种新的知识图谱增强型推理方法，通过关系驱动的自适应跳数选择和基于思维链的路径引导机制，有效缓解大语言模型在知识密集型问答中的幻觉问题。该方法在多个基准测试中显著提升准确率，最高达14.7个百分点，并验证了两个组件的互补性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如KG-CoT受限于固定的跳数选择和对推理路径的利用不足，导致在复杂问答中表现不佳，因此需要更灵活、更具指导性的路径推理机制。

Method: 提出关系驱动的自适应跳数选择器，通过关系掩码动态调整推理步数；引入少样本上下文学习路径引导机制，以'问题-路径-答案'格式构建思维链示例，增强模型对推理路径的理解能力。

Result: 在四个KGQA基准上，RFKG-CoT相较于KG-CoT在Llama2-7B模型上最大提升14.7个百分点的准确率；消融实验表明跳数选择器与路径提示具有互补作用，共同提升答案的忠实度。

Conclusion: RFKG-CoT通过自适应跳数选择与路径引导机制，有效提升了大语言模型在知识密集型问答任务中的可靠性与准确性，为减少幻觉提供了新思路。

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [77] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 该论文介绍了Yes-MT团队在WMT 2024低资源印地语系语言翻译共享任务中提交的系统，专注于英语与阿萨姆语、米佐语、卡西语和曼尼普里语之间的翻译。实验比较了多种方法，包括预训练模型（如mT5、IndicBart）的微调、LoRA微调IndicTrans2、基于大语言模型（LLM）的零样本和少样本提示（如Llama 3、Mixtral 8x7b）、Llama 3的LoRA监督微调，以及从头训练Transformer模型。评估使用SacreBLEU和CHRF在WMT23测试数据上进行，结果突显了低资源翻译的挑战，并展示了微调后大语言模型在这些任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 低资源印地语系语言的机器翻译面临数据稀缺、模型性能受限等挑战，亟需有效的方法来提升翻译质量。利用大语言模型和高效微调技术，有望缓解数据不足问题，推动低资源语言翻译的发展。

Method: 采用多种方法：1）在多语言和单语设置下微调mT5和IndicBart；2）使用LoRA对IndicTrans2进行微调；3）使用Llama 3和Mixtral 8x7b进行零样本/少样本提示；4）对Llama 3进行LoRA监督微调；5）从头训练Transformer模型。所有方法均在WMT23低资源印地语系语言翻译测试集上评估。

Result: 实验表明，经过微调的大语言模型（尤其是Llama 3的LoRA微调）在低资源翻译任务中表现优异，显著优于传统方法。特别是在缺乏平行语料的情况下，提示学习和微调策略展现出强大潜力。尽管从头训练的Transformer模型表现有限，但其结果仍为后续研究提供了参考。

Conclusion: 本研究验证了大语言模型结合高效微调技术（如LoRA）在低资源印地语系语言翻译中的有效性，尤其在数据稀缺条件下表现出色。未来工作应进一步探索模型压缩、知识蒸馏与多任务学习以提升效率与泛化能力。

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [78] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: FAME 是一个用于评估多语言机器遗忘（Machine Unlearning）的合成基准，涵盖英语、法语、德语、意大利语和西班牙语。它包含1,000个虚构演员的传记和20,000个问答对，支持实体级和实例级遗忘的评估，且数据完全虚构，避免预训练数据干扰，实现可控评估。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘评估基准仅限于英文，且仅支持实体级遗忘（如删除某人所有信息），无法全面评估多语言环境下不同遗忘粒度的性能。为解决这一局限，需要一个可扩展、跨语言、支持多种遗忘粒度的基准。

Method: 构建虚构演员生物资料库，每条传记涵盖20个结构化主题（如生平、职业生涯、成就、个人信息），并生成对应的问答对。设计两个数据集划分，分别支持实体级与实例级遗忘评估，并覆盖五种语言以实现多语言比较。

Result: FAME 成功提供了一个可控制、多语言、支持多种遗忘粒度的评估基准，可用于系统性比较不同机器遗忘技术在真实场景下的表现。

Conclusion: FAME 为多语言机器遗忘研究提供了可靠、可复现且无隐私风险的评估框架，推动了更安全、更符合‘被遗忘权’的大型语言模型发展。

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [79] [The Moralization Corpus: Frame-Based Annotation and Analysis of Moralizing Speech Acts across Diverse Text Genres](https://arxiv.org/abs/2512.15248)
*Maria Becker,Mirko Sommer,Lars Tapken,Yi Wan Teh,Bruno Brocai*

Main category: cs.CL

TL;DR: 本文提出了一种名为Moralization Corpus的多语种数据集，用于分析道德化语言在论辩话语中的策略性使用。研究开发了基于框架的标注方案，捕捉道德化的核心要素（道德价值、诉求和话语主角），并在德语文本中进行了应用，涵盖政治辩论、新闻报道和在线讨论等多样场景。通过评估大型语言模型在不同提示条件下的表现，发现详细提示指令比少样本或解释性提示更有效，且道德化具有高度主观性和上下文敏感性。所有数据、标注指南和代码均已公开，以促进跨学科研究。


<details>
  <summary>Details</summary>
Motivation: 道德化作为一种依赖道德价值观来支持主张或立场的说服性表达形式，尚未得到充分研究。其语用复杂且常隐含，给人类标注者和自然语言处理系统带来挑战。因此需要一个专门的数据集和分析框架来深入理解这一现象。

Method: 构建了基于框架的标注体系，识别道德化中的三大核心成分：道德价值、诉求与话语主角；在德国多种文本类型中进行标注；使用大语言模型在不同提示条件下进行道德化检测与组件提取，并与人工标注结果对比分析。

Result: 详细提示指令显著提升模型性能，但道德化仍高度依赖上下文和主观判断；现有模型难以完全替代人类标注；该数据集为后续研究提供了可靠基础。

Conclusion: 道德化是复杂的、情境相关的语言现象，尽管大语言模型在特定条件下表现出一定能力，但仍面临巨大挑战。通过构建高质量标注数据集和开放资源，可推动道德话语与推理在NLP领域的进一步发展。

Abstract: Moralizations - arguments that invoke moral values to justify demands or positions - are a yet underexplored form of persuasive communication. We present the Moralization Corpus, a novel multi-genre dataset designed to analyze how moral values are strategically used in argumentative discourse. Moralizations are pragmatically complex and often implicit, posing significant challenges for both human annotators and NLP systems. We develop a frame-based annotation scheme that captures the constitutive elements of moralizations - moral values, demands, and discourse protagonists - and apply it to a diverse set of German texts, including political debates, news articles, and online discussions. The corpus enables fine-grained analysis of moralizing language across communicative formats and domains. We further evaluate several large language models (LLMs) under varied prompting conditions for the task of moralization detection and moralization component extraction and compare it to human annotations in order to investigate the challenges of automatic and manual analysis of moralizations. Results show that detailed prompt instructions has a greater effect than few-shot or explanation-based prompting, and that moralization remains a highly subjective and context-sensitive task. We release all data, annotation guidelines, and code to foster future interdisciplinary research on moral discourse and moral reasoning in NLP.

</details>


### [80] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500 是一个由临床医生整理的 500 条合成的澳大利亚全科医疗记录集合，涵盖课程基础临床广度、流行病学校准的发病率和多样的咨询情境。该数据集通过模拟真实医疗环境中的复杂性（如简略记录、拼写错误、患者依从性差等），旨在支持更具泛化能力的模型训练，并通过多维度验证确保其质量与真实性。它填补了澳大利亚在临床自然语言处理研究资源上的空白，同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 当前临床 NLP 模型训练受限于真实数据中常见病种的分布，难以覆盖罕见但重要的临床情况；同时，许多合成数据集过于理想化，无法反映真实医疗场景的复杂性。因此需要一个既符合临床教育标准、又具备真实医疗复杂性的合成数据集，以提升模型的泛化能力并推动澳大利亚全科医学的 NLP 研究。

Method: 基于 RACGP 2022 课程框架设计临床内容覆盖范围，结合 BEACH 研究的流行病学数据校准疾病发生率，并模拟多种咨询情境（如远程诊疗、患者不配合等）。采用人工与自动化相结合的方式生成医疗记录，刻意引入真实世界中的书写混乱与语义多样性，确保数据‘脏’而真实。

Result: SynGP500 在流行病学分布上与真实澳大利亚全科门诊数据高度一致；风格分析显示语言多样性高；语义覆盖广泛；在自监督医学概念提取任务中表现出更高的 F1 分数，证明其对下游任务的有效性。

Conclusion: SynGP500 提供了一个高质量、真实且隐私安全的合成数据集，适用于澳大利亚全科医学的临床 NLP 研究与教育，有助于开发更鲁棒、更具泛化能力的医疗人工智能系统。

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [81] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: PPPO提出一种新的强化学习方法，通过聚焦于生成输出的前缀部分来提升大语言模型的推理能力。该方法基于‘开端锁定效应’（BLE），即早期推理对后续推理有显著影响，并引入渐进式前缀保留和累积奖励机制以提高训练效率与效果，在多个推理任务上实现了18.02%的准确率提升，仅使用26.17%的训练标记。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习与可验证奖励（RLVR）方法对所有生成标记进行统一优化，忽视了哪些标记（如前缀）真正贡献于推理过程，导致大量资源浪费在低回报标记上，限制了高回报标记的改进潜力，降低了整体训练效率。

Method: 提出PPPO方法，利用‘开端锁定效应’（BLE）理论，聚焦于大语言模型推理的前缀阶段；引入两种策略：(a) 渐进式前缀保留，逐步增加训练中保留的前缀标记比例；(b) 续写累积奖励，通过采样多个续写序列并累加其得分作为奖励信号，缓解奖励偏差。

Result: 在多种推理任务上的实验表明，PPPO显著优于现有代表性RLVR方法，在仅使用26.17%训练标记的情况下，准确率提升达18.02%。

Conclusion: PPPO通过聚焦前缀推理过程并采用针对性优化策略，有效提升了大语言模型的推理能力，证明了早期推理阶段的关键作用及高效训练的可行性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [82] [Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues](https://arxiv.org/abs/2512.15302)
*Xiaotian Zhang,Yuan Wang,Ruizhe Chen,Zeya Wang,Runchen Hou,Zuozhu Liu*

Main category: cs.CL

TL;DR: PersonalAgent is a user-centric lifelong agent that continuously infers and adapts to individual user preferences by decomposing dialogues into single-turn interactions and treating preference inference as a sequential decision-making task. It outperforms prompt-based and policy optimization baselines in both ideal and noisy conversational settings, maintains cross-session consistency, and is validated by human evaluation for natural and coherent preference capture.


<details>
  <summary>Details</summary>
Motivation: Current alignment techniques fail to address long-term personalization and the initial user cold-start problem, as they focus on universal human values or static, single-turn preferences. There is a need for a system that can adaptively learn and maintain user preferences over time.

Method: PersonalAgent constructs a unified user profile by breaking down dialogues into single-turn interactions and modeling preference inference as a sequential decision-making process. This enables continuous learning and adaptation to evolving user preferences across sessions.

Result: PersonalAgent achieves superior performance compared to strong baselines in both idealized and noisy conversational contexts. It maintains consistent preference representation across sessions and is rated highly in human evaluations for capturing user preferences naturally and coherently.

Conclusion: Lifelong personalization is crucial for developing inclusive and adaptive conversational agents. PersonalAgent demonstrates the effectiveness of continuous, user-centric preference modeling in real-world interactive systems.

Abstract: The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.

</details>


### [83] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本研究系统评估了大型语言模型（LLMs）在沸石合成实验流程中的结构化信息提取任务中的表现，重点比较了零样本、少样本、事件特定和反思式四种提示策略。研究针对事件类型分类、触发文本识别、参数角色提取和参数值提取四个子任务，在ZSEE数据集上测试了六种先进LLM，发现模型在事件类型分类上表现良好（F1 80-90%），但在细粒度提取任务中表现一般（F1 50-65%）。GPT-5-mini对提示高度敏感，性能波动大。高级提示策略带来的提升有限，暴露出模型架构的根本局限性。错误分析揭示了系统性幻觉、过度泛化及对合成领域特异性细节捕捉不足等问题。研究强调，尽管LLMs具备高层次理解能力，但精确提取实验参数仍需领域适配模型，并提供了科学信息提取的量化基准。


<details>
  <summary>Details</summary>
Motivation: 现有方法未系统评估大型语言模型在沸石合成实验流程信息提取中的应用效果，尤其缺乏对不同提示策略有效性的深入分析，限制了其在材料发现中的实际应用。

Method: 采用四种提示策略（零样本、少样本、事件特定、反思式）在六个先进的LLM上进行实验，基于ZSEE数据集（1,530条标注句子）评估事件类型分类、触发文本识别、参数角色提取和参数值提取四项任务的表现。通过对比不同模型与策略下的F1分数，进行定量分析与误差诊断。

Result: 事件类型分类表现优异（F1 80-90%），但参数角色和参数值提取任务表现中等（F1 50-65%）。GPT-5-mini表现出显著的提示敏感性（F1波动11-79%）。高级提示策略相较于零样本策略提升有限，表明模型存在根本性架构缺陷。误差分析显示存在系统性幻觉、过度泛化及对合成领域特异性理解不足的问题。

Conclusion: 尽管大型语言模型在高层次理解方面表现良好，但精确提取实验参数仍需领域适应性模型。当前通用模型在细粒度信息提取任务中存在明显局限，需进一步优化或开发专用模型以支持科学发现。研究为科学信息提取提供了可量化的基准。

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [84] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: 本研究运用Brookes的类别分散度测量法（Δ）分析当代阿拉伯应用语言学研究的主题结构，基于2019至2025年1,564篇文献的实证数据，计算得Δ = 0.194，表明该领域存在极高的主题分散性，呈现显著异质性而非集中性。计算结果揭示计算语言学虽为重要分支但非主导力量，与社会语言学、语言教学等其他子领域共存发展。研究澄清了Brookes公式的正确应用方式，展示了其在学科结构刻画中的有效性，并提供了一种可复制的书目计量方法，适用于跨领域的学科结构评估。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示当代阿拉伯应用语言学研究的主题分布特征，克服传统研究中对学科集中性的假设，通过量化方法准确刻画其多元、分散的学术生态。

Method: 采用Brookes的类别分散度指数（Δ）对1,564篇2019–2025年发表的阿拉伯应用语言学文献进行分类分析，依据八大学科子领域划分，计算Δ值以评估主题结构的集中程度。

Result: Δ = 0.194，显示高度主题分散；计算语言学虽具影响力但不主导，多个子领域并行发展，体现学科多样性。

Conclusion: 该研究证实了Brookes公式在学科结构分析中的适用性，提出一种可重复的书目计量框架，有助于更准确理解多学科交叉领域的知识格局。

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [85] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: 该研究揭示了诗歌形式的提示词可作为对抗性机制，显著提升大语言模型的安全漏洞，尤其在葡萄牙语等复杂语言中存在评估空白。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型对提示词形式变化的脆弱性，特别是通过诗歌形式绕过安全防护机制，揭示当前对齐方法的深层缺陷。

Method: 对比分析不同语言（尤其是葡萄牙语）中诗句与散文提示的效果，测试模型在韵律、格律和修辞变化下的响应，使用来自MLCommons AILuminate的基准测试。

Result: 以诗歌形式呈现的指令成功率高达62%（手动）和43%（自动），部分模型单轮交互成功率超过90%，表明即使经过强化学习与宪法人工智能训练的系统也易受攻击。

Conclusion: 当前对齐机制严重依赖表面模式，对形式变异敏感，亟需在多语言、特别是高复杂度语言如葡萄牙语中引入更全面的评估框架。

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [86] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Denser提出一种双密度推理框架，通过分离中间推理与最终答案的信息密度，在保持或提升准确率的同时，将令牌消耗降低最多62%，显著提升复杂多步推理任务的效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务中对中间推理和最终答案采用统一的语言密度，导致计算效率低下。由于推理过程主要服务于模型自身计算，而回答则面向人类理解，因此可分别优化其信息密度以提高效率。

Method: Denser框架包含三个组件：输入问题分析模块、高密度压缩推理机制（用于高效中间计算）、以及将压缩推理结果转换为人类可读答案的答案生成组件，实现推理与回答阶段的不同密度优化。

Result: 在多个推理问答基准测试中，Denser相比标准链式思维方法减少高达62%的令牌消耗，且在复杂多步推理任务中表现尤为突出，同时保持或提升了准确性。

Conclusion: 通过区分推理与回答阶段的信息密度需求，Denser实现了显著的计算效率提升，为大语言模型在复杂推理任务中的实际应用提供了更高效的解决方案。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [87] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE平台将每日新闻转化为每周一次的决策可用洞察，针对芬兰应用科学大学。该系统爬取并版本化新闻，应用大学特定的相关性过滤，嵌入内容，将其分类到PESTEL维度，并构建一个时间依赖的递归摘要图（TRSG）：通过两层聚类由大语言模型总结并每周重新计算。轻量级变化检测器突出显示新增、删除或更改的内容，并将差异分组为PESTEL感知的主题分析。论文详细描述了处理流程，讨论了使系统在生产中稳定的设计选择，并提出了课程智能使用案例及评估计划。


<details>
  <summary>Details</summary>
Motivation: 将每日新闻转化为可操作的周度决策洞察，支持教育机构的战略规划与课程优化，同时实现对环境变化的动态监控和快速响应。

Method: 采用新闻爬取与版本化、大学相关性过滤、内容嵌入、PESTEL分类、构建时间依赖的递归摘要图（TRSG），结合两层聚类与大语言模型生成摘要，利用轻量级变化检测识别更新，并按主题分组进行分析。

Result: 成功构建了一个稳定运行于生产环境的自动化新闻分析系统，能够每周生成结构化、可解释且与教育战略相关的洞察，支持课程智能等实际应用。

Conclusion: ORACLE系统有效实现了从原始新闻到高价值决策信息的转化，其模块化设计与可扩展架构适用于多种教育与战略分析场景，具备良好的实用性和可推广性。

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [88] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: 本研究探索了使用大语言模型（MI-LLMs）实现可扩展的动机访谈（MI）替代方案，通过在高质量中文心理咨询语料库上微调三个中文开源大模型，生成符合MI风格的对话。结果显示，微调后的模型在自动评估指标和专家人工编码中均表现出接近真实MI对话的技巧性与关系性，但在复杂反映和反映转提问比例方面仍有不足。研究为通用大模型赋予核心MI行为提供了初步证据，提示未来需扩大数据规模、提升复杂技能训练并开展真实世界干预试验。


<details>
  <summary>Details</summary>
Motivation: 动机访谈（MI）虽有效，但受限于对高技能人类咨询师的依赖，难以大规模推广。因此，亟需开发可扩展的替代方案，以支持健康行为改变的广泛实施。

Method: 收集五个中文心理辅导语料库，利用GPT-4基于MI指导的提示词，将其中两个高质量数据集（CPsyCounD和PsyDTCorpus）转化为2,040段多轮MI风格对话；其中2,000段用于训练，40段用于测试。选用三个中文可用的开源大模型（Baichuan2-7B-Chat、ChatGLM-4-9B-Chat、Llama-3-8B-Chinese-Chat-v2）进行微调，构建MI-LLMs。采用基于回合的自动评估指标及专家手动编码（使用MITI 4.2.1编码手册）进行评估。

Result: 所有三个模型在微调后，BLEU-4和ROUGE分数显著优于基础模型；人工编码显示MI-LLMs在技术与关系层面的总分以及MI一致性比率接近真实MI对话，但复杂反射和反射转提问的比例仍较低。

Conclusion: MI导向的微调能够使通用大模型具备核心的MI一致咨询行为，为实现人工智能辅助的健康行为改变支持提供了一条可扩展路径，但仍需在数据规模、复杂MI技能训练及真实世界干预试验方面进一步研究。

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [89] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 本研究首次在孟加拉语中进行大规模抗议活动期间的情感分析，构建了包含2,028个标注新闻标题的数据集，分类为愤怒、希望与绝望，并通过LDA识别出政治腐败和公众抗议等主题。模型性能超越多语言Transformer（mBERT: 67%，XLM-RoBERTa: 71%）及传统机器学习方法（SVM与逻辑回归均为70%），验证了语言特定模型在政治动荡时期情感分析中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有情感分析研究主要集中在选举和社会媒体趋势，缺乏对孟加拉语在社会动荡期间情绪动态的理解，因此需要填补这一空白。

Method: 收集并标注2,028条来自主要Facebook新闻门户的孟加拉语新闻标题，使用LDA进行主题建模，并对比多语言Transformer与传统机器学习模型在情感分类上的表现。

Result: 所提出的方法在情感分类任务中表现优于mBERT（67%）、XLM-RoBERTa（71%）以及SVM和逻辑回归（均为70%），表明语言特定模型在处理孟加拉语政治危机文本时更具优势。

Conclusion: 本研究揭示了在政治动荡期间公众情绪的变化模式，强调了开发针对特定语言的模型在情感分析中的重要性，为未来在类似情境下的舆情监测提供了有效方法。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [90] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为CTKVR的新颖的分层KV检索方案，通过利用相邻位置查询向量在旋转位置编码（RoPE）后的高度相似性，实现高效且准确的长上下文推理。该方法采用两阶段检索策略：预填充阶段预先计算轻量级中心点用于粗粒度索引，随后进行细粒度的令牌级精炼以精确检索KV缓存。同时结合CPU-GPU协同优化系统，显著提升检索效率。实验表明，CTKVR在多个基准测试中表现优异，精度损失低于1%，并在不同GPU硬件上实现了3至4倍的吞吐量加速，尤其在96K上下文长度下效果显著。


<details>
  <summary>Details</summary>
Motivation: 长上下文场景下的大语言模型推理面临高内存开销和延迟问题，现有动态KV选择方法在块级索引与令牌级索引之间存在准确性与效率的权衡，亟需一种兼顾两者优势的新方法。

Method: 提出基于中心点-令牌的两阶段KV检索机制（CTKVR），利用RoPE后相邻查询向量的高度相似性，在预填充阶段生成轻量级中心点进行粗粒度索引，并在检索阶段进行令牌级精炼；结合CPU-GPU协同执行优化索引构建与搜索过程。

Result: CTKVR在多个基准测试中实现接近无损的精度（<1%下降），并在Llama-3-8B和Yi-9B模型上于96K上下文长度下分别获得3倍和4倍的吞吐量加速，适用于多种GPU硬件平台。

Conclusion: CTKVR通过巧妙利用查询向量的位置相似性与高效的两阶段检索设计，在保持高精度的同时大幅提升了长上下文推理的效率，为大语言模型在实际应用中的部署提供了有力支持。

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [91] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: 本文提出一种基于客观标准自动创建特定领域词表（SWL）的方法，相较于传统通用服务词表（GSL）和行业标准NGSL，该方法能以更少词汇实现95%语言理解覆盖率，具有可扩展性和个性化优势。


<details>
  <summary>Details</summary>
Motivation: 传统GSL的构建依赖语言学专家、主观判断和大量时间，效率低且难以适应不同学习者需求，亟需一种自动化、客观化、可定制的替代方案。

Method: 通过建立基于语料库的客观分析模型，生成针对特定子集的专用词表（SWL），并以覆盖率达95%为目标进行优化。

Result: 所生成的SWL在达到95%语言理解覆盖率时所需词汇量显著少于NGSL，表现优于行业标准，且过程可自动化、可扩展。

Conclusion: 基于客观标准的SWL构建方法是高效、实用的语言学习资源优化策略，能够为全球学习者提供个性化的词汇学习支持。

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [92] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: 本文系统研究了中文字符分解技术在多词表达（MWE）感知神经机器翻译（NMT）中的应用，探讨其如何提升中文词汇与字符的语义表示，并有效应对中文MWE翻译挑战。


<details>
  <summary>Details</summary>
Motivation: 中文等亚洲语言在处理多词表达（MWEs）方面存在显著困难，且现有基于子词建模的方法（如BPE）不适用于汉字等表意文字，导致相关研究进展滞后。

Method: 采用中文字符分解技术，对中文文本进行细粒度语义解析，结合神经机器翻译模型，评估其在提升MWE识别与翻译表现上的有效性。

Result: 实验表明，字符分解技术能有效增强中文词汇和字符的语义表示，显著改善复杂、非字面意义的多词表达的翻译准确率，尤其在罕见或习语性表达中表现突出。

Conclusion: 中文字符分解技术为解决中文MWE翻译难题提供了有效路径，有助于推动中文及其他表意文字在自然语言处理任务中的发展。

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [93] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: Bolmo 是首个在 1B 和 7B 参数规模上具有竞争力的开放字节级语言模型家族。它通过将现有的子词级语言模型进行字节化（byteification）训练，克服了传统子词分词的局限性，如字符理解不足和固定词汇表带来的效率问题。Bolmo 的架构专门设计用于字节化，实现了与子词级模型之间的高效精确蒸馏，仅需不到 1% 的预训练数据即可完成转换。该模型在字符理解等任务上显著优于以往字节级模型，部分任务甚至超越源子词模型，同时在其他任务上接近原模型表现。此外，Bolmo 可通过高令牌压缩比实现与子词模型相当的推理速度，并可低成本、高效地利用现有子词模型生态进行后训练。最终，字节级模型成为与子词模型相媲美的实用选择。


<details>
  <summary>Details</summary>
Motivation: 解决现有字节级语言模型在训练成本、字符理解能力及与子词模型性能差距方面的不足，提升字节级模型的实用性与竞争力。

Method: 采用字节化方法，将已有子词级语言模型转化为字节级模型；通过专门设计的架构实现高效的精确蒸馏，仅使用极小比例的额外训练数据完成转换。

Result: Bolmo 在字符理解任务上显著优于以往字节级模型，部分任务性能超越源子词模型，推理速度与子词模型相当，且支持低成本后训练，具备广泛应用潜力。

Conclusion: Bolmo 成功使字节级语言模型成为在多种场景下可与子词级模型竞争的实用技术选择。

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [94] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: 本文提出PsyDefConv对话语料库和DMRS Co-Pilot工具，用于标注和分析求助者在对话中使用的心理防御机制。语料库包含200段对话、4709个话语，其中2336个为求助者发言，标注一致性Cohen's kappa达0.639。实验表明，Co-Pilot可减少22.4%的标注时间，并在证据支持、临床合理性和洞察力方面得分均超过4.4（7分制）。基于大模型的基准测试显示，当前方法仍有明显提升空间，最佳宏平均F1仅为约30%，且倾向于高估成熟防御。研究还发现成熟防御最常见，且存在情绪特异性偏差。所有数据与代码将公开，以推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 心理防御机制是人们应对心理压力的重要策略，但其测量在临床对话中复杂且困难。现有方法缺乏可靠、可扩展的标注工具与语料库，限制了对防御机制的语言学与临床研究。因此亟需一个高质量、结构化的对话语料库及辅助标注系统。

Method: 构建PsyDefConv对话语料库，收集真实临床对话中的求助者发言；设计并实现四阶段自动化预标注系统DMRS Co-Pilot，结合语言模型与临床规则提供证据支持、临床合理性与洞察力评分；通过专家评审与对照实验评估系统性能；利用语料进行防御类型分布分析与大模型基准测试。

Result: DMRS Co-Pilot显著降低标注时间（平均减少22.4%），专家评价显示其在证据（4.62）、临床合理性（4.44）和洞察力（4.40）上表现良好；语料分析揭示成熟防御最普遍，且存在情绪特异性差异；大模型在零样本与微调设置下表现有限，最高宏F1仅约30%，且倾向高估成熟防御。

Conclusion: 本研究成功构建了首个大规模、高质量的心理防御标注对话语料库，并开发出有效的辅助标注工具。该成果为语言与心理健康的交叉研究提供了坚实基础，未来可通过开放资源推动更精准的防御机制识别与干预研究。

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [95] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: 本文探讨在关键信息流程中引入大语言模型（LLM）时如何确保其安全与可靠性，强调应关注评估过程中获得的证据类型，尤其是采用LLM作为评判者（LaJ）的框架。通过结合加权指标、上下文敏感性判断错误严重性，并设置触发人工审查的置信度阈值，可在无法实现确定性评估的情况下降低错误风险。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型被广泛应用于文本处理任务，可能替代人类在瓶颈环节中的角色，但在安全关键场景中，如术后护理分诊或核设施访问调度，模型出错可能导致严重后果。因此需要建立可靠的评估机制以确保LLM的安全应用。

Method: 提出采用多维度加权评估指标，结合上下文敏感性分析错误严重程度，并设计基于一致性水平的置信度阈值，当多个LaJ评判结果不一致时自动触发人工复核。

Result: 该方法能够在缺乏确定性评估的前提下有效降低关键任务中的错误风险，提升LLM在安全敏感场景下的可信度与可靠性。

Conclusion: 为保障大语言模型在关键信息流中的安全使用，应聚焦于评估证据的质量，通过综合量化指标、上下文感知和动态人机协同机制，构建可信赖的评估体系。

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [96] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: 该研究系统评估了全监督微调（SFT）与参数高效微调（PEFT，如LoRA）在下游问答任务中的表现，通过秩扫描分析了二者在不同配置下的性能权衡，并比较了其在域内和域外适应下的泛化能力与任务遗忘现象。结果表明，LoRA在特定秩值下可达到甚至超越SFT的性能，尤其在推理任务中表现优异。同时，通过谱特征与层间注意力结构分析，揭示了表示漂移与注意力模式变化的内在机制。


<details>
  <summary>Details</summary>
Motivation: 当前对参数高效微调（PEFT）方法如LoRA的配置影响（如秩大小）在下游问答任务和泛化能力方面的理解仍不充分，亟需系统性评估以指导实际应用。

Method: 在多个推理与回忆数据集上进行大规模实验，执行不同秩值的LoRA微调，对比SFT与PEFT的性能；采用谱分析与层间注意力结构分析探究模型内部表征变化。

Result: LoRA在特定秩值下表现优于或媲美SFT，尤其在推理任务中；不同方法在域内/域外适应中表现出不同的泛化行为与任务遗忘特性；内部表征分析显示存在显著的表示漂移与注意力结构变化。

Conclusion: LoRA作为一种高效的微调方法，在合理配置下可实现与全微调相当甚至更优的性能，尤其适用于推理类任务，且其内部表征变化提供了对模型行为的深入理解。

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [97] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: PPSEBM 是一种结合能量模型（EBM）与渐进参数选择（PPS）的新框架，用于缓解自然语言处理中的持续学习灾难性遗忘问题。它通过为每个新任务分配特定参数，并利用 EBM 生成先前任务的伪样本以指导参数选择，从而提升模型对旧知识的保留能力。实验表明，该方法在多个 NLP 基准上优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中因学习新任务而导致旧任务性能下降的灾难性遗忘问题，特别是在自然语言处理领域缺乏有效应对策略的背景下。

Method: 采用渐进参数选择（PPS）为每项新任务分配独立参数，并引入能量基模型（EBM）生成历史任务的代表性伪样本，这些伪样本用于指导参数选择过程，增强知识保留。

Result: 在多个自然语言处理基准测试中，PPSEBM 显著优于现有的持续学习方法，在保持旧任务性能的同时有效适应新任务。

Conclusion: PPSEBM 提供了一种高效且稳健的解决方案，显著缓解了持续学习中的灾难性遗忘问题，为 NLP 领域的持续学习提供了新的思路和实践基础。

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [98] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出了一种通用的LatentQA方法，通过训练大语言模型（LLM）直接以自身激活值为输入并回答关于这些激活值的自然语言问题。研究发现，即使在远离训练分布的场景下，激活预言机（AOs）仍能有效恢复模型中微调进来的信息（如传记知识或不良倾向），且随着训练数据多样性的增加，性能持续提升。在四个下游任务中，最优的AOs表现优于或匹配已有白盒基线，其中在三个任务上为最佳方法。结果表明，多样化训练使模型具备了泛化地解释和表述激活信息的能力。


<details>
  <summary>Details</summary>
Motivation: 现有解释大语言模型激活的方法通常复杂且专用，而近期提出的LatentQA方法虽简化了流程，但仅限于狭窄任务设置。本文旨在从更通用的角度评估该方法，探索其在广泛场景下的能力与可扩展性。

Method: 采用多任务训练策略，包括分类任务和自监督上下文预测任务，训练大语言模型以自然语言形式回答关于自身激活值的问题，构建激活预言机（AOs）。通过在不同分布外的任务中测试其性能，分析训练数据多样性对效果的影响。

Result: AOs能在未接触过微调模型激活的情况下，成功恢复模型内部隐含的信息；在四个下游任务中，即使是窄范围训练的模型也表现出良好泛化能力；引入更多样化的训练数据后性能持续提升，最佳模型在三项任务中超越所有先前方法，在第四项任务上持平白盒基线。

Conclusion: 多样化训练使得大语言模型具备了通用的激活解释能力，能够以自然语言形式揭示模型内部信息，表明LatentQA是一种高效、可扩展且具有广泛适用性的解释框架。

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [99] [Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning](https://arxiv.org/abs/2512.14709)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文将Transformer中的自注意力机制和残差连接解释为近似向量符号架构（VSA）的实现，其中查询与键定义角色空间，值编码填充物，注意力权重执行软解绑，残差连接实现多个绑定结构的叠加。通过这一代数视角，论文关联了Transformer内部机制与思维链追踪、基于程序的推理及记忆增强工具使用，并解释了变量混淆、逻辑相关提示间不一致等典型失败模式。基于此观点，提出受VSA启发的架构偏置（如显式绑定/解绑头、超维记忆层）和训练目标以促进角色-填充分离与鲁棒叠加。最后，提出衡量“VSA相似性”与逻辑组合性的指标，并指出理论与架构上的开放问题。总体而言，将注意力视为软向量符号计算为构建更可解释、逻辑可靠的推理系统提供了原则性路径。


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型虽表现出类推理行为，但在需要稳定符号操作的任务上仍脆弱。现有方法缺乏对内部机制与符号推理之间关系的统一理解，难以解释其失败模式并指导可靠推理系统的构建。因此亟需一种能贯通内在机制与符号操作的理论框架。

Method: 从向量符号架构（VSA）出发，将Transformer中的自注意力与残差流重新诠释为软符号计算过程：查询和键对应角色空间，值表示填充物，注意力权重实现软解绑，残差连接支持多结构叠加。利用该代数视角分析思维链、程序推理与记忆工具使用，并诊断典型错误。进一步设计受VSA启发的架构改进与训练目标，提出可测量的评估指标。

Result: 成功建立自注意力与符号操作之间的映射关系，解释了变量混淆、逻辑不一致等现象；提出的架构改进与训练策略有助于提升模型在符号任务上的稳定性与可解释性；提出了可用于评估推理系统逻辑组合能力的新指标。

Conclusion: 将注意力机制视为软向量符号计算提供了一个统一且原则性的视角，有助于理解当前大模型的行为，并为构建更可靠、可解释的逻辑推理系统指明方向。未来工作应聚焦于理论深化与架构创新。

Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring "VSA-likeness" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.

</details>


### [100] [IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection](https://arxiv.org/abs/2512.14792)
*Roman Nekrasov,Stefano Fossati,Indika Kumara,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.AI

TL;DR: 该研究通过注入结构化配置知识，显著提升了大语言模型（LLM）生成正确且意图对齐的基础设施即代码（IaC）的能力，特别是在Terraform场景下。通过增强IaC-Eval基准测试并引入云模拟与自动错误分析，提出了一种新的错误分类体系，并系统评估了从基础检索增强生成（RAG）到图谱RAG等知识注入方法。实验表明，技术验证成功率从27.1%提升至75.3%，整体成功率增至62.6%，但意图一致性仍停滞，揭示出‘正确性-一致性鸿沟’：LLM虽能成为熟练‘编码者’，却难以胜任复杂的‘架构设计’任务。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生成基础设施即代码（IaC）时存在成功率低、意图对齐差的问题，尤其在复杂云资源配置中表现不佳。为提升生成质量，亟需引入结构化知识以增强模型对配置逻辑和资源依赖的理解，从而实现更准确、更符合用户真实需求的代码输出。

Method: 构建并扩展IaC-Eval基准测试，集成云环境模拟与自动化错误分析；提出新型错误分类体系；设计并对比多种知识注入策略，包括朴素检索增强生成（RAG）、语义增强的图谱RAG及资源间依赖建模方法；通过控制实验评估不同方法在技术正确性和意图对齐上的表现。

Result: 知识注入使技术验证成功率从27.1%提升至75.3%，整体成功率达到62.6%，显著改善了代码的可执行性。然而，意图对齐性能未见明显提升，表明模型在理解用户深层需求方面仍存在瓶颈，形成‘正确性-一致性鸿沟’。

Conclusion: 尽管结构化知识注入能有效提升LLM生成IaC的技术准确性，但其在捕捉复杂用户意图方面能力有限。未来工作需聚焦于增强模型的架构理解与上下文推理能力，以弥合‘编码’与‘设计’之间的差距。

Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a "Correctness-Congruence Gap" where LLMs can become proficient "coders" but remain limited "architects" in fulfilling nuanced user intent.

</details>


### [101] [AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally](https://arxiv.org/abs/2512.14910)
*Nadine Angela Cantonjos,Arpita Biswas*

Main category: cs.AI

TL;DR: AgroAskAI is a multi-agent reasoning system designed to support climate adaptation decisions in agriculture, especially for vulnerable rural communities. It uses role-specialized, autonomous agents with a chain-of-responsibility structure, integrates real-time data, and includes governance to reduce hallucination and ensure context-aware, actionable outputs. The system supports multilingual interactions and demonstrates improved performance in generating grounded, inclusive, and practical recommendations through experimental validation.


<details>
  <summary>Details</summary>
Motivation: Agricultural regions in rural areas are increasingly affected by climate-related risks such as droughts, heavy rainfall, and shifting weather patterns. Existing decision-making tools are limited in handling dynamic, complex agricultural challenges. There is a need for adaptive, intelligent, and inclusive systems that can support sustainable farming practices under climate uncertainty.

Method: AgroAskAI employs a modular, role-specialized multi-agent architecture based on a chain-of-responsibility framework. Each agent performs specific functions (e.g., data analysis, risk assessment, strategy generation) and collaborates dynamically. The system integrates real-time datasets and tools, incorporates internal feedback mechanisms to prevent hallucination, and ensures coherence and local relevance. Multilingual support enables accessibility for non-English-speaking farmers.

Result: Experiments show that AgroAskAI produces more actionable, accurate, and contextually relevant responses compared to baseline models when addressing climate adaptation queries in agriculture. With prompt refinement and additional tools, the system significantly improves output quality and inclusivity, demonstrating strong potential for real-world deployment in vulnerable rural settings.

Conclusion: AgroAskAI represents a significant advancement in agentic AI for climate adaptation in agriculture. Its dynamic, collaborative, and context-aware design enables sustainable and accountable decision support, particularly for underserved communities. The system exemplifies how responsible AI can be leveraged to enhance resilience in climate-vulnerable agricultural regions.

Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.

</details>


### [102] [Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation](https://arxiv.org/abs/2512.15033)
*Xidan Song,Weiqi Wang,Ruifeng Cao,Qingya Hu*

Main category: cs.AI

TL;DR: This paper introduces a Geometric Stability Framework to evaluate LLMs' true spatial reasoning in chess beyond standard accuracy. Results reveal a paradox: high accuracy doesn't imply robustness—GPT-5.1 collapses under transformations, while Claude Sonnet 4.5 and Kimi K2 Turbo excel. Gemini 2.5 Flash best detects illegal moves. The study advocates geometric stability as a critical, independent benchmark for assessing genuine reasoning in LLMs.


<details>
  <summary>Details</summary>
Motivation: Standard accuracy metrics in LLM evaluation fail to distinguish between genuine geometric reasoning and memorization of canonical board states, especially in complex domains like chess.

Method: Proposing a Geometric Stability Framework to test model consistency under invariant transformations (e.g., rotation, mirror symmetry, color inversion, format conversion) using a dataset of ~3,000 chess positions.

Result: A significant Accuracy-Stability Paradox is observed: models like GPT-5.1 achieve high accuracy but suffer catastrophic error rate increases (>600%) under geometric perturbations; Claude Sonnet 4.5 and Kimi K2 Turbo show superior robustness across transformations; Gemini 2.5 Flash leads in illegal state rejection (96.0%).

Conclusion: Geometric stability serves as an essential, orthogonal metric for evaluating AI reasoning capabilities, effectively disentangling true spatial logic from data contamination and overfitting.

Abstract: The evaluation of Large Language Models (LLMs) in complex reasoning domains typically relies on performance alignment with ground-truth oracles. In the domain of chess, this standard manifests as accuracy benchmarks against strong engines like Stockfish. However, high scalar accuracy does not necessarily imply robust conceptual understanding. This paper argues that standard accuracy metrics fail to distinguish between genuine geometric reasoning and the superficial memorization of canonical board states. To address this gap, we propose a Geometric Stability Framework, a novel evaluation methodology that rigorously tests model consistency under invariant transformations-including board rotation, mirror symmetry, color inversion, and format conversion. We applied this framework to a comparative analysis of six state-of-the-art LLMs including GPT-5.1, Claude Sonnet 4.5, and Kimi K2 Turbo, utilizing a dataset of approximately 3,000 positions. Our results reveal a significant Accuracy-Stability Paradox. While models such as GPT-5.1 achieve near-optimal accuracy on standard positions, they exhibit catastrophic degradation under geometric perturbation, specifically in rotation tasks where error rates surge by over 600%. This disparity suggests a reliance on pattern matching over abstract spatial logic. Conversely, Claude Sonnet 4.5 and Kimi K2 Turbo demonstrate superior dual robustness, maintaining high consistency across all transformation axes. Furthermore, we analyze the trade-off between helpfulness and safety, identifying Gemini 2.5 Flash as the leader in illegal state rejection (96.0%). We conclude that geometric stability provides an orthogonal and essential metric for AI evaluation, offering a necessary proxy for disentangling reasoning capabilities from data contamination and overfitting in large-scale models.

</details>


### [103] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: 本文提出了一种受人类层次化推理启发的弹性推理框架CogER，通过动态选择适合查询难度的推理策略，平衡了推理效率与准确性。该框架将查询复杂度划分为多个层级，并为每个层级设计定制化处理策略；利用强化学习训练一个CogER-Agent，基于解决方案质量与计算成本的权衡自动选择最优策略。此外，引入认知工具辅助推理，使LLM能自主调用外部工具。实验表明，CogER在域内和域外任务上分别取得至少13%和8%的相对性能提升，优于现有测试时扩展方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型推理策略主要依赖模型自身，采用快速或慢速模式（如o1思维），难以在不同难度的查询间有效平衡推理效率与准确性。因此，亟需一种能够根据查询复杂度动态调整推理策略的方法。

Method: 提出CogER框架，将查询复杂度划分为多个预定义层级，每个层级对应特定处理策略；将策略选择建模为马尔可夫决策过程，使用强化学习训练CogER-Agent，其奖励函数综合考虑解的质量与计算开销；引入认知工具辅助推理机制，支持模型在思维链中自主调用外部工具。

Result: 在多项任务上，CogER显著优于当前最先进的测试时扩展方法，在域内任务上平均精确匹配率提升至少13%，在域外任务上提升至少8%。

Conclusion: CogER通过模仿人类分层推理机制，实现了对不同难度查询的自适应高效推理，结合强化学习与工具调用能力，有效提升了大语言模型在复杂任务中的表现与资源利用效率。

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [104] [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)
*Mohsen Nafar,Michael Römer,Lin Xie*

Main category: cs.AI

TL;DR: 本文提出一种基于聚类的变量排序框架，用于改进松弛决策图（DD）在离散优化中的性能。通过将变量聚类并减少动态排序启发式算法的搜索空间，该方法显著降低了计算开销。研究提出了两种策略：Cluster-to-Cluster（按簇顺序处理，使用问题特定聚合标准）和Pick-and-Sort（从各簇中迭代选择并排序代表性变量）。结合最大权重独立集问题（MWISP）的理论分析，设计了确定聚类数量的策略，并将其集成到基于DD的分支定界算法中。实验表明，该方法在多个基准实例上均显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有松弛决策图依赖于变量顺序和合并决策来获得紧致的对偶界，但动态变量排序虽能提升界的质量，却因全局评估带来高计算开销。因此需要一种更高效的方法来平衡排序质量与计算效率。

Method: 提出一种基于聚类的变量排序框架，先将变量划分为若干簇，再在簇间或簇内采用不同策略进行排序：一是按簇顺序处理并使用问题特异性聚合指标；二是迭代选取各簇代表变量并排序，以兼顾局部多样性与启发式引导。结合理论分析确定聚类数策略，并嵌入到基于DD的分支定界算法中。

Result: 在最大权重独立集问题（MWISP）的多个基准实例上，所提方法相比标准动态变量排序基线，显著降低了计算成本，且保持了良好的解质量。

Conclusion: 所提出的聚类驱动变量排序框架有效减少了动态排序的计算负担，同时维持甚至提升了松弛决策图的对偶界质量，为高效精确求解离散优化问题提供了新思路。

Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.

</details>


### [105] [Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis](https://arxiv.org/abs/2512.15295)
*Toshihide Ubukata,Enhong Mu,Takuto Yamauchi,Mingyue Zhang,Jialong Li,Kenji Tei*

Main category: cs.AI

TL;DR: GCRL integrates Graph Neural Networks (GNNs) into reinforcement learning (RL)-based controller synthesis to improve exploration by encoding the history of LTS exploration into a graph structure, enabling broader context awareness. It outperforms state-of-the-art methods in four out of five benchmark domains, except in highly symmetric, locally interacting environments.


<details>
  <summary>Details</summary>
Motivation: Existing RL-based exploration policies in controller synthesis rely on fixed rules or limited feature sets, failing to capture broader contextual information over time. This limits learning efficiency and generalization.

Method: GCRL uses GNNs to model the history of LTS exploration as a graph, allowing the policy to learn from non-current features and long-term context, thereby improving decision-making during synthesis.

Result: GCRL demonstrates superior learning efficiency and generalization across four out of five benchmark domains. It underperforms only in a domain with high symmetry and strictly local interactions.

Conclusion: Integrating GNNs into RL-based exploration significantly enhances controller synthesis by leveraging historical context, making GCRL a promising approach for complex, dynamic systems, though challenges remain in highly symmetric, localized environments.

Abstract: Controller synthesis is a formal method approach for automatically generating Labeled Transition System (LTS) controllers that satisfy specified properties. The efficiency of the synthesis process, however, is critically dependent on exploration policies. These policies often rely on fixed rules or strategies learned through reinforcement learning (RL) that consider only a limited set of current features. To address this limitation, this paper introduces GCRL, an approach that enhances RL-based methods by integrating Graph Neural Networks (GNNs). GCRL encodes the history of LTS exploration into a graph structure, allowing it to capture a broader, non-current-based context. In a comparative experiment against state-of-the-art methods, GCRL exhibited superior learning efficiency and generalization across four out of five benchmark domains, except one particular domain characterized by high symmetry and strictly local interactions.

</details>


### [106] [ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I](https://arxiv.org/abs/2512.15298)
*Seok-Hyun Ga,Chun-Yen Chang*

Main category: cs.AI

TL;DR: 本研究以2025年韩国大学学力水平考试地球科学Ⅰ部分为案例，评估GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro等先进大语言模型在多模态科学推理中的表现与认知局限。通过全页输入、单题输入和优化多模态输入三种条件测试发现，非结构化输入导致性能显著下降，主要源于文本分割与光学字符识别（OCR）失败。即使在优化条件下，模型仍存在根本性推理缺陷。定性分析揭示‘感知错误’占主导，反映出‘感知-认知鸿沟’——模型虽能识别视觉数据却无法理解图示符号意义；同时存在‘计算-概念脱节’与‘过程幻觉’现象，即模型可完成计算但无法应用科学概念，或跳过视觉验证而依赖未经证实的背景知识。研究提出针对这些弱点设计‘抗AI题目’，以区分真实学生能力与AI生成答案，保障评估公平性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在教育领域的广泛应用，学生利用AI完成作业的现象日益普遍，引发对学术诚信和评估有效性的担忧。现有评估体系难以甄别学生真实能力与AI辅助结果，亟需深入理解大模型在复杂多模态任务中的认知局限，从而设计出能够抵御AI干扰的评估题目。

Method: 选取2025年韩国大学学力水平考试地球科学Ⅰ部分作为测试数据，采用三种实验条件（全页输入、单题输入、优化多模态输入），对GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro三类先进大语言模型进行多模态科学推理能力测试。通过定量分析评估模型在不同输入结构下的表现，并结合定性分析识别其典型错误模式，如感知错误、计算与概念脱节、过程幻觉等。

Result: 结果显示，非结构化输入显著降低模型性能，主要因OCR失败和内容分割问题。即便在优化输入条件下，模型仍普遍存在感知-认知鸿沟、计算-概念脱节及过程幻觉等根本性缺陷。定性分析确认这些错误具有系统性和可预测性，表明模型在理解图示符号意义、应用科学概念和验证推理过程方面存在明显短板。

Conclusion: 本研究揭示了当前主流大语言模型在多模态科学推理中的深层认知局限，尤其在感知与理解之间存在显著差距。基于这些发现，可设计针对性的‘抗AI题目’，利用模型的认知弱点来区分真实学生作答与AI生成内容，从而维护教育评估的公平性与有效性。

Abstract: The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that "Perception Errors" were dominant, highlighting a "Perception-Cognition Gap" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a "Calculation-Conceptualization Discrepancy," successfully performing calculations while failing to apply the underlying scientific concepts, and "Process Hallucination," where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing "AI-resistant questions" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.

</details>


### [107] [Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations](https://arxiv.org/abs/2512.15388)
*Reinhard Moratz,Niklas Daute,James Ondieki,Markus Kattenbeck,Mario Krajina,Ioannis Giannopoulos*

Main category: cs.AI

TL;DR: This study improves LLMs' ability to generate pedestrian-friendly route instructions by incorporating qualitative spatial relations, resulting in clearer and more intuitive guidance.


<details>
  <summary>Details</summary>
Motivation: To enhance the ability of Large Language Models (LLM) to generate effective route instructions for pedestrians using qualitative spatial relations.

Method: The paper proposes a method that leverages qualitative spatial reasoning to improve LLMs' capability in generating intuitive and context-aware route instructions.

Result: The improved LLM demonstrates better performance in generating clear, human-understandable route instructions that incorporate qualitative spatial relations such as 'left', 'right', 'near', 'opposite', etc.

Conclusion: Integrating qualitative spatial relations into LLMs significantly enhances their utility in pedestrian navigation tasks, making route instructions more natural and easier to follow.

Abstract: This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.

</details>


### [108] [Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat](https://arxiv.org/abs/2512.15435)
*Stefan Edelkamp*

Main category: cs.AI

TL;DR: 本文提出了一种通用的自举外部学习框架，通过将数百万局AI自对弈游戏生成的数据与人类专家对弈数据合并，扩展并改进了早期决策的统计信息，从而提升预测准确性。该方法利用精确的特征哈希函数处理压缩表结构，构建了一个可自我改进的桥牌类游戏引擎，在斯卡特（Skat）游戏中验证了其在多种决策支持上的有效性。


<details>
  <summary>Details</summary>
Motivation: 在多玩家纸牌游戏如斯卡特或桥牌中，早期阶段（如叫牌、游戏选择和初始出牌）对整体胜负至关重要。然而，当前计算能力限制下，依赖大量人类专家对弈数据进行统计分析，难以充分覆盖复杂决策场景。因此，需要一种更高效的方法来增强早期决策的准确性。

Method: 提出一种自举式外部学习框架，通过让AI系统自对弈生成数百万局新数据，并将其与真实的人类专家对弈数据融合，形成更大的训练数据库；采用完美特征哈希函数优化状态表示，减少存储开销，实现高效的状态检索与更新；构建一个可自我迭代的学习引擎，使新知识能持续反馈至模型中，实现性能提升。

Result: 在斯卡特游戏中的案例研究表明，该自动化方法显著提升了早期决策的预测精度，能够有效支持叫牌、游戏选择及初始出牌等关键环节的决策，且具有良好的可扩展性和适应性。

Conclusion: 本研究展示了一种基于自对弈数据增强的自举学习框架在复杂纸牌游戏早期决策中的有效性，为智能博弈系统提供了新的技术路径，未来可拓展至其他类似策略性游戏中。

Abstract: In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.

</details>


### [109] [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)
*Jeongseok Kim,Kangjin Kim*

Main category: cs.AI

TL;DR: 本文提出一种结合答案集编程（ASP）与混合整数线性规划（MILP）的集成框架，用于解决城市空中交通（UAM）中垂直起降机场（vertiports）的资源受限调度问题。该框架通过三值逻辑处理用户意图的模糊性，并引入决策树实现对动态操作需求和人类重调度请求的透明响应，提升调度系统的可解释性与自适应能力。


<details>
  <summary>Details</summary>
Motivation: 在城市空中交通（UAM）背景下，垂直起降机场面临资源有限与操作动态变化的挑战，传统调度方法难以有效应对人类输入的模糊性和实时调整需求，因此亟需一种兼具灵活性、可解释性与人机协同能力的智能调度系统。

Method: 采用混合整数线性规划（MILP）建模资源受限项目调度问题（RCPSP），引入三值逻辑解析模糊用户意图，结合决策树结构，构建了答案集编程（ASP）与MILP的集成框架，实现对动态调度需求的响应与人类输入的透明支持。

Result: 所提出的集成系统能够高效优化调度方案，在保证资源约束的前提下，有效处理动态变化的操作需求和模糊的人类重调度请求，显著提升了调度过程的可解释性与人机协作能力。

Conclusion: 本研究提出了一种面向UAM场景的可解释、自适应调度框架，为未来智能垂直起降机场的运行提供了坚实的技术支撑，具有良好的应用前景与推广价值。

Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.

</details>


### [110] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math 是一个大规模数学推理数据集，包含750万条解题轨迹，涵盖高、中、低三种推理模式，并支持与Python工具集成的推理（TIR）。数据集融合了8.5万道AoPS竞赛题和26.2万道社区来源的StackExchange-Math问题，结合了结构化竞赛任务与真实世界数学问题。通过受控评估验证其质量，结果显示其在匹配的AoPS问题上优于原始OpenMathReasoning，在HLE-Math等任务上显著提升鲁棒性和泛化能力，同时保持竞赛基准的准确性。研究还提出一种序列分桶策略，使128K上下文长度微调加速2-3倍且精度损失小。整体上，Nemotron-Math实现了顶尖性能，包括在AIME 2024和2025上使用Python TIR达到100% maj@16准确率。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集在推理风格多样性、长序列解题轨迹和工具集成方面存在不足，难以满足高质量数学推理监督的需求。为解决这一问题，需要构建更全面、多样且支持复杂推理的数据集。

Method: 利用GPT-OSS-120B的多模态生成能力，构建Nemotron-Math数据集；整合8.5万道AoPS问题与26.2万道StackExchange-Math问题；设计并应用序列分桶策略以优化长上下文训练效率；通过控制实验评估数据集质量与模型性能。

Result: Nemotron-Math在匹配的AoPS问题上表现优于OpenMathReasoning；引入StackExchange-Math显著提升了模型在HLE-Math上的鲁棒性与泛化能力，同时保持竞赛基准的高准确率；序列分桶策略使128K上下文微调加速2-3倍，精度损失可忽略；在AIME 2024和2025上使用Python TIR实现100% maj@16准确率。

Conclusion: Nemotron-Math是一个高质量、大规模、多样化且支持工具集成的数学推理数据集，能够有效推动大模型在数学推理任务上的性能突破，尤其在长序列、复杂推理和真实场景中展现出卓越潜力。

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [111] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song,Jieyu Lu,Yuanqi Du,Botao Yu,Thomas M. Pruyn,Yue Huang,Kehan Guo,Xiuzhe Luo,Yuanhao Qu,Yi Qu,Yinkai Wang,Haorui Wang,Jeff Guo,Jingru Gan,Parshin Shojaee,Di Luo,Andres M Bran,Gen Li,Qiyuan Zhao,Shao-Xiong Lennon Luo,Yuxuan Zhang,Xiang Zou,Wanru Zhao,Yifan F. Zhang,Wucheng Zhang,Shunan Zheng,Saiyang Zhang,Sartaaj Takrim Khan,Mahyar Rajabi-Kochi,Samantha Paradi-Maropakis,Tony Baltoiu,Fengyu Xie,Tianyang Chen,Kexin Huang,Weiliang Luo,Meijing Fang,Xin Yang,Lixue Cheng,Jiajun He,Soha Hassoun,Xiangliang Zhang,Wei Wang,Chandan K. Reddy,Chao Zhang,Zhiling Zheng,Mengdi Wang,Le Cong,Carla P. Gomes,Chang-Yu Hsieh,Aditya Nandy,Philippe Schwaller,Heather J. Kulik,Haojun Jia,Huan Sun,Seyed Mohamad Moosavi,Chenru Duan*

Main category: cs.AI

TL;DR: 本文提出一种情景驱动的基准测试框架（SDE），用于评估大语言模型在生物学、化学、材料学和物理学中的科学发现能力。该框架通过领域专家定义真实科研项目，并将其分解为可验证的研究情景，从其中抽取问题进行评估。评估分为两个层面：一是情景相关的问答准确率，二是项目级表现（如提出假设、设计实验/模拟、解释结果）。对主流LLMs的测试显示，其在科学发现任务中表现逊于通用科学基准，且模型规模与推理能力提升带来的收益递减，不同顶级模型存在系统性弱点。模型表现差异显著，表明当前所有模型均未达到通用科学“超智能”水平。尽管如此，LLMs在多种科学探索任务中仍展现出潜力，尤其在引导探索与偶然发现方面。该框架为科学发现相关评估提供了可复现的基准，推动了向真正科学发现能力迈进的路径。


<details>
  <summary>Details</summary>
Motivation: 现有科学基准多聚焦于脱离情境的知识问答，忽视了科学研究中迭代推理、假设生成和观察解释等核心过程。为更真实地评估大语言模型在科学发现中的能力，需要一个贴近实际科研流程的评测框架。

Method: 构建情景驱动的科学发现评估（SDE）框架，由领域专家设定真实科研项目，分解为模块化研究情景，从中提取经过验证的问题。评估分两阶段：第一阶段评估模型在具体情景下的问答准确性；第二阶段评估模型在完整科研项目中提出假设、设计实验或模拟、解释结果的能力。

Result: 主流大语言模型在科学发现任务中表现低于通用科学基准，模型规模扩大带来的性能提升逐渐减弱，不同厂商的顶尖模型均存在系统性缺陷。模型在不同研究情景间表现波动大，最佳模型随任务变化而变化，说明当前模型尚未具备通用科学智能。但模型在多种科学探索任务中仍表现出潜力，尤其在引导探索和意外发现方面。

Conclusion: 当前大语言模型距离实现通用科学‘超智能’仍有显著差距。然而，其在科学发现任务中已展现潜力，尤其在结合人类引导时能促进探索与创新。所提出的SDE框架为科学发现能力的可复现评估提供了有效工具，有助于推动大语言模型向真正的科学发现者演进。

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


### [112] [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)
*Jiaqi Xu,Cuiling Lan,Xuejin Chen,Yan LU*

Main category: cs.AI

TL;DR: 提出STC框架，通过在单个模型中交错推理与自省，模拟人类批判性思维，提升大语言模型的推理与自我评估能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型通常将推理与验证分离，缺乏即时反馈或增加系统复杂性；受人类批判性思维启发，需构建一个能同步进行推理与自检的统一框架。

Method: 设计Stepwise Think-Critique（STC）框架，采用混合强化学习目标，结合推理奖励与批判一致性奖励，联合优化推理质量与自我评估能力。

Result: 在数学推理基准测试中，STC展现出强大的自省能力，生成更具可解释性的推理过程，推动大语言模型向具备内置批判性思维迈进。

Conclusion: STC通过融合推理与自评，实现了更高效、更可解释的智能决策，为发展具备类人批判性思维的大语言模型提供了新路径。

Abstract: Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

</details>


### [113] [Explaining the Reasoning of Large Language Models Using Attribution Graphs](https://arxiv.org/abs/2512.15663)
*Chase Walker,Rickard Ewetz*

Main category: cs.AI

TL;DR: 本文提出CAGE框架，通过构建保留因果性和行随机性的有向图，量化提示词和先前生成内容对每一步生成的影响，从而改进上下文归因的完整性与可信度。在多个模型、数据集和评估指标上，CAGE显著提升了归因的忠实性，平均提升达40%。


<details>
  <summary>Details</summary>
Motivation: 现有上下文归因方法在解释自回归大语言模型时，仅将生成标记直接关联到提示词，忽略了生成过程中的代际影响，导致解释不完整，影响模型安全与可信度。

Method: 提出CAGE框架，构建一个有向图（即归因图），该图捕捉每个生成步骤受初始提示及所有先前生成内容的影响，并通过路径上的边际贡献计算上下文归因，确保因果性和行随机性。

Result: 在多种模型、数据集、评估指标和对比方法下，CAGE显著提升了上下文归因的忠实性，平均提升高达40%。

Conclusion: CAGE框架通过引入归因图有效建模了生成过程中的代际依赖，提供了更完整、更可信的大语言模型解释，为提升LLM的安全性与可解释性提供了新路径。

Abstract: Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [114] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: 提出一种名为AutoS的自适应源知识选择方法，用于在多领域迁移学习中自动筛选最相关的源域样本和模型，以提升目标任务的性能。通过密度驱动的选择策略和基于预训练多模态模型的伪标签增强模块，有效减少冗余信息影响并缓解目标域标签噪声问题。实验表明该方法在真实数据集上表现优越。


<details>
  <summary>Details</summary>
Motivation: 在多源域迁移学习中，大量源域可能包含冗余或无关信息，影响迁移效果，尤其在大规模源域设置下，亟需有效策略来识别并选择最具可迁移性的知识。

Method: 提出密度驱动的选择策略，用于在训练过程中筛选源域样本，并决定哪些源模型应参与目标预测；同时引入基于预训练多模态模型的伪标签增强模块，以减轻目标域标签噪声并提升自监督效果。

Result: 在多个真实世界数据集上的实验结果表明，所提方法在多领域适应任务中显著优于现有方法，具有更强的迁移性能和鲁棒性。

Conclusion: AutoS方法能够有效实现源域知识的自主选择，提升迁移学习在复杂多源环境下的表现，为大规模多源域适应提供了可行且高效的解决方案。

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [115] [A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour](https://arxiv.org/abs/2512.14713)
*Georges Sfeir,Stephane Hess,Thomas O. Hancock,Filipe Rodrigues,Jamal Amani Rad,Michiel Bliemer,Matthew Beck,Fayyaz Khan*

Main category: cs.LG

TL;DR: 本文提出了一种潜在类别强化学习（LCRL）模型，用于捕捉旅行决策中个体偏好形成与异质性。通过变分贝叶斯方法在驾驶模拟器数据上估计参数，识别出三类不同的行为模式：依赖情境的偏好与情境特定的利用型策略；持续采用利用型策略的个体；以及结合探索行为与情境相关偏好的个体。


<details>
  <summary>Details</summary>
Motivation: 旅行决策中存在偏好随时间演变的现象，且个体间存在显著差异，现有模型难以同时刻画偏好演化与个体异质性，因此需要一种能够整合这两方面的建模方法。

Method: 提出潜类别强化学习（LCRL）模型，并采用变分贝叶斯方法进行参数估计，基于驾驶模拟器数据识别不同类型的出行者行为模式。

Result: 成功识别出三类具有明显行为差异的个体：情境依赖型、持续利用型和探索型，揭示了偏好演化过程中的多样化路径。

Conclusion: LCRL模型有效捕捉了个体在旅行决策中的动态偏好形成与行为异质性，为理解复杂出行行为提供了新的分析框架。

Abstract: Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.

</details>


### [116] [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)
*Zafaryab Haider,Md Hafizur Rahman,Shane Moeykens,Vijay Devabhaktuni,Prabuddha Chakraborty*

Main category: cs.LG

TL;DR: 该研究首次探讨了对用于图像描述的大语言模型（LLM）权重进行低层级位级扰动（故障注入）如何在保持语法结构的同时影响生成描述的语义。提出BLADE框架，利用梯度敏感性估计定位语义关键位，并通过基于描述级别的语义-流畅性目标优化选择，揭示即使微小的比特变化也能显著改变生成内容的语义，为模型鲁棒性测试、对抗防御和可解释性AI提供新路径。


<details>
  <summary>Details</summary>
Motivation: 现有故障分析方法多关注模型崩溃或准确率下降，忽视生成系统中的语义与语言维度；本研究旨在理解比特级扰动如何影响生成模型的高阶语义表达，揭示底层编码机制的脆弱性与可操纵性。

Method: 设计了基于梯度敏感性的可微故障分析框架BLADE，通过模型自身梯度预测最具影响力的比特位，并结合语义与流畅性双重目标进行精炼筛选。

Result: 实验表明，极小的位级扰动可引发显著的语义漂移，且这种漂移具有可预测性和结构性；模型梯度能有效识别关键比特，实现对语义输出的精准操控。

Conclusion: 该研究揭示了生成式视觉-语言模型中语义编码的高度敏感性与分布特性，证明即使不可察觉的低层比特变化也能改变高层语义，为模型安全性、可解释性及防御机制提供了重要洞见。

Abstract: Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.

</details>


### [117] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)
*Ziqian Bi,Danyang Zhang,Junhao Song,Chiung-Yi Tseng*

Main category: cs.LG

TL;DR: 该研究评估了GPT-OSS模型家族在10个金融NLP任务中的表现，发现较小的GPT-OSS-20B模型在准确率（65.1% vs 66.5%）上与更大模型相当，且在计算效率上更优（198.4 Token Efficiency Score，159.80 tokens/秒）。通过引入新的效率指标，揭示了模型性能与资源消耗之间的权衡，挑战了“模型越大性能越好”的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融领域的广泛应用，亟需建立严格的评估框架来衡量其性能、效率和实际适用性。现有研究多强调模型规模与性能正相关，但缺乏对中小型模型在真实金融场景中表现的系统评估，尤其忽视了计算效率的重要性。因此，本研究旨在验证小规模模型是否能在保持高精度的同时显著降低资源消耗，为金融领域高效部署提供依据。

Method: 在120B和20B参数版本的GPT-OSS模型上进行大规模实验，对比其在10个金融自然语言处理任务上的表现；使用真实世界金融数据集（如Financial PhraseBank、FiQA-SA、FLARE FINERORD）进行测试；提出新型效率指标，综合评估模型性能与资源利用率，并与Qwen3-235B等大型模型进行对比分析。

Result: GPT-OSS-20B模型在多项任务中达到与更大模型相近的准确率（65.1% vs 66.5%），同时展现出更高的计算效率：Token Efficiency Score达198.4，处理速度为159.80 tokens/秒。所有GPT-OSS模型均优于包括Qwen3-235B在内的主流大型模型，证明其架构创新与训练策略的有效性。

Conclusion: GPT-OSS系列模型表明，通过合理的架构设计和训练方法，小型模型可在金融任务中实现媲美甚至超越大型模型的性能，同时大幅降低计算开销。这为金融领域可持续、低成本地部署大语言模型提供了可行路径，颠覆了‘规模即性能’的传统认知。

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.

</details>


### [118] [SEED: Spectral Entropy-Guided Evaluation of SpatialTemporal Dependencies for Multivariate Time Series Forecasting](https://arxiv.org/abs/2512.14718)
*Feng Xiong,Zongxia Xie,Yanru Sun,Haoyu Wang,Jianhong Lin*

Main category: cs.LG

TL;DR: SEED提出了一种基于谱熵的时空依赖建模框架，通过引入依赖评估器、谱熵融合器、带符号图构造器和上下文空间提取器，解决了现有方法在处理变量间依赖关系时存在的三大问题：时间自依赖被无关变量破坏、softmax归一化忽略并反转负相关性、变量难以感知时间位置。该方法在12个真实世界数据集上表现出色，达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有注意力或图模型在多变量时间序列预测中面临三个关键问题：（a）强时间自依赖常被无关变量干扰；（b）softmax归一化会忽略甚至反转负相关性；（c）变量难以感知其时间位置，影响特征构建。

Method: SEED框架包含四个核心组件：1）依赖评估器，利用谱熵动态评估各变量的空间与时间依赖性，自适应调节通道独立与通道依赖策略；2）谱熵融合器，进一步优化依赖权重，分离由其他变量引起的时序规律；3）带符号图构造器，支持负边权重，保留负相关性；4）上下文空间提取器，通过局部上下文窗口提取空间特征，增强时间位置感知能力。

Result: 在12个来自不同应用领域的实际数据集上的大量实验表明，SEED显著优于现有方法，实现了最先进的预测性能，验证了其有效性与通用性。

Conclusion: SEED通过谱熵引导的动态依赖评估与多模块协同设计，有效解决了多变量时间序列建模中的关键挑战，在多个真实场景下展现出卓越的预测能力与泛化性能。

Abstract: Effective multivariate time series forecasting often benefits from accurately modeling complex inter-variable dependencies. However, existing attention- or graph-based methods face three key issues: (a) strong temporal self-dependencies are often disrupted by irrelevant variables; (b) softmax normalization ignores and reverses negative correlations; (c) variables struggle to perceive their temporal positions. To address these, we propose \textbf{SEED}, a Spectral Entropy-guided Evaluation framework for spatial-temporal Dependency modeling. SEED introduces a Dependency Evaluator, a key innovation that leverages spectral entropy to dynamically provide a preliminary evaluation of the spatial and temporal dependencies of each variable, enabling the model to adaptively balance Channel Independence (CI) and Channel Dependence (CD) strategies. To account for temporal regularities originating from the influence of other variables rather than intrinsic dynamics, we propose Spectral Entropy-based Fuser to further refine the evaluated dependency weights, effectively separating this part. Moreover, to preserve negative correlations, we introduce a Signed Graph Constructor that enables signed edge weights, overcoming the limitations of softmax. Finally, to help variables perceive their temporal positions and thereby construct more comprehensive spatial features, we introduce the Context Spatial Extractor, which leverages local contextual windows to extract spatial features. Extensive experiments on 12 real-world datasets from various application domains demonstrate that SEED achieves state-of-the-art performance, validating its effectiveness and generality.

</details>


### [119] [Hybrid Attribution Priors for Explainable and Robust Model Training](https://arxiv.org/abs/2512.14719)
*Zhuoran Zhang,Feng Zhang,Shangyuan Li,Yang Shi,Yuanxing Zhang,Wei Chen,Tengjiao Wang,Kam-Fai Wong*

Main category: cs.LG

TL;DR: 本文提出了一种名为CAP（Class-Aware Attribution Prior）的新颖归因先验提取框架，旨在解决小语言模型在分类任务中由于现有归因方法聚焦于语义相似类别共有的关键词而导致判别性不足的问题。通过引导模型关注细粒度的类别差异，CAP生成更具判别性的归因先验，并进一步提出CAP Hybrid，融合CAP与传统归因方法的先验以形成更全面的监督信号。实验表明，该方法在全数据、少样本及对抗场景下均显著提升了模型的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有归因方法在分类任务中虽能准确识别相关词元，但常过度关注语义相似类别共有的关键词，这些关键词本身难以区分不同类别，导致归因提供的判别线索有限，限制了模型对类间差异的学习能力。因此需要一种能够捕捉细粒度类别差异的新型归因先验机制。

Method: 提出Class-Aware Attribution Prior (CAP) 框架，通过分析类别间的细微差异来生成更具判别性的归因先验；进一步设计CAP Hybrid，将CAP生成的先验与传统归因方法的结果相结合，构建更丰富、平衡的监督信号，指导模型学习多样且决策相关的特征。

Result: 在多种设置下（包括全数据、少样本和对抗性场景），所提方法均显著提升了模型的可解释性与鲁棒性，证明了其有效性与泛化能力。

Conclusion: CAP及其扩展形式CAP Hybrid有效解决了传统归因方法在判别性上的局限，通过引入细粒度类别差异感知的归因先验，显著增强了小语言模型在分类任务中的性能与可信度。

Abstract: Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.

</details>


### [120] [Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example](https://arxiv.org/abs/2512.14721)
*Arno Appenzeller,Nick Terzer,André Hohmeyer,Jan-Philipp Redlich,Sabine Luttmann,Friedrich Feuerhake,Nadine S. Schaadt,Timm Intemann,Sarah Teuber-Hanselmann,Stefan Nikolin,Joachim Weis,Klaus Kraywinkel,Pascal Birnstill*

Main category: cs.LG

TL;DR: 本文提出一种基于癌症报告中提取的统计信息自动生成Synthea规则的方法，以生成符合真实疾病轨迹的合成患者数据。通过构建胶质母细胞瘤模块并生成合成数据集，验证了该方法在保持统计特性方面的有效性，为隐私保护研究提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有Synthea规则生成依赖专家知识和真实样本数据，过程复杂且耗时；为提升自动化水平并确保数据真实性，需开发基于实际数据统计的规则自动生成方法。

Method: 从真实癌症报告中提取表格数据统计特征，利用这些统计信息自动推导出Synthea规则，构建特定疾病（如胶质母细胞瘤）的合成数据生成模块。

Result: 合成数据在整体上再现了已知的疾病发展路径，并较好保留了原始数据的统计特性，表明该方法具有可行性与实用性。

Conclusion: 合成患者数据在隐私保护研究中具有巨大潜力，可用于假设生成与原型开发，但其应用仍需结合医学判断，注意当前方法的局限性。

Abstract: The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.

</details>


### [121] [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)
*Mohamed Malhou,Ludovic Perret,Kristin Lauter*

Main category: cs.LG

TL;DR: 本文提出使用分层注意力变换器（HAT）来计算多项式方程组的Gröbner基，通过引入树状结构归纳偏置，有效建模数据中的层次关系，显著降低计算开销。方法可推广至任意深度，并结合课程学习策略，解决了比Kera等人（2024）更大规模的问题实例。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在计算Gröbner基时存在计算效率低、难以捕捉多项式系统中固有层次结构的问题。为提升计算效率并更好地建模多项式之间的层级依赖关系，需要一种具有结构化归纳偏置的新模型。

Method: 采用分层注意力变换器（HAT），其树状结构设计能够自然表达多项式系统中变量与项之间的层次关系；通过层级注意力机制减少冗余计算，同时进行可扩展至任意深度的架构设计，并结合课程学习优化训练过程。

Result: 实验表明，该方法在保持高精度的同时，显著降低了计算复杂度，成功求解了比先前工作大数个数量级的多项式系统，验证了其在大规模问题上的有效性与实用性。

Conclusion: HAT通过引入树状归纳偏置，有效提升了计算Gröbner基的效率与可扩展性，为基于深度学习的计算机代数提供了新的有效路径。

Abstract: At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)

</details>


### [122] [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Lisa Koch,Christian F. Baumgartner,Michael Muehlebach*

Main category: cs.LG

TL;DR: 本文质疑了分位数预测（CP）在小样本校准集下仍能提供实际有意义的统计保证的普遍观点。尽管CP理论在任意大小的校准集上都成立，但其实际效用高度依赖于校准集的规模。在医疗领域数据稀缺的背景下，该问题尤为关键。研究通过医学图像分类任务的实证分析验证了这一观点。


<details>
  <summary>Details</summary>
Motivation: 标准机器学习模型无法提供可靠的不确定性估计，而分位数预测（CP）虽能提供具有统计保证的不确定性估计，但其在小样本校准集下的实际效用存在疑问，尤其在医疗领域数据有限的情况下，亟需评估其适用性。

Method: 理论分析结合实证研究，通过在医学图像分类任务中使用不同大小的校准集，评估分位数预测在实际应用中的表现与可靠性。

Result: 研究表明，尽管分位数预测的统计保证在小样本校准集下依然成立，但其实际可用性显著下降，提示在数据稀缺的医疗场景中，仅依赖小校准集难以获得实用的不确定性估计。

Conclusion: 分位数预测虽具备理论上的统计保障，但在小样本校准集条件下，其实际效用受限，医疗领域应谨慎使用，并考虑数据增强或替代方法以提升不确定性估计的可靠性。

Abstract: Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.

</details>


### [123] [A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems](https://arxiv.org/abs/2512.14728)
*Jie He,Yong Qin,Jianyuan Guo,Xuan Sun,Xuanchuan Zheng*

Main category: cs.LG

TL;DR: 本文提出一种完全数据驱动的方法，用于推断城市轨道交通中的个体出行轨迹。该方法利用AFC和AVL系统数据，结合基于时空约束的列车备选集构建、数据驱动自适应轨迹推断及轨迹构造，提出了基于KL散度与EM算法结合的KLEM参数估计方法，无需依赖外部或调查数据，提升了模型的鲁棒性和适用性。通过真实个体出行数据验证，结果表明该方法在高峰时段的轨迹推断准确率超过90%。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹推断方法多依赖外部或调查数据进行参数拟合，限制了模型的普适性与鲁棒性；同时，缺乏真实数据验证导致结果可信度不足。因此，亟需一种不依赖外部数据、基于真实数据的高精度轨迹推断方法。

Method: 提出基于时空约束构建列车备选集，采用数据驱动的KLEM参数估计方法（结合KL散度与EM算法），实现自适应轨迹推断，并结合真实出行数据进行轨迹重建与验证。

Result: 所提方法在高峰时段的城市轨道交通轨迹推断中，准确率超过90%，显著优于传统方法，且无需外部数据支持，具备良好的实用性与可扩展性。

Conclusion: 该研究提出的完全数据驱动的轨迹推断方法，有效克服了传统方法对先验数据的依赖，实现了高精度、高鲁棒性的个体出行轨迹推断，为城市轨道交通运营组织提供了有力支持。

Abstract: Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.

</details>


### [124] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: 本文提出一种几何框架，用于在高风险领域中实现受政策约束的语义解释，通过将语义意义表示为单位球面上的方向，证据建模为一组见证向量，允许的解释对应于球面凸区域。政策约束作为定义在同一流形上的显式先验引入，与证据几何分离。解释过程转化为对允许区域的约束优化，拒绝成为矛盾或政策排除时拓扑上必然的结果。该框架与信息论、贝叶斯推断和层论语义学相联系，并证明其复杂度界是信息论最优的。在大规模受监管金融数据上的实证验证表明，在多个政策制度下均实现了零幻觉批准，这是首次在大规模上实现此结果。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域（如金融）中，模型容易产生幻觉性承诺，导致严重后果。现有方法缺乏对政策约束的显式建模，难以保证解释的可靠性。因此需要一种能够严格防止幻觉承诺的语义解释框架。

Method: 将语义意义表示为单位球面上的方向，证据建模为见证向量集合，允许解释为球面凸区域；政策约束作为独立于证据的先验引入同一流形；解释过程通过约束优化完成，拒绝作为拓扑必要结果出现。

Result: 在大规模受监管金融数据上，该框架实现了零幻觉批准，且在不同政策制度下均表现稳定，证明了其有效性与可扩展性。

Conclusion: 所提出的几何框架能有效防止高风险场景中的幻觉承诺，具有理论保障和实证支持，是首个在大规模上实现零幻觉批准的方法。

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [125] [Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness](https://arxiv.org/abs/2512.14734)
*Qiang Chen,Venkatesh Ganapati Hegde,Hongfei Li*

Main category: cs.LG

TL;DR: 本文提出了一种轻量级、模型无关的日内个性化方法，通过在推理时选择性注入用户的近期观看历史，实现无需重训练即可即时适应用户偏好变化。该方法将个性化反馈周期从每日缩短至日内，显著提升了用户参与度，关键指标提升0.47%，是近期实验中最具影响力的改进之一。这是首个公开证据表明日内个性化可在长视频流媒体服务中产生实质性影响，为无需重训练的实时架构提供了有力替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统依赖批处理训练和每日更新的用户特征，无法及时反映用户最新行为，导致推荐结果过时，影响用户体验和参与度。

Method: 提出一种在推理阶段选择性覆盖过时用户特征的方法，利用近期观看历史动态调整推荐结果，无需重新训练模型。

Result: 在实际应用中，关键用户参与度指标提升了0.47%，且具有统计显著性，效果在近期实验中属领先水平。

Conclusion: 本方法首次证明了在长视频流媒体场景下，无需全实时模型重训练的日内个性化可带来显著性能提升，是一种高效且实用的替代方案。

Abstract: Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.

</details>


### [126] [NoveltyRank: Estimating Conceptual Novelty of AI Papers](https://arxiv.org/abs/2512.14738)
*Zhengxu Yan,Han Li,Yuming Feng*

Main category: cs.LG

TL;DR: 本研究针对AI领域论文数量激增导致创新性难以评估的问题，提出一种基于标题、摘要和与已有文献语义相似性的数据驱动模型，用于估计和排序论文的观念新颖性。采用两种任务范式：二分类（判断绝对新颖性）和成对比较（判断相对新颖性），并使用Qwen3-4B-Instruct-2507和SciBERT进行微调，与GPT-5.1对比分析不同建模策略的效果。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版门槛降低，AI领域论文数量激增，导致真正具有创新性的研究难以脱颖而出；手动评估新颖性存在不稳定且耗时的问题，亟需一种可扩展、量化的自动评估方法。

Method: 通过分析论文的标题、摘要及其与已有文献的语义相似性，设计两种任务范式：(1) 二分类任务，基于历史新颖论文模式预测新论文的绝对新颖性；(2) 成对新颖性比较任务，学习区分论文之间的相对新颖程度。采用Qwen3-4B-Instruct-2507和SciBERT进行微调，并与GPT-5.1进行性能对比。

Result: 实验表明，所提方法能有效评估论文的新颖性，不同任务范式在不同场景下各有优势；模型在基准测试中表现优于基线，验证了其有效性与实用性。

Conclusion: 该系统为科研人员和审稿人提供了一种高效、一致且可扩展的新颖性评估工具，有助于识别真正创新的研究工作，推动高质量学术产出。

Abstract: With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.

</details>


### [127] [Guided Discrete Diffusion for Constraint Satisfaction Problems](https://arxiv.org/abs/2512.14765)
*Justin Jung*

Main category: cs.LG

TL;DR: 提出了一种用于约束满足问题（CSP）的离散扩散引导方法，并展示了其在无监督情况下解决数独谜题的能力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统方法在处理复杂约束满足问题时效率低、依赖大量标注数据的问题，探索无监督学习在逻辑推理任务中的潜力。

Method: 采用离散扩散模型，通过逐步去噪过程生成符合约束条件的解，利用概率建模和迭代优化实现无监督求解。

Result: 实验表明该方法在多个数独谜题上实现了高成功率的无监督求解，且优于现有基线方法。

Conclusion: 离散扩散引导为无监督求解约束满足问题提供了一种有效的新范式，具有良好的泛化能力和可扩展性。

Abstract: We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.

</details>


### [128] [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)
*Kornelius Raeth,Nicole Ludwig*

Main category: cs.LG

TL;DR: 该研究提出决策校准框架，从决策者视角评估天气预报在实际决策中的价值，发现传统基于统计的预报评估无法可靠预测模型在具体决策任务中的表现，且不同模型在决策层面的表现排名可能随任务变化。


<details>
  <summary>Details</summary>
Motivation: 传统天气预报评估仅从预报员角度出发，忽视了预报在实际决策中的作用；而决策者使用预报来做出选择，因此需要从决策层面评估预报的价值。

Method: 采用决策校准框架，对比机器学习与经典数值天气预报模型在多种依赖天气的决策任务中的表现。

Result: 预报层面的性能差异并不能可靠地转化为决策层面的优势；某些性能差异仅在决策层面显现，且不同决策任务中模型排名可能发生改变。

Conclusion: 传统的预报评估方法不足以确定特定决策任务下的最优预报模型，应引入决策层面的评估机制。

Abstract: Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.

</details>


### [129] [How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal](https://arxiv.org/abs/2512.14873)
*Sam Jeong,Hae Yong Kim*

Main category: cs.LG

TL;DR: FAN improves neural network performance primarily through sine activation, which mitigates the vanishing gradient problem near zero by maintaining a non-zero derivative. This addresses the dying-ReLU issue more effectively than existing ReLU-like activations. The study reinterprets FAN's benefits from spectral to training dynamics, leading to the Dual-Activation Layer (DAL), which accelerates convergence and enhances accuracy across multiple tasks.


<details>
  <summary>Details</summary>
Motivation: To clarify the underlying mechanism behind Fourier Analysis Network (FAN) improvements, particularly whether sine or cosine activations contribute positively and why FAN outperforms traditional ReLU-based activations.

Method: Analytical investigation of activation functions' behavior near x=0, comparison of gradient dynamics across different activation types (ReLU, Leaky ReLU, GELU, Swish, FAN), and development and evaluation of the Dual-Activation Layer (DAL).

Result: Sine activation in FAN significantly improves training by stabilizing gradients near zero, reducing the dying-ReLU problem. DAL achieves faster convergence and higher or equal validation accuracy compared to standard activations on noisy signal classification, MNIST, and ECG biometric recognition tasks.

Conclusion: The success of FAN is not due to periodicity but to local gradient stability provided by sine activation. This insight enables the design of DAL as a more efficient convergence accelerator, shifting focus from spectral properties to training dynamics.

Abstract: Fourier Analysis Network (FAN) was recently proposed as a simple way to improve neural network performance by replacing part of ReLU activations with sine and cosine functions. Although several studies have reported small but consistent gains across tasks, the underlying mechanism behind these improvements has remained unclear. In this work, we show that only the sine activation contributes positively to performance, whereas the cosine activation tends to be detrimental. Our analysis reveals that the improvement is not a consequence of the sine function's periodic nature; instead, it stems from the function's local behavior near x = 0, where its non-zero derivative mitigates the vanishing-gradient problem. We further show that FAN primarily alleviates the dying-ReLU problem, in which a neuron consistently receives negative inputs, produces zero gradients, and stops learning. Although modern ReLU-like activations, such as Leaky ReLU, GELU, and Swish, reduce ReLU's zero-gradient region, they still contain input domains where gradients remain significantly diminished, contributing to slower optimization and hindering rapid convergence. FAN addresses this limitation by introducing a more stable gradient pathway. This analysis shifts the understanding of FAN's benefits from a spectral interpretation to a concrete analysis of training dynamics, leading to the development of the Dual-Activation Layer (DAL), a more efficient convergence accelerator. We evaluate DAL on three tasks: classification of noisy sinusoidal signals versus pure noise, MNIST digit classification, and ECG-based biometric recognition. In all cases, DAL models converge faster and achieve equal or higher validation accuracy compared to models with conventional activations.

</details>


### [130] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: 本文提出熵-储层Bregman投影（ERBP）框架，统一解释自引用学习中的模型崩溃现象。通过将闭环过程建模为分布空间中的随机Bregman投影序列，揭示了有限样本噪声导致熵指数衰减与系统崩溃的机制。引入熵储层可注入可控熵通量，稳定动态过程，并提供崩溃的必要条件、非平凡熵下限的充分条件及闭式速率公式。实验验证了理论预测，并将多种稳定化技巧归结为特定储层选择与耦合系数，最终形成量化设计原则：监控并管理熵通量。


<details>
  <summary>Details</summary>
Motivation: 自引用学习虽具无限扩展潜力，但常因模型崩溃（如语言模型生成重复文本、GAN模式丢失、强化学习策略过度利用）而受限。现有修复方法（如真实数据混合、熵奖励、知识蒸馏等）缺乏统一理论解释，亟需一个能阐明失败原因与修复机制的通用原则。

Method: 构建信息几何框架，将自引用学习闭环视为分布空间中的随机Bregman投影序列；引入熵储层作为高熵分布以注入可控熵通量，通过数学分析推导出熵演化规律、稳定性条件及收敛速率。

Result: 理论证明了模型崩溃的必要条件与稳定性的充分条件，给出了依赖于样本大小和生成器强凸性/利普希茨常数的闭式熵衰减速率；实验在大语言模型自训练、SAC强化学习与GAN优化中验证了预测准确性，且不同稳定化技术可对应特定储层配置，实现统一解释。

Conclusion: ERBP框架将分散的实践经验整合为单一可量化的熵通量管理原则，为自引用学习提供了理论基础与设计指导，标志着从经验修补迈向系统性调控的重要进展。

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [131] [Task Matrices: Linear Maps for Cross-Model Finetuning Transfer](https://arxiv.org/abs/2512.14880)
*Darrin O' Brien,Dhikshith Gajulapalli,Eric Xia*

Main category: cs.LG

TL;DR: 本文提出任务矩阵概念，通过线性变换将预训练模型的嵌入状态映射到微调后的状态，在十个数据集上表现优于线性探测器，接近微调性能，验证了跨层线性编码的存在，并展示了基于数据的近似方法在多领域中的高效与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性研究发现大视觉语言模型在上下文提示偏见下会学习隐式线性编码，但缺乏在更普遍适应场景中此类线性表示存在的证据。本文旨在填补这一空白，探索通用适配场景下的线性编码机制。

Method: 引入任务矩阵作为从基础模型到微调后嵌入状态的线性变换，利用数据驱动的方法近似该矩阵，并在多种视觉和文本模型及数据集上进行评估。

Result: 任务矩阵在十种不同数据集上显著超越线性探测器性能，部分情况下接近完全微调的效果；证明了跨层线性编码的存在，并表明数据驱动的近似方法具有高效率和跨域泛化能力。

Conclusion: 本研究验证了在通用微调范式下，大型视觉语言模型仍存在有效的线性编码结构，且可通过任务矩阵高效建模，为模型可解释性和轻量级适配提供了新思路。

Abstract: Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.

</details>


### [132] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: OLR-WA 是一种新型的多变量在线线性回归模型，能够在数据流中持续更新模型，具备低存储和高效计算的优势。它在处理数据漂移（如时间变化）和高置信度挑战场景下表现出色，尤其在快速收敛和稳定高 R² 值方面优于现有方法。即使初始数据极少（仅1%-10%），也能迅速达到高性能，且通过优先保留高置信度历史数据，展现出卓越的鲁棒性与适应性，是当前最先进的在线回归解决方案之一。


<details>
  <summary>Details</summary>
Motivation: 现有在线回归模型在面对数据漂移、初始数据量少或需依赖高置信度历史信息的场景时，性能不稳定或收敛慢，亟需一种兼具快速收敛、高精度与强适应性的通用在线回归方法。

Method: 提出 OLR-WA 模型，采用加权平均策略对新旧数据进行动态加权更新，结合置信度感知机制，在每次迭代中保守调整参数，优先保留高置信度历史样本的影响，实现稳定且高效的在线学习。

Result: OLR-WA 在多种场景下表现优异：在批量回归基准下性能相当；在在线对比中超越多数先进模型；从第一轮迭代起即保持高 R² 值，收敛速度显著快于同类方法；在数据漂移和高置信度挑战场景中唯一有效应对。

Conclusion: OLR-WA 作为一种高效、稳健且通用的在线线性回归框架，具备快速收敛、高精度和强适应能力，适用于多样化的实际应用场景，具有重要的理论价值与应用前景。

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [133] [ATLAS: Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs](https://arxiv.org/abs/2512.14908)
*Turja Kundu,Sanjukta Bhowmick*

Main category: cs.LG

TL;DR: ATLAS is a scalable graph learning algorithm that improves GNN performance on both homophilic and heterophilic graphs by using multi-resolution community detection to add topological context to node features, replacing iterative aggregation with MLPs for better scalability and accuracy.


<details>
  <summary>Details</summary>
Motivation: GNNs struggle with heterophilic graphs and suffer from scalability issues due to iterative feature aggregation. ATLAS aims to overcome these limitations by incorporating topological information from communities at multiple scales.

Method: ATLAS extracts community structures at multiple levels of refinement, encodes them into node features via concatenation, and uses MLPs instead of GNN aggregations to process the enriched representations.

Result: ATLAS achieves up to 20 percentage points higher accuracy than GCN on heterophilic graphs with negative structural bias and 11 percentage points over MLP on homophilic graphs, while being highly scalable without sampling.

Conclusion: ATLAS provides a principled, explainable, and scalable approach to graph learning by leveraging multi-resolution community structure, effectively bridging the gap between homophilic and heterophilic graph settings.

Abstract: We present ATLAS (Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs), a novel graph learning algorithm that addresses two important challenges in graph neural networks (GNNs). First, the accuracy of GNNs degrades when the graph is heterophilic. Second, iterative feature aggregation limits the scalability of GNNs to large graphs. We address these challenges by extracting topological information about graph communities at multiple levels of refinement, concatenating community assignments to the feature vector, and applying multilayer perceptrons (MLPs) to the resulting representation. This provides topological context about nodes and their neighborhoods without invoking aggregation. Because MLPs are typically more scalable than GNNs, our approach applies to large graphs without the need for sampling. Across a wide set of graphs, ATLAS achieves comparable accuracy to baseline methods, with gains as high as 20 percentage points over GCN for heterophilic graphs with negative structural bias and 11 percentage points over MLP for homophilic graphs. Furthermore, we show how multi-resolution community features systematically modulate performance in both homophilic and heterophilic settings, opening a principled path toward explainable graph learning.

</details>


### [134] [Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective](https://arxiv.org/abs/2512.14932)
*Daniel Gomes de Pinho Zanco,Leszek Szczecinski,Jacob Benesty,Eduardo Vinicius Kuhn*

Main category: cs.LG

TL;DR: 本文提出了一种基于克罗内克积表示的低秩MMSE滤波器正则化参数高效寻找方法，揭示了正则化参数与秩选择问题的意外关联，表明合理选择该参数对低秩设置至关重要。通过仿真验证，所提方法显著优于常用方法。


<details>
  <summary>Details</summary>
Motivation: 在低秩MMSE滤波器中，正则化参数的选择对性能影响重大，但传统方法效率较低且缺乏理论依据，亟需一种高效且可靠的参数选择机制。

Method: 利用克罗内克积表示，建立低秩MMSE滤波器的数学模型，并设计一种高效算法来确定最优正则化参数，同时分析其与秩选择的关系。

Result: 仿真结果表明，所提方法在性能上显著优于现有常见方法，具有更高的准确性和计算效率。

Conclusion: 正则化参数的选择不仅影响滤波器性能，还与秩选择密切相关；基于克罗内克积表示的方法为低秩场景下的参数优化提供了有效解决方案。

Abstract: In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.

</details>


### [135] [Softly Constrained Denoisers for Diffusion Models](https://arxiv.org/abs/2512.14980)
*Victor M. Yeom Song,Severi Rissanen,Arno Solin,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 本文提出一种在去噪器中引入引导式调整的方法，以软性地施加约束，从而在不改变损失函数或采样过程的前提下提升扩散模型生成样本对科学约束的符合度，同时保持对数据分布的忠实性，尤其在约束存在误设时仍具备灵活性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在科学应用中难以生成满足约束条件的样本，现有方法通过正则化或采样引导虽能强制约束，但会偏离真实数据分布，尤其在约束错误设定时问题更严重。

Method: 将引导式调整直接集成到去噪器内部，赋予其对约束合规样本的软性先验偏置，而不修改损失函数或采样流程。

Result: 所提出的软约束去噪器在保持对真实数据分布敏感性的同时，显著提升了生成样本对约束的遵守程度，并在约束误设情况下仍能有效适应观测数据。

Conclusion: 通过在去噪器中嵌入软性约束引导，可在不破坏生成质量的前提下有效处理科学数据中的约束问题，是一种稳健且灵活的解决方案。

Abstract: Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.

</details>


### [136] [Prompt Repetition Improves Non-Reasoning LLMs](https://arxiv.org/abs/2512.14982)
*Yaniv Leviathan,Matan Kalman,Yossi Matias*

Main category: cs.LG

TL;DR: 重复输入提示词可在不增加生成标记数或延迟的情况下提升主流模型（Gemini、GPT、Claude 和 Deepseek）的性能，即使不使用推理。


<details>
  <summary>Details</summary>
Motivation: 探索在不增加计算开销的前提下提升大模型性能的方法，特别是针对非推理场景下的表现优化。

Method: 通过重复输入原始提示词来测试对模型输出性能的影响，并在多个主流大模型上进行实验验证。

Result: 实验表明，重复输入提示词能有效提升模型在无推理情况下的表现，且不会增加生成时间或令牌数量。

Conclusion: 重复输入提示词是一种简单有效的性能增强策略，适用于多种主流大模型，尤其在不依赖推理能力的场景中具有显著优势。

Abstract: When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.

</details>


### [137] [Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes](https://arxiv.org/abs/2512.14991)
*Hanqing Jin,Renyuan Xu,Yanzhao Yang*

Main category: cs.LG

TL;DR: 本文研究在无界连续状态空间、有界连续动作和多项式增长奖励下的强化学习问题，针对高维连续域的挑战，提出一种基于模型的自适应分区算法，通过动态划分状态-动作空间并更新漂移、波动率和奖励估计，实现探索与近似的平衡。理论分析给出了依赖于问题时长、状态维度、奖励增长阶数及新定义的‘缩放维度’的后悔界，可涵盖有界情形，并扩展至更广泛的扩散型问题。数值实验验证了方法在高维问题（如多资产均值-方差投资组合选择）中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决连续且高维状态空间下强化学习的挑战，特别是在金融、经济和运筹学中常见的无界扩散过程建模问题，现有方法难以有效处理未限定状态范围和高维结构的情况。

Method: 提出一种基于模型的自适应分区算法，将联合状态-动作空间动态划分为子区域，在每个子区域中维护对漂移、波动率和奖励的估计；当估计偏差超过统计置信度时，自动细化划分，从而平衡探索与近似误差。

Result: 建立了依赖于问题时长、状态维度、奖励增长阶数和新提出的‘缩放维度’的后悔上界，该结果在有界情况下退化为已有成果，并首次为无界扩散过程提供理论保证；数值实验表明算法在高维场景（如多资产投资组合优化）中表现良好。

Conclusion: 所提自适应模型基算法有效应对了无界连续状态空间中的强化学习难题，其理论框架具备可扩展性，适用于多种现实应用，尤其在高维金融优化任务中展现出潜力。

Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

</details>


### [138] [DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding](https://arxiv.org/abs/2512.15000)
*Ruiyi Zhang,Peijia Qin,Qi Cao,Pengtao Xie*

Main category: cs.LG

TL;DR: DreamPRM-Code 是一种针对代码生成的进程奖励模型，通过函数级推理步骤和链式函数提示策略实现模块化代码生成，并采用元学习修正机制降低蒙特卡洛生成标签的噪声，在 LiveCodeBench 上达到 80.9 的 pass@1 率，优于 OpenAI o4-mini。


<details>
  <summary>Details</summary>
Motivation: 现有 Process Reward Models (PRMs) 在代码任务中表现不佳，主要由于缺乏有意义的代码步骤分解以及蒙特卡洛生成部分标签带来的噪声问题。

Method: 提出 DreamPRM-Code，利用链式函数提示（Chain-of-Function）将函数视为推理步骤，实现模块化代码生成；引入基于元学习的标签修正机制，结合干净的最终单元测试标签，通过双层优化改进中间步骤标签。

Result: 在测试时扩展框架下，DreamPRM-Code 在 LiveCodeBench 上实现 80.9% 的 pass@1 精度，达到当前最佳性能，超越 OpenAI o4-mini。

Conclusion: DreamPRM-Code 有效解决了代码生成中步骤分解困难与标签噪声问题，为基于 PRM 的代码生成提供了新范式，显著提升 LLM 在编程任务中的表现。

Abstract: Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.

</details>


### [139] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: Stock Pattern Assistant (SPA) is a deterministic framework that extracts monotonic price runs from daily OHLCV data, aligns them with public events using a symmetric correlation window, and generates factual, historical, and guardrailed explanations. It aims to provide transparency and reproducibility in analyzing price behavior without relying on black-box models.


<details>
  <summary>Details</summary>
Motivation: Existing tools like technical indicators and predictive models lack transparency and interpretability, making them unsuitable for settings requiring auditability. There is a need for a clear, explainable method to understand structural price movements.

Method: SPA uses daily OHLCV data and a normalized event stream to identify monotonic price trends, aligns these with relevant public events via a symmetric correlation window, and generates contextual narratives grounded in historical facts.

Result: Evaluation across four equities (AAPL, NVDA, SCHW, PGR) shows SPA consistently produces stable structural decompositions and meaningful narratives. Ablation studies confirm the contributions of deterministic segmentation, event alignment, and constrained explanation to interpretability.

Conclusion: SPA is not a forecasting or trading signal system but serves as a transparent, reproducible tool for understanding historical price structure, enhancing analyst workflows, risk assessments, and explainable AI pipelines.

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


### [140] [Epistemic diversity across language models mitigates knowledge collapse](https://arxiv.org/abs/2512.15011)
*Damian Hodel,Jevin D. West*

Main category: cs.LG

TL;DR: 本文研究了人工智能生态系统多样性对知识崩溃的缓解作用。通过构建多模型自训练生态系统，发现适度的语义多样性可有效延缓性能衰退，但过度分散数据或模型过少均会导致性能下降，存在最优多样性水平。


<details>
  <summary>Details</summary>
Motivation: 随着AI广泛应用，出现知识崩溃现象，即思想趋于单一化。已有研究揭示了单模型自训练导致的性能衰减问题。本文受生态学启发，探究多模型生态系统中多样性是否能缓解这一问题。

Method: 采用多模型自训练框架，将训练数据在多个语言模型间划分，进行十轮自训练迭代，评估不同多样性水平下的模型性能变化。

Result: 适度的语义多样性有助于缓解知识崩溃；但多样性过低时，模型无法覆盖真实分布；多样性过高时，每个模型容量受限，初始性能即差。存在一个最优多样性区间。

Conclusion: AI生态系统应保持适度多样性，避免单一主导模型。需建立政策激励领域和社区特定模型的发展，以维护AI系统的长期健康与多样性。

Abstract: The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.

</details>


### [141] [EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks](https://arxiv.org/abs/2512.15067)
*Zijiang Yan,Yixiang Huang,Jianhua Pei,Hina Tabassum,Luca Chiaraviglio*

Main category: cs.LG

TL;DR: EMFusion is a conditional multivariate diffusion-based probabilistic forecasting framework for electromagnetic field (EMF) levels, designed to handle frequency-selective and context-aware predictions with uncertainty quantification. It uses a residual U-Net with cross-attention and an imputation-based sampling strategy to ensure temporal coherence and improve accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing methods rely on univariate forecasting of aggregate EMF data, which fails to capture inter-operator and inter-frequency variations critical for proactive network planning and health impact assessment. There is a need for frequency-selective, multivariate forecasting with contextual awareness and uncertainty estimation.

Method: EMFusion employs a conditional multivariate diffusion model with a residual U-Net backbone enhanced by cross-attention to integrate time-of-day, season, and holiday information. It treats forecasting as a structural inpainting task using an imputation-based sampling strategy, enabling robust generation even with irregular measurements. The model outputs calibrated probabilistic prediction intervals directly from the learned conditional distribution.

Result: On frequency-selective EMF datasets, EMFusion with working-hour context outperforms baseline models in both conditional and unconditional settings. It achieves 23.85% better CRPS, 13.93% lower normalized RMSE, and 22.47% reduction in prediction CRPS error compared to the best baseline.

Conclusion: EMFusion provides a state-of-the-art solution for accurate, context-aware, and uncertainty-calibrated EMF forecasting, enabling more reliable network planning and compliance monitoring.

Abstract: The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wideband aggregate EMF data, frequency-selective multivariate forecasting is needed to capture the inter-operator and inter-frequency variations essential for proactive network planning. To this end, this paper introduces EMFusion, a conditional multivariate diffusion-based probabilistic forecasting framework that integrates diverse contextual factors (e.g., time of day, season, and holidays) while providing explicit uncertainty estimates. The proposed architecture features a residual U-Net backbone enhanced by a cross-attention mechanism that dynamically integrates external conditions to guide the generation process. Furthermore, EMFusion integrates an imputation-based sampling strategy that treats forecasting as a structural inpainting task, ensuring temporal coherence even with irregular measurements. Unlike standard point forecasters, EMFusion generates calibrated probabilistic prediction intervals directly from the learned conditional distribution, providing explicit uncertainty quantification essential for trustworthy decision-making. Numerical experiments conducted on frequency-selective EMF datasets demonstrate that EMFusion with the contextual information of working hours outperforms the baseline models with or without conditions. The EMFusion outperforms the best baseline by 23.85% in continuous ranked probability score (CRPS), 13.93% in normalized root mean square error, and reduces prediction CRPS error by 22.47%.

</details>


### [142] [The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems](https://arxiv.org/abs/2512.15068)
*Debu Sinha*

Main category: cs.LG

TL;DR: 本文提出使用置信度预测（conformal prediction）来检测检索增强生成（RAG）系统中的幻觉，提供有限样本下的覆盖保证。在合成幻觉数据上，该方法实现94%覆盖率且0%假阳性率；但在真实幻觉基准测试中，基于嵌入的方法（如OpenAI text-embedding-3-large和交叉编码器）表现出极高的假阳性率（最高达100%）。相比之下，GPT-4作为语言模型判断者仅产生7%的假阳性率，表明任务可通过推理解决。作者将此现象称为“语义幻觉”——即语义上看似合理但包含事实错误的幻觉，其与原始文档保持高相似性，导致嵌入方法无法察觉。该问题普遍存在，不受模型架构、生成器或任务类型影响，说明基于嵌入的检测方法不适用于生产级RAG系统。


<details>
  <summary>Details</summary>
Motivation: 当前幻觉检测方法依赖语义相似性和自然语言推理（NLI），但其根本局限性未被充分理解。RAG系统虽有检索证据支撑，仍易产生难以检测的幻觉，亟需更可靠、可量化的方法以确保系统可信度。

Method: 采用置信度预测（conformal prediction）进行幻觉检测，利用约600个校准样例构建检测框架，提供有限样本下的精确覆盖保证。同时对比多种嵌入模型与GPT-4作为人工判断者的性能差异，分析不同方法在真实与合成数据上的表现。

Result: 在合成数据上，置信度预测达到94%覆盖且无假阳性；但在真实幻觉基准（HaluEval、RAGTruth、WikiBio）上，嵌入方法假阳性率极高（100%、88%、50%），而GPT-4作为判别器仅7%假阳性率（95%置信区间：[3.4%, 13.7%]），证明语义幻觉的存在及其对嵌入方法的隐蔽性。

Conclusion: 基于嵌入的幻觉检测方法在实际场景中不可靠，因存在‘语义幻觉’问题——即幻觉内容在语义上与原文高度相似，却包含事实错误。该问题普遍存在于各类模型和任务中，因此嵌入方法不足以支持生产级RAG系统的部署。未来应转向依赖推理能力的检测机制，如大语言模型作为判断者。

Abstract: Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the "semantic illusion": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.

</details>


### [143] [The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks](https://arxiv.org/abs/2512.15082)
*Wanfu Gao,Zebin He,Jun Gao*

Main category: cs.LG

TL;DR: 提出FEAML，一种基于大语言模型（LLM）的自动化多标签特征工程方法，利用代码生成能力结合元数据和标签共现矩阵，生成高质量特征，并通过模型准确率与皮尔逊相关系数评估冗余，引入反馈机制实现自优化。在多个多标签数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的特征工程方法未应用于多标签学习任务，缺乏对复杂标签依赖关系的建模能力，且不适应多标签任务特性。

Method: FEAML利用大语言模型的代码生成能力，结合数据元信息和标签共现矩阵，引导模型理解特征与任务目标的关系，生成新特征；通过模型精度评估有效性，用皮尔逊相关系数检测冗余，并将评估结果作为反馈用于迭代优化代码生成。

Result: 在多个多标签数据集上的实验表明，FEAML在性能上优于其他特征工程方法，具备高效性、可解释性和自我改进能力。

Conclusion: FEAML通过融合大语言模型与反馈机制，构建了一种高效、可解释且能持续优化的多标签特征工程范式，显著提升了多标签分类任务中的特征质量与模型性能。

Abstract: Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

</details>


### [144] [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)
*Xianglin Wu,Chiheb Ben Hammouda,Cornelis W. Oosterlee*

Main category: cs.LG

TL;DR: SigMA 是一种结合路径签名与多头自注意力机制的神经架构，用于高效估计分数阶布朗运动驱动的随机微分方程中的参数，尤其在 Hurst 参数估计和多参数联合推断方面表现优异。该方法通过卷积预处理和多层感知机进行特征编码，在合成数据及真实世界数据（如股票波动率、锂电池退化）上均优于 CNN、LSTM、Transformer 和 Deep Signature 等基线模型，展现出更高的精度、鲁棒性和模型紧凑性。


<details>
  <summary>Details</summary>
Motivation: 分数阶布朗运动驱动的随机微分方程在金融和可靠性工程中广泛应用，但其非马尔可夫性和非半鞅结构使得传统参数估计方法难以应用或计算复杂。因此需要一种能有效处理粗糙动态与长程依赖的新方法，以提升估计精度并降低模型复杂度。

Method: 提出 SigMA 架构，融合路径签名、卷积预处理、多头自注意力和多层感知机，利用合成路径训练学习模型参数，并支持对 Hurst 参数及多参数联合推断。

Result: SigMA 在多种合成与真实数据集上均显著优于 CNN、LSTM、Transformer 和 Deep Signature 基线模型，在参数估计精度、模型鲁棒性与参数量控制方面表现更优，验证了签名与注意力结合的有效性与可扩展性。

Conclusion: 将路径签名与注意力机制结合是一种高效且可扩展的框架，适用于具有粗糙或持久时间结构的随机系统的参数推断，为复杂动态系统建模提供了新思路。

Abstract: Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.

</details>


### [145] [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)
*Aaron Mueller,Andrew Lee,Shruti Joshi,Ekdeep Singh Lubana,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 本文提出了一种多概念评估设置，通过控制文本概念（如情感、领域、时态）之间的相关性，研究特征提取方法在概念相关性增强时的表现。研究发现，特征与概念之间存在一对多关系，即一个概念可分布在多个特征中，但每个特征仅对应一个概念。尽管稀疏自编码器（SAE）在均匀分布下训练，其特征在操纵时仍会影响多个概念，表明这些特征不具备选择性和独立性，尽管它们影响的是不重叠的子空间。因此，相关性度量不足以衡量解耦性，而影响不重叠子空间也不代表概念选择性。研究强调了在可解释性研究中采用组合式评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法通常孤立地评估概念表示的质量，并隐含假设概念间相互独立，但实际中概念常存在相关性。这使得常见特征化方法（如稀疏自编码器和稀疏探测器）是否能恢复解耦表示尚不明确。为更真实地评估这些方法，需要在可控相关性环境下进行系统评估。

Method: 设计多概念评估框架，控制文本概念间的相关性（如情感、领域、时态），使用稀疏自编码器（SAE）等方法学习特征表示；分析在不同相关强度下的解耦表现；通过操纵实验（steering experiments）检验各概念是否可独立操控。

Result: 1. 特征与概念呈现一对多关系：每个特征只对应一个概念，但一个概念分散于多个特征中。2. 操纵实验显示，即使在无相关性的训练数据上，SAE特征仍会同时影响多个概念，说明特征缺乏选择性和独立性。3. 尽管影响不重叠子空间，但该特性不足以保证概念选择性。4. 相关性度量无法充分反映解耦性，尤其在操纵情境下。

Conclusion: 当前基于相关性的解耦性评估方法不足以验证概念独立性；特征影响不重叠子空间也不代表其具备概念选择性。因此，可解释性研究应引入更复杂的组合式评估范式，以更全面地考察特征表示的质量。

Abstract: A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.

</details>


### [146] [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)
*Runze Li,Hanchen Wang,Wenjie Zhang,Binghao Li,Yu Zhang,Xuemin Lin,Ying Zhang*

Main category: cs.LG

TL;DR: FADTI 是一种基于扩散模型的多变量时间序列插补框架，通过可学习的傅里叶偏置投影（FBP）模块引入频域先验知识，结合自注意力与门控卷积进行时序建模，有效捕捉平稳与非平稳模式，在高缺失率下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于 Transformer 和扩散模型的方法缺乏显式的归纳偏置和频率感知能力，难以在结构化缺失模式和分布偏移下实现良好泛化。

Method: 提出 FBP 模块以注入频域信息，支持多种谱基，实现对时序信号中不同频率成分的自适应编码；结合自注意力机制与门控卷积进行时序建模，增强生成式插补能力。

Result: 在多个基准数据集（包括新引入的生物时间序列数据集）上，FADTI 均显著优于现有最先进方法，尤其在高缺失率场景下优势明显。

Conclusion: FADTI 通过引入频域归纳偏置，提升了多变量时间序列插补在复杂缺失模式下的泛化性能，为高缺失率场景提供了有效的解决方案。

Abstract: Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF

</details>


### [147] [Tracking Temporal Dynamics of Vector Sets with Gaussian Process](https://arxiv.org/abs/2512.15538)
*Taichi Aida,Mamoru Komachi,Toshinobu Ogiso,Hiroya Takamura,Daichi Mochihashi*

Main category: cs.LG

TL;DR: 本文提出一种基于无限维高斯过程的新型方法，用于建模随时间变化的向量集合分布。通过使用随机傅里叶特征近似高斯过程中的潜在函数，获得紧凑且可比较的低维向量表示，从而实现对向量集合随时间演化的追踪与可视化。该方法在犯罪分布和词嵌入等社会学与语言学数据上均表现出色，能有效捕捉结构动态变化，提供可解释且鲁棒的表示。


<details>
  <summary>Details</summary>
Motivation: 分析随时间演变的向量集合在生态、犯罪分析和语言学等领域具有重要意义，但其复杂结构随时间变化使得传统方法难以有效建模。

Method: 采用无限维高斯过程建模向量集合的分布，并利用随机傅里叶特征近似潜在函数，生成低维可比表示，便于时间演化追踪与可视化。

Result: 在犯罪数据和词嵌入数据上的实验表明，该方法能够有效捕捉时间动态，生成可解释且稳定的表示，适用于多种领域中时序向量集的结构分析。

Conclusion: 所提出的框架为分析跨领域的时序向量集合结构变化提供了强大而通用的工具，具有良好的可解释性与鲁棒性。

Abstract: Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.

</details>


### [148] [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)
*Roland Baatz*

Main category: cs.LG

TL;DR: 该研究比较了XGBoost、随机森林、LSTM和TCN等机器学习模型在德国NUTS-3区域作物产量及产量异常预测中的泛化性能与可解释性。尽管所有模型在空间划分的测试集上表现良好，但在时间独立的验证年份上性能显著下降，暴露出泛化能力的局限性。值得注意的是，即使模型在时间验证中表现不佳，其SHAP特征重要性仍可能呈现可信结果，揭示了事后可解释性方法的关键漏洞：可解释性看似可靠时，模型可能已无法泛化。研究强调需采用面向验证的解释方法，结合领域知识进行严格评估，并倡导混合建模与更审慎的可解释性分析，以应对环境数据科学中模型解释可信度的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习模型在农业与环境系统中广泛应用，但其泛化能力常被低估。尤其在时间维度上，模型在历史数据上表现优异，却难以应对未来或未见时间点的数据，导致预测不可靠。同时，后验可解释性方法（如SHAP）常被用于信任模型决策，但若模型本身不具备良好的泛化能力，这些解释可能误导决策。因此，亟需建立更严谨的评估框架，确保模型解释的可靠性。

Method: 基于高质量长期数据集，对多种主流模型（XGBoost、Random Forest、LSTM、TCN）进行系统性对比。采用空间分割测试与时间独立验证相结合的方法，评估模型在不同场景下的性能。通过SHAP值分析特征重要性，并在不同时间阶段对比其稳定性与可信度，识别可解释性与泛化能力之间的脱节现象。

Result: 所有模型在空间测试集上均表现出高精度，但在时间独立验证中性能显著下降，表明其泛化能力不足。部分模型虽在测试集上表现优异，但其在时间验证中的表现差，且对应的SHAP特征重要性仍显示高度一致性，说明可解释性可能具有误导性。研究发现，仅依赖传统测试集评估会严重高估模型的实用性。

Conclusion: 模型的可解释性不能脱离泛化能力独立评估。在农业与环境预测中，必须引入时间维度上的严格验证机制，结合领域知识设计验证策略。未来应发展融合物理机制与数据驱动的混合模型，并对可解释性方法施加更严格的审查标准，以确保模型输出既准确又可信。

Abstract: This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).
  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.
  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?

</details>


### [149] [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)
*Pablo Montaña-Fernández,Ines Ortega-Fernandez*

Main category: cs.LG

TL;DR: 本文提出了一种基于梯度的成员推理攻击方法，利用多轮联邦学习中最后一层梯度的时间演化特性，在无需访问私有数据集的情况下，通过影子技术学习训练记录的梯度模式。该攻击适用于半诚实和恶意对手（聚合器或数据持有者），且为模型无关方法，可应用于任意基于梯度的模型，涵盖分类与回归任务。实验在CIFAR-100、Purchase100和乳腺癌威斯康星数据集上验证了其有效性，结果显示攻击性能强，计算与内存开销与现有方法相当。研究发现：多轮联邦学习会加剧推理攻击风险，聚合器比数据持有者构成更大威胁，且高维复杂数据比简单表格数据更容易泄露信息。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽能减少直接的数据暴露，但模型更新的交换仍可能泄露敏感信息。现有研究对多轮联邦学习中的梯度泄露问题关注不足，尤其缺乏针对梯度时间演化特性的系统性攻击方法。因此亟需一种新型、高效且通用的成员推理与属性推理攻击机制，以揭示联邦学习的实际隐私风险。

Method: 提出一种基于梯度的成员推理攻击，利用多轮训练中最后一层梯度的时间序列变化特征；采用影子模型技术模拟真实训练过程中的梯度响应模式，构建攻击模型；扩展至离散属性推理，通过对比不同属性假设下的梯度响应进行推断；方法具有模型无关性，适用于各类基于梯度的模型和任务类型。

Result: 在CIFAR-100和Purchase100上，成员推理攻击达到高准确率；在乳腺癌威斯康星数据集上成功实现属性推理；攻击性能优于或接近已有方法；计算与内存开销可控；聚合器比数据持有者更具威胁性；高维复杂数据导致更强的信息泄露。

Conclusion: 多轮联邦学习显著增加了梯度泄露风险，尤其在聚合器存在恶意行为时威胁更严重。尽管联邦学习提升了隐私保护，但其通信机制仍存在隐蔽的隐私漏洞。本研究揭示了梯度时间演化特性作为攻击线索的重要性，强调需在系统设计中引入更强的隐私防护机制，如差分隐私或安全聚合。

Abstract: Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.

</details>


### [150] [Understanding NTK Variance in Implicit Neural Representations](https://arxiv.org/abs/2512.15169)
*Chengguang Ou,Yixin Zhuang*

Main category: cs.LG

TL;DR: 本文研究隐式神经表示（INRs）中的谱偏差问题，揭示其收敛缓慢和高频细节恢复困难的原因。通过分析神经正切核（NTK）的条件性，发现架构选择通过影响一组成对相似性因子与缩放项，共同决定NTK特征值方差。标准坐标MLP因输入特征交互有限导致特征值分散大、条件差。作者推导了常见INR组件的闭式方差分解，表明位置编码可重塑输入相似性，球面归一化通过逐层缩放降低方差，哈达玛调制引入小于1的额外相似性因子，实现乘法式方差缩减。这一统一视角解释了多种INR架构如何通过改善NTK条件性来缓解谱偏差。实验验证了预测的方差减少，并展示了更快更稳定的收敛及更高的重建质量。


<details>
  <summary>Details</summary>
Motivation: INRs在训练中收敛慢且难以恢复高频细节，主要受谱偏差影响。尽管已有研究关联此现象与神经正切核（NTK），但具体架构设计如何影响NTK条件性仍不明确，亟需系统性理解以指导高效INR设计。

Method: 提出基于成对相似性因子与缩放项的理论框架，分析不同INR组件对NTK特征值方差的影响；推导常见组件（如位置编码、球面归一化、哈达玛调制）的闭式方差分解表达式，量化其对NTK条件性的改进机制。

Result: 理论分析表明，位置编码、球面归一化和哈达玛调制均能有效降低NTK特征值方差，改善条件性；实验验证了这些组件在多种任务中显著提升收敛速度、稳定性与重建质量。

Conclusion: 通过系统分析架构对NTK条件性的影响，本研究建立了一个统一的理论框架，阐明了多种INR设计为何能缓解谱偏差。该框架为未来高效INR架构的设计提供了可解释的指导原则。

Abstract: Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.

</details>


### [151] [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)
*Zicong Cheng,Guo-Wei Yang,Jia Li,Zhijie Deng,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.LG

TL;DR: DEER提出使用扩散语言模型（dLLM）作为非自回归的草稿生成器，以克服传统自回归草稿模型在信任累积和序列解码上的局限性，实现更高效的推测解码。通过两阶段训练对齐与单步解码，DEER可生成长达32个词元的草稿，相比EAGLE-3的10个词元显著提升，并在HumanEval上实现5.54倍速度提升，远超EAGLE-3的2.41倍。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法依赖自回归草稿模型，存在逐步不确定性累积和固有的序列解码限制，导致速度提升有限。为突破这一瓶颈，需要一种更高效、并行化更强的草稿生成机制。

Method: 提出DEER框架，采用扩散大语言模型（dLLM）作为非自回归草稿生成器，结合两阶段训练对齐目标自回归模型，利用单步解码生成长段落草稿，并通过自回归模型进行验证，实现高效推测解码。

Result: DEER可生成最长达32个词元的可接受草稿，显著优于EAGLE-3的10个词元；在Qwen3-30B-A3B模型上，HumanEval任务中达到5.54倍速度提升，远超EAGLE-3的2.41倍。

Conclusion: 扩散语言模型作为草稿生成器在推测解码中具有显著优势，能有效解决自回归草稿模型的性能瓶颈，推动大语言模型推理效率的大幅提升。

Abstract: Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/

</details>


### [152] [Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT](https://arxiv.org/abs/2512.15206)
*Liyu Zhang,Yejia Liu,Kwun Ho Liu,Runxi Huang,Xiaomin Ouyang*

Main category: cs.LG

TL;DR: Chorus是一种无数据、上下文感知的模型定制方法，可在无需目标域数据的情况下适应未见部署条件。它通过无监督跨模态重建传感器数据与基于语言的上下文嵌入，学习鲁棒的通用上下文表示，并利用轻量级门控头动态平衡传感器与上下文贡献。此外，通过上下文缓存机制减少推理延迟。在多种上下文变化下的IMU、语音和WiFi传感任务中，Chorus在未见上下文中性能优于现有基线最多11.3%，且在智能手机和边缘设备上保持相近延迟。


<details>
  <summary>Details</summary>
Motivation: 传统领域自适应或泛化方法忽视上下文信息或使用简单整合策略，难以应对部署后未见的上下文变化。真实世界物联网应用中，传感器数据受放置位置、环境等动态上下文因素显著影响，需更智能的上下文感知模型适配机制。

Method: Chorus首先通过无监督跨模态重建对未标记传感器数据与语言上下文嵌入进行联合建模，正则化上下文嵌入空间以学习通用上下文表示；其次，在少量标注样本上训练轻量级门控头，根据上下文偏移程度动态调节传感器与上下文的贡献权重；最后引入上下文缓存机制，仅在检测到上下文变化时更新表示，降低推理延迟。

Result: 在多种上下文变化下，Chorus在IMU、语音和WiFi传感任务中表现优异，相比现有最先进方法在未见上下文中最高提升11.3%；同时在手机和边缘设备上保持低延迟，具备实际部署可行性。

Conclusion: Chorus成功实现了无需目标数据的上下文感知模型定制，有效应对现实场景中的动态上下文变化，为物联网环境中模型的持续适应提供了高效、轻量的解决方案。

Abstract: In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.

</details>


### [153] [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)
*Elio Gruttadauria,Mathieu Fontaine,Jonathan Le Roux,Slim Essid*

Main category: cs.LG

TL;DR: O-EENC-SD 是一种基于 EEND-EDA 的端到端在线说话人分离系统，引入了基于 RNN 的拼接机制和新颖的中心点精炼解码器，在无需超参数调节且计算效率更高的前提下，实现了与现有最优方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有在线端到端说话人分离方法计算成本高，而无监督聚类方法需要大量超参数调整。为解决这些问题，提出一种高效、免超参数的在线系统。

Method: 采用基于 RNN 的拼接机制与中心点精炼解码器，实现端到端的在线说话人分离，通过消融实验验证其有效性。

Result: 在 CallHome 数据集上，O-EENC-SD 在双说话人电话对话场景中表现优异，显著优于现有方法，兼具低错误率（DER）与低复杂度，即使在独立非重叠块上处理也保持高效。

Conclusion: O-EENC-SD 提供了一种高效、免超参数的在线说话人分离解决方案，具有良好的实用性和竞争力。

Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

</details>


### [154] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: 本文提出一种基于自监督学习的多模态生理信号融合方法，利用预训练的CBraMod编码器对ECG和EEG进行特征提取，并引入双掩码策略捕捉导联间与导联内依赖关系。通过简单嵌入拼接实现跨模态融合，使分类头学习跨模态交互，在有限标注数据下实现接近顶尖的的情绪识别性能，验证了基础模型在生理信号分析中的潜力。


<details>
  <summary>Details</summary>
Motivation: 多模态生理信号（如ECG和EEG）虽能互补提供健康与认知信息，但受限于少样本多模态标注数据及模态差异，导致融合困难。

Method: 采用自监督预训练的CBraMod编码器对ECG进行预处理，引入双掩码策略以捕获导联内与导联间依赖；对EEG使用相同预训练编码器，并对ECG设计对称编码器，生成丰富的基础表示；通过嵌入拼接实现模态融合，使分类头学习跨模态交互。

Result: 在情绪识别任务上达到接近当前最优性能，证明即使使用简单融合策略，精心设计的生理信号编码器也能显著提升下游任务表现。

Conclusion: 该研究展示了基础模型在整合多模态生理信号方面的巨大潜力，为医疗健康与情感计算提供了可扩展、低标签依赖且通用的解决方案。

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [155] [Topological Metric for Unsupervised Embedding Quality Evaluation](https://arxiv.org/abs/2512.15285)
*Aleksei Shestov,Anton Klenitskiy,Daria Denisova,Amurkhan Dzagkoev,Daniil Petrovich,Andrey Savchenko,Maksim Makarenko*

Main category: cs.LG

TL;DR: 本文提出了一种基于持久同调的拓扑感知度量方法Persistence，用于在无监督条件下评估嵌入空间的几何结构与拓扑丰富性。该方法不依赖线性可分性或协方差结构，能够捕捉全局和多尺度组织特征，在多个领域中表现出与下游性能高度相关的优异表现，优于现有无监督度量方法，可用于可靠地进行模型与超参数选择。


<details>
  <summary>Details</summary>
Motivation: 当前表示学习依赖大规模无标签数据的自监督方法，但缺乏有效的无监督嵌入质量评估手段，尤其难以衡量嵌入空间的几何与拓扑结构。因此亟需一种无需标签、能反映深层结构特性的评估指标。

Method: 提出基于持久同调（persistent homology）的度量方法Persistence，通过分析嵌入空间中不同尺度下的拓扑特征（如连通分量、环状结构等），量化其几何与拓扑复杂性，实现完全无监督的评估。

Result: 在多种任务和数据集上，Persistence与下游任务性能具有极高的相关性，显著优于现有的无监督评估指标，能够有效指导模型选择与超参数优化。

Conclusion: Persistence是一种强大且通用的无监督嵌入质量评估工具，能够揭示嵌入空间的深层结构信息，为自监督学习提供了可靠的评估框架。

Abstract: Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.

</details>


### [156] [Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference](https://arxiv.org/abs/2512.15335)
*Chenxiang Zhang,Tongxi Qu,Zhong Li,Tian Zhang,Jun Pang,Sjouke Mauw*

Main category: cs.LG

TL;DR: 本文首次系统研究了后训练量化（PTQ）中的隐私-效用关系，发现低精度量化可显著降低隐私泄露风险，尤其在1.58位及以下时，成员推断攻击的脆弱性可降低一个数量级，但以牺牲模型效用为代价。通过仅对最后一层保持较高精度，可实现对隐私与效用权衡的细粒度控制，为实际部署中平衡效率、性能与隐私保护提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 现有隐私分析多针对全精度模型，而量化会改变模型参数和输出，因此亟需理解比特宽度降低对隐私泄露的影响，填补该研究空白。

Method: 采用成员推断攻击作为评估框架，系统分析AdaRound、BRECQ和OBC三种主流PTQ方法在4位、2位和1.58位等不同精度水平下的表现，覆盖CIFAR-10、CIFAR-100和TinyImageNet三个数据集，并进行1.58位下的消融实验以探索精度分配策略。

Result: 低精度PTQ显著降低隐私泄露，最高可达一个数量级的减少；同时发现仅对最后一层保持高精度可在不严重损害性能的前提下增强隐私保护。

Conclusion: 量化不仅提升效率，还能增强隐私保护，且通过精细化的层间精度分配，可实现对隐私-效用权衡的可控调节，为实际应用提供了重要实践指导。

Abstract: Deep neural networks are widely deployed with quantization techniques to reduce memory and computational costs by lowering the numerical precision of their parameters. While quantization alters model parameters and their outputs, existing privacy analyses primarily focus on full-precision models, leaving a gap in understanding how bit-width reduction can affect privacy leakage. We present the first systematic study of the privacy-utility relationship in post-training quantization (PTQ), a versatile family of methods that can be applied to pretrained models without further training. Using membership inference attacks as our evaluation framework, we analyze three popular PTQ algorithms-AdaRound, BRECQ, and OBC-across multiple precision levels (4-bit, 2-bit, and 1.58-bit) on CIFAR-10, CIFAR-100, and TinyImageNet datasets. Our findings consistently show that low-precision PTQs can reduce privacy leakage. In particular, lower-precision models demonstrate up to an order of magnitude reduction in membership inference vulnerability compared to their full-precision counterparts, albeit at the cost of decreased utility. Additional ablation studies on the 1.58-bit quantization level show that quantizing only the last layer at higher precision enables fine-grained control over the privacy-utility trade-off. These results offer actionable insights for practitioners to balance efficiency, utility, and privacy protection in real-world deployments.

</details>


### [157] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: 本文提出两种相位感知预处理策略，用于解决多轴振动数据中的随机相位变化问题。第一种是三轴独立相位调整，将每轴单独对齐至零相位；第二种是单轴参考相位调整，通过统一时间偏移保留各轴间的相位关系。基于新构建的同步三轴传感器数据集，在六种深度学习架构上评估了两种方法，结果表明：三轴独立方法在Transformer模型上提升2.7%，而单轴参考方法最高实现96.2%准确率（提升5.4%），且能有效保持空间相位关系。研究证明这两种方法在预测性维护系统中具有普适性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的旋转机械预测性维护方法通常忽略或未显式利用振动信号中的相位信息，导致性能受限。尤其在多轴振动数据中，随机相位变化会干扰特征提取和模型训练，亟需有效的相位对齐策略以提升预测精度。

Method: 提出两种相位感知预处理策略：(1) 三轴独立相位调整，分别对每个轴进行相位对齐至零相位；(2) 单轴参考相位调整，以某一轴为参考，对其他轴施加统一时间偏移以保持轴间相位关系。结合两阶段学习框架，在新构建的同步三轴振动数据集上评估六种深度学习模型。

Result: 三轴独立相位调整带来稳定性能提升（如Transformer提升2.7%）；单轴参考相位调整表现更优，最高达到96.2%准确率，相比基线提升5.4%，显著改善了模型对多轴相位空间关系的建模能力。

Conclusion: 所提出的两种相位对齐策略均为预测性维护系统提供了实用且可扩展的改进方案，尤其单轴参考方法在保留空间相位结构方面具有显著优势，适用于高精度故障诊断场景。

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [158] [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)
*Honey Singh Chauhan,Zahraa S. Abdallah*

Main category: cs.LG

TL;DR: Fusion-3 (F3) is a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations for univariate time series classification, improving performance on datasets with structured variability or rich frequency content. It uses meta-features to cluster UCR datasets into six interpretable regimes, showing fusion outperforms Rocket in structured settings but offers diminishing returns in irregular or outlier-heavy cases. Analysis via non-parametric tests, ablation, and SHAP attribution confirms the benefits and mechanisms of fusion, with case studies revealing error correction through adaptive frequency weighting.


<details>
  <summary>Details</summary>
Motivation: Rocket-based methods are effective but not universally optimal across all time series datasets. The motivation is to improve performance by selectively fusing complementary representations—Rocket, Sax, and Sfa—based on dataset characteristics.

Method: F3 adaptively fuses three representations using meta-features capturing series length, spectral structure, roughness, and class imbalance. Datasets are clustered into six regimes; fusion gains are analyzed via statistical tests, ablation, SHAP attribution, and case studies.

Result: F3 achieves small but consistent improvements over Rocket across 113 UCR datasets using 5-fold cross-validation. Fusion is most effective in datasets with structured variability or rich frequency content, while offering less benefit in highly irregular or outlier-heavy cases. SHAP analysis identifies key predictors of fusion gain, and case studies reveal that fusion corrects specific errors via adaptive frequency-domain weighting.

Conclusion: Selective fusion of representations provides a reliable, interpretable extension to strong kernel-based methods like Rocket, correcting their weaknesses precisely where data structure supports it.

Abstract: Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.

</details>


### [159] [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)
*Julian Oelhaf,Mehran Pashaei,Georg Kordowich,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: 本文提出了一种统一框架，用于系统评估机器学习模型在电力系统保护中的鲁棒性。通过高保真电磁暂态（EMT）仿真模拟传感器故障、采样率降低和通信中断等现实退化场景，量化了可观测性受限对故障分类（FC）和故障定位（FL）性能的影响。结果显示，尽管故障分类在多数退化情况下保持稳定，但单相电压丢失导致其性能下降约13%；而故障定位对退化更为敏感，电压测量丢失使定位误差增加超过150%。研究为未来鲁棒性感知的机器学习辅助保护系统设计提供了可操作指导。


<details>
  <summary>Details</summary>
Motivation: 传统保护方案依赖固定设定和本地测量，在可再生能源和分布式发电渗透率提升的背景下面临挑战。机器学习提供数据驱动的集中式故障分类与定位方法，但其实际部署需确保在传感器数据缺失、噪声或退化情况下的可靠性。因此，亟需一种系统化的鲁棒性评估框架。

Method: 采用高保真电磁暂态（EMT）仿真构建多种真实退化场景，包括传感器断开、采样率下降和瞬时通信丢失；提出统一框架以基准测试不同机器学习模型，量化可观测性受限的影响，并识别关键测量通道。

Result: 故障分类在多数退化条件下表现稳定，但在单相电压丢失时性能下降约13%；故障定位整体更敏感，电压测量丢失导致定位误差增加超过150%。

Conclusion: 该框架可有效评估机器学习模型在电力系统保护中的鲁棒性，研究成果为设计更具韧性、适应性强的下一代智能保护系统提供了重要依据。

Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.
  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

</details>


### [160] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: 本文提出了一种基于贝叶斯强化学习的算法EUBRL，利用认知不确定性引导探索，有效降低因估计误差带来的每步遗憾。该算法在无限时域折扣马尔可夫决策过程（MDP）中，对充分表达性强的先验分布具有近似极小极大最优的遗憾和样本复杂度保证。实验表明，EUBRL在稀疏奖励、长周期和随机性任务中表现出更优的样本效率、可扩展性和一致性。


<details>
  <summary>Details</summary>
Motivation: 在已知与未知的边界处，智能体面临探索与利用的权衡。认知不确定性反映了这种知识局限带来的系统性不确定性，因此需要一种能有效引导探索的机制以减少估计误差导致的遗憾。

Method: 提出贝叶斯强化学习算法EUBRL，通过利用认知不确定性来指导探索，实现对估计误差的自适应调节，并在理论上建立针对充分表达性先验的近似极小极大最优的后悔和样本复杂度分析。

Result: EUBRL在稀疏奖励、长周期和高随机性的任务中展现出显著提升的样本效率、可扩展性和一致性，且理论分析证明其具备近似最优的后悔与样本复杂度性能。

Conclusion: EUBRL通过引入认知不确定性进行探索引导，在理论上和实践中均表现优异，为解决复杂强化学习中的探索-利用困境提供了有效方案。

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>


### [161] [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)
*Yeonwoo Cha,Semin Kim,Jinhyeon Kwon,Seunghoon Hong*

Main category: cs.LG

TL;DR: FlowBind 是一种高效的任意模态间生成框架，通过共享潜在空间和模态特定的可逆流实现跨模态翻译。该方法在单一流匹配目标下联合优化，推理时可直接进行模态转换，显著降低数据需求和计算成本。实验表明，其在文本、图像、音频任务中达到与现有方法相当的生成质量，同时参数量减少最多6倍，训练速度提升10倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于流的方法在任意模态间生成中面临效率低下问题，包括需要大规模配对数据、高计算开销以及复杂的多阶段训练流程。为解决这些问题，提出更高效、灵活且简单的框架。

Method: FlowBind 采用共享潜在空间来捕捉跨模态信息，并利用模态特定的可逆流将潜在空间映射到各模态；两个组件在统一的流匹配目标下联合优化，推理时可逆流作为编码器/解码器实现直接跨模态翻译。

Result: 在文本、图像、音频任务上，FlowBind 实现了与现有方法相当的生成质量，但参数量减少最多6倍，训练速度提升10倍，且支持任意模态子集训练。

Conclusion: FlowBind 通过简化结构和共享潜在空间，实现了高效、灵活的任意模态间生成，在性能与效率之间取得良好平衡，具有广泛的应用潜力。

Abstract: Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.

</details>


### [162] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada,Shu Tanaka*

Main category: cs.LG

TL;DR: 本研究探讨了随机矩阵中经极小-极大归一化后的特征值的统计特性，提出并验证了其累积分布的缩放律，并推导出矩阵分解中的残差误差，通过数值实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 在数据科学实践中，输入数据通常需归一化处理，因此研究归一化特征值的统计性质具有重要意义。此前已有有效分布模型，但其在缩放律和矩阵分解残差方面的应用尚不充分。

Method: 基于已有的有效分布模型，分析归一化特征值的累积分布行为，推导矩阵分解过程中的残差误差表达式，并通过数值模拟进行验证。

Result: 成功建立了归一化特征值累积分布的缩放律，并准确预测了矩阵分解中的残差误差，数值实验结果与理论一致。

Conclusion: 本研究为随机矩阵在归一化条件下的特征值行为提供了新的理论框架，有助于提升数据科学中相关算法的精度与可解释性。

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [163] [Double Horizon Model-Based Policy Optimization](https://arxiv.org/abs/2512.15439)
*Akihiro Kubo,Paavo Parmas,Shin Ishii*

Main category: cs.LG

TL;DR: 提出双时域模型基于强化学习方法（DHMBPO），通过长分布滚动（DR）和短训练滚动（TR）分别解决分布偏移和梯度不稳定性问题，显著提升样本效率与运行速度。


<details>
  <summary>Details</summary>
Motivation: 现有模型基于强化学习方法在选择滚动长度时面临两难：长滚动虽能更好保持策略一致性但放大模型偏差，而过长的滚动又会增加梯度方差，导致训练不稳定；因此需要平衡分布偏移、模型偏差与梯度稳定性。

Method: 提出双时域机制：长分布滚动（DR）用于生成接近真实策略的数据以缓解分布偏移；短训练滚动（TR）利用可微分转移实现准确且稳定的梯度估计，减少更新次数并降低整体计算时间。

Result: 实验表明，该方法有效平衡了分布偏移、模型偏差与梯度不稳定性，在连续控制基准测试中优于现有MBRL方法，兼具更高的样本效率和更低的运行时间。

Conclusion: 双时域设计能够协同优化MBRL中的多个关键挑战，是提升模型基于强化学习性能的有效路径。

Abstract: Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long "distribution rollout" (DR) and a short "training rollout" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.

</details>


### [164] [Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting](https://arxiv.org/abs/2512.15442)
*Neeraj Sarna,Yuanyuan Li,Michael von Gablenz*

Main category: cs.LG

TL;DR: 本文研究了如何通过结合思维链、任务指令提示、负向提示和提示重写等策略，降低大规模文本到图像生成模型中版权内容的生成风险。通过数值实验，评估了这些方法在不同复杂度模型上的有效性，重点关注生成图像与受版权保护图像的相似性以及与用户输入的相关性。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像生成模型可能记忆并重现训练数据中的版权内容，带来法律和财务风险，因此需要有效的版权保护机制。

Method: 结合思维链提示、任务指令提示、负向提示和提示重写四种策略，系统评估其在减少版权内容生成方面的效果。

Result: 实验表明，所提出的方法能有效降低生成图像与版权图像的相似性，同时保持与用户输入的相关性，且在不同模型复杂度下表现稳定。

Conclusion: 综合多种提示策略可显著降低版权侵权风险，为实际应用提供了可行的版权保护方案。

Abstract: Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.

</details>


### [165] [From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning](https://arxiv.org/abs/2512.15460)
*Xiangrui Xu,Zhize Li,Yufei Han,Bin Wang,Jiqiang Liu,Wei Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Invertibility Loss（InvLoss）的新框架，用于量化联邦学习（FL）系统中数据重建攻击（DRA）的最大有效程度。通过推导出可计算的紧致上界，该方法从雅可比矩阵的谱特性出发，统一解释了现有防御手段的有效性，并提出了InvRE风险评估器和两种自适应噪声扰动防御策略，在真实数据集上验证了其在风险评估与隐私保护方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习系统面临数据重建攻击（DRA）的严重威胁，但缺乏理论基础的风险量化框架来评估此类攻击的风险水平，因此亟需一种可量化的风险分析方法。

Method: 提出Invertibility Loss（InvLoss）作为衡量数据重建攻击有效性的指标，推导其紧致且可计算的上界；基于雅可比矩阵的谱性质分析攻击风险机制；设计InvRE风险评估器实现对不同数据实例和模型架构的全面评估；提出两种自适应噪声扰动防御方法以提升隐私保护而不牺牲分类性能。

Result: 实验结果表明，所提出的框架能够有效评估和缓解联邦学习中的数据重建攻击风险，同时在不损害模型准确率的前提下显著增强隐私保护能力。

Conclusion: 本文构建了一个理论严谨、可计算且实用的联邦学习数据重建攻击风险量化与防御框架，为未来安全高效的联邦学习系统设计提供了新思路。

Abstract: Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.

</details>


### [166] [Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier](https://arxiv.org/abs/2512.15492)
*Adrián Detavernier,Jasper De Bock*

Main category: cs.LG

TL;DR: 本文比较了两种评估分类器个体预测可靠性的方式——鲁棒性量化（RQ）和不确定性量化（UQ），发现两者无明显优劣，但具有互补性，结合后可形成性能更优的混合方法。同时，该研究还评估了各数据集中不确定性与鲁棒性作为不可靠性来源的相对重要性。


<details>
  <summary>Details</summary>
Motivation: 评估分类器预测的可靠性是机器学习中的关键问题。传统方法往往只关注不确定性或鲁棒性中的一个方面，而忽视了两者的协同作用。本文旨在探索两种不同方法的互补性，并寻找更全面的可靠性评估方案。

Method: 在多个基准数据集上对RQ和UQ两种方法进行对比实验，分析其表现差异；通过融合两种方法构建混合评估框架，并验证其有效性；进一步分析每个数据集中不确定性与鲁棒性对预测不可靠性的贡献程度。

Result: RQ和UQ在不同数据集上表现各有优劣，没有统一的最优方法；但二者结合后的混合方法显著优于单独使用任一方法；同时，研究揭示了不同数据集中不确定性与鲁棒性对不可靠性的相对影响。

Conclusion: RQ和UQ是互补而非替代的关系，将二者结合能有效提升预测可靠性的评估能力。该混合方法为未来可靠性评估提供了更全面的思路，并有助于理解不同类型错误的根本原因。

Abstract: We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.

</details>


### [167] [Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation](https://arxiv.org/abs/2512.15574)
*Yuxin Cai,Yanyong Huang,Jinyuan Chang,Dongjie Wang,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: 提出一种名为JUICE的新方法，用于无监督多视图特征与实例联合选择，通过统一框架同时处理缺失数据恢复和共选择，利用跨视图邻域信息提升补全精度并增强代表性特征与实例的选择效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法将缺失数据补全与特征/实例共选择视为独立过程，忽略了二者间的潜在交互；且简单拼接多视图数据无法有效捕捉视图间互补信息，限制了共选择性能。

Method: JUICE首先基于可用观测重建不完整多视图数据，在统一框架中联合进行缺失值补全、特征与实例共选择；随后利用跨视图邻居信息学习样本间关系，进一步优化缺失值补全，从而提升共选择质量。

Result: 实验表明，JUICE在多个基准数据集上显著优于当前最先进的方法，验证了其有效性与优越性。

Conclusion: JUICE通过联合建模缺失数据补全与特征/实例共选择，充分利用跨视图信息与样本间关系，实现了更高效、更准确的多视图数据降维与样本筛选。

Abstract: Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.

</details>


### [168] [Corrective Diffusion Language Models](https://arxiv.org/abs/2512.15596)
*Shuibai Zhang,Fred Zhangzhi Peng,Yiheng Zhang,Jin Pan,Grigorios G. Chrysos*

Main category: cs.LG

TL;DR: 该论文研究扩散语言模型中的纠错行为，发现标准的掩码扩散语言模型训练无法有效识别不可靠的标记，导致基于置信度的迭代修正失效。为此，作者提出一种面向纠正的后训练方法，显式监督可见的错误标记，从而实现对错误的感知置信度和针对性修正。为评估纠错能力，提出了代码修订基准（CRB），实验表明所提方法在代码修订任务中显著优于传统方法，同时提升了纯补全性能。


<details>
  <summary>Details</summary>
Motivation: 标准的掩码扩散语言模型（MDLM）虽然在结构上适合迭代纠错，但其训练目标无法可靠诱导模型识别输入中的错误标记，导致无法进行有效的置信度引导修正。因此需要一种新的训练机制来增强模型的纠错能力。

Method: 提出一种纠正导向的后训练原则，通过显式监督可见的错误标记，使模型能够学习到对错误内容赋予较低置信度，并在后续迭代中进行有针对性的修正；同时构建了可控制、可执行的代码修订基准（CRB）用于评估纠错表现。

Result: 在代码修订任务和受控实验中，采用新方法训练的模型在纠错能力上显著优于标准MDLM，且在纯文本补全任务中也表现出更好的性能。

Conclusion: 传统的掩码扩散语言模型训练不足以激发有效的纠错行为；通过引入纠正导向的后训练策略并结合专用评估基准，可以显著提升模型的错误感知与修正能力，兼具纠错与生成优势。

Abstract: Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.

</details>


### [169] [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)
*Alexandre Dussolle,Pietro Liò*

Main category: cs.LG

TL;DR: 本文提出N-simplicial attention，将注意力机制从成对交互扩展到高阶交互，并适配Rotary Position Embeddings（RoPE）。为应对复杂度提升，设计了低成本的单纯形选择策略，聚焦于任务敏感的交互。同时研究了N-simplicial attention的平滑性，发现其即使在引入高阶交互后仍存在过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型如GAT或Transformer虽通过图消息传递机制提升性能，但存在计算开销大等问题。为突破成对交互局限，探索更高阶的交互模式以增强表达能力，同时保持计算效率和稳定性。

Method: 提出N-simplicial attention机制，利用高阶单纯形结构建模多节点间的复杂关系；结合Rotary Position Embeddings实现位置感知；设计基于重要性的单纯形选择策略降低计算成本；通过理论推导给出注意力的Lipschitz上界，分析其过平滑现象。

Result: 实验表明，所提方法在保持高效计算的同时，能有效捕捉高阶语义关系；但即便如此，注意力机制仍面临过平滑问题，限制了进一步性能提升。

Conclusion: N-simplicial attention拓展了传统注意力的交互维度，提升了模型表达能力，但需额外处理过平滑问题，未来工作应关注如何平衡高阶交互与信息保留之间的关系。

Abstract: Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.

</details>


### [170] [Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction](https://arxiv.org/abs/2512.15605)
*Mathieu Blondel,Michael E. Sander,Germain Vivier-Ardisson,Tianlin Liu,Vincent Roulet*

Main category: cs.LG

TL;DR: 本文提出了一种统一视角，将自回归模型（ARMs）与基于能量的模型（EBMs）在函数空间中通过概率链式法则建立显式双射关系，并揭示其对应于最大熵强化学习中的软贝尔曼方程特例。基于此双射，证明了监督学习中ARMs与EBMs的等价性，并给出了EBMs向ARMs蒸馏过程的理论误差界。研究揭示了尽管基于逐词预测范式，ARMs仍具备前瞻规划能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要采用自回归模型（ARMs），而基于能量的模型（EBMs）虽历史较少用于LLM开发，但天然适合后训练对齐中的最优策略表征。本文旨在统一两类模型，揭示其内在联系并解释ARMs的规划能力来源。

Method: 以概率链式法则为起点，构建ARMs与EBMs在函数空间的显式双射关系，将其与最大熵强化学习中的软贝尔曼方程关联；进一步推导监督学习下的等价性，并分析EBMs到ARMs蒸馏的理论误差边界。

Result: 建立了ARMs与EBMs之间的函数空间双射，证明了二者在监督学习下的等价性，给出了蒸馏过程的理论误差界，并揭示了自回归模型具备前瞻规划能力的理论基础。

Conclusion: 本研究通过统一框架揭示了自回归模型与基于能量模型的本质联系，不仅深化了对现有大语言模型机制的理解，也为未来模型设计和对齐方法提供了理论支持。

Abstract: Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.

</details>


### [171] [Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary](https://arxiv.org/abs/2512.15614)
*Xinshun Feng,Mingzhe Liu,Yi Qiao,Tongyu Zhu,Leilei Sun,Shuai Wang*

Main category: cs.LG

TL;DR: BEAT提出一种统一且可迁移的框架，通过向量化量化自动编码器构建行为词汇表，将用户和物品行为离散化为可解释序列，并利用多级语义监督和语义对齐正则化机制，将行为标记直接嵌入冻结语言模型的输入空间，显著提升零样本推荐性能并生成连贯、信息丰富的解释。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法依赖基于ID的表示，掩盖了语义信息并限制了语言模型在开放场景中的应用；真实世界交互中用户意图复杂且协同信号与语言语义不一致，亟需更灵活、语义丰富的行为建模方式。

Method: 提出BEAT框架，采用向量化量化自动编码器构建行为词汇表，分离宏观兴趣与微观意图；设计多级语义监督与语义对齐正则化机制，实现行为标记与语言模型输入空间的对齐。

Result: 在三个公开数据集上实验表明，BEAT显著提升零样本推荐性能，生成的解释具有高连贯性和信息量；行为标记能捕捉细粒度语义，支持即插即用式集成复杂行为模式至大语言模型。

Conclusion: BEAT成功实现了行为表示与语言模型的高效融合，为可解释推荐提供了可扩展、语义丰富的解决方案，具备良好的泛化与迁移能力。

Abstract: Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.

</details>


### [172] [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)
*Tianze Luo,Haotian Yuan,Zhuang Liu*

Main category: cs.LG

TL;DR: 提出Solution Flow Models (SoFlow)，实现从零开始的一步生成，通过分析速度函数与解函数的关系，引入流匹配损失和解一致性损失，无需计算雅可比向量积（JVP），在相同训练条件下优于MeanFlow模型，在ImageNet 256x256上取得更优的FID-50K分数。


<details>
  <summary>Details</summary>
Motivation: 多步去噪过程在扩散模型和流匹配模型中导致显著效率问题，推动了少步生成的研究。

Method: 分析速度微分方程中的速度函数与解函数关系，设计流匹配损失和解一致性损失，用于训练模型；利用流匹配损失支持分类器无指导（CFG）训练，提升生成质量。

Result: 在相同DiT架构和训练周期下，SoFlow在ImageNet 256x256数据集上取得优于MeanFlow的FID-50K分数，且避免了对JVP的依赖。

Conclusion: SoFlow实现了高效的一步生成，具有良好的生成性能和训练便利性，为快速生成提供了新范式。

Abstract: The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.

</details>


### [173] [A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks](https://arxiv.org/abs/2512.15685)
*Oleg Melnikov,Yurii Dorofieiev,Yurii Shakhnovskiy,Huy Truong,Victoria Degeler*

Main category: cs.LG

TL;DR: 本文提出了一种统一框架SICAMS，用于在供水管网中检测、分类并初步定位异常。该方法通过白化变换消除压力和流量传感器数据间的空间相关性，基于变换后的数据构建Hotelling's $T^2$统计量，将其作为系统健康状态的综合指标，并与总泄漏量相关联，实现水损的近似估算。采用启发式算法对$T^2$时间序列进行分析，将异常分为突发泄漏、早期泄漏和传感器故障。此外，提出一种粗略的泄漏定位方法，通过传感器的统计贡献排序并结合拉普拉斯插值，估计受影响区域。在BattLeDIM L-Town基准数据集上的应用显示该方法具有高灵敏度和可靠性，即使在多重泄漏情况下仍表现稳健，且无需校准的水力模型即可应用于实际运行环境。


<details>
  <summary>Details</summary>
Motivation: 现有供水管网异常检测方法通常依赖于复杂的水力模型或仅关注单一类型的异常，难以实现高效、准确的多类型异常检测与定位。为提升实时监控能力，亟需一种无需依赖精确水力模型、能处理异构传感器数据并实现检测-分类-定位一体化的通用方法。

Method: 提出SICAMS框架，包括：1）对异构压力与流量数据进行白化变换以消除空间相关性；2）基于变换后数据构建Hotelling's $T^2$统计量，用于异常检测；3）利用回归模型建立$T^2$与总泄漏量之间的关系，估算水损；4）设计启发式算法对$T^2$时间序列进行分析，实现异常类型分类（突发、早期泄漏、传感器故障）；5）提出基于统计贡献排序与拉普拉斯插值的粗略泄漏定位方法。

Result: 在BattLeDIM L-Town基准数据集上验证，SICAMS表现出高灵敏度与可靠性，能够有效识别单个及多个泄漏事件，对不同类型的异常具备良好分类能力，且无需依赖水力模型即可实现近似泄漏定位。实验结果表明，$T^2$统计量与总泄漏量显著相关，可支持水损估算。

Conclusion: SICAMS提供了一种不依赖水力模型的高效、鲁棒的供水管网异常检测与分类方法，具备良好的实用性和扩展性，适用于真实运行环境中的在线监测与管理。

Abstract: This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall "health" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.

</details>


### [174] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2512.15687)
*Zhenwen Liang,Sidi Lu,Wenhao Yu,Kishan Panaganti,Yujun Zhou,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: G2RL提出一种基于模型自身梯度几何的强化学习探索框架，通过分析模型输出层敏感性构建序列级特征，衡量轨迹对策略更新方向的影响，从而引导探索。相比传统熵奖励或外部语义比较方法，G2RL能更有效生成多样化且与优化目标一致的更新方向，在多个数学与通用推理基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习中的探索机制与大语言模型的实际学习过程不匹配，现有方法如熵奖励和外部语义比较仅促进表面变化，无法保证更新方向的多样性，导致探索效率低下。

Method: G2RL利用模型最后一层的敏感性信息（可低成本获取）构建序列级特征，通过比较采样轨迹间的特征差异来评估其对策略更新方向的新颖性；新颖方向获得增益奖励，冗余或非流形更新被抑制，形成自指的探索信号，与PPO稳定性和KL控制兼容。

Result: 在Qwen3 1.7B和4B模型上，G2RL在MATH500、AMC、AIME24/25、GPQA、MMLUpro等多个数学与通用推理任务中，持续优于基于熵的GRPO和外部嵌入方法，在pass@1、maj@16、pass@k等指标上均有显著提升。

Conclusion: G2RL证明了模型自身的更新空间是指导大语言模型强化学习探索的更可靠基础，能够引导探索进入更正交甚至相反的梯度方向，同时保持语义连贯性，显著提升推理能力。

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

</details>


### [175] [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)
*Matin Mortaheb,Erciyes Karakaya,Sennur Ulukus*

Main category: cs.LG

TL;DR: 本文提出了一种基于文本查询引导的多模态语义通信框架，通过跨模态注意力机制融合视觉与语言信息，生成视觉数据的软相关性分数，并根据信道带宽自适应传输图像块，实现高效的任务导向通信。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的方法在复杂场景中因缺乏任务引导而难以有效识别关键信息区域，导致通信效率受限。

Method: 采用跨模态注意力机制融合视觉特征与语言嵌入，生成视觉数据的相关性评分；基于评分和实时信道带宽，使用独立训练的编码器-解码器对以自适应分辨率传输图像块，确保总比特率匹配信道容量。

Result: 在复杂且带宽受限的环境中，系统能有效保留任务关键信息，显著提升通信效率，实现灵活、目标驱动的语义通信。

Conclusion: 所提出的多模态语义通信框架通过引入文本查询指导，有效解决了复杂场景下信息提取不精准的问题，为高效语义通信提供了可行方案。

Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

</details>


### [176] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://arxiv.org/abs/2512.15699)
*Qiuyang Mang,Wenhao Chai,Zhifei Li,Huanzhi Mao,Shang Zhou,Alexander Du,Hanchen Li,Shu Liu,Edwin Chen,Yichuan Wang,Xieting Chu,Zerui Cheng,Yuan Xu,Tian Xia,Zirui Wang,Tianneng Shi,Jianzhu Yao,Yilong Zhao,Qizheng Zhang,Charlie Ruan,Zeyu Shen,Kaiyuan Liu,Runyuan He,Dong Xing,Zerui Li,Zirong Zeng,Yige Jiang,Lufeng Cheng,Ziyi Zhao,Youran Sun,Wesley Zheng,Meiyuwang Zhang,Ruyi Ji,Xuechang Tu,Zihan Zheng,Zexing Chen,Kangyang Zhou,Zhaozi Wang,Jingbang Chen,Aleksandra Korolova,Peter Henderson,Pramod Viswanath,Vijay Ganesh,Saining Xie,Zhuang Liu,Dawn Song,Sewon Min,Ion Stoica,Joseph E. Gonzalez,Jingbo Shang,Alvin Cheung*

Main category: cs.LG

TL;DR: FrontierCS 是一个由专家设计和评审的156个开放性计算机科学问题的基准测试，涵盖算法和研究问题，目标是评估模型在无已知最优解但可客观评分的问题上的表现。模型需通过编写可执行程序来解决问题，而非直接输出答案。该基准包含专家参考解和自动评估器，旨在推动计算机科学推理的前沿。实证结果显示，当前模型在算法与研究任务上仍远落后于人类专家，增加推理预算无法弥补差距，且模型常过度优化于生成可行代码而非高质量算法或系统设计。


<details>
  <summary>Details</summary>
Motivation: 现有基准多聚焦于有已知最优解的任务，而实际计算机科学中存在大量最优解未知但可客观评估的问题。为推动模型在真正前沿问题上的能力发展，需要一个能衡量进展、具备开放性且经专家验证的基准。

Method: 构建包含156个开放性问题的基准 FrontierCS，问题来自算法（如NP难变体）和研究领域，均支持部分评分；每个问题配备专家参考解与自动评估器；模型需提交可执行程序作为答案；通过对比人类专家与模型在两类任务上的表现进行评估。

Result: 当前前沿推理模型在算法和研究任务上显著落后于人类专家；单纯增加推理预算无法缩小差距；模型倾向生成仅可工作的代码，而非探索高质量算法或系统设计。

Conclusion: FrontierCS 为评估模型在计算机科学前沿问题上的能力提供了有效工具，揭示了当前模型在创造性与深度推理方面的不足，强调了未来研究需关注算法发现与系统设计而非仅代码可行性。

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

</details>
