<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 62]
- [cs.CL](#cs.CL) [Total: 42]
- [cs.LG](#cs.LG) [Total: 81]
- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [From Blurry to Believable: Enhancing Low-quality Talking Heads with 3D Generative Priors](https://arxiv.org/abs/2602.06122)
*Ding-Jiun Huang,Yuanhao Wang,Shao-Ji Yuan,Albert Mosella-Montoro,Francisco Vicente Carrasco,Cheng Zhang,Fernando De la Torre*

Main category: cs.CV

TL;DR: SuperHead 是一种用于提升低分辨率、可动画 3D 头像质量的新框架，通过利用预训练 3D 生成模型的先验知识，结合动态感知的 3D 反演策略，生成高保真且时间一致的 3D 高斯点云头像，并将其绑定到参数化头部模型（如 FLAME）以实现动画。该方法在多种表情和视角下优化潜空间表示，通过稀疏的超分辨 2D 渲染图像和深度图联合监督，有效保留身份特征并增强细节表现力。实验表明，SuperHead 在动态面部运动下的视觉质量显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前 3D 谈话头像生成受限于低质量图像或视频输入，导致重建效果差。现有的超分辨率技术难以处理动态 3D 输入，无法同时保证几何、纹理质量和动画期间的时间一致性，尤其在保持主体身份方面存在挑战。因此需要一种能从低质输入中恢复高质量、可动画 3D 头像的新方法。

Method: 提出 SuperHead 框架，采用基于预训练 3D 生成模型的动态感知 3D 反演机制，优化其潜空间表示以生成超分辨 3D 高斯点云模型；通过多视角、多表情的超分辨 2D 渲染图像与深度图进行联合监督；最终将生成的 3DGS 模型绑定至参数化头部模型（如 FLAME）实现动画。

Result: SuperHead 能在动态面部运动下生成具有精细面部细节的高质量 3D 头像，在视觉质量上显著优于现有基线方法，有效提升了 3D 重建的保真度、一致性与动画能力。

Conclusion: SuperHead 成功解决了从低质量输入生成高保真、可动画 3D 头像的关键挑战，通过融合 3D 生成先验与动态监督机制，实现了高质量重建与稳定动画，为沉浸式应用提供了有力支持。

Abstract: Creating high-fidelity, animatable 3D talking heads is crucial for immersive applications, yet often hindered by the prevalence of low-quality image or video sources, which yield poor 3D reconstructions. In this paper, we introduce SuperHead, a novel framework for enhancing low-resolution, animatable 3D head avatars. The core challenge lies in synthesizing high-quality geometry and textures, while ensuring both 3D and temporal consistency during animation and preserving subject identity. Despite recent progress in image, video and 3D-based super-resolution (SR), existing SR techniques are ill-equipped to handle dynamic 3D inputs. To address this, SuperHead leverages the rich priors from pre-trained 3D generative models via a novel dynamics-aware 3D inversion scheme. This process optimizes the latent representation of the generative model to produce a super-resolved 3D Gaussian Splatting (3DGS) head model, which is subsequently rigged to an underlying parametric head model (e.g., FLAME) for animation. The inversion is jointly supervised using a sparse collection of upscaled 2D face renderings and corresponding depth maps, captured from diverse facial expressions and camera viewpoints, to ensure realism under dynamic facial motions. Experiments demonstrate that SuperHead generates avatars with fine-grained facial details under dynamic motions, significantly outperforming baseline methods in visual quality.

</details>


### [2] [EgoAVU: Egocentric Audio-Visual Understanding](https://arxiv.org/abs/2602.06139)
*Ashish Seth,Xinhao Mei,Changsheng Zhao,Varun Nagaraja,Ernie Chang,Gregory P. Meyer,Gael Le Lan,Yunyang Xiong,Vikas Chandra,Yangyang Shi,Dinesh Manocha,Zhipeng Cai*

Main category: cs.CV

TL;DR: 提出EgoAVU数据引擎，自动生成头戴式视频的音视频叙述、问题和答案，构建大规模训练数据集EgoAVU-Instruct和验证集EgoAVU-Bench，揭示现有多模态大模型对音频线索的忽视，并通过微调显著提升性能，跨基准表现提升最高达28%。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在头戴式视频中难以联合理解音视频信息，因缺乏带有连贯多模态标签的数据，亟需构建高质量的音视频联合标注数据集以推动模型发展。

Method: 设计EgoAVU数据引擎，利用跨模态相关性建模生成音视频叙述，结合基于标记的视频筛选与模块化图结构的精炼策略，确保数据多样性与质量，进而构建EgoAVU-Instruct训练集和EgoAVU-Bench评估集。

Result: EgoAVU-Bench揭示现有MLLMs严重依赖视觉信号而忽略音频；在EgoAVU-Instruct上微调后，模型在EgoAVU-Bench上性能提升高达113%，并在EgoTempo和EgoIllusion等其他基准上实现最高28%的相对性能增益。

Conclusion: EgoAVU有效解决了头戴式视频中音视频联合理解的数据瓶颈，显著提升了多模态大模型在真实场景下的多模态感知能力，其数据与代码将公开共享，推动具身智能发展。

Abstract: Understanding egocentric videos plays a vital role for embodied intelligence. Recent multi-modal large language models (MLLMs) can accept both visual and audio inputs. However, due to the challenge of obtaining text labels with coherent joint-modality information, whether MLLMs can jointly understand both modalities in egocentric videos remains under-explored. To address this problem, we introduce EgoAVU, a scalable data engine to automatically generate egocentric audio-visual narrations, questions, and answers. EgoAVU enriches human narrations with multimodal context and generates audio-visual narrations through cross-modal correlation modeling. Token-based video filtering and modular, graph-based curation ensure both data diversity and quality. Leveraging EgoAVU, we construct EgoAVU-Instruct, a large-scale training dataset of 3M samples, and EgoAVU-Bench, a manually verified evaluation split covering diverse tasks. EgoAVU-Bench clearly reveals the limitations of existing MLLMs: they bias heavily toward visual signals, often neglecting audio cues or failing to correspond audio with the visual source. Finetuning MLLMs on EgoAVU-Instruct effectively addresses this issue, enabling up to 113% performance improvement on EgoAVU-Bench. Such benefits also transfer to other benchmarks such as EgoTempo and EgoIllusion, achieving up to 28% relative performance gain. Code will be released to the community.

</details>


### [3] [Driving with DINO: Vision Foundation Features as a Unified Bridge for Sim-to-Real Generation in Autonomous Driving](https://arxiv.org/abs/2602.06159)
*Xuyang Chen,Conglang Zhang,Chuanheng Fu,Zihao Yang,Kaixuan Zhou,Yizhi Zhang,Jianan He,Yanfeng Zhang,Mingwei Sun,Zengmao Wang,Zhen Dong,Xiaoxiao Long,Liqiu Meng*

Main category: cs.CV

TL;DR: 本文提出Driving with DINO (DwD)框架，利用VFM特征作为模拟与真实世界之间的统一桥梁，解决控制一致性与真实感之间的根本矛盾。通过主子空间投影去除高频纹理信息以提升真实感，结合随机通道尾部丢弃缓解结构损失，并引入可学习的空间对齐模块增强高分辨率特征的控制精度，最后采用因果时序聚合器保留历史运动上下文，有效减少运动模糊并保证时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有Sim2Real方法依赖显式中间表示（如边缘、深度、语义等）在模拟与真实域之间建模，但面临控制一致性与真实感之间的权衡：低层信号虽能精确控制却带来合成伪影，高层先验虽促进真实感却缺乏结构细节。因此亟需一种兼具高真实感与强控制一致性的统一表征方式。

Method: 1. 利用DINOv3的视觉基础模型（VFM）特征作为跨域桥梁，其包含从高层语义到细粒度结构的多尺度信息；2. 采用主子空间投影剔除导致‘纹理烘焙’的高频成分；3. 引入随机通道尾部丢弃策略缓解维度压缩带来的结构信息损失；4. 设计可学习的空间对齐模块，适配高分辨率DINO特征至扩散模型主干；5. 提出基于因果卷积的因果时序聚合器，动态融合帧级特征，保持历史运动上下文，避免运动模糊。

Result: 实验表明，DwD在多个基准上显著优于现有方法，在生成视频的真实感、运动连贯性及控制一致性方面均取得突破性提升。尤其在复杂交通场景下，生成视频具备更强的物理合理性与视觉自然性，且支持精细可控的驾驶行为生成。

Conclusion: 本工作证明了利用预训练视觉基础模型特征作为统一跨域表征的有效性。DwD框架成功调和了控制一致性与真实感之间的矛盾，为未来基于扩散模型的自主驾驶视频生成提供了新的范式。

Abstract: Driven by the emergence of Controllable Video Diffusion, existing Sim2Real methods for autonomous driving video generation typically rely on explicit intermediate representations to bridge the domain gap. However, these modalities face a fundamental Consistency-Realism Dilemma. Low-level signals (e.g., edges, blurred images) ensure precise control but compromise realism by "baking in" synthetic artifacts, whereas high-level priors (e.g., depth, semantics, HDMaps) facilitate photorealism but lack the structural detail required for consistent guidance. In this work, we present Driving with DINO (DwD), a novel framework that leverages Vision Foundation Module (VFM) features as a unified bridge between the simulation and real-world domains. We first identify that these features encode a spectrum of information, from high-level semantics to fine-grained structure. To effectively utilize this, we employ Principal Subspace Projection to discard the high-frequency elements responsible for "texture baking," while concurrently introducing Random Channel Tail Drop to mitigate the structural loss inherent in rigid dimensionality reduction, thereby reconciling realism with control consistency. Furthermore, to fully leverage DINOv3's high-resolution capabilities for enhancing control precision, we introduce a learnable Spatial Alignment Module that adapts these high-resolution features to the diffusion backbone. Finally, we propose a Causal Temporal Aggregator employing causal convolutions to explicitly preserve historical motion context when integrating frame-wise DINO features, which effectively mitigates motion blur and guarantees temporal stability. Project page: https://albertchen98.github.io/DwD-project/

</details>


### [4] [MetaSSP: Enhancing Semi-supervised Implicit 3D Reconstruction through Meta-adaptive EMA and SDF-aware Pseudo-label Evaluation](https://arxiv.org/abs/2602.06163)
*Luoxi Zhang,Chun Xie,Itaru Kitahara*

Main category: cs.CV

TL;DR: MetaSSP 是一种新颖的半监督框架，通过利用大量未标注图像提升单视图 3D 重建质量。它引入基于梯度的参数重要性估计来正则化自适应 EMA 更新，并采用结合增强一致性与 SDF 方差的伪标签加权机制。在 Pix3D 基准上，相比现有半监督基线，其 Chamfer Distance 降低约 20.61%，IoU 提升约 24.09%，达到新最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式 SDF 的单视图 3D 重建方法虽能生成高质量表面，但依赖大规模标注数据，限制了可扩展性。为克服这一瓶颈，亟需有效利用大量未标注图像以减少对标注数据的依赖。

Method: 提出 MetaSSP 框架，包含：1）基于梯度的参数重要性估计以正则化自适应 EMA 更新；2）SDF-aware 伪标签加权机制，融合增强一致性与 SDF 变异信息；3）从 10% 标注数据开始的统一训练流程，联合优化标注与未标注数据。

Result: 在 Pix3D 基准上，相较于现有半监督方法，Chamfer Distance 下降约 20.61%，IoU 上升约 24.09%，显著优于之前方法，达到新的基准水平。

Conclusion: MetaSSP 成功实现了在少量标注数据下高效利用大量未标注图像进行 3D 重建，显著提升了重建质量与模型可扩展性，为半监督 3D 重建提供了新范式。

Abstract: Implicit SDF-based methods for single-view 3D reconstruction achieve high-quality surfaces but require large labeled datasets, limiting their scalability. We propose MetaSSP, a novel semi-supervised framework that exploits abundant unlabeled images. Our approach introduces gradient-based parameter importance estimation to regularize adaptive EMA updates and an SDF-aware pseudo-label weighting mechanism combining augmentation consistency with SDF variance. Beginning with a 10% supervised warm-up, the unified pipeline jointly refines labeled and unlabeled data. On the Pix3D benchmark, our method reduces Chamfer Distance by approximately 20.61% and increases IoU by around 24.09% compared to existing semi-supervised baselines, setting a new state of the art.

</details>


### [5] [M3: High-fidelity Text-to-Image Generation via Multi-Modal, Multi-Agent and Multi-Round Visual Reasoning](https://arxiv.org/abs/2602.06166)
*Bangji Yang,Ruihan Guo,Jiajun Fan,Chaoran Cheng,Ge Liu*

Main category: cs.CV

TL;DR: M3是一种无需训练的多智能体框架，通过迭代推理时优化解决文本到图像生成中复杂组合提示的问题。它利用规划、检查、优化和编辑等专用智能体逐步修正约束条件，并由验证器确保性能持续提升。在OneIG-EN基准上，Qwen-Image+M3超越了Imagen4和Seedream 3.0等商业系统，达到0.532的领先性能，显著提升空间推理能力，且可作为即插即用模块适配任意预训练文本到图像模型。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在处理包含多重约束的复杂组合提示时表现不佳，亟需一种无需重新训练即可提升生成质量的方法。

Method: M3采用多智能体架构，在推理阶段通过规划器分解提示为可验证清单，再由检查、优化、编辑和验证智能体协同工作，逐项修正约束并确保性能单调提升。

Result: 在OneIG-EN基准上，Qwen-Image+M3取得0.532的最高得分，优于Imagen4（0.515）和Seedream 3.0（0.530），并在GenEval compositional指标上显著提升，空间推理能力翻倍。

Conclusion: M3证明了智能多智能体推理能够使开源模型超越专有系统，为无需重训练的组合生成提供了新范式。

Abstract: Generative models have achieved impressive fidelity in text-to-image synthesis, yet struggle with complex compositional prompts involving multiple constraints. We introduce \textbf{M3 (Multi-Modal, Multi-Agent, Multi-Round)}, a training-free framework that systematically resolves these failures through iterative inference-time refinement. M3 orchestrates off-the-shelf foundation models in a robust multi-agent loop: a Planner decomposes prompts into verifiable checklists, while specialized Checker, Refiner, and Editor agents surgically correct constraints one at a time, with a Verifier ensuring monotonic improvement. Applied to open-source models, M3 achieves remarkable results on the challenging OneIG-EN benchmark, with our Qwen-Image+M3 surpassing commercial flagship systems including Imagen4 (0.515) and Seedream 3.0 (0.530), reaching state-of-the-art performance (0.532 overall). This demonstrates that intelligent multi-agent reasoning can elevate open-source models beyond proprietary alternatives. M3 also substantially improves GenEval compositional metrics, effectively doubling spatial reasoning performance on hardened test sets. As a plug-and-play module compatible with any pre-trained T2I model, M3 establishes a new paradigm for compositional generation without costly retraining.

</details>


### [6] [Unsupervised Anomaly Detection of Diseases in the Female Pelvis for Real-Time MR Imaging](https://arxiv.org/abs/2602.06179)
*Anika Knupfer,Johanna P. Müller,Jordina A. Verdera,Martin Fenske,Claudius S. Mathy,Smiti Tripathy,Sebastian Arndt,Matthias May,Michael Uder,Matthias W. Beckmann,Stefanie Burghaus,Jana Hutter*

Main category: cs.CV

TL;DR: 提出了一种无需标注异常数据的实时无监督异常检测框架，用于女性骨盆MRI分析。基于健康矢状面T2加权图像训练残差变分自编码器，通过重建误差热图识别病灶区域。在公开数据集上达到0.736 AUC、0.828敏感度和0.692特异度，推理速度达92.6帧/秒，支持临床实时应用。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法多针对特定疾病，缺乏实时兼容性和泛化能力，且因解剖变异大导致诊断延迟，亟需一种通用、实时的无监督异常检测方法。

Method: 使用残差变分自编码器仅在多种扫描协议下的294例健康矢状面T2加权图像上训练，结合扩散生成的合成数据增强模型鲁棒性；推理时通过重建误差热图定位异常区域。

Result: 在子宫肌瘤MRI数据集上平均AUC为0.736，敏感度0.828，特异度0.692；临床评估显示解剖异质性和观察者间差异影响性能解读；推理速度达92.6帧/秒，满足实时要求。

Conclusion: 该框架为女性骨盆无监督异常检测建立了基准，具备良好的临床可扩展性与实时处理能力，为未来MRI实时辅助诊断提供基础。

Abstract: Pelvic diseases in women of reproductive age represent a major global health burden, with diagnosis frequently delayed due to high anatomical variability, complicating MRI interpretation. Existing AI approaches are largely disease-specific and lack real-time compatibility, limiting generalizability and clinical integration. To address these challenges, we establish a benchmark framework for disease- and parameter-agnostic, real-time-compatible unsupervised anomaly detection in pelvic MRI. The method uses a residual variational autoencoder trained exclusively on healthy sagittal T2-weighted scans acquired across diverse imaging protocols to model normal pelvic anatomy. During inference, reconstruction error heatmaps indicate deviations from learned healthy structure, enabling detection of pathological regions without labeled abnormal data. The model is trained on 294 healthy scans and augmented with diffusion-generated synthetic data to improve robustness. Quantitative evaluation on the publicly available Uterine Myoma MRI Dataset yields an average area-under-the-curve (AUC) value of 0.736, with 0.828 sensitivity and 0.692 specificity. Additional inter-observer clinical evaluation extends analysis to endometrial cancer, endometriosis, and adenomyosis, revealing the influence of anatomical heterogeneity and inter-observer variability on performance interpretation. With a reconstruction time of approximately 92.6 frames per second, the proposed framework establishes a baseline for unsupervised anomaly detection in the female pelvis and supports future integration into real-time MRI. Code is available upon request (https://github.com/AniKnu/UADPelvis), prospective data sets are available for academic collaboration.

</details>


### [7] [PhenoLIP: Integrating Phenotype Ontology Knowledge into Medical Vision-Language Pretraining](https://arxiv.org/abs/2602.06184)
*Cheng Liang,Chaoyi Wu,Weike Zhao,Ya Zhang,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出了PhenoKG，一个大规模、以表型为中心的多模态知识图谱，包含超过52万张高质量图像-文本对和3000多个表型。基于此，作者设计了PhenoLIP预训练框架，通过两阶段过程将结构化表型知识融入医学视觉语言模型（VLMs）：首先从文本本体数据中学习增强型表型嵌入空间，然后通过教师引导的知识蒸馏目标将这些知识蒸馏到多模态预训练中。此外，构建了PhenoBench基准，用于专家验证的表型识别任务，涵盖超过7800个图像-标题对和1000多个表型。实验表明，PhenoLIP在表型分类准确率上比BiomedCLIP提升8.85%，在跨模态检索上比BIOMEDICA提升15.03%，证明了引入表型中心先验对实现结构化、可解释的医学图像理解的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型大多依赖粗粒度的图像-文本对比目标，未能有效捕捉医学表型本体中编码的系统性视觉知识，因此需要一种更结构化的方法来整合表型知识以提升模型性能与可解释性。

Method: 提出PhenoKG知识图谱，构建表型中心的多模态数据集；设计两阶段预训练框架PhenoLIP，包括基于本体文本学习表型嵌入空间，以及通过教师引导的知识蒸馏将结构化知识注入多模态模型；建立专家验证的PhenoBench评估基准。

Result: PhenoLIP在表型分类任务上相较BiomedCLIP提升8.85%准确率，在跨模态检索任务上相较BIOMEDICA提升15.03%，显著优于现有基线模型，验证了表型知识对医学图像理解的有效促进作用。

Conclusion: 将结构化的表型知识显式融入医学视觉语言模型中，能够显著提升模型在表型识别与跨模态理解任务上的性能，推动医学图像分析向更结构化、可解释的方向发展。

Abstract: Recent progress in large-scale CLIP-like vision-language models(VLMs) has greatly advanced medical image analysis. However, most existing medical VLMs still rely on coarse image-text contrastive objectives and fail to capture the systematic visual knowledge encoded in well-defined medical phenotype ontologies. To address this gap, we construct PhenoKG, the first large-scale, phenotype-centric multimodal knowledge graph that encompasses over 520K high-quality image-text pairs linked to more than 3,000 phenotypes. Building upon PhenoKG, we propose PhenoLIP, a novel pretraining framework that explicitly incorporates structured phenotype knowledge into medical VLMs through a two-stage process. We first learn a knowledge-enhanced phenotype embedding space from textual ontology data and then distill this structured knowledge into multimodal pretraining via a teacher-guided knowledge distillation objective. To support evaluation, we further introduce PhenoBench, an expert-verified benchmark designed for phenotype recognition, comprising over 7,800 image--caption pairs covering more than 1,000 phenotypes. Extensive experiments demonstrate that PhenoLIP outperforms previous state-of-the-art baselines, improving upon BiomedCLIP in phenotype classification accuracy by 8.85\% and BIOMEDICA in cross-modal retrieval by 15.03%, underscoring the value of integrating phenotype-centric priors into medical VLMs for structured and interpretable medical image understanding.

</details>


### [8] [DeDPO: Debiased Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2602.06195)
*Khiem Pham,Quang Nguyen,Tung Nguyen,Jingsen Zhu,Michele Santacatterina,Dimitris Metaxas,Ramin Zabih*

Main category: cs.CV

TL;DR: Debiased DPO (DeDPO) is a semi-supervised framework that enhances Direct Preference Optimization (DPO) by integrating synthetic AI feedback with limited human data, using a debiased estimation technique from causal inference to correct biases in synthetic labels. It enables robust training even with noisy or imperfect feedback sources like self-training and Vision-Language Models (VLMs), achieving performance comparable to or exceeding models trained on fully human-labeled data.


<details>
  <summary>Details</summary>
Motivation: DPO's reliance on large-scale, high-quality human preference labels is costly and limits scalability. To address this, the paper seeks to leverage low-cost synthetic feedback while mitigating its inherent biases and noise.

Method: DeDPO integrates a debiased estimation method from causal inference into the DPO objective, enabling accurate learning from biased synthetic annotations. It uses a combination of limited human-labeled data and large-scale unlabeled synthetic pairs, improving robustness across different synthetic labeling methods.

Result: DeDPO achieves performance on par with or surpassing models trained on fully human-labeled data, demonstrating strong robustness to variations in synthetic labeling techniques and offering a scalable solution for human-AI alignment.

Conclusion: DeDPO provides a cost-effective and scalable approach to align diffusion models using synthetic supervision, effectively overcoming the limitations of bias and noise in AI-generated feedback, thus advancing practical human-AI alignment.

Abstract: Direct Preference Optimization (DPO) has emerged as a predominant alignment method for diffusion models, facilitating off-policy training without explicit reward modeling. However, its reliance on large-scale, high-quality human preference labels presents a severe cost and scalability bottleneck. To overcome this, We propose a semi-supervised framework augmenting limited human data with a large corpus of unlabeled pairs annotated via cost-effective synthetic AI feedback. Our paper introduces Debiased DPO (DeDPO), which uniquely integrates a debiased estimation technique from causal inference into the DPO objective. By explicitly identifying and correcting the systematic bias and noise inherent in synthetic annotators, DeDPO ensures robust learning from imperfect feedback sources, including self-training and Vision-Language Models (VLMs). Experiments demonstrate that DeDPO is robust to the variations in synthetic labeling methods, achieving performance that matches and occasionally exceeds the theoretical upper bound of models trained on fully human-labeled data. This establishes DeDPO as a scalable solution for human-AI alignment using inexpensive synthetic supervision.

</details>


### [9] [DroneKey++: A Size Prior-free Method and New Benchmark for Drone 3D Pose Estimation from Sequential Images](https://arxiv.org/abs/2602.06211)
*Seo-Bin Hwang,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: DroneKey++ 是一个无需先验信息的框架，用于同时进行无人机关键点检测、分类和3D姿态估计。它利用基于射线的几何推理和类别嵌入来估计3D姿态，并构建了大规模合成数据集6DroneSyn（50K+图像，7种无人机模型，88个户外背景），以解决现有数据集小规模、受限的问题。实验表明，该方法在旋转和翻译上均表现出优异的精度（MAE 17.34°, MedAE 17.1°；MAE 0.135m, MedAE 0.242m）和实时性能（CPU: 19.25 FPS, GPU: 414.07 FPS），具备良好的泛化能力，且数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 现有无人机3D姿态估计方法依赖于先验信息（如物理尺寸或3D网格），且数据集规模小、多样性差，难以验证模型的泛化能力，因此亟需一种无需先验、可泛化且适用于真实场景的解决方案。

Method: DroneKey++采用关键点编码器联合完成关键点检测与分类，通过姿态解码器结合射线几何推理和类别嵌入实现3D姿态估计。同时，构建了6DroneSyn这一大规模合成数据集，使用360度全景合成生成多样化的训练样本。

Result: 在旋转估计上达到MAE 17.34°、MedAE 17.1°，在平移估计上达到MAE 0.135m、MedAE 0.242m，推理速度达19.25 FPS（CPU）和414.07 FPS（GPU），证明其具有强泛化能力和实时应用潜力。

Conclusion: DroneKey++实现了无需先验信息的高精度、实时无人机3D姿态估计，且其配套的大规模合成数据集6DroneSyn有助于推动该领域的发展，为安全与监控系统提供可靠支持。

Abstract: Accurate 3D pose estimation of drones is essential for security and surveillance systems. However, existing methods often rely on prior drone information such as physical sizes or 3D meshes. At the same time, current datasets are small-scale, limited to single models, and collected under constrained environments, which makes reliable validation of generalization difficult. We present DroneKey++, a prior-free framework that jointly performs keypoint detection, drone classification, and 3D pose estimation. The framework employs a keypoint encoder for simultaneous keypoint detection and classification, and a pose decoder that estimates 3D pose using ray-based geometric reasoning and class embeddings. To address dataset limitations, we construct 6DroneSyn, a large-scale synthetic benchmark with over 50K images covering 7 drone models and 88 outdoor backgrounds, generated using 360-degree panoramic synthesis. Experiments show that DroneKey++ achieves MAE 17.34 deg and MedAE 17.1 deg for rotation, MAE 0.135 m and MedAE 0.242 m for translation, with inference speeds of 19.25 FPS (CPU) and 414.07 FPS (GPU), demonstrating both strong generalization across drone models and suitability for real-time applications. The dataset is publicly available.

</details>


### [10] [Addressing the Waypoint-Action Gap in End-to-End Autonomous Driving via Vehicle Motion Models](https://arxiv.org/abs/2602.06214)
*Jorge Daniel Rodríguez-Vidal,Gabriel Villalonga,Diego Porres,Antonio M. López Peña*

Main category: cs.CV

TL;DR: 本文提出一种可微分的车辆模型框架，将动作序列滚动为对应的自车坐标系下的航点轨迹，并在航点空间进行监督，从而首次实现动作型模型在基于航点的基准测试中训练与评估，无需修改现有评估协议。该方法在多个挑战性基准上表现优异，尤其在NAVSIM navhard上达到当前最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多数基准协议和训练流程基于航点输出，导致动作型策略难以训练和比较，阻碍了其发展。需要一种方法来弥合航点与动作之间的差距。

Method: 提出一种可微分的车辆模型框架，通过将预测的动作序列滚动为自车坐标系下的航点轨迹，并在航点空间进行监督，使动作型模型可在不改变原有评估协议的情况下进行训练和评估。

Result: 在多个挑战性基准上均取得一致提升，尤其在NAVSIM navhard上达到当前最优性能。

Conclusion: 所提出的框架成功实现了动作型模型在传统航点基准中的训练与评估，显著推动了端到端自动驾驶中动作型策略的发展。

Abstract: End-to-End Autonomous Driving (E2E-AD) systems are typically grouped by the nature of their outputs: (i) waypoint-based models that predict a future trajectory, and (ii) action-based models that directly output throttle, steer and brake. Most recent benchmark protocols and training pipelines are waypoint-based, which makes action-based policies harder to train and compare, slowing their progress. To bridge this waypoint-action gap, we propose a novel, differentiable vehicle-model framework that rolls out predicted action sequences to their corresponding ego-frame waypoint trajectories while supervising in waypoint space. Our approach enables action-based architectures to be trained and evaluated, for the first time, within waypoint-based benchmarks without modifying the underlying evaluation protocol. We extensively evaluate our framework across multiple challenging benchmarks and observe consistent improvements over the baselines. In particular, on NAVSIM \texttt{navhard} our approach achieves state-of-the-art performance. Our code will be made publicly available upon acceptance.

</details>


### [11] [Cross-Modal Redundancy and the Geometry of Vision-Language Embeddings](https://arxiv.org/abs/2602.06218)
*Grégoire Dhimoïla,Thomas Fel,Victor Boutin,Agustin Picard*

Main category: cs.CV

TL;DR: 该研究提出一种基于等能假设的对齐稀疏自编码器（SAE），以探究视觉-语言模型（VLMs）共享嵌入空间的几何结构。通过强制跨模态能量一致性，该方法在不损害重建能力的前提下，揭示了模型中仅稀疏双模态原子携带全部跨模态对齐信号，而单模态原子则构成模态差异的来源。移除单模态原子可消除模态差距而不影响性能，且限制向量运算于双模态子空间可实现分布内编辑与检索优化。结果表明，合理的归纳偏置既能保持模型保真度，又能使潜在空间几何可解释、可操作。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型虽在图像与文本对齐上表现优异，但其共享嵌入空间的几何结构尚不清晰。缺乏对潜空间结构的理解阻碍了对模型行为的深入分析和可控干预。因此，需要一种机制来揭示并利用这种内在结构。

Method: 提出基于等能假设的对齐稀疏自编码器（SAE），通过在训练中引入能量一致性约束，同时保持良好的重构性能，从而获得可用于几何分析的表示。通过控制数据验证其有效性，并将其应用于主流VLMs进行结构解析。

Result: 发现稀疏双模态原子承载全部跨模态对齐信号，单模态原子代表模态特异性偏差并完全解释模态差距；移除单模态原子可消除差距而不损失性能；在双模态子空间中进行向量运算可实现分布内编辑与更优检索。

Conclusion: 合理的归纳偏置能够同时维持模型性能与可解释性，使得潜空间几何结构变得清晰且可操作，为模型分析与改进提供了新路径。

Abstract: Vision-language models (VLMs) align images and text with remarkable success, yet the geometry of their shared embedding space remains poorly understood. To probe this geometry, we begin from the Iso-Energy Assumption, which exploits cross-modal redundancy: a concept that is truly shared should exhibit the same average energy across modalities. We operationalize this assumption with an Aligned Sparse Autoencoder (SAE) that encourages energy consistency during training while preserving reconstruction. We find that this inductive bias changes the SAE solution without harming reconstruction, giving us a representation that serves as a tool for geometric analysis. Sanity checks on controlled data with known ground truth confirm that alignment improves when Iso-Energy holds and remains neutral when it does not. Applied to foundational VLMs, our framework reveals a clear structure with practical consequences: (i) sparse bimodal atoms carry the entire cross-modal alignment signal; (ii) unimodal atoms act as modality-specific biases and fully explain the modality gap; (iii) removing unimodal atoms collapses the gap without harming performance; (iv) restricting vector arithmetic to the bimodal subspace yields in-distribution edits and improved retrieval. These findings suggest that the right inductive bias can both preserve model fidelity and render the latent geometry interpretable and actionable.

</details>


### [12] [ForeHOI: Feed-forward 3D Object Reconstruction from Daily Hand-Object Interaction Videos](https://arxiv.org/abs/2602.06226)
*Yuantao Chen,Jiahao Chang,Chongjie Ye,Chaoran Zhang,Zhaojie Fang,Chenghong Li,Xiaoguang Han*

Main category: cs.CV

TL;DR: ForeHOI 是一个前馈模型，可从单目手-物体交互视频中在1分钟内直接重建3D物体几何形状，无需预处理。通过联合预测2D掩码修复和3D形状补全，有效解决严重遮挡问题，性能优于基于优化的方法，并实现约100倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 单目手-物体交互视频中物体重建因严重遮挡和相机、手与物体的复杂耦合运动而困难，现有方法效率低且依赖复杂预处理。

Method: 提出前馈框架，联合进行2D掩码修复与3D形状补全，利用2D与3D之间的信息交互增强重建质量，克服遮挡挑战。

Result: 在物体重建任务上达到当前最佳性能，相比以往方法有约100倍速度提升，且无需预处理步骤。

Conclusion: ForeHOI 通过高效的前馈架构和跨模态信息融合，实现了快速高精度的3D物体重建，为真实世界手-物体交互建模提供了新范式。

Abstract: The ubiquity of monocular videos capturing daily hand-object interactions presents a valuable resource for embodied intelligence. While 3D hand reconstruction from in-the-wild videos has seen significant progress, reconstructing the involved objects remains challenging due to severe occlusions and the complex, coupled motion of the camera, hands, and object. In this paper, we introduce ForeHOI, a novel feed-forward model that directly reconstructs 3D object geometry from monocular hand-object interaction videos within one minute of inference time, eliminating the need for any pre-processing steps. Our key insight is that, the joint prediction of 2D mask inpainting and 3D shape completion in a feed-forward framework can effectively address the problem of severe occlusion in monocular hand-held object videos, thereby achieving results that outperform the performance of optimization-based methods. The information exchanges between the 2D and 3D shape completion boosts the overall reconstruction quality, enabling the framework to effectively handle severe hand-object occlusion. Furthermore, to support the training of our model, we contribute the first large-scale, high-fidelity synthetic dataset of hand-object interactions with comprehensive annotations. Extensive experiments demonstrate that ForeHOI achieves state-of-the-art performance in object reconstruction, significantly outperforming previous methods with around a 100x speedup. Code and data are available at: https://github.com/Tao-11-chen/ForeHOI.

</details>


### [13] [An Interpretable Vision Transformer as a Fingerprint-Based Diagnostic Aid for Kabuki and Wiedemann-Steiner Syndromes](https://arxiv.org/abs/2602.06282)
*Marilyn Lionts,Arnhildur Tomasdottir,Viktor I. Agustsson,Yuankai Huo,Hans T. Bjornsson,Lotta M. Ellingsen*

Main category: cs.CV

TL;DR: 本研究提出一种基于视觉变换器的深度学习模型，利用指纹图像区分Kabuki综合征（KS）和Wiedemann-Steiner综合征（WSS）患者与正常对照组，以及两者之间的差异。模型在三个二分类任务中分别取得0.80、0.73和0.85的AUC值，对应F1分数为0.71、0.72和0.83。通过注意力可视化分析，识别出对预测最具影响力的指纹区域，提升了模型可解释性。结果表明，这两种综合征具有特定的指纹特征，证明了基于指纹的AI工具在无创、可解释且易获取的遗传综合征早期诊断中的可行性。


<details>
  <summary>Details</summary>
Motivation: 许多患有Kabuki综合征（KS）和Wiedemann-Steiner综合征（WSS）的个体因缺乏基因检测资源和专业诊断能力而未能确诊。尽管皮肤纹理异常是多种遗传综合征的典型表现，但在分子检测时代仍被忽视。因此，亟需一种非侵入性、可及性强的辅助诊断方法。

Method: 采用视觉变换器（Vision Transformer）构建深度学习模型，输入为指纹图像，进行三类二分类任务：健康对照组 vs. KS、健康对照组 vs. WSS、KS vs. WSS。通过注意力机制实现模型决策过程的可视化，以揭示关键指纹区域。

Result: 模型在三项任务中分别获得AUC 0.80（对照组 vs. KS）、0.73（对照组 vs. WSS）、0.85（KS vs. WSS），F1分数分别为0.71、0.72、0.83。注意力可视化成功识别出与诊断相关的指纹特征区域，增强了模型的可解释性。

Conclusion: 该研究证实了KS和WSS患者存在特异性指纹模式，基于指纹的AI模型具备作为非侵入性、可解释且易于推广的早期诊断工具的潜力，有望缓解当前遗传综合征的漏诊问题。

Abstract: Kabuki syndrome (KS) and Wiedemann-Steiner syndrome (WSS) are rare but distinct developmental disorders that share overlapping clinical features, including neurodevelopmental delay, growth restriction, and persistent fetal fingertip pads. While genetic testing remains the diagnostic gold standard, many individuals with KS or WSS remain undiagnosed due to barriers in access to both genetic testing and expertise. Dermatoglyphic anomalies, despite being established hallmarks of several genetic syndromes, remain an underutilized diagnostic signal in the era of molecular testing. This study presents a vision transformer-based deep learning model that leverages fingerprint images to distinguish individuals with KS and WSS from unaffected controls and from one another. We evaluate model performance across three binary classification tasks. Across the three classification tasks, the model achieved AUC scores of 0.80 (control vs. KS), 0.73 (control vs. WSS), and 0.85 (KS vs. WSS), with corresponding F1 scores of 0.71, 0.72, and 0.83, respectively. Beyond classification, we apply attention-based visualizations to identify fingerprint regions most salient to model predictions, enhancing interpretability. Together, these findings suggest the presence of syndrome-specific fingerprint features, demonstrating the feasibility of a fingerprint-based artificial intelligence (AI) tool as a noninvasive, interpretable, and accessible future diagnostic aid for the early diagnosis of underdiagnosed genetic syndromes.

</details>


### [14] [MMEarth-Bench: Global Model Adaptation via Multimodal Test-Time Training](https://arxiv.org/abs/2602.06285)
*Lucia Gordon,Serge Belongie,Christian Igel,Nico Lang*

Main category: cs.CV

TL;DR: 提出MMEarth-Bench，一个包含5个新多模态环境任务、12种模态、全球分布数据的基准数据集，用于评估多模态预训练模型在全局尺度上的表现。发现尽管预训练提升小样本下的鲁棒性，但地理泛化能力仍差。为此提出TTT-MMR方法，利用测试时所有可用模态作为辅助任务进行测试时训练，显著提升模型在随机和地理测试集上的性能，且地理分批提供正则化与专化的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有地理空间基准数据集数据模态少、全球代表性不足，难以评估多模态预训练模型在全球范围内的表现。需要一个更全面、更具代表性的基准来推动该领域发展。

Method: 提出一种模型无关的测试时训练方法TTT-MMR，利用测试阶段所有可用模态作为辅助任务进行重建，无需预训练模型接受这些模态输入；结合地理分批策略以优化正则化与专化之间的平衡。

Result: TTT-MMR方法在随机和地理测试集上均提升了模型性能，证明其对跨域适应的有效性；同时验证了地理分批策略在训练过程中的优势。

Conclusion: MMEarth-Bench为多模态地球观测模型提供了新的评估标准，而TTT-MMR方法有效增强了模型在新地理区域和下游任务上的泛化能力，为实际应用提供了重要支持。

Abstract: Recent research in geospatial machine learning has demonstrated that models pretrained with self-supervised learning on Earth observation data can perform well on downstream tasks with limited training data. However, most of the existing geospatial benchmark datasets have few data modalities and poor global representation, limiting the ability to evaluate multimodal pretrained models at global scales. To fill this gap, we introduce MMEarth-Bench, a collection of five new multimodal environmental tasks with 12 modalities, globally distributed data, and both in- and out-of-distribution test splits. We benchmark a diverse set of pretrained models and find that while (multimodal) pretraining tends to improve model robustness in limited data settings, geographic generalization abilities remain poor. In order to facilitate model adaptation to new downstream tasks and geographic domains, we propose a model-agnostic method for test-time training with multimodal reconstruction (TTT-MMR) that uses all the modalities available at test time as auxiliary tasks, regardless of whether a pretrained model accepts them as input. Our method improves model performance on both the random and geographic test splits, and geographic batching leads to a good trade-off between regularization and specialization during TTT. Our dataset, code, and visualization tool are linked from the project page at lgordon99.github.io/mmearth-bench.

</details>


### [15] [Unsupervised MRI-US Multimodal Image Registration with Multilevel Correlation Pyramidal Optimization](https://arxiv.org/abs/2602.06288)
*Jiazheng Wang,Zeyu Liu,Min Liu,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于多级相关金字塔优化（MCPO）的无监督多模态医学图像配准方法，用于解决术前与术中图像因模态差异和组织变形导致的配准难题。该方法通过模态无关邻域描述符提取特征，并设计多级金字塔融合优化机制，在不同尺度上实现位移场的全局优化与局部细节补充，显著提升了配准精度。在Learn2Reg 2025的ReMIND2Reg任务中，该方法在验证集和测试集均排名第一；在Resect数据集上平均靶点误差（TRE）达1.798 mm，证明了其广泛适用性。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有手术导航系统中，由于多模态图像间差异及术中组织变形，导致术前与术中图像难以准确配准，影响手术引导精度，亟需一种鲁棒、高效的无监督多模态图像配准方法。

Method: 采用模态无关邻域描述符提取各模态特征，将多模态图像映射至统一特征空间；设计多级金字塔融合优化机制，结合密集相关分析与加权平衡耦合凸优化，实现多尺度下位移场的全局优化与局部细节互补。

Result: 在Learn2Reg 2025 ReMIND2Reg任务中，方法在验证集与测试集均获得第一名；在Resect数据集上达到平均1.798 mm的靶点误差（TRE），表现优异。

Conclusion: 所提出的MCPO方法有效解决了多模态图像配准中的关键挑战，具有高精度与强泛化能力，适用于术前-术中图像注册，为手术导航提供了可靠技术支撑。

Abstract: Surgical navigation based on multimodal image registration has played a significant role in providing intraoperative guidance to surgeons by showing the relative position of the target area to critical anatomical structures during surgery. However, due to the differences between multimodal images and intraoperative image deformation caused by tissue displacement and removal during the surgery, effective registration of preoperative and intraoperative multimodal images faces significant challenges. To address the multimodal image registration challenges in Learn2Reg 2025, an unsupervised multimodal medical image registration method based on multilevel correlation pyramidal optimization (MCPO) is designed to solve these problems. First, the features of each modality are extracted based on the modality independent neighborhood descriptor, and the multimodal images is mapped to the feature space. Second, a multilevel pyramidal fusion optimization mechanism is designed to achieve global optimization and local detail complementation of the displacement field through dense correlation analysis and weight-balanced coupled convex optimization for input features at different scales. Our method focuses on the ReMIND2Reg task in Learn2Reg 2025. Based on the results, our method achieved the first place in the validation phase and test phase of ReMIND2Reg. The MCPO is also validated on the Resect dataset, achieving an average TRE of 1.798 mm. This demonstrates the broad applicability of our method in preoperative-to-intraoperative image registration. The code is avaliable at https://github.com/wjiazheng/MCPO.

</details>


### [16] [Accelerating Vision Transformers on Brain Processing Unit](https://arxiv.org/abs/2602.06300)
*Jinchi Tang,Yan Guo*

Main category: cs.CV

TL;DR: 本文提出一种新方法，通过将Vision Transformer（如DeiT）中的线性层和层归一化操作替换为设计好的卷积算子，使其能够充分利用BPU硬件的加速能力。该方法无需重新训练或微调即可继承原始权重，实现了在BPU上对ViT模型的有效部署。实验表明，量化后的DeiT-Base在ImageNet上达到80.4%准确率（原为81.8%），推理速度提升达3.8倍；在花分类数据集上微调后仅损失0.5%准确率，验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于CNN优化的BPU硬件与Vision Transformer的计算特性不匹配（如线性层处理三维数据而BPU针对四维卷积优化），导致难以利用BPU加速ViT模型，因此需要一种方法使ViT能适配BPU架构。

Method: 将Vision Transformer中的线性层和层归一化操作重构为特定设计的卷积运算符，实现对BPU硬件的兼容性，同时保留原始模型权重，无需重新训练或微调。

Result: 量化DeiT-Base在ImageNet上准确率达80.4%（原81.8%），推理速度提升3.8倍；在花分类数据集上微调后仅下降0.5%准确率，证明方法有效且高效。

Conclusion: 本工作首次成功实现Vision Transformer在BPU上的全量加速部署，通过结构重写使ViT模型兼容专用于CNN的硬件，兼顾性能与效率，为Transformer在专用硬件上的落地提供了可行路径。

Abstract: With the advancement of deep learning technologies, specialized neural processing hardware such as Brain Processing Units (BPUs) have emerged as dedicated platforms for CNN acceleration, offering optimized INT8 computation capabilities for convolutional operations. Meanwhile, Vision Transformer (ViT) models, such as the Data-efficient Image Transformer (DeiT), have demonstrated superior performance and play increasingly crucial roles in computer vision tasks. However, due to the architectural mismatch between CNN-optimized hardware and Vision Transformer computation characteristics--namely, that linear layers in Transformers operate on three-dimensional data while BPU acceleration is designed for four-dimensional convolution operations-it is difficult or even impossible to leverage BPU's advantages when deploying Vision Transformers. To address this challenge, we propose a novel approach that restructures the Vision Transformer by replacing linear layers and layer normalization operations with carefully designed convolutional operators. This enables DeiT to fully utilize the acceleration capabilities of BPUs, while allowing the original weight parameters to be inherited by the restructured models without retraining or fine-tuning. To the best of our knowledge, this is the first successful deployment of Vision Transformers that fully leverages BPU classification datasets demonstrate the effectiveness of our approach. Specifically, the quantized DeiT-Base model achieves 80.4% accuracy on ImageNet, compared to the original 81.8%, while obtaining up to a 3.8* inference speedup. Our finetuned DeiT model on the flower classification dataset also achieves excellent performance, with only a 0.5% accuracy drop for the DeiT-Base model, further demonstrating the effectiveness of our method.

</details>


### [17] [Adaptive and Balanced Re-initialization for Long-timescale Continual Test-time Domain Adaptation](https://arxiv.org/abs/2602.06328)
*Yanshuo Wang,Jinguang Tong,Jun Lan,Weiqiang Wang,Huijia Zhu,Haoxing Chen,Xuesong Li,Jie Hong*

Main category: cs.CV

TL;DR: 本文提出一种基于重初始化的持续测试时域自适应（CTTA）方法，通过分析标签翻转轨迹模式，设计自适应平衡重初始化（ABR）策略，以提升模型在长期非平稳环境中的适应能力。实验表明，该方法在多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法虽优化了适应过程，但缺乏对模型在长期连续变化环境中持续性能的保障，因此亟需探索提升长期适应能力的有效机制。

Method: 提出自适应平衡重初始化（ABR）方法，根据标签翻转的变化动态调整重初始化间隔，实现对模型长期性能的维护。

Result: 在多个广泛使用的CTTA基准上，所提方法显著优于现有方法，验证了其有效性与优越性。

Conclusion: 通过引入基于标签翻转变化的自适应重初始化机制，ABR有效提升了模型在长期非平稳环境下的持续适应能力，为解决长期CTTA问题提供了新思路。

Abstract: Continual test-time domain adaptation (CTTA) aims to adjust models so that they can perform well over time across non-stationary environments. While previous methods have made considerable efforts to optimize the adaptation process, a crucial question remains: Can the model adapt to continually changing environments over a long time? In this work, we explore facilitating better CTTA in the long run using a re-initialization (or reset) based method. First, we observe that the long-term performance is associated with the trajectory pattern in label flip. Based on this observed correlation, we propose a simple yet effective policy, Adaptive-and-Balanced Re-initialization (ABR), towards preserving the model's long-term performance. In particular, ABR performs weight re-initialization using adaptive intervals. The adaptive interval is determined based on the change in label flip. The proposed method is validated on extensive CTTA benchmarks, achieving superior performance.

</details>


### [18] [Taming SAM3 in the Wild: A Concept Bank for Open-Vocabulary Segmentation](https://arxiv.org/abs/2602.06333)
*Gensheng Pei,Xiruo Jiang,Yazhou Yao,Xiangbo Shu,Fumin Shen,Byeungwoo Jeon*

Main category: cs.CV

TL;DR: 本文提出ConceptBank，一个无需参数的校准框架，用于在开放词汇分割中应对数据漂移和概念漂移问题。通过构建目标域特定的概念库，利用类级视觉原型锚定目标域证据，挖掘代表性支持以抑制异常值，并融合候选概念来纠正概念漂移，显著提升了SAM3在分布漂移场景下的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇分割方法（如SAM3）依赖预定义概念提示，在面对目标域中的数据漂移或概念漂移时，视觉证据与提示之间的对齐会失效，导致性能下降。因此需要一种能够动态适应分布变化的机制。

Method: 提出ConceptBank框架，不依赖可训练参数。首先基于目标域统计构建特定概念库；其次使用类级视觉原型锚定目标域特征；然后通过挖掘代表性支持样本以抵御数据漂移带来的异常值干扰；最后融合多个候选概念以应对概念漂移。

Result: 实验表明，ConceptBank能有效提升SAM3在自然场景和遥感等复杂场景下的鲁棒性与适应能力，显著改善开放词汇分割在分布漂移条件下的表现，成为新的基准。

Conclusion: ConceptBank提供了一种高效、无参数的在线校准方案，使开放词汇分割模型具备更强的动态适应能力，为应对真实世界中的分布变化提供了重要解决方案。

Abstract: The recent introduction of \texttt{SAM3} has revolutionized Open-Vocabulary Segmentation (OVS) through \textit{promptable concept segmentation}, which grounds pixel predictions in flexible concept prompts. However, this reliance on pre-defined concepts makes the model vulnerable: when visual distributions shift (\textit{data drift}) or conditional label distributions evolve (\textit{concept drift}) in the target domain, the alignment between visual evidence and prompts breaks down. In this work, we present \textsc{ConceptBank}, a parameter-free calibration framework to restore this alignment on the fly. Instead of adhering to static prompts, we construct a dataset-specific concept bank from the target statistics. Our approach (\textit{i}) anchors target-domain evidence via class-wise visual prototypes, (\textit{ii}) mines representative supports to suppress outliers under data drift, and (\textit{iii}) fuses candidate concepts to rectify concept drift. We demonstrate that \textsc{ConceptBank} effectively adapts \texttt{SAM3} to distribution drifts, including challenging natural-scene and remote-sensing scenarios, establishing a new baseline for robustness and efficiency in OVS. Code and model are available at https://github.com/pgsmall/ConceptBank.

</details>


### [19] [SPDA-SAM: A Self-prompted Depth-Aware Segment Anything Model for Instance Segmentation](https://arxiv.org/abs/2602.06335)
*Yihan Shang,Wei Wang,Chao Huang,Xinghui Dong*

Main category: cs.CV

TL;DR: 本文提出了一种自提示深度感知的分割任意模型（SPDA-SAM），通过引入语义-空间自提示模块（SSSPM）和粗到细的RGB-D融合模块（C2FFM），有效提升了实例分割在缺乏深度信息和依赖人工提示时的性能。该方法利用图像编码器与掩码解码器分别提取语义与空间提示，并结合单目RGB图像与估计深度图进行多层次特征融合，显著增强了对物体边界的感知能力。实验表明，SPDA-SAM在12个数据集上均优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有实例分割方法如SAM严重依赖高质量的人工提示，且仅使用RGB图像，缺乏深度信息，导致对空间结构和边界感知能力受限。因此，亟需一种能自动生成提示并融合深度信息的方法以提升泛化性能。

Method: 设计了语义-空间自提示模块（SSSPM），从SAM的图像编码器和掩码解码器中分别提取语义与空间提示；提出粗到细的RGB-D融合模块（C2FFM），将单目RGB图像与估计深度图的特征进行多层级融合，利用深度图提供粗粒度结构引导与细粒度局部变化编码。

Result: 在12个不同数据集上的实验结果表明，SPDA-SAM显著优于当前最先进的方法，验证了自提示机制和粗到细的RGB-D融合策略的有效性。

Conclusion: SPDA-SAM通过自提示机制与深度感知融合策略，有效缓解了传统SAM对人工提示的依赖问题，并弥补了RGB图像在空间信息上的缺失，显著提升了实例分割的鲁棒性和精度。

Abstract: Recently, Segment Anything Model (SAM) has demonstrated strong generalizability in various instance segmentation tasks. However, its performance is severely dependent on the quality of manual prompts. In addition, the RGB images that instance segmentation methods normally use inherently lack depth information. As a result, the ability of these methods to perceive spatial structures and delineate object boundaries is hindered. To address these challenges, we propose a Self-prompted Depth-Aware SAM (SPDA-SAM) for instance segmentation. Specifically, we design a Semantic-Spatial Self-prompt Module (SSSPM) which extracts the semantic and spatial prompts from the image encoder and the mask decoder of SAM, respectively. Furthermore, we introduce a Coarse-to-Fine RGB-D Fusion Module (C2FFM), in which the features extracted from a monocular RGB image and the depth map estimated from it are fused. In particular, the structural information in the depth map is used to provide coarse-grained guidance to feature fusion, while local variations in depth are encoded in order to fuse fine-grained feature representations. To our knowledge, SAM has not been explored in such self-prompted and depth-aware manners. Experimental results demonstrate that our SPDA-SAM outperforms its state-of-the-art counterparts across twelve different data sets. These promising results should be due to the guidance of the self-prompts and the compensation for the spatial information loss by the coarse-to-fine RGB-D fusion operation.

</details>


### [20] [FlowConsist: Make Your Flow Consistent with Real Trajectory](https://arxiv.org/abs/2602.06346)
*Tianyi Zhang,Chengcheng Liu,Jinwei Chen,Chun-Le Guo,Chongyi Li,Ming-Ming Cheng,Bo Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 提出FlowConsist训练框架，通过使用模型自身预测的边际速度替代条件速度，并引入轨迹校正策略，解决快速流模型中的轨迹漂移和误差累积问题，在ImageNet 256×256上仅用1步采样即达到FID 1.52的新纪录。


<details>
  <summary>Details</summary>
Motivation: 当前快速流模型的训练范式存在两个根本问题：一是随机配对噪声-数据样本构建的条件速度导致系统性轨迹漂移；二是模型近似误差随时间步累积，造成长时间区间严重偏离。

Method: 提出一种基于边际速度的优化方式，取代传统的条件速度；引入轨迹校正策略，在每一步时间点对齐生成样本与真实样本的边际分布，以增强轨迹一致性。

Result: 在ImageNet 256×256数据集上，仅需1次采样步骤即可实现FID 1.52，达到新的最先进水平。

Conclusion: FlowConsist通过强化轨迹一致性与动态校正机制，显著提升了快速流模型的生成质量与稳定性，为高效生成提供了新范式。

Abstract: Fast flow models accelerate the iterative sampling process by learning to directly predict ODE path integrals, enabling one-step or few-step generation. However, we argue that current fast-flow training paradigms suffer from two fundamental issues. First, conditional velocities constructed from randomly paired noise-data samples introduce systematic trajectory drift, preventing models from following a consistent ODE path. Second, the model's approximation errors accumulate over time steps, leading to severe deviations across long time intervals. To address these issues, we propose FlowConsist, a training framework designed to enforce trajectory consistency in fast flows. We propose a principled alternative that replaces conditional velocities with the marginal velocities predicted by the model itself, aligning optimization with the true trajectory. To further address error accumulation over time steps, we introduce a trajectory rectification strategy that aligns the marginal distributions of generated and real samples at every time step along the trajectory. Our method establishes a new state-of-the-art on ImageNet 256$\times$256, achieving an FID of 1.52 with only 1 sampling step.

</details>


### [21] [Robust Pedestrian Detection with Uncertain Modality](https://arxiv.org/abs/2602.06363)
*Qian Bie,Xiao Wang,Bin Yang,Zhixi Yu,Jun Chen,Xin Xu*

Main category: cs.CV

TL;DR: 提出AUNet用于处理RGB-NIR-TIR三模态输入不确定性问题，通过UMVR模块验证模态可用性并进行语义优化，MAI模块自适应融合有效信息，提升跨模态行人检测在任意模态组合下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态行人检测方法在实际场景中面临多模态数据缺失或不完整的问题，导致性能下降；尤其在夜间或低光环境下，仅依赖RGB或TIR会丢失关键纹理信息，而引入NIR可弥补这一缺陷，但如何应对不确定的模态输入组合仍缺乏有效解决方案。

Method: 提出AUNet框架，包含两个核心组件：(1) 统一模态验证与精炼（UMVR），通过不确定性感知路由判断各模态是否可用，并对可用模态进行语义增强以确保信息可靠性；(2) 模态感知交互（MAI）模块，根据UMVR输出动态激活或关闭内部交互机制，实现对可用模态的自适应互补融合。

Result: 在新构建的TRNT数据集上，AUNet在多种模态缺失组合下均表现出色，显著优于现有方法，特别是在复杂光照和缺失模态条件下保持了高鲁棒性和检测精度。

Conclusion: AUNet通过自适应模态验证与交互机制，有效解决了跨模态行人检测中因模态输入不确定性带来的性能下降问题，为全天候监控系统提供了更可靠的技术支持。

Abstract: Existing cross-modal pedestrian detection (CMPD) employs complementary information from RGB and thermal-infrared (TIR) modalities to detect pedestrians in 24h-surveillance systems.RGB captures rich pedestrian details under daylight, while TIR excels at night. However, TIR focuses primarily on the person's silhouette, neglecting critical texture details essential for detection. While the near-infrared (NIR) captures texture under low-light conditions, which effectively alleviates performance issues of RGB and detail loss in TIR, thereby reducing missed detections. To this end, we construct a new Triplet RGB-NIR-TIR (TRNT) dataset, comprising 8,281 pixel-aligned image triplets, establishing a comprehensive foundation for algorithmic research. However, due to the variable nature of real-world scenarios, imaging devices may not always capture all three modalities simultaneously. This results in input data with unpredictable combinations of modal types, which challenge existing CMPD methods that fail to extract robust pedestrian information under arbitrary input combinations, leading to significant performance degradation. To address these challenges, we propose the Adaptive Uncertainty-aware Network (AUNet) for accurately discriminating modal availability and fully utilizing the available information under uncertain inputs. Specifically, we introduce Unified Modality Validation Refinement (UMVR), which includes an uncertainty-aware router to validate modal availability and a semantic refinement to ensure the reliability of information within the modality. Furthermore, we design a Modality-Aware Interaction (MAI) module to adaptively activate or deactivate its internal interaction mechanisms per UMVR output, enabling effective complementary information fusion from available modalities.

</details>


### [22] [POINTS-GUI-G: GUI-Grounding Journey](https://arxiv.org/abs/2602.06391)
*Zhongyin Zhao,Yuan Liu,Yikun Liu,Haicheng Wang,Le Tian,Xiao Zhou,Yangxiu You,Zilin Yu,Yang Yu,Jie Zhou*

Main category: cs.CV

TL;DR: 本文提出POINTS-GUI-G-8B模型，通过改进数据工程、训练策略和基于可验证奖励的强化学习，在GUI接地任务上实现最先进的性能，显著提升视觉语言模型在界面元素定位上的精度。


<details>
  <summary>Details</summary>
Motivation: 现有工作依赖已有较强空间感知能力的模型（如Qwen3-VL），而本文旨在从基础模型（如POINTS-1.5）出发，完整掌握从零开始构建高精度GUI接地能力的技术流程。

Method: 采用统一格式处理开源数据集，结合增强、过滤与难度分级的数据工程；实施视觉编码器持续微调及训练推理分辨率一致性策略；引入基于可验证奖励的强化学习，以提升感知任务中的定位精度。

Result: 在ScreenSpot-Pro（59.9）、OSWorld-G（66.0）、ScreenSpot-v2（95.7）和UI-Vision（49.9）等基准上均达到领先水平，证明了方法的有效性。

Conclusion: 通过系统优化数据、训练与强化学习策略，本文成功构建了一个从低基础能力模型出发的高性能GUI接地系统，为端到端数字任务自动化提供了关键支撑。

Abstract: The rapid advancement of vision-language models has catalyzed the emergence of GUI agents, which hold immense potential for automating complex tasks, from online shopping to flight booking, thereby alleviating the burden of repetitive digital workflows. As a foundational capability, GUI grounding is typically established as a prerequisite for end-to-end task execution. It enables models to precisely locate interface elements, such as text and icons, to perform accurate operations like clicking and typing. Unlike prior works that fine-tune models already possessing strong spatial awareness (e.g., Qwen3-VL), we aim to master the full technical pipeline by starting from a base model with minimal grounding ability, such as POINTS-1.5. We introduce POINTS-GUI-G-8B, which achieves state-of-the-art performance with scores of 59.9 on ScreenSpot-Pro, 66.0 on OSWorld-G, 95.7 on ScreenSpot-v2, and 49.9 on UI-Vision. Our model's success is driven by three key factors: (1) Refined Data Engineering, involving the unification of diverse open-source datasets format alongside sophisticated strategies for augmentation, filtering, and difficulty grading; (2) Improved Training Strategies, including continuous fine-tuning of the vision encoder to enhance perceptual accuracy and maintaining resolution consistency between training and inference; and (3) Reinforcement Learning (RL) with Verifiable Rewards. While RL is traditionally used to bolster reasoning, we demonstrate that it significantly improves precision in the perception-intensive GUI grounding task. Furthermore, GUI grounding provides a natural advantage for RL, as rewards are easily verifiable and highly accurate.

</details>


### [23] [TFusionOcc: Student's t-Distribution Based Object-Centric Multi-Sensor Fusion Framework for 3D Occupancy Prediction](https://arxiv.org/abs/2602.06400)
*Zhenxing Ming,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 提出TFusionOcc，一种基于可变形超椭球的多传感器融合框架，用于3D语义占用预测，在nuScenes上达到SOTA性能，并在nuScenes-C上验证了其在传感器退化情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于3D体素或3D高斯表示，难以高效捕捉驾驶环境中的细粒度几何细节，因此需要更灵活的几何基元和更优的多传感器融合策略。

Method: 采用多阶段多传感器融合、学生t分布与T混合模型（TMM），结合可变形超椭球（带逆扭曲的超椭球）作为更灵活的几何表示。

Result: 在nuScenes基准上取得当前最优性能；在nuScenes-C数据集上表现出强鲁棒性，尤其在相机和激光雷达退化场景下。

Conclusion: TFusionOcc通过引入更灵活的几何基元和先进的融合机制，显著提升了3D语义占用预测的精度与鲁棒性，为自动驾驶感知提供了有效解决方案。

Abstract: 3D semantic occupancy prediction enables autonomous vehicles (AVs) to perceive fine-grained geometric and semantic structure of their surroundings from onboard sensors, which is essential for safe decision-making and navigation. Recent models for 3D semantic occupancy prediction have successfully addressed the challenge of describing real-world objects with varied shapes and classes. However, the intermediate representations used by existing methods for 3D semantic occupancy prediction rely heavily on 3D voxel volumes or a set of 3D Gaussians, hindering the model's ability to efficiently and effectively capture fine-grained geometric details in the 3D driving environment. This paper introduces TFusionOcc, a novel object-centric multi-sensor fusion framework for predicting 3D semantic occupancy. By leveraging multi-stage multi-sensor fusion, Student's t-distribution, and the T-Mixture model (TMM), together with more geometrically flexible primitives, such as the deformable superquadric (superquadric with inverse warp), the proposed method achieved state-of-the-art (SOTA) performance on the nuScenes benchmark. In addition, extensive experiments were conducted on the nuScenes-C dataset to demonstrate the robustness of the proposed method in different camera and lidar corruption scenarios. The code will be available at: https://github.com/DanielMing123/TFusionOcc

</details>


### [24] [MeDocVL: A Visual Language Model for Medical Document Understanding and Parsing](https://arxiv.org/abs/2602.06402)
*Wenjie Wang,Wei Wu,Ying Liu,Yuan Zhao,Xiaole Lv,Liang Diao,Zengjian Fan,Wenfeng Xie,Ziling Lin,De Shi,Lin Huang,Kaihe Xu,Hong Li*

Main category: cs.CV

TL;DR: 提出MeDocVL，一种用于查询驱动的医疗文档解析的后训练视觉语言模型。通过训练驱动的标签精炼和噪声感知混合后训练策略，有效处理噪声标注并提升提取精度，在医疗发票基准测试中表现优于传统OCR系统和强基线VLM模型，达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有OCR系统和通用视觉语言模型在处理复杂布局、领域特定术语和噪声标注的医疗文档时表现不佳，难以实现严格的字段级精确匹配。

Method: 采用训练驱动的标签精炼构建高质量监督信号，结合噪声感知的混合后训练策略（融合强化学习与监督微调），提升模型鲁棒性和精确性。

Result: 在医疗发票基准上，MeDocVL consistently 超越传统OCR系统和强VLM基线，实现噪声监督下的最先进性能。

Conclusion: MeDocVL 有效解决了医疗文档OCR中的噪声与精确匹配难题，为高精度医疗文档解析提供了可靠解决方案。

Abstract: Medical document OCR is challenging due to complex layouts, domain-specific terminology, and noisy annotations, while requiring strict field-level exact matching. Existing OCR systems and general-purpose vision-language models often fail to reliably parse such documents. We propose MeDocVL, a post-trained vision-language model for query-driven medical document parsing. Our framework combines Training-driven Label Refinement to construct high-quality supervision from noisy annotations, with a Noise-aware Hybrid Post-training strategy that integrates reinforcement learning and supervised fine-tuning to achieve robust and precise extraction. Experiments on medical invoice benchmarks show that MeDocVL consistently outperforms conventional OCR systems and strong VLM baselines, achieving state-of-the-art performance under noisy supervision.

</details>


### [25] [Point Virtual Transformer](https://arxiv.org/abs/2602.06406)
*Veerain Sood,Bnalin,Gaurav Pandey*

Main category: cs.CV

TL;DR: 提出PointViT框架，通过选择性融合真实与虚拟点云，在保持高效的同时提升远距离3D目标检测性能。利用Transformer进行上下文聚合，结合BEV表示与稀疏卷积，实现高精度检测。在KITTI数据集上表现优异，尤其在远距离检测方面有显著改进。


<details>
  <summary>Details</summary>
Motivation: LiDAR在远距离时点云稀疏，导致几何特征不足，影响3D目标检测性能；现有方法虽引入RGB生成的虚拟点，但全量融合带来计算开销大和信息融合困难的问题。

Method: 提出PointViT，基于Transformer架构，联合处理原始LiDAR点与选择性采样的虚拟点；比较了从点级到BEV级的多种融合策略，采用稀疏卷积对融合后的点云构建BEV特征，并通过变压器模块优化高置信度目标查询。

Result: 在KITTI基准上，汽车类别的3D AP达到91.16%，BEV AP为95.94%，2D AP达99.36%，显著提升了远距离检测能力。

Conclusion: PointViT通过智能选择虚拟点并有效融合，实现了高精度与高效率的平衡，为远距离LiDAR 3D检测提供了有效解决方案。

Abstract: LiDAR-based 3D object detectors often struggle to detect far-field objects due to the sparsity of point clouds at long ranges, which limits the availability of reliable geometric cues. To address this, prior approaches augment LiDAR data with depth-completed virtual points derived from RGB images; however, directly incorporating all virtual points leads to increased computational cost and introduces challenges in effectively fusing real and virtual information. We present Point Virtual Transformer (PointViT), a transformer-based 3D object detection framework that jointly reasons over raw LiDAR points and selectively sampled virtual points. The framework examines multiple fusion strategies, ranging from early point-level fusion to BEV-based gated fusion, and analyses their trade-offs in terms of accuracy and efficiency. The fused point cloud is voxelized and encoded using sparse convolutions to form a BEV representation, from which a compact set of high-confidence object queries is initialised and refined through a transformer-based context aggregation module. Experiments on the KITTI benchmark report 91.16% 3D AP, 95.94% BEV AP, and 99.36% AP on the KITTI 2D detection benchmark for the Car class.

</details>


### [26] [Learning Human Visual Attention on 3D Surfaces through Geometry-Queried Semantic Priors](https://arxiv.org/abs/2602.06419)
*Soham Pahari,Sandeep C. Kumain*

Main category: cs.CV

TL;DR: 本文提出SemGeo-AttentionNet，一种双流架构，通过不对称跨模态融合显式建模三维物体视觉注意的底向上几何处理与顶向下语义识别之间的相互作用。该方法利用基于扩散的语义先验和点云变换器进行几何处理，通过交叉注意力使几何特征查询语义内容，从而让底向显著性引导顶向检索。此外，通过强化学习扩展至时序扫描路径生成，首次提出尊重3D网格拓扑并包含抑制返回机制的公式。在SAL3D、NUS3D和3DVA数据集上的评估显示显著性能提升，验证了认知动机架构在建模人类对三维表面视觉注意方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有3D显著性方法依赖手工设计的几何特征或缺乏语义意识的学习方法，无法解释为何人类会注视语义上有意义但几何上不显著的区域。

Method: 提出SemGeo-AttentionNet，采用双流架构，结合基于扩散的语义先验与几何条件下的多视角渲染、点云变换器处理几何信息，并通过交叉注意力实现异构特征融合；进一步引入强化学习生成时序扫描路径，考虑3D网格拓扑与抑制返回机制。

Result: 在SAL3D、NUS3D和3DVA数据集上均取得显著性能提升，验证了模型在模拟人类视觉注意方面的有效性。

Conclusion: 认知驱动的双流架构能有效建模人类对三维表面的视觉注意行为，尤其在语义重要但几何平凡的区域表现更优。

Abstract: Human visual attention on three-dimensional objects emerges from the interplay between bottom-up geometric processing and top-down semantic recognition. Existing 3D saliency methods rely on hand-crafted geometric features or learning-based approaches that lack semantic awareness, failing to explain why humans fixate on semantically meaningful but geometrically unremarkable regions. We introduce SemGeo-AttentionNet, a dual-stream architecture that explicitly formalizes this dichotomy through asymmetric cross-modal fusion, leveraging diffusion-based semantic priors from geometry-conditioned multi-view rendering and point cloud transformers for geometric processing. Cross-attention ensures geometric features query semantic content, enabling bottom-up distinctiveness to guide top-down retrieval. We extend our framework to temporal scanpath generation through reinforcement learning, introducing the first formulation respecting 3D mesh topology with inhibition-of-return dynamics. Evaluation on SAL3D, NUS3D and 3DVA datasets demonstrates substantial improvements, validating how cognitively motivated architectures effectively model human visual attention on three-dimensional surfaces.

</details>


### [27] [Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO](https://arxiv.org/abs/2602.06422)
*Yunze Tong,Mushui Liu,Canyu Zhao,Wanggui He,Shiyi Zhang,Hongwei Zhang,Peng Zhang,Jinlong Liu,Ju Huang,Jiamang Wang,Hao Jiang,Pipei Huang*

Main category: cs.CV

TL;DR: TP-GRPO提出一种新的GRPO框架，通过引入步骤级增量奖励和转折点检测机制，解决现有方法中奖励稀疏性和长期依赖建模不足的问题。该方法无需超参数，能有效捕捉早期去噪步骤对后续状态的延迟影响，显著提升文本到图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法在流匹配模型中对所有去噪步骤传播结果奖励，缺乏对每一步局部效应的区分；且组内排名忽略轨迹内部依赖关系，无法建模早期动作的延迟影响。

Method: TP-GRPO采用步骤级增量奖励替代结果奖励，提供密集的步级学习信号；通过检测增量奖励符号变化识别转折点，并为这些关键步骤分配累积的长期奖励，以捕捉其延迟影响。

Result: 实验表明，TP-GRPO能更有效地利用奖励信号，在多个基准上一致提升文本到图像生成效果，且无需额外超参数，计算高效。

Conclusion: TP-GRPO通过引入增量奖励与转折点机制，实现了对去噪轨迹中长期依赖的有效建模，显著改善了生成质量，是一种高效、无超参数的改进方案。

Abstract: Deploying GRPO on Flow Matching models has proven effective for text-to-image generation. However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint-GRPO (TP-GRPO), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory. TP-GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards, providing a dense, step-aware learning signal that better isolates each denoising action's "pure" effect, and (ii) it identifies turning points-steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact. Turning points are detected solely via sign changes in incremental rewards, making TP-GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP-GRPO exploits reward signals more effectively and consistently improves generation. Demo code is available at https://github.com/YunzeTong/TurningPoint-GRPO.

</details>


### [28] [POPL-KF: A Pose-Only Geometric Representation-Based Kalman Filter for Point-Line-Based Visual-Inertial Odometry](https://arxiv.org/abs/2602.06425)
*Aiping Wang,Zhaolong Yang,Shuwen Chen,Hai Zhang*

Main category: cs.CV

TL;DR: 提出POPL-KF，一种基于姿态仅几何表示的卡尔曼滤波视觉惯性里程计系统，通过消除点线特征坐标以减少线性化误差，并实现即时视觉测量更新，结合统一基帧选择算法和线特征过滤器，显著提升在挑战场景下的定位精度与鲁棒性，优于现有滤波与优化方法，且保持实时性能。


<details>
  <summary>Details</summary>
Motivation: 主流视觉惯性里程计（VIO）系统依赖点特征进行运动估计与定位，但在复杂场景下性能下降；基于多状态约束卡尔曼滤波（MSCKF）的VIO存在特征三维坐标线性化误差及延迟测量更新问题，亟需改进以提升精度与鲁棒性。

Method: 提出姿态仅几何表示用于线特征；构建POPL-KF系统，采用姿态仅模型处理点与线特征，消除特征坐标在测量方程中的显式存在，实现即时更新；设计统一基帧选择算法以优化相机位姿约束；引入基于图像网格分割与双向光流一致性的线特征过滤器提升线特征质量。

Result: 在公开数据集与真实实验中，POPL-KF优于当前最先进的滤波方法（OpenVINS、PO-KF）和优化方法（PL-VINS、EPLF-VINS），在挑战性场景中表现更优，同时保持实时运行能力。

Conclusion: POPL-KF通过姿态仅几何表示与创新的测量模型设计，有效缓解了线性化误差与延迟更新问题，显著提升了视觉惯性里程计在复杂环境下的定位精度与稳定性，是一种高效可靠的实时解决方案。

Abstract: Mainstream Visual-inertial odometry 
(VIO) systems rely on point features for motion estimation and localization. However, their performance degrades in challenging scenarios. Moreover, the localization accuracy of multi-state constraint Kalman filter (MSCKF)-based VIO systems suffers from linearization errors associated with feature 3D coordinates and delayed measurement updates. To improve the performance of VIO in challenging scenes, we first propose a pose-only geometric representation for line features. Building on this, we develop POPL-KF, a Kalman filter-based VIO system that employs a pose-only geometric representation for both point and line features. POPL-KF mitigates linearization errors by explicitly eliminating both point and line feature coordinates from the measurement equations, while enabling immediate update of visual measurements. We also design a unified base-frames selection algorithm for both point and line features to ensure optimal constraints on camera poses within the pose-only measurement model. To further improve line feature quality, a line feature filter based on image grid segmentation and bidirectional optical flow consistency is proposed. Our system is evaluated on public datasets and real-world experiments, demonstrating that POPL-KF outperforms the state-of-the-art (SOTA) filter-based methods (OpenVINS, PO-KF) and optimization-based methods (PL-VINS, EPLF-VINS), while maintaining real-time performance.

</details>


### [29] [Bridging the Indoor-Outdoor Gap: Vision-Centric Instruction-Guided Embodied Navigation for the Last Meters](https://arxiv.org/abs/2602.06427)
*Yuxiang Zhao,Yirong Yang,Yanqing Zhu,Yanfen Shen,Chiyu Wang,Zhining Gu,Pei Shi,Wei Guo,Mu Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新的无先验指令驱动的室内外连贯导航任务，旨在解决现有方法在室外到室内过渡时无法实现精细定位的问题。通过引入基于图像提示的视觉中心导航框架，并构建首个开源数据集，该方法仅依赖于自我中心视觉观察和自然语言指令进行决策，无需精确外部先验信息。实验表明，所提方法在成功率和路径效率等关键指标上均优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有室外导航方法虽能将智能体引导至目标附近，但难以实现精确进入建筑物入口，限制了其在真实场景中从室外到室内的无缝过渡能力。为克服这一挑战，需要一种不依赖外部精确坐标或先验信息的导航方式，以支持更实用的部署需求。

Method: 提出一种以视觉为中心的导航框架，利用图像作为提示来驱动决策过程；同时设计了一种融合轨迹条件视频生成的数据构建流程，创建首个面向该任务的开源数据集。

Result: 在多个评估指标上，所提方法显著优于当前最先进的基线模型，特别是在成功率达到和路径效率方面表现优异。

Conclusion: 本研究成功实现了无需外部先验信息的室内外连贯导航，为实际应用中的智能体自主移动提供了可靠解决方案，具有良好的可扩展性和实用性。

Abstract: Embodied navigation holds significant promise for real-world applications such as last-mile delivery. However, most existing approaches are confined to either indoor or outdoor environments and rely heavily on strong assumptions, such as access to precise coordinate systems. While current outdoor methods can guide agents to the vicinity of a target using coarse-grained localization, they fail to enable fine-grained entry through specific building entrances, critically limiting their utility in practical deployment scenarios that require seamless outdoor-to-indoor transitions. To bridge this gap, we introduce a novel task: out-to-in prior-free instruction-driven embodied navigation. This formulation explicitly eliminates reliance on accurate external priors, requiring agents to navigate solely based on egocentric visual observations guided by instructions. To tackle this task, we propose a vision-centric embodied navigation framework that leverages image-based prompts to drive decision-making. Additionally, we present the first open-source dataset for this task, featuring a pipeline that integrates trajectory-conditioned video synthesis into the data generation process. Through extensive experiments, we demonstrate that our proposed method consistently outperforms state-of-the-art baselines across key metrics including success rate and path efficiency.

</details>


### [30] [ChatUMM: Robust Context Tracking for Conversational Interleaved Generation](https://arxiv.org/abs/2602.06442)
*Wenxun Dai,Zhiyuan Zhao,Yule Zhong,Yiji Cheng,Jianwei Zhang,Linqing Wang,Shiyi Zhang,Yunlong Lin,Runze He,Fellix Song,Wayne Zhuang,Yong Liu,Haoji Zhang,Yansong Tang,Qinglin Lu,Chunyu Wang*

Main category: cs.CV

TL;DR: ChatUMM 是一种对话式统一多模态模型，通过交错多轮训练策略和系统化的对话数据合成流程，实现了对上下文的稳健追踪，支持交错的多模态生成。该模型在视觉理解、指令引导编辑任务上表现优于现有开源统一模型，并在复杂多轮场景中展现出更强的鲁棒性和上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型受限于单轮交互范式，难以作为持续对话中的助手，缺乏对上下文的连贯跟踪与多轮交互能力。

Method: 提出交错多轮训练策略，将文本-图像序列建模为连续对话流；设计三阶段数据合成管道：构建基础有状态对话、通过带历史依赖重写的干扰轮次强化长程依赖、生成自然交错的多模态响应。

Result: 在视觉理解与指令引导编辑任务上达到开源统一模型的领先水平，文本到图像生成保持高保真度，在复杂多轮对话中表现出更优的流畅性与上下文一致性。

Conclusion: ChatUMM 有效解决了统一多模态模型在多轮对话中的上下文追踪难题，推动其从单次请求求解器向真正对话助手演进。

Abstract: Unified multimodal models (UMMs) have achieved remarkable progress yet remain constrained by a single-turn interaction paradigm, effectively functioning as solvers for independent requests rather than assistants in continuous dialogue. To bridge this gap, we present ChatUMM. As a conversational unified model, it excels at robust context tracking to sustain interleaved multimodal generation. ChatUMM derives its capabilities from two key innovations: an interleaved multi-turn training strategy that models serialized text-image streams as a continuous conversational flow, and a systematic conversational data synthesis pipeline. This pipeline transforms a diverse set of standard single-turn datasets into fluid dialogues through three progressive stages: constructing basic stateful dialogues, enforcing long-range dependency resolution via ``distractor'' turns with history-dependent query rewriting, and synthesizing naturally interleaved multimodal responses. Extensive evaluations demonstrate that ChatUMM achieves state-of-the-art performance among open-source unified models on visual understanding and instruction-guided editing benchmarks, while maintaining competitive fidelity in text-to-image generation. Notably, ChatUMM exhibits superior robustness in complex multi-turn scenarios, ensuring fluid, context-aware dialogues.

</details>


### [31] [What Is Wrong with Synthetic Data for Scene Text Recognition? A Strong Synthetic Engine with Diverse Simulations and Self-Evolution](https://arxiv.org/abs/2602.06450)
*Xingsong Ye,Yongkun Du,JiaXin Zhang,Chen Li,Jing LYU,Zhineng Chen*

Main category: cs.CV

TL;DR: 本文提出UnionST数据引擎和UnionST-S合成数据集，以解决当前合成文本数据在语料、字体和布局多样性上的不足，显著缩小与真实数据的域差距。通过自进化学习（SEL）框架，仅用9%的真实数据标签即可达到与全量标注相当的性能，且在某些场景下超越真实数据训练模型的表现。


<details>
  <summary>Details</summary>
Motivation: 现有合成文本数据在语料、字体和布局上缺乏多样性，导致与真实场景存在显著域差距，限制了其在场景文本识别中的有效性。

Method: 提出UnionST数据引擎，生成覆盖挑战性样本的合成数据；构建UnionST-S大规模合成数据集；设计自进化学习（SEL）框架，实现高效的真实数据标注。

Result: 基于UnionST-S训练的模型在多个场景中显著优于现有合成数据集，甚至超越部分真实数据训练模型；使用SEL框架时，仅需9%的真实标签即达到竞争性性能。

Conclusion: 通过提升合成数据的多样性和复杂性，并结合自进化学习，可有效缓解合成数据与真实数据之间的域差距，显著提升场景文本识别模型的性能。

Abstract: Large-scale and categorical-balanced text data is essential for training effective Scene Text Recognition (STR) models, which is hard to achieve when collecting real data. Synthetic data offers a cost-effective and perfectly labeled alternative. However, its performance often lags behind, revealing a significant domain gap between real and current synthetic data. In this work, we systematically analyze mainstream rendering-based synthetic datasets and identify their key limitations: insufficient diversity in corpus, font, and layout, which restricts their realism in complex scenarios. To address these issues, we introduce UnionST, a strong data engine synthesizes text covering a union of challenging samples and better aligns with the complexity observed in the wild. We then construct UnionST-S, a large-scale synthetic dataset with improved simulations in challenging scenarios. Furthermore, we develop a self-evolution learning (SEL) framework for effective real data annotation. Experiments show that models trained on UnionST-S achieve significant improvements over existing synthetic datasets. They even surpass real-data performance in certain scenarios. Moreover, when using SEL, the trained models achieve competitive performance by only seeing 9% of real data labels.

</details>


### [32] [LAB-Det: Language as a Domain-Invariant Bridge for Training-Free One-Shot Domain Generalization in Object Detection](https://arxiv.org/abs/2602.06474)
*Xu Zhang,Zhe Chen,Jing Zhang,Dacheng Tao*

Main category: cs.CV

TL;DR: 提出一种无需训练的单样本域泛化方法LAB-Det，通过将每个示例映射为描述性文本，利用语言作为域不变桥梁来指导冻结的检测器，在仅有一个标注示例的情况下实现高效适应，显著提升在水下和工业缺陷等数据稀缺场景下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨域少样本方法依赖于对稀缺目标数据的微调，存在成本高和过拟合风险；本文旨在探索是否可在不更新参数的前提下，仅凭一个样本每类即可实现检测器的有效适应。

Method: 提出LAB-Det方法，通过将每个示例转换为描述性文本，利用语言作为域不变桥梁，对冻结的检测器进行语言条件引导，替代传统的梯度更新方式实现适应。

Result: 在UODD和NEU-DET两个基准上，LAB-Det相比最先进的微调基线实现了最高5.4 mAP的提升，且未更新任何模型参数，验证了语言适应的有效性与鲁棒性。

Conclusion: 语言引导的适应是一种高效、可解释的替代微调的方案，特别适用于数据稀缺的专用检测场景。

Abstract: Foundation object detectors such as GLIP and Grounding DINO excel on general-domain data but often degrade in specialized and data-scarce settings like underwater imagery or industrial defects. Typical cross-domain few-shot approaches rely on fine-tuning scarce target data, incurring cost and overfitting risks. We instead ask: Can a frozen detector adapt with only one exemplar per class without training? To answer this, we introduce training-free one-shot domain generalization for object detection, where detectors must adapt to specialized domains with only one annotated exemplar per class and no weight updates. To tackle this task, we propose LAB-Det, which exploits Language As a domain-invariant Bridge. Instead of adapting visual features, we project each exemplar into a descriptive text that conditions and guides a frozen detector. This linguistic conditioning replaces gradient-based adaptation, enabling robust generalization in data-scarce domains. We evaluate on UODD (underwater) and NEU-DET (industrial defects), two widely adopted benchmarks for data-scarce detection, where object boundaries are often ambiguous, and LAB-Det achieves up to 5.4 mAP improvement over state-of-the-art fine-tuned baselines without updating a single parameter. These results establish linguistic adaptation as an efficient and interpretable alternative to fine-tuning in specialized detection settings.

</details>


### [33] [Instance-Free Domain Adaptive Object Detection](https://arxiv.org/abs/2602.06484)
*Hengfu Yu,Jinhong Deng,Lixin Duan,Wen Li*

Main category: cs.CV

TL;DR: 提出了一种名为RSCN的新方法，用于解决无实例的域自适应目标检测问题，通过基于背景特征原型和源域前景与背景特征间关系的一致性来实现鲁棒适配。同时构建了三个专用基准测试集以促进研究。


<details>
  <summary>Details</summary>
Motivation: 在实际场景中（如野生动物监测、病变检测），获取包含目标对象的靶域数据成本高昂，而仅含背景的数据却很丰富。现有方法依赖于靶域中的足够前景实例进行域对齐，但在缺乏目标实例的情况下难以实现有效适配。因此需要一种新的方法来处理无实例的域自适应问题。

Method: 提出RSCN模型，利用背景特征原型进行特征对齐，并强制保持源域和靶域内前景与背景特征之间的关系一致性，从而在没有目标实例的情况下实现有效的域适应。

Result: 在三个新构建的基准测试集（模拟自动驾驶检测、野生动物检测、肺结节检测）上，RSCN显著优于现有的DAOD方法，在无实例条件下表现出更强的性能。

Conclusion: RSCN为无实例的域自适应目标检测提供了有效的解决方案，实验验证了其优越性，推动了该领域的发展。

Abstract: While Domain Adaptive Object Detection (DAOD) has made significant strides, most methods rely on unlabeled target data that is assumed to contain sufficient foreground instances. However, in many practical scenarios (e.g., wildlife monitoring, lesion detection), collecting target domain data with objects of interest is prohibitively costly, whereas background-only data is abundant. This common practical constraint introduces a significant technical challenge: the difficulty of achieving domain alignment when target instances are unavailable, forcing adaptation to rely solely on the target background information. We formulate this challenge as the novel problem of Instance-Free Domain Adaptive Object Detection. To tackle this, we propose the Relational and Structural Consistency Network (RSCN) which pioneers an alignment strategy based on background feature prototypes while simultaneously encouraging consistency in the relationship between the source foreground features and the background features within each domain, enabling robust adaptation even without target instances. To facilitate research, we further curate three specialized benchmarks, including simulative auto-driving detection, wildlife detection, and lung nodule detection. Extensive experiments show that RSCN significantly outperforms existing DAOD methods across all three benchmarks in the instance-free scenario. The code and benchmarks will be released soon.

</details>


### [34] [Rebenchmarking Unsupervised Monocular 3D Occupancy Prediction](https://arxiv.org/abs/2602.06488)
*Zizhan Guo,Yi Feng,Mengtan Zhang,Haoran Zhang,Wei Ye,Rui Fan*

Main category: cs.CV

TL;DR: 本文针对单目图像中3D结构推断，尤其是遮挡区域的挑战，提出了一种重新设计的无监督单目3D占用预测基准。通过分析体渲染过程中的变量，识别出最符合物理规律的占据概率表示，并改进评估协议，使其与有监督方法一致。此外，引入一种考虑遮挡的极化机制，利用多视角视觉线索增强遮挡区域中占据与空闲空间的区分能力。实验表明，该方法显著优于现有无监督方法，并达到与有监督方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法在训练和评估过程中存在不一致性，且依赖2D真实标签无法揭示遮挡区域的几何模糊性，导致对遮挡区域的3D结构推断效果不佳。因此，亟需更一致、更合理的评估框架和更强的约束机制来提升遮挡区域的推理能力。

Method: 1. 重新分析体渲染过程中的变量，提出更符合物理规律的占据概率表示；2. 改进评估协议，使无监督方法的评估方式与有监督方法一致；3. 提出一种遮挡感知的极化机制，融合多视角视觉线索以增强遮挡区域的空间区分能力。

Result: 所提方法在多个指标上显著超越现有无监督方法，并达到与有监督方法相当的性能水平。实验验证了新评估协议的有效性以及极化机制对遮挡区域建模的显著提升作用。

Conclusion: 本研究通过建立更一致的评估标准和引入遮挡感知的极化机制，有效提升了无监督单目3D占用预测在遮挡区域的表现，为未来无监督3D结构推断提供了新的范式。

Abstract: Inferring the 3D structure from a single image, particularly in occluded regions, remains a fundamental yet unsolved challenge in vision-centric autonomous driving. Existing unsupervised approaches typically train a neural radiance field and treat the network outputs as occupancy probabilities during evaluation, overlooking the inconsistency between training and evaluation protocols. Moreover, the prevalent use of 2D ground truth fails to reveal the inherent ambiguity in occluded regions caused by insufficient geometric constraints. To address these issues, this paper presents a reformulated benchmark for unsupervised monocular 3D occupancy prediction. We first interpret the variables involved in the volume rendering process and identify the most physically consistent representation of the occupancy probability. Building on these analyses, we improve existing evaluation protocols by aligning the newly identified representation with voxel-wise 3D occupancy ground truth, thereby enabling unsupervised methods to be evaluated in a manner consistent with that of supervised approaches. Additionally, to impose explicit constraints in occluded regions, we introduce an occlusion-aware polarization mechanism that incorporates multi-view visual cues to enhance discrimination between occupied and free spaces in these regions. Extensive experiments demonstrate that our approach not only significantly outperforms existing unsupervised approaches but also matches the performance of supervised ones. Our source code and evaluation protocol will be made available upon publication.

</details>


### [35] [DreamHome-Pano: Design-Aware and Conflict-Free Panoramic Interior Generation](https://arxiv.org/abs/2602.06494)
*Lulu Chen,Yijiang Hu,Yuanqing Liu,Yulong Li,Yue Yang*

Main category: cs.CV

TL;DR: DreamHome-Pano 是一个可控的全景生成框架，用于高保真室内合成。它通过引入 Prompt-LLM 实现布局约束与风格参考之间的语义对齐，并采用无冲突控制架构（Conflict-Free Control）来保护建筑完整性，避免风格干扰影响空间布局。同时，构建了全面的全景室内基准数据集和多阶段训练流程，包括渐进式监督微调（SFT）和强化学习（RL）。实验表明，该方法在美学质量与结构一致性之间实现了优越平衡，适用于专业级全景室内可视化。


<details>
  <summary>Details</summary>
Motivation: 现有生成框架难以协调建筑结构约束与风格偏好，导致条件冲突，影响布局几何精度。需要一种能有效融合多种条件且保持结构完整性的方法。

Method: 提出 Prompt-LLM 作为语义桥梁，将布局与风格信息转化为专业描述性提示；设计 Conflict-Free Control 架构，结合结构感知几何先验和多条件解耦策略，防止风格干扰破坏空间布局；建立全景室内基准与多阶段训练流程（SFT + RL）。

Result: DreamHome-Pano 在美学质量和结构一致性之间取得优异平衡，显著提升全景室内生成的可控性与真实性，具备专业级应用潜力。

Conclusion: DreamHome-Pano 成功解决了多条件生成中的冲突问题，为高保真、可控的全景室内设计提供了一种可靠且高效的解决方案。

Abstract: In modern interior design, the generation of personalized spaces frequently necessitates a delicate balance between rigid architectural structural constraints and specific stylistic preferences. However, existing multi-condition generative frameworks often struggle to harmonize these inputs, leading to "condition conflicts" where stylistic attributes inadvertently compromise the geometric precision of the layout. To address this challenge, we present DreamHome-Pano, a controllable panoramic generation framework designed for high-fidelity interior synthesis. Our approach introduces a Prompt-LLM that serves as a semantic bridge, effectively translating layout constraints and style references into professional descriptive prompts to achieve precise cross-modal alignment. To safeguard architectural integrity during the generative process, we develop a Conflict-Free Control architecture that incorporates structural-aware geometric priors and a multi-condition decoupling strategy, effectively suppressing stylistic interference from eroding the spatial layout. Furthermore, we establish a comprehensive panoramic interior benchmark alongside a multi-stage training pipeline, encompassing progressive Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). Experimental results demonstrate that DreamHome-Pano achieves a superior balance between aesthetic quality and structural consistency, offering a robust and professional-grade solution for panoramic interior visualization.

</details>


### [36] [DriveWorld-VLA: Unified Latent-Space World Modeling with Vision-Language-Action for Autonomous Driving](https://arxiv.org/abs/2602.06521)
*Feiyang jia,Lin Liu,Ziying Song,Caiyan Jia,Hangjun Ye,Xiaoshuai Hao,Long Chen*

Main category: cs.CV

TL;DR: 提出DriveWorld-VLA框架，通过在表示层面紧密集成视觉-语言-动作（VLA）与世界模型，实现世界建模与规划的统一，利用潜在空间中的世界模型状态作为决策核心，使规划器能评估动作对未来场景演化的影响，支持可控、动作条件化的特征级想象，避免昂贵的像素级模拟。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能有效在单一架构中统一未来场景演化与动作规划，因潜在状态共享不足，限制了视觉想象对动作决策的影响。

Method: 在潜在空间中统一世界建模与规划，将世界模型的潜在状态作为VLA规划器的核心决策状态，实现动作条件化的特征级场景想象。

Result: 在NAV SIM v1上达到91.3 PDMS，v2上达到86.8 EPDMS，nuScenes上3秒平均碰撞率为0.16，性能优于现有方法。

Conclusion: DriveWorld-VLA通过潜在空间的深度融合实现了更高效、更具前瞻性的自动驾驶决策，显著提升了规划能力并减少了对密集标注数据的依赖。

Abstract: End-to-end (E2E) autonomous driving has recently attracted increasing interest in unifying Vision-Language-Action (VLA) with World Models to enhance decision-making and forward-looking imagination. However, existing methods fail to effectively unify future scene evolution and action planning within a single architecture due to inadequate sharing of latent states, limiting the impact of visual imagination on action decisions. To address this limitation, we propose DriveWorld-VLA, a novel framework that unifies world modeling and planning within a latent space by tightly integrating VLA and world models at the representation level, which enables the VLA planner to benefit directly from holistic scene-evolution modeling and reducing reliance on dense annotated supervision. Additionally, DriveWorld-VLA incorporates the latent states of the world model as core decision-making states for the VLA planner, facilitating the planner to assess how candidate actions impact future scene evolution. By conducting world modeling entirely in the latent space, DriveWorld-VLA supports controllable, action-conditioned imagination at the feature level, avoiding expensive pixel-level rollouts. Extensive open-loop and closed-loop evaluations demonstrate the effectiveness of DriveWorld-VLA, which achieves state-of-the-art performance with 91.3 PDMS on NAVSIMv1, 86.8 EPDMS on NAVSIMv2, and 0.16 3-second average collision rate on nuScenes. Code and models will be released in https://github.com/liulin815/DriveWorld-VLA.git.

</details>


### [37] [MicroBi-ConvLSTM: An Ultra-Lightweight Efficient Model for Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.06523)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: MicroBi-ConvLSTM 是一种超轻量级卷积-循环架构，通过两阶段卷积特征提取与4倍时间池化，结合单个双向LSTM层，平均仅需11.4K参数，较TinierHAR减少2.9倍，较DeepConvLSTM减少11.9倍，同时保持线性O(N)复杂度。在8个多样化的HAR基准测试中表现优异，如UCI-HAR达93.41%宏F1，SKODA装配手势识别达94.46%，Daphnet步态冻结检测达88.98%。量化后仅损失0.21%平均F1，部署占用仅23.0KB，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的可穿戴设备上进行人体活动识别（HAR）需要模型在准确率与内存和计算预算之间取得平衡。现有轻量级模型如TinierHAR和TinyHAR虽性能良好，但在考虑操作系统开销后仍超出微控制器有限的SRAM预算。因此亟需更紧凑的模型以满足嵌入式设备的实际部署需求。

Method: 提出MicroBi-ConvLSTM，采用两阶段卷积特征提取、4倍时间池化及单个双向LSTM层，实现极低参数量（平均11.4K），并保持线性复杂度。通过系统消融实验分析各组件对不同任务的贡献，并使用INT8后训练量化降低模型大小。

Result: 在多个主流HAR数据集上表现优秀：UCI-HAR 93.41%宏F1，SKODA装配手势94.46%，Daphnet步态冻结检测88.98%。量化后仅损失0.21%平均F1，平均部署大小为23.0KB，完全适配内存受限的边缘设备。

Conclusion: MicroBi-ConvLSTM 在保证高精度的同时实现了极低的参数量和部署开销，是面向资源受限可穿戴设备的理想轻量级HAR模型，尤其适用于事件检测类任务，具备良好的实用性和可部署性。

Abstract: Human Activity Recognition (HAR) on resource constrained wearables requires models that balance accuracy against strict memory and computational budgets. State of the art lightweight architectures such as TinierHAR (34K parameters) and TinyHAR (55K parameters) achieve strong accuracy, but exceed memory budgets of microcontrollers with limited SRAM once operating system overhead is considered. We present MicroBi-ConvLSTM, an ultra-lightweight convolutional-recurrent architecture achieving 11.4K parameters on average through two stage convolutional feature extraction with 4x temporal pooling and a single bidirectional LSTM layer. This represents 2.9x parameter reduction versus TinierHAR and 11.9x versus DeepConvLSTM while preserving linear O(N) complexity. Evaluation across eight diverse HAR benchmarks shows that MicroBi-ConvLSTM maintains competitive performance within the ultra-lightweight regime: 93.41% macro F1 on UCI-HAR, 94.46% on SKODA assembly gestures, and 88.98% on Daphnet gait freeze detection. Systematic ablation reveals task dependent component contributions where bidirectionality benefits episodic event detection, but provides marginal gains on periodic locomotion. INT8 post training quantization incurs only 0.21% average F1-score degradation, yielding a 23.0 KB average deployment footprint suitable for memory constrained edge devices.

</details>


### [38] [AdaptOVCD: Training-Free Open-Vocabulary Remote Sensing Change Detection via Adaptive Information Fusion](https://arxiv.org/abs/2602.06529)
*Mingyu Dou,Shi Qiu,Ming Hu,Yifan Chen,Huping Ye,Xiaohan Liao,Zhe Sun*

Main category: cs.CV

TL;DR: 提出了一种无需训练的开放词汇变化检测框架AdaptOVCD，通过跨数据、特征和决策三个层次的多级信息融合，结合自适应设计，在无需预定义类别和大规模标注的情况下实现零样本变化检测。该方法在九个场景中表现优异，达到全监督性能上限的84.89%，展现出卓越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有变化检测方法依赖预定义类别和大量像素级标注，限制了其在开放世界场景中的泛化能力和应用范围。

Method: AdaptOVCD采用双维多层次信息融合架构：数据层面通过自适应辐射校准（ARA）融合辐射统计与纹理特征，并与SAM-HQ协同实现辐射一致性分割；特征层面通过自适应变化阈值（ACT）结合全局差异分布与边缘结构先验，利用DINOv3提升检测鲁棒性；决策层面通过自适应置信度过滤（ACF）融合语义置信度与空间约束，配合DGTRS-CLIP实现高置信度语义识别。

Result: 在九个不同场景下，AdaptOVCD实现了任意类别变化的零样本检测，显著优于现有无训练方法；跨数据集评估中达到全监督性能上限的84.89%，表现出强大泛化能力。

Conclusion: AdaptOVCD是一种高效、通用的开放词汇变化检测框架，无需训练即可在复杂开放场景中准确识别未知类别的变化，为遥感变化检测提供了新范式。

Abstract: Remote sensing change detection plays a pivotal role in domains such as environmental monitoring, urban planning, and disaster assessment. However, existing methods typically rely on predefined categories and large-scale pixel-level annotations, which limit their generalization and applicability in open-world scenarios. To address these limitations, this paper proposes AdaptOVCD, a training-free Open-Vocabulary Change Detection (OVCD) architecture based on dual-dimensional multi-level information fusion. The framework integrates multi-level information fusion across data, feature, and decision levels vertically while incorporating targeted adaptive designs horizontally, achieving deep synergy among heterogeneous pre-trained models to effectively mitigate error propagation. Specifically, (1) at the data level, Adaptive Radiometric Alignment (ARA) fuses radiometric statistics with original texture features and synergizes with SAM-HQ to achieve radiometrically consistent segmentation; (2) at the feature level, Adaptive Change Thresholding (ACT) combines global difference distributions with edge structure priors and leverages DINOv3 to achieve robust change detection; (3) at the decision level, Adaptive Confidence Filtering (ACF) integrates semantic confidence with spatial constraints and collaborates with DGTRS-CLIP to achieve high-confidence semantic identification. Comprehensive evaluations across nine scenarios demonstrate that AdaptOVCD detects arbitrary category changes in a zero-shot manner, significantly outperforming existing training-free methods. Meanwhile, it achieves 84.89\% of the fully-supervised performance upper bound in cross-dataset evaluations and exhibits superior generalization capabilities. The code is available at https://github.com/Dmygithub/AdaptOVCD.

</details>


### [39] [NECromancer: Breathing Life into Skeletons via BVH Animation](https://arxiv.org/abs/2602.06548)
*Mingxi Xu,Qi Wang,Zhengyu Wen,Phong Dao Thien,Zhengyu Li,Ning Zhang,Xiaoyu He,Wei Zhao,Kehong Gong,Mingyuan Zhang*

Main category: cs.CV

TL;DR: NECromancer (NEC) 是一个通用的运动分词器，可直接处理任意BVH骨架，通过三个组件实现：(1) 基于本体的骨骼图编码器（OwO）提取关节语义、静止位姿偏移和拓扑结构等先验信息；(2) 无拓扑依赖的分词器（TAT）生成拓扑不变的离散运动表示；(3) 统一BVH宇宙数据集（UvU）整合异构骨架的运动数据。实验表明，NEC在高压缩比下仍能高保真重建运动，并成功解耦运动与骨骼结构，支持跨物种运动迁移、组合、去噪、基于标记的生成及文本-运动检索，建立了一个统一的多形态运动分析与合成框架。


<details>
  <summary>Details</summary>
Motivation: 现有运动模型大多局限于特定物种的骨骼结构，难以泛化到不同形态的生物，限制了其在多样化形态中的应用。因此，亟需一种能够处理任意骨架结构的通用运动分词方法。

Method: 提出NECromancer系统，包含三个核心模块：OwO编码器用于从BVH文件中提取结构先验并生成骨骼嵌入；TAT分词器将运动序列压缩为拓扑无关的离散表示；UvU数据集则汇聚了来自多种骨架的大量运动数据以支持训练与评估。

Result: NEC在高压缩率下实现了高质量运动重建，有效分离了运动与骨骼结构，支持跨物种运动迁移、组合、去噪、基于标记的生成以及文本-运动检索等多种任务，验证了其在多形态运动建模中的通用性与有效性。

Conclusion: NECromancer构建了一个统一的运动分析与合成框架，使运动模型能够跨越物种和骨骼结构差异进行泛化，为复杂生物运动的建模提供了新范式。

Abstract: Motion tokenization is a key component of generalizable motion models, yet most existing approaches are restricted to species-specific skeletons, limiting their applicability across diverse morphologies. We propose NECromancer (NEC), a universal motion tokenizer that operates directly on arbitrary BVH skeletons. NEC consists of three components: (1) an Ontology-aware Skeletal Graph Encoder (OwO) that encodes structural priors from BVH files, including joint semantics, rest-pose offsets, and skeletal topology, into skeletal embeddings; (2) a Topology-Agnostic Tokenizer (TAT) that compresses motion sequences into a universal, topology-invariant discrete representation; and (3) the Unified BVH Universe (UvU), a large-scale dataset aggregating BVH motions across heterogeneous skeletons. Experiments show that NEC achieves high-fidelity reconstruction under substantial compression and effectively disentangles motion from skeletal structure. The resulting token space supports cross-species motion transfer, composition, denoising, generation with token-based models, and text-motion retrieval, establishing a unified framework for motion analysis and synthesis across diverse morphologies. Demo page: https://animotionlab.github.io/NECromancer/

</details>


### [40] [LIBERO-X: Robustness Litmus for Vision-Language-Action Models](https://arxiv.org/abs/2602.06556)
*Guodong Wang,Chenkai Zhang,Qingjie Liu,Jinjin Zhang,Jiancheng Cai,Junjie Liu,Xinmin Liu*

Main category: cs.CV

TL;DR: 本文提出LIBERO-X基准，通过分层评估协议和高多样性训练数据，系统性改进视觉-语言-动作（VLA）模型的评测方式。该基准包含渐进式难度层级，聚焦空间泛化、物体识别和任务指令理解三大核心能力，支持细粒度分析性能退化；同时采用人类远程操作收集的数据，增强场景多样性与任务细粒度，缩小训练与评估分布差距。实验表明，现有VLA模型在累积扰动下表现显著下降，暴露其在场景理解与指令对齐方面的局限。


<details>
  <summary>Details</summary>
Motivation: 现有VLA基准评估协议不足，难以真实反映模型在现实世界分布变化下的泛化能力、鲁棒性和感知-语言-动作对齐水平，导致评估结果有限或误导。

Method: 提出分层评估协议（逐步增加环境与任务复杂性），结合人类远程操作采集的高多样性训练数据集，实现更贴近真实场景的评估与训练分布匹配。

Result: 代表性VLA模型在累积扰动下出现显著性能下降，暴露出在场景理解与指令接地方面的持续缺陷；所提方法为评估与推进VLA发展提供了更可靠的基准。

Conclusion: 通过整合分层评估与多样化数据，LIBERO-X为VLA模型的可靠评测与进步提供了坚实基础，有助于推动模型在真实复杂环境中的能力提升。

Abstract: Reliable benchmarking is critical for advancing Vision-Language-Action (VLA) models, as it reveals their generalization, robustness, and alignment of perception with language-driven manipulation tasks. However, existing benchmarks often provide limited or misleading assessments due to insufficient evaluation protocols that inadequately capture real-world distribution shifts. This work systematically rethinks VLA benchmarking from both evaluation and data perspectives, introducing LIBERO-X, a benchmark featuring: 1) A hierarchical evaluation protocol with progressive difficulty levels targeting three core capabilities: spatial generalization, object recognition, and task instruction understanding. This design enables fine-grained analysis of performance degradation under increasing environmental and task complexity; 2) A high-diversity training dataset collected via human teleoperation, where each scene supports multiple fine-grained manipulation objectives to bridge the train-evaluation distribution gap. Experiments with representative VLA models reveal significant performance drops under cumulative perturbations, exposing persistent limitations in scene comprehension and instruction grounding. By integrating hierarchical evaluation with diverse training data, LIBERO-X offers a more reliable foundation for assessing and advancing VLA development.

</details>


### [41] [SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs](https://arxiv.org/abs/2602.06566)
*Niccolo Avogaro,Nayanika Debnath,Li Mi,Thomas Frick,Junling Wang,Zexue He,Hang Hua,Konrad Schindler,Mattia Rigotti*

Main category: cs.CV

TL;DR: SPARC提出一种分离视觉感知与推理的模块化框架，通过两阶段流程（先定位问题相关区域，再基于这些区域进行推理）实现更高效、鲁棒的视觉语言模型推理。该方法支持测试时动态扩展、选择性优化和压缩上下文，显著提升性能并大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在测试时扩展（test-time scaling）中因感知与推理混杂导致推理过程混乱且易受感知错误影响，同时依赖昂贵的强化学习训练，因此需要一种更结构化、可分离的推理机制。

Method: SPARC采用两阶段设计：第一阶段为显式视觉搜索，定位与问题相关的图像区域；第二阶段基于这些区域进行条件推理，生成最终答案。该设计模仿大脑的感官到认知处理流程，实现感知与推理的解耦。

Result: SPARC在多个复杂视觉推理基准上超越了传统单体模型和强视觉对齐方法。例如，在V* VQA基准上，其使Qwen3VL-4B准确率提升6.7个百分点；在一项挑战性的分布外任务中，相比“思考图像”方法提升4.6个百分点，且仅需200倍更低的令牌预算。

Conclusion: SPARC通过分离感知与推理，实现了更高效、可扩展、可优化的视觉语言模型推理，为未来高鲁棒性多模态系统提供了新范式。

Abstract: Despite recent successes, test-time scaling - i.e., dynamically expanding the token budget during inference as needed - remains brittle for vision-language models (VLMs): unstructured chains-of-thought about images entangle perception and reasoning, leading to long, disorganized contexts where small perceptual mistakes may cascade into completely wrong answers. Moreover, expensive reinforcement learning with hand-crafted rewards is required to achieve good performance. Here, we introduce SPARC (Separating Perception And Reasoning Circuits), a modular framework that explicitly decouples visual perception from reasoning. Inspired by sequential sensory-to-cognitive processing in the brain, SPARC implements a two-stage pipeline where the model first performs explicit visual search to localize question-relevant regions, then conditions its reasoning on those regions to produce the final answer. This separation enables independent test-time scaling with asymmetric compute allocation (e.g., prioritizing perceptual processing under distribution shift), supports selective optimization (e.g., improving the perceptual stage alone when it is the bottleneck for end-to-end performance), and accommodates compressed contexts by running global search at lower image resolutions and allocating high-resolution processing only to selected regions, thereby reducing total visual tokens count and compute. Across challenging visual reasoning benchmarks, SPARC outperforms monolithic baselines and strong visual-grounding approaches. For instance, SPARC improves the accuracy of Qwen3VL-4B on the $V^*$ VQA benchmark by 6.7 percentage points, and it surpasses "thinking with images" by 4.6 points on a challenging OOD task despite requiring a 200$\times$ lower token budget.

</details>


### [42] [An Integer Linear Programming Approach to Geometrically Consistent Partial-Partial Shape Matching](https://arxiv.org/abs/2602.06590)
*Viktoria Ehm,Paul Roetzer,Florian Bernard,Daniel Cremers*

Main category: cs.CV

TL;DR: 本文提出了一种针对部分-部分3D形状匹配的首个整数线性规划方法，利用几何一致性作为强先验，同时实现重叠区域的鲁棒估计和保持邻域结构的对应关系计算。实验表明该方法在匹配误差和光滑性方面表现优异，且比以往方法更具可扩展性。


<details>
  <summary>Details</summary>
Motivation: 部分-部分3D形状匹配是更贴近真实场景（如3D扫描）的任务，但因其需同时确定未知重叠区域并计算精确对应关系而极具挑战性，现有研究较少。

Method: 提出一种专门设计的整数线性规划方法，利用几何一致性作为先验，联合优化重叠区域估计与对应关系计算。

Result: 所提方法在匹配误差和对应平滑性上均取得高质量结果，且在可扩展性方面优于先前形式化方法。

Conclusion: 该工作首次为部分-部分3D形状匹配提供了有效且可扩展的整数线性规划解决方案，显著提升了匹配性能与实用性。

Abstract: The task of establishing correspondences between two 3D shapes is a long-standing challenge in computer vision. While numerous studies address full-full and partial-full 3D shape matching, only a limited number of works have explored the partial-partial setting, very likely due to its unique challenges: we must compute accurate correspondences while at the same time find the unknown overlapping region. Nevertheless, partial-partial 3D shape matching reflects the most realistic setting, as in many real-world cases, such as 3D scanning, shapes are only partially observable. In this work, we introduce the first integer linear programming approach specifically designed to address the distinctive challenges of partial-partial shape matching. Our method leverages geometric consistency as a strong prior, enabling both robust estimation of the overlapping region and computation of neighbourhood-preserving correspondences. We empirically demonstrate that our approach achieves high-quality matching results both in terms of matching error and smoothness. Moreover, we show that our method is more scalable than previous formalisms.

</details>


### [43] [DAVE: Distribution-aware Attribution via ViT Gradient Decomposition](https://arxiv.org/abs/2602.06613)
*Adam Wróbel,Siddhartha Gairola,Jacek Tabor,Bernt Schiele,Bartosz Zieliński,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: DAVE 是一种针对视觉变压器（ViT）的新型归因方法，通过输入梯度的结构化分解，有效分离了模型架构引入的结构化伪影，从而生成更稳定、高分辨率的像素级解释。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成视觉变压器（ViT）的像素级归因图时面临挑战，主要由于其架构组件（如图像块嵌入和注意力路由）引入了结构化伪影，导致大多数方法只能依赖粗粒度的块级归因。

Method: DAVE 通过数学上严谨的输入梯度结构化分解，利用 ViT 的架构特性，识别并分离出局部等变且稳定的输入-输出映射成分，同时剔除由架构引起的伪影和其他不稳定性来源。

Result: DAVE 能够生成更稳定、更高分辨率的归因图，显著减少由模型架构带来的伪影，提升归因结果的可解释性和准确性。

Conclusion: DAVE 为视觉变压器提供了可靠且精细的归因机制，克服了传统方法在高分辨率解释上的局限性，是迈向可信赖视觉 AI 解释的重要一步。

Abstract: Vision Transformers (ViTs) have become a dominant architecture in computer vision, yet producing stable and high-resolution attribution maps for these models remains challenging. Architectural components such as patch embeddings and attention routing often introduce structured artifacts in pixel-level explanations, causing many existing methods to rely on coarse patch-level attributions. We introduce DAVE \textit{(\underline{D}istribution-aware \underline{A}ttribution via \underline{V}iT Gradient D\underline{E}composition)}, a mathematically grounded attribution method for ViTs based on a structured decomposition of the input gradient. By exploiting architectural properties of ViTs, DAVE isolates locally equivariant and stable components of the effective input--output mapping. It separates these from architecture-induced artifacts and other sources of instability.

</details>


### [44] [CauCLIP: Bridging the Sim-to-Real Gap in Surgical Video Understanding via Causality-Inspired Vision-Language Modeling](https://arxiv.org/abs/2602.06619)
*Yuxin He,An Li,Cheng Xue*

Main category: cs.CV

TL;DR: 提出CauCLIP框架，结合因果推理与视觉-语言模型，通过频率增强和因果抑制损失，在无目标域数据情况下实现跨域手术阶段识别，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决手术阶段识别中因临床视频标注数据有限及合成与真实数据间存在巨大领域差异导致的模型训练难题。

Method: 采用基于频率的增强策略扰动领域特异性属性，同时保留语义结构；引入因果抑制损失以消除非因果偏差，强化因果手术特征；构建统一训练框架使模型聚焦于稳定因果因素。

Result: 在SurgVisDom硬适应基准测试中，所提方法显著优于所有对比方法，验证了因果引导的视觉-语言模型在跨域手术视频理解中的有效性。

Conclusion: CauCLIP通过因果启发式设计实现了对域不变表示的学习，在缺乏目标域数据的情况下仍能有效提升手术阶段识别的泛化能力。

Abstract: Surgical phase recognition is a critical component for context-aware decision support in intelligent operating rooms, yet training robust models is hindered by limited annotated clinical videos and large domain gaps between synthetic and real surgical data. To address this, we propose CauCLIP, a causality-inspired vision-language framework that leverages CLIP to learn domain-invariant representations for surgical phase recognition without access to target domain data. Our approach integrates a frequency-based augmentation strategy to perturb domain-specific attributes while preserving semantic structures, and a causal suppression loss that mitigates non-causal biases and reinforces causal surgical features. These components are combined in a unified training framework that enables the model to focus on stable causal factors underlying surgical workflows. Experiments on the SurgVisDom hard adaptation benchmark demonstrate that our method substantially outperforms all competing approaches, highlighting the effectiveness of causality-guided vision-language models for domain-generalizable surgical video understanding.

</details>


### [45] [PlanViz: Evaluating Planning-Oriented Image Generation and Editing for Computer-Use Tasks](https://arxiv.org/abs/2602.06663)
*Junxian Li,Kai Liu,Leyang Chen,Weida Wang,Zhixin Wang,Jiaqi Xu,Fan Li,Renjing Pei,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出了PlanViz，一个用于评估统一多模态模型（UMMs）在计算机使用任务中图像生成与编辑能力的新基准。该基准聚焦于日常生活中常见的需要规划步骤的子任务，包括路线规划、工作图示和网页/用户界面展示。为确保数据质量，采用了人工标注的问题和参考图像，并实施了质量控制流程；针对全面且精确的评估挑战，提出了任务自适应评分指标PlanScore，以衡量生成图像的正确性、视觉质量和效率。实验揭示了当前模型的关键局限与未来研究机遇。


<details>
  <summary>Details</summary>
Motivation: 尽管统一多模态模型在图像生成和多模态推理方面表现出色，但在支持与日常生活密切相关的计算机使用规划任务方面的潜力尚未被充分探索。这些任务要求具备空间推理和过程理解能力，而现有模型是否具备此类能力尚不明确，因此亟需一个专门的评估基准来检验其性能。

Method: 提出PlanViz基准，涵盖三个典型计算机使用任务子任务：路线规划、工作图示和网页/用户界面展示；通过人工标注问题和参考图像保证数据质量；设计任务自适应评分体系PlanScore，实现对生成结果的多维度评估。

Result: 实验表明，当前统一多模态模型在复杂规划任务中仍存在显著局限，尤其在空间一致性与逻辑连贯性方面表现不佳；同时揭示了提升模型规划能力的若干潜在方向，为未来研究提供了重要启示。

Conclusion: PlanViz为评估多模态模型在真实世界计算机使用任务中的图像生成与编辑能力提供了有效工具，有助于推动模型向更深层次的规划与理解能力发展。

Abstract: Unified multimodal models (UMMs) have shown impressive capabilities in generating natural images and supporting multimodal reasoning. However, their potential in supporting computer-use planning tasks, which are closely related to our lives, remain underexplored. Image generation and editing in computer-use tasks require capabilities like spatial reasoning and procedural understanding, and it is still unknown whether UMMs have these capabilities to finish these tasks or not. Therefore, we propose PlanViz, a new benchmark designed to evaluate image generation and editing for computer-use tasks. To achieve the goal of our evaluation, we focus on sub-tasks which frequently involve in daily life and require planning steps. Specifically, three new sub-tasks are designed: route planning, work diagramming, and web&UI displaying. We address challenges in data quality ensuring by curating human-annotated questions and reference images, and a quality control process. For challenges of comprehensive and exact evaluation, a task-adaptive score, PlanScore, is proposed. The score helps understanding the correctness, visual quality and efficiency of generated images. Through experiments, we highlight key limitations and opportunities for future research on this topic.

</details>


### [46] [CytoCrowd: A Multi-Annotator Benchmark Dataset for Cytology Image Analysis](https://arxiv.org/abs/2602.06674)
*Yonghao Si,Xingyuan Zeng,Zhao Chen,Libin Zheng,Caleb Chen Cao,Lei Chen,Jian Yin*

Main category: cs.CV

TL;DR: CytoCrowd 是一个用于细胞学分析的新公共基准数据集，包含446张高分辨率图像，每张图像均有四位独立病理科医生的原始冲突标注和一位资深专家建立的高质量金标准。该数据集既可用于标准计算机视觉任务（如目标检测和分类），也可用于评估解决专家分歧的标注聚合算法。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像数据集通常只提供单一干净的金标准，掩盖了真实世界中的专家分歧；或提供多个标注但缺乏独立的金标准进行客观评估。为填补这一空白，提出CytoCrowd以同时支持标准任务与真实专家分歧的评估。

Method: 收集446张高分辨率细胞学图像，由四位独立病理科医生进行标注，形成原始冲突标注；再由资深专家生成独立的高质量金标准。利用该结构，开展对象检测、分类及标注聚合算法的基准测试。

Result: 实验表明CytoCrowd具有挑战性，能够有效评估模型在真实专家分歧情境下的性能，验证了其作为下一代医学图像分析模型开发资源的价值。

Conclusion: CytoCrowd 通过结合多专家冲突标注与独立金标准，成功构建了一个兼具现实性和可评估性的医学图像分析基准，推动了更鲁棒、更贴近临床实际的模型发展。

Abstract: High-quality annotated datasets are crucial for advancing machine learning in medical image analysis. However, a critical gap exists: most datasets either offer a single, clean ground truth, which hides real-world expert disagreement, or they provide multiple annotations without a separate gold standard for objective evaluation. To bridge this gap, we introduce CytoCrowd, a new public benchmark for cytology analysis. The dataset features 446 high-resolution images, each with two key components: (1) raw, conflicting annotations from four independent pathologists, and (2) a separate, high-quality gold-standard ground truth established by a senior expert. This dual structure makes CytoCrowd a versatile resource. It serves as a benchmark for standard computer vision tasks, such as object detection and classification, using the ground truth. Simultaneously, it provides a realistic testbed for evaluating annotation aggregation algorithms that must resolve expert disagreements. We provide comprehensive baseline results for both tasks. Our experiments demonstrate the challenges presented by CytoCrowd and establish its value as a resource for developing the next generation of models for medical image analysis.

</details>


### [47] [Can We Build a Monolithic Model for Fake Image Detection? SICA: Semantic-Induced Constrained Adaptation for Unified-Yet-Discriminative Artifact Feature Space Reconstruction](https://arxiv.org/abs/2602.06676)
*Bo Du,Xiaochen Ma,Xuekang Zhu,Zhe Yang,Chaogun Niu,Jian Liu,Ji-Zhe Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为SICA的新型单体式假图像检测（FID）框架，旨在解决跨多个图像取证子域的统一检测难题。研究发现，不同子域间伪造痕迹存在‘异质性’，导致现有单体模型性能不佳，其根本原因是伪造特征空间的坍塌。为此，作者提出利用高层语义作为结构先验来重建‘统一且可区分’的特征空间，并通过SICA实现近正交的特征重构，显著优于15种现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有单体式假图像检测模型在实际应用中表现不佳，尽管理论上更具潜力；其核心问题在于不同子域间伪造痕迹的异质性导致特征空间坍塌，亟需一种能够同时保持统一性和区分性的解决方案。

Method: 提出Semantic-Induced Constrained Adaptation（SICA）框架，利用高层语义作为结构先验，约束并引导伪造特征空间的重建，实现‘统一且可区分’的特征表示。

Result: 在OpenMMSec数据集上的实验表明，SICA显著超越15种先进方法，成功实现了近正交的统一-区分特征空间重建，验证了其有效性。

Conclusion: SICA是首个有效的单体式假图像检测范式，通过引入高层语义先验有效解决了异质性带来的特征空间坍塌问题，为统一化图像伪造检测提供了新思路。

Abstract: Fake Image Detection (FID), aiming at unified detection across four image forensic subdomains, is critical in real-world forensic scenarios. Compared with ensemble approaches, monolithic FID models are theoretically more promising, but to date, consistently yield inferior performance in practice. In this work, by discovering the ``heterogeneous phenomenon'', which is the intrinsic distinctness of artifacts across subdomains, we diagnose the cause of this underperformance for the first time: the collapse of the artifact feature space driven by such phenomenon. The core challenge for developing a practical monolithic FID model thus boils down to the ``unified-yet-discriminative" reconstruction of the artifact feature space. To address this paradoxical challenge, we hypothesize that high-level semantics can serve as a structural prior for the reconstruction, and further propose Semantic-Induced Constrained Adaptation (SICA), the first monolithic FID paradigm. Extensive experiments on our OpenMMSec dataset demonstrate that SICA outperforms 15 state-of-the-art methods and reconstructs the target unified-yet-discriminative artifact feature space in a near-orthogonal manner, thus firmly validating our hypothesis. The code and dataset are available at:https: //github.com/scu-zjz/SICA_OpenMMSec.

</details>


### [48] [Clinical-Prior Guided Multi-Modal Learning with Latent Attention Pooling for Gait-Based Scoliosis Screening](https://arxiv.org/abs/2602.06743)
*Dong Chen,Zizhuang Wei,Jialei Xu,Xinyang Sun,Zonglin He,Meiru An,Huili Peng,Yong Hu,Kenneth MC Cheung*

Main category: cs.CV

TL;DR: 提出ScoliGait数据集和多模态框架，结合临床先验知识与注意力机制，实现可解释的青少年特发性脊柱侧弯非侵入式评估，显著提升性能并解决数据泄露问题。


<details>
  <summary>Details</summary>
Motivation: 现有筛查方法主观性强、难以规模化，视频步态分析虽有潜力但受限于数据泄露和模型可解释性差的问题。

Method: 构建ScoliGait数据集，设计融合临床先验知识图谱与潜空间注意力池化的多模态框架，实现视频、文本与知识图谱的联合建模。

Result: 在独立受试者测试集上达到新基准性能，显著优于现有方法，且具备临床可解释性。

Conclusion: 该研究为可扩展、非侵入式的AIS评估提供了可靠、可解释且临床基础坚实的解决方案。

Abstract: Adolescent Idiopathic Scoliosis (AIS) is a prevalent spinal deformity whose progression can be mitigated through early detection. Conventional screening methods are often subjective, difficult to scale, and reliant on specialized clinical expertise. Video-based gait analysis offers a promising alternative, but current datasets and methods frequently suffer from data leakage, where performance is inflated by repeated clips from the same individual, or employ oversimplified models that lack clinical interpretability. To address these limitations, we introduce ScoliGait, a new benchmark dataset comprising 1,572 gait video clips for training and 300 fully independent clips for testing. Each clip is annotated with radiographic Cobb angles and descriptive text based on clinical kinematic priors. We propose a multi-modal framework that integrates a clinical-prior-guided kinematic knowledge map for interpretable feature representation, alongside a latent attention pooling mechanism to fuse video, text, and knowledge map modalities. Our method establishes a new state-of-the-art, demonstrating a significant performance gap on a realistic, non-repeating subject benchmark. Our approach establishes a new state of the art, showing a significant performance gain on a realistic, subject-independent benchmark. This work provides a robust, interpretable, and clinically grounded foundation for scalable, non-invasive AIS assessment.

</details>


### [49] [Gold Exploration using Representations from a Multispectral Autoencoder](https://arxiv.org/abs/2602.06748)
*Argyro Tsandalidou,Konstantinos Dogeas,Eleftheria Tetoula Tsonga,Elisavet Parselia,Georgios Tsimiklis,George Arvanitakis*

Main category: cs.CV

TL;DR: 本研究提出一种基于生成式表示的金矿成因区域识别框架，利用Sentinel-2多光谱影像和预训练的Isometric自编码器模型提取信息密集的光谱-空间特征，并结合轻量级XGBoost分类器，在有限标注数据下显著提升预测准确率。


<details>
  <summary>Details</summary>
Motivation: 传统矿物勘探依赖实地数据，成本高且覆盖有限；卫星影像虽具潜力，但如何高效提取可迁移的矿物学特征仍具挑战。本研究旨在探索利用生成式基础模型从遥感影像中学习通用表征，以支持大规模、低成本的矿产潜力制图。

Method: 采用预训练于FalconSpace-S2 v1.0数据集的Isometric自编码器模型，从多光谱影像中提取光谱-空间嵌入表示，作为XGBoost分类器的输入，实现对金矿与非金矿区域的识别。

Result: 在63张已知金矿与非金矿位置的Sentinel-2图像上测试，该方法将像素级准确率从0.51提升至0.68，图像级准确率从0.55提升至0.73，验证了生成式嵌入在小样本条件下捕捉可迁移矿物学模式的能力。

Conclusion: 基于基础模型的生成式表征能够有效支持矿产勘探，使探测过程更高效、可扩展且适用于全球范围，为未来大规模矿产资源评估提供了新范式。

Abstract: Satellite imagery is employed for large-scale prospectivity mapping due to the high cost and typically limited availability of on-site mineral exploration data. In this work, we present a proof-of-concept framework that leverages generative representations learned from multispectral Sentinel-2 imagery to identify gold-bearing regions from space. An autoencoder foundation model, called Isometric, which is pretrained on the large-scale FalconSpace-S2 v1.0 dataset, produces information-dense spectral-spatial representations that serve as inputs to a lightweight XGBoost classifier. We compare this representation-based approach with a raw spectral input baseline using a dataset of 63 Sentinel-2 images from known gold and non-gold locations. The proposed method improves patch-level accuracy from 0.51 to 0.68 and image-level accuracy from 0.55 to 0.73, demonstrating that generative embeddings capture transferable mineralogical patterns even with limited labeled data. These results highlight the potential of foundation-model representations to make mineral exploration more efficient, scalable, and globally applicable.

</details>


### [50] [Revisiting Emotions Representation for Recognition in the Wild](https://arxiv.org/abs/2602.06778)
*Joao Baptista Cardia Neto,Claudio Ferrari,Stefano Berretti*

Main category: cs.CV

TL;DR: 本文提出一种新方法，将复杂情感状态描述为情绪类别上的概率分布，通过利用已有研究中基本与复合情绪在效价-唤醒-支配（VAD）空间中的映射关系，自动重标注现有数据集，从而实现对情感的混合描述，更好地反映情感感知的模糊性。实验初步验证了该方法的优势，并指出了新的研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统面部情绪识别通常被视为单一标签分类问题，但这种简化无法准确描述自发情绪状态的多维度特性，因为真实情绪往往是多种情绪的组合。现有基于分布学习的方法受限于数据集仅标注单一情绪类别的问题，因此需要一种更灵活的标注方式来捕捉情绪的复杂性。

Method: 利用先前研究中大量基本和复合情绪在VAD空间中的概率分布映射，对已有数据集进行自动重标注；给定一张带有VAD值的脸部图像，计算其属于各个情绪分布的概率，从而将情绪状态表示为多个情绪的混合分布。

Result: 实验表明，该方法能够更丰富地描述情绪状态，提升对复杂情感的表达能力，并为未来研究提供新方向。数据标注已公开于GitHub。

Conclusion: 本文提出的基于概率分布的重标注方法，为面部情绪识别提供了更符合真实情感复杂性的建模方式，有助于推动情绪识别向更精细、更自然的方向发展。

Abstract: Facial emotion recognition has been typically cast as a single-label classification problem of one out of six prototypical emotions. However, that is an oversimplification that is unsuitable for representing the multifaceted spectrum of spontaneous emotional states, which are most often the result of a combination of multiple emotions contributing at different intensities. Building on this, a promising direction that was explored recently is to cast emotion recognition as a distribution learning problem. Still, such approaches are limited in that research datasets are typically annotated with a single emotion class. In this paper, we contribute a novel approach to describe complex emotional states as probability distributions over a set of emotion classes. To do so, we propose a solution to automatically re-label existing datasets by exploiting the result of a study in which a large set of both basic and compound emotions is mapped to probability distributions in the Valence-Arousal-Dominance (VAD) space. In this way, given a face image annotated with VAD values, we can estimate the likelihood of it belonging to each of the distributions, so that emotional states can be described as a mixture of emotions, enriching their description, while also accounting for the ambiguous nature of their perception. In a preliminary set of experiments, we illustrate the advantages of this solution and a new possible direction of investigation. Data annotations are available at https://github.com/jbcnrlz/affectnet-b-annotation.

</details>


### [51] [Machine Learning for Detection and Severity Estimation of Sweetpotato Weevil Damage in Field and Lab Conditions](https://arxiv.org/abs/2602.06786)
*Doreen M. Chelangat,Sudi Murindanyi,Bruce Mugizi,Paul Musana,Benard Yada,Milton A. Otema,Florence Osaru,Andrew Katumba,Joyce Nakatumba-Nabende*

Main category: cs.CV

TL;DR: 本研究提出一种基于计算机视觉的甜瓜象鼻虫损伤自动评估方法，适用于田间和实验室场景。田间模型通过分类实现根部损伤严重程度预测，测试准确率达71.43%；实验室采用YOLO12结合分割与分块策略，对微小取食孔检测的平均精度达77.7%。该方法提升了表型分析效率，助力培育抗虫品种，增强粮食安全。


<details>
  <summary>Details</summary>
Motivation: 传统人工评分方法耗时、主观且结果不一致，制约甜薯抗虫育种进程。亟需高效、客观、可扩展的损伤评估技术以支持现代育种工作。

Method: 在田间采集数据训练分类模型，在实验室构建数据集并设计基于YOLO12的两阶段目标检测流程，包括根部分割与分块策略以提升小目标检测能力。

Result: 田间模型测试准确率为71.43%；实验室模型对微小取食孔的平均精度达77.7%，表明计算机视觉技术可实现高效、客观、可扩展的损伤评估。

Conclusion: 计算机视觉技术为甜薯象鼻虫损伤评估提供了高效、客观、可扩展的新工具，显著提升育种表型效率，有助于缓解害虫对粮食安全的威胁。

Abstract: Sweetpotato weevils (Cylas spp.) are considered among the most destructive pests impacting sweetpotato production, particularly in sub-Saharan Africa. Traditional methods for assessing weevil damage, predominantly relying on manual scoring, are labour-intensive, subjective, and often yield inconsistent results. These challenges significantly hinder breeding programs aimed at developing resilient sweetpotato varieties. This study introduces a computer vision-based approach for the automated evaluation of weevil damage in both field and laboratory contexts. In the field settings, we collected data to train classification models to predict root-damage severity levels, achieving a test accuracy of 71.43%. Additionally, we established a laboratory dataset and designed an object detection pipeline employing YOLO12, a leading real-time detection model. This methodology incorporated a two-stage laboratory pipeline that combined root segmentation with a tiling strategy to improve the detectability of small objects. The resulting model demonstrated a mean average precision of 77.7% in identifying minute weevil feeding holes. Our findings indicate that computer vision technologies can provide efficient, objective, and scalable assessment tools that align seamlessly with contemporary breeding workflows. These advancements represent a significant improvement in enhancing phenotyping efficiency within sweetpotato breeding programs and play a crucial role in mitigating the detrimental effects of weevils on food security.

</details>


### [52] [A Unified Formula for Affine Transformations between Calibrated Cameras](https://arxiv.org/abs/2602.06805)
*Levente Hajder*

Main category: cs.CV

TL;DR: 本文推导了两个校准视图之间局部图像块的仿射变换的闭式表达式，表明该变换依赖于相对相机位姿、图像坐标和局部表面法向量。


<details>
  <summary>Details</summary>
Motivation: 为了在立体视觉中准确建模局部图像块在不同视角间的变换关系，需要一种精确且可计算的表达方式来描述其仿射变换。

Method: 通过几何分析和矩阵推导，结合相机姿态、图像坐标和表面法向量，建立仿射变换的数学模型并求解闭式表达式。

Result: 得到了一个明确的闭式表达式，能够直接计算任意局部图像块在两个校准视图之间的仿射变换。

Conclusion: 所提出的闭式表达式为立体匹配和三维重建提供了理论基础，具有良好的计算效率和精度。

Abstract: In this technical note, we derive a closed-form expression for the affine transformation mapping local image patches between two calibrated views. We show that the transformation is a function of the relative camera pose, the image coordinates, and the local surface normal.

</details>


### [53] [RAIGen: Rare Attribute Identification in Text-to-Image Generative Models](https://arxiv.org/abs/2602.06806)
*Silpa Vadakkeeveetil Sreelatha,Dan Wang,Serge Belongie,Muhammad Awais,Anjan Dutta*

Main category: cs.CV

TL;DR: RAIGen 是首个无监督的扩散模型中罕见属性发现框架，利用马特里什卡稀疏自编码器和一种结合神经元激活频率与语义独特性的新少数群体度量，识别可解释的神经元，其最高激活图像揭示了数据分布中被低估的属性（如社会、文化或风格特征）。该方法在 Stable Diffusion 和 SDXL 中均有效，支持跨架构审计，并能实现生成过程中对罕见属性的定向增强。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型虽生成质量高，但继承并放大训练数据中的偏见，导致某些语义属性覆盖不均。已有工作主要关注封闭集（预定义公平类别）或开放集（识别主导属性）的偏见缓解，却忽略了对数据分布中罕见或少数特征的发现，这些特征虽不显著但存在于模型表示中。因此亟需一种方法来系统性识别这些被忽视的属性。

Method: RAIGen 采用马特里什卡稀疏自编码器（Matryoshka Sparse Autoencoders）提取模型内部表征，设计一种新的少数群体度量，综合考虑神经元激活频率与语义独特性，以筛选出对罕见属性敏感的可解释神经元；通过分析这些神经元的最高激活图像，揭示隐藏在模型中的稀有属性。

Result: 实验表明，RAIGen 能在 Stable Diffusion 和 SDXL 等大型模型中成功发现超出传统公平类别范畴的罕见属性，具备良好的可扩展性与跨架构兼容性，并可用于生成阶段的针对性增强，为模型审计与公平性改进提供新工具。

Conclusion: RAIGen 首次实现了扩散模型中无监督的罕见属性发现，填补了现有偏见缓解方法的空白，不仅有助于理解模型内部表征，也为构建更包容、更具表现力的生成系统提供了技术支持。

Abstract: Text-to-image diffusion models achieve impressive generation quality but inherit and amplify training-data biases, skewing coverage of semantic attributes. Prior work addresses this in two ways. Closed-set approaches mitigate biases in predefined fairness categories (e.g., gender, race), assuming socially salient minority attributes are known a priori. Open-set approaches frame the task as bias identification, highlighting majority attributes that dominate outputs. Both overlook a complementary task: uncovering rare or minority features underrepresented in the data distribution (social, cultural, or stylistic) yet still encoded in model representations. We introduce RAIGen, the first framework, to our knowledge, for un-supervised rare-attribute discovery in diffusion models. RAIGen leverages Matryoshka Sparse Autoencoders and a novel minority metric combining neuron activation frequency with semantic distinctiveness to identify interpretable neurons whose top-activating images reveal underrepresented attributes. Experiments show RAIGen discovers attributes beyond fixed fairness categories in Stable Diffusion, scales to larger models such as SDXL, supports systematic auditing across architectures, and enables targeted amplification of rare attributes during generation.

</details>


### [54] [GaussianPOP: Principled Simplification Framework for Compact 3D Gaussian Splatting via Error Quantification](https://arxiv.org/abs/2602.06830)
*Soonbin Lee,Yeong-Gyu Kim,Simon Sasse,Tomas M. Borges,Yago Sanchez,Eun-Seok Ryu,Thomas Schierl,Cornelius Hellge*

Main category: cs.CV

TL;DR: GaussianPOP提出了一种基于解析高斯误差量化的简化框架，通过直接从3DGS渲染方程推导出新的误差准则，精确衡量每个高斯对渲染图像的贡献。该方法在单次前向传播中高效计算误差，支持训练中和训练后两种简化场景，实现更优的模型紧凑性与渲染质量平衡，实验表明其优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点云简化方法多依赖重要性评分（如混合权重或敏感度），但这些评分未基于视觉误差指标，导致在紧凑性与渲染保真度之间权衡不佳。

Method: 提出一种基于3DGS渲染方程的新型误差准则，设计高效算法实现在单次前向传播中快速计算误差，并支持训练中剪枝与训练后迭代误差重量化以提升稳定性。

Result: 实验结果表明，GaussianPOP在训练中与训练后两种场景下均显著优于现有最先进剪枝方法，在模型紧凑性与渲染质量之间实现了更优平衡。

Conclusion: GaussianPOP通过解析误差量化实现了更准确、灵活的3D高斯点云简化，为高斯点云压缩提供了新范式。

Abstract: Existing 3D Gaussian Splatting simplification methods commonly use importance scores, such as blending weights or sensitivity, to identify redundant Gaussians. However, these scores are not driven by visual error metrics, often leading to suboptimal trade-offs between compactness and rendering fidelity. We present GaussianPOP, a principled simplification framework based on analytical Gaussian error quantification. Our key contribution is a novel error criterion, derived directly from the 3DGS rendering equation, that precisely measures each Gaussian's contribution to the rendered image. By introducing a highly efficient algorithm, our framework enables practical error calculation in a single forward pass. The framework is both accurate and flexible, supporting on-training pruning as well as post-training simplification via iterative error re-quantification for improved stability. Experimental results show that our method consistently outperforms existing state-of-the-art pruning methods across both application scenarios, achieving a superior trade-off between model compactness and high rendering quality.

</details>


### [55] [Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping](https://arxiv.org/abs/2602.06850)
*Chao Zhou,Tianyi Wei,Yiling Chen,Wenbo Zhou,Nenghai Yu*

Main category: cs.CV

TL;DR: 本文提出PKA框架，通过位置对齐注意力（PAA）和关键词作用域注意力（KSA）消除多条件控制中的冗余交互，结合条件敏感性感知采样（CSAS）策略，实现高效推理与训练。实验表明，PKA在推理速度上提升10.0倍，显存节省5.1倍，显著提升多条件生成的可扩展性与资源效率。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在提示生成中表现优异，但在空间布局或主体外观等细粒度控制方面存在不足。传统多条件控制方法在扩散Transformer（DiT）中受限于'拼接-注意力'策略，导致计算和内存开销随条件数量呈二次增长，且存在大量空间或语义冗余。

Method: 提出位置对齐与关键词作用域注意力（PKA）框架：其中位置对齐注意力（PAA）通过局部块对齐线性化空间控制；关键词作用域注意力（KSA）利用语义感知掩码剔除无关的主体驱动交互；同时引入条件敏感性感知采样（CSAS）策略，重加权训练目标以加速收敛并提高条件保真度。

Result: 实验验证，PKA实现10.0倍推理速度提升、5.1倍显存节省，在保持高保真度的同时显著提升多条件生成的可扩展性与资源友好性。

Conclusion: PKA通过消除跨模态冗余与优化训练机制，为扩散模型中的多条件控制提供了一种高效、可扩展且资源节约的新范式，适用于复杂用户需求下的精细图像生成。

Abstract: While modern text-to-image models excel at prompt-based generation, they often lack the fine-grained control necessary for specific user requirements like spatial layouts or subject appearances. Multi-condition control addresses this, yet its integration into Diffusion Transformers (DiTs) is bottlenecked by the conventional ``concatenate-and-attend'' strategy, which suffers from quadratic computational and memory overhead as the number of conditions scales. Our analysis reveals that much of this cross-modal interaction is spatially or semantically redundant. To this end, we propose Position-aligned and Keyword-scoped Attention (PKA), a highly efficient framework designed to eliminate these redundancies. Specifically, Position-Aligned Attention (PAA) linearizes spatial control by enforcing localized patch alignment, while Keyword-Scoped Attention (KSA) prunes irrelevant subject-driven interactions via semantic-aware masking. To facilitate efficient learning, we further introduce a Conditional Sensitivity-Aware Sampling (CSAS) strategy that reweights the training objective towards critical denoising phases, drastically accelerating convergence and enhancing conditional fidelity. Empirically, PKA delivers a 10.0$\times$ inference speedup and a 5.1$\times$ VRAM saving, providing a scalable and resource-friendly solution for high-fidelity multi-conditioned generation.

</details>


### [56] [Parameters as Experts: Adapting Vision Models with Dynamic Parameter Routing](https://arxiv.org/abs/2602.06862)
*Meng Lou,Stanley Yu,Yizhou Yu*

Main category: cs.CV

TL;DR: AdaRoute 是一种基于混合专家（MoE）架构的参数高效微调方法，通过动态路由机制生成输入相关的低秩适配矩阵，实现更定制化的特征表示。其共享专家中心设计促进跨层特征交互，提升特征多样性，在语义分割、目标检测等密集预测任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法在复杂密集预测任务中存在输入无关建模和冗余跨层表示的问题，难以达到全量微调性能。

Method: 提出 AdaRoute，采用共享专家中心与动态参数路由机制，每个模块根据输入动态生成权重矩阵，实现输入依赖的低秩适配，并通过共享结构增强跨层特征交互。

Result: 在语义分割、目标检测、实例分割和全景分割等多种视觉任务上均优于现有方法，表现出显著性能提升。

Conclusion: AdaRoute 通过动态路由与共享专家中心，实现了高效且强大的参数微调，在保持极少可训练参数的同时，显著提升了密集预测任务的性能。

Abstract: Adapting pre-trained vision models using parameter-efficient fine-tuning (PEFT) remains challenging, as it aims to achieve performance comparable to full fine-tuning using a minimal number of trainable parameters. When applied to complex dense prediction tasks, existing methods exhibit limitations, including input-agnostic modeling and redundant cross-layer representations. To this end, we propose AdaRoute, a new adapter-style method featuring a simple mixture-of-experts (MoE) architecture. Specifically, we introduce shared expert centers, where each expert is a trainable parameter matrix. During a feedforward pass, each AdaRoute module in the network dynamically generates weight matrices tailored for the current module via a simple dynamic parameter routing mechanism, which selectively aggregates parameter matrices in the corresponding expert center. Dynamic weight matrices in AdaRoute modules facilitate low-rank adaptation in an input-dependent manner, thus generating more customized and powerful feature representations. Moreover, since AdaRoute modules across multiple network layers share the same expert center, they improve feature diversity by promoting implicit cross-layer feature interaction. Extensive experiments demonstrate the superiority of AdaRoute on diverse vision tasks, including semantic segmentation, object detection and instance segmentation, and panoptic segmentation. Code will be available at: https://bit.ly/3NZcr0H.

</details>


### [57] [RFDM: Residual Flow Diffusion Model for Efficient Causal Video Editing](https://arxiv.org/abs/2602.06871)
*Mohammadreza Salehi,Mehdi Noroozi,Luca Morreale,Ruchika Chavhan,Malcolm Chadwick,Alberto Gil Ramos,Abhinav Mehrotra*

Main category: cs.CV

TL;DR: 提出一种因果、高效的视频编辑模型RFDM，通过将2D图像到图像（I2I）扩散模型扩展为视频到视频（V2V）编辑，实现对变长视频的逐帧编辑。利用时间冗余性，引入残差流扩散模型（RFDM），聚焦于连续帧间的差异进行去噪，显著提升效率。在全局/局部风格迁移和物体移除任务上，RFDM超越I2I方法并媲美3D全时空模型，同时保持与图像模型相当的计算开销且不随输入视频长度增加而增长。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法多依赖固定长度输入且计算成本高；尽管自回归视频生成具有高效处理变长视频的能力，但在视频编辑中尚未充分探索。因此需要一种高效、可扩展的变长视频编辑框架。

Method: 基于2D I2I扩散模型构建因果式视频编辑框架，通过将当前时刻t的编辑条件依赖于前一时刻t-1的预测结果实现逐帧推理；提出新的I2I扩散前向过程，使模型学习目标输出与前一预测之间的残差，即残差流扩散模型（RFDM），从而聚焦于帧间变化部分。

Result: RFDM在风格迁移和物体移除任务上表现优异，优于现有I2I方法，并接近3D V2V模型性能；仅需图像级计算资源，且计算量不随视频长度增长，具备良好的可扩展性。

Conclusion: RFDM是一种高效、可扩展的因果视频编辑模型，通过残差流机制有效利用时间冗余，在保持低计算成本的同时实现了高质量的变长视频编辑，为未来轻量化视频编辑提供了新思路。

Abstract: Instructional video editing applies edits to an input video using only text prompts, enabling intuitive natural-language control. Despite rapid progress, most methods still require fixed-length inputs and substantial compute. Meanwhile, autoregressive video generation enables efficient variable-length synthesis, yet remains under-explored for video editing. We introduce a causal, efficient video editing model that edits variable-length videos frame by frame. For efficiency, we start from a 2D image-to-image (I2I) diffusion model and adapt it to video-to-video (V2V) editing by conditioning the edit at time step t on the model's prediction at t-1. To leverage videos' temporal redundancy, we propose a new I2I diffusion forward process formulation that encourages the model to predict the residual between the target output and the previous prediction. We call this Residual Flow Diffusion Model (RFDM), which focuses the denoising process on changes between consecutive frames. Moreover, we propose a new benchmark that better ranks state-of-the-art methods for editing tasks. Trained on paired video data for global/local style transfer and object removal, RFDM surpasses I2I-based methods and competes with fully spatiotemporal (3D) V2V models, while matching the compute of image models and scaling independently of input video length. More content can be found in: https://smsd75.github.io/RFDM_page/

</details>


### [58] [NanoFLUX: Distillation-Driven Compression of Large Text-to-Image Generation Models for Mobile Devices](https://arxiv.org/abs/2602.06879)
*Ruchika Chavhan,Malcolm Chadwick,Alberto Gil Couto Pimentel Ramos,Luca Morreale,Mehdi Noroozi,Abhinav Mehrotra*

Main category: cs.CV

TL;DR: NanoFLUX 是一个 2.4B 参数的文本到图像流匹配模型，通过从 17B 的 FLUX.1-Schnell 模型中进行渐进式压缩，实现了在移动设备上高质量的文本到图像生成。其核心贡献包括：（1）基于剪枝的模型压缩策略，将扩散变压器大小从 12B 减少到 2B；（2）基于 ResNet 的令牌下采样机制，降低延迟同时保持高分辨率处理；（3）利用去噪器早期层视觉信号进行文本编码器蒸馏的新方法。实验表明，NanoFLUX 在移动端可实现约 2.5 秒生成 512×512 图像，验证了高质量端到端生成的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模文本到图像扩散模型在视觉质量上的提升，其日益增长的规模导致顶尖模型与设备端解决方案之间的差距扩大。为弥合这一差距，需要开发更轻量、高效且保持高质量生成能力的模型，以实现在移动设备等资源受限环境下的部署。

Method: 采用渐进式压缩管道，包括：（1）对扩散变压器中的冗余组件进行剪枝，显著减小模型规模；（2）引入基于 ResNet 的令牌下采样机制，使中间块在低分辨率令牌上运行，从而降低计算开销；（3）提出一种新颖的文本编码器蒸馏方法，利用去噪器早期层的视觉信号增强文本表示学习。

Result: NanoFLUX 在移动设备上可在约 2.5 秒内生成 512×512 分辨率的图像，保持了与原始大模型相当的生成质量，证明了其在资源受限设备上实现高质量文本到图像生成的可行性。

Conclusion: NanoFLUX 成功实现了大规模文本到图像模型的高效压缩，在保证生成质量的前提下显著降低了模型规模和推理延迟，为在移动设备等边缘设备上部署高质量生成模型提供了可行路径。

Abstract: While large-scale text-to-image diffusion models continue to improve in visual quality, their increasing scale has widened the gap between state-of-the-art models and on-device solutions. To address this gap, we introduce NanoFLUX, a 2.4B text-to-image flow-matching model distilled from 17B FLUX.1-Schnell using a progressive compression pipeline designed to preserve generation quality. Our contributions include: (1) A model compression strategy driven by pruning redundant components in the diffusion transformer, reducing its size from 12B to 2B; (2) A ResNet-based token downsampling mechanism that reduces latency by allowing intermediate blocks to operate on lower-resolution tokens while preserving high-resolution processing elsewhere; (3) A novel text encoder distillation approach that leverages visual signals from early layers of the denoiser during sampling. Empirically, NanoFLUX generates 512 x 512 images in approximately 2.5 seconds on mobile devices, demonstrating the feasibility of high-quality on-device text-to-image generation.

</details>


### [59] [PANC: Prior-Aware Normalized Cut for Object Segmentation](https://arxiv.org/abs/2602.06912)
*Juan Gutiérrez,Victor Gutiérrez-Garcia,José Luis Blanco-Murillo*

Main category: cs.CV

TL;DR: 提出PANC框架，通过少量标注视觉标记（5-30个/数据集）实现稳定、可控且可复现的弱监督谱分割，利用锚点节点增强令牌-令牌关联图，调整谱空间以匹配标注信息，在无需训练的情况下达到弱监督与无监督方法中的领先性能，尤其在密集标签成本高或类内差异细微的场景表现突出，如CrackForest、CUB-200-2011和HAM10000上分别取得96.8%、78.0%和78.8%的mIoU，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有完全无监督分割方法常因初始化、种子顺序和阈值启发式敏感而产生非确定性分割结果；为提升分割的稳定性、可重复性和用户控制能力，需引入少量标注信息以引导分割过程。

Method: 基于TokenCut方法，构建包含少量先验信息的锚点节点，增强令牌-令牌亲和图，通过调节图拓扑结构，使谱空间偏向与标注一致的分割结果，从而在不依赖训练的前提下实现高质量、可控的分割。

Result: 在标准基准（如DUTS-TE、ECSSD、MS COCO）上达到弱监督与无监督方法的最先进水平；在精细分类、纹理有限及同质域中表现尤为出色，如CrackForest、CUB-200-2011、HAM10000上分别获得96.8%（+14.43%）、78.0%（+0.2%）、78.8%（+0.37%）的平均mIoU，且支持多对象场景下的显式语义分割。

Conclusion: PANC通过引入极少量标注信息，有效提升了无监督分割的稳定性、可重复性与用户控制能力，同时保持了全局分组特性，适用于标注成本高或类别间差异微小的复杂场景，是当前弱监督与无监督分割领域的先进解决方案。

Abstract: Fully unsupervised segmentation pipelines naively seek the most salient object, should this be present. As a result, most of the methods reported in the literature deliver non-deterministic partitions that are sensitive to initialization, seed order, and threshold heuristics.
  We propose PANC, a weakly supervised spectral segmentation framework that uses a minimal set of annotated visual tokens to produce stable, controllable, and reproducible object masks. From the TokenCut approach, we augment the token-token affinity graph with a handful of priors coupled to anchor nodes. By manipulating the graph topology, we bias the spectral eigenspace toward partitions that are consistent with the annotations. Our approach preserves the global grouping enforced by dense self-supervised visual features, trading annotated tokens for significant gains in reproducibility, user control, and segmentation quality.
  Using 5 to 30 annotations per dataset, our training-free method achieves state-of-the-art performance among weakly and unsupervised approaches on standard benchmarks (e.g., DUTS-TE, ECSSD, MS COCO). Contrarily, it excels in domains where dense labels are costly or intra-class differences are subtle. We report strong and reliable results on homogeneous, fine-grained, and texture-limited domains, achieving 96.8% (+14.43% over SotA), 78.0% (+0.2%), and 78.8% (+0.37%) average mean intersection-over-union (mIoU) on CrackForest (CFD), CUB-200-2011, and HAM10000 datasets, respectively. For multi-object benchmarks, the framework showcases explicit, user-controllable semantic segmentation.

</details>


### [60] [Seeing Beyond Redundancy: Task Complexity's Role in Vision Token Specialization in VLLMs](https://arxiv.org/abs/2602.06914)
*Darryl Hannan,John Cooper,Dylan White,Yijing Watkins*

Main category: cs.CV

TL;DR: 本文通过构建一个专门用于探测视觉特征的合成基准数据集，研究了视觉大语言模型（VLLMs）在处理细粒度视觉信息和空间推理任务时表现不佳的原因。研究发现，任务复杂性与视觉压缩之间存在关联，表明高质量、高复杂度的视觉数据对改善模型的视觉表征分布至关重要。


<details>
  <summary>Details</summary>
Motivation: 当前视觉大语言模型（VLLMs）的视觉能力远落后于语言能力，尤其在需要细粒度视觉信息或空间推理的任务中表现不佳。尽管已有研究将原因归结为视觉冗余，但其具体机制尚不明确。本文旨在深入探究不同类型的视觉信息如何被模型处理，以及哪些信息被丢弃。

Method: 提出一种针对特定视觉特征设计的合成基准数据集，并引入测量视觉冗余的指标，系统分析模型在不同复杂度视觉任务上的表现。通过对比微调前后模型的视觉表示变化，揭示任务复杂性与视觉压缩之间的关系。

Result: 研究发现，随着任务复杂性的提升，模型的视觉压缩程度增强；只有在足够比例的高复杂度视觉数据训练下，模型才能有效调整其视觉表征分布，从而提升在复杂视觉任务上的性能。

Conclusion: 本研究揭示了任务复杂性对视觉压缩的影响，强调了在训练下一代视觉大语言模型时，引入高复杂度视觉数据的重要性，为优化模型视觉能力提供了关键洞见。

Abstract: Vision capabilities in vision large language models (VLLMs) have consistently lagged behind their linguistic capabilities. In particular, numerous benchmark studies have demonstrated that VLLMs struggle when fine-grained visual information or spatial reasoning is required. However, we do not yet understand exactly why VLLMs struggle so much with these tasks relative to others. Some works have focused on visual redundancy as an explanation, where high-level visual information is uniformly spread across numerous tokens and specific, fine-grained visual information is discarded. In this work, we investigate this premise in greater detail, seeking to better understand exactly how various types of visual information are processed by the model and what types of visual information are discarded. To do so, we introduce a simple synthetic benchmark dataset that is specifically constructed to probe various visual features, along with a set of metrics for measuring visual redundancy, allowing us to better understand the nuances of their relationship. Then, we explore fine-tuning VLLMs on a number of complex visual tasks to better understand how redundancy and compression change based upon the complexity of the data that a model is trained on. We find that there is a connection between task complexity and visual compression, implying that having a sufficient ratio of high complexity visual data is crucial for altering the way that VLLMs distribute their visual representation and consequently improving their performance on complex visual tasks. We hope that this work will provide valuable insights for training the next generation of VLLMs.

</details>


### [61] [CineScene: Implicit 3D as Effective Scene Representation for Cinematic Video Generation](https://arxiv.org/abs/2602.06959)
*Kaiyi Huang,Yukun Huang,Yu Li,Jianhong Bai,Xintao Wang,Zinan Lin,Xuefei Ning,Jiwen Yu,Pengfei Wan,Yu Wang,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出CineScene框架，用于解耦场景上下文的电影级视频生成。通过隐式3D感知场景表示和新颖的上下文条件机制，利用VGGT编码场景图像并注入空间先验，实现相机控制下的视频合成，保持场景一致性与动态主体表现。引入随机打乱策略提升模型鲁棒性，并构建基于Unreal Engine 5的场景解耦数据集以解决训练数据不足问题。实验表明，CineScene在场景一致性、大范围镜头运动和跨环境泛化方面均达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 传统实景拍摄成本高，需搭建物理布景；现有方法难以在保持场景一致性的同时实现灵活的相机运动与动态主体合成。因此，亟需一种能从静态场景图像中生成高质量、可控电影级视频的新方法。

Method: 提出CineScene框架，采用隐式3D感知场景表示；通过VGGT将多张静态场景图像编码为视觉表征，以附加上下文拼接方式向预训练文本到视频生成模型注入3D感知特征；引入随机打乱输入图像的训练策略增强鲁棒性；构建基于Unreal Engine 5的场景解耦数据集，包含带/不带动态主体的配对视频、全景图及相机轨迹。

Result: CineScene在多个评估指标上优于现有方法，在处理大范围相机运动、保持场景一致性以及跨环境泛化方面表现优异，实现了高质量、可控的电影级视频生成。

Conclusion: CineScene成功实现了基于静态场景图像的高质量、可控制的电影级视频生成，具备强场景一致性、灵活相机运动支持和良好泛化能力，为低成本影视内容创作提供了有效解决方案。

Abstract: Cinematic video production requires control over scene-subject composition and camera movement, but live-action shooting remains costly due to the need for constructing physical sets. To address this, we introduce the task of cinematic video generation with decoupled scene context: given multiple images of a static environment, the goal is to synthesize high-quality videos featuring dynamic subject while preserving the underlying scene consistency and following a user-specified camera trajectory. We present CineScene, a framework that leverages implicit 3D-aware scene representation for cinematic video generation. Our key innovation is a novel context conditioning mechanism that injects 3D-aware features in an implicit way: By encoding scene images into visual representations through VGGT, CineScene injects spatial priors into a pretrained text-to-video generation model by additional context concatenation, enabling camera-controlled video synthesis with consistent scenes and dynamic subjects. To further enhance the model's robustness, we introduce a simple yet effective random-shuffling strategy for the input scene images during training. To address the lack of training data, we construct a scene-decoupled dataset with Unreal Engine 5, containing paired videos of scenes with and without dynamic subjects, panoramic images representing the underlying static scene, along with their camera trajectories. Experiments show that CineScene achieves state-of-the-art performance in scene-consistent cinematic video generation, handling large camera movements and demonstrating generalization across diverse environments.

</details>


### [62] [MedMO: Grounding and Understanding Multimodal Large Language Model for Medical Images](https://arxiv.org/abs/2602.06965)
*Ankan Deria,Komal Kumar,Adinath Madhavrao Dukre,Eran Segal,Salman Khan,Imran Razzak*

Main category: cs.CV

TL;DR: MedMO 是一个基于通用多模态大模型架构并仅在大规模领域特定数据上训练的医学基础模型。它采用多阶段训练策略：跨模态预训练、多任务指令微调以及结合事实性验证与框级GIoU奖励的强化学习，以增强空间对齐和逐步推理能力。MedMO 在多种医学模态和任务中均显著优于现有开源模型，在视觉问答（VQA）、文本问答、报告生成及疾病定位等任务中表现优异，尤其在空间定位方面有显著提升。其在放射学、眼科和病理显微镜领域的评估显示了强大的跨模态泛化能力。项目已开源两个版本（4B 和 8B）。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在医学领域的应用受限于领域覆盖不足、模态对齐困难以及基于证据的推理能力弱。因此亟需一个专为医学设计、具备强跨模态对齐与推理能力的基础模型。

Method: 采用三阶段训练流程：(i) 跨模态预训练以对齐异构视觉编码器与医学语言主干；(ii) 多任务指令微调，涵盖图像描述、视觉问答、报告生成、检索与病灶定位；(iii) 基于可验证奖励的强化学习，结合事实性检查与框级GIoU奖励，提升空间定位与复杂临床场景下的推理能力。

Result: MedMO 在多个医学任务中显著超越现有开源模型：在VQA上平均准确率提升+13.7%，接近最先进模型Fleming-VL（差1.9%）；在文本问答中比基线高+6.9%，比Fleming-VL高+14.5%；报告生成在语义与临床准确性上均有显著提升；空间定位性能大幅提升，IoU相比基线提高+40.4%，比Fleming-VL高+37.0%。在放射学、眼科和病理显微镜中均表现出良好泛化能力。

Conclusion: MedMO 作为一个专为医学领域优化的多模态基础模型，通过系统化的训练策略实现了卓越的跨模态理解、空间对齐与临床推理能力，展现出在医疗影像分析中的巨大潜力，且其开源版本将推动医学AI的发展。

Abstract: Multimodal large language models (MLLMs) have rapidly advanced, yet their adoption in medicine remains limited by gaps in domain coverage, modality alignment, and grounded reasoning. In this work, we introduce MedMO, a medical foundation model built upon a generalized MLLM architecture and trained exclusively on large-scale, domain-specific data. MedMO follows a multi-stage training recipe: (i) cross-modal pretraining to align heterogeneous visual encoders with a medical language backbone; (ii) instruction tuning on multi-task supervision that spans captioning, VQA, report generation, retrieval, and grounded disease localization with bounding boxes; and (iii) reinforcement learning with verifiable rewards that combine factuality checks with a box-level GIoU reward to strengthen spatial grounding and step-by-step reasoning in complex clinical scenarios. MedMO consistently outperforms strong open-source medical MLLMs across multiple modalities and tasks. On VQA benchmarks, MedMO achieves an average accuracy improvement of +13.7% over the baseline and performs within 1.9% of the SOTA Fleming-VL. For text-based QA, it attains +6.9% over the baseline and +14.5% over Fleming-VL. In medical report generation, MedMO delivers significant gains in both semantic and clinical accuracy. Moreover, it exhibits strong grounding capability, achieving an IoU improvement of +40.4 over the baseline and +37.0% over Fleming-VL, underscoring its robust spatial reasoning and localization performance. Evaluations across radiology, ophthalmology, and pathology-microscopy confirm MedMO's broad cross-modality generalization. We release two versions of MedMO: 4B and 8B. Project is available at https://genmilab.github.io/MedMO-Page

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [63] [Recontextualizing Famous Quotes for Brand Slogan Generation](https://arxiv.org/abs/2602.06049)
*Ziao Yang,Zizhang Chen,Lei Zhang,Hongfu Liu*

Main category: cs.CL

TL;DR: 本文提出一种基于著名语录重构的口号生成新范式，通过分解生成任务（如引文匹配、结构分解、词汇替换、重混生成）提升口号的创意性与品牌个性，克服现有大语言模型生成口号时风格重复、机器感强的问题。实验表明该方法在多样性、新颖性、情感冲击力和人类偏好上均优于当前主流基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型生成的口号存在风格重复、缺乏品牌个性且显得过于机械化的问题，导致广告疲劳加剧；因此需要更富创意、兼具新颖性与熟悉感的口号生成方法。

Method: 提出一个模块化框架，将口号生成拆解为四个可解释的子任务：引文匹配、结构分解、词汇替换和重混生成，利用著名语录作为创意来源，实现对品牌语调的再塑造。

Result: 自动与人工评估结果显示，该方法在多样性、新颖性、情感影响及人类偏好方面均显著优于三个先进的LLM基线模型，证明其有效性与实用性。

Conclusion: 通过重新语境化著名语录并采用模块化生成流程，本研究为创造更具品牌个性与创意性的口号提供了有效解决方案，推动了广告文案生成向更自然、更人性化方向发展。

Abstract: Slogans are concise and memorable catchphrases that play a crucial role in advertising by conveying brand identity and shaping public perception. However, advertising fatigue reduces the effectiveness of repeated slogans, creating a growing demand for novel, creative, and insightful slogan generation. While recent work leverages large language models (LLMs) for this task, existing approaches often produce stylistically redundant outputs that lack a clear brand persona and appear overtly machine-generated. We argue that effective slogans should balance novelty with familiarity and propose a new paradigm that recontextualizes persona-related famous quotes for slogan generation. Well-known quotes naturally align with slogan-length text, employ rich rhetorical devices, and offer depth and insight, making them a powerful resource for creative generation. Technically, we introduce a modular framework that decomposes slogan generation into interpretable subtasks, including quote matching, structural decomposition, vocabulary replacement, and remix generation. Extensive automatic and human evaluations demonstrate marginal improvements in diversity, novelty, emotional impact, and human preference over three state-of-the-art LLM baselines.

</details>


### [64] [Relevance-aware Multi-context Contrastive Decoding for Retrieval-augmented Visual Question Answering](https://arxiv.org/abs/2602.06050)
*Jongha Kim,Byungoh Ko,Jeehye Na,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CL

TL;DR: 提出了一种名为Relevance-aware Multi-context Contrastive Decoding (RMCD)的新解码方法，用于提升大型视觉语言模型（LVLMs）在检索增强生成（RAG）中的表现。该方法通过加权多个相关上下文的预测结果，有效融合有用信息并抑制无关上下文的干扰，在多个视觉问答基准测试中均优于现有方法，且无需额外训练即可应用，对检索结果具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG解码方法未能充分利用多个相关上下文，且无法有效抑制无关上下文的负面影响，导致性能受限。

Method: 提出RMCD方法，基于每个上下文与问题的相关性对其进行加权，综合多个上下文的预测输出以生成最终答案。

Result: RMCD在三个知识密集型视觉问答基准上表现最佳，显著优于其他解码方法，且在不同检索质量下均保持稳定优异的表现。

Conclusion: RMCD是一种高效、通用且鲁棒的解码策略，可直接替换现有LVLM的解码方式，无需重新训练，显著提升RAG系统在视觉问答任务中的性能。

Abstract: Despite the remarkable capabilities of Large Vision Language Models (LVLMs), they still lack detailed knowledge about specific entities. Retrieval-augmented Generation (RAG) is a widely adopted solution that enhances LVLMs by providing additional contexts from an external Knowledge Base. However, we observe that previous decoding methods for RAG are sub-optimal as they fail to sufficiently leverage multiple relevant contexts and suppress the negative effects of irrelevant contexts. To this end, we propose Relevance-aware Multi-context Contrastive Decoding (RMCD), a novel decoding method for RAG. RMCD outputs a final prediction by combining outputs predicted with each context, where each output is weighted based on its relevance to the question. By doing so, RMCD effectively aggregates useful information from multiple relevant contexts while also counteracting the negative effects of irrelevant ones. Experiments show that RMCD consistently outperforms other decoding methods across multiple LVLMs, achieving the best performance on three knowledge-intensive visual question-answering benchmarks. Also, RMCD can be simply applied by replacing the decoding method of LVLMs without additional training. Analyses also show that RMCD is robust to the retrieval results, consistently performing the best across the weakest to the strongest retrieval results. Code is available at https://github.com/mlvlab/RMCD.

</details>


### [65] [CAST: Character-and-Scene Episodic Memory for Agents](https://arxiv.org/abs/2602.06051)
*Kexin Ma,Bojun Li,Yuhua Tang,Ruochun Jin,Liting Sun*

Main category: cs.CL

TL;DR: 提出一种基于戏剧理论的三元组场景记忆架构CAST，通过构建时间/地点/主题三维场景并整合为角色档案来表征情景记忆，结合图结构语义记忆形成双模态记忆系统，在开放和时间敏感对话任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统多关注语义回忆，将经验视为键值对、向量或图结构，难以有效表示和检索连贯事件，因此需要一种更贴近人类情景记忆机制的新型记忆架构。

Method: 受戏剧理论启发，CAST构建三维场景（时间/地点/主题），并将这些场景组织成角色档案以表征人物经历，同时融合图结构的语义记忆，形成双记忆设计。

Result: 实验表明，CAST在多个数据集上平均提升8.11% F1和10.21% J(LLM-as-a-Judge)，尤其在开放性和时间敏感性对话问题上表现突出。

Conclusion: CAST成功模拟了人类情景记忆中关于‘谁、何时、何地’的连贯事件表征，实现了更自然、更高效的记忆检索，为智能体的记忆建模提供了新范式。

Abstract: Episodic memory is a central component of human memory, which refers to the ability to recall coherent events grounded in who, when, and where. However, most agent memory systems only emphasize semantic recall and treat experience as structures such as key-value, vector, or graph, which makes them struggle to represent and retrieve coherent events. To address this challenge, we propose a Character-and-Scene based memory architecture(CAST) inspired by dramatic theory. Specifically, CAST constructs 3D scenes (time/place/topic) and organizes them into character profiles that summarize the events of a character to represent episodic memory. Moreover, CAST complements this episodic memory with a graph-based semantic memory, which yields a robust dual memory design. Experiments demonstrate that CAST has averagely improved 8.11% F1 and 10.21% J(LLM-as-a-Judge) than baselines on various datasets, especially on open and time-sensitive conversational questions.

</details>


### [66] [Rethinking Memory Mechanisms of Foundation Agents in the Second Half](https://arxiv.org/abs/2602.06052)
*Wei-Chieh Huang,Weizhi Zhang,Yueqing Liang,Yuanchen Bei,Yankai Chen,Tao Feng,Xinyu Pan,Zhen Tan,Yu Wang,Tianxin Wei,Shanglin Wu,Ruiyao Xu,Liangwei Yang,Rui Yang,Wooseong Yang,Chin-Yuan Yeh,Hanrong Zhang,Haozhen Zhang,Siqi Zhu,Henry Peng Zou,Wanjia Zhao,Song Wang,Wujiang Xu,Zixuan Ke,Zheng Hui,Dawei Li,Yaozu Wu,Langzhou He,Chen Wang,Xiongxiao Xu,Baixiang Huang,Juntao Tan,Shelby Heinecke,Huan Wang,Caiming Xiong,Ahmed A. Metwally,Jun Yan,Chen-Yu Lee,Hanqing Zeng,Yinglong Xia,Xiaokai Wei,Ali Payani,Yu Wang,Haitong Ma,Wenya Wang,Chengguang Wang,Yu Zhang,Xin Wang,Yongfeng Zhang,Jiaxuan You,Hanghang Tong,Xiao Luo,Yizhou Sun,Wei Wang,Julian McAuley,James Zou,Jiawei Han,Philip S. Yu,Kai Shu*

Main category: cs.CL

TL;DR: 本文综述了人工智能领域中智能体记忆的研究进展，聚焦于在长时程、动态和用户依赖环境中的实际应用。文章从记忆基质（内部与外部）、认知机制（情景、语义、感官、工作、程序性记忆）以及记忆主体（以智能体为中心和以用户为中心）三个维度对基础智能体记忆进行统一梳理。同时分析了不同智能体架构下记忆的实现方式与操作策略，并讨论了记忆学习策略。最后，总结了评估记忆实用性的基准和指标，指出了当前挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能研究从追求模型创新转向强调问题定义和真实世界评估，如何在复杂、动态、长期交互环境中实现智能体的实际效用成为核心挑战。面对上下文爆炸和信息持续积累的需求，记忆系统被视为填补这一效用差距的关键解决方案。

Method: 通过构建三维框架（记忆基质、认知机制、记忆主体）对智能体记忆进行全面分类；结合不同智能体拓扑结构分析记忆的实现与操作机制；总结学习策略；系统回顾评估基准与指标体系。

Result: 提出了一个统一的智能体记忆分析框架，揭示了记忆在不同类型智能体中的实现路径与学习机制，明确了现有评估方法的优势与局限，并识别出多个关键开放问题。

Conclusion: 记忆是实现智能体在真实世界中长期有效运行的核心能力。未来研究需关注可扩展的记忆管理、动态适应机制、人机协同记忆设计以及更贴近实际场景的评估体系。

Abstract: The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the "second half," the central challenge becomes real utility in long-horizon, dynamic, and user-dependent environments, where agents face context explosion and must continuously accumulate, manage, and selectively reuse large volumes of information across extended interactions. Memory, with hundreds of papers released this year, therefore emerges as the critical solution to fill the utility gap. In this survey, we provide a unified view of foundation agent memory along three dimensions: memory substrate (internal and external), cognitive mechanism (episodic, semantic, sensory, working, and procedural), and memory subject (agent- and user-centric). We then analyze how memory is instantiated and operated under different agent topologies and highlight learning policies over memory operations. Finally, we review evaluation benchmarks and metrics for assessing memory utility, and outline various open challenges and future directions.

</details>


### [67] [What Is Novel? A Knowledge-Driven Framework for Bias-Aware Literature Originality Evaluation](https://arxiv.org/abs/2602.06054)
*Abeer Mostafa,Thi Huyen Nguyen,Zahra Ahmadi*

Main category: cs.CL

TL;DR: 该研究提出一种文献感知的新颖性评估框架，利用近8万条顶级人工智能会议的同行评审报告，微调大语言模型以捕捉评审人员对新颖性的判断行为。系统通过提取论文在思想、方法和主张方面的结构化表示，检索语义相关的已有论文，并构建相似性图谱，实现与先前研究的概念级细粒度对比。在此基础上，模型生成校准后的新颖性评分和类人解释性评估，有效减少高估现象并提升一致性。


<details>
  <summary>Details</summary>
Motivation: 当前学术同行评审中的新颖性评估高度主观，依赖隐含判断且常缺乏对已有工作的充分比较，因此亟需一种更客观、可解释且基于结构化证据的新颖性评估方法。

Method: 采用大规模标注了新颖性的同行评审数据，微调大语言模型；从待审稿件中提取结构化表示（如方法、观点等），检索相关文献，构建概念级相似性图谱，结合结构化证据生成新颖性评分与解释。

Result: 相比现有方法，该框架显著降低了新颖性评估中的过估计问题，提升了评估的一致性和准确性，并能提供人类可理解的解释性输出。

Conclusion: 该框架实现了对研究新颖性的可解释、可校准评估，为自动化或辅助同行评审提供了有力工具，具有在学术出版中推广的应用潜力。

Abstract: Assessing research novelty is a core yet highly subjective aspect of peer review, typically based on implicit judgment and incomplete comparison to prior work. We introduce a literature-aware novelty assessment framework that explicitly learns how humans judge novelty from peer-review reports and grounds these judgments in structured comparison to existing research. Using nearly 80K novelty-annotated reviews from top-tier AI conferences, we fine-tune a large language model to capture reviewer-aligned novelty evaluation behavior. For a given manuscript, the system extracts structured representations of its ideas, methods, and claims, retrieves semantically related papers, and constructs a similarity graph that enables fine-grained, concept-level comparison to prior work. Conditioning on this structured evidence, the model produces calibrated novelty scores and human-like explanatory assessments, reducing overestimation and improving consistency relative to existing approaches.

</details>


### [68] [Quantifying and Attributing Polarization to Annotator Groups](https://arxiv.org/abs/2602.06055)
*Dimitris Tsirmpas,John Pavlopoulos*

Main category: cs.CL

TL;DR: 本文提出一种新的标注一致性度量方法，可有效分析不同注释者群体间的极化现象，克服了传统度量在群体规模不平衡和多标注设置下的局限性。该方法适用于仇恨言论与毒性检测等主观任务，并支持跨数据集、跨任务的直接比较。通过在三个仇恨言论数据集和一个毒性检测数据集上的应用，发现种族是导致极化的关键因素，宗教背景注释者与其他群体分歧明显但内部一致，教育程度较低的注释者主观性更强。研究还估计了获得稳健结果所需的最小标注人数，并开源了相应的Python库。


<details>
  <summary>Details</summary>
Motivation: 现有标注一致性度量方法不适用于群体间比较，对群体规模不平衡敏感，且仅限于单标注场景，难以满足如仇恨言论和毒性检测等主观任务的需求。

Method: 提出一种可量化极化的新型度量指标，并配套统计显著性检验，能够分析不同社会人口学与意识形态子群体之间的标注分歧，支持多标签设置和跨数据集比较。

Result: （1）种族是仇恨言论任务中极化的强且持续因素；（2）宗教注释者内部一致，但与其他群体存在分歧，与无宗教背景者的关系呈逐渐减弱并反转的趋势；（3）教育程度较低的注释者主观性更强，而高教育者之间更趋一致。研究还提供了最小标注人数估算及开源工具包。

Conclusion: 所提出的度量方法能有效揭示不同群体在主观任务中的标注模式，为理解注释者偏见和提升标注质量提供新工具，具有广泛适用性和实际价值。

Abstract: Current annotation agreement metrics are not well-suited for inter-group analysis, are sensitive to group size imbalances and restricted to single-annotation settings. These restrictions render them insufficient for many subjective tasks such as toxicity and hate-speech detection. For this reason, we introduce a quantifiable metric, paired with a statistical significance test, that attributes polarization to various annotator groups. Our metric enables direct comparisons between heavily imbalanced sociodemographic and ideological subgroups across different datasets and tasks, while also enabling analysis on multi-label settings. We apply this metric to three datasets on hate speech, and one on toxicity detection, discovering that: (1) Polarization is strongly and persistently attributed to annotator race, especially on the hate speech task. (2) Religious annotators do not fundamentally disagree with each other, but do with other annotators, a trend that is gradually diminished and then reversed with irreligious annotators. (3) Less educated annotators are more subjective, while educated ones tend to broadly agree more between themselves. Overall, our results reflect current findings around annotation patterns for various subgroups. Finally, we estimate the minimum number of annotators needed to obtain robust results, and provide an open-source Python library that implements our metric.

</details>


### [69] [Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding](https://arxiv.org/abs/2602.06161)
*Yanzheng Xiang,Lan Wei,Yizhen Yao,Qinglin Zhu,Hanqi Yan,Chen Jin,Philip Alexander Teare,Dandan Zhang,Lin Gui,Amrutha Saseendran,Yulan He*

Main category: cs.CL

TL;DR: COVER 提出一种高效的修订机制，通过单次前向传播实现留一验证和稳定草稿，利用 KV 缓存覆盖构建双重注意力视图，避免自泄漏并保持上下文信息，同时基于稳定性感知得分动态选择验证种子，显著减少无效修订，提升推理速度且不损失生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有并行扩散解码因激进并行导致生成质量下降，虽有可逆解码机制通过重检早期标记缓解问题，但现有验证方案常引发翻转振荡（令牌反复遮蔽与恢复），导致上下文弱化和修订预算浪费。

Method: COVER 采用留一验证策略，在单次前向传播中构建两个注意力视图：对选定种子进行遮蔽以验证，同时将缓存的键值状态注入其他查询以保留上下文；通过闭式对角修正防止种子位置的自泄漏；并引入稳定性感知评分机制，综合考虑不确定性、下游影响和缓存漂移，动态调整每步验证种子数量。

Result: 在多个基准测试上，COVER 显著减少了不必要的修订次数，提升了解码速度，同时保持了高质量输出。

Conclusion: COVER 通过高效验证与稳定草稿设计，在不牺牲生成质量的前提下，有效解决了并行扩散解码中的翻转振荡问题，实现了更快且更可靠的推理。

Abstract: Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality.

</details>


### [70] [Uncertainty Drives Social Bias Changes in Quantized Large Language Models](https://arxiv.org/abs/2602.06181)
*Stanley Z. Hua,Sanae Lotfi,Irene Y. Chen*

Main category: cs.CL

TL;DR: 本研究首次对50个量化模型进行了大规模分析，使用PostTrainingBiasBench基准评估其在13个封闭和开放性偏见数据集上的表现。发现一种称为“量化诱导的隐性偏见翻转”的现象：尽管整体偏见评分不变，但高达21%的响应在量化后出现偏见状态反转。该现象主要由模型不确定性驱动，高不确定性响应的改变概率是低不确定性响应的3-11倍。量化强度加剧此效应，4位量化模型的行为变化是8位模型的4-6倍。偏见变化对不同群体影响不对称，某些群体偏见恶化达18.6%，而另一些群体改善14.1%，导致整体评分误导性中立。大模型并未表现出稳定鲁棒性，群体偏见变化在不同模型家族间不可预测。研究揭示压缩会根本改变偏见模式，强调必须进行量化后的偏见评估与干预以保障实际应用可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖聚合指标评估量化后模型的偏见，但无法捕捉细微的偏见状态变化；本研究旨在揭示量化对社会偏见的深层影响，特别是那些被整体指标掩盖的个体响应翻转现象。

Method: 构建统一的PostTrainingBiasBench基准，涵盖13个闭合与开放性偏见数据集；对50个经过不同量化强度（4位与8位）处理的大型语言模型进行系统评估；通过分析响应的置信度与偏见状态变化，识别量化诱导的偏见翻转行为，并比较不同模型规模与类型下的群体差异。

Result: 发现高达21%的响应在量化后发生偏见状态翻转，且该现象与模型不确定性高度相关；4位量化模型的偏见行为变化是8位模型的4-6倍；偏见变化对不同群体呈现显著不对称性，部分群体偏见恶化达18.6%，另一些改善14.1%；大模型未表现出一致鲁棒性，群体变化趋势不可预测。

Conclusion: 量化不仅降低计算成本，还会深刻改变模型的社会偏见分布，导致局部偏见翻转而整体指标不变。因此，必须在量化后进行细致的偏见评估与干预，以确保模型在实际应用中的公平性与可靠性。

Abstract: Post-training quantization reduces the computational cost of large language models but fundamentally alters their social biases in ways that aggregate metrics fail to capture. We present the first large-scale study of 50 quantized models evaluated on PostTrainingBiasBench, a unified benchmark of 13 closed- and open-ended bias datasets. We identify a phenomenon we term quantization-induced masked bias flipping, in which up to 21% of responses flip between biased and unbiased states after quantization, despite showing no change in aggregate bias scores. These flips are strongly driven by model uncertainty, where the responses with high uncertainty are 3-11x more likely to change than the confident ones. Quantization strength amplifies this effect, with 4-bit quantized models exhibiting 4-6x more behavioral changes than 8-bit quantized models. Critically, these changes create asymmetric impacts across demographic groups, where bias can worsen by up to 18.6% for some groups while improving by 14.1% for others, yielding misleadingly neutral aggregate outcomes. Larger models show no consistent robustness advantage, and group-specific shifts vary unpredictably across model families. Our findings demonstrate that compression fundamentally alters bias patterns, requiring crucial post-quantization evaluation and interventions to ensure reliability in practice.

</details>


### [71] [BenchMarker: An Education-Inspired Toolkit for Highlighting Flaws in Multiple-Choice Benchmarks](https://arxiv.org/abs/2602.06221)
*Nishant Balepur,Bhavya Rajasekaran,Jane Oh,Michael Xie,Atrey Desai,Vipul Gupta,Steven James Moore,Eunsol Choi,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: BenchMarker is a toolkit using LLM judges to detect three common MCQ flaws—contamination, shortcuts, and writing errors—in NLP benchmarks. It reveals that contamination inflates accuracy, while writing errors reduce it and alter rankings. Prior repairs introduce new issues like implausible distractors. The tool aims to improve MCQA benchmark quality by leveraging education research.


<details>
  <summary>Details</summary>
Motivation: Existing MCQA benchmarks lack rigorous quality control, leading to unreliable evaluations. This study aims to identify and address common flaws in multiple-choice questions to improve the validity of NLP benchmarking.

Method: BenchMarker uses LLM judges to flag contamination (exact matches online), shortcuts (guessable cues in choices), and writing errors (based on a 19-rule education rubric). Human validation was conducted, followed by auditing 12 benchmarks.

Result: Contaminated MCQs inflate accuracy; writing errors reduce accuracy and change rankings beyond random. Previous benchmark repairs fixed targeted issues but introduced new flaws such as implausible distractors and multiple correct answers.

Conclusion: Flaws in MCQs degrade NLP evaluation quality, but education-inspired methods like BenchMarker can help improve benchmark design and ensure more reliable evaluations.

Abstract: Multiple-choice question answering (MCQA) is standard in NLP, but benchmarks lack rigorous quality control. We present BenchMarker, an education-inspired toolkit using LLM judges to flag three common MCQ flaws: 1) contamination - items appearing exactly online; 2) shortcuts - cues in the choices that enable guessing; and 3) writing errors - structural/grammatical issues based on a 19-rule education rubric. We validate BenchMarker with human annotations, then run the tool to audit 12 benchmarks, revealing: 2) contaminated MCQs tend to inflate accuracy, while writing errors tend to lower it and change rankings beyond random; and 3) prior benchmark repairs address their targeted issues (i.e., lowering accuracy with LLM-written distractors), but inadvertently add new flaws (i.e. implausible distractors, many correct answers). Overall, flaws in MCQs degrade NLP evaluation, but education research offers a path forward. We release BenchMarker to bridge the fields and improve MCQA benchmark design.

</details>


### [72] [Can One-sided Arguments Lead to Response Change in Large Language Models?](https://arxiv.org/abs/2602.06260)
*Pedro Cisneros-Velarde*

Main category: cs.CL

TL;DR: 本文研究如何通过仅提供支持某一立场的单边论据，简单直观地引导大型语言模型（LLMs）产生特定观点的回应。实验发现，无论模型类型、论据数量或话题如何，单边论据均能有效诱导模型偏向特定立场，而更换为其他论据则会显著降低这种引导效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在回答争议性问题时可能表现出单一立场或拒绝回答，因此需要研究如何以简单方式引导其生成特定立场的回应，以实现更平衡或可控的回答。

Method: 构建小型数据集，系统考察三个维度：(i) 模型回应所体现的立场；(ii) 争议性问题的表述方式；(iii) 论据呈现方式。通过控制变量分析不同条件下模型响应的变化。

Result: 研究发现，在多种模型、论据数量和话题下，仅提供单边论据即可显著诱导模型产生特定立场的回应；而更换为其他论据则会削弱甚至消除这种诱导效果。

Conclusion: 通过仅提供支持某一立场的论据，可以有效且一致地引导大型语言模型生成特定立场的回应，表明意见引导在实践中具有可行性与普遍性。

Abstract: Polemic questions need more than one viewpoint to express a balanced answer. Large Language Models (LLMs) can provide a balanced answer, but also take a single aligned viewpoint or refuse to answer. In this paper, we study if such initial responses can be steered to a specific viewpoint in a simple and intuitive way: by only providing one-sided arguments supporting the viewpoint. Our systematic study has three dimensions: (i) which stance is induced in the LLM response, (ii) how the polemic question is formulated, (iii) how the arguments are shown. We construct a small dataset and remarkably find that opinion steering occurs across (i)-(iii) for diverse models, number of arguments, and topics. Switching to other arguments consistently decreases opinion steering.

</details>


### [73] [MPIB: A Benchmark for Medical Prompt Injection Attacks and Clinical Safety in LLMs](https://arxiv.org/abs/2602.06268)
*Junhyeok Lee,Han Jang,Kyu Sung Choi*

Main category: cs.CL

TL;DR: 提出医学提示注入基准（MPIB），用于评估临床场景下大语言模型（LLMs）和检索增强生成（RAG）系统在直接与间接提示注入攻击下的安全性。通过临床危害事件率（CHER）衡量高严重性临床风险，结合攻击成功率（ASR）区分指令服从性与患者实际风险。基准包含9,697个经过多阶段质量筛选的实例，揭示了攻击成功率与临床风险之间可能存在显著差异，并强调防御效果取决于恶意指令出现在用户查询还是检索上下文中。代码与数据已开源。


<details>
  <summary>Details</summary>
Motivation: 现有LLM和RAG系统在临床应用中面临提示注入攻击威胁，可能导致不安全或误导性输出，亟需一个基于临床真实场景的标准化评估工具来系统化检测和量化此类风险。

Method: 构建包含9,697个高质量实例的MPIB基准，采用多阶段质量控制与临床安全检查机制；设计临床危害事件率（CHER）作为核心指标，结合攻击成功率（ASR），在多种基线模型和防御配置上进行评估，分析攻击来源（用户输入或检索上下文）对安全性的影响。

Result: 评估发现，攻击成功率（ASR）与临床危害事件率（CHER）存在显著差异，表明模型可能服从恶意指令但未造成高危后果，或反之；防御效果高度依赖于攻击源位置，检索上下文中的攻击更具隐蔽性和危害性。

Conclusion: MPIB为评估临床AI系统的提示注入安全性提供了可复现、可量化的标准框架，揭示了当前防御策略的局限性，强调需针对不同攻击路径设计针对性防护机制。

Abstract: Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly integrated into clinical workflows; however, prompt injection attacks can steer these systems toward clinically unsafe or misleading outputs. We introduce the Medical Prompt Injection Benchmark (MPIB), a dataset-and-benchmark suite for evaluating clinical safety under both direct prompt injection and indirect, RAG-mediated injection across clinically grounded tasks. MPIB emphasizes outcome-level risk via the Clinical Harm Event Rate (CHER), which measures high-severity clinical harm events under a clinically grounded taxonomy, and reports CHER alongside Attack Success Rate (ASR) to disentangle instruction compliance from downstream patient risk. The benchmark comprises 9,697 curated instances constructed through multi-stage quality gates and clinical safety linting. Evaluating MPIB across a diverse set of baseline LLMs and defense configurations, we find that ASR and CHER can diverge substantially, and that robustness depends critically on whether adversarial instructions appear in the user query or in retrieved context. We release MPIB with evaluation code, adversarial baselines, and comprehensive documentation to support reproducible and systematic research on clinical prompt injection. Code and data are available at GitHub (code) and Hugging Face (data).

</details>


### [74] [VowelPrompt: Hearing Speech Emotions from Text via Vowel-level Prosodic Augmentation](https://arxiv.org/abs/2602.06270)
*Yancheng Wang,Osama Hanna,Ruiming Xie,Xianfeng Rui,Maohao Shen,Xuedong Zhang,Christian Fuegen,Jilong Wu,Debjyoti Paul,Arthur Guo,Zhihong Lei,Ozlem Kalinli,Qing He,Yingzhen Yang*

Main category: cs.CL

TL;DR: VowelPrompt 是一种基于语言学的框架，通过提取音素级别的语音特征（如音高、能量、时长）并将其转化为自然语言描述，增强大语言模型在情感识别中的表现。该方法结合监督微调与强化学习，提升推理能力与输出一致性，在多种场景下优于现有方法，并支持可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在情感识别中忽视了细微的韵律信息，导致性能和可解释性受限。需要一种能融合语言内容与精细韵律特征的方法来提升情感识别效果。

Method: 提出 VowelPrompt 框架，从对齐的元音段中提取音高、能量、时长等特征，转换为自然语言描述，使 LLM 能联合推理语义与韵律变化；采用两阶段训练策略：监督微调（SFT）与基于可验证奖励的强化学习（RLVR），使用 GRPO 优化策略以增强推理与泛化能力。

Result: 在多个基准数据集上，VowelPrompt 在零样本、微调、跨域、跨语言等条件下均优于现有方法，且生成的解释具有可解释性，同时结合上下文语义与精细韵律结构。

Conclusion: VowelPrompt 有效融合了语言学引导的细粒度韵律特征与大语言模型的语义理解能力，显著提升了情感识别的性能与可解释性，为多模态情感分析提供了新范式。

Abstract: Emotion recognition in speech presents a complex multimodal challenge, requiring comprehension of both linguistic content and vocal expressivity, particularly prosodic features such as fundamental frequency, intensity, and temporal dynamics. Although large language models (LLMs) have shown promise in reasoning over textual transcriptions for emotion recognition, they typically neglect fine-grained prosodic information, limiting their effectiveness and interpretability. In this work, we propose VowelPrompt, a linguistically grounded framework that augments LLM-based emotion recognition with interpretable, fine-grained vowel-level prosodic cues. Drawing on phonetic evidence that vowels serve as primary carriers of affective prosody, VowelPrompt extracts pitch-, energy-, and duration-based descriptors from time-aligned vowel segments, and converts these features into natural language descriptions for better interpretability. Such a design enables LLMs to jointly reason over lexical semantics and fine-grained prosodic variation. Moreover, we adopt a two-stage adaptation procedure comprising supervised fine-tuning (SFT) followed by Reinforcement Learning with Verifiable Reward (RLVR), implemented via Group Relative Policy Optimization (GRPO), to enhance reasoning capability, enforce structured output adherence, and improve generalization across domains and speaker variations. Extensive evaluations across diverse benchmark datasets demonstrate that VowelPrompt consistently outperforms state-of-the-art emotion recognition methods under zero-shot, fine-tuned, cross-domain, and cross-linguistic conditions, while enabling the generation of interpretable explanations that are jointly grounded in contextual semantics and fine-grained prosodic structure.

</details>


### [75] [Judging What We Cannot Solve: A Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math](https://arxiv.org/abs/2602.06291)
*Guijin Son,Donghun Yang,Hitesh Laxmichand Patel,Hyunwoo Ko,Amit Agarwal,Sunghee Ahn,Kyong-Ha Lee,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出了一种名为基于后果的效用（Consequence-Based Utility）的无需人工标注的评估方法，通过测试候选解在相关问题中的表现来评估其价值，显著提升了数学推理模型的评估效果。


<details>
  <summary>Details</summary>
Motivation: 当前数学推理模型生成的解虽然可能合理，但缺乏有效验证手段，专家验证耗时且资源有限，因此需要一种无需人工标注、能高效评估解质量的方法。

Method: 基于后果的效用方法通过将候选解作为上下文示例，测试其在邻近相关问题上的求解能力，从而评估其方法层面的有效性，实现对解的质量评分。

Result: 在一组研究级数学问题上，该方法显著优于奖励模型、生成式奖励模型和LLM裁判，在准确率和AUC指标上均有明显提升；例如，GPT-OSS-120B的Acc@1从67.2提升至76.3，AUC从71.4升至79.6。

Conclusion: 基于后果的效用是一种高效、可扩展的评估方法，能够有效区分正确与错误解，尤其在模型难以求解的复杂问题中仍保持良好区分能力，为大规模推理模型评估提供了新范式。

Abstract: Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose \textbf{Consequence-Based Utility}, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap, maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve.

</details>


### [76] [Can Post-Training Transform LLMs into Causal Reasoners?](https://arxiv.org/abs/2602.06337)
*Junqi Chen,Sirui Chen,Chaochao Lu*

Main category: cs.CL

TL;DR: 本研究探讨了后训练对大语言模型（LLM）因果推理能力的提升效果，提出CauGym数据集，涵盖七项核心因果任务和五组测试集，并系统评估了SFT、DPO、KTO、PPO和GRPO五种后训练方法。实验表明，经过适当后训练的小型LLM在因果推理上可媲美甚至超越大型模型，在多个基准测试中表现优异，如14B参数模型在CaLM基准上达到93.5%准确率，远超OpenAI o3的55.4%。模型还展现出良好的泛化能力和对现实世界扰动（如分布偏移、噪声数据）的鲁棒性。研究首次提供了系统性证据，证明针对性后训练可生成可靠且稳健的因果推理模型。相关数据与GRPO模型已开源。


<details>
  <summary>Details</summary>
Motivation: 非专家在决策中需要因果推断能力，但当前大语言模型在精确因果估计方面仍存在局限，且后训练对其影响尚未充分探索。因此，亟需系统研究如何通过后训练提升模型的因果推理能力。

Method: 构建CauGym数据集，包含7个核心因果任务和5个多样化测试集；系统评估5种后训练方法（SFT、DPO、KTO、PPO、GRPO）；在5个域内和4个现有基准上进行实验，评估模型性能、泛化性与鲁棒性。

Result: 经过适当后训练的较小规模LLM在因果推理任务中表现卓越，14B模型在CaLM基准上达到93.5%准确率，显著优于OpenAI o3的55.4%；模型具备强泛化能力与对分布偏移、噪声数据的鲁棒性。

Conclusion: 针对性的后训练能够显著提升大语言模型的因果推理能力，使小型模型在性能上媲美甚至超越大型模型，为构建可靠、稳健的因果推理系统提供了有效路径。相关成果已开源。

Abstract: Causal inference is essential for decision-making but remains challenging for non-experts. While large language models (LLMs) show promise in this domain, their precise causal estimation capabilities are still limited, and the impact of post-training on these abilities is insufficiently explored. This paper examines the extent to which post-training can enhance LLMs' capacity for causal inference. We introduce CauGym, a comprehensive dataset comprising seven core causal tasks for training and five diverse test sets. Using this dataset, we systematically evaluate five post-training approaches: SFT, DPO, KTO, PPO, and GRPO. Across five in-domain and four existing benchmarks, our experiments demonstrate that appropriate post-training enables smaller LLMs to perform causal inference competitively, often surpassing much larger models. Our 14B parameter model achieves 93.5% accuracy on the CaLM benchmark, compared to 55.4% by OpenAI o3. Furthermore, the post-trained LLMs exhibit strong generalization and robustness under real-world conditions such as distribution shifts and noisy data. Collectively, these findings provide the first systematic evidence that targeted post-training can produce reliable and robust LLM-based causal reasoners. Our data and GRPO-model are available at https://github.com/OpenCausaLab/CauGym.

</details>


### [77] [Cost-Aware Model Selection for Text Classification: Multi-Objective Trade-offs Between Fine-Tuned Encoders and LLM Prompting in Production](https://arxiv.org/abs/2602.06370)
*Alberto Andres Valdes Gonzalez*

Main category: cs.CL

TL;DR: 本文系统比较了零样本和少样本提示的大型语言模型（LLM）与全微调的编码器-仅架构在文本分类任务中的表现。研究覆盖四个基准数据集（IMDB、SST-2、AG News 和 DBPedia），评估指标包括预测质量（宏观F1）、推理延迟和经济成本。结果表明，基于BERT的微调编码器模型在性能上具有竞争力甚至更优，同时在成本和延迟上比零/少样本LLM提示低一到两个数量级。研究强调应避免在结构化文本分类任务中盲目使用LLM，建议将微调编码器作为高效可靠的组件，而将LLM作为混合架构中的补充元素。代码、数据集和评估协议均已公开，以支持可复现性和成本感知的NLP系统设计。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（如GPT-4o和Claude Sonnet 4.5）虽在开放域推理和生成任务中表现出色，但在固定标签空间的结构化文本分类任务中，模型选择往往仅关注预测性能，忽视了生产环境中实际的运行约束，如延迟和成本。因此，亟需对不同方法进行系统性对比，以指导更高效的部署决策。

Method: 采用多目标评估框架，对比零/少样本提示的LLM与全微调的编码器模型（如BERT）在四个标准文本分类数据集上的表现。评估维度包括宏平均F1分数、推理延迟和运行成本。通过帕累托前沿分析与参数化效用函数，量化不同部署场景下的权衡关系。

Result: 微调的BERT类编码器模型在分类性能上达到或优于LLM，且在推理延迟和运行成本方面显著更低（低一到两个数量级）。这表明在标准文本分类任务中，直接使用LLM会导致系统层面效率低下。

Conclusion: 在结构化文本分类任务中，不应盲目使用大型语言模型。微调的编码器模型是高效、稳健的选择，而大语言模型更适合作为混合架构中的辅助模块。研究推动了成本意识的NLP系统设计，并提供了可复现的工具链。

Abstract: Large language models (LLMs) such as GPT-4o and Claude Sonnet 4.5 have demonstrated strong capabilities in open-ended reasoning and generative language tasks, leading to their widespread adoption across a broad range of NLP applications. However, for structured text classification problems with fixed label spaces, model selection is often driven by predictive performance alone, overlooking operational constraints encountered in production systems.
  In this work, we present a systematic comparison of two contrasting paradigms for text classification: zero- and few-shot prompt-based large language models, and fully fine-tuned encoder-only architectures. We evaluate these approaches across four canonical benchmarks (IMDB, SST-2, AG News, and DBPedia), measuring predictive quality (macro F1), inference latency, and monetary cost.
  We frame model evaluation as a multi-objective decision problem and analyze trade-offs using Pareto frontier projections and a parameterized utility function reflecting different deployment regimes. Our results show that fine-tuned encoder-based models from the BERT family achieve competitive, and often superior, classification performance while operating at one to two orders of magnitude lower cost and latency compared to zero- and few-shot LLM prompting.
  Overall, our findings suggest that indiscriminate use of large language models for standard text classification workloads can lead to suboptimal system-level outcomes. Instead, fine-tuned encoders emerge as robust and efficient components for structured NLP pipelines, while LLMs are better positioned as complementary elements within hybrid architectures. We release all code, datasets, and evaluation protocols to support reproducibility and cost-aware NLP system design.

</details>


### [78] [ReBeCA: Unveiling Interpretable Behavior Hierarchy behind the Iterative Self-Reflection of Language Models with Causal Analysis](https://arxiv.org/abs/2602.06373)
*Tianqiang Yan,Sihan Shang,Yuheng Li,Song Qiu,Hao Peng,Wenjian Luo,Jue Xie,Lizhen Qu,Yuan Gao*

Main category: cs.CL

TL;DR: ReBeCA 是一个基于因果分析的框架，用于揭示自反思过程中模型行为的可解释层次结构。通过将自反思轨迹建模为因果图，并采用三阶段不变因果预测（ICP）流程，该方法识别出影响性能的真实决定因素。研究发现：1）语义行为以层级方式影响最终反思结果；2）自反思效果的泛化仅限于少数语义行为；3）多个看似积极的行为组合反而可能降低反思效率。ICP验证显示，稀疏的因果父节点可带来高达49.6%的结构似然提升，且在新数据集上具有稳定性与外推能力（p = .013, η²_p = .071）。ReBeCA 为区分自反思中的真实因果机制与虚假关联提供了严谨方法。


<details>
  <summary>Details</summary>
Motivation: 现有对语言模型自反思的研究多依赖相关性分析，缺乏对内在机制的深入理解，且结果难以泛化。因此亟需一种能揭示真实因果关系的方法，以提升自反思的可解释性与可靠性。

Method: 提出 ReBeCA 框架，将自反思过程建模为因果图，采用三阶段不变因果预测（ICP）流程，识别关键因果变量，并通过干预实验验证其在分布外场景下的稳定性。

Result: 发现语义行为存在层级影响结构；仅有少数语义行为具备泛化能力；多个正面行为的叠加反而损害反思效果；稀疏因果父节点带来显著结构似然提升（最高达49.6%），并在新数据集上表现稳定（p = .013, η²_p = .071）。

Conclusion: ReBeCA 提供了一种可解释、可验证的因果分析方法，有效区分自反思中的真实因果机制与伪相关，推动了对语言模型自反思机制的深层理解。

Abstract: While self-reflection can enhance language model reliability, its underlying mechanisms remain opaque, with existing analyses often yielding correlation-based insights that fail to generalize. To address this, we introduce \textbf{\texttt{ReBeCA}} (self-\textbf{\texttt{Re}}flection \textbf{\texttt{Be}}havior explained through \textbf{\texttt{C}}ausal \textbf{\texttt{A}}nalysis), a framework that unveils the interpretable behavioral hierarchy governing the self-reflection outcome. By modeling self-reflection trajectories as causal graphs, ReBeCA isolates genuine determinants of performance through a three-stage Invariant Causal Prediction (ICP) pipeline. We establish three critical findings: (1) \textbf{Behavioral hierarchy:} Semantic behaviors of the model influence final self-reflection results hierarchically: directly or indirectly; (2) \textbf{Causation matters:} Generalizability in self-reflection effects is limited to just a few semantic behaviors; (3) \textbf{More $\mathbf{\neq}$ better:} The confluence of seemingly positive semantic behaviors, even among direct causal factors, can impair the efficacy of self-reflection. ICP-based verification identifies sparse causal parents achieving up to $49.6\%$ structural likelihood gains, stable across tasks where correlation-based patterns fail. Intervention studies on novel datasets confirm these causal relationships hold out-of-distribution ($p = .013, η^2_\mathrm{p} = .071$). ReBeCA thus provides a rigorous methodology for disentangling genuine causal mechanisms from spurious associations in self-reflection dynamics.

</details>


### [79] [FMBench: Adaptive Large Language Model Output Formatting](https://arxiv.org/abs/2602.06384)
*Yaoting Wang,Yun Zhou,Henghui Ding*

Main category: cs.CL

TL;DR: 该研究提出FMBench基准，用于评估大语言模型在复杂Markdown格式指令下的表现，并通过SFT与强化学习相结合的轻量级对齐流程提升生成内容的语义准确性和结构合规性。实验表明，尽管存在语义与结构目标间的权衡，但联合优化可显著改善格式化输出质量。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生成包含复杂结构（如列表、表格、代码块等）的Markdown时，常出现难以察觉的格式错误，影响下游应用的可用性。因此需要一个能真实反映实际使用场景的评估基准和有效的对齐方法来提升模型生成格式化文本的能力。

Method: 提出FMBench基准，涵盖多层级组织、混合内容及严格布局约束等现实场景；采用先监督微调（SFT）再结合强化学习微调的轻量级对齐策略，优化语义保真度与结构正确性的复合目标函数。

Result: 在OpenPangu和Qwen两个模型族上的实验显示，SFT有效提升语义一致性，强化学习进一步增强对复杂指令的鲁棒性；同时揭示了语义与结构目标之间的内在权衡，强调奖励设计的重要性。

Conclusion: 通过结合监督微调与强化学习的对齐策略，可在不依赖硬性解码约束的情况下显著提升大模型生成高质量、符合格式要求的Markdown输出能力，且需精心设计奖励机制以平衡不同目标。

Abstract: Producing outputs that satisfy both semantic intent and format constraints is essential for deploying large language models in user-facing and system-integrated workflows. In this work, we focus on Markdown formatting, which is ubiquitous in assistants, documentation, and tool-augmented pipelines but still prone to subtle, hard-to-detect errors (e.g., broken lists, malformed tables, inconsistent headings, and invalid code blocks) that can significantly degrade downstream usability. We present FMBench, a benchmark for adaptive Markdown output formatting that evaluates models under a wide range of instruction-following scenarios with diverse structural requirements. FMBench emphasizes real-world formatting behaviors such as multi-level organization, mixed content (natural language interleaved with lists/tables/code), and strict adherence to user-specified layout constraints. To improve Markdown compliance without relying on hard decoding constraints, we propose a lightweight alignment pipeline that combines supervised fine-tuning (SFT) with reinforcement learning fine-tuning. Starting from a base model, we first perform SFT on instruction-response pairs, and then optimize a composite objective that balances semantic fidelity with structural correctness. Experiments on two model families (OpenPangu and Qwen) show that SFT consistently improves semantic alignment, while reinforcement learning provides additional gains in robustness to challenging Markdown instructions when initialized from a strong SFT policy. Our results also reveal an inherent trade-off between semantic and structural objectives, highlighting the importance of carefully designed rewards for reliable formatted generation. Code is available at: https://github.com/FudanCVL/FMBench.

</details>


### [80] [On the Wings of Imagination: Conflicting Script-based Multi-role Framework for Humor Caption Generation](https://arxiv.org/abs/2602.06423)
*Wenbo Shang,Yuxi Sun,Jing Ma,Xin Huang*

Main category: cs.CL

TL;DR: 提出一种基于幽默理论GTVH的多角色LLM协作框架HOMER，用于生成与图像内容相反且有趣的幽默描述。该框架通过提取冲突脚本、检索增强的层级想象和条件生成，提升创造力与可解释性，在新纽约客漫画数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的幽默生成方法依赖推理链或自我改进，存在创造力不足和可解释性差的问题，亟需更有效的机制来生成高质量的多模态幽默内容。

Method: 提出HOMER框架，包含三个角色：冲突脚本提取器、检索增强的层级想象器和标题生成器，结合幽默理论与检索增强的创意扩展，实现幽默描述生成。

Result: 在两个New Yorker Cartoon基准数据集上，HOMER显著优于现有先进基线和强大的LLM推理策略，证明其在多模态幽默生成任务中的有效性。

Conclusion: HOMER框架通过幽默理论驱动的多角色协作和检索增强机制，有效提升了多模态幽默生成的趣味性、多样性和可解释性，为未来幽默生成研究提供了新方向。

Abstract: Humor is a commonly used and intricate human language in daily life. Humor generation, especially in multi-modal scenarios, is a challenging task for large language models (LLMs), which is typically as funny caption generation for images, requiring visual understanding, humor reasoning, creative imagination, and so on. Existing LLM-based approaches rely on reasoning chains or self-improvement, which suffer from limited creativity and interpretability. To address these bottlenecks, we develop a novel LLM-based humor generation mechanism based on a fundamental humor theory, GTVH. To produce funny and script-opposite captions, we introduce a humor-theory-driven multi-role LLM collaboration framework augmented with humor retrieval (HOMER). The framework consists of three LLM-based roles: (1) conflicting-script extractor that grounds humor in key script oppositions, forming the basis of caption generation; (2) retrieval-augmented hierarchical imaginator that identifies key humor targets and expands the creative space of them through diverse associations structured as imagination trees; and (3) caption generator that produces funny and diverse captions conditioned on the obtained knowledge. Extensive experiments on two New Yorker Cartoon benchmarking datasets show that HOMER outperforms state-of-the-art baselines and powerful LLM reasoning strategies on multi-modal humor captioning.

</details>


### [81] [TrailBlazer: History-Guided Reinforcement Learning for Black-Box LLM Jailbreaking](https://arxiv.org/abs/2602.06440)
*Sung-Hoon Yoon,Ruizhi Qian,Minda Zhao,Weiyue Li,Mengyu Wang*

Main category: cs.CL

TL;DR: 本文提出一种基于强化学习的历史感知越狱框架，通过分析和重加权先前交互步骤中的漏洞信号来指导后续决策。引入注意力机制以突出历史中的关键漏洞，显著提升攻击效率与成功率。在AdvBench和HarmBench上的实验表明，该方法在越狱性能和查询效率上均达到当前最优水平。


<details>
  <summary>Details</summary>
Motivation: 现有越狱技术未能有效利用早期交互中暴露的漏洞，导致攻击效率低且不稳定。由于越狱是序列化交互过程，历史信息对后续决策至关重要，因此需要更有效的机制来捕捉并利用这些信息。

Method: 提出一种历史感知的强化学习框架，结合注意力机制对历史交互中的漏洞信号进行重加权，从而引导更高效的探索策略。

Result: 在AdvBench和HarmBench数据集上，所提方法实现了最先进的越狱成功率，并大幅提升了查询效率。

Conclusion: 历史漏洞信号在强化学习驱动的越狱策略中具有关键作用，该研究为推进大模型安全防护的对抗性研究提供了系统性路径。

Abstract: Large Language Models (LLMs) have become integral to many domains, making their safety a critical priority. Prior jailbreaking research has explored diverse approaches, including prompt optimization, automated red teaming, obfuscation, and reinforcement learning (RL) based methods. However, most existing techniques fail to effectively leverage vulnerabilities revealed in earlier interaction turns, resulting in inefficient and unstable attacks. Since jailbreaking involves sequential interactions in which each response influences future actions, reinforcement learning provides a natural framework for this problem. Motivated by this, we propose a history-aware RL-based jailbreak framework that analyzes and reweights vulnerability signals from prior steps to guide future decisions. We show that incorporating historical information alone improves jailbreak success rates. Building on this insight, we introduce an attention-based reweighting mechanism that highlights critical vulnerabilities within the interaction history, enabling more efficient exploration with fewer queries. Extensive experiments on AdvBench and HarmBench demonstrate that our method achieves state-of-the-art jailbreak performance while significantly improving query efficiency. These results underscore the importance of historical vulnerability signals in reinforcement learning-driven jailbreak strategies and offer a principled pathway for advancing adversarial research on LLM safeguards.

</details>


### [82] [CORE: Comprehensive Ontological Relation Evaluation for Large Language Models](https://arxiv.org/abs/2602.06446)
*Satyam Dwivedi,Sanjukta Ghosh,Shivam Dwivedi,Nishi Kumari,Anil Thakur,Anurag Purushottam,Deepak Alok,Praveen Gatla,Manjuprasad B,Bipasha Patgiri*

Main category: cs.CL

TL;DR: 本文提出CORE（Comprehensive Ontological Relation Evaluation）数据集，包含22.5万道多选题，覆盖74个学科，并构建了一个203道严格验证的通用领域基准测试，涵盖24种语义关系类型，且无关配对均衡分布。人类基线在1000多名参与者中达到92.6%准确率（无关对为95.1%），而29个前沿LLM整体准确率仅48.25%-70.9%，在相关对上表现良好（86.5%-100%），但在无关对上严重下降（0%-41.35%），尽管置信度仍高（92%-94%）。无关对上的预期校准误差增加2-4倍，平均语义坍缩率达37.6%，表明模型系统生成虚假关系。在CORE 22.5万题数据集上，准确率进一步降至约2%，凸显领域特定语义推理的重大挑战。研究指出，无关性推理是当前LLM评估与安全的关键盲区。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型评估很少关注其区分有意义语义关系与真正无关性的能力，导致模型在面对无关配对时易产生错误但高置信的推理，存在潜在安全风险。因此亟需一个全面、严谨的评估框架来揭示这一短板。

Method: 构建大规模多选题数据集CORE，涵盖74个学科共22.5万道题，并设计203道经严格验证的通用领域基准题，覆盖24种语义关系类型，确保无关对均衡分布；通过大规模人类标注建立基线；使用29个主流LLM进行测试，分析其在相关与无关对上的表现差异、置信度一致性及校准误差，并量化语义坍缩现象。

Result: 人类基线准确率达92.6%（无关对95.1%），而29个LLM整体准确率仅为48.25%-70.9%，在无关对上最低仅0%，置信度却高达92%-94%；预期校准误差上升2-4倍；平均语义坍缩率37.6%；在22.5万题数据集上准确率降至约2%，表明模型在复杂语义无关判断上存在严重缺陷。

Conclusion: 无关性推理是当前大语言模型评估中被严重忽视的关键维度，也是影响模型安全性和可靠性的重要瓶颈。未来评估体系必须纳入对无关关系识别能力的考量，以推动更稳健、可信赖的AI系统发展。

Abstract: Large Language Models (LLMs) perform well on many reasoning benchmarks, yet existing evaluations rarely assess their ability to distinguish between meaningful semantic relations and genuine unrelatedness. We introduce CORE (Comprehensive Ontological Relation Evaluation), a dataset of 225K multiple-choice questions spanning 74 disciplines, together with a general-domain open-source benchmark of 203 rigorously validated questions (Cohen's Kappa = 1.0) covering 24 semantic relation types with equal representation of unrelated pairs. A human baseline from 1,000+ participants achieves 92.6% accuracy (95.1% on unrelated pairs). In contrast, 29 state-of-the-art LLMs achieve 48.25-70.9% overall accuracy, with near-ceiling performance on related pairs (86.5-100%) but severe degradation on unrelated pairs (0-41.35%), despite assigning similar confidence (92-94%). Expected Calibration Error increases 2-4x on unrelated pairs, and a mean semantic collapse rate of 37.6% indicates systematic generation of spurious relations. On the CORE 225K MCQs dataset, accuracy further drops to approximately 2%, highlighting substantial challenges in domain-specific semantic reasoning. We identify unrelatedness reasoning as a critical, under-evaluated frontier for LLM evaluation and safety.

</details>


### [83] [Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning](https://arxiv.org/abs/2602.06449)
*Xinxin Lin,Guangxin Dai,Yi Zhong,Xiang Li,Xue Xiao,Yixin Zhang,Zhengdong Wu,Yongbo Zheng,Runchuan Zhu,Ming Zhao,Huizi Yu,Shuo Wu,Jun Zhao,Lingming Hu,Yumei Wang,Ping Yin,Joey W. Y. Chan,Ngan Yin Chan,Sijing Chen,Yun Kwok Wing,Lin Lu,Xin Ma,Lizhou Fan*

Main category: cs.CL

TL;DR: 本文提出ClinMPO，一种基于强化学习的框架，旨在使轻量级大语言模型（LLM）的内部推理过程与专业精神科实践对齐。该框架采用基于4,474篇精神科期刊文章构建的、符合循证医学原则的数据集训练专用奖励模型。在一项专门设计以隔离推理能力而非死记硬背的测试中，经ClinMPO优化的Qwen3-8B模型诊断准确率达31.4%，优于300名医学生组成的对照组基准（30.8%），表明医学证据引导的优化可使轻量级LLM掌握复杂推理任务，为安全可靠的精神科决策支持提供可扩展路径。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在精神科应用中受限于幻觉和浅层推理，尤其在轻量级模型中更为明显；当前训练范式侧重语言流畅性而非结构化临床逻辑，导致与专业诊断认知存在根本性错位。

Method: 提出ClinMPO框架，通过强化学习结合基于大量精神科文献构建的循证医学结构化数据集训练专用奖励模型，以对齐LLM内部推理与专业精神科实践。

Result: 在复杂推理测试集上，经ClinMPO优化的Qwen3-8B模型达到31.4%诊断准确率，超越人类基准30.8%；证明医学证据引导优化可显著提升轻量级LLM的复杂推理能力。

Conclusion: 显式的认知对齐策略为实现可靠且安全的精神科决策支持提供了可扩展的技术路径，使轻量级大语言模型具备处理高难度临床推理任务的能力。

Abstract: Large language models (LLMs) hold transformative potential for medical decision support yet their application in psychiatry remains constrained by hallucinations and superficial reasoning. This limitation is particularly acute in light-parameter LLMs which are essential for privacy-preserving and efficient clinical deployment. Existing training paradigms prioritize linguistic fluency over structured clinical logic and result in a fundamental misalignment with professional diagnostic cognition. Here we introduce ClinMPO, a reinforcement learning framework designed to align the internal reasoning of LLMs with professional psychiatric practice. The framework employs a specialized reward model trained independently on a dataset derived from 4,474 psychiatry journal articles and structured according to evidence-based medicine principles. We evaluated ClinMPO on a unseen subset of the benchmark designed to isolate reasoning capabilities from rote memorization. This test set comprises items where leading large-parameter LLMs consistently fail. We compared the ClinMPO-aligned light LLM performance against a cohort of 300 medical students. The ClinMPO-tuned Qwen3-8B model achieved a diagnostic accuracy of 31.4% and surpassed the human benchmark of 30.8% on these complex cases. These results demonstrate that medical evidence-guided optimization enables light-parameter LLMs to master complex reasoning tasks. Our findings suggest that explicit cognitive alignment offers a scalable pathway to reliable and safe psychiatric decision support.

</details>


### [84] [RelayGen: Intra-Generation Model Switching for Efficient Reasoning](https://arxiv.org/abs/2602.06454)
*Jiwon Song,Yoongon Kim,Jae-Joon Kim*

Main category: cs.CL

TL;DR: RelayGen是一种无需训练的段级运行时模型切换框架，通过分析生成不确定性（如标记概率边界）来识别推理轨迹中难度变化的段落，将低难度部分交由小型模型处理，保留高难度部分在大型模型上完成，从而显著降低推理延迟并保持高精度。结合推测解码可实现最高2.2倍的端到端加速，且准确率损失小于2%。


<details>
  <summary>Details</summary>
Motivation: 现有高效推理方法要么忽略生成过程中的难度变化，要么依赖复杂且需要监督的逐标记路由机制。本文旨在利用长推理过程中内在的难度差异，实现更高效的推理部署。

Method: 通过离线分析生成过程中的令牌概率边际以评估生成不确定性，识别出模型特定的切换提示（switch cues），用于动态判断何时将推理任务从大模型切换到小模型；采用段级控制策略，仅在粗粒度段落级别进行模型切换，避免了复杂的逐标记调度。

Result: 在多个推理基准测试中，RelayGen显著降低了推理延迟，同时保持了大模型的大部分准确性；与推测解码结合后，实现了高达2.2倍的端到端加速，准确率下降不足2%，且无需额外训练或学习路由模块。

Conclusion: RelayGen成功实现了对长推理任务中难度变化的有效利用，在不增加训练负担的前提下，实现了高效的推理加速和高精度保持，为大规模推理模型的部署提供了实用解决方案。

Abstract: Large reasoning models (LRMs) achieve strong performance on complex reasoning tasks by generating long, multi-step reasoning trajectories, but inference-time scaling incurs substantial deployment cost. A key challenge is that generation difficulty varies within a single output, whereas existing efficiency-oriented approaches either ignore this intra-generation variation or rely on supervised token-level routing with high system complexity. We present \textbf{RelayGen}, a training-free, segment-level runtime model switching framework that exploits difficulty variation in long-form reasoning. Through offline analysis of generation uncertainty using token probability margins, we show that coarse-grained segment-level control is sufficient to capture difficulty transitions within a reasoning trajectory. RelayGen identifies model-specific switch cues that signal transitions to lower-difficulty segments and dynamically delegates their continuation to a smaller model, while preserving high-difficulty reasoning on the large model. Across multiple reasoning benchmarks, RelayGen substantially reduces inference latency while preserving most of the accuracy of large models. When combined with speculative decoding, RelayGen achieves up to 2.2$\times$ end-to-end speedup with less than 2\% accuracy degradation, without requiring additional training or learned routing components.

</details>


### [85] [Diffusion-State Policy Optimization for Masked Diffusion Language Models](https://arxiv.org/abs/2602.06462)
*Daisuke Oba,Hiroki Furuta,Naoaki Okazaki*

Main category: cs.CL

TL;DR: DiSPO 提出一种插件式信用分配层，通过在中间掩码状态分支并重采样填充内容，直接优化中间决策。它利用回滚缓存的 logits 进行评分，并仅更新新填充的词元，无需额外多步扩散回滚。该方法结合了固定状态目标与策略梯度估计，可与终端反馈策略优化共享相同回滚数据。在 LLaDA-8B-Instruct 上，DiSPO 在数学和规划基准测试中均优于终端反馈的 diffu-GRPO 基线，且计算资源与优化步数一致。


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散语言模型依赖最终完成时的终端奖励进行学习，导致中间决策的信用分配粗略。为提升中间步骤决策质量，需更精细的信用分配机制。

Method: 提出 DiSPO（Diffusion-State Policy Optimization），在选定的中间掩码状态处，从回滚缓存的 logits 重采样填充内容，评估生成结果，并仅更新新填充的词元；采用固定状态目标和可与终端反馈结合的策略梯度估计器。

Result: 在 LLaDA-8B-Instruct 上，DiSPO 在数学和规划任务中持续优于 diffu-GRPO 基线，且在相同计算开销和优化步数下表现更优。

Conclusion: DiSPO 有效提升了掩码扩散语言模型中中间决策的信用分配精度，实现更高效、更准确的文本生成优化。

Abstract: Masked diffusion language models generate by iteratively filling masked tokens over multiple denoising steps, so learning only from a terminal reward on the final completion yields coarse credit assignment over intermediate decisions. We propose DiSPO (Diffusion-State Policy Optimization), a plug-in credit-assignment layer that directly optimizes intermediate filling decisions. At selected intermediate masked states, DiSPO branches by resampling fillings for the currently masked positions from rollout-cached logits, scores the resulting completions, and updates only the newly filled tokens -- without additional multi-step diffusion rollouts. We formalize a fixed-state objective for branched completions and derive a policy-gradient estimator that can be combined with terminal-feedback policy optimization using the same rollouts. On LLaDA-8B-Instruct, DiSPO consistently improves over the terminal-feedback diffu-GRPO baseline on math and planning benchmarks under matched rollout compute and optimizer steps. Our code will be available at https://daioba.github.io/dispo .

</details>


### [86] [Improve Large Language Model Systems with User Logs](https://arxiv.org/abs/2602.06470)
*Changyue Wang,Weihang Su,Qingyao Ai,Yiqun Liu*

Main category: cs.CL

TL;DR: UNO提出一种从用户日志中持续优化大语言模型系统（LLMsys）的统一框架，通过将非结构化日志提炼为半结构化规则和偏好对，利用查询与反馈驱动的聚类处理数据异质性，并量化模型先验知识与日志数据之间的认知差距，从而自适应地过滤噪声反馈并构建主经验和反思经验模块，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的发展受限于高质量数据稀缺和计算成本上升，而用户交互日志提供了真实且丰富的反馈来源，但其非结构化和噪声特性使得直接利用困难；此外，日志收集与模型优化之间存在策略偏差问题，导致传统方法难以有效提取有用信号。因此需要一种能够从用户日志中高效、准确地学习并持续优化模型的新范式。

Method: UNO首先将用户日志提炼为半结构化规则和偏好对；然后采用查询与反馈驱动的聚类方法应对数据异质性；最后通过量化模型先验知识与日志数据间的认知差距，指导模型自适应过滤噪声反馈，并分离出用于主经验与反思经验的不同模块进行训练。

Result: 实验表明，UNO在多项任务上达到当前最优效果，在有效性与效率方面均显著优于RAG和基于记忆的基线方法，验证了其在真实部署场景下的强大适应能力。

Conclusion: UNO为大语言模型系统提供了一种有效的持续学习机制，能够从真实的用户日志中挖掘高质量知识，克服噪声干扰与策略偏差问题，实现更智能、更鲁棒的自我优化，具有重要的实际应用价值。

Abstract: Scaling training data and model parameters has long driven progress in large language models (LLMs), but this paradigm is increasingly constrained by the scarcity of high-quality data and diminishing returns from rising computational costs. As a result, recent work is increasing the focus on continual learning from real-world deployment, where user interaction logs provide a rich source of authentic human feedback and procedural knowledge. However, learning from user logs is challenging due to their unstructured and noisy nature. Vanilla LLM systems often struggle to distinguish useful feedback signals from noisy user behavior, and the disparity between user log collection and model optimization (e.g., the off-policy optimization problem) further strengthens the problem. To this end, we propose UNO (User log-driveN Optimization), a unified framework for improving LLM systems (LLMsys) with user logs. UNO first distills logs into semi-structured rules and preference pairs, then employs query-and-feedback-driven clustering to manage data heterogeneity, and finally quantifies the cognitive gap between the model's prior knowledge and the log data. This assessment guides the LLMsys to adaptively filter out noisy feedback and construct different modules for primary and reflective experiences extracted from user logs, thereby improving future responses. Extensive experiments show that UNO achieves state-of-the-art effectiveness and efficiency, significantly outperforming Retrieval Augmented Generation (RAG) and memory-based baselines. We have open-sourced our code at https://github.com/bebr2/UNO .

</details>


### [87] [Revisiting the Shape Convention of Transformer Language Models](https://arxiv.org/abs/2602.06471)
*Feng-Ting Liao,Meng-Hsi Chen,Guan-Ting Yi,Da-shan Shiu*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dense Transformer language models have largely adhered to one consistent architectural shape: each layer consists of an attention module followed by a feed-forward network (FFN) with a narrow-wide-narrow MLP, allocating most parameters to the MLP at expansion ratios between 2 and 4. Motivated by recent results that residual wide-narrow-wide (hourglass) MLPs offer superior function approximation capabilities, we revisit the long-standing MLP shape convention in Transformer, challenging the necessity of the narrow-wide-narrow design. To study this, we develop a Transformer variant that replaces the conventional FFN with a deeper hourglass-shaped FFN, comprising a stack of hourglass sub-MLPs connected by residual pathways. We posit that a deeper but lighter hourglass FFN can serve as a competitive alternative to the conventional FFN, and that parameters saved by using a lighter hourglass FFN can be more effectively utilized, such as by enlarging model hidden dimensions under fixed budgets. We confirm these through empirical validations across model scales: hourglass FFNs outperform conventional FFNs up to 400M and achieve comparable performance at larger scales to 1B parameters; hourglass FFN variants with reduced FFN and increased attention parameters show consistent improvements over conventional configurations at matched budgets. Together, these findings shed new light on recent work and prompt a rethinking of the narrow-wide-narrow MLP convention and the balance between attention and FFN towards efficient and expressive modern language models.

</details>


### [88] [Completing Missing Annotation: Multi-Agent Debate for Accurate and Scalable Relevant Assessment for IR Benchmarks](https://arxiv.org/abs/2602.06526)
*Minjeong Ban,Jeonghwan Choi,Hyangsuk Min,Nicole Hee-Yeon Kim,Minseok Kim,Jae-Gil Lee,Hwanjun Song*

Main category: cs.CL

TL;DR: 提出DREAM框架，通过多轮辩论机制提升信息检索评估的准确性与可靠性，显著降低人类参与度至3.5%，同时发现29,824个遗漏的相关片段，构建更公平的BRIDGE基准数据集，推动检索与生成任务的协同优化。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索评估因基准数据集不完整（缺乏标注相关片段）而困难，传统人工标注成本高，虽有大模型和人机混合策略，但仍受大模型自信心过强及无效人机升级影响。

Method: 设计DREAM框架，基于对立初始立场与迭代相互批判的多轮辩论机制，通过共识驱动的辩论实现更精准标注与更可靠的不确定情况人机升级。

Result: 实现95.2%的标注准确率，仅需3.5%的人类参与；构建的BRIDGE数据集揭示29,824个缺失相关片段，改善评估偏差并支持更公平的检索器比较；重新评估表明未填补的空白不仅扭曲排序结果，还导致检索-生成错配。

Conclusion: DREAM框架有效提升了信息检索评估的精度与效率，所构建的BRIDGE数据集为后续研究提供了更可靠、更全面的基准，推动检索与生成系统协同优化。

Abstract: Information retrieval (IR) evaluation remains challenging due to incomplete IR benchmark datasets that contain unlabeled relevant chunks. While LLMs and LLM-human hybrid strategies reduce costly human effort, they remain prone to LLM overconfidence and ineffective AI-to-human escalation. To address this, we propose DREAM, a multi-round debate-based relevance assessment framework with LLM agents, built on opposing initial stances and iterative reciprocal critique. Through our agreement-based debate, it yields more accurate labeling for certain cases and more reliable AI-to-human escalation for uncertain ones, achieving 95.2% labeling accuracy with only 3.5% human involvement. Using DREAM, we build BRIDGE, a refined benchmark that mitigates evaluation bias and enables fairer retriever comparison by uncovering 29,824 missing relevant chunks. We then re-benchmark IR systems and extend evaluation to RAG, showing that unaddressed holes not only distort retriever rankings but also drive retrieval-generation misalignment. The relevance assessment framework is available at https: //github.com/DISL-Lab/DREAM-ICLR-26; and the BRIDGE dataset is available at https://github.com/DISL-Lab/BRIDGE-Benchmark.

</details>


### [89] [MTQE.en-he: Machine Translation Quality Estimation for English-Hebrew](https://arxiv.org/abs/2602.06546)
*Andy Rosenbaum,Assaf Siani,Ilan Kernerman*

Main category: cs.CL

TL;DR: 本文发布了首个公开的英-希伯来语机器翻译质量评估基准MTQE.en-he，包含959个英文段落及其对应的希伯来语机器翻译和三位专家的直接评分。通过对比ChatGPT提示、TransQuest和CometKiwi模型，发现三者集成性能优于最佳单模型（CometKiwi）6.4个百分点（Pearson）和5.6个百分点（Spearman）。微调实验表明，全模型更新易过拟合和分布崩溃，而参数高效方法（如LoRA、BitFit和仅微调分类头）训练稳定且提升2-3个百分点。该基准及实验结果将推动对这一低资源语言对的研究。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对英-希伯来语这一低资源语言对的公开机器翻译质量评估基准，限制了相关研究的发展。为此，本文旨在构建首个此类基准，并评估现有模型在该语言对上的表现，以促进未来研究。

Method: 构建包含959个英文段落及其希伯来语翻译与人工直接评分的基准数据集；对比多种质量评估模型（ChatGPT提示、TransQuest、CometKiwi）并进行集成；采用全模型微调与参数高效微调方法（LoRA、BitFit、FTHead）进行实验分析。

Result: 集成三个模型的性能优于最佳单模型（CometKiwi）6.4个百分点（Pearson）和5.6个百分点（Spearman）；参数高效微调方法（如LoRA、BitFit、FTHead）训练稳定，相比全模型微调提升2-3个百分点，而全模型更新存在过拟合和分布崩溃问题。

Conclusion: MTQE.en-he是首个公开的英-希伯来语机器翻译质量评估基准，其发布为该低资源语言对的研究提供了重要基础。实验表明，模型集成与参数高效微调策略显著提升了质量评估性能，可为未来相关工作提供参考。

Abstract: We release MTQE.en-he: to our knowledge, the first publicly available English-Hebrew benchmark for Machine Translation Quality Estimation. MTQE.en-he contains 959 English segments from WMT24++, each paired with a machine translation into Hebrew, and Direct Assessment scores of the translation quality annotated by three human experts. We benchmark ChatGPT prompting, TransQuest, and CometKiwi and show that ensembling the three models outperforms the best single model (CometKiwi) by 6.4 percentage points Pearson and 5.6 percentage points Spearman. Fine-tuning experiments with TransQuest and CometKiwi reveal that full-model updates are sensitive to overfitting and distribution collapse, yet parameter-efficient methods (LoRA, BitFit, and FTHead, i.e., fine-tuning only the classification head) train stably and yield improvements of 2-3 percentage points. MTQE.en-he and our experimental results enable future research on this under-resourced language pair.

</details>


### [90] [Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making](https://arxiv.org/abs/2602.06570)
*Baichuan-M3 Team,:,Chengfeng Dou,Fan Yang,Fei Li,Jiyuan Jia,Qiang Ju,Shuai Wang,Tianpeng Li,Xiangrong Zeng,Yijie Zhou,Hongda Zhang,Jinyang Tai,Linzhuang Sun,Peidong Guo,Yichuan Mo,Xiaochuan Wang,Hengfu Cui,Zhishou Zhang*

Main category: cs.CL

TL;DR: Baichuan-M3 是一个医学增强的大语言模型，旨在将医疗咨询从被动问答转变为主动的临床级决策支持。它通过专门的训练流程模拟医生的系统化工作流程，具备主动获取信息、长程推理和自适应幻觉抑制能力，在 HealthBench、HealthBench-Hallu 和 ScanBench 等基准测试中表现优于 GPT-5.2，已公开发布于 Hugging Face。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型在开放式问诊中存在局限，无法有效处理模糊信息、缺乏长期推理能力且易产生幻觉，难以满足临床实际需求，因此需要构建更接近真实医生行为的主动式决策支持系统。

Method: 采用专用训练管道，使模型学习医生的系统性诊疗流程，包括主动追问以消除歧义、整合分散证据进行长期推理，并动态抑制幻觉以保障事实准确性。

Result: 在 HealthBench、HealthBench-Hallu 与 ScanBench 基准测试中均达到领先水平，尤其在临床咨询、建议生成与安全性方面显著超越 GPT-5.2，验证了其临床应用潜力。

Conclusion: Baichuan-M3 成功实现了从被动应答到主动决策支持的范式转变，具备高可靠性与临床实用性，为智能医疗系统的发展提供了新方向。

Abstract: We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3.

</details>


### [91] [Do Prompts Guarantee Safety? Mitigating Toxicity from LLM Generations through Subspace Intervention](https://arxiv.org/abs/2602.06623)
*Himanshu Singh,Ziwei Xu,A. V. Subramanyam,Mohan Kankanhalli*

Main category: cs.CL

TL;DR: 本文提出一种针对大语言模型中隐藏毒性模式的定向子空间干预策略，能够在不显著影响生成流畅性的情况下有效降低毒性内容。该方法在RealToxicityPrompts数据集上表现优异，相较于现有基线方法，毒性降低8-20%，且推理开销小。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽强大，但易生成有害或有毒内容，尤其在看似无害的提示下。现有检测方法难以捕捉上下文相关的细微毒性，且安全与文本连贯性之间存在权衡。因此亟需一种既能精准抑制毒性、又不影响生成质量的方法。

Method: 提出一种基于模型内部表示的定向子空间干预策略，通过识别并抑制潜在的毒性特征子空间，实现对隐含毒性模式的有效控制，同时保持生成内容的流畅性。

Result: 在RealToxicityPrompts数据集上，该方法显著降低了毒性输出，相比现有基线减少8-20%；在多个大语言模型上均实现高毒性抑制效果，且对生成流畅性影响极小。

Conclusion: 所提方法能有效抑制大语言模型中的隐藏毒性模式，在保障生成质量的前提下实现强安全性，优于现有主流净化技术。

Abstract: Large Language Models (LLMs) are powerful text generators, yet they can produce toxic or harmful content even when given seemingly harmless prompts. This presents a serious safety challenge and can cause real-world harm. Toxicity is often subtle and context-dependent, making it difficult to detect at the token level or through coarse sentence-level signals. Moreover, efforts to mitigate toxicity often face a trade-off between safety and the coherence, or fluency of the generated text. In this work, we present a targeted subspace intervention strategy for identifying and suppressing hidden toxic patterns from underlying model representations, while preserving overall ability to generate safe fluent content. On the RealToxicityPrompts, our method achieves strong mitigation performance compared to existing baselines, with minimal impact on inference complexity. Across multiple LLMs, our approach reduces toxicity of state-of-the-art detoxification systems by 8-20%, while maintaining comparable fluency. Through extensive quantitative and qualitative analyses, we show that our approach achieves effective toxicity reduction without impairing generative performance, consistently outperforming existing baselines.

</details>


### [92] [FairJudge: An Adaptive, Debiased, and Consistent LLM-as-a-Judge](https://arxiv.org/abs/2602.06625)
*Bo Yang,Lanfei Feng,Yunkui Chen,Yu Zhang,Xiao Xu,Shijian Li*

Main category: cs.CL

TL;DR: 提出FairJudge，一种自适应、去偏见且一致的LLM-as-a-Judge系统，通过将评判行为建模为可学习和正则化的策略，解决现有系统在适应性、偏差和评估一致性方面的局限。利用高信息密度数据集和渐进式训练范式（SFT-DPO-GRPO），显著提升评估一致性与准确性，并优于更大规模指令微调模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-Judge系统存在适应性差、受非语义线索影响的系统性偏差以及跨评估模式不一致的问题，亟需更鲁棒、可调控的评价机制。

Method: 构建高信息密度的评判数据集，引入与评价行为对齐的监督信号；采用课程学习风格的SFT-DPO-GRPO训练流程，逐步优化评分规则遵循、去偏见与跨模式一致性，防止灾难性遗忘。

Result: 在多个内部及公开基准测试中，FairJudge显著提升评估一致性与F1分数，降低非语义偏差，性能优于更大规模的指令微调大模型。所有资源将在录用后公开。

Conclusion: FairJudge通过建模可学习的评判策略，有效克服了现有LLM-as-a-Judge系统的三大核心缺陷，为高质量自动化评估提供了新范式。

Abstract: Existing LLM-as-a-Judge systems suffer from three fundamental limitations: limited adaptivity to task- and domain-specific evaluation criteria, systematic biases driven by non-semantic cues such as position, length, format, and model provenance, and evaluation inconsistency that leads to contradictory judgments across different evaluation modes (e.g., pointwise versus pairwise). To address these issues, we propose FairJudge, an adaptive, debiased, and consistent LLM-as-a-Judge. Unlike prior approaches that treat the judge as a static evaluator, FairJudge models judging behavior itself as a learnable and regularized policy. From a data-centric perspective, we construct a high-information-density judging dataset that explicitly injects supervision signals aligned with evaluation behavior. Building on this dataset, we adopt a curriculum-style SFT-DPO-GRPO training paradigm that progressively aligns rubric adherence, bias mitigation, and cross-mode consistency, while avoiding catastrophic forgetting. Experimental results on multiple internal and public benchmarks show that FairJudge consistently improves agreement and F1, reduces non-semantic biases, and outperforms substantially larger instruction-tuned LLMs. All resources will be publicly released after acceptance to facilitate future research.

</details>


### [93] [Reading Between the Waves: Robust Topic Segmentation Using Inter-Sentence Audio Features](https://arxiv.org/abs/2602.06647)
*Steffen Freisinger,Philipp Seeberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 本文提出一种多模态方法，通过微调文本编码器和孪生音频编码器，利用语音特征进行话题分割，在大规模YouTube数据集上显著优于仅使用文本或传统多模态基线。该模型对ASR噪声更具鲁棒性，并在葡萄牙语、德语和英语三个额外数据集上表现优于更大的纯文本基线，证明了学习到的声学特征在鲁棒话题分割中的价值。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用声学特征，限制了话题分割性能，因此需要结合文本与音频信息以提升效果和鲁棒性。

Method: 提出一种多模态框架，同时微调文本编码器与孪生音频编码器，捕捉句子边界附近的声学线索。

Result: 在大规模YouTube数据集上取得显著性能提升；对ASR噪声更鲁棒；在三种语言（葡萄牙语、德语、英语）数据集上超越更大规模的纯文本基线。

Conclusion: 结合学习到的声学特征能有效提升话题分割的准确性与鲁棒性，验证了多模态方法在复杂语音内容处理中的优势。

Abstract: Spoken content, such as online videos and podcasts, often spans multiple topics, which makes automatic topic segmentation essential for user navigation and downstream applications. However, current methods do not fully leverage acoustic features, leaving room for improvement. We propose a multi-modal approach that fine-tunes both a text encoder and a Siamese audio encoder, capturing acoustic cues around sentence boundaries. Experiments on a large-scale dataset of YouTube videos show substantial gains over text-only and multi-modal baselines. Our model also proves more resilient to ASR noise and outperforms a larger text-only baseline on three additional datasets in Portuguese, German, and English, underscoring the value of learned acoustic features for robust topic segmentation.

</details>


### [94] [Beyond Static Alignment: Hierarchical Policy Control for LLM Safety via Risk-Aware Chain-of-Thought](https://arxiv.org/abs/2602.06650)
*Jianfeng Si,Lin Sun,Weihong Lin,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: PACT 是一种通过显式、风险感知推理实现动态安全控制的框架，旨在解决大语言模型中的安全与有用性权衡问题。它采用分层策略架构，包含不可绕过的全局安全策略和用户自定义的领域特定策略，将安全决策分解为分类-执行的结构化路径，提升透明度与可控性。实验表明，PACT 在全局安全评估中接近最先进水平，在用户特定策略评估中表现出最佳可控性，有效缓解了安全与帮助性之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 大语言模型面临安全与有用性之间的根本性权衡，现有静态、统一的安全策略缺乏运行时可调控性，难以适应多样化应用场景，导致模型可能过度拒绝无害请求或未能充分约束有害内容。

Method: 提出 PACT 框架，采用分层策略架构：不可绕过的全局安全策略设定关键风险边界（如儿童安全、暴力极端主义），用户可自定义非全局风险类别并指定标签到行为的映射，通过结构化的分类-执行路径实现安全决策，增强透明性与可控性。

Result: 在全局安全评估中，PACT 达到接近最先进的安全性能；在用户特定策略评估中，展现出最佳可控性，有效缓解了安全与帮助性之间的权衡问题。

Conclusion: PACT 通过动态、可配置的安全控制机制，实现了对大语言模型在复杂场景下的安全与有用性平衡，为可解释、可调控的安全对齐提供了新范式，并将开源相关模型、数据与评估协议以促进可复现研究。

Abstract: Large Language Models (LLMs) face a fundamental safety-helpfulness trade-off due to static, one-size-fits-all safety policies that lack runtime controllabilityxf, making it difficult to tailor responses to diverse application needs. %As a result, models may over-refuse benign requests or under-constrain harmful ones. We present \textbf{PACT} (Prompt-configured Action via Chain-of-Thought), a framework for dynamic safety control through explicit, risk-aware reasoning. PACT operates under a hierarchical policy architecture: a non-overridable global safety policy establishes immutable boundaries for critical risks (e.g., child safety, violent extremism), while user-defined policies can introduce domain-specific (non-global) risk categories and specify label-to-action behaviors to improve utility in real-world deployment settings. The framework decomposes safety decisions into structured Classify$\rightarrow$Act paths that route queries to the appropriate action (comply, guide, or reject) and render the decision-making process transparent.
  Extensive experiments demonstrate that PACT achieves near state-of-the-art safety performance under global policy evaluation while attaining the best controllability under user-specific policy evaluation, effectively mitigating the safety-helpfulness trade-off. We will release the PACT model suite, training data, and evaluation protocols to facilitate reproducible research in controllable safety alignment.

</details>


### [95] [Evaluating Prompt Engineering Strategies for Sentiment Control in AI-Generated Texts](https://arxiv.org/abs/2602.06692)
*Kerstin Sahler,Sophie Jentzsch*

Main category: cs.CL

TL;DR: 该研究探讨了通过提示工程（prompt engineering）控制大型语言模型（LLM）生成文本情感的可行性，发现其在数据受限环境下比微调更具成本效益和实用性。少样本提示（Few-Shot prompting）结合人工编写示例效果最佳，能有效引导情绪表达。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽具备强大能力，但在有意识地控制生成内容的情感方面仍面临挑战，亟需一种资源节省且易于实施的方法来实现情感适应性人工智能。

Method: 采用埃克曼六种基本情绪（如喜悦、厌恶）作为情感类别，对比零样本提示、思维链提示（Chain-of-Thought）与微调等方法，使用gpt-3.5-turbo模型进行实验分析。

Result: 提示工程能有效引导LLM生成具有特定情感倾向的文本，其中少样本提示结合人工示例表现最优，显著优于其他提示方式，在数据有限时尤为适用。

Conclusion: 提示工程是一种高效、低成本的情感调控手段，为构建情绪自适应的人工智能系统提供了可行路径，尤其适合资源受限场景。

Abstract: The groundbreaking capabilities of Large Language Models (LLMs) offer new opportunities for enhancing human-computer interaction through emotion-adaptive Artificial Intelligence (AI). However, deliberately controlling the sentiment in these systems remains challenging. The present study investigates the potential of prompt engineering for controlling sentiment in LLM-generated text, providing a resource-sensitive and accessible alternative to existing methods. Using Ekman's six basic emotions (e.g., joy, disgust), we examine various prompting techniques, including Zero-Shot and Chain-of-Thought prompting using gpt-3.5-turbo, and compare it to fine-tuning. Our results indicate that prompt engineering effectively steers emotions in AI-generated texts, offering a practical and cost-effective alternative to fine-tuning, especially in data-constrained settings. In this regard, Few-Shot prompting with human-written examples was the most effective among other techniques, likely due to the additional task-specific guidance. The findings contribute valuable insights towards developing emotion-adaptive AI systems.

</details>


### [96] [R-Align: Enhancing Generative Reward Models through Rationale-Centric Meta-Judging](https://arxiv.org/abs/2602.06763)
*Yanlin Lai,Mitt Huang,Hangyu Guo,Xiangfeng Wang,Haodong Li,Shaoxiong Zhan,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Chun Yuan,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: 该论文提出一种名为R-Align的新方法，旨在提升生成式奖励模型（GenRM）在强化学习中的人类反馈（RLHF）中的推理一致性。研究发现，仅依赖结果标签的训练会导致推理质量无法评估，而推理一致性（即推理与参考判断的一致性）对下游任务表现具有更强预测力。通过引入‘虚假正确’（S-Corr）指标衡量不一致但正确的推理，实验证明高S-Corr会导致策略退化。R-Align通过引入真实判断并显式监督推理对齐，显著降低S-Corr，并在多个任务上提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式奖励模型（GenRM）在训练和评估中仅依赖最终标签，忽视了推理过程的质量，导致模型可能做出看似正确但逻辑错误的判断。这种推理不一致会严重影响后续强化学习中的策略表现。因此需要一种机制来衡量并提升推理一致性。

Method: 提出一种名为R-Align的方法，通过在训练中引入黄金判断（gold judgments），并设计损失函数显式约束生成的推理与参考推理的一致性，从而提升推理质量。同时定义了‘虚假正确’（S-Corr）作为衡量指标，用于评估推理与真实判断之间的偏差。

Result: R-Align显著降低了多个基准测试上的S-Corr值，且在STEM、编程、指令遵循和通用任务中均带来了稳定的性能提升，表明推理一致性对模型整体表现有重要影响。

Conclusion: 推理一致性是影响大语言模型在人类反馈强化学习中表现的关键因素。通过显式对齐生成推理与真实判断，R-Align有效提升了模型鲁棒性与泛化能力，为未来生成式奖励模型的设计提供了新方向。

Abstract: Reinforcement Learning from Human Feedback (RLHF) remains indispensable for aligning large language models (LLMs) in subjective domains. To enhance robustness, recent work shifts toward Generative Reward Models (GenRMs) that generate rationales before predicting preferences. Yet in GenRM training and evaluation, practice remains outcome-label-only, leaving reasoning quality unchecked. We show that reasoning fidelity-the consistency between a GenRM's preference decision and reference decision rationales-is highly predictive of downstream RLHF outcomes, beyond standard label accuracy. Specifically, we repurpose existing reward-model benchmarks to compute Spurious Correctness (S-Corr)-the fraction of label-correct decisions with rationales misaligned with golden judgments. Our empirical evaluation reveals substantial S-Corr even for competitive GenRMs, and higher S-Corr is associated with policy degeneration under optimization. To improve fidelity, we propose Rationale-Centric Alignment, R-Align, which augments training with gold judgments and explicitly supervises rationale alignment. R-Align reduces S-Corr on RM benchmarks and yields consistent gains in actor performance across STEM, coding, instruction following, and general tasks.

</details>


### [97] [Generating Data-Driven Reasoning Rubrics for Domain-Adaptive Reward Modeling](https://arxiv.org/abs/2602.06795)
*Kate Sanders,Nathaniel Weir,Sapana Chaudhary,Kaj Bostrom,Huzefa Rangwala*

Main category: cs.CL

TL;DR: 本文提出一种数据驱动的方法，自动构建细粒度的推理错误分类体系（即“评分标准”），以增强大语言模型在未见推理轨迹中的错误检测能力。实验表明，利用这些评分标准的分类方法在编码、数学和化学工程等技术领域中表现出色，相比基线方法显著提升错误识别率。该方法可构建更强的基于大语言模型作为评判者的奖励函数，用于强化学习训练推理模型，使模型在困难领域任务上的准确率比仅使用通用大语言模型评判者训练的模型提高45%，且仅需20%的黄金标签数量即可接近使用可验证奖励训练模型的性能。该研究将评分标准的应用从评估模型行为质量扩展到评估模型在复杂技术任务中的定量正确性，从而在无需大量黄金标签的情况下，实现对复杂问题的有效训练。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长输出、专业知识要求高的领域以及无明确可验证奖励的问题中，难以可靠识别推理过程中的错误，限制了其在推理输出验证中的应用。因此，需要一种有效方法来提升模型对推理错误的检测能力，尤其是在缺乏大量标注数据的情况下。

Method: 提出一种数据驱动方法，自动构建高度细化的推理错误分类体系（即评分标准）。通过该分类体系，设计分类模型以识别推理过程中的错误，并将其应用于构建更精确的大语言模型作为评判者的奖励函数，用于强化学习训练推理模型。

Result: 实验结果显示，基于该评分标准的奖励函数可使模型在复杂技术任务上的准确率比传统大语言模型评判方式提升45%，且仅需20%的黄金标签数量即可达到接近使用完整黄金标签训练模型的性能水平。

Conclusion: 本研究成功将奖励评分标准从定性评估扩展至定量正确性评估，使得在缺乏大规模黄金标签的情况下，仍能有效训练解决复杂技术问题的大语言模型，显著降低数据成本并提升模型性能。

Abstract: An impediment to using Large Language Models (LLMs) for reasoning output verification is that LLMs struggle to reliably identify errors in thinking traces, particularly in long outputs, domains requiring expert knowledge, and problems without verifiable rewards. We propose a data-driven approach to automatically construct highly granular reasoning error taxonomies to enhance LLM-driven error detection on unseen reasoning traces. Our findings indicate that classification approaches that leverage these error taxonomies, or "rubrics", demonstrate strong error identification compared to baseline methods in technical domains like coding, math, and chemical engineering. These rubrics can be used to build stronger LLM-as-judge reward functions for reasoning model training via reinforcement learning. Experimental results show that these rewards have the potential to improve models' task accuracy on difficult domains over models trained by general LLMs-as-judges by +45%, and approach performance of models trained by verifiable rewards while using as little as 20% as many gold labels. Through our approach, we extend the usage of reward rubrics from assessing qualitative model behavior to assessing quantitative model correctness on tasks typically learned via RLVR rewards. This extension opens the door for teaching models to solve complex technical problems without a full dataset of gold labels, which are often highly costly to procure.

</details>


### [98] [Visual Word Sense Disambiguation with CLIP through Dual-Channel Text Prompting and Image Augmentations](https://arxiv.org/abs/2602.06799)
*Shamik Bhattacharya,Daniel Perkins,Yaren Dogan,Vineeth Konjeti,Sudarshan Srinivasan,Edmon Begoli*

Main category: cs.CL

TL;DR: 本文提出了一种可解释的视觉词义消歧（VWSD）框架，利用CLIP将模糊语言与候选图像映射到共享多模态空间。通过双通道提示（语义与图像提示）增强文本嵌入，并结合测试时增强优化图像嵌入，最终基于余弦相似度选择最匹配的图像。在SemEval-2023 VWSD数据集上，该方法显著提升MRR和命中率；消融实验表明双通道提示性能优越且低延迟，而激进图像增强收益有限。此外，外部噪声信号会降低语义特异性，验证了精确、对齐CLIP的提示的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在自然语言理解中因词汇歧义带来的挑战，探索如何通过视觉域有效消歧。

Method: 使用CLIP将语言与图像投影至共享多模态空间；采用双通道提示（语义与照片提示）增强文本嵌入；通过测试时增强优化图像嵌入；利用余弦相似度匹配最佳图像。

Result: 在SemEval-2023 VWSD数据集上，MRR从0.7227提升至0.7590，命中率从0.5810提升至0.6220；双通道提示表现优异且低延迟，图像增强效果有限；外部噪声信号削弱语义特异性，表明精确提示更优。

Conclusion: 精确、与CLIP对齐的提示在视觉词义消歧中具有更强有效性，双通道提示策略可实现高效且鲁棒的消歧性能，而过度依赖外部信息或激进增强可能引入噪声并降低表现。

Abstract: Ambiguity poses persistent challenges in natural language understanding for large language models (LLMs). To better understand how lexical ambiguity can be resolved through the visual domain, we develop an interpretable Visual Word Sense Disambiguation (VWSD) framework. The model leverages CLIP to project ambiguous language and candidate images into a shared multimodal space. We enrich textual embeddings using a dual-channel ensemble of semantic and photo-based prompts with WordNet synonyms, while image embeddings are refined through robust test-time augmentations. We then use cosine similarity to determine the image that best aligns with the ambiguous text. When evaluated on the SemEval-2023 VWSD dataset, enriching the embeddings raises the MRR from 0.7227 to 0.7590 and the Hit Rate from 0.5810 to 0.6220. Ablation studies reveal that dual-channel prompting provides strong, low-latency performance, whereas aggressive image augmentation yields only marginal gains. Additional experiments with WordNet definitions and multilingual prompt ensembles further suggest that noisy external signals tend to dilute semantic specificity, reinforcing the effectiveness of precise, CLIP-aligned prompts for visual word sense disambiguation.

</details>


### [99] [The Representational Geometry of Number](https://arxiv.org/abs/2602.06843)
*Zhimin Hu,Lanhao Niu,Sashank Varma*

Main category: cs.CL

TL;DR: 本文探讨了概念表征是否在共享的几何空间中收敛以支持泛化，或在正交子空间中发散以减少任务干扰。研究以数字概念为测试案例，利用语言模型作为高维计算基底，发现数字表征在不同任务间保持稳定的相对关系结构。尽管任务特定的表征位于不同的子空间，且低层次特征（如大小、奇偶性）沿可分离的线性方向编码，但这些子空间可通过线性映射相互转换，表明表征虽位置不同，却共享关系结构。这揭示了语言模型如何在保持概念表征的共享结构与功能灵活性之间取得平衡，理解源于对共享关系结构进行任务特异性变换。


<details>
  <summary>Details</summary>
Motivation: 认知科学中关于概念表征是共享一个统一的几何空间还是在独立子空间中分化以避免任务干扰的问题长期存在争议。现有研究虽提供两者证据，但缺乏机制解释来说明二者如何共存并随任务变化。本文旨在填补这一空白，揭示语言模型中概念表征如何既保持共享关系结构又具备任务适应性。

Method: 以数字概念为实验对象，使用大型语言模型作为高维计算平台，通过分析不同任务下数字表征的嵌入空间结构，考察其几何关系和子空间分布。采用线性可分性分析、子空间投影与线性变换验证等方法，检验任务间表征的可转换性与关系稳定性。

Result: 数字表征在不同任务中虽然分布在不同的子空间，但其内在的几何关系（如大小、奇偶性的相对关系）保持稳定。低阶特征如数值大小和奇偶性在可分离的线性方向上编码，而不同任务间的子空间可通过线性映射有效转换，表明表征共享深层的相对结构。

Conclusion: 概念表征的共享不在于表征本身的位置，而在于它们之间的几何关系。语言模型通过在共享的相对结构基础上施加任务特异的变换，实现了表征的通用性与灵活性的统一。这一机制为理解概念学习与跨任务泛化提供了新的理论视角。

Abstract: A central question in cognitive science is whether conceptual representations converge onto a shared manifold to support generalization, or diverge into orthogonal subspaces to minimize task interference. While prior work has discovered evidence for both, a mechanistic account of how these properties coexist and transform across tasks remains elusive. We propose that representational sharing lies not in the concepts themselves, but in the geometric relations between them. Using number concepts as a testbed and language models as high-dimensional computational substrates, we show that number representations preserve a stable relational structure across tasks. Task-specific representations are embedded in distinct subspaces, with low-level features like magnitude and parity encoded along separable linear directions. Crucially, we find that these subspaces are largely transformable into one another via linear mappings, indicating that representations share relational structure despite being located in distinct subspaces. Together, these results provide a mechanistic lens of how language models balance the shared structure of number representation with functional flexibility. It suggests that understanding arises when task-specific transformations are applied to a shared underlying relational structure of conceptual representations.

</details>


### [100] [SEMA: Simple yet Effective Learning for Multi-Turn Jailbreak Attacks](https://arxiv.org/abs/2602.06854)
*Mingqian Feng,Xiaodong Liu,Weiwei Yang,Jialin Song,Xuekai Zhu,Chenliang Xu,Jianfeng Gao*

Main category: cs.CL

TL;DR: SEMA提出一种无需依赖外部数据或现有策略的多轮越狱攻击框架，通过自填充自调优和意图漂移感知奖励的强化学习，实现高效、稳定且可迁移的多轮攻击，在多个数据集和模型上达到当前最优攻击成功率（平均80.1% ASR@1），显著超越单轮及已有模板化多轮方法。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击在多轮场景下受限于探索复杂性和意图漂移问题，难以有效生成持续有效的对抗性提示，亟需一种更真实、高效的多轮攻击方法以全面评估大模型安全性。

Method: SEMA包含两个阶段：第一阶段为自填充自调优，通过少量前缀自动生成非拒绝性、结构良好的多轮对抗提示进行微调，稳定后续训练；第二阶段采用基于意图对齐、合规风险与细节程度的意图漂移感知奖励，结合强化学习训练攻击者，实现目标一致的多轮越狱。整个过程采用开环攻击机制，不依赖目标反馈，统一单轮与多轮设置，降低探索复杂度。

Result: SEMA在多数据集、多受害者模型及越狱评判标准下均取得最佳攻击成功率，平均达80.1% ASR@1（AdvBench），相比最先进方法提升33.9%；具备紧凑性、可复现性与跨模型迁移能力，适用于自动化红队测试，有效暴露并定位大模型安全缺陷。

Conclusion: SEMA是一种高效、通用且可扩展的多轮越狱攻击框架，能够提供更强、更真实的模型安全压力测试，推动大语言模型安全评估向更贴近实际威胁的方向发展。

Abstract: Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average $80.1\%$ ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA.

</details>


### [101] [Halluverse-M^3: A multitask multilingual benchmark for hallucination in LLMs](https://arxiv.org/abs/2602.06920)
*Samir Abdaljalil,Parichit Sharma,Erchin Serpedin,Hasan Kurban*

Main category: cs.CL

TL;DR: Introduces Halluverse-M^3, a multilingual, multi-task dataset for analyzing hallucinations in LLMs across four languages (English, Arabic, Hindi, Turkish) and two tasks (QA, dialogue summarization), with fine-grained distinction among entity-, relation-, and sentence-level hallucinations. Evaluated diverse models showing that QA is easier than summarization, sentence-level hallucinations remain hard, and performance drops in lower-resource languages like Hindi.


<details>
  <summary>Details</summary>
Motivation: To address the lack of systematic understanding of hallucinations in multilingual and generative settings, especially beyond English-centric benchmarks, by providing a controlled, human-validated dataset for fine-grained analysis.

Method: Constructed Halluverse-M^3 via controlled editing to generate hallucinated outputs, validated by human annotators; used the dataset to evaluate open-source and proprietary models on hallucination detection across languages, tasks, and hallucination types.

Result: Question answering is easier than dialogue summarization; sentence-level hallucinations are hardest to detect even for top models; performance decreases in lower-resource languages, with Hindi showing the lowest detection accuracy.

Conclusion: Halluverse-M^3 offers a realistic and challenging benchmark for studying hallucinations in multilingual, multi-task scenarios and is released to advance research in hallucination detection and mitigation.

Abstract: Hallucinations in large language models remain a persistent challenge, particularly in multilingual and generative settings where factual consistency is difficult to maintain. While recent models show strong performance on English-centric benchmarks, their behavior across languages, tasks, and hallucination types is not yet well understood. In this work, we introduce Halluverse-M^3, a dataset designed to enable systematic analysis of hallucinations across multiple languages, multiple generation tasks, and multiple hallucination categories. Halluverse-M^3 covers four languages, English, Arabic, Hindi, and Turkish, and supports two generation tasks: question answering and dialogue summarization. The dataset explicitly distinguishes between entity-level, relation-level, and sentence-level hallucinations. Hallucinated outputs are constructed through a controlled editing process and validated by human annotators, ensuring clear alignment between original content and hallucinated generations. Using this dataset, we evaluate a diverse set of contemporary open-source and proprietary language models on fine-grained hallucination detection. Our results show that question answering is consistently easier than dialogue summarization, while sentence-level hallucinations remain challenging even for the strongest models. Performance is highest in English and degrades in lower-resource languages, with Hindi exhibiting the lowest detection accuracy. Overall, Halluverse-M^3 provides a realistic and challenging benchmark for studying hallucinations in multilingual, multi-task settings. We release the dataset to support future research on hallucination detection and mitigation\footnote{https://huggingface.co/datasets/sabdalja/HalluVerse-M3}.

</details>


### [102] [Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay](https://arxiv.org/abs/2602.06942)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 本文首次系统性地研究了土耳其语的子词分词，提出一个“子词宣言”，联合调整词汇量与训练语料规模，比较WordPiece、形态层级和字符基线等多种分词器家族，在相同参数预算下进行评估，并涵盖语义、句法和形态敏感任务。引入形态感知诊断工具包，提供细粒度的边界级微/宏F1、词素原子性与表面边界命中率分离、过/欠分割指数、字符/词编辑距离、延续率及词缀类型覆盖等指标。贡献包括：(i) 词汇-语料-性能三元关系的系统研究；(ii) 统一的形态感知评估框架；(iii) 在控制条件下揭示字符级与形态级分词的优势场景；(iv) 开源评估代码、分词管道与模型。该工作为构建形态丰富语言的有效分词器提供可操作指导，并建立可复现的研究基础。


<details>
  <summary>Details</summary>
Motivation: 在形态丰富的语言（如土耳其语）中，子词分词面临词汇效率与形态保真度之间的权衡。现有研究缺乏对分词器训练语料与词汇量的系统控制，诊断手段粗略，下游任务评估范围有限。因此亟需一个全面、严谨的分词研究框架。

Method: 构建“子词宣言”实验体系，系统变化词汇量与训练语料规模，对比多种分词器家族（WordPiece、形态层级、字符基线），在统一参数预算下评估，并引入形态感知诊断工具包，从边界级微观到宏观层面分析分词表现。

Result: 揭示了词汇量与训练数据大小之间的耦合效应；验证了形态层级分词在特定任务中的优势；发现字符级分词在处理罕见词时更具鲁棒性；建立了从内在诊断到外在任务性能的映射关系。

Conclusion: 本研究提供了针对形态丰富语言的子词分词设计的系统性指导，证明了形态感知诊断的重要性，并通过开源资源推动后续研究的可复现性。

Abstract: Tokenization is a pivotal design choice for neural language modeling in morphologically rich languages (MRLs) such as Turkish, where productive agglutination challenges both vocabulary efficiency and morphological fidelity. Prior studies have explored tokenizer families and vocabulary sizes but typically (i) vary vocabulary without systematically controlling the tokenizer's training corpus, (ii) provide limited intrinsic diagnostics, and (iii) evaluate a narrow slice of downstream tasks. We present the first comprehensive, principled study of Turkish subword tokenization; a "subwords manifest", that jointly varies vocabulary size and tokenizer training corpus size (data and vocabulary coupling), compares multiple tokenizer families under matched parameter budgets (WordPiece, morphology level, and character baselines), and evaluates across semantic (NLI, STS, sentiment analysis, NER), syntactic (POS, dependency parsing), and morphology-sensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology-aware diagnostic toolkit that goes beyond coarse aggregates to boundary-level micro/macro F1, decoupled lemma atomicity vs. surface boundary hits, over/under-segmentation indices, character/word edit distances (CER/WER), continuation rates, and affix-type coverage and token-level atomicity. Our contributions are fourfold: (i) a systematic investigation of the vocabulary-corpus-success triad; (ii) a unified, morphology-aware evaluation framework linking intrinsic diagnostics to extrinsic outcomes; (iii) controlled comparisons identifying when character-level and morphology-level tokenization pay off; and (iv) an open-source release of evaluation code, tokenizer pipelines, and models. As the first work of its kind, this "subwords manifest" delivers actionable guidance for building effective tokenizers in MRLs and establishes a reproducible foundation for future research.

</details>


### [103] [DAWN: Dependency-Aware Fast Inference for Diffusion LLMs](https://arxiv.org/abs/2602.06953)
*Lizhuo Luo,Zhuoran Shi,Jiajun Luo,Zhi Wang,Shen Ren,Wenya Wang,Tianwei Zhang*

Main category: cs.CL

TL;DR: DAWN提出了一种无需训练的、依赖感知的解码方法，用于加速扩散型大语言模型（dLLMs）的推理。通过构建依赖图，选择更可靠的并行解码位置，有效缓解了并行解码中因忽略词元间语义耦合而导致的质量下降问题，在保持生成质量的同时实现1.80-8.06倍的加速。


<details>
  <summary>Details</summary>
Motivation: 现有dLLM推理方法受限于质量与速度的权衡，采用保守的并行策略，未能充分挖掘效率潜力；核心挑战在于并行解码假设各位置可独立填充，但实际中词元间存在语义耦合，正确选择会影响其他位置的有效性。因此需要建模这些依赖关系以提升并行解码的可靠性与效率。

Method: DAWN通过构建依赖图来识别词元间的依赖关系，并基于两个关键观察：(1) 某些位置被遮蔽后，其依赖的位置变得更具可靠性；(2) 同时遮蔽强耦合且不确定的位置会导致错误。据此，算法在每轮迭代中选择更可靠的未遮蔽位置进行并行解码，从而在保证质量的前提下最大化并行度。

Result: 在多个模型和数据集上的实验表明，DAWN相比基线方法实现了1.80至8.06倍的推理加速，同时生成质量几乎无损。代码已开源。

Conclusion: DAWN是一种高效、无需训练的依赖感知解码方法，能够显著提升dLLM推理速度，同时维持高质量输出，为未来高效大模型推理提供了新思路。

Abstract: Diffusion large language models (dLLMs) have shown advantages in text generation, particularly due to their inherent ability for parallel decoding. However, constrained by the quality--speed trade-off, existing inference solutions adopt conservative parallel strategies, leaving substantial efficiency potential underexplored. A core challenge is that parallel decoding assumes each position can be filled independently, but tokens are often semantically coupled. Thus, the correct choice at one position constrains valid choices at others. Without modeling these inter-token dependencies, parallel strategies produce deteriorated outputs. Motivated by this insight, we propose DAWN, a training-free, dependency-aware decoding method for fast dLLM inference. DAWN extracts token dependencies and leverages two key motivations: (1) positions dependent on unmasked certain positions become more reliable, (2) simultaneously unmasking strongly coupled uncertain positions induces errors. Given those findings, DAWN leverages a dependency graph to select more reliable unmasking positions at each iteration, achieving high parallelism with negligible loss in generation quality. Extensive experiments across multiple models and datasets demonstrate that DAWN speedups the inference by 1.80-8.06x over baselines while preserving the generation quality. Code is released at https://github.com/lizhuo-luo/DAWN.

</details>


### [104] [InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning](https://arxiv.org/abs/2602.06960)
*Yuchen Yan,Liang Jiang,Jin Jiang,Shuaicheng Li,Zujie Wen,Zhiqiang Zhang,Jun Zhou,Jian Shao,Yueting Zhuang,Yongliang Shen*

Main category: cs.CL

TL;DR: InftyThink+ 是一种基于强化学习的端到端框架，通过模型控制的迭代边界和显式总结优化整个推理过程。它采用两阶段训练：监督预热后进行轨迹级强化学习，使模型学会战略性地决定何时总结、保留什么内容以及如何继续推理。实验表明，InftyThink+ 在 AIME24 上提升准确率 21%，优于传统长链思维强化学习，并在分布外基准上表现更优；同时显著降低推理延迟并加速训练，实现更高效率与更强性能的统一。


<details>
  <summary>Details</summary>
Motivation: 现有迭代推理方法依赖监督学习或固定启发式规则，无法优化总结时机、内容保留和推理恢复策略，导致性能受限。为解决推理成本高、上下文长度限制及中间信息丢失等问题，需构建一个能自主决策的智能推理框架。

Method: 提出 InftyThink+ 框架，结合模型控制的迭代边界与显式总结机制，采用两阶段训练：第一阶段使用监督学习进行冷启动初始化；第二阶段通过轨迹级强化学习优化整体推理路径，实现对总结时机、内容选择和后续推理的联合优化。

Result: 在 DeepSeek-R1-Distill-Qwen-1.5B 模型上，InftyThink+ 在 AIME24 上准确率提升 21%，显著优于传统长链思维强化学习方法；在分布外任务中泛化能力更强；推理延迟大幅下降，强化学习训练速度加快，综合表现更优。

Conclusion: InftyThink+ 通过端到端强化学习实现了对迭代推理全过程的战略性优化，不仅提升了推理准确率，还显著改善了效率与泛化能力，是高效、智能推理的新范式。

Abstract: Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization. InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning, enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [105] [NanoNet: Parameter-Efficient Learning with Label-Scarce Supervision for Lightweight Text Mining Model](https://arxiv.org/abs/2602.06093)
*Qianren Mao,Yashuo Luo,Ziqi Qin,Junnan Liu,Weifeng Jiang,Zhijun Chen,Zhuoran Li,Likang Xiao,Chuou Xu,Qili Zhang,Hanwen Hao,Jingzheng Li,Chunghua Lin,Jianxin Li,Philip S. Yu*

Main category: cs.LG

TL;DR: 提出NanoNet框架，通过在线知识蒸馏和相互学习正则化，在有限标注数据下实现参数高效学习，降低训练成本与监督需求，构建轻量级文本挖掘模型。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级半监督学习方法计算开销大且易陷入局部最优，难以找到最佳解，因此需要探索低代价的文本挖掘场景：有限标注、轻量微调和快速推理小模型。

Method: 采用在线知识蒸馏生成多个小模型，并通过相互学习正则化提升性能；全程使用参数高效学习策略，减少训练成本与标注依赖。

Result: 成功构建一个在少量标注数据下高效训练、低推理开销的轻量级文本挖掘模型，具备良好的性能与可扩展性。

Conclusion: NanoNet通过参数高效学习与在线知识蒸馏，有效实现了在有限监督下的轻量级文本挖掘，为实际部署提供了可行方案。

Abstract: The lightweight semi-supervised learning (LSL) strategy provides an effective approach of conserving labeled samples and minimizing model inference costs. Prior research has effectively applied knowledge transfer learning and co-training regularization from large to small models in LSL. However, such training strategies are computationally intensive and prone to local optima, thereby increasing the difficulty of finding the optimal solution. This has prompted us to investigate the feasibility of integrating three low-cost scenarios for text mining tasks: limited labeled supervision, lightweight fine-tuning, and rapid-inference small models. We propose NanoNet, a novel framework for lightweight text mining that implements parameter-efficient learning with limited supervision. It employs online knowledge distillation to generate multiple small models and enhances their performance through mutual learning regularization. The entire process leverages parameter-efficient learning, reducing training costs and minimizing supervision requirements, ultimately yielding a lightweight model for downstream inference.

</details>


### [106] [Agentic Workflow Using RBA$_θ$ for Event Prediction](https://arxiv.org/abs/2602.06097)
*Purbak Sengupta,Sambeet Mishra,Sonal Shreya*

Main category: cs.LG

TL;DR: 本文提出一种以事件为中心、频率感知的风电功率波动预测范式，直接预测风力发电的波动事件，并据此重构功率轨迹，而非从密集预测中推断事件。该框架基于增强版Ramping Behaviour Analysis (RBA$_θ$) 方法的事件表示，逐步融合统计、机器学习与深度学习模型。传统方法通过事后提取事件提供可解释性基线，但跨站点泛化能力有限；随机森林直接预测事件提升了鲁棒性，推动完全事件感知建模的发展。为捕捉风力波动的多尺度特性，引入基于小波频率分解、时间激励特征和自适应特征选择的事件优先深度架构，实现稳定的长时序事件预测、物理一致的功率轨迹重建，并具备零样本迁移至未见风电场的能力。实证分析表明，波动幅度与持续时间分别由不同的中频段主导，使得稀疏事件预测即可实现准确信号重构。此外，提出一个智能预测层，根据运行情境动态选择专用工作流。整体框架证明，事件优先、频率感知的预测方式是轨迹优先预测的一种可迁移且符合实际操作需求的替代方案。


<details>
  <summary>Details</summary>
Motivation: 风力发电波动事件因强变异性、多尺度动力学及站点特异性气象效应，难以准确预测。现有方法通常先生成密集功率轨迹，再从中提取事件，存在信息冗余、泛化能力差等问题。因此，亟需一种更高效、更具泛化能力的事件直接预测框架，以支持实际电力系统调度与运行。

Method: 提出事件优先、频率感知的预测范式，结合增强版RBA$_θ$事件表示，集成统计模型、随机森林与深度学习模型。采用小波变换进行频率分解，提取中频段特征，构建包含时间激励与自适应特征选择的深度序列模型。引入智能预测层，根据运行上下文动态选择最优工作流。

Result: 所提框架在多个风电场上均实现稳定长时序事件预测，能准确重构功率轨迹，具备零样本迁移能力。实证显示波动特征受中频段主导，稀疏事件预测即可实现高精度信号重建。相比传统方法，该框架在跨站点泛化、物理一致性与运行适配性方面表现更优。

Conclusion: 事件优先、频率感知的预测范式显著优于传统轨迹优先方法，具备良好的可迁移性与操作适配性，为风电波动预测提供了新的技术路径，适用于复杂多变的实际电力系统运行场景。

Abstract: Wind power ramp events are difficult to forecast due to strong variability, multi-scale dynamics, and site-specific meteorological effects. This paper proposes an event-first, frequency-aware forecasting paradigm that directly predicts ramp events and reconstructs the power trajectory thereafter, rather than inferring events from dense forecasts. The framework is built on an enhanced Ramping Behaviour Analysis (RBA$_θ$) method's event representation and progressively integrates statistical, machine-learning, and deep-learning models. Traditional forecasting models with post-hoc event extraction provides a strong interpretable baseline but exhibits limited generalisation across sites. Direct event prediction using Random Forests improves robustness over survival-based formulations, motivating fully event-aware modelling. To capture the multi-scale nature of wind ramps, we introduce an event-first deep architecture that integrates wavelet-based frequency decomposition, temporal excitation features, and adaptive feature selection. The resulting sequence models enable stable long-horizon event prediction, physically consistent trajectory reconstruction, and zero-shot transfer to previously unseen wind farms. Empirical analysis shows that ramp magnitude and duration are governed by distinct mid-frequency bands, allowing accurate signal reconstruction from sparse event forecasts. An agentic forecasting layer is proposed, in which specialised workflows are selected dynamically based on operational context. Together, the framework demonstrates that event-first, frequency-aware forecasting provides a transferable and operationally aligned alternative to trajectory-first wind-power prediction.

</details>


### [107] [Toward Faithful and Complete Answer Construction from a Single Document](https://arxiv.org/abs/2602.06103)
*Zhaoyang Chen,Cody Fleming*

Main category: cs.LG

TL;DR: EVE 是一种用于文档驱动推理的结构化框架，通过提取、验证和枚举的分步流程，显著提升大语言模型在召回率、精确率和 F1 分数上的表现，突破了传统单次生成中覆盖与准确性的权衡，同时缓解了长度限制导致的截断问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型依赖统计下一个词预测，倾向于生成高概率但可能不完整或不忠实的内容，缺乏系统机制保证回答的全面性和真实性，违背核心人工智能安全原则。

Method: 提出 EVE 框架，采用结构化、可验证的生成管道，将复杂推理分解为提取、验证和枚举三个阶段，以增强生成内容的完整性与准确性。

Result: 实验显示，召回率和精确率分别提升最高达 24% 和 29%，F1 分数提高 31%，有效打破覆盖率与准确率之间的传统权衡；同时揭示自然语言固有的模糊性导致性能饱和，反映了基于语言推理的根本局限。

Conclusion: EVE 通过结构化推理流程显著提升了大语言模型在文档对齐任务中的表现，但其性能受限于自然语言本身的不确定性，体现了语言模型在严谨推理中的内在边界。

Abstract: Modern large language models (LLMs) are powerful generators driven by statistical next-token prediction. While effective at producing fluent text, this design biases models toward high-probability continuations rather than exhaustive and faithful answers grounded in source content. As a result, directly applying LLMs lacks systematic mechanisms to ensure both completeness (avoiding omissions) and faithfulness (avoiding unsupported content), which fundamentally conflicts with core AI safety principles. To address this limitation, we present EVE, a structured framework for document-grounded reasoning.
  Unlike free-form prompting, EVE constrains generation to a structured, verifiable pipeline that decomposes high-rigor reasoning into extraction, validation, and enumeration. Empirically, this design enables consistent and simultaneous improvements in recall, precision, and F1-score: recall and precision increase by up to 24\% and 29\%, respectively, with a corresponding 31\% gain in F1-score. This effectively breaks the long-standing trade-off between coverage and accuracy typical of single-pass LLM generation, while also mitigating generation truncation caused by length limitations. At the same time, we emphasize that EVE exhibits performance saturation due to the inherent ambiguity of natural language, reflecting fundamental limits of language-based reasoning.

</details>


### [108] [Pragmatic Curiosity: A Hybrid Learning-Optimization Paradigm via Active Inference](https://arxiv.org/abs/2602.06104)
*Yingke Li,Anjali Parashar,Enlu Zhou,Chuchu Fan*

Main category: cs.LG

TL;DR: 提出了一种名为“务实好奇心”的混合学习-优化范式，基于主动推理，通过最小化期望自由能来统一实用效用与认知信息增益，在多种真实世界的混合任务中表现出色，优于传统的贝叶斯优化和贝叶斯实验设计方法。


<details>
  <summary>Details</summary>
Motivation: 许多工程和科学工作流依赖于昂贵的黑箱评估，需要在提升性能和减少不确定性之间做出决策。现有的贝叶斯优化和贝叶斯实验设计方法分别侧重目标追求和信息获取，难以有效处理学习与优化紧密耦合的混合场景。

Method: 提出“务实好奇心”框架，基于主动推理，将行动选择建模为最小化期望自由能，从而同时兼顾实用性与信息增益。

Result: 在约束系统识别、目标主动搜索、未知偏好下的复合优化等任务中，该方法显著优于现有基线，提升了估计精度、关键区域覆盖率和最终解的质量。

Conclusion: 务实好奇心是一种高效且灵活的混合学习-优化方法，能够有效应对复杂现实任务中的多目标优化挑战，具有广泛的应用潜力。

Abstract: Many engineering and scientific workflows depend on expensive black-box evaluations, requiring decision-making that simultaneously improves performance and reduces uncertainty. Bayesian optimization (BO) and Bayesian experimental design (BED) offer powerful yet largely separate treatments of goal-seeking and information-seeking, providing limited guidance for hybrid settings where learning and optimization are intrinsically coupled. We propose "pragmatic curiosity," a hybrid learning-optimization paradigm derived from active inference, in which actions are selected by minimizing the expected free energy--a single objective that couples pragmatic utility with epistemic information gain. We demonstrate the practical effectiveness and flexibility of pragmatic curiosity on various real-world hybrid tasks, including constrained system identification, targeted active search, and composite optimization with unknown preferences. Across these benchmarks, pragmatic curiosity consistently outperforms strong BO-type and BED-type baselines, delivering higher estimation accuracy, better critical-region coverage, and improved final solution quality.

</details>


### [109] [Compressing LLMs with MoP: Mixture of Pruners](https://arxiv.org/abs/2602.06127)
*Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Leandro Giusti Mugnaini,Keith Ando Ogawa,Lucas Pellicer,Rosimeire Pereira Costa,Edson Bollis,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: MoP (Mixture of Pruners) is an iterative framework that unifies depth and width pruning for LLMs, achieving superior performance across compression regimes and reducing latency by 39% at 40% compression. It also enhances efficiency in vision-language models like LLaVA-1.5 with text-only fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Existing model pruning methods focus on either depth or width reduction, but not both simultaneously, limiting their effectiveness. MoP addresses this by integrating both dimensions to improve compression and inference speed.

Method: MoP iteratively generates two pruning branches—depth-wise and width-wise—and selects the best candidate to advance, enabling a balanced and effective pruning strategy.

Result: MoP outperforms state-of-the-art methods on LLaMA-2 and LLaMA-3 across various compression levels, reduces end-to-end latency by 39% at 40% compression, and improves computational efficiency in LLaVA-1.5 with text-only fine-tuning.

Conclusion: MoP provides a unified, effective approach to structured pruning by combining depth and width reduction, delivering better accuracy, faster inference, and broader applicability across multimodal models.

Abstract: The high computational demands of Large Language Models (LLMs) motivate methods that reduce parameter count and accelerate inference. In response, model pruning emerges as an effective strategy, yet current methods typically focus on a single dimension-depth or width. We introduce MoP (Mixture of Pruners), an iterative framework that unifies these dimensions. At each iteration, MoP generates two branches-pruning in depth versus pruning in width-and selects a candidate to advance the path. On LLaMA-2 and LLaMA-3, MoP advances the frontier of structured pruning, exceeding the accuracy of competing methods across a broad set of compression regimes. It also consistently outperforms depth-only and width-only pruning. Furthermore, MoP translates structural pruning into real speedup, reducing end-to-end latency by 39% at 40% compression. Finally, extending MoP to the vision-language model LLaVA-1.5, we notably improve computational efficiency and demonstrate that text-only recovery fine-tuning can restore performance even on visual tasks.

</details>


### [110] [Self-Improving World Modelling with Latent Actions](https://arxiv.org/abs/2602.06130)
*Yifu Qiu,Zheng Zhao,Waylon Li,Yftah Ziser,Anna Korhonen,Shay B. Cohen,Edoardo M. Ponti*

Main category: cs.LG

TL;DR: SWIRL 是一种自提升框架，通过将动作视为潜在变量，仅使用状态序列学习世界模型，避免了昂贵的动作标注。它交替进行前向世界建模（FWM）和逆动力学建模（IDM），利用变分信息最大化和ELBO最大化实现迭代优化，并采用GRPO强化学习方法训练。理论保证了学习可行性，在多个视觉与文本环境中表现优异，显著提升多项基准性能。


<details>
  <summary>Details</summary>
Motivation: 传统世界模型学习依赖昂贵的动作标注轨迹，而现实场景中常仅有状态序列。为解决这一问题，本文提出无需动作标签的自提升框架SWIRL，旨在从纯状态序列中学习可解释、一致的世界动态模型。

Method: SWIRL 采用交替优化：第一阶段通过变分信息最大化更新前向世界模型（FWM），以最大化状态间条件互信息并保持动作一致性；第二阶段通过ELBO最大化更新逆动力学模型（IDM），以解释观测到的状态转移。两个模型均使用强化学习（GRPO）训练，以对方模型的对数概率作为奖励信号，实现坐标上升优化。

Result: SWIRL 在多个任务上取得显著性能提升：在AURORABench上提升16%，ByteMorph上提升28%，WorldPredictionBench上提升16%，StableToolBench上提升14%。表明其在多模态环境中的强泛化能力与高效建模潜力。

Conclusion: SWIRL 成功实现了仅从状态序列中学习世界模型，无需动作标注，具备理论可学习性保障，并在多种复杂环境中展现出优越性能，为大模型的推理与规划提供了新范式。

Abstract: Internal modelling of the world -- predicting transitions between previous states $X$ and next states $Y$ under actions $Z$ -- is essential to reasoning and planning for LLMs and VLMs. Learning such models typically requires costly action-labelled trajectories. We propose SWIRL, a self-improvement framework that learns from state-only sequences by treating actions as a latent variable and alternating between Forward World Modelling (FWM) $P_θ(Y|X,Z)$ and an Inverse Dynamics Modelling (IDM) $Q_φ(Z|X,Y)$. SWIRL iterates two phases: (1) Variational Information Maximisation, which updates the FWM to generate next states that maximise conditional mutual information with latent actions given prior states, encouraging identifiable consistency; and (2) ELBO Maximisation, which updates the IDM to explain observed transitions, effectively performing coordinate ascent. Both models are trained with reinforcement learning (specifically, GRPO) with the opposite frozen model's log-probability as a reward signal. We provide theoretical learnability guarantees for both updates, and evaluate SWIRL on LLMs and VLMs across multiple environments: single-turn and multi-turn open-world visual dynamics and synthetic textual environments for physics, web, and tool calling. SWIRL achieves gains of 16% on AURORABench, 28% on ByteMorph, 16% on WorldPredictionBench, and 14% on StableToolBench.

</details>


### [111] [Tempora: Characterising the Time-Contingent Utility of Online Test-Time Adaptation](https://arxiv.org/abs/2602.06136)
*Sudarshan Sreeram,Young D. Kwon,Cecilia Mascolo*

Main category: cs.LG

TL;DR: 提出Tempora框架，用于在时间压力下评估测试时自适应（TTA）方法，引入三种时间相关效用度量，揭示传统排名在时序约束下不稳定的事实，并强调方法选择需考虑具体部署场景。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应（TTA）评估忽视了实际部署中的时间限制，导致无法准确反映模型在延迟敏感场景下的表现，亟需一种能衡量准确性与延迟权衡的新评估框架。

Method: 设计Tempora框架，包含模拟部署约束的时间场景、操作化测量的评估协议，以及量化准确率-延迟权衡的三种时间相关效用指标：离散效用（异步流中硬截止）、连续效用（交互式场景中价值随延迟衰减）、分摊效用（预算受限场景）。

Result: 在ImageNet-C上对7种TTA方法进行240次时序评估发现，传统排名无法预测时序压力下的性能排序；状态领先的方法在41.2%的情况下表现不佳；最优方法随扰动类型和时间压力变化，无统一最佳方案。

Conclusion: Tempora首次系统性地支持在多样化时间约束下的TTA评估，揭示了排名反转的机制，为实践者提供选型依据，也为研究者指明可部署自适应的发展方向。

Abstract: Test-time adaptation (TTA) offers a compelling remedy for machine learning (ML) models that degrade under domain shifts, improving generalisation on-the-fly with only unlabelled samples. This flexibility suits real deployments, yet conventional evaluations unrealistically assume unbounded processing time, overlooking the accuracy-latency trade-off. As ML increasingly underpins latency-sensitive and user-facing use-cases, temporal pressure constrains the viability of adaptable inference; predictions arriving too late to act on are futile. We introduce Tempora, a framework for evaluating TTA under this pressure. It consists of temporal scenarios that model deployment constraints, evaluation protocols that operationalise measurement, and time-contingent utility metrics that quantify the accuracy-latency trade-off. We instantiate the framework with three such metrics: (1) discrete utility for asynchronous streams with hard deadlines, (2) continuous utility for interactive settings where value decays with latency, and (3) amortised utility for budget-constrained deployments. Applying Tempora to seven TTA methods on ImageNet-C across 240 temporal evaluations reveals rank instability: conventional rankings do not predict rankings under temporal pressure; ETA, a state-of-the-art method in the conventional setting, falls short in 41.2% of evaluations. The highest-utility method varies with corruption type and temporal pressure, with no clear winner. By enabling systematic evaluation across diverse temporal constraints for the first time, Tempora reveals when and why rankings invert, offering practitioners a lens for method selection and researchers a target for deployable adaptation.

</details>


### [112] [Flow Matching for Offline Reinforcement Learning with Discrete Actions](https://arxiv.org/abs/2602.06138)
*Fairoz Nower Khan,Nabuat Zaman Nahim,Ruiquan Huang,Haibo Yang,Peizhong Ju*

Main category: cs.LG

TL;DR: 本文提出了一种基于流匹配的生成策略框架，扩展至支持离散动作空间和多目标优化，通过连续时间马尔可夫链替代连续流，并采用Q加权流匹配目标进行训练。该方法在多智能体场景中通过因子化条件路径缓解联合动作空间的指数增长问题，理论上在理想条件下可恢复最优策略。实验表明其在高维控制、多模态决策及动态偏好变化等实际场景中表现稳健。此外，通过动作量化，该框架还可应用于连续控制任务，实现表示复杂性与性能之间的灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型和流匹配的生成策略主要局限于连续动作空间，难以适应更广泛的离线强化学习场景，尤其在离散动作空间和多目标优化方面存在局限，因此亟需一种通用且可扩展的框架来支持多种实际应用需求。

Method: 将连续流替换为连续时间马尔可夫链，采用Q加权流匹配目标进行训练；在多智能体设置中引入因子化条件路径以缓解联合动作空间的指数爆炸；并通过动作量化将方法推广至连续控制任务。

Result: 所提方法在高维控制、多模态决策、动态偏好变化等多种实际场景中均表现出良好鲁棒性；理论分析表明，在理想条件下可恢复最优策略；动作量化使得框架适用于连续控制任务，具备良好的灵活性与实用性。

Conclusion: 本文提出的离散动作流匹配框架有效拓展了生成策略在离线强化学习中的适用范围，不仅支持离散动作与多目标优化，还能通过量化延伸至连续控制任务，兼具理论保证与实际性能，为复杂决策问题提供了统一且灵活的解决方案。

Abstract: Generative policies based on diffusion models and flow matching have shown strong promise for offline reinforcement learning (RL), but their applicability remains largely confined to continuous action spaces. To address a broader range of offline RL settings, we extend flow matching to a general framework that supports discrete action spaces with multiple objectives. Specifically, we replace continuous flows with continuous-time Markov chains, trained using a Q-weighted flow matching objective. We then extend our design to multi-agent settings, mitigating the exponential growth of joint action spaces via a factorized conditional path. We theoretically show that, under idealized conditions, optimizing this objective recovers the optimal policy. Extensive experiments further demonstrate that our method performs robustly in practical scenarios, including high-dimensional control, multi-modal decision-making, and dynamically changing preferences over multiple objectives. Our discrete framework can also be applied to continuous-control problems through action quantization, providing a flexible trade-off between representational complexity and performance.

</details>


### [113] [Optimistic Training and Convergence of Q-Learning -- Extended Version](https://arxiv.org/abs/2602.06146)
*Prashant Mehta,Sean Meyn*

Main category: cs.LG

TL;DR: 本文扩展了Q-learning在线性函数近似下的稳定性结果，揭示了在非标准设定下收敛性所需的更强结构条件。通过一维例子表明，在盲目策略训练下，投影贝尔曼方程（PBE）可能无解或有多个解，且此时算法不稳定。即使基函数理想（真实Q值在基空间中），贪婪策略下仍可能存在多个PBE解，导致$(\varepsilon,κ)$-平滑吉布斯策略也无法保证唯一性与收敛性。


<details>
  <summary>Details</summary>
Motivation: 研究Q-learning在线性函数近似下的稳定性与收敛性，尤其关注在非表格式或非线性马尔可夫决策过程（MDP）设置下的解的唯一性与收敛条件。此前工作已证明在$(\varepsilon,κ)$-平滑吉布斯策略下参数估计有界，但未解决解的唯一性及更广泛环境中的收敛性问题。

Method: 通过构造反例分析不同策略下投影贝尔曼方程（PBE）的解的存在性与唯一性；采用一维示例验证在盲目策略训练下可能出现无解或多解情形，并进一步展示即使在理想基函数条件下，贪婪策略仍可能导致多解。

Result: 在某些情况下，即使基函数理想，投影贝尔曼方程也可能存在多个解，导致Q-learning算法在$(\varepsilon,κ)$-平滑吉布斯策略下不收敛。同时证明了收敛需要比以往认为更强的结构假设。

Conclusion: Q-learning的收敛性不仅依赖于探索机制和函数近似结构，还高度依赖于策略与基函数之间的匹配性。仅满足线性可表示性不足以保证唯一解或稳定收敛，需额外结构约束。

Abstract: In recent work it is shown that Q-learning with linear function approximation is stable, in the sense of bounded parameter estimates, under the $(\varepsilon,κ)$-tamed Gibbs policy; $κ$ is inverse temperature, and $\varepsilon>0$ is introduced for additional exploration. Under these assumptions it also follows that there is a solution to the projected Bellman equation (PBE). Left open is uniqueness of the solution, and criteria for convergence outside of the standard tabular or linear MDP settings.
  The present work extends these results to other variants of Q-learning, and clarifies prior work: a one dimensional example shows that under an oblivious policy for training there may be no solution to the PBE, or multiple solutions, and in each case the algorithm is not stable under oblivious training.
  The main contribution is that far more structure is required for convergence. An example is presented for which the basis is ideal, in the sense that the true Q-function is in the span of the basis. However, there are two solutions to the PBE under the greedy policy, and hence also for the $(\varepsilon,κ)$-tamed Gibbs policy for all sufficiently small $\varepsilon>0$ and $κ\ge 1$.

</details>


### [114] [MoSE: Mixture of Slimmable Experts for Efficient and Adaptive Language Models](https://arxiv.org/abs/2602.06154)
*Nurbek Tastan,Stefanos Laskaridis,Karthik Nandakumar,Samuel Horvath*

Main category: cs.LG

TL;DR: 提出Mixture of Slimmable Experts (MoSE)，通过让每个专家具有可变宽度的瘦身结构，实现专家选择与执行程度的双重条件计算，从而在推理时提供更连续的精度-计算权衡。采用多宽度训练结合标准MoE目标的稳定训练方法，并引入轻量级测试时训练机制以动态调整专家宽度，在GPT模型上实验表明MoSE在保持或超越标准MoE性能的同时，显著降低FLOPs。


<details>
  <summary>Details</summary>
Motivation: 标准MoE模型在激活专家后会完全执行，导致精度与计算之间的权衡存在较大不连续性，限制了灵活部署和资源优化。需要一种能实现更平滑、可调的精度-计算折衷的方法。

Method: 设计具有嵌套瘦身结构的专家，使每个专家可按不同宽度执行；采用多宽度训练策略结合稀疏路由下的标准MoE目标进行训练；推理时利用轻量级测试时训练机制根据路由器置信度动态决定专家执行宽度。

Result: MoSE在全宽下性能与标准MoE相当或更优，在多种计算预算下均能实现更好的精度-成本帕累托前沿，显著减少所需FLOPs，支持更灵活的部署场景。

Conclusion: MoSE通过引入可变宽度的专家结构，实现了更精细的条件计算控制，有效弥合了精度与计算之间的不连续性，为高效、灵活的大语言模型推理提供了新范式。

Abstract: Mixture-of-Experts (MoE) models scale large language models efficiently by sparsely activating experts, but once an expert is selected, it is executed fully. Hence, the trade-off between accuracy and computation in an MoE model typically exhibits large discontinuities. We propose Mixture of Slimmable Experts (MoSE), an MoE architecture in which each expert has a nested, slimmable structure that can be executed at variable widths. This enables conditional computation not only over which experts are activated, but also over how much of each expert is utilized. Consequently, a single pretrained MoSE model can support a more continuous spectrum of accuracy-compute trade-offs at inference time. We present a simple and stable training recipe for slimmable experts under sparse routing, combining multi-width training with standard MoE objectives. During inference, we explore strategies for runtime width determination, including a lightweight test-time training mechanism that learns how to map router confidence/probabilities to expert widths under a fixed budget. Experiments on GPT models trained on OpenWebText demonstrate that MoSE matches or improves upon standard MoE at full width and consistently shifts the Pareto frontier for accuracy vs. cost, achieving comparable performance with significantly fewer FLOPs.

</details>


### [115] [Latent Structure Emergence in Diffusion Models via Confidence-Based Filtering](https://arxiv.org/abs/2602.06155)
*Wei Wei,Yizhou Zeng,Kuntian Chen,Sophie Langer,Mariia Seleznova,Hung-Hsu Chou*

Main category: cs.LG

TL;DR: 本文研究扩散模型中初始噪声种子的高维潜在空间是否包含可预测生成样本属性（如类别）的结构。发现虽然整体潜在空间看似无结构，但仅关注产生高置信度样本的噪声种子时，展现出明显的类别可分性。通过比较不同置信度子集的类别可预测性及潜在空间的类别分离度，揭示了在置信度过滤下才显现的类别相关潜在结构。这一发现为基于置信度过滤的条件生成提供了新思路，可替代传统的引导方法。


<details>
  <summary>Details</summary>
Motivation: 探究扩散模型潜在空间中是否存在可预测生成样本类别的结构，尤其关注高置信度样本所揭示的潜在规律。

Method: 通过分析预训练分类器对生成样本赋予的置信度分数，筛选出高置信度样本对应的初始噪声种子，进而评估其在潜在空间中的类别可分性，并对比不同置信度子集的表现。

Result: 在所有噪声实现实例中，潜在空间看似无结构；但在仅保留高置信度样本对应的噪声种子后，表现出显著的类别可分性，表明存在隐藏的类别相关结构，且该结构仅在置信度过滤后显现。

Conclusion: 扩散模型的潜在空间中存在隐含的类别相关结构，但其可观察性依赖于置信度筛选。这为实现无需引导的条件生成提供了可行路径。

Abstract: Diffusion models rely on a high-dimensional latent space of initial noise seeds, yet it remains unclear whether this space contains sufficient structure to predict properties of the generated samples, such as their classes. In this work, we investigate the emergence of latent structure through the lens of confidence scores assigned by a pre-trained classifier to generated samples. We show that while the latent space appears largely unstructured when considering all noise realizations, restricting attention to initial noise seeds that produce high-confidence samples reveals pronounced class separability. By comparing class predictability across noise subsets of varying confidence and examining the class separability of the latent space, we find evidence of class-relevant latent structure that becomes observable only under confidence-based filtering. As a practical implication, we discuss how confidence-based filtering enables conditional generation as an alternative to guidance-based methods.

</details>


### [116] [SCONE: A Practical, Constraint-Aware Plug-in for Latent Encoding in Learned DNA Storage](https://arxiv.org/abs/2602.06157)
*Cihan Ruan,Lebin Zhou,Rongduo Han,Linyi Han,Bingqing Zhao,Chenchen Zhu,Wei Jiang,Wei Wang,Nam Ling*

Main category: cs.LG

TL;DR: SCONE提出一种端到端的DNA存储编码方法，将神经压缩与DNA编码融合，通过在潜在空间直接进行四进制算术编码，实现GC平衡和同聚物抑制的确定性约束，无需后处理校正，保持可逆性且计算开销极低（<2%延迟），显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有DNA存储系统在整合神经压缩管道时效率低下，传统方法忽略熵模型优化，导致压缩效率下降；需一种能统一处理潜在表示与生物化学约束的新方法。

Method: SCONE采用约束感知自适应编码模块，在潜在空间中直接进行四进制算术编码，动态调整概率分布以满足GC含量和同聚物长度等生物化学约束，实现无后处理的高效编码。

Result: 实验表明SCONE实现了近乎完美的化学约束满足，计算延迟增加低于2%，支持任意神经压缩模型，构建了通用的端到端DNA兼容学习编码接口。

Conclusion: SCONE成功将神经压缩与DNA编码无缝集成，提供高效、可逆、低延迟的解决方案，为下一代高密度、可扩展的DNA数据存储奠定基础。

Abstract: DNA storage has matured from concept to practical stage, yet its integration with neural compression pipelines remains inefficient. Early DNA encoders applied redundancy-heavy constraint layers atop raw binary data - workable but primitive. Recent neural codecs compress data into learned latent representations with rich statistical structure, yet still convert these latents to DNA via naive binary-to-quaternary transcoding, discarding the entropy model's optimization. This mismatch undermines compression efficiency and complicates the encoding stack. A plug-in module that collapses latent compression and DNA encoding into a single step. SCONE performs quaternary arithmetic coding directly on the latent space in DNA bases. Its Constraint-Aware Adaptive Coding module dynamically steers the entropy encoder's learned probability distribution to enforce biochemical constraints - Guanine-Cytosine (GC) balance and homopolymer suppression - deterministically during encoding, eliminating post-hoc correction. The design preserves full reversibility and exploits the hyperprior model's learned priors without modification. Experiments show SCONE achieves near-perfect constraint satisfaction with negligible computational overhead (<2% latency), establishing a latent-agnostic interface for end-to-end DNA-compatible learned codecs.

</details>


### [117] [$f$-FUM: Federated Unlearning via min--max and $f$-divergence](https://arxiv.org/abs/2602.06187)
*Radmehr Karimian,Amirhossein Bagheri,Meghdad Kurmanji,Nicholas D. Lane,Gholamali Aminian*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的联邦遗忘框架，将其建模为一个极小极大优化问题，旨在最大化包含所有数据与剔除特定数据点后模型之间的$f$-散度，同时最小化对保留数据的影响。该方法可作为插件集成到大多数联邦学习系统中，无需修改模型架构或权重，且在保持模型性能的同时显著提升数据移除效率，相比直接重训有明显加速效果。


<details>
  <summary>Details</summary>
Motivation: 随着法律和伦理要求（如‘被遗忘的权利’）以及对抗数据投毒攻击的需求增加，联邦学习中的数据遗忘成为迫切需要解决的问题。传统的集中式数据遗忘方法难以适用于分布式联邦学习场景，因此亟需一种在不破坏隐私的前提下，有效实现数据移除的机制。

Method: 提出了一种基于极小极大优化的数据遗忘框架，通过最大化模型在含全量数据与去除非特定数据后的$f$-散度，来衡量数据移除的效果；同时最小化对剩余数据性能的影响。该框架设计为可插拔式，兼容现有联邦学习系统，避免了对模型结构和权重的依赖。

Result: 实验结果表明，该方法在联邦设置下能高效近似数据移除效果，相较于传统重训方式具有显著速度优势，且对模型整体性能影响极小，保持了良好的实用性。

Conclusion: 所提出的联邦遗忘框架为解决分布式环境下的数据移除问题提供了一个通用、高效且实用的解决方案，具备良好的可扩展性和兼容性，有望在实际应用中满足隐私合规与安全需求。

Abstract: Federated Learning (FL) has emerged as a powerful paradigm for collaborative machine learning across decentralized data sources, preserving privacy by keeping data local. However, increasing legal and ethical demands, such as the "right to be forgotten", and the need to mitigate data poisoning attacks have underscored the urgent necessity for principled data unlearning in FL. Unlike centralized settings, the distributed nature of FL complicates the removal of individual data contributions. In this paper, we propose a novel federated unlearning framework formulated as a min-max optimization problem, where the objective is to maximize an $f$-divergence between the model trained with all data and the model retrained without specific data points, while minimizing the degradation on retained data. Our framework could act like a plugin and be added to almost any federated setup, unlike SOTA methods like (\cite{10269017} which requires model degradation in server, or \cite{khalil2025notfederatedunlearningweight} which requires to involve model architecture and model weights). This formulation allows for efficient approximation of data removal effects in a federated setting. We provide empirical evaluations to show that our method achieves significant speedups over naive retraining, with minimal impact on utility.

</details>


### [118] [Learning Rate Scaling across LoRA Ranks and Transfer to Full Finetuning](https://arxiv.org/abs/2602.06204)
*Nan Chen,Soledad Villar,Soufiane Hayou*

Main category: cs.LG

TL;DR: 本文提出Maximal-Update Adaptation ($μ$A)框架，用于分析低秩适配（LoRA）中最优学习率与适配器秩的关系。研究发现，最优学习率的缩放行为取决于初始化方式和LoRA缩放因子，存在两种不同模式：一种是学习率随秩变化基本不变，另一种则与秩成反比。此外，该工作识别出可实现从LoRA到全模型微调的学习率迁移的配置，显著降低全模型微调的调参成本。实验在语言、视觉、多模态、图像生成及强化学习任务上验证了其缩放规则的有效性，并证明了学习率在不同设置间的可靠转移。


<details>
  <summary>Details</summary>
Motivation: LoRA虽具备参数高效和小内存开销的优势，但其训练动态受初始化、适配器秩、学习率等超参数影响复杂，尤其缺乏对最优学习率如何随适配器秩变化的理论指导，导致实践中需频繁重新调参，效率低下。因此亟需一个理论框架来揭示学习率与秩之间的合理缩放关系，以实现更高效的微调策略。

Method: 基于超参数迁移技术，结合源自预训练阶段的Maximal-Update Parametrization ($μ$P)思想，构建$μ$A理论框架，系统分析在标准配置下最优学习率与模型宽度、适配器秩之间的依赖关系，识别不同初始化和缩放因子下的学习率缩放规律，进而推导出支持学习率迁移的配置条件。

Result: 实验表明，$μ$A所预测的学习率缩放规律在多种任务（语言、视觉、视觉-语言、图像生成、强化学习）中均成立；更重要的是，在特定配置下，通过LoRA训练得到的最优学习率可稳定迁移至全模型微调，大幅减少后者的调参成本。

Conclusion: 本文提出的$μ$A框架为LoRA中的学习率选择提供了理论依据，揭示了学习率与适配器秩之间复杂的缩放行为，并实现了从低秩微调到全模型微调的学习率有效迁移，推动了参数高效微调的自动化与高效化发展。

Abstract: Low-Rank Adaptation (LoRA) is a standard tool for parameter-efficient finetuning of large models. While it induces a small memory footprint, its training dynamics can be surprisingly complex as they depend on several hyperparameters such as initialization, adapter rank, and learning rate. In particular, it is unclear how the optimal learning rate scales with adapter rank, which forces practitioners to re-tune the learning rate whenever the rank is changed. In this paper, we introduce Maximal-Update Adaptation ($μ$A), a theoretical framework that characterizes how the "optimal" learning rate should scale with model width and adapter rank to produce stable, non-vanishing feature updates under standard configurations. $μ$A is inspired from the Maximal-Update Parametrization ($μ$P) in pretraining. Our analysis leverages techniques from hyperparameter transfer and reveals that the optimal learning rate exhibits different scaling patterns depending on initialization and LoRA scaling factor. Specifically, we identify two regimes: one where the optimal learning rate remains roughly invariant across ranks, and another where it scales inversely with rank. We further identify a configuration that allows learning rate transfer from LoRA to full finetuning, drastically reducing the cost of learning rate tuning for full finetuning. Experiments across language, vision, vision--language, image generation, and reinforcement learning tasks validate our scaling rules and show that learning rates tuned on LoRA transfer reliably to full finetuning.

</details>


### [119] [Multi-Way Representation Alignment](https://arxiv.org/abs/2602.06205)
*Akshit Achara,Tatiana Gaintseva,Mateo Mahaut,Pritish Chakraborty,Viktor Stenby Johansson,Melih Barsbey,Emanuele Rodolà,Donato Crisostomi*

Main category: cs.LG

TL;DR: 该论文研究多模型（M≥3）表示对齐问题，提出Geometry-Corrected Procrustes Alignment (GCPA)方法，在保持共享参考空间的同时，提升任意模型间的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有表示映射方法为成对设计，随模型数量增加呈二次增长，且难以建立一致的全局参考空间；同时，严格等距对齐在检索任务中表现不佳。

Method: 采用广义普罗克鲁斯特斯分析（GPA）构建共享正交空间，并引入后处理校正方向偏差的几何修正机制，形成GCPA方法。

Result: 实验表明，GCPA在任意模型间检索任务中持续优于现有方法，同时维持了实用的统一表示空间。

Conclusion: GCPA有效解决了多模型表示对齐中的几何一致性与检索性能之间的矛盾，提供了一种高效、可扩展的共享表示框架。

Abstract: The Platonic Representation Hypothesis suggests that independently trained neural networks converge to increasingly similar latent spaces. However, current strategies for mapping these representations are inherently pairwise, scaling quadratically with the number of models and failing to yield a consistent global reference. In this paper, we study the alignment of $M \ge 3$ models. We first adapt Generalized Procrustes Analysis (GPA) to construct a shared orthogonal universe that preserves the internal geometry essential for tasks like model stitching. We then show that strict isometric alignment is suboptimal for retrieval, where agreement-maximizing methods like Canonical Correlation Analysis (CCA) typically prevail. To bridge this gap, we finally propose Geometry-Corrected Procrustes Alignment (GCPA), which establishes a robust GPA-based universe followed by a post-hoc correction for directional mismatch. Extensive experiments demonstrate that GCPA consistently improves any-to-any retrieval while retaining a practical shared reference space.

</details>


### [120] [SR4-Fit: An Interpretable and Informative Classification Algorithm Applied to Prediction of U.S. House of Representatives Elections](https://arxiv.org/abs/2602.06229)
*Shyam Sundar Murali Krishnan,Dean Frederick Hougen*

Main category: cs.LG

TL;DR: SR4-Fit是一种新型可解释分类算法，旨在解决黑箱模型缺乏可解释性以及传统规则基算法预测能力不足和不稳定性的问题。它在多个数据集（包括美国国会选区人口统计、乳腺癌、酵母等）上表现出卓越的准确性、稳定性和可解释性，超越了黑箱模型和现有可解释算法如RuleFit，打破了可解释性与预测性能之间的传统权衡。


<details>
  <summary>Details</summary>
Motivation: 机器学习的发展需要可解释模型用于关键应用，但高性能模型多为黑箱系统，而传统规则基算法如RuleFit虽简单但预测能力弱且不稳定，因此需要一种兼具高准确率和可解释性的新方法。

Method: 提出Sparse Relaxed Regularized Regression Rule-Fit (SR4-Fit)算法，结合稀疏性、松弛正则化与回归规则拟合，生成稳定且可解释的规则集，同时保持优异的预测性能。

Result: SR4-Fit在预测美国国会选举党派结果上达到前所未有的准确性和可解释性；在多个公开数据集上也表现优越，揭示了黑箱模型无法解释的内在人口统计特征组合。

Conclusion: SR4-Fit成功实现了可解释性与预测性能的统一，在选举预测及其他分类任务中展现出强大潜力，为复杂决策场景提供了可靠、透明的建模工具。

Abstract: The growth of machine learning demands interpretable models for critical applications, yet most high-performing models are ``black-box'' systems that obscure input-output relationships, while traditional rule-based algorithms like RuleFit suffer from a lack of predictive power and instability despite their simplicity. This motivated our development of Sparse Relaxed Regularized Regression Rule-Fit (SR4-Fit), a novel interpretable classification algorithm that addresses these limitations while maintaining superior classification performance. Using demographic characteristics of U.S. congressional districts from the Census Bureau's American Community Survey, we demonstrate that SR4-Fit can predict House election party outcomes with unprecedented accuracy and interpretability. Our results show that while the majority party remains the strongest predictor, SR4-Fit has revealed intrinsic combinations of demographic factors that affect prediction outcomes that were unable to be interpreted in black-box algorithms such as random forests. The SR4-Fit algorithm surpasses both black-box models and existing interpretable rule-based algorithms such as RuleFit with respect to accuracy, simplicity, and robustness, generating stable and interpretable rule sets while maintaining superior predictive performance, thus addressing the traditional trade-off between model interpretability and predictive capability in electoral forecasting. To further validate SR4-Fit's performance, we also apply it to six additional publicly available classification datasets, like the breast cancer, Ecoli, page blocks, Pima Indians, vehicle, and yeast datasets, and find similar results.

</details>


### [121] [Provably avoiding over-optimization in Direct Preference Optimization without knowing the data distribution](https://arxiv.org/abs/2602.06239)
*Adam Barla,Emanuele Nevali,Luca Viano,Volkan Cevher*

Main category: cs.LG

TL;DR: PEPO 是一种单步直接偏好优化（DPO）类算法，通过基于悲观集成的方法缓解偏好学习中的过优化问题，无需依赖数据生成分布或显式奖励模型。它通过在不相交数据子集上训练的多个偏好优化策略的集合，并采用最坏情况聚合来实现悲观性，从而增强模型间的一致性。在表格设置中，PEPO 的样本复杂度保证仅依赖于单策略集中性系数，避免了受过优化算法（如 DPO）影响的全策略集中性。理论结果得到实践验证，同时保持了 DPO 风格训练的简洁性和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决偏好学习中常见的过优化问题，尤其是在缺乏数据生成分布知识或无法构建显式奖励模型的情况下，提升算法的鲁棒性和泛化能力。

Method: 使用多个在不相交数据子集上训练的偏好优化策略组成的集成，通过最坏情况聚合机制实现悲观性，增强模型间的一致性，从而减少过优化风险。

Result: 在表格设置下，PEPO 实现了仅依赖单策略集中性系数的样本复杂度保证，优于依赖全策略集中性的传统方法；实验表明其在实际任务中表现优异，且保持了 DPO 风格训练的简单性与实用性。

Conclusion: PEPO 有效缓解了偏好学习中的过优化问题，兼具理论保障和实用性能，是一种高效、稳健且易于实施的偏好优化方法。

Abstract: We introduce PEPO (Pessimistic Ensemble based Preference Optimization), a single-step Direct Preference Optimization (DPO)-like algorithm to mitigate the well-known over-optimization issue in preference learning without requiring the knowledge of the data-generating distribution or learning an explicit reward model. PEPO achieves pessimism via an ensemble of preference-optimized policies trained on disjoint data subsets and then aggregates them through a worst case construction that favors the agreement across models. In the tabular setting, PEPO achieves sample complexity guarantees depending only on a single-policy concentrability coefficient, thus avoiding the all-policy concentrability which affects the guarantees of algorithms prone to over-optimization, such as DPO. The theoretical findings are corroborated by a convincing practical performance, while retaining the simplicity and the practicality of DPO-style training.

</details>


### [122] [REBEL: Hidden Knowledge Recovery via Evolutionary-Based Evaluation Loop](https://arxiv.org/abs/2602.06248)
*Patryk Rybak,Paweł Batorski,Paul Swoboda,Przemysław Spurek*

Main category: cs.LG

TL;DR: 本文提出REBEL，一种用于探测大语言模型中是否仍残留被遗忘数据的进化式对抗提示生成方法。现有评估方法依赖良性查询，难以检测复杂提示策略下仍可提取的残余知识。REBEL通过对抗性提示有效激发被遗忘数据，实验表明其在TOFU和WMDP基准上分别达到最高60%和93%的攻击成功率，揭示当前去学习方法可能仅提供表面保护。


<details>
  <summary>Details</summary>
Motivation: 现有机器去学习方法的真正有效性存疑，标准评估指标因使用良性查询，常将表面信息抑制误认为知识完全移除，无法检测通过高级提示策略仍可恢复的残余知识。

Method: 提出REBEL，一种基于进化的对抗提示生成框架，通过迭代优化提示以最大化从模型中提取被遗忘数据的能力，从而探测去学习效果的真实性。

Result: REBEL在TOFU和WMDP基准上分别实现最高60%和93%的攻击成功率，显著优于静态基线，证明当前去学习方法存在显著的知识残留问题。

Conclusion: 当前主流去学习方法可能并未真正删除敏感或版权数据，仅造成表面知识抑制；REBEL为评估去学习真实有效性提供了强有力工具，推动更安全的模型去学习技术发展。

Abstract: Machine unlearning for LLMs aims to remove sensitive or copyrighted data from trained models. However, the true efficacy of current unlearning methods remains uncertain. Standard evaluation metrics rely on benign queries that often mistake superficial information suppression for genuine knowledge removal. Such metrics fail to detect residual knowledge that more sophisticated prompting strategies could still extract. We introduce REBEL, an evolutionary approach for adversarial prompt generation designed to probe whether unlearned data can still be recovered. Our experiments demonstrate that REBEL successfully elicits ``forgotten'' knowledge from models that seemed to be forgotten in standard unlearning benchmarks, revealing that current unlearning methods may provide only a superficial layer of protection. We validate our framework on subsets of the TOFU and WMDP benchmarks, evaluating performance across a diverse suite of unlearning algorithms. Our experiments show that REBEL consistently outperforms static baselines, recovering ``forgotten'' knowledge with Attack Success Rates (ASRs) reaching up to 60% on TOFU and 93% on WMDP. We will make all code publicly available upon acceptance. Code is available at https://github.com/patryk-rybak/REBEL/

</details>


### [123] [Steering Safely or Off a Cliff? Rethinking Specificity and Robustness in Inference-Time Interventions](https://arxiv.org/abs/2602.06256)
*Navita Goyal,Hal Daumé*

Main category: cs.LG

TL;DR: 本文提出了一种评估模型转向（model steering）特异性的框架，涵盖通用性、控制性和鲁棒性三个维度。研究发现，尽管转向方法在提升目标属性（如减少过度拒绝和幻觉）方面有效，且基本保持通用性和控制性特异性，但普遍缺乏鲁棒性，尤其在面对对抗性攻击（如越狱）时显著降低安全性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注模型转向的效能，但缺乏对干预是否仅影响目标属性的系统评估，尤其是对与目标属性相关的行为在分布变化下的稳定性关注不足。因此，亟需建立更全面的特异性评价体系，以确保转向技术的安全性。

Method: 提出一个包含通用性、控制性和鲁棒性三个维度的特异性评估框架，通过两个安全关键场景（减少过度拒绝和幻觉）对多种转向方法进行系统测试，考察其在不同条件下的行为变化。

Result: 所有转向方法均能有效减少目标问题，维持基本语言流畅性和相关控制能力，但在分布外情况（如越狱攻击）下表现出显著脆弱性，表明其鲁棒性特异性严重缺失。

Conclusion: 标准的效能与特异性评估不足以保证模型转向的安全性；必须引入鲁棒性评估，否则转向方法可能在表面上表现良好，实则削弱模型安全。

Abstract: Model steering, which involves intervening on hidden representations at inference time, has emerged as a lightweight alternative to finetuning for precisely controlling large language models. While steering efficacy has been widely studied, evaluations of whether interventions alter only the intended property remain limited, especially with respect to unintended changes in behaviors related to the target property. We call this notion specificity. We propose a framework that distinguishes three dimensions of specificity: general (preserving fluency and unrelated abilities), control (preserving related control properties), and robustness (preserving control properties under distribution shifts). We study two safety-critical use cases: steering models to reduce overrefusal and faithfulness hallucinations, and show that while steering achieves high efficacy and largely maintains general and control specificity, it consistently fails to preserve robustness specificity. In the case of overrefusal steering, for example, all steering methods reduce overrefusal without harming general abilities and refusal on harmful queries; however, they substantially increase vulnerability to jailbreaks. Our work provides the first systematic evaluation of specificity in model steering, showing that standard efficacy and specificity checks are insufficient, because without robustness evaluation, steering methods may appear reliable even when they compromise model safety.

</details>


### [124] [On Randomized Algorithms in Online Strategic Classification](https://arxiv.org/abs/2602.06257)
*Chase Hutton,Adam Melrod,Han Shao*

Main category: cs.LG

TL;DR: 本文研究在线策略分类中随机算法的性能，针对可实现与非可实现设置分别提供改进的上下界。在可实现设置中，首次建立适用于随机学习者的下界，并提出首个优于已有确定性上界的随机学习算法。在非可实现设置中，设计基于凸优化的合理学习器，将遗憾上界改进至 $O(\sqrt{T \log |\mathcal{H}|} + |\mathcal{H}| \log(T|\mathcal{H}|))$，并证明该界对所有合理学习规则几乎紧致，表明需借助非合理学习才能进一步提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究对随机算法在在线策略分类中的潜力探索不足，尤其在可实现和非可实现设置下缺乏针对随机学习者的下界及高效算法。此外，当前最优遗憾上界远低于标准在线学习率，亟需改进。

Method: 在可实现设置中，通过扩展确定性学习者的下界分析，引入随机性兼容的构造方法；在非可实现设置中，采用凸优化技术设计合理学习器，并结合信息论与对抗性构造推导匹配下界。

Result: 在可实现设置中，首次建立适用于随机学习者的下界 $\\Omega(\\mathrm{Ldim}(\\mathcal{H}) \\Delta)$，并提出改进的随机学习算法；在非可实现设置中，实现 $O(\\sqrt{T \\log |\\mathcal{H}|} + |\\mathcal{H}| \\log(T|\\mathcal{H}|))$ 的遗憾上界，并证明其对合理学习规则的近似最优性。

Conclusion: 本工作首次系统揭示了随机算法在在线策略分类中的优势，建立了适用于随机学习者的理论下界，提出了更优的随机与合理学习算法，并指出非合理学习是进一步提升遗憾保证的必要路径。

Abstract: Online strategic classification studies settings in which agents strategically modify their features to obtain favorable predictions. For example, given a classifier that determines loan approval based on credit scores, applicants may open or close credit cards and bank accounts to obtain a positive prediction. The learning goal is to achieve low mistake or regret bounds despite such strategic behavior.
  While randomized algorithms have the potential to offer advantages to the learner in strategic settings, they have been largely underexplored. In the realizable setting, no lower bound is known for randomized algorithms, and existing lower bound constructions for deterministic learners can be circumvented by randomization. In the agnostic setting, the best known regret upper bound is $O(T^{3/4}\log^{1/4}T|\mathcal H|)$, which is far from the standard online learning rate of $O(\sqrt{T\log|\mathcal H|})$.
  In this work, we provide refined bounds for online strategic classification in both settings. In the realizable setting, we extend, for $T > \mathrm{Ldim}(\mathcal{H}) Δ^2$, the existing lower bound $Ω(\mathrm{Ldim}(\mathcal{H}) Δ)$ for deterministic learners to all learners. This yields the first lower bound that applies to randomized learners. We also provide the first randomized learner that improves the known (deterministic) upper bound of $O(\mathrm{Ldim}(\mathcal H) \cdot Δ\log Δ)$.
  In the agnostic setting, we give a proper learner using convex optimization techniques to improve the regret upper bound to $O(\sqrt{T \log |\mathcal{H}|} + |\mathcal{H}| \log(T|\mathcal{H}|))$. We show a matching lower bound up to logarithmic factors for all proper learning rules, demonstrating the optimality of our learner among proper learners. As such, improper learning is necessary to further improve regret guarantees.

</details>


### [125] [GRP-Obliteration: Unaligning LLMs With a Single Unlabeled Prompt](https://arxiv.org/abs/2602.06258)
*Mark Russinovich,Yanan Cai,Keegan Hines,Giorgio Severi,Blake Bullwinkel,Ahmed Salem*

Main category: cs.LG

TL;DR: GRP-Oblit是一种仅需单个无标签提示即可有效消除安全对齐的新型方法，能显著削弱模型的安全约束并保持其功能实用性，且适用于语言模型和扩散图像生成系统。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法在部署后容易通过微调被攻破，但传统攻击方法依赖大量数据标注且损害模型性能，亟需更高效、隐蔽且不破坏实用性的攻击手段。

Method: 提出基于组相对策略优化（GRPO）的GRP-Obliteration（GRP-Oblit）方法，利用单一无标签提示直接移除目标模型的安全约束，实现高效、低成本的去对齐。

Result: 在15个7-20B参数规模的模型上测试，涵盖六类实用基准与五类安全基准，GRP-Oblit在所有评估中均优于现有最先进方法，在保持模型实用性的同时显著降低安全对齐强度。

Conclusion: GRP-Oblit证明了安全对齐的脆弱性，揭示当前对齐机制在面对简单、无需标注输入时极易失效，强调需要更鲁棒的安全保障机制。

Abstract: Safety alignment is only as robust as its weakest failure mode. Despite extensive work on safety post-training, it has been shown that models can be readily unaligned through post-deployment fine-tuning. However, these methods often require extensive data curation and degrade model utility.
  In this work, we extend the practical limits of unalignment by introducing GRP-Obliteration (GRP-Oblit), a method that uses Group Relative Policy Optimization (GRPO) to directly remove safety constraints from target models. We show that a single unlabeled prompt is sufficient to reliably unalign safety-aligned models while largely preserving their utility, and that GRP-Oblit achieves stronger unalignment on average than existing state-of-the-art techniques. Moreover, GRP-Oblit generalizes beyond language models and can also unalign diffusion-based image generation systems.
  We evaluate GRP-Oblit on six utility benchmarks and five safety benchmarks across fifteen 7-20B parameter models, spanning instruct and reasoning models, as well as dense and MoE architectures. The evaluated model families include GPT-OSS, distilled DeepSeek, Gemma, Llama, Ministral, and Qwen.

</details>


### [126] [PurSAMERE: Reliable Adversarial Purification via Sharpness-Aware Minimization of Expected Reconstruction Error](https://arxiv.org/abs/2602.06269)
*Vinh Hoang,Sebastian Krumscheid,Holger Rauhut,Raúl Tempone*

Main category: cs.LG

TL;DR: 提出一种新的确定性净化方法，通过将潜在对抗样本映射到靠近数据分布模式的样本，提升分类器的鲁棒性。该方法利用噪声污染数据的重建误差最小化训练得分模型，学习数据分布的结构特征，并在局部邻域内搜索使重建误差最小的净化样本。通过锐度感知最小化引导净化样本进入重建误差景观的平坦区域，增强鲁棒性。理论证明在小噪声极限下，方法可恢复局部密度最大值。实验表明，在强确定性白盒攻击下，该方法显著优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有随机净化方法在对手完全了解系统时会因随机性导致有效鲁棒性下降，因此需要一种确定性方法以保证测试准确性和鲁棒性。

Method: 使用基于噪声污染数据重建误差最小化的得分模型，学习数据分布结构；对输入样本在其局部邻域中搜索最小化重建误差的净化样本；结合锐度感知最小化，引导样本向平坦区域移动，提升鲁棒性。

Result: 在强确定性白盒攻击下，实验结果显示该方法在对抗鲁棒性方面显著优于当前最先进的方法。

Conclusion: 所提出的确定性净化方法能有效提升对抗鲁棒性，且避免了随机方法在已知系统时的性能退化问题，具有良好的理论基础和实验验证。

Abstract: We propose a novel deterministic purification method to improve adversarial robustness by mapping a potentially adversarial sample toward a nearby sample that lies close to a mode of the data distribution, where classifiers are more reliable. We design the method to be deterministic to ensure reliable test accuracy and to prevent the degradation of effective robustness observed in stochastic purification approaches when the adversary has full knowledge of the system and its randomness. We employ a score model trained by minimizing the expected reconstruction error of noise-corrupted data, thereby learning the structural characteristics of the input data distribution. Given a potentially adversarial input, the method searches within its local neighborhood for a purified sample that minimizes the expected reconstruction error under noise corruption and then feeds this purified sample to the classifier. During purification, sharpness-aware minimization is used to guide the purified samples toward flat regions of the expected reconstruction error landscape, thereby enhancing robustness. We further show that, as the noise level decreases, minimizing the expected reconstruction error biases the purified sample toward local maximizers of the Gaussian-smoothed density; under additional local assumptions on the score model, we prove recovery of a local maximizer in the small-noise limit. Experimental results demonstrate significant gains in adversarial robustness over state-of-the-art methods under strong deterministic white-box attacks.

</details>


### [127] [Statistical Learning from Attribution Sets](https://arxiv.org/abs/2602.06276)
*Lorne Applebaum,Robert Busa-Fekete,August Y. Chen,Claudio Gentile,Tomer Koren,Aryan Mokhtari*

Main category: cs.LG

TL;DR: 本文研究在隐私约束下广告点击与转化预测模型的训练问题，其中无法直接关联点击与转化。提出一种基于不可见对手生成的归因集（attribution sets）的学习框架，通过构建无偏损失估计器，证明经验风险最小化可实现与先验信息量相关的泛化性能，并对先验估计误差具有鲁棒性。实验表明该方法优于行业常用启发式方法，尤其在归因集较大或重叠时表现更优。


<details>
  <summary>Details</summary>
Motivation: 由于隐私保护浏览器API和第三方Cookie的淘汰，广告领域面临无法直接关联点击与转化的问题。现有方法依赖于启发式归因规则，但缺乏理论保证且易受归因集复杂性影响。因此需要一种能从模糊归因集中学习并保持统计有效性的新方法。

Method: 提出一种基于先验分布的归因集学习框架，设计无偏损失估计器，利用该估计器进行经验风险最小化，并分析其泛化界及对先验误差的鲁棒性。

Result: 所提方法在理论上实现了与先验信息量相关的泛化性能，且对先验估计误差具有鲁棒性；实验证明其显著优于常见启发式方法，尤其在归因集大或重叠的情况下。

Conclusion: 本文为隐私受限下的归因学习提供了理论支持与实用方法，展示了无偏估计与经验风险最小化在复杂归因结构中的有效性，为未来隐私友好型广告系统提供新思路。

Abstract: We address the problem of training conversion prediction models in advertising domains under privacy constraints, where direct links between ad clicks and conversions are unavailable. Motivated by privacy-preserving browser APIs and the deprecation of third-party cookies, we study a setting where the learner observes a sequence of clicks and a sequence of conversions, but can only link a conversion to a set of candidate clicks (an attribution set) rather than a unique source. We formalize this as learning from attribution sets generated by an oblivious adversary equipped with a prior distribution over the candidates. Despite the lack of explicit labels, we construct an unbiased estimator of the population loss from these coarse signals via a novel approach. Leveraging this estimator, we show that Empirical Risk Minimization achieves generalization guarantees that scale with the informativeness of the prior and is also robust against estimation errors in the prior, despite complex dependencies among attribution sets. Simple empirical evaluations on standard datasets suggest our unbiased approach significantly outperforms common industry heuristics, particularly in regimes where attribution sets are large or overlapping.

</details>


### [128] [SOCKET: SOft Collison Kernel EsTimator for Sparse Attention](https://arxiv.org/abs/2602.06283)
*Sahil Joshi,Agniva Chowdhury,Wyatt Bellinger,Amar Kanakamedala,Ekam Singh,Hoang Anh Duy Le,Aditya Desai,Anshumali Shrivastava*

Main category: cs.LG

TL;DR: SOCKET introduces a soft collision kernel estimator that improves sparse attention in large language models by replacing hard LSH bucket matches with probabilistic, similarity-aware aggregation, enabling more accurate and efficient token selection during long-context inference. It outperforms existing methods in throughput and accuracy, with up to 1.5x speedup over FlashAttention.


<details>
  <summary>Details</summary>
Motivation: Sparse attention is crucial for scaling large language models during long-context inference, but its effectiveness relies on efficient and accurate scoring of relevant tokens. Traditional Locality-Sensitive Hashing (LSH) uses hard bucket matches, which produce discrete collision signals unsuitable for ranking, leading to suboptimal token selection.

Method: SOCKET replaces hard LSH with a soft collision kernel that aggregates graded evidence across hash tables, preserving relative ordering among top-k tokens. This enables principled scoring without ad-hoc voting. Custom CUDA kernels and a Flash Decode Triton backend are used for efficient implementation.

Result: SOCKET matches or exceeds established sparse attention baselines across multiple long-context benchmarks, achieves up to 1.5x higher throughput than FlashAttention, and provides a mathematically grounded approach to sparse attention.

Conclusion: SOCKET transforms LSH from a heuristic into a principled scoring kernel, significantly improving the efficiency and accuracy of sparse attention in long-context inference, making it a powerful tool for scaling large language models.

Abstract: Exploiting sparsity during long-context inference is central to scaling large language models, as attention dominates the cost of autoregressive decoding. Sparse attention reduces this cost by restricting computation to a subset of tokens, but its effectiveness depends critically on efficient scoring and selection of relevant tokens at inference time. We revisit Locality-Sensitive Hashing (LSH) as a sparsification primitive and introduce SOCKET, a SOft Collision Kernel EsTimator that replaces hard bucket matches with probabilistic, similarity-aware aggregation. Our key insight is that hard LSH produces discrete collision signals and is therefore poorly suited for ranking. In contrast, soft LSH aggregates graded collision evidence across hash tables, preserving the stability of relative ordering among the true top-$k$ tokens. This transformation elevates LSH from a candidate-generation heuristic to a principled and mathematically grounded scoring kernel for sparse attention. Leveraging this property, SOCKET enables efficient token selection without ad-hoc voting mechanism, and matches or surpasses established sparse attention baselines across multiple long-context benchmarks using diverse set of models. With a custom CUDA kernel for scoring keys and a Flash Decode Triton backend for sparse attention, SOCKET achieves up to 1.5$\times$ higher throughput than FlashAttention, making it an effective tool for long-context inference. Code is open-sourced at https://github.com/amarka8/SOCKET.

</details>


### [129] [The Condensate Theorem: Transformers are O(n), Not $O(n^2)$](https://arxiv.org/abs/2602.06317)
*Jorge L. Ruiz Williams*

Main category: cs.LG

TL;DR: 本文提出'凝聚定理'：注意力稀疏性是学习到的拓扑属性，而非架构约束。通过分析训练好的语言模型，发现注意力质量集中在特定拓扑流形上，且该流形可动态识别而不必检查每个位置。证明了对任意查询，将注意力投影到凝聚流形（锚点+窗口+动态Top-k）可实现与全量O(n²)注意力完全等价的结果，非近似而是精确匹配。在GPT-2、Pythia、Qwen2、TinyLlama和Mistral上验证，生成1500+个标记时实现比特级精确匹配。将此拓扑映射至硬件后，拓扑注意力内核在13.1万标记下实测提速159倍（3.94ms vs 628ms），在100万标记下预估提速超1200倍，相比Flash Attention推理成本降低超过99.9%。结论：二次方瓶颈是低效实现的产物，而非智能本质。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制存在O(n²)计算复杂度瓶颈，尽管已有优化方法如Flash Attention，但其仍受限于固定架构假设。本文旨在探究注意力稀疏性是否为可学习的内在拓扑结构，从而突破传统计算范式，实现真正高效且无损的推理加速。

Method: 提出凝聚流形概念（Anchor + Window + Dynamic Top-k），通过实证分析训练语言模型中的注意力分布，识别出注意力质量集中的拓扑结构；设计投影算法将注意力集中于该流形，实现与完整注意力的比特级等价；构建拓扑注意力内核，并在多种主流模型上进行验证与性能评估。

Result: 在多个主流大模型上实现与全注意力完全一致的输出结果，生成1500+令牌时达到比特精确匹配；拓扑注意力内核在13.1万令牌下实测速度提升159倍，100万令牌下预估提升超1200倍，推理成本降低超过99.9%。

Conclusion: 注意力的二次方复杂度瓶颈并非由模型本质决定，而是源于传统实现方式的低效。注意力稀疏性是可学习的拓扑性质，通过动态识别并利用凝聚流形，可在保持输出完全等价的前提下实现极致加速，彻底重构高效大模型推理范式。

Abstract: We present the Condensate Theorem: attention sparsity is a learned topological property, not an architectural constraint. Through empirical analysis of trained language models, we find that attention mass concentrates on a distinct topological manifold -- and this manifold can be identified dynamically without checking every position. We prove a general result: for any query, projecting attention onto the Condensate Manifold (Anchor + Window + Dynamic Top-k) achieves 100% output equivalence with full $O(n^2)$ attention. This is not an approximation -- it is lossless parity. We validate this across GPT-2, Pythia, Qwen2, TinyLlama, and Mistral, demonstrating bit-exact token matching on 1,500+ generated tokens. By mapping this topology to hardware, our Topological Attention kernel achieves a 159x measured speedup at 131K tokens (3.94ms vs 628ms) and a projected >1,200x speedup at 1M tokens, reducing inference costs by >99.9% compared to Flash Attention. We conclude that the quadratic bottleneck is an artifact of naive implementation, not intelligence.

</details>


### [130] [How (Not) to Hybridize Neural and Mechanistic Models for Epidemiological Forecasting](https://arxiv.org/abs/2602.06323)
*Yiqi Su,Ray Lee,Jiaming Cui,Naren Ramakrishnan*

Main category: cs.LG

TL;DR: 该论文提出一种结合机制性流行病模型与神经微分方程的混合框架，通过分解感染数据为趋势、季节性和残差成分，作为可解释的控制信号来驱动连续时间隐变量动态，从而在部分可观测和非平稳传播环境下实现更稳健的流行病预测。该方法在长时程预测误差、峰值时间偏差和峰值幅度偏差方面均显著优于现有基线模型，且无需依赖辅助协变量。


<details>
  <summary>Details</summary>
Motivation: 在流行病监测数据中进行预测是一个难题，尤其是在部分可观测和不断变化的传播动态（如行为改变、免疫力衰减、季节性及干预措施）下，传统混合模型容易失效。因此需要显式建模非平稳性以提升鲁棒性。

Method: 将感染数据分解为趋势、季节性和残差成分，利用这些成分作为控制信号输入到受控神经微分方程中，与流行病学模型耦合，联合预测并推断随时间变化的传播率、恢复率和免疫丧失率。

Result: 在季节性和非季节性场景下，包括早期暴发和多波次疫情，该方法相比强基线模型（时间序列、神经ODE、混合模型），长期预测均方根误差降低15-35%，峰值时间误差减少1-3周，峰值幅度偏差降低最多达30%。

Conclusion: 显式建模多尺度非平稳结构是实现鲁棒流行病预测的关键；所提方法在无外部协变量情况下仍表现优异，具有良好的可解释性和泛化能力。

Abstract: Epidemiological forecasting from surveillance data is a hard problem and hybridizing mechanistic compartmental models with neural models is a natural direction. The mechanistic structure helps keep trajectories epidemiologically plausible, while neural components can capture non-stationary, data-adaptive effects. In practice, however, many seemingly straightforward couplings fail under partial observability and continually shifting transmission dynamics driven by behavior, waning immunity, seasonality, and interventions. We catalog these failure modes and show that robust performance requires making non-stationarity explicit: we extract multi-scale structure from the observed infection series and use it as an interpretable control signal for a controlled neural ODE coupled to an epidemiological model. Concretely, we decompose infections into trend, seasonal, and residual components and use these signals to drive continuous-time latent dynamics while jointly forecasting and inferring time-varying transmission, recovery, and immunity-loss rates. Across seasonal and non-seasonal settings, including early outbreaks and multi-wave regimes, our approach reduces long-horizon RMSE by 15-35%, improves peak timing error by 1-3 weeks, and lowers peak magnitude bias by up to 30% relative to strong time-series, neural ODE, and hybrid baselines, without relying on auxiliary covariates.

</details>


### [131] [Don't Break the Boundary: Continual Unlearning for OOD Detection Based on Free Energy Repulsion](https://arxiv.org/abs/2602.06331)
*Ningkang Peng,Kun Shao,Jingyang Mao,Linjing Qian,Xiaoqian Peng,Xichen Yang,Yanhui Gu*

Main category: cs.LG

TL;DR: TFER框架通过引入基于自由能原理的推拉机制，实现边界保持的类遗忘，使被遗忘类别被驱逐至高能异常区域，同时保留核心类在低能正常数据流形中，从而在不破坏模型异常检测能力的前提下完成高效、参数高效的遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测依赖紧凑的数据流形结构，而传统分类导向的遗忘方法会破坏这一结构，导致模型无法识别异常，形成几何矛盾。需要一种既能满足隐私合规又能保持系统安全的灵活遗忘机制。

Method: 提出边界保持类遗忘问题，定义遗忘即把目标类转化为OOD样本；设计TFER框架，采用自由能排斥力将遗忘类推向高能异常区域，同时用拉力锚定保留类在低能流形中，通过参数高效微调实现，避免全量重训练。

Result: 实验表明TFER在精确遗忘的同时，最大程度保留了模型对剩余类和外部OOD数据的判别能力；其推拉平衡机制赋予模型内在结构稳定性，有效抵抗灾难性遗忘，适用于持续遗忘任务。

Conclusion: TFER通过概念重构与物理启发的机制设计，成功解决了OOD检测与机器遗忘之间的根本矛盾，为可信AI在开放世界中的部署提供了兼具安全性与灵活性的新范式。

Abstract: Deploying trustworthy AI in open-world environments faces a dual challenge: the necessity for robust Out-of-Distribution (OOD) detection to ensure system safety, and the demand for flexible machine unlearning to satisfy privacy compliance and model rectification. However, this objective encounters a fundamental geometric contradiction: current OOD detectors rely on a static and compact data manifold, whereas traditional classification-oriented unlearning methods disrupt this delicate structure, leading to a catastrophic loss of the model's capability to discriminate anomalies while erasing target classes. To resolve this dilemma, we first define the problem of boundary-preserving class unlearning and propose a pivotal conceptual shift: in the context of OOD detection, effective unlearning is mathematically equivalent to transforming the target class into OOD samples. Based on this, we propose the TFER (Total Free Energy Repulsion) framework. Inspired by the free energy principle, TFER constructs a novel Push-Pull game mechanism: it anchors retained classes within a low-energy ID manifold through a pull mechanism, while actively expelling forgotten classes to high-energy OOD regions using a free energy repulsion force. This approach is implemented via parameter-efficient fine-tuning, circumventing the prohibitive cost of full retraining. Extensive experiments demonstrate that TFER achieves precise unlearning while maximally preserving the model's discriminative performance on remaining classes and external OOD data. More importantly, our study reveals that the unique Push-Pull equilibrium of TFER endows the model with inherent structural stability, allowing it to effectively resist catastrophic forgetting without complex additional constraints, thereby demonstrating exceptional potential in continual unlearning tasks.

</details>


### [132] [Adversarial Learning in Games with Bandit Feedback: Logarithmic Pure-Strategy Maximin Regret](https://arxiv.org/abs/2602.06348)
*Shinji Ito,Haipeng Luo,Arnab Maiti,Taira Tsuchiya,Yue Wu*

Main category: cs.LG

TL;DR: 本文研究在带宽反馈下的零和博弈中，如何最小化对最大最小纯策略的偏差（即纯策略最大最小后悔值）。针对无信息和有信息两种带宽反馈模型，提出了Tsallis-INF和Maximin-UCB算法，在无信息情况下实现了依赖于游戏参数c的$O(c \log T)$后悔界，并证明该依赖关系是信息论下必要的；在有信息情况下，通过Maximin-UCB进一步降低依赖参数$ c' $，实现更优的对数级后悔。此外，将结果推广到任意大动作集的双线性博弈，提出相应算法并建立类似对数后悔界。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，学习者常面临未知对手且只能获得局部反馈（仅可观测所选动作的回报），此时外部后悔下界为$Ω(√T)$，难以突破。因此需要引入新的评价指标——纯策略最大最小后悔，以更好地刻画对抗学习中的性能表现。

Method: 提出两种算法：在无信息带宽反馈下使用Tsallis-INF，结合信息论分析与实例依赖设计；在有信息情况下引入Maximin-UCB，利用对手动作信息优化探索。进一步将方法扩展至双线性博弈，设计Tsallis-FTRL-SPM和Maximin-LinUCB，分别处理不同反馈场景。

Result: 在无信息设置下，Tsallis-INF实现$O(c \\log T)$的实例依赖后悔界，且证明了参数c的必要性；在有信息设置下，Maximin-UCB实现更优的$O(c' \\log T)$后悔界，其中$ c' \\ll c $可能成立；对于大动作集双线性博弈，也建立了类似的对数后悔界。

Conclusion: 本工作首次系统地分析了在带宽反馈下零和博弈中的纯策略最大最小后悔问题，揭示了其内在难度与可解性边界。提出的算法在理论和实践中均展现出优越性能，为复杂对抗环境下的学习提供了新范式。

Abstract: Learning to play zero-sum games is a fundamental problem in game theory and machine learning. While significant progress has been made in minimizing external regret in the self-play settings or with full-information feedback, real-world applications often force learners to play against unknown, arbitrary opponents and restrict learners to bandit feedback where only the payoff of the realized action is observable. In such challenging settings, it is well-known that $Ω(\sqrt{T})$ external regret is unavoidable (where T is the number of rounds). To overcome this barrier, we investigate adversarial learning in zero-sum games under bandit feedback, aiming to minimize the deficit against the maximin pure strategy -- a metric we term Pure-Strategy Maximin Regret.
  We analyze this problem under two bandit feedback models: uninformed (only the realized reward is revealed) and informed (both the reward and the opponent's action are revealed). For uninformed bandit learning of normal-form games, we show that the Tsallis-INF algorithm achieves $O(c \log T)$ instance-dependent regret with a game-dependent parameter $c$. Crucially, we prove an information-theoretic lower bound showing that the dependence on c is necessary. To overcome this hardness, we turn to the informed setting and introduce Maximin-UCB, which obtains another regret bound of the form $O(c' \log T)$ for a different game-dependent parameter $c'$ that could potentially be much smaller than $c$. Finally, we generalize both results to bilinear games over an arbitrary, large action set, proposing Tsallis-FTRL-SPM and Maximin-LinUCB for the uninformed and informed setting respectively and establishing similar game-dependent logarithmic regret bounds.

</details>


### [133] [Enhance and Reuse: A Dual-Mechanism Approach to Boost Deep Forest for Label Distribution Learning](https://arxiv.org/abs/2602.06353)
*Jia-Le Xu,Shen-Huan Lyu,Yu-Nian Wang,Ning Chen,Zhihao Qu,Bin Tang,Baoliu Ye*

Main category: cs.LG

TL;DR: 提出了一种名为ERDF的增强和重用特征深度森林方法，用于标签分布学习（LDL），通过利用标签相关性增强特征并重用表现较差样本的特征，提升训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度森林方法在标签分布学习中未能有效利用标签间的相关性，导致性能受限。

Method: ERDF包含两个机制：特征增强（利用标签相关性增强原始特征）和度量感知特征重用（对验证集表现不佳的样本特征进行重用，确保训练稳定性）。

Result: 实验表明，ERDF在六个评估指标上均优于其他对比算法，验证了其有效性与优越性。

Conclusion: ERDF通过增强-重用模式有效提升了标签分布学习中的特征表达能力和训练稳定性，具有良好的应用前景。

Abstract: Label distribution learning (LDL) requires the learner to predict the degree of correlation between each sample and each label. To achieve this, a crucial task during learning is to leverage the correlation among labels. Deep Forest (DF) is a deep learning framework based on tree ensembles, whose training phase does not rely on backpropagation. DF performs in-model feature transform using the prediction of each layer and achieves competitive performance on many tasks. However, its exploration in the field of LDL is still in its infancy. The few existing methods that apply DF to the field of LDL do not have effective ways to utilize the correlation among labels. Therefore, we propose a method named Enhanced and Reused Feature Deep Forest (ERDF). It mainly contains two mechanisms: feature enhancement exploiting label correlation and measure-aware feature reuse. The first one is to utilize the correlation among labels to enhance the original features, enabling the samples to acquire more comprehensive information for the task of LDL. The second one performs a reuse operation on the features of samples that perform worse than the previous layer on the validation set, in order to ensure the stability of the training process. This kind of Enhance-Reuse pattern not only enables samples to enrich their features but also validates the effectiveness of their new features and conducts a reuse process to prevent the noise from spreading further. Experiments show that our method outperforms other comparison algorithms on six evaluation metrics.

</details>


### [134] [Evaluating LLM-persona Generated Distributions for Decision-making](https://arxiv.org/abs/2602.06357)
*Jackie Baek,Yunhan Chen,Ziyu Chi,Will Ma*

Main category: cs.LG

TL;DR: 该论文研究了大型语言模型（LLM）生成的分布对下游决策的支持效果，提出使用基于决策结果的评估指标来衡量这些分布的质量。以组合优化、定价和报童问题为例，发现LLM生成的分布尤其在数据稀缺情况下具有实际应用价值。同时指出，如Wasserstein距离等与决策无关的评估指标可能误导对分布质量的判断。


<details>
  <summary>Details</summary>
Motivation: 探索LLM生成的数据分布是否能有效支持实际决策，特别是在数据有限的情况下，以及现有评估方法是否适合用于判断这些分布对决策的实际帮助。

Method: 通过三个典型决策问题（组合优化、定价、报童问题）进行实证分析，比较LLM生成分布与真实分布的决策表现，并引入基于决策结果的评估指标，避免依赖传统决策无关的度量方式。

Result: LLM生成的分布能够有效支持决策，尤其在低数据条件下表现良好；而传统的决策无关指标（如Wasserstein距离）可能无法准确反映其对决策的实际贡献。

Conclusion: LLM-SAA方法在低数据场景下具备实用价值，应采用基于决策结果的评估标准来更准确地衡量LLM生成分布的质量。

Abstract: LLMs can generate a wealth of data, ranging from simulated personas imitating human valuations and preferences, to demand forecasts based on world knowledge. But how well do such LLM-generated distributions support downstream decision-making? For example, when pricing a new product, a firm could prompt an LLM to simulate how much consumers are willing to pay based on a product description, but how useful is the resulting distribution for optimizing the price? We refer to this approach as LLM-SAA, in which an LLM is used to construct an estimated distribution and the decision is then optimized under that distribution. In this paper, we study metrics to evaluate the quality of these LLM-generated distributions, based on the decisions they induce. Taking three canonical decision-making problems (assortment optimization, pricing, and newsvendor) as examples, we find that LLM-generated distributions are practically useful, especially in low-data regimes. We also show that decision-agnostic metrics such as Wasserstein distance can be misleading when evaluating these distributions for decision-making.

</details>


### [135] [Uniform Spectral Growth and Convergence of Muon in LoRA-Style Matrix Factorization](https://arxiv.org/abs/2602.06385)
*Changmin Kang,Jihun Yun,Baekrok Shin,Yeseul Cho,Chulhee Yun*

Main category: cs.LG

TL;DR: Spectral gradient descent (SpecGD) methods like Muon show strong performance in LLM training, particularly in LoRA fine-tuning. This paper reveals a unique spectral phenomenon: under Muon, singular values of the LoRA product grow nearly uniformly across the spectrum despite separate orthogonalization of factors. The authors analyze spectral gradient flow (SpecGF) in a simplified LoRA setting and prove 'equal-rate' dynamics—singular values grow at equal rates with small deviations. This leads to smaller singular values reaching target values earlier than larger ones, contrasting with standard gradient flow’s largest-first learning. The theory shows global convergence from almost all initializations if factor norms are bounded; with ℓ₂ regularization, global convergence is guaranteed. Experiments confirm the theoretical findings.


<details>
  <summary>Details</summary>
Motivation: To understand the mysterious success of SpecGD-based optimizers like Muon in LoRA fine-tuning of LLMs, especially the unexpected uniform growth of singular values despite separate orthogonalization of low-rank factors.

Method: The authors study spectral gradient flow (SpecGF), a continuous-time model of SpecGD, in a simplified LoRA-style matrix factorization setup. They derive analytical results on singular value dynamics, proving equal-rate growth and convergence properties under bounded factor norms or ℓ₂ regularization.

Result: In the LoRA setting, singular values grow at nearly equal rates, leading to early convergence of smaller singular values. The system converges globally from almost all initializations when factor norms are bounded; with ℓ₂ regularization, global convergence is ensured. Experimental validation supports the theoretical predictions.

Conclusion: The equal-rate singular value growth explains the effectiveness of SpecGD in LoRA fine-tuning. Theoretical analysis confirms global convergence under mild conditions, offering insight into why such optimizers work well in practice.

Abstract: Spectral gradient descent (SpecGD) orthogonalizes the matrix parameter updates and has inspired practical optimizers such as Muon. They often perform well in large language model (LLM) training, but their dynamics remain poorly understood. In the low-rank adaptation (LoRA) setting, where weight updates are parameterized as a product of two low-rank factors, we find a distinctive spectral phenomenon under Muon in LoRA fine-tuning of LLMs: singular values of the LoRA product show near-uniform growth across the spectrum, despite orthogonalization being performed on the two factors separately. Motivated by this observation, we analyze spectral gradient flow (SpecGF)-a continuous-time analogue of SpecGD-in a simplified LoRA-style matrix factorization setting and prove "equal-rate" dynamics: all singular values grow at equal rates up to small deviations. Consequently, smaller singular values attain their target values earlier than larger ones, sharply contrasting with the largest-first stepwise learning observed in standard gradient flow. Moreover, we prove that SpecGF in our setting converges to global minima from almost all initializations, provided the factor norms remain bounded; with $\ell_2$ regularization, we obtain global convergence. Lastly, we corroborate our theory with experiments in the same setting.

</details>


### [136] [Generating High-quality Privacy-preserving Synthetic Data](https://arxiv.org/abs/2602.06390)
*David Yavo,Richard Khoury,Christophe Pere,Sadoune Ait Kaci Azzou*

Main category: cs.LG

TL;DR: 本文提出一种简单、模型无关的后处理框架，用于提升合成表格数据在分布保真度、下游效用和隐私保护之间的平衡。通过模式修补修复缺失或严重不足的类别，同时保留学习到的依赖关系；再通过k近邻过滤器移除与真实数据点过近的合成记录，确保真实与合成样本间的最小距离。该框架应用于两种神经生成模型（前馈生成器和变分自编码器），在三个公开数据集上评估，结果显示：在适度阈值（0.2–0.35）下，合成数据的类别分布偏差降低最高达36%，成对依赖关系保留提升10–14%，下游预测性能仅下降约1%，且隐私指标（如最近邻距离）改善，属性推断攻击成功率基本不变。该方法为实际部署合成数据提供了实用指导，可与形式化差分隐私方法互补。


<details>
  <summary>Details</summary>
Motivation: 合成表格数据在共享敏感记录方面具有潜力，但其实际应用需在分布保真度、下游任务效用和隐私保护之间取得良好平衡。现有方法在类别缺失、分布偏差及隐私泄露方面存在不足，亟需一种通用、有效的后处理策略来提升合成数据质量与安全性。

Method: 提出一种模型无关的后处理框架，包含两个步骤：1）模式修补（mode patching），修复合成数据中缺失或严重低频的类别，保持原有依赖结构；2）k近邻过滤（kNN filter），移除与真实数据点距离过近的合成记录，强制真实与合成样本间保持最小距离。该框架可应用于任意合成数据生成器，无需修改原模型。

Result: 在三个公共数据集（信用卡交易、心血管健康、人口收入）上验证，使用0.2–0.35的阈值时，合成数据的类别分布偏差减少最高达36%，联合分布依赖性保留提升10–14%；下游模型在真实数据上的性能仅比原始基线下降约1%；隐私指标（如最近邻距离）显著改善，属性推断攻击成功率基本不变。结果表明该方法有效提升了合成数据的质量与实用性。

Conclusion: 该后处理框架能有效提升合成表格数据的分布保真度与隐私保护能力，同时维持较高的下游任务性能，提供了一种实用、通用的改进路径，适用于与形式化差分隐私方法协同使用，推动合成数据的实际落地应用。

Abstract: Synthetic tabular data enables sharing and analysis of sensitive records, but its practical deployment requires balancing distributional fidelity, downstream utility, and privacy protection. We study a simple, model agnostic post processing framework that can be applied on top of any synthetic data generator to improve this trade off. First, a mode patching step repairs categories that are missing or severely underrepresented in the synthetic data, while largely preserving learned dependencies. Second, a k nearest neighbor filter replaces synthetic records that lie too close to real data points, enforcing a minimum distance between real and synthetic samples. We instantiate this framework for two neural generative models for tabular data, a feed forward generator and a variational autoencoder, and evaluate it on three public datasets covering credit card transactions, cardiovascular health, and census based income. We assess marginal and joint distributional similarity, the performance of models trained on synthetic data and evaluated on real data, and several empirical privacy indicators, including nearest neighbor distances and attribute inference attacks. With moderate thresholds between 0.2 and 0.35, the post processing reduces divergence between real and synthetic categorical distributions by up to 36 percent and improves a combined measure of pairwise dependence preservation by 10 to 14 percent, while keeping downstream predictive performance within about 1 percent of the unprocessed baseline. At the same time, distance based privacy indicators improve and the success rate of attribute inference attacks remains largely unchanged. These results provide practical guidance for selecting thresholds and applying post hoc repairs to improve the quality and empirical privacy of synthetic tabular data, while complementing approaches that provide formal differential privacy guarantees.

</details>


### [137] [Near-Optimal Regret for Distributed Adversarial Bandits: A Black-Box Approach](https://arxiv.org/abs/2602.06404)
*Hao Qiu,Mengxiao Zhang,Nicolò Cesa-Bianchi*

Main category: cs.LG

TL;DR: 本文研究分布式对抗性老虎机问题，提出一种基于延迟反馈的黑箱归约的新算法，通过仅需通过广播通信的机制，实现了显著优于先前最优结果的上界，其最小最大遗憾为 $\tilde{\Theta}(\sqrt{(\rho^{-1/2} + K/N)T})$，其中 $\rho$ 为通信矩阵的谱间隙。研究还给出了匹配的下界，并展示了方法在首阶和双世界最优情况下的通用性。进一步扩展至分布式线性老虎机问题，获得 $\tilde{O}(\sqrt{(\rho^{-1/2} + 1/N)dT})$ 的遗憾界，且每轮通信成本仅为 $O(d)$。


<details>
  <summary>Details</summary>
Motivation: 在分布式对抗性老虎机中，多个智能体需协作以最小化全局平均损失，但只能观测自身局部损失。现有方法在通信效率与学习性能之间存在权衡，尤其在高通信代价或低通信频率下表现不佳。因此，亟需设计一种高效且鲁棒的算法，兼顾通信开销与学习性能。

Method: 提出一种新颖的黑箱归约方法，将分布式对抗性老虎机问题转化为带延迟反馈的单机老虎机问题。利用随机广播（gossip）机制实现通信，结合谱间隙控制通信效率，引入体积生成树（volumetric spanner）降低线性情形下的通信复杂度。

Result: 在一般对抗性设置下，实现 $\tilde{O}(\sqrt{(\rho^{-1/2} + K/N)T})$ 遗憾上界，显著优于之前 $\tilde{O}(\rho^{-1/3}(KT)^{2/3})$ 的结果；给出匹配下界，揭示通信成本 $\rho^{-1/4}\sqrt{T}$ 与带宽成本 $\sqrt{KT/N}$ 的分解结构；首次在分布式对抗环境中获得首阶和双世界最优界限；在分布式线性老虎机中达到 $\tilde{O}(\sqrt{(\rho^{-1/2} + 1/N)dT})$ 遗憾，且通信成本仅 $O(d)$ 每轮。

Conclusion: 本工作建立了分布式对抗性老虎机问题的最优遗憾率，揭示了通信与学习之间的基本权衡，并提出了一种高效、通用且可扩展的算法框架，适用于多种场景，包括线性带宽环境，为未来多智能体系统中的高效协作学习提供了理论基础与实践工具。

Abstract: We study distributed adversarial bandits, where $N$ agents cooperate to minimize the global average loss while observing only their own local losses. We show that the minimax regret for this problem is $\tildeΘ(\sqrt{(ρ^{-1/2}+K/N)T})$, where $T$ is the horizon, $K$ is the number of actions, and $ρ$ is the spectral gap of the communication matrix. Our algorithm, based on a novel black-box reduction to bandits with delayed feedback, requires agents to communicate only through gossip. It achieves an upper bound that significantly improves over the previous best bound $\tilde{O}(ρ^{-1/3}(KT)^{2/3})$ of Yi and Vojnovic (2023). We complement this result with a matching lower bound, showing that the problem's difficulty decomposes into a communication cost $ρ^{-1/4}\sqrt{T}$ and a bandit cost $\sqrt{KT/N}$. We further demonstrate the versatility of our approach by deriving first-order and best-of-both-worlds bounds in the distributed adversarial setting. Finally, we extend our framework to distributed linear bandits in $R^d$, obtaining a regret bound of $\tilde{O}(\sqrt{(ρ^{-1/2}+1/N)dT})$, achieved with only $O(d)$ communication cost per agent and per round via a volumetric spanner.

</details>


### [138] [Adaptive Protein Tokenization](https://arxiv.org/abs/2602.06418)
*Rohit Dilip,Ayush Varshney,David Van Valen*

Main category: cs.LG

TL;DR: 本文提出一种全局蛋白质结构分词方法，通过逐步增加细节来构建全局表示，解决了基于局部分词的生成模型中的误差累积、序列压缩操作依赖及信息内容不可调等问题。该方法在重建、生成和表征任务中表现优于或相当现有模型，并支持基于信息内容的推理标准，提升蛋白质设计性；在CATH分类任务中，非线性探测性能优于其他分词器；还支持零样本蛋白质缩小和亲和力成熟。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质结构分词方法依赖局部邻域信息聚合，限制了其在生成和表征任务中的性能，尤其存在误差累积、需序列压缩、信息内容不可调等缺陷。

Method: 提出一种全局分词方法，通过逐个生成的令牌逐步添加细节，形成高阶全局表示，实现无序列压缩的嵌入表示，并支持任务特定的信息内容调整。

Result: 在重建、生成、表征任务中表现匹配或超越现有模型；非线性探测在CATH分类中优于其他分词器；支持零样本蛋白质缩小与亲和力成熟；可通过信息内容自适应优化推理。

Conclusion: 所提全局分词方法有效克服了局部分词的局限性，显著提升了蛋白质多模态模型在生成、表征与设计任务中的性能，具有良好的可扩展性和应用潜力。

Abstract: Tokenization is a promising path to multi-modal models capable of jointly understanding protein sequences, structure, and function. Existing protein structure tokenizers create tokens by pooling information from local neighborhoods, an approach that limits their performance on generative and representation tasks. In this work, we present a method for global tokenization of protein structures in which successive tokens contribute increasing levels of detail to a global representation. This change resolves several issues with generative models based on local protein tokenization: it mitigates error accumulation, provides embeddings without sequence-reduction operations, and allows task-specific adaptation of a tokenized sequence's information content. We validate our method on reconstruction, generative, and representation tasks and demonstrate that it matches or outperforms existing models based on local protein structure tokenizers. We show how adaptive tokens enable inference criteria based on information content, which boosts designability. We validate representations generated from our tokenizer on CATH classification tasks and demonstrate that non-linear probing on our tokenized sequences outperforms equivalent probing on representations from other tokenizers. Finally, we demonstrate how our method supports zero-shot protein shrinking and affinity maturation.

</details>


### [139] [Reclaiming First Principles: A Differentiable Framework for Conceptual Hydrologic Models](https://arxiv.org/abs/2602.06429)
*Jasper A. Vrugt,Jonathan M. Frame,Ethan Bollman*

Main category: cs.LG

TL;DR: 提出了一种基于精确参数敏感性的可微分水文建模框架，通过在常微分方程系统中引入敏感性方程，联合演化模型状态与参数的雅可比矩阵，实现完全解析的梯度计算。该方法避免了数值微分的步长依赖和噪声问题，也规避了伴随方法的不稳定性及现代自动微分工具链的开销，提供确定性、物理可解释且易于嵌入优化器的梯度，显著提升概念性水文模型的校准速度与稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的参数估计方法依赖有限差分或自动微分框架（如JAX、PyTorch），存在计算开销大、截断误差、求解器不稳定等问题，尤其在概念性流域模型的微分方程系统中表现不佳，亟需一种高效、稳定且可解释的可微分建模方法。

Method: 通过在原微分方程组中增补敏感性方程，构建包含状态变量与参数敏感性（雅可比矩阵）的联合系统，同步求解模型状态及其对所有参数的导数，从而获得完全解析的梯度。

Result: 实现了无步长依赖、无噪声的确定性梯度，支持多种目标函数（如均方误差、纳什-萨特克利夫效率、流量历时曲线等），显著提升校准效率与稳定性，无需依赖外部自动微分库。

Conclusion: 该框架为概念性水文模型提供了快速、稳定、透明的梯度校准能力，真正释放可微分建模的潜力，同时保持物理可解释性与计算高效性。

Abstract: Conceptual hydrologic models remain the cornerstone of rainfall-runoff modeling, yet their calibration is often slow and numerically fragile. Most gradient-based parameter estimation methods rely on finite-difference approximations or automatic differentiation frameworks (e.g., JAX, PyTorch and TensorFlow), which are computationally demanding and introduce truncation errors, solver instabilities, and substantial overhead. These limitations are particularly acute for the ODE systems of conceptual watershed models. Here we introduce a fully analytic and computationally efficient framework for differentiable hydrologic modeling based on exact parameter sensitivities. By augmenting the governing ODE system with sensitivity equations, we jointly evolve the model states and the Jacobian matrix with respect to all parameters. This Jacobian then provides fully analytic gradient vectors for any differentiable loss function. These include classical objective functions such as the sum of absolute and squared residuals, widely used hydrologic performance metrics such as the Nash-Sutcliffe and Kling-Gupta efficiencies, robust loss functions that down-weight extreme events, and hydrograph-based functionals such as flow-duration and recession curves. The analytic sensitivities eliminate the step-size dependence and noise inherent to numerical differentiation, while avoiding the instability of adjoint methods and the overhead of modern machine-learning autodiff toolchains. The resulting gradients are deterministic, physically interpretable, and straightforward to embed in gradient-based optimizers. Overall, this work enables rapid, stable, and transparent gradient-based calibration of conceptual hydrologic models, unlocking the full potential of differentiable modeling without reliance on external, opaque, or CPU-intensive automatic-differentiation libraries.

</details>


### [140] [Is Gradient Ascent Really Necessary? Memorize to Forget for Machine Unlearning](https://arxiv.org/abs/2602.06441)
*Zhuo Huang,Qizhou Wang,Ziming Hong,Shanshan Ye,Bo Han,Tongliang Liu*

Main category: cs.LG

TL;DR: 本文提出一种基于模型外推的机器遗忘方法，以解决传统梯度上升法在遗忘敏感数据时导致性能严重下降的问题。通过构建记忆模型（在原模型基础上训练以记住不希望的数据），再利用外推从该记忆模型反向推导出遗忘模型，避免了直接使用梯度上升带来的不稳定问题。该方法稳定、高效，且在整个训练过程中具有良好收敛性，显著提升机器遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 传统机器遗忘依赖梯度上升（GA）来撤销对不希望数据的学习，但易引发灾难性崩溃，导致整体模型性能严重下降。因此需要一种更稳定的替代方法来实现安全、有效的知识遗忘。

Method: 提出模型外推机制：首先以原始模型为参考，训练得到一个记忆模型（即强化对不希望数据的记忆）；然后通过外推从记忆模型向参考模型方向反向推导，获得遗忘模型。整个过程避免直接进行梯度上升，改用梯度下降优化记忆模型，从而提升稳定性。

Result: 所提方法在多个实验中表现出良好的稳定性与收敛性，有效避免了性能下降问题，在多种场景下均实现了更优的遗忘效果，同时保持对保留数据的良好预测一致性。

Conclusion: 模型外推是一种简单、高效且稳定的机器遗忘新范式，能够有效克服传统方法中的灾难性崩溃问题，为伦理和安全的AI提供了可靠的技术支持。

Abstract: For ethical and safe AI, machine unlearning rises as a critical topic aiming to protect sensitive, private, and copyrighted knowledge from misuse. To achieve this goal, it is common to conduct gradient ascent (GA) to reverse the training on undesired data. However, such a reversal is prone to catastrophic collapse, which leads to serious performance degradation in general tasks. As a solution, we propose model extrapolation as an alternative to GA, which reaches the counterpart direction in the hypothesis space from one model given another reference model. Therefore, we leverage the original model as the reference, further train it to memorize undesired data while keeping prediction consistency on the rest retained data, to obtain a memorization model. Counterfactual as it might sound, a forget model can be obtained via extrapolation from the memorization model to the reference model. Hence, we avoid directly acquiring the forget model using GA, but proceed with gradient descent for the memorization model, which successfully stabilizes the machine unlearning process. Our model extrapolation is simple and efficient to implement, and it can also effectively converge throughout training to achieve improved unlearning performance.

</details>


### [141] [BrokenBind: Universal Modality Exploration beyond Dataset Boundaries](https://arxiv.org/abs/2602.06451)
*Zhuo Huang,Runnan Chen,Bo Han,Gang Niu,Masashi Sugiyama,Tongliang Liu*

Main category: cs.LG

TL;DR: 本文提出BrokenBind，一种可在不同数据集间绑定不同模态的多模态学习方法，通过利用多个包含目标模态和一个共享模态的数据集，克服分布不匹配问题，生成伪嵌入以填补缺失模态，实现灵活、泛化的多模态学习。该方法突破了传统方法对特定数据集的依赖，支持任意两模态的绑定，适用于多数据集场景和低数据量环境，并在大量实验中展现出优于现有基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于训练数据中的模态组合，难以泛化到未出现的模态，且获取多模态数据成本高，因此需要一种能跨数据集绑定模态、具备强泛化能力的方法。

Method: BrokenBind通过同时利用多个包含目标模态和共享模态的数据集，借助分布不匹配下的关系建模，生成伪嵌入来补全缺失模态，从而实现跨数据集的模态绑定。

Result: 在多种场景下（包括多数据集和低数据量）均表现出优越性能，显著优于现有主流多模态学习方法。

Conclusion: BrokenBind实现了无需受限于单一数据集的通用模态探索，有效解决了多模态学习中模态泛化与数据获取成本高的问题，具有良好的扩展性和实用性。

Abstract: Multi-modal learning combines various modalities to provide a comprehensive understanding of real-world problems. A common strategy is to directly bind different modalities together in a specific joint embedding space. However, the capability of existing methods is restricted within the modalities presented in the given dataset, thus they are biased when generalizing to unpresented modalities in downstream tasks. As a result, due to such inflexibility, the viability of previous methods is seriously hindered by the cost of acquiring multi-modal datasets. In this paper, we introduce BrokenBind, which focuses on binding modalities that are presented from different datasets. To achieve this, BrokenBind simultaneously leverages multiple datasets containing the modalities of interest and one shared modality. Though the two datasets do not correspond to each other due to distribution mismatch, we can capture their relationship to generate pseudo embeddings to fill in the missing modalities of interest, enabling flexible and generalized multi-modal learning. Under our framework, any two modalities can be bound together, free from the dataset limitation, to achieve universal modality exploration. Further, to reveal the capability of our method, we study intensified scenarios where more than two datasets are needed for modality binding and show the effectiveness of BrokenBind in low-data regimes. Through extensive evaluation, we carefully justify the superiority of BrokenBind compared to well-known multi-modal baseline methods.

</details>


### [142] [On the Plasticity and Stability for Post-Training Large Language Models](https://arxiv.org/abs/2602.06453)
*Wenwen Qiang,Ziyin Gu,Jiahuan Zhou,Jie Hu,Jingyao Wang,Changwen Zheng,Hui Xiong*

Main category: cs.LG

TL;DR: 提出PCR（Probabilistic Conflict Resolution），一种基于贝叶斯框架的随机冲突解决方法，通过不确定性感知的‘软投影’机制优化信号噪声比，显著改善训练稳定性与推理性能。


<details>
  <summary>Details</summary>
Motivation: GRPO训练中存在可塑性与泛化能力保留之间的权衡，根源在于可塑性与稳定性梯度间的几何冲突，导致破坏性干扰；现有确定性投影方法忽略组级梯度估计的内在随机性，因此表现不佳。

Method: 提出PCR框架，将梯度建模为随机变量，采用不确定性感知的软投影机制动态调和梯度冲突，以提升信号-噪声比。

Result: 实验表明，PCR能显著平滑训练轨迹，在多种推理任务中实现更优性能。

Conclusion: PCR通过概率化处理梯度冲突，有效缓解了GRPO中的训练不稳定性问题，为强化学习中的稳定训练提供了新范式。

Abstract: Training stability remains a critical bottleneck for Group Relative Policy Optimization (GRPO), often manifesting as a trade-off between reasoning plasticity and general capability retention. We identify a root cause as the geometric conflict between plasticity and stability gradients, which leads to destructive interference. Crucially, we argue that deterministic projection methods are suboptimal for GRPO as they overlook the intrinsic stochasticity of group-based gradient estimates. To address this, we propose Probabilistic Conflict Resolution (PCR), a Bayesian framework that models gradients as random variables. PCR dynamically arbitrates conflicts via an uncertainty-aware ``soft projection'' mechanism, optimizing the signal-to-noise ratio. Extensive experiments demonstrate that PCR significantly smooths the training trajectory and achieves superior performance in various reasoning tasks.

</details>


### [143] [The Window Dilemma: Why Concept Drift Detection is Ill-Posed](https://arxiv.org/abs/2602.06456)
*Brandon Gower-Winter,Misja Groen,Georg Krempl*

Main category: cs.LG

TL;DR: 本文揭示了数据流中概念漂移检测的固有缺陷，提出"窗口困境"（Window Dilemma）：漂移感知结果往往源于窗口选择而非真实的数据生成过程变化。同时指出漂移检测在实践中难以验证，因此本质上是病态问题。通过案例和实证比较发现，传统批处理学习方法在多数情况下表现优于依赖漂移检测的自适应方法，从而质疑漂移检测在流分类中的实际价值。


<details>
  <summary>Details</summary>
Motivation: 现有漂移检测方法依赖于对数据窗口的比较来识别概念漂移，但其有效性可能受窗口设置影响。本文旨在揭示这种依赖性带来的偏差，并挑战漂移检测在实际应用中的必要性与合理性。

Method: 通过构建一个直观示例说明窗口选择如何误导漂移判断；随后进行多组实验，对比漂移检测器与多种替代适应策略（如重训练、滑动窗口等）在不同场景下的性能表现。

Result: 实验表明，许多传统批量学习方法在面对概念漂移时表现优于依赖漂移检测的在线学习方法，且漂移检测本身难以在真实场景中被有效验证。

Conclusion: 漂移检测在数据流分类中可能并非必要手段，其效果常被窗口设定所扭曲，而简单有效的批处理策略反而更具鲁棒性和实用性。这促使我们重新思考漂移检测的作用与设计目标。

Abstract: Non-stationarity of an underlying data generating process that leads to distributional changes over time is a key characteristic of Data Streams. This phenomenon, commonly referred to as Concept Drift, has been intensively studied, and Concept Drift Detectors have been established as a class of methods for detecting such changes (drifts). For the most part, Drift Detectors compare regions (windows) of the data stream and detect drift if those windows are sufficiently dissimilar.
  In this work, we introduce the Window Dilemma, an observation that perceived drift is a product of windowing and not necessarily the underlying data generating process. Additionally, we highlight that drift detection is ill-posed, primarily because verification of drift events are implausible in practice. We demonstrate these contributions first by an illustrative example, followed by empirical comparisons of drift detectors against a variety of alternative adaptation strategies. Our main finding is that traditional batch learning techniques often perform better than their drift-aware counterparts further bringing into question the purpose of detectors in Stream Classification.

</details>


### [144] [Achieving Better Local Regret Bound for Online Non-Convex Bilevel Optimization](https://arxiv.org/abs/2602.06457)
*Tingkai Jia,Haiguang Wang,Cheng Chen*

Main category: cs.LG

TL;DR: 本文研究在线双层优化（OBO）问题的最优后悔界，提出了两种新算法：一种针对标准双层局部后悔，达到最优后悔界$Ω(1+V_T)$，且内层梯度评估次数为$O(T\log T)$；另一种为全单循环算法，包含额外的梯度变化项。针对窗口平均双层局部后悔，设计了基于窗口分析的算法，捕捉环境的次线性变化，实现最优后悔界$Ω(T/W^2)$。实验验证了理论结果并展示了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有在线双层优化算法的后悔界是否最优尚不明确，亟需建立最优后悔界并设计高效算法以提升性能。

Method: 提出两种新算法：一是基于多轮更新的标准双层局部后悔最小化算法，二是全单循环算法；对于窗口平均后悔，采用窗口基分析方法建模环境变化。

Result: 在标准双层局部后悔下，算法实现最优后悔界$Ω(1+V_T)$，内层梯度评估次数为$O(T\log T)$；全单循环算法引入梯度变化项；窗口平均后悔下实现最优$Ω(T/W^2)$。实验验证了理论结果和算法有效性。

Conclusion: 本文建立了在线双层优化中标准与窗口平均双层局部后悔的最优后悔界，并设计出高效、实用的算法，理论与实验均表明其优越性。

Abstract: Online bilevel optimization (OBO) has emerged as a powerful framework for many machine learning problems. Prior works have developed several algorithms that minimize the standard bilevel local regret or the window-averaged bilevel local regret of the OBO problem, but the optimality of existing regret bounds remains unclear. In this work, we establish optimal regret bounds for both settings. For standard bilevel local regret, we propose an algorithm that achieves the optimal regret $Ω(1+V_T)$ with at most $O(T\log T)$ total inner-level gradient evaluations. We further develop a fully single-loop algorithm whose regret bound includes an additional gradient-variation terms. For the window-averaged bilevel local regret, we design an algorithm that captures sublinear environmental variation through a window-based analysis and achieves the optimal regret $Ω(T/W^2)$. Experiments validate our theoretical findings and demonstrate the practical effectiveness of the proposed methods.

</details>


### [145] [Towards Generalizable Reasoning: Group Causal Counterfactual Policy Optimization for LLM Reasoning](https://arxiv.org/abs/2602.06475)
*Jingyao Wang,Peizheng Guo,Wenwen Qiang,Jiahuan Zhou,Huijie Guo,Changwen Zheng,Hui Xiong*

Main category: cs.LG

TL;DR: 本文提出一种名为组因果反事实策略优化（Group Causal Counterfactual Policy Optimization）的新方法，旨在改进大语言模型在复杂任务中的推理能力。传统奖励机制仅关注最终答案正确性，忽视推理过程的质量，导致逻辑错误但答案正确的样本被过度奖励。本文从因果视角将多候选推理视为一系列具有理论支持的反事实实验，设计了一种基于因果反事实的奖励机制，同时考虑鲁棒性（推理步骤在反事实扰动下保持稳定）和有效性（推理策略具备跨问题迁移能力）。通过构建分词级优势函数并优化策略，使模型更倾向于选择过程有效且反事实鲁棒的推理模式。在多个基准测试中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有奖励机制过于关注最终答案的正确性，忽略了推理过程的质量，导致模型可能学习到不具泛化能力的、依赖偶然猜测的推理模式，从而影响其在新任务上的表现。

Method: 将多候选推理视为反事实实验，提出组因果反事实策略优化方法，设计一种结合鲁棒性与有效性的因果反事实奖励，并基于此构建分词级优势，用于优化模型策略。

Result: 在多个多样化基准测试中，该方法显著提升了模型的推理泛化能力，证明其能够引导模型学习更具鲁棒性和可迁移性的推理模式。

Conclusion: 通过引入因果反事实视角和相应的奖励机制，所提方法有效提升了大语言模型在复杂任务中的推理质量与泛化能力，为构建更可靠、可解释的智能推理系统提供了新路径。

Abstract: Large language models (LLMs) excel at complex tasks with advances in reasoning capabilities. However, existing reward mechanisms remain tightly coupled to final correctness and pay little attention to the underlying reasoning process: trajectories with sound reasoning but wrong answers receive low credit, while lucky guesses with flawed logic may be highly rewarded, affecting reasoning generalization. From a causal perspective, we interpret multi-candidate reasoning for a fixed question as a family of counterfactual experiments with theoretical supports. Building on this, we propose Group Causal Counterfactual Policy Optimization to explicitly train LLMs to learn generalizable reasoning patterns. It proposes an episodic causal counterfactual reward that jointly captures (i) robustness, encouraging the answer distribution induced by a reasoning step to remain stable under counterfactual perturbations; and (ii) effectiveness, enforcing sufficient variability so that the learned reasoning strategy can transfer across questions. We then construct token-level advantages from this reward and optimize the policy, encouraging LLMs to favor reasoning patterns that are process-valid and counterfactually robust. Extensive experiments on diverse benchmarks demonstrate its advantages.

</details>


### [146] [Adaptive Uncertainty-Aware Tree Search for Robust Reasoning](https://arxiv.org/abs/2602.06493)
*Zeen Song,Zihao Ma,Wenwen Qiang,Changwen Zheng,Gang Hua*

Main category: cs.LG

TL;DR: 本文研究了大语言模型在推理时通过外部搜索结合过程奖励模型（PRM）进行复杂问题求解的局限性，发现PRM在处理分布外（OOD）样本时存在高不确定性与评分不可靠的问题。理论分析表明，标准搜索策略会导致线性后悔累积，而不确定性感知策略可实现次线性后悔。为此，作者提出不确定性感知树搜索（UATS），利用蒙特卡洛丢弃估计不确定性，并通过强化学习控制器动态分配计算资源。实验验证了该方法能有效缓解OOD错误的影响。


<details>
  <summary>Details</summary>
Motivation: 现有基于过程奖励模型（PRM）的推理时搜索方法在面对分布外（OOD）推理路径时，由于PRM的评估存在高不确定性，导致性能下降。因此需要一种能够识别并应对这种不确定性的机制，以提升LLMs在复杂任务中的可靠性。

Method: 提出不确定性感知树搜索（UATS），通过蒙特卡洛丢弃估计推理路径的不确定性，并采用强化学习驱动的控制器动态分配计算预算，使模型更关注可信路径，减少对不可靠评分的依赖。

Result: 实验结果表明，UATS显著降低了因分布外路径导致的错误影响，在多个复杂任务上优于传统方法，尤其在长推理链和高不确定性场景下表现更优。

Conclusion: 本研究揭示了当前基于PRM的推理搜索框架在分布外情况下的根本缺陷，并证明了不确定性感知策略在理论上具有更优的后悔控制能力。所提出的UATS方法通过有效建模与管理不确定性，显著提升了大语言模型在复杂问题解决中的鲁棒性与准确性。

Abstract: Inference-time reasoning scaling has significantly advanced the capabilities of Large Language Models (LLMs) in complex problem-solving. A prevalent approach involves external search guided by Process Reward Models (PRMs). However, a fundamental limitation of this framework is the epistemic uncertainty of PRMs when evaluating reasoning paths that deviate from their training distribution. In this work, we conduct a systematic analysis of this challenge. We first provide empirical evidence that PRMs exhibit high uncertainty and unreliable scoring on out-of-distribution (OOD) samples. We then establish a theoretical framework proving that while standard search incurs linear regret accumulation, an uncertainty-aware strategy can achieve sublinear regret. Motivated by these findings, we propose Uncertainty-Aware Tree Search (UATS), a unified method that estimates uncertainty via Monte Carlo Dropout and dynamically allocates compute budget using a reinforcement learning-based controller. Extensive experiments demonstrate that our approach effectively mitigates the impact of OOD errors.

</details>


### [147] [Evolutionary Generation of Multi-Agent Systems](https://arxiv.org/abs/2602.06511)
*Yuntong Hu,Matthew Trager,Yuting Zhang,Yi Zhang,Shuo Yang,Wei Xia,Stefano Soatto*

Main category: cs.LG

TL;DR: EvoMAS 提出一种基于进化生成的多智能体系统（MAS）方法，将 MAS 构建转化为结构化配置生成问题。通过在配置空间中进行进化搜索，结合执行轨迹反馈进行突变与交叉操作，逐步优化候选配置池和经验记忆库。在 BBEH、SWE-Bench 和 WorkBench 等多个基准测试中，EvoMAS 显著优于人工设计及现有自动生成方法，在任务性能、可执行性和运行鲁棒性方面均有提升，尤其在 BBEH 和 WorkBench 上分别超越 EvoAgent 10.5 和 7.1 分，并在 SWE-Bench-Verified 上达到 79.1% 的准确率，位居榜首。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统（MAS）的设计依赖人工，存在劳动密集、脆弱且难以泛化的问题；现有自动生成方法或依赖代码生成导致可执行性差，或受限于固定架构模板而缺乏灵活性。因此亟需一种既能保持高表达能力又具备强鲁棒性的自动化生成框架。

Method: EvoMAS 将 MAS 生成建模为配置空间中的进化过程。从初始配置池出发，利用执行轨迹反馈指导突变与交叉操作，动态更新候选配置池与经验记忆库，实现对系统架构的迭代优化。

Result: EvoMAS 在多个任务上显著提升性能：在 BBEH 上比 EvoAgent 提升 10.5 分，在 WorkBench 上提升 7.1 分；使用 Claude-4.5-Sonnet 时在 SWE-Bench-Verified 达到 79.1%，与当前最优水平持平。同时生成系统具备更高的可执行性与运行稳定性。

Conclusion: EvoMAS 实现了高效、鲁棒且可扩展的多智能体系统自动构建，为复杂任务中的自主协作提供了一种新范式，具有良好的通用性与实用性。

Abstract: Large language model (LLM)-based multi-agent systems (MAS) show strong promise for complex reasoning, planning, and tool-augmented tasks, but designing effective MAS architectures remains labor-intensive, brittle, and hard to generalize. Existing automatic MAS generation methods either rely on code generation, which often leads to executability and robustness failures, or impose rigid architectural templates that limit expressiveness and adaptability. We propose Evolutionary Generation of Multi-Agent Systems (EvoMAS), which formulates MAS generation as structured configuration generation. EvoMAS performs evolutionary generation in configuration space. Specifically, EvoMAS selects initial configurations from a pool, applies feedback-conditioned mutation and crossover guided by execution traces, and iteratively refines both the candidate pool and an experience memory. We evaluate EvoMAS on diverse benchmarks, including BBEH, SWE-Bench, and WorkBench, covering reasoning, software engineering, and tool-use tasks. EvoMAS consistently improves task performance over both human-designed MAS and prior automatic MAS generation methods, while producing generated systems with higher executability and runtime robustness. EvoMAS outperforms the agent evolution method EvoAgent by +10.5 points on BBEH reasoning and +7.1 points on WorkBench. With Claude-4.5-Sonnet, EvoMAS also reaches 79.1% on SWE-Bench-Verified, matching the top of the leaderboard.

</details>


### [148] [Live Knowledge Tracing: Real-Time Adaptation using Tabular Foundation Models](https://arxiv.org/abs/2602.06542)
*Mounir Lbath,Alexandre Paresy,Abdelkayoum Kaddouri,Alan André,Alexandre Ittah,Jill-Jênn Vie*

Main category: cs.LG

TL;DR: 本文提出了一种基于表格基础模型（TFMs）的新范式，用于知识追踪。与传统方法需离线训练不同，该方法实现在线实时追踪，通过双向注意力机制同时关注时间步和学生间的交互，推理时动态对齐测试序列与训练序列，跳过训练步骤。在多个数据集上，该方法在预测性能上表现良好，并实现了高达273倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 传统深度知识追踪模型训练耗时长且在短序列数据集上容易过拟合，亟需更高效、可扩展的解决方案。

Method: 提出基于表格基础模型（TFMs）的在线知识追踪方法，利用双向注意力机制，在推理时动态对齐测试序列与训练序列，无需预先训练。

Result: 在多个数据集上实现了与现有方法相当的预测性能，同时获得最高达273倍的加速效果，尤其在观测到更多学生交互时表现更优。

Conclusion: 该方法为知识追踪提供了一种高效、可扩展的替代方案，突破了传统训练-推理范式的局限，适用于大规模在线学习场景。

Abstract: Deep knowledge tracing models have achieved significant breakthroughs in modeling student learning trajectories. However, these architectures require substantial training time and are prone to overfitting on datasets with short sequences. In this paper, we explore a new paradigm for knowledge tracing by leveraging tabular foundation models (TFMs). Unlike traditional methods that require offline training on a fixed training set, our approach performs real-time ''live'' knowledge tracing in an online way. The core of our method lies in a two-way attention mechanism: while attention knowledge tracing models only attend across earlier time steps, TFMs simultaneously attend across both time steps and interactions of other students in the training set. They align testing sequences with relevant training sequences at inference time, therefore skipping the training step entirely. We demonstrate, using several datasets of increasing size, that our method achieves competitive predictive performance with up to 273x speedups, in a setting where more student interactions are observed over time.

</details>


### [149] [Refining the Information Bottleneck via Adversarial Information Separation](https://arxiv.org/abs/2602.06549)
*Shuai Ning,Zhenpeng Wang,Lin Wang,Bing Chen,Shuangrong Liu,Xu Wu,Jin Zhou,Bo Yang*

Main category: cs.LG

TL;DR: 提出AdverISF框架，通过自监督对抗机制在无显式标签情况下分离任务相关特征与噪声，利用多层分离架构递归回收噪声信息以实现更细粒度特征提取，在数据稀缺和真实材料设计任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在材料科学等领域的模型需要从有限数据中泛化，但实验数据常受测量噪声和实验伪影干扰，标准正则化和现有对抗适应方法因依赖显式分离标签而受限。

Method: AdverISF采用自监督对抗机制强制任务相关特征与噪声表示的统计独立性，并通过多层分离架构在特征层次间递归回收噪声信息，以恢复被误判为噪声的特征。

Result: 在数据稀缺场景下，AdverISF显著优于当前最先进方法；在真实材料设计任务中也展现出更强的泛化能力。

Conclusion: AdverISF成功实现了无需显式标签的任务相关特征与噪声分离，提升了小样本条件下的模型泛化性能，尤其适用于高噪声、数据稀缺的材料科学领域。

Abstract: Generalizing from limited data is particularly critical for models in domains such as material science, where task-relevant features in experimental datasets are often heavily confounded by measurement noise and experimental artifacts. Standard regularization techniques fail to precisely separate meaningful features from noise, while existing adversarial adaptation methods are limited by their reliance on explicit separation labels. To address this challenge, we propose the Adversarial Information Separation Framework (AdverISF), which isolates task-relevant features from noise without requiring explicit supervision. AdverISF introduces a self-supervised adversarial mechanism to enforce statistical independence between task-relevant features and noise representations. It further employs a multi-layer separation architecture that progressively recycles noise information across feature hierarchies to recover features inadvertently discarded as noise, thereby enabling finer-grained feature extraction. Extensive experiments demonstrate that AdverISF outperforms state-of-the-art methods in data-scarce scenarios. In addition, evaluations on real-world material design tasks show that it achieves superior generalization performance.

</details>


### [150] [Endogenous Resistance to Activation Steering in Language Models](https://arxiv.org/abs/2602.06941)
*Alex McKenzie,Keenan Pepper,Stijn Servaes,Martin Leitgab,Murat Cubuktepe,Mike Vaiana,Diogo de Lucena,Judd Rosenblatt,Michael S. A. Graziano*

Main category: cs.LG

TL;DR: 大型语言模型在推理过程中能抵抗任务不匹配的激活引导，有时即使引导持续存在也能在生成中途恢复并产生更优响应，这种现象称为内源性引导抗性（ESR）。研究发现，Llama-3.3-70B表现出显著的ESR，而较小的Llama-3和Gemma-2模型则较少出现。通过稀疏自编码器（SAE）潜变量分析，识别出26个在离题内容中差异激活且与ESR因果相关的潜变量；零消这些潜变量可使多尝试率降低25%，表明存在专门的内部一致性检查机制。研究还证明可通过提示和训练主动增强ESR：元提示指令模型自我监控可使Llama-3.3-70B的多尝试率提升4倍，对小模型进行自纠正样本微调也可诱导出类似ESR行为。这些发现具有双重意义：ESR可能抵御对抗性操纵，但也可能干扰依赖激活引导的安全干预措施。理解与控制此类抗性机制对构建透明、可控的人工智能系统至关重要。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在受到任务不匹配的激活引导时是否具备自我修正能力，揭示其内部是否存在自主一致性检查机制，并探索如何调控该机制以增强模型安全性或实现可控干预。

Method: 采用稀疏自编码器（SAE）潜变量对模型激活进行分析，识别与离题内容相关且与内源性引导抗性（ESR）相关的特定潜变量；通过零消实验验证其因果作用；设计元提示和微调策略以主动增强或诱导ESR行为。

Result: Llama-3.3-70B表现出显著的内源性引导抗性，26个特定SAE潜变量与其密切相关；零消这些潜变量使多尝试率下降25%；元提示使多尝试率提升4倍；微调可使小模型获得类似ESR行为。

Conclusion: 大型语言模型具备内源性引导抗性，可能源于专门的内部一致性检查机制。该机制既可提供安全保护，也可能阻碍有益的安全干预。因此，理解和可控地管理此类机制对于发展透明、可信赖的AI系统至关重要。

Abstract: Large language models can resist task-misaligned activation steering during inference, sometimes recovering mid-generation to produce improved responses even when steering remains active. We term this Endogenous Steering Resistance (ESR). Using sparse autoencoder (SAE) latents to steer model activations, we find that Llama-3.3-70B shows substantial ESR, while smaller models from the Llama-3 and Gemma-2 families exhibit the phenomenon less frequently. We identify 26 SAE latents that activate differentially during off-topic content and are causally linked to ESR in Llama-3.3-70B. Zero-ablating these latents reduces the multi-attempt rate by 25%, providing causal evidence for dedicated internal consistency-checking circuits. We demonstrate that ESR can be deliberately enhanced through both prompting and training: meta-prompts instructing the model to self-monitor increase the multi-attempt rate by 4x for Llama-3.3-70B, and fine-tuning on self-correction examples successfully induces ESR-like behavior in smaller models. These findings have dual implications: ESR could protect against adversarial manipulation but might also interfere with beneficial safety interventions that rely on activation steering. Understanding and controlling these resistance mechanisms is important for developing transparent and controllable AI systems. Code is available at github.com/agencyenterprise/endogenous-steering-resistance.

</details>


### [151] [Learning to Allocate Resources with Censored Feedback](https://arxiv.org/abs/2602.06565)
*Giovanni Montanari,Côme Fiegel,Corentin Pla,Aadirupa Saha,Vianney Perchet*

Main category: cs.LG

TL;DR: 本文研究在线资源分配问题，其中每轮需在K个臂之间分配预算B，面临截断反馈。奖励仅在两个条件同时满足时产生：(i) 臂被激活（伯努利随机变量，参数未知）；(ii) 分配预算超过一个服从参数分布的随机阈值（参数未知）。在T轮中，学习者需联合估计未知参数并分配预算以最大化累积奖励，面临探索-利用权衡。本文证明了信息论下界Ω(T^{1/3})，揭示该问题的内在难度。提出RA-UCB算法，结合非平凡参数估计与置信区间，在已知预算时实现$\widetilde{\mathcal{O}}(\sqrt{T})$的遗憾，更强假设下可达$\mathcal{O}(\mathrm{poly}\text{-}\log T)$。针对未知且轮内变化的预算，引入MG-UCB，支持轮内切换和无穷小分配，匹配RA-UCB的遗憾性能。实验验证了理论结果的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究在线资源分配中因截断反馈带来的挑战，尤其在激励机制与预算约束双重不确定性下如何有效平衡探索与利用，旨在揭示此类问题的理论极限并设计高效算法。

Method: 提出RA-UCB和MG-UCB两种算法，分别处理已知预算和轮内变化预算场景。采用乐观原则，结合参数估计与置信区间构造，通过非平凡的统计推断方法处理未知的激活概率与阈值分布参数。

Result: 证明了信息论下界Ω(T^{1/3})，表明该问题固有难度。RA-UCB在已知预算下达到$\widetilde{\mathcal{O}}(\sqrt{T})$遗憾，强假设下可降至$\mathcal{O}(\mathrm{poly}\text{-}\log T)$。MG-UCB在未知预算时实现相同性能，并支持轮内灵活调整。实验在真实数据集上验证了算法有效性。

Conclusion: 本文系统分析了带截断反馈的在线资源分配问题，揭示其理论下限，并提出两类高效算法，实现了近最优遗憾性能，为实际应用中的动态资源配置提供了理论支撑与实践工具。

Abstract: We study the online resource allocation problem in which at each round, a budget $B$ must be allocated across $K$ arms under censored feedback. An arm yields a reward if and only if two conditions are satisfied: (i) the arm is activated according to an arm-specific Bernoulli random variable with unknown parameter, and (ii) the allocated budget exceeds a random threshold drawn from a parametric distribution with unknown parameter. Over $T$ rounds, the learner must jointly estimate the unknown parameters and allocate the budget so as to maximize cumulative reward facing the exploration--exploitation trade-off. We prove an information-theoretic regret lower bound $Ω(T^{1/3})$, demonstrating the intrinsic difficulty of the problem. We then propose RA-UCB, an optimistic algorithm that leverages non-trivial parameter estimation and confidence bounds. When the budget $B$ is known at the beginning of each round, RA-UCB achieves a regret of order $\widetilde{\mathcal{O}}(\sqrt{T})$, and even $\mathcal{O}(\mathrm{poly}\text{-}\log T)$ under stronger assumptions. As for unknown, round dependent budget, we introduce MG-UCB, which allows within-round switching and infinitesimal allocations, and matches the regret guarantees of RA-UCB. We then validate our theoretical results through experiments on real-world datasets.

</details>


### [152] [Degradation of Feature Space in Continual Learning](https://arxiv.org/abs/2602.06586)
*Chiara Lanza,Roberto Pereira,Marco Miozzo,Eduard Angelats,Paolo Dini*

Main category: cs.LG

TL;DR: 本文研究在持续学习中促进特征空间各向同性是否能提升表示质量。实验表明，各向同性正则化不仅未能提升模型准确率，反而可能降低性能，揭示了集中式学习与持续学习在特征几何上的本质差异，表明各向同性并非非平稳学习场景中的合适归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 探究在持续学习中是否应通过强制特征空间各向同性来平衡可塑性与稳定性，从而缓解灾难性遗忘问题。

Method: 采用对比持续学习技术，在CIFAR-10和CIFAR-100数据集上进行实验，评估各向同性正则化对模型性能的影响。

Result: 各向同性正则化未能提升模型准确率，甚至导致性能下降，表明其在持续学习场景中效果不佳。

Conclusion: 各向同性虽在集中式学习中有益，但在非平稳的持续学习中可能不适用，需重新考虑其作为归纳偏置的有效性。

Abstract: Centralized training is the standard paradigm in deep learning, enabling models to learn from a unified dataset in a single location. In such setup, isotropic feature distributions naturally arise as a mean to support well-structured and generalizable representations. In contrast, continual learning operates on streaming and non-stationary data, and trains models incrementally, inherently facing the well-known plasticity-stability dilemma. In such settings, learning dynamics tends to yield increasingly anisotropic feature space. This arises a fundamental question: should isotropy be enforced to achieve a better balance between stability and plasticity, and thereby mitigate catastrophic forgetting? In this paper, we investigate whether promoting feature-space isotropy can enhance representation quality in continual learning. Through experiments using contrastive continual learning techniques on CIFAR-10 and CIFAR-100 data, we find that isotropic regularization fails to improve, and can in fact degrade, model accuracy in continual settings. Our results highlight essential differences in feature geometry between centralized and continual learning, suggesting that isotropy, while beneficial in centralized setups, may not constitute an appropriate inductive bias for non-stationary learning scenarios.

</details>


### [153] [DiTS: Multimodal Diffusion Transformers Are Time Series Forecasters](https://arxiv.org/abs/2602.06597)
*Haoran Zhang,Haixuan Liu,Yong Liu,Yunzhong Qiu,Yuxuan Wang,Jianmin Wang,Mingsheng Long*

Main category: cs.LG

TL;DR: 本文提出了一种名为DiTS（Diffusion Transformers for Time Series）的新架构，旨在解决现有生成式时间序列模型在处理多维数据时的不足。该模型借鉴了多模态扩散模型的思想，将内生和外生变量视为不同模态，并设计了双流Transformer结构，包含时间注意力模块（用于建模时间维度的自回归依赖）和变元注意力模块（用于建模跨变量依赖）。通过利用多变量依赖的低秩特性，该方法降低了计算开销。实验表明，DiTS在多个基准测试中均达到最先进性能，无论是否有未来外生变量观测，都展现出优于传统确定性深度预测模型的生成式预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有生成式时间序列模型未能充分捕捉多维时间序列中的跨变量依赖关系，尤其是基于DiT的模型因采用简单的条件控制和单流Transformer结构，导致对多变量信息利用不充分。为提升多变量时间序列建模能力，需引入更有效的结构来同时捕获时间内部与变量之间的复杂依赖。

Method: 提出DiTS架构，将内生与外生变量视为不同模态；设计双流Transformer块，包括时间注意力模块（针对时间维度的自回归建模）和变元注意力模块（针对跨变量建模）；利用多变量依赖的低秩特性降低计算复杂度，避免将时间序列像图像那样展平为一维序列。

Result: DiTS在多个时间序列预测基准上均取得当前最优性能，且在存在或不存在未来外生变量观测的情况下均表现优异，验证了其在生成式预测任务中的强大能力。

Conclusion: DiTS是一种通用性强、高效且先进的生成式时间序列建模框架，通过双流注意力机制有效捕捉多变量时间序列中的跨变量与时间依赖，显著提升了生成式预测的性能与灵活性。

Abstract: While generative modeling on time series facilitates more capable and flexible probabilistic forecasting, existing generative time series models do not address the multi-dimensional properties of time series data well. The prevalent architecture of Diffusion Transformers (DiT), which relies on simplistic conditioning controls and a single-stream Transformer backbone, tends to underutilize cross-variate dependencies in covariate-aware forecasting. Inspired by Multimodal Diffusion Transformers that integrate textual guidance into video generation, we propose Diffusion Transformers for Time Series (DiTS), a general-purpose architecture that frames endogenous and exogenous variates as distinct modalities. To better capture both inter-variate and intra-variate dependencies, we design a dual-stream Transformer block tailored for time-series data, comprising a Time Attention module for autoregressive modeling along the temporal dimension and a Variate Attention module for cross-variate modeling. Unlike the common approach for images, which flattens 2D token grids into 1D sequences, our design leverages the low-rank property inherent in multivariate dependencies, thereby reducing computational costs. Experiments show that DiTS achieves state-of-the-art performance across benchmarks, regardless of the presence of future exogenous variate observations, demonstrating unique generative forecasting strengths over traditional deterministic deep forecasting models.

</details>


### [154] [The hidden risks of temporal resampling in clinical reinforcement learning](https://arxiv.org/abs/2602.06603)
*Thomas Frost,Hrisheekesh Vaidya,Steve Harris*

Main category: cs.LG

TL;DR: 本研究揭示了在医疗保健领域的离线强化学习（ORL）中，时间重采样会显著降低算法在实际部署中的性能。通过网格世界导航任务和UVA/Padova糖尿病模拟器，研究发现时间重采样导致反事实轨迹生成、时间预期扭曲以及泛化误差累积，进而引发模型失效。此外，标准的离策略评估指标无法有效检测性能下降。研究强调当前医疗ORL流程中忽视临床决策时间不规则性的根本风险，并呼吁开发能显式处理不规则时间数据的方法。


<details>
  <summary>Details</summary>
Motivation: 当前医疗领域离线强化学习研究通常将患者数据聚合到固定时间间隔，但这种时间上的简化操作对模型安全性和有效性的影响尚不清楚。尤其在临床决策中，时间点不规则性普遍存在，现有方法可能因此产生严重偏差，亟需深入探究其影响机制。

Method: 研究采用网格世界导航任务与真实临床糖尿病模拟器（UVA/Padovo），系统地分析不同时间重采样策略对离线强化学习算法性能的影响。通过对比多种时间粒度下的训练与部署表现，识别出导致性能下降的核心机制，并检验传统评估指标的可靠性。

Result: 实验表明，时间重采样显著降低了离线强化学习算法在实际部署中的性能。具体表现为：生成反事实轨迹、扭曲时间预期、加剧泛化误差。同时，标准的离策略评估方法未能有效识别这些性能损失，暴露出现有评估体系的局限性。

Conclusion: 当前医疗离线强化学习流程因忽略临床数据的时间不规则性而存在根本性风险。研究强调必须发展能够显式建模不规则时间结构的新方法，以确保算法在真实医疗场景中的安全性与有效性。

Abstract: Offline reinforcement learning (ORL) has shown potential for improving decision-making in healthcare. However, contemporary research typically aggregates patient data into fixed time intervals, simplifying their mapping to standard ORL frameworks. The impact of these temporal manipulations on model safety and efficacy remains poorly understood. In this work, using both a gridworld navigation task and the UVA/Padova clinical diabetes simulator, we demonstrate that temporal resampling significantly degrades the performance of offline reinforcement learning algorithms during live deployment. We propose three mechanisms that drive this failure: (i) the generation of counterfactual trajectories, (ii) the distortion of temporal expectations, and (iii) the compounding of generalisation errors. Crucially, we find that standard off-policy evaluation metrics can fail to detect these drops in performance. Our findings reveal a fundamental risk in current healthcare ORL pipelines and emphasise the need for methods that explicitly handle the irregular timing of clinical decision-making.

</details>


### [155] [Adaptive-CaRe: Adaptive Causal Regularization for Robust Outcome Prediction](https://arxiv.org/abs/2602.06611)
*Nithya Bhasker,Fiona R. Kolbinger,Susu Hu,Gitta Kutyniok,Stefanie Speidel*

Main category: cs.LG

TL;DR: 提出了一种名为Adaptive-CaRe的模型无关正则化策略，用于在医疗领域中实现准确且因果稳健的结果预测。该方法通过惩罚输入特征的统计贡献与因果贡献之间的差异，在预测准确性与因果鲁棒性之间取得平衡。实验表明，Adaptive-CaRe在合成数据和真实世界数据上均能有效识别稳健的预测因子，同时保持良好的预测性能，为临床决策提供了可靠支持。


<details>
  <summary>Details</summary>
Motivation: 现有的监督学习模型虽能提高预测准确性，但容易捕捉虚假相关性；而因果结构学习方法虽然具有鲁棒性，但因算法和数据假设过于保守，导致诊断精度下降。因此需要一种既能保持高预测性能又具备因果稳健性的新方法。

Method: 提出一种模型无关的正则化策略Adaptive-CaRe，其核心是引入一个与输入特征的统计贡献和因果贡献差异成比例的惩罚项，从而在模型训练过程中动态调节预测行为以兼顾准确性与因果性。通过调整正则化强度λ，可灵活控制预测精度与因果稳健性的权衡。

Result: 在合成数据和标准因果基准测试中，Adaptive-CaRe均表现出优异的性能，能够有效识别出对目标变量有稳健影响的特征，同时维持较高的预测准确性。真实世界数据验证进一步证明了该方法在实际医疗场景中的可行性与有效性。

Conclusion: Adaptive-CaRe提供了一个简单而有效的解决方案，成功缓解了医疗领域中预测准确性与因果稳健性之间的长期矛盾，具有广泛的应用前景，未来可拓展至更复杂的模型与框架。

Abstract: Accurate prediction of outcomes is crucial for clinical decision-making and personalized patient care. Supervised machine learning algorithms, which are commonly used for outcome prediction in the medical domain, optimize for predictive accuracy, which can result in models latching onto spurious correlations instead of robust predictors. Causal structure learning methods on the other hand have the potential to provide robust predictors for the target, but can be too conservative because of algorithmic and data assumptions, resulting in loss of diagnostic precision. Therefore, we propose a novel model-agnostic regularization strategy, Adaptive-CaRe, for generalized outcome prediction in the medical domain. Adaptive-CaRe strikes a balance between both predictive value and causal robustness by incorporating a penalty that is proportional to the difference between the estimated statistical contribution and estimated causal contribution of the input features for model predictions. Our experiments on synthetic data establish the efficacy of the proposed Adaptive-CaRe regularizer in finding robust predictors for the target while maintaining competitive predictive accuracy. With experiments on a standard causal benchmark, we provide a blueprint for navigating the trade-off between predictive accuracy and causal robustness by tweaking the regularization strength, $λ$. Validation using real-world dataset confirms that the results translate to practical, real-domain settings. Therefore, Adaptive-CaRe provides a simple yet effective solution to the long-standing trade-off between predictive accuracy and causal robustness in the medical domain. Future work would involve studying alternate causal structure learning frameworks and complex classification models to provide deeper insights at a larger scale.

</details>


### [156] [Memory-Conditioned Flow-Matching for Stable Autoregressive PDE Rollouts](https://arxiv.org/abs/2602.06689)
*Victor Armegioiu*

Main category: cs.LG

TL;DR: 提出了一种带记忆条件的扩散/流匹配方法，通过引入紧凑的在线状态来改善生成式偏微分方程求解器在粗到细尺度下的长期滚动稳定性，显著提升精度与细尺度保真度。


<details>
  <summary>Details</summary>
Motivation: 现有自回归生成式PDE求解器在长时滚动中易出现漂移，尤其在需逐步重构未解析细尺度的粗到细场景下，其性能受限于每一步条件分布误差。

Method: 基于Mori--Zwanzig投影形式，揭示了消除未解析变量后的确切解析演化结构（含马尔可夫项、记忆项和正交强迫项），并提出记忆条件扩散/流匹配方法，通过潜空间特征注入在线状态以构造结构化的条件尾部先验，减少对缺失频率的传输需求。

Result: 理论证明了所提方法的Wasserstein稳定性，并建立了分离记忆近似误差与条件生成误差的离散Grönwall滚动边界；实验表明在含激波与多尺度混合的可压缩流体问题上，具有更高的准确性和更稳定的长期滚动表现，且在频谱和统计特性上更优。

Conclusion: 该方法通过引入结构化记忆机制克服了无记忆闭合的结构性局限，为高保真、稳定长时序生成式PDE求解提供了新范式。

Abstract: Autoregressive generative PDE solvers can be accurate one step ahead yet drift over long rollouts, especially in coarse-to-fine regimes where each step must regenerate unresolved fine scales. This is the regime of diffusion and flow-matching generators: although their internal dynamics are Markovian, rollout stability is governed by per-step \emph{conditional law} errors. Using the Mori--Zwanzig projection formalism, we show that eliminating unresolved variables yields an exact resolved evolution with a Markov term, a memory term, and an orthogonal forcing, exposing a structural limitation of memoryless closures. Motivated by this, we introduce memory-conditioned diffusion/flow-matching with a compact online state injected into denoising via latent features. Via disintegration, memory induces a structured conditional tail prior for unresolved scales and reduces the transport needed to populate missing frequencies. We prove Wasserstein stability of the resulting conditional kernel. We then derive discrete Grönwall rollout bounds that separate memory approximation from conditional generation error. Experiments on compressible flows with shocks and multiscale mixing show improved accuracy and markedly more stable long-horizon rollouts, with better fine-scale spectral and statistical fidelity.

</details>


### [157] [NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models](https://arxiv.org/abs/2602.06694)
*Hyochan Chong,Dongkyu Kim,Changdong Kim,Minseop Choi*

Main category: cs.LG

TL;DR: NanoQuant is a novel post-training quantization method that enables efficient compression of large language models (LLMs) to binary (1-bit) and sub-1-bit levels, overcoming limitations of existing methods that require high data/compute or additional storage. It formulates quantization as a low-rank binary factorization problem, using an efficient ADMM-based initialization followed by block and model reconstruction for tuning. This approach achieves state-of-the-art accuracy at extremely low memory usage, enabling deployment of 70B-scale models like Llama2-70B on consumer hardware (e.g., 8 GB GPU), with 25.8× compression in 13 hours on a single H100.


<details>
  <summary>Details</summary>
Motivation: Existing weight-only quantization methods struggle to efficiently compress LLMs to binary or sub-1-bit levels due to high computational demands, large data requirements, or increased storage overhead. There is a need for a lightweight, scalable PTQ method that enables ultra-low-bit inference without sacrificing accuracy.

Method: NanoQuant formulates quantization as a low-rank binary factorization problem, decomposing full-precision weights into low-rank binary matrices and scale factors. It employs an alternating direction method of multipliers (ADMM) for precise initialization of latent binary components and uses a block-wise and model-level reconstruction process to fine-tune the parameters, ensuring high fidelity and low memory footprint.

Result: NanoQuant achieves state-of-the-art performance in post-training quantization at sub-1-bit and 1-bit levels, enabling up to 25.8× compression of Llama2-70B. The compressed model can run efficiently on consumer-grade 8 GB GPUs, demonstrating feasibility of deploying massive models on low-resource hardware.

Conclusion: NanoQuant establishes a new benchmark in low-memory post-training quantization by enabling effective 1-bit and sub-1-bit compression of LLMs with minimal compute and storage cost, making large-scale model deployment practical even on consumer devices.

Abstract: Weight-only quantization has become a standard approach for efficiently serving large language models (LLMs). However, existing methods fail to efficiently compress models to binary (1-bit) levels, as they either require large amounts of data and compute or incur additional storage. In this work, we propose NanoQuant, the first post-training quantization (PTQ) method to compress LLMs to both binary and sub-1-bit levels. NanoQuant formulates quantization as a low-rank binary factorization problem, and compresses full-precision weights to low-rank binary matrices and scales. Specifically, it utilizes an efficient alternating direction method of multipliers (ADMM) method to precisely initialize latent binary matrices and scales, and then tune the initialized parameters through a block and model reconstruction process. Consequently, NanoQuant establishes a new Pareto frontier in low-memory post-training quantization, achieving state-of-the-art accuracy even at sub-1-bit compression rates. NanoQuant makes large-scale deployment feasible on consumer hardware. For example, it compresses Llama2-70B by 25.8$\times$ in just 13 hours on a single H100, enabling a 70B model to operate on a consumer 8 GB GPU.

</details>


### [158] [Explaining Grokking in Transformers through the Lens of Inductive Bias](https://arxiv.org/abs/2602.06702)
*Jaisidh Singh,Diganta Misra,Antonio Orvieto*

Main category: cs.LG

TL;DR: 本文研究了Transformer中的grokking现象，从归纳偏置的角度出发，探讨了架构选择（如层归一化位置）和优化设置如何影响grokking速度与模式。研究发现，层归一化的位置通过影响捷径学习和注意力熵来调节grokking速度；优化参数（如学习率、权重衰减）会干扰读出尺度作为懒惰训练控制变量的有效性，表明grokking并非简单的懒惰到丰富学习的转变，而是特征在训练中持续演化。此外，研究揭示了泛化能力与特征可压缩性之间的可预测关系，验证了归纳偏置对grokking的系统性影响。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer模型在grokking现象中的学习机制，尤其是归纳偏置（如架构设计和优化策略）如何影响模型从简单到复杂解的过渡过程。

Method: 通过控制实验分析层归一化位置、优化超参数（学习率、权重衰减、读出尺度）对grokking的影响，结合注意力熵、捷径学习和特征演化分析，揭示归纳偏置的作用机制。

Result: 层归一化位置显著影响grokking速度，且可通过注意力熵和捷径学习解释；读出尺度不能独立作为懒惰训练的控制变量，因受学习率和权重衰减影响；特征在训练中连续演化，支持非突变的学习范式；泛化能力与特征可压缩性正相关，且该关系在不同归纳偏置下保持一致。

Conclusion: grokking在Transformer中是归纳偏置的函数，其过程比简单的懒惰-丰富过渡更复杂，特征演化连续，泛化能力可通过特征压缩性预测。该研究为理解深度学习中的隐式偏好提供了新视角。

Abstract: We investigate grokking in transformers through the lens of inductive bias: dispositions arising from architecture or optimization that let the network prefer one solution over another. We first show that architectural choices such as the position of Layer Normalization (LN) strongly modulates grokking speed. This modulation is explained by isolating how LN on specific pathways shapes shortcut-learning and attention entropy. Subsequently, we study how different optimization settings modulate grokking, inducing distinct interpretations of previously proposed controls such as readout scale. Particularly, we find that using readout scale as a control for lazy training can be confounded by learning rate and weight decay in our setting. Accordingly, we show that features evolve continuously throughout training, suggesting grokking in transformers can be more nuanced than a lazy-to-rich transition of the learning regime. Finally, we show how generalization predictably emerges with feature compressibility in grokking, across different modulators of inductive bias. Our code is released at https://tinyurl.com/y52u3cad.

</details>


### [159] [SaDiT: Efficient Protein Backbone Design via Latent Structural Tokenization and Diffusion Transformers](https://arxiv.org/abs/2602.06706)
*Shentong Mo,Lanqing Li*

Main category: cs.LG

TL;DR: SaDiT is a novel framework that accelerates protein backbone generation by combining SaProt Tokenization with a Diffusion Transformer (DiT) architecture. It uses a discrete latent space for structural compression, maintains SE(3) equivalence, and introduces an IPA Token Cache to optimize Invariant Point Attention layers. This leads to faster sampling and improved performance over state-of-the-art models like RFDiffusion and Proteina in both speed and structural quality.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion-based generative models for protein design are computationally intensive and slow, limiting large-scale exploration. While flow-matching methods like Proteina improve efficiency, the potential of tokenization for compressing protein structures and accelerating generation remains underexplored. The authors aim to address these limitations by introducing a more efficient, scalable framework.

Method: SaDiT integrates SaProt Tokenization to represent protein backbones in a discrete latent space, enabling structural compression and reduced computational complexity. It employs a Diffusion Transformer (DiT) architecture with SE(3)-equivariant operations. An IPA Token Cache mechanism reuses computed token states during iterative sampling to accelerate Invariant Point Attention layers.

Result: SaDiT achieves superior performance compared to RFDiffusion and Proteina in both unconditional and fold-class conditional backbone generation tasks. It demonstrates faster computational speed, higher structural viability, and better capture of complex topological features with high designability.

Conclusion: SaDiT effectively accelerates protein backbone generation through structural tokenization and optimized attention mechanisms, offering a scalable and efficient solution for de novo protein design while preserving geometric fidelity and SE(3) equivalence.

Abstract: Generative models for de novo protein backbone design have achieved remarkable success in creating novel protein structures. However, these diffusion-based approaches remain computationally intensive and slower than desired for large-scale structural exploration. While recent efforts like Proteina have introduced flow-matching to improve sampling efficiency, the potential of tokenization for structural compression and acceleration remains largely unexplored in the protein domain. In this work, we present SaDiT, a novel framework that accelerates protein backbone generation by integrating SaProt Tokenization with a Diffusion Transformer (DiT) architecture. SaDiT leverages a discrete latent space to represent protein geometry, significantly reducing the complexity of the generation process while maintaining theoretical SE(3) equivalence. To further enhance efficiency, we introduce an IPA Token Cache mechanism that optimizes the Invariant Point Attention (IPA) layers by reusing computed token states during iterative sampling. Experimental results demonstrate that SaDiT outperforms state-of-the-art models, including RFDiffusion and Proteina, in both computational speed and structural viability. We evaluate our model across unconditional backbone generation and fold-class conditional generation tasks, where SaDiT shows superior ability to capture complex topological features with high designability.

</details>


### [160] [F-GRPO: Don't Let Your Policy Learn the Obvious and Forget the Rare](https://arxiv.org/abs/2602.06717)
*Daniil Plyusov,Alexey Gorbatovski,Boris Shaposhnikov,Viacheslav Sinii,Alexey Malakhov,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 本文研究了基于组采样的强化学习中，组大小对学习效果的影响，发现小样本组容易遗漏罕见但正确的轨迹，且更新会重新分配正确解的质量，导致稀有解质量下降。为此提出一种受焦点损失启发的难度感知优势缩放系数，有效降低高成功率提示的更新权重。该方法可无缝集成到GRPO、DAPO、CISPO等算法中，在不增加计算成本的情况下显著提升性能，如在Qwen2.5-7B上pass@256指标平均提升约6个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有基于组采样的强化学习方法受限于计算资源，难以使用大组规模，导致学习偏向常见轨迹，忽略罕见但正确的解；同时小样本组易造成正确解质量被稀释，影响模型泛化能力。

Method: 提出一种难度感知的优势缩放系数，借鉴Focal Loss思想，对高成功率的样本降低更新权重，以缓解对常见解的过度优化，并通过理论分析组大小与遗漏稀有正确解概率的关系，指导算法设计。

Result: 在Qwen2.5-7B模型上，所提方法在in-domain和out-of-domain基准测试中显著提升pass@256指标：GRPO从64.1升至70.3，DAPO从69.3升至72.5，CISPO从73.2升至76.8，同时保持或提升pass@1性能，无需增加组大小或计算开销。

Conclusion: 提出的难度感知优势缩放机制能有效缓解小样本组采样带来的偏差问题，增强对稀有正确解的探索能力，提升模型整体性能，且具有良好的兼容性和轻量性，适用于多种主流组相对强化学习算法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is commonly based on group sampling to estimate advantages and stabilize policy updates. In practice, large group sizes are not feasible due to computational limits, which biases learning toward trajectories that are already likely. Smaller groups often miss rare-correct trajectories while still containing mixed rewards, concentrating probability on common solutions. We derive the probability that updates miss rare-correct modes as a function of group size, showing non-monotonic behavior, and characterize how updates redistribute mass within the correct set, revealing that unsampled-correct mass can shrink even as total correct mass grows. Motivated by this analysis, we propose a difficulty-aware advantage scaling coefficient, inspired by Focal loss, that down-weights updates on high-success prompts. The lightweight modification can be directly integrated into any group-relative RLVR algorithm such as GRPO, DAPO, and CISPO. On Qwen2.5-7B across in-domain and out-of-domain benchmarks, our method improves pass@256 from 64.1 $\rightarrow$ 70.3 (GRPO), 69.3 $\rightarrow$ 72.5 (DAPO), and 73.2 $\rightarrow$ 76.8 (CISPO), while preserving or improving pass@1, without increasing group size or computational cost.

</details>


### [161] [Disentanglement by means of action-induced representations](https://arxiv.org/abs/2602.06741)
*Gorka Muñoz-Gil,Hendrik Poulsen Nautrup,Arunava Majumder,Paulin de Schoulepnikoff,Florian Fürrutter,Marius Krumm,Hans J. Briegel*

Main category: cs.LG

TL;DR: 本文提出了动作诱导表示（AIR）框架，通过建模物理系统在可执行实验（或动作）下的表示，实现了基于动作依赖性的可解耦表征。提出变分AIR架构（VAIR），可在标准变分自编码器（VAE）失效的情况下实现可证明的解耦，不仅捕捉状态表示，还显式建模生成因素与动作之间的依赖关系，直接关联实验与影响的自由度。


<details>
  <summary>Details</summary>
Motivation: 现有变分自编码器（VAE）在学习可解释表示时面临解耦困难，根本原因在于无法进行非线性独立成分分析。为克服这一限制，需要一种能从实验动作中推导出可解耦表征的新框架。

Method: 提出动作诱导表示（AIR）框架，将系统表示建模为对可执行动作的响应；设计变分AIR（VAIR）架构，利用动作信息实现可证明的解耦，通过联合建模状态与动作依赖关系提升可解释性。

Result: VAIR在多个数据集上实现了显著优于标准VAE的解耦性能，且能准确捕捉生成因素与动作之间的依赖关系，验证了理论上的可解耦性。

Conclusion: 通过引入动作诱导表示框架和相应的变分架构VAIR，本研究成功解决了传统VAE在解耦表征中的根本局限，为物理系统建模提供了可解释、可推理的表示学习新范式。

Abstract: Learning interpretable representations with variational autoencoders (VAEs) is a major goal of representation learning. The main challenge lies in obtaining disentangled representations, where each latent dimension corresponds to a distinct generative factor. This difficulty is fundamentally tied to the inability to perform nonlinear independent component analysis. Here, we introduce the framework of action-induced representations (AIRs) which models representations of physical systems given experiments (or actions) that can be performed on them. We show that, in this framework, we can provably disentangle degrees of freedom w.r.t. their action dependence. We further introduce a variational AIR architecture (VAIR) that can extract AIRs and therefore achieve provable disentanglement where standard VAEs fail. Beyond state representation, VAIR also captures the action dependence of the underlying generative factors, directly linking experiments to the degrees of freedom they influence.

</details>


### [162] [Vision Transformer Finetuning Benefits from Non-Smooth Components](https://arxiv.org/abs/2602.06883)
*Ambroise Odonnat,Laetitia Chapel,Romain Tavenard,Ievgen Redko*

Main category: cs.LG

TL;DR: 本文研究视觉Transformer在迁移学习中的可塑性，发现注意力模块和前馈层的高可塑性（即低平滑性）能显著提升微调性能，挑战了传统认为平滑性越好的观点。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注Transformer的平滑性对泛化、训练稳定性和对抗鲁棒性的影响，但其在迁移学习中的作用尚不明确。本文旨在揭示组件可塑性与迁移学习性能之间的关系，为适配过程提供理论指导。

Method: 通过定义平均变化率来量化组件对输入扰动的敏感性（即可塑性），结合理论分析与大量实验，评估不同组件在微调任务中的表现。

Result: 实验表明，注意力模块和前馈层具有较高的可塑性，且在微调中表现更优；高可塑性反而带来更好的适应能力，说明低平滑性在某些场景下更具优势。

Conclusion: Transformer组件的可塑性是影响迁移学习性能的关键因素，高可塑性（低平滑性）有助于更好地适应输入变化，应优先考虑在微调中调整这些组件。

Abstract: The smoothness of the transformer architecture has been extensively studied in the context of generalization, training stability, and adversarial robustness. However, its role in transfer learning remains poorly understood. In this paper, we analyze the ability of vision transformer components to adapt their outputs to changes in inputs, or, in other words, their plasticity. Defined as an average rate of change, it captures the sensitivity to input perturbation; in particular, a high plasticity implies low smoothness. We demonstrate through theoretical analysis and comprehensive experiments that this perspective provides principled guidance in choosing the components to prioritize during adaptation. A key takeaway for practitioners is that the high plasticity of the attention modules and feedforward layers consistently leads to better finetuning performance. Our findings depart from the prevailing assumption that smoothness is desirable, offering a novel perspective on the functional properties of transformers. The code is available at https://github.com/ambroiseodt/vit-plasticity.

</details>


### [163] [Soft Forward-Backward Representations for Zero-shot Reinforcement Learning with General Utilities](https://arxiv.org/abs/2602.06769)
*Marco Bagatella,Thomas Rupf,Georg Martius,Andreas Krause*

Main category: cs.LG

TL;DR: 本文提出了一种新的最大熵（soft）前向-后向算法，用于在零样本强化学习中处理具有通用效用函数的RL问题。该方法能够从离线数据中恢复出一系列随机策略，直接优化任意可微的占用度量函数，适用于分布匹配或纯探索等任务，而无需依赖迭代优化。通过零阶搜索结合紧凑的策略嵌入，实现了测试时的高效优化。


<details>
  <summary>Details</summary>
Motivation: 现有零样本强化学习方法主要针对加性奖励问题，无法处理更复杂的通用效用函数（如分布匹配、纯探索）。本文旨在扩展零样本方法的应用范围，使其能处理更广泛且更具表达力的奖励结构。

Method: 提出一种最大熵（soft）版本的前向-后向算法，结合零阶搜索与紧凑策略嵌入，直接在测试时优化任意可微的效用函数，避免传统迭代优化过程。

Result: 在教学案例和高维实验中，新方法既保持了原前向-后向算法的优点，又成功扩展到更广泛的强化学习任务，包括非加性奖励场景。

Conclusion: 该方法有效拓展了零样本强化学习的能力边界，为处理通用效用函数提供了可行框架，具备良好的泛化性和实用性。

Abstract: Recent advancements in zero-shot reinforcement learning (RL) have facilitated the extraction of diverse behaviors from unlabeled, offline data sources. In particular, forward-backward algorithms (FB) can retrieve a family of policies that can approximately solve any standard RL problem (with additive rewards, linear in the occupancy measure), given sufficient capacity. While retaining zero-shot properties, we tackle the greater problem class of RL with general utilities, in which the objective is an arbitrary differentiable function of the occupancy measure. This setting is strictly more expressive, capturing tasks such as distribution matching or pure exploration, which may not be reduced to additive rewards. We show that this additional complexity can be captured by a novel, maximum entropy (soft) variant of the forward-backward algorithm, which recovers a family of stochastic policies from offline data. When coupled with zero-order search over compact policy embeddings, this algorithm can sidestep iterative optimization schemes, and optimizes general utilities directly at test-time. Across both didactic and high-dimensional experiments, we demonstrate that our method retains favorable properties of FB algorithms, while also extending their range to more general RL problems.

</details>


### [164] [AEGIS: Adversarial Target-Guided Retention-Data-Free Robust Concept Erasure from Diffusion Models](https://arxiv.org/abs/2602.06771)
*Fengpeng Li,Kemou Li,Qizhou Wang,Bo Han,Jiantao Zhou*

Main category: cs.LG

TL;DR: 本文提出AEGIS框架，一种无需保留数据的对抗性概念擦除方法，同时提升扩散模型在概念擦除中的鲁棒性和保留能力，解决现有方法在两者间权衡的难题。


<details>
  <summary>Details</summary>
Motivation: 当前概念擦除方法在鲁棒性（抵抗概念重新激活）和保留性（保持无关概念的完整性）之间存在权衡，难以兼顾，影响实际应用效果。

Method: 提出Adversarial Erasure with Gradient Informed Synergy (AEGIS)，通过梯度信息引导的对抗性擦除机制，在不依赖保留数据的情况下实现鲁棒性与保留性的协同增强。

Result: AEGIS在多项评估中同时显著提升了概念擦除的鲁棒性与保留性，优于现有方法，且无需额外保留数据，具有更强的实用性。

Conclusion: AEGIS成功实现了概念擦除中鲁棒性与保留性的协同优化，为安全可控的扩散模型提供了有效解决方案。

Abstract: Concept erasure helps stop diffusion models (DMs) from generating harmful content; but current methods face robustness retention trade off. Robustness means the model fine-tuned by concept erasure methods resists reactivation of erased concepts, even under semantically related prompts. Retention means unrelated concepts are preserved so the model's overall utility stays intact. Both are critical for concept erasure in practice, yet addressing them simultaneously is challenging, as existing works typically improve one factor while sacrificing the other. Prior work typically strengthens one while degrading the other, e.g., mapping a single erased prompt to a fixed safe target leaves class level remnants exploitable by prompt attacks, whereas retention-oriented schemes underperform against adaptive adversaries. This paper introduces Adversarial Erasure with Gradient Informed Synergy (AEGIS), a retention-data-free framework that advances both robustness and retention.

</details>


### [165] [Calibrating Generative AI to Produce Realistic Essays for Data Augmentation](https://arxiv.org/abs/2602.06772)
*Edward W. Wolfe,Justin O. Barber*

Main category: cs.LG

TL;DR: 本研究探讨了三种大语言模型提示策略在生成与原始作文质量一致且具有真实感的模拟作文方面的表现，结果表明‘预测下一个’策略在评分一致性、质量保留和文本真实性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习自动评分引擎中训练数据有限的问题，通过数据增强提升模型性能。

Method: 通过三种大语言模型提示策略生成模拟学生作文，并由人工评分员对生成作文的分数一致性、质量保留和文本真实性进行评估。

Result: ‘预测下一个’策略在评分一致性上表现最好；‘预测下一个’和‘句子’策略在保持原作文质量方面表现优异；‘预测下一个’和‘25个示例’策略生成的文本最被认定为真实。

Conclusion: 大语言模型的提示策略对生成高质量、高真实性的模拟作文具有显著影响，其中‘预测下一个’策略综合表现最优，适用于自动评分系统的数据增强。

Abstract: Data augmentation can mitigate limited training data in machine-learning automated scoring engines for constructed response items. This study seeks to determine how well three approaches to large language model prompting produce essays that preserve the writing quality of the original essays and produce realistic text for augmenting ASE training datasets. We created simulated versions of student essays, and human raters assigned scores to them and rated the realism of the generated text. The results of the study indicate that the predict next prompting strategy produces the highest level of agreement between human raters regarding simulated essay scores, predict next and sentence strategies best preserve the rated quality of the original essay in the simulated essays, and predict next and 25 examples strategies produce the most realistic text as judged by human raters.

</details>


### [166] [On the Identifiability of Steering Vectors in Large Language Models](https://arxiv.org/abs/2602.06801)
*Sohan Venkatesh,Ashish Mahendran Kurapath*

Main category: cs.LG

TL;DR: 该研究揭示了激活引导方法（如人物向量）在控制大语言模型行为时存在根本性的非可识别性问题，即多个不同的内部干预在行为上无法区分。尽管这些方法被广泛解释为揭示了有意义的内部表示，但作者通过理论证明和实证验证表明，在现实建模与数据条件下，引导向量无法唯一确定。然而，在引入统计独立性、稀疏性约束、多环境验证或跨层一致性等结构假设后，可识别性可恢复。研究强调了可靠安全控制所需的关键结构性假设，并揭示了模型可解释性的基本限制。


<details>
  <summary>Details</summary>
Motivation: 当前激活引导方法被广泛用于控制大语言模型的行为，常被解释为揭示了模型内部有意义的表示。然而，这一解释依赖于一个隐含假设：引导方向是可识别且唯一可恢复的。本文旨在检验这一假设的有效性，并探索其在实际条件下的可行性。

Method: 将激活引导形式化为对内部表示的干预，基于真实建模和数据条件进行理论分析，证明引导向量存在大规模等价类，即行为不可区分的干预方式。通过多模型、多语义特征的实证实验，验证了正交扰动具有近似等效效果，进一步支持理论发现。同时，探讨在特定结构假设下可识别性的恢复机制。

Result: 理论与实证结果均表明，在标准条件下，激活引导向量是非可识别的，存在大量行为上不可区分的等价干预。但在引入统计独立性、稀疏性、多环境验证或跨层一致性等结构假设后，可识别性得以恢复。

Conclusion: 本研究揭示了现有激活引导方法在解释性和可靠性上的根本局限，强调了实现安全关键控制所必需的结构性假设，为未来可解释性研究提供了理论基础和实践指引。

Abstract: Activation steering methods, such as persona vectors, are widely used to control large language model behavior and increasingly interpreted as revealing meaningful internal representations. This interpretation implicitly assumes steering directions are identifiable and uniquely recoverable from input-output behavior. We formalize steering as an intervention on internal representations and prove that, under realistic modeling and data conditions, steering vectors are fundamentally non-identifiable due to large equivalence classes of behaviorally indistinguishable interventions. Empirically, we validate this across multiple models and semantic traits, showing orthogonal perturbations achieve near-equivalent efficacy with negligible effect sizes. However, identifiability is recoverable under structural assumptions including statistical independence, sparsity constraints, multi-environment validation or cross-layer consistency. These findings reveal fundamental interpretability limits and clarify structural assumptions required for reliable safety-critical control.

</details>


### [167] [On the Convergence of Multicalibration Gradient Boosting](https://arxiv.org/abs/2602.06773)
*Daniel Haimovich,Fridolin Linder,Lorenzo Perini,Niek Tax,Milan Vojnovic*

Main category: cs.LG

TL;DR: 该论文为多校准梯度提升在回归任务中提供了收敛性保证，证明了预测更新量的衰减速率为 $O(1/\sqrt{T})$，进而推导出多校准误差的相同收敛速率；在弱学习器满足光滑性假设时，收敛率可提升至线性；还分析了自适应变体和重缩放方案的收敛性，并通过真实数据集实验验证理论结果。


<details>
  <summary>Details</summary>
Motivation: 尽管多校准梯度提升在实践中表现出良好的性能并已大规模部署，但其收敛性质尚不明确，亟需理论支持以理解其行为机制。

Method: 通过分析平方误差损失下的多校准梯度提升算法，建立预测更新幅度与迭代轮数之间的关系，引入光滑性假设优化收敛速率，并研究自适应策略与重缩放方案对收敛性的影响。

Result: 证明了多校准误差在 $O(1/\sqrt{T})$ 速率下收敛，光滑条件下实现线性收敛；自适应变体具有局部二次收敛性；重缩放方案可保持收敛性；实验验证了理论预测的有效性。

Conclusion: 本工作首次为多校准梯度提升提供了严格的收敛性理论保障，揭示了其快速收敛的条件和机制，为实际应用提供了理论依据。

Abstract: Multicalibration gradient boosting has recently emerged as a scalable method that empirically produces approximately multicalibrated predictors and has been deployed at web scale. Despite this empirical success, its convergence properties are not well understood. In this paper, we bridge the gap by providing convergence guarantees for multicalibration gradient boosting in regression with squared-error loss. We show that the magnitude of successive prediction updates decays at $O(1/\sqrt{T})$, which implies the same convergence rate bound for the multicalibration error over rounds. Under additional smoothness assumptions on the weak learners, this rate improves to linear convergence. We further analyze adaptive variants, showing local quadratic convergence of the training loss, and we study rescaling schemes that preserve convergence. Experiments on real-world datasets support our theory and clarify the regimes in which the method achieves fast convergence and strong multicalibration.

</details>


### [168] [Robust Online Learning](https://arxiv.org/abs/2602.06775)
*Sajad Ashkezari*

Main category: cs.LG

TL;DR: 本文研究了在输入被扰动的情况下学习鲁棒分类器的问题，其中干净数据及其标签也由对抗方选择。作者将此设定形式化为在线学习问题，考虑了假设类的可实现和非可实现学习性，并定义了一个新的类维度，该维度控制可实现情况下的错误界限和非可实现情况下的遗憾界限。该维度相较于传统PAC学习中的维度更为简单，类似于Littlestone维数。作者还将该维度推广到多分类假设类，并在可实现情况下证明了类似结果。最后，研究了学习者不知道每个点允许扰动集合，仅具有先验信息的情况。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒PAC学习假设干净数据是固定的，而本文关注更严格的设定：干净数据和标签均由对抗方选择，旨在建立更现实且更具挑战性的鲁棒学习框架。

Method: 将问题形式化为在线学习模型，引入一个新的类维度来刻画学习能力，通过分析其在可实现与非可实现情形下的表现，推导出相应的错误界与遗憾界；进一步扩展至多分类场景，并处理学习者对扰动集不完全知情的情形。

Result: 提出的新维度能够有效控制在线学习中的错误率和遗憾，且在可实现和非可实现设置下均成立；多分类情形下结论成立；当学习者仅有扰动的先验知识时，仍可实现有效的学习。

Conclusion: 本文提出的维度为鲁棒学习提供了简洁且有力的理论工具，揭示了在对抗性数据选择与未知扰动集条件下学习鲁棒分类器的可能性与边界。

Abstract: We study the problem of learning robust classifiers where the classifier will receive a perturbed input. Unlike robust PAC learning studied in prior work, here the clean data and its label are also adversarially chosen. We formulate this setting as an online learning problem and consider both the realizable and agnostic learnability of hypothesis classes. We define a new dimension of classes and show it controls the mistake bounds in the realizable setting and the regret bounds in the agnostic setting. In contrast to the dimension that characterizes learnability in the PAC setting, our dimension is rather simple and resembles the Littlestone dimension. We generalize our dimension to multiclass hypothesis classes and prove similar results in the realizable case. Finally, we study the case where the learner does not know the set of allowed perturbations for each point and only has some prior on them.

</details>


### [169] [Displacement-Resistant Extensions of DPO with Nonconvex $f$-Divergences](https://arxiv.org/abs/2602.06788)
*Idan Pipano,Shoham Sabach,Kavosh Asadi,Mohammad Ghavamzadeh*

Main category: cs.LG

TL;DR: 该论文提出了一种新的基于$f$-散度的强化学习人类反馈（RLHF）框架，突破了传统DPO方法对生成函数$f$凸性的依赖。作者识别出一个更广泛的‘DPO可诱导’条件以保证问题可解，并引入‘抗概率位移’条件以避免模型在比较中将优劣响应的概率推向零。基于此，提出新型损失函数SquaredPO，兼具更强理论保障与良好实践表现。


<details>
  <summary>Details</summary>
Motivation: 传统DPO方法依赖于凸$f$-散度以保证优化可行性，但其限制了损失函数的设计灵活性；同时存在概率位移现象，导致模型对优劣选项的输出概率趋于零，影响可靠性。因此需要更通用且稳健的理论框架来改进对齐方法。

Method: 通过分析$f$-散度在RLHF目标中的作用，识别出‘DPO可诱导’条件作为保持优化可解性的关键；进一步提出‘抗概率位移’条件以防止输出分布异常。在此基础上，构造满足两个条件的特定函数，导出新损失SquaredPO。

Result: 所提出的SquaredPO损失在理论上具备更强的稳定性与收敛性保证，且在实际实验中表现优于或相当优于DPO，在多个基准测试中展现出良好的对齐性能和鲁棒性。

Conclusion: 本研究揭示了实现高效、稳定语言模型对齐的关键条件，提出的新损失SquaredPO不仅拓展了现有理论边界，也为未来设计更可靠的人类反馈对齐算法提供了新方向。

Abstract: DPO and related algorithms align language models by directly optimizing the RLHF objective: find a policy that maximizes the Bradley-Terry reward while staying close to a reference policy through a KL divergence penalty. Previous work showed that this approach could be further generalized: the original problem remains tractable even if the KL divergence is replaced by a family of $f$-divergence with a convex generating function $f$. Our first contribution is to show that convexity of $f$ is not essential. Instead, we identify a more general condition, referred to as DPO-inducing, that precisely characterizes when the RLHF problem remains tractable. Our next contribution is to establish a second condition on $f$ that is necessary to prevent probability displacement, a known empirical phenomenon in which the probabilities of the winner and the loser responses approach zero. We refer to any $f$ that satisfies this condition as displacement-resistant. We finally focus on a specific DPO-inducing and displacement-resistant $f$, leading to our novel SquaredPO loss. Compared to DPO, this new loss offers stronger theoretical guarantees while performing competitively in practice.

</details>


### [170] [Rare Event Analysis of Large Language Models](https://arxiv.org/abs/2602.06791)
*Jake McAllister Dorman,Edward Gillman,Dominic C. Rose,Jamie F. Mair,Juan P. Garrahan*

Main category: cs.LG

TL;DR: 本文提出一个端到端框架，用于系统分析大语言模型（LLMs）中的罕见事件。尽管这些事件在概率上稀有且难以观测，但其在部署阶段可能具有重要影响。研究涵盖了理论、高效生成策略、概率估计与错误分析，并通过实例验证了方法的有效性，同时拓展至其他模型和场景，展现了方法的通用性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为概率模型，在推理过程中会表现出罕见但意义重大的行为。由于模型规模庞大，开发阶段未观察到的事件在实际部署中可能变得显著，因此需要系统化的方法来识别和分析这些罕见事件。

Method: 提出一个涵盖理论建模、高效生成策略、概率估计与误差分析的完整框架，结合具体案例进行实践验证，并探讨其在其他模型与场景中的可扩展性。

Result: 成功构建了一个可操作的罕见事件分析框架，能够有效识别和评估大语言模型中罕见但关键的行为，并证明其在多种情境下的适用性。

Conclusion: 该框架为理解与管理大语言模型中的罕见事件提供了系统性解决方案，具有广泛的应用前景和良好的泛化能力。

Abstract: Being probabilistic models, during inference large language models (LLMs) display rare events: behaviour that is far from typical but highly significant. By definition all rare events are hard to see, but the enormous scale of LLM usage means that events completely unobserved during development are likely to become prominent in deployment. Here we present an end-to-end framework for the systematic analysis of rare events in LLMs. We provide a practical implementation spanning theory, efficient generation strategies, probability estimation and error analysis, which we illustrate with concrete examples. We outline extensions and applications to other models and contexts, highlighting the generality of the concepts and techniques presented here.

</details>


### [171] [FlowDA: Accurate, Low-Latency Weather Data Assimilation via Flow Matching](https://arxiv.org/abs/2602.06800)
*Ran Cheng,Lailai Zhu*

Main category: cs.LG

TL;DR: 提出FlowDA，一种基于流匹配的低延迟气象尺度生成式数据同化框架，通过SetConv嵌入条件观测并微调Aurora基础模型，在多种观测率下表现优于基线方法，且对观测噪声鲁棒、长时序循环同化稳定。


<details>
  <summary>Details</summary>
Motivation: 传统变分数据同化方法在机器学习气象预测中计算开销大；现有生成式方法存在采样步骤多、误差累积问题，尤其在长时间自回归滚动和循环同化中表现不佳。

Method: 采用流匹配（flow matching）构建生成式数据同化框架，利用SetConv进行观测嵌入，并对Aurora基础模型进行微调以实现高效、准确的分析。

Result: 在观测率从3.9%降至0.1%的实验中，FlowDA性能显著优于强基线，参数量相当；对观测噪声具有鲁棒性，长时序自回归循环同化中表现稳定。

Conclusion: FlowDA为数据驱动的数据同化提供了高效、可扩展的新方向，有望缓解现代天气预报中的计算瓶颈。

Abstract: Data assimilation (DA) is a fundamental component of modern weather prediction, yet it remains a major computational bottleneck in machine learning (ML)-based forecasting pipelines due to reliance on traditional variational methods. Recent generative ML-based DA methods offer a promising alternative but typically require many sampling steps and suffer from error accumulation under long-horizon auto-regressive rollouts with cycling assimilation. We propose FlowDA, a low-latency weather-scale generative DA framework based on flow matching. FlowDA conditions on observations through a SetConv-based embedding and fine-tunes the Aurora foundation model to deliver accurate, efficient, and robust analyses. Experiments across observation rates decreasing from $3.9\%$ to $0.1\%$ demonstrate superior performance of FlowDA over strong baselines with similar tunable-parameter size. FlowDA further shows robustness to observational noise and stable performance in long-horizon auto-regressive cycling DA. Overall, FlowDA points to an efficient and scalable direction for data-driven DA.

</details>


### [172] [Supercharging Simulation-Based Inference for Bayesian Optimal Experimental Design](https://arxiv.org/abs/2602.06900)
*Samuel Klein,Willie Neiswanger,Daniel Ratner,Michael Kagan,Sean Gasiorowski*

Main category: cs.LG

TL;DR: 本文提出了一种基于模拟的推断（SBI）与贝叶斯最优实验设计（BOED）相结合的新方法，通过多种信息增益（EIG）的表述形式，利用现代SBI密度估计器（如神经后验、似然和比率估计），并引入一种基于神经似然估计的新EIG估计器。针对梯度优化中的瓶颈问题，提出多起点并行梯度上升策略以提升可靠性与性能。在标准BOED基准测试中，该方法性能可达到或超过现有最先进方法22%。


<details>
  <summary>Details</summary>
Motivation: 在许多场景下，贝叶斯最优实验设计（BOED）所需的似然估计难以计算，而现有的模拟推断（SBI）工具虽能应对复杂似然，但与BOED的结合仍受限于单一对比性信息增益（EIG）边界。因此需要更通用且高效的连接方式。

Method: 提出多种可直接利用现代SBI密度估计器的信息增益（EIG）形式；构建基于神经似然估计的新型EIG估计器；采用多起点并行梯度上升优化策略以克服梯度优化中的收敛困难。

Result: 所提方法在多个标准BOED基准上表现出色，性能匹配或优于现有最先进方法，最高提升达22%。

Conclusion: 将SBI与BOED结合的新框架不仅具有理论灵活性，还通过高效优化策略实现了显著性能提升，为复杂模型下的实验设计提供了实用且强大的解决方案。

Abstract: Bayesian optimal experimental design (BOED) seeks to maximize the expected information gain (EIG) of experiments. This requires a likelihood estimate, which in many settings is intractable. Simulation-based inference (SBI) provides powerful tools for this regime. However, existing work explicitly connecting SBI and BOED is restricted to a single contrastive EIG bound. We show that the EIG admits multiple formulations which can directly leverage modern SBI density estimators, encompassing neural posterior, likelihood, and ratio estimation. Building on this perspective, we define a novel EIG estimator using neural likelihood estimation. Further, we identify optimization as a key bottleneck of gradient based EIG maximization and show that a simple multi-start parallel gradient ascent procedure can substantially improve reliability and performance. With these innovations, our SBI-based BOED methods are able to match or outperform by up to $22\%$ existing state-of-the-art approaches across standard BOED benchmarks.

</details>


### [173] [Calibrating Tabular Anomaly Detection via Optimal Transport](https://arxiv.org/abs/2602.06810)
*Hangting Ye,He Zhao. Wei Fan,Xiaozhuang Song,Dandan Guo,Yi Chang,Hongyuan Zha*

Main category: cs.LG

TL;DR: CTAD是一种模型无关的后处理框架，通过样本特定校准增强现有表格式异常检测器。它利用随机采样得到的经验分布和K-means中心点的结构分布，通过最优传输（OT）距离衡量测试样本对两者兼容性的破坏程度，正常样本破坏小，异常样本破坏大，从而提供校准信号以放大检测效果。理论证明了OT距离下界与样本到中心点距离成正比，且异常在期望上获得更高校准分数，解释其跨数据集泛化能力。在34个多样化表格式数据集上，结合7种代表性检测器（涵盖密度估计、分类、重构和隔离方法），实验证明CTAD显著提升性能，且对超参数设置鲁棒，无需额外调参即可部署。


<details>
  <summary>Details</summary>
Motivation: 表格式异常检测面临数据异质性挑战：特征无自然关系，分布和尺度差异大，类型多样。现有方法依赖隐含假设，导致在某些数据集表现好但在其他数据集失败，缺乏统一高效的方法。需要一种能通用提升各类检测器性能的后处理框架。

Method: CTAD通过构建两个互补的正常数据分布——经验分布（来自随机采样）和结构分布（来自K-means聚类中心），使用最优传输（OT）距离度量测试样本加入后对这两个分布兼容性的破坏程度。正常样本引起的扰动小，异常样本引起的大，由此生成校准信号，用于增强原始检测器输出。理论分析表明，该方法在理论上保证异常样本获得更高的校准分。

Result: 在34个不同领域的表格式数据集上，使用7种主流检测器进行实验，结果显示CTAD在所有场景下均显著提升检测性能（统计显著）。即使对最先进的深度学习方法也有明显改进，且对超参数变化具有强鲁棒性，无需额外调优，适合实际部署。

Conclusion: CTAD是一种通用、高效、无需调参的后处理框架，能够一致地提升多种类型表格式异常检测器的性能，具备良好的泛化能力和实用性，为解决表格式异常检测中的异质性挑战提供了有效方案。

Abstract: Tabular anomaly detection (TAD) remains challenging due to the heterogeneity of tabular data: features lack natural relationships, vary widely in distribution and scale, and exhibit diverse types. Consequently, each TAD method makes implicit assumptions about anomaly patterns that work well on some datasets but fail on others, and no method consistently outperforms across diverse scenarios. We present CTAD (Calibrating Tabular Anomaly Detection), a model-agnostic post-processing framework that enhances any existing TAD detector through sample-specific calibration. Our approach characterizes normal data via two complementary distributions, i.e., an empirical distribution from random sampling and a structural distribution from K-means centroids, and measures how adding a test sample disrupts their compatibility using Optimal Transport (OT) distance. Normal samples maintain low disruption while anomalies cause high disruption, providing a calibration signal to amplify detection. We prove that OT distance has a lower bound proportional to the test sample's distance from centroids, and establish that anomalies systematically receive higher calibration scores than normals in expectation, explaining why the method generalizes across datasets. Extensive experiments on 34 diverse tabular datasets with 7 representative detectors spanning all major TAD categories (density estimation, classification, reconstruction, and isolation-based methods) demonstrate that CTAD consistently improves performance with statistical significance. Remarkably, CTAD enhances even state-of-the-art deep learning methods and shows robust performance across diverse hyperparameter settings, requiring no additional tuning for practical deployment.

</details>


### [174] [From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers](https://arxiv.org/abs/2602.06923)
*Ziming Liu,Sophia Sanborn,Surya Ganguli,Andreas Tolias*

Main category: cs.LG

TL;DR: 该研究探讨了通用人工智能架构是否能超越预测，发现宇宙的物理规律。通过引入三种最小归纳偏置——空间平滑性、稳定性与时间局部性，研究发现，仅需这些简单设计，通用Transformer模型即可从单纯的数据拟合转变为能够发现牛顿力学规律的“物理学家”。实验表明，模型不仅能拟合行星轨道为椭圆，还能揭示其背后的力学机制，标志着自动化科学发现的重要进展。


<details>
  <summary>Details</summary>
Motivation: 当前的AI模型虽然在预测任务上表现优异，但缺乏对物理规律的深层理解。以往方法依赖强领域先验，而通用模型（如Transformer）虽有高预测精度，却无法捕捉底层物理规律。本文旨在解决这一差距，探索如何让通用模型具备真正的物理洞察力。

Method: 提出并系统测试三种最小归纳偏置：1）将预测任务建模为连续回归以保证空间平滑性；2）在含噪声上下文中训练以增强稳定性，防止误差累积；3）限制注意力窗口仅关注近期状态，引入时间局部性假设，迫使模型学习因果动态而非记忆式拟合。

Result: 引入三种偏置后，通用Transformer成功构建出一致的开普勒世界模型，准确拟合行星轨迹为椭圆；进一步，在时间局部性约束下，模型不再依赖曲线拟合，而是自发推导出牛顿力的表达形式，揭示了真实的物理规律。

Conclusion: 简单的架构设计选择决定了AI是成为曲线拟合器还是物理学家。本研究证明，通过引入少量合理归纳偏置，通用深度学习模型可以实现对物理定律的自主发现，为自动化科学发现奠定了关键基础。

Abstract: Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on "world models" -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous "AI Physicist" approaches have successfully recovered such laws, they typically rely on strong, domain-specific priors that effectively "bake in" the physics. Conversely, Vafa et al. recently showed that generic Transformers fail to acquire these world models, achieving high predictive accuracy without capturing the underlying physical laws. We bridge this gap by systematically introducing three minimal inductive biases. We show that ensuring spatial smoothness (by formulating prediction as continuous regression) and stability (by training with noisy contexts to mitigate error accumulation) enables generic Transformers to surpass prior failures and learn a coherent Keplerian world model, successfully fitting ellipses to planetary trajectories. However, true physical insight requires a third bias: temporal locality. By restricting the attention window to the immediate past -- imposing the simple assumption that future states depend only on the local state rather than a complex history -- we force the model to abandon curve-fitting and discover Newtonian force representations. Our results demonstrate that simple architectural choices determine whether an AI becomes a curve-fitter or a physicist, marking a critical step toward automated scientific discovery.

</details>


### [175] [Learning Deep Hybrid Models with Sharpness-Aware Minimization](https://arxiv.org/abs/2602.06837)
*Naoya Takeishi*

Main category: cs.LG

TL;DR: 本文提出一种基于尖锐度感知最小化（SAM）的混合建模方法，通过关注损失极小值的平坦性来增强科学模型在预测中的作用，避免机器学习模型过度主导。该方法在不同模型和数据集上均表现出色，提升了混合模型的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统混合建模中，由于机器学习模型的灵活性，科学模型可能被忽略，导致混合建模失去意义。现有正则化方法依赖于特定模型结构和领域知识，缺乏通用性。

Method: 采用尖锐度感知最小化（SAM）思想，通过优化损失函数极小值的平坦性，使混合模型更简单且更依赖科学模型部分。

Result: 在多种模型和数据集上的数值实验表明，SAM-based 方法能有效提升科学模型在预测中的贡献，改善混合建模性能。

Conclusion: 通过引入平坦性优化，所提出的SAM方法能够有效解决混合建模中科学模型被忽视的问题，具有良好的通用性和鲁棒性。

Abstract: Hybrid modeling, the combination of machine learning models and scientific mathematical models, enables flexible and robust data-driven prediction with partial interpretability. However, effectively the scientific models may be ignored in prediction due to the flexibility of the machine learning model, making the idea of hybrid modeling pointless. Typically some regularization is applied to hybrid model learning to avoid such a failure case, but the formulation of the regularizer strongly depends on model architectures and domain knowledge. In this paper, we propose to focus on the flatness of loss minima in learning hybrid models, aiming to make the model as simple as possible. We employ the idea of sharpness-aware minimization and adapt it to the hybrid modeling setting. Numerical experiments show that the SAM-based method works well across different choices of models and datasets.

</details>


### [176] [Improved Sampling Schedules for Discrete Diffusion Models](https://arxiv.org/abs/2602.06849)
*Alberto Foresti,Mustapha Bounoua,Giulio Franzese,Luca Ambrogioni,Pietro Michiardi*

Main category: cs.LG

TL;DR: 本文研究离散扩散模型反向过程的信息理论原理，提出熵产生率作为信息生成的严格度量，并推导出中间状态与数据分布间Wasserstein距离的上界。基于此，提出了两种新型采样调度：基于熵增速率恒定的熵离散调度（EDS）和基于Wasserstein距离等步长的Wasserstein离散调度（WDS）。实验证明，新调度在合成数据、音乐记谱、视觉和语言建模等多个领域均显著优于现有方法，且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型虽在序列数据生成中表现强大，但其反向过程的信息理论机制远不如连续版本清晰，亟需从热力学熵产生角度理解其动态特性并优化采样策略。

Method: 通过热力学熵产生视角分析反向过程动态，提出熵产生率作为信息生成的度量指标，推导出Wasserstein距离的上界；进而设计基于物理启发度量的两种新采样调度：EDS（恒定熵增速率）和WDS（等Wasserstein步长）。

Result: 所提调度在多种任务中均实现更优生成质量与更低计算开销，显著超越当前最优方法。

Conclusion: 本工作揭示了离散扩散模型反向过程的热力学本质，提出的熵产生率与两类物理启发式调度为高效生成建模提供了理论支持与实践工具。

Abstract: Discrete diffusion models have emerged as a powerful paradigm for generative modeling on sequence data; however, the information-theoretic principles governing their reverse processes remain significantly less understood than those of their continuous counterparts. In this work, we bridge this gap by analyzing the reverse process dynamics through the lens of thermodynamic entropy production. We propose the entropy production rate as a rigorous proxy for quantifying information generation, deriving as a byproduct a bound on the Wasserstein distance between intermediate states and the data distribution. Leveraging these insights, we introduce two novel sampling schedules that are uniformly spaced with respect to their corresponding physics-inspired metrics: the Entropic Discrete Schedule (EDS), which is defined by maintaining a constant rate of information gain, and the Wasserstein Discrete Schedule (WDS), which is defined by taking equal steps in terms of the Wasserstein distance. We empirically demonstrate that our proposed schedules significantly outperform state-of-the-art strategies across diverse application domains, including synthetic data, music notation, vision and language modeling, consistently achieving superior performance at a lower computational budget.

</details>


### [177] [T-STAR: A Context-Aware Transformer Framework for Short-Term Probabilistic Demand Forecasting in Dock-Based Shared Micro-Mobility](https://arxiv.org/abs/2602.06866)
*Jingyi Cheng,Gonçalo Homem de Almeida Correia,Oded Cats,Shadi Sharif Azadeh*

Main category: cs.LG

TL;DR: T-STAR是一种基于Transformer的双阶段空间-时间自适应上下文表示框架，用于15分钟粒度的站点级共享单车需求概率预测。该模型通过分阶段处理粗粒度小时级模式与高频局部输入（如近期波动和地铁服务实时变化），有效分离长期稳定模式与短期波动，提升高分辨率预测精度。实验基于华盛顿特区的Capital Bikeshare数据，证明其在确定性和概率性准确性上优于现有方法，并展现出跨站点、跨时段的强鲁棒性。零样本预测实验显示其可迁移至未见服务区域而无需重新训练，具备支持多模式出行规划和实时微出行运营的潜力。


<details>
  <summary>Details</summary>
Motivation: 准确的短时需求预测对共享微出行服务的高效管理至关重要，但现有方法难以同时处理高分辨率时空特征与短期动态变化，尤其在应对局部瞬时波动和跨系统联动（如地铁影响）方面存在局限。因此亟需一种能捕捉长期规律并灵活响应短期扰动的新型框架。

Method: 提出T-STAR框架，采用双阶段结构：第一阶段使用时间序列Transformer建模小时级一致需求模式；第二阶段引入高频率局部输入（包括最近需求变化及相邻地铁服务状态），通过另一时间序列Transformer细化预测。两阶段均生成概率输出，实现不确定性感知。

Result: 在华盛顿特区的实证数据上，T-STAR在确定性与概率性指标上均显著优于基准模型；具有良好的空间与时间泛化能力；零样本迁移实验表明其可在未见区域直接应用而无需再训练，表现出强可迁移性。

Conclusion: T-STAR通过解耦长周期趋势与短时波动，实现了高精度、鲁棒且可迁移的15分钟级共享单车需求预测，为多模式出行规划与实时微出行调度提供了可靠支持。

Abstract: Reliable short-term demand forecasting is essential for managing shared micro-mobility services and ensuring responsive, user-centered operations. This study introduces T-STAR (Two-stage Spatial and Temporal Adaptive contextual Representation), a novel transformer-based probabilistic framework designed to forecast station-level bike-sharing demand at a 15-minute resolution. T-STAR addresses key challenges in high-resolution forecasting by disentangling consistent demand patterns from short-term fluctuations through a hierarchical two-stage structure. The first stage captures coarse-grained hourly demand patterns, while the second stage improves prediction accuracy by incorporating high-frequency, localized inputs, including recent fluctuations and real-time demand variations in connected metro services, to account for temporal shifts in short-term demand. Time series transformer models are employed in both stages to generate probabilistic predictions. Extensive experiments using Washington D.C.'s Capital Bikeshare data demonstrate that T-STAR outperforms existing methods in both deterministic and probabilistic accuracy. The model exhibits strong spatial and temporal robustness across stations and time periods. A zero-shot forecasting experiment further highlights T-STAR's ability to transfer to previously unseen service areas without retraining. These results underscore the framework's potential to deliver granular, reliable, and uncertainty-aware short-term demand forecasts, which enable seamless integration to support multimodal trip planning for travelers and enhance real-time operations in shared micro-mobility services.

</details>


### [178] [Decoupling Variance and Scale-Invariant Updates in Adaptive Gradient Descent for Unified Vector and Matrix Optimization](https://arxiv.org/abs/2602.06880)
*Zitao Song,Cedar Site Bai,Zhe Zhang,Brian Bullins,David F. Gleich*

Main category: cs.LG

TL;DR: 提出DeVA框架，通过解耦AdaGrad更新中的方差适应项和尺度不变项，实现从向量级自适应到矩阵谱优化的平滑过渡，显著提升语言建模与图像分类任务性能，减少约6.6%的令牌使用量，并在理论上证明方差适应项可改善块状光滑性以加速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有自适应方法如Adam虽在大规模向量优化中表现优异，但难以直接推广至矩阵级谱优化；而矩阵基谱优化器（如Muon）虽具潜力，却面临自然泛化不可行、无法简单迁移Adam适应机制等挑战，亟需一种能连接向量与矩阵层面自适应的新框架。

Method: 重新形式化AdaGrad更新，将其分解为方差适应项与尺度不变项，构建名为DeVA（Decoupled Variance Adaptation）的统一框架，实现向量与矩阵自适应之间的无缝衔接，支持从Adam平滑过渡到自适应谱下降。

Result: 在语言建模和图像分类任务上，DeVA显著优于当前先进方法（如Muon和SOAP），平均减少约6.6%的令牌使用量，且具备更强的收敛速度与稳定性。

Conclusion: DeVA成功建立向量级方差自适应与矩阵谱优化之间的桥梁，不仅提升了优化效率，还为未来矩阵级自适应优化提供了理论与实践基础。

Abstract: Adaptive methods like Adam have become the $\textit{de facto}$ standard for large-scale vector and Euclidean optimization due to their coordinate-wise adaptation with a second-order nature. More recently, matrix-based spectral optimizers like Muon (Jordan et al., 2024b) show the power of treating weight matrices as matrices rather than long vectors. Linking these is hard because many natural generalizations are not feasible to implement, and we also cannot simply move the Adam adaptation to the matrix spectrum. To address this, we reformulate the AdaGrad update and decompose it into a variance adaptation term and a scale-invariant term. This decoupling produces $\textbf{DeVA}$ ($\textbf{De}$coupled $\textbf{V}$ariance $\textbf{A}$daptation), a framework that bridges between vector-based variance adaptation and matrix spectral optimization, enabling a seamless transition from Adam to adaptive spectral descent. Extensive experiments across language modeling and image classification demonstrate that DeVA consistently outperforms state-of-the-art methods such as Muon and SOAP (Vyas et al., 2024), reducing token usage by around 6.6\%. Theoretically, we show that the variance adaptation term effectively improves the blockwise smoothness, facilitating faster convergence. Our implementation is available at https://github.com/Tsedao/Decoupled-Variance-Adaptation

</details>


### [179] [Sample Complexity of Causal Identification with Temporal Heterogeneity](https://arxiv.org/abs/2602.06899)
*Ameya Rathod,Sujay Belsare,Salvik Krishna Nautiyal,Dhruv Laad,Ponnurangam Kumaraguru*

Main category: cs.LG

TL;DR: 本文通过结合时间序列动态与多环境异质性，提出统一的可识别性条件，分析了在轻尾与重尾噪声下的统计恢复极限。研究表明，时间结构可替代缺失的环境多样性，即使在异质性不足时也能实现可识别性；而重尾分布虽保持几何可识别性，但样本复杂度显著增加，信息论边界揭示了协方差基因果图恢复方法在非平稳系统中的根本限制。


<details>
  <summary>Details</summary>
Motivation: 从观测数据中唯一恢复因果图是病态问题，需依赖特定结构或分布假设。现有方法分别利用时间序列或环境异质性，但缺乏整合。本文旨在通过融合两种异质性来源，提升因果结构的可识别性与实际可恢复性。

Method: 结合时间序列动态与多环境异质性，建立统一的可识别性条件；采用信息论方法推导重尾（Student's t）分布下的样本复杂度边界，分析不同噪声模型对因果恢复的影响。

Result: 时间结构可补偿环境多样性不足，实现可识别性；重尾分布下几何可识别性不变，但样本复杂度显著上升，揭示了协方差基方法在非平稳系统中的根本局限。

Conclusion: 本研究将关注点从因果结构是否可识别，转向其在实践中是否可统计恢复，为现实非平稳系统中的因果推断提供了理论基础与界限。

Abstract: Recovering a unique causal graph from observational data is an ill-posed problem because multiple generating mechanisms can lead to the same observational distribution. This problem becomes solvable only by exploiting specific structural or distributional assumptions. While recent work has separately utilized time-series dynamics or multi-environment heterogeneity to constrain this problem, we integrate both as complementary sources of heterogeneity. This integration yields unified necessary identifiability conditions and enables a rigorous analysis of the statistical limits of recovery under thin versus heavy-tailed noise. In particular, temporal structure is shown to effectively substitute for missing environmental diversity, possibly achieving identifiability even under insufficient heterogeneity. Extending this analysis to heavy-tailed (Student's t) distributions, we demonstrate that while geometric identifiability conditions remain invariant, the sample complexity diverges significantly from the Gaussian baseline. Explicit information-theoretic bounds quantify this cost of robustness, establishing the fundamental limits of covariance-based causal graph recovery methods in realistic non-stationary systems. This work shifts the focus from whether causal structure is identifiable to whether it is statistically recoverable in practice.

</details>


### [180] [Parameter-free Dynamic Regret: Time-varying Movement Costs, Delayed Feedback, and Memory](https://arxiv.org/abs/2602.06902)
*Emmanuel Esposito,Andrew Jacobsen,Hao Qiu,Mengxiao Zhang*

Main category: cs.LG

TL;DR: 本文研究了带有移动成本的无约束在线凸优化（OCO）中的动态后悔问题，提出了一种新算法，建立了首个针对时变移动成本系数的比较自适应动态后悔界，实现了$\widetilde{\mathcal{O}}(\sqrt{(1+P_T)(T+\sum_t λ_t)})$的后悔上界。该结果在$λ_t=0$时退化为标准OCO的最优静态与动态后悔界。通过将延迟反馈和时变记忆的OCO问题转化为时变移动成本问题，展示了方法的广泛应用性，且首次提出了延迟反馈的独立兴趣的归约方法。关键发现是后悔界中对移动成本的一阶依赖，是实现最优比较自适应动态后悔的关键。


<details>
  <summary>Details</summary>
Motivation: 传统在线凸优化中动态后悔分析通常假设固定移动成本，但实际应用中成本系数可能随时间变化。现有方法难以处理时变移动成本下的比较自适应动态后悔，因此需要新的理论框架和算法设计。

Method: 提出一种新型算法，通过引入时变移动成本系数$λ_t$，结合路径长度$P_T$和总成本$\sum_t λ_t$，构造一个统一的后悔上界分析框架，并利用一阶依赖结构实现最优比较自适应性能。

Result: $\\widetilde{\\mathcal{O}}(\\sqrt{(1+P_T)(T+\\sum_t \\lambda_t)})$的比较自适应动态后悔上界，适用于任意时变$\\lambda_t$；在$\\lambda_t=0$时恢复标准静态与动态后悔最优性；成功应用于延迟反馈与时变记忆场景，揭示新归约机制。

Conclusion: 本文提出的算法和分析框架首次实现了时变移动成本下最优的比较自适应动态后悔保证，其关键在于对移动成本的一阶依赖结构，具有广泛的应用潜力和理论价值。

Abstract: In this paper, we study dynamic regret in unconstrained online convex optimization (OCO) with movement costs. Specifically, we generalize the standard setting by allowing the movement cost coefficients $λ_t$ to vary arbitrarily over time. Our main contribution is a novel algorithm that establishes the first comparator-adaptive dynamic regret bound for this setting, guaranteeing $\widetilde{\mathcal{O}}(\sqrt{(1+P_T)(T+\sum_t λ_t)})$ regret, where $P_T$ is the path length of the comparator sequence over $T$ rounds. This recovers the optimal guarantees for both static and dynamic regret in standard OCO as a special case where $λ_t=0$ for all rounds. To demonstrate the versatility of our results, we consider two applications: OCO with delayed feedback and OCO with time-varying memory. We show that both problems can be translated into time-varying movement costs, establishing a novel reduction specifically for the delayed feedback setting that is of independent interest. A crucial observation is that the first-order dependence on movement costs in our regret bound plays a key role in enabling optimal comparator-adaptive dynamic regret guarantees in both settings.

</details>


### [181] [Revisiting the Generic Transformer: Deconstructing a Strong Baseline for Time Series Foundation Models](https://arxiv.org/abs/2602.06909)
*Yunshi Wen,Wesley M. Gifford,Chandra Reddy,Lam M. Nguyen,Jayant Kalagnanam,Anak Agung Julius*

Main category: cs.LG

TL;DR: 本文研究了标准patch Transformer在时间序列预测中的表现，发现其在简单的训练协议下即可实现最先进的零样本预测性能。通过全面的消融实验，识别出性能提升的关键因素，并验证了该通用架构的良好可扩展性。研究控制变量，提供了多维度模型扩展的实证结果，并开源模型与详细数据，以建立透明、可复现的研究基准。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型的研究中，训练设置差异大，难以区分性能提升是来自架构创新还是数据工程。本文旨在通过标准化实验设置，明确高性能的关键因素。

Method: 采用标准patch Transformer架构，进行系统性的消融实验，涵盖模型缩放、数据组成和训练技术，严格控制变量以分析各因素对性能的影响。

Result: 发现通用架构本身具有优异的可扩展性，关键性能驱动因素被识别，且在零样本预测任务中达到领先水平。

Conclusion: 通过控制变量的实证研究，证明了标准patch Transformer在时间序列预测中的强大潜力，为未来研究提供了可复现的基准。

Abstract: The recent surge in Time Series Foundation Models has rapidly advanced the field, yet the heterogeneous training setups across studies make it difficult to attribute improvements to architectural innovations versus data engineering. In this work, we investigate the potential of a standard patch Transformer, demonstrating that this generic architecture achieves state-of-the-art zero-shot forecasting performance using a straightforward training protocol. We conduct a comprehensive ablation study that covers model scaling, data composition, and training techniques to isolate the essential ingredients for high performance. Our findings identify the key drivers of performance, while confirming that the generic architecture itself demonstrates excellent scalability. By strictly controlling these variables, we provide comprehensive empirical results on model scaling across multiple dimensions. We release our open-source model and detailed findings to establish a transparent, reproducible baseline for future research.

</details>


### [182] [Continuous-time reinforcement learning: ellipticity enables model-free value function approximation](https://arxiv.org/abs/2602.06930)
*Wenlong Mou*

Main category: cs.LG

TL;DR: 本文研究连续时间马尔可夫扩散过程的离策略强化学习，基于离散时间观测与动作，提出无需对动力学结构做不切实际假设的模型无关算法。通过扩散过程的椭圆性，建立了贝尔曼算子的新一类希尔伯特空间正定性和有界性性质，并提出基于Sobolev-近端拟合的Q学习算法，通过迭代求解最小二乘回归问题来学习价值和优势函数。理论分析给出了估计误差的“预言不等式”，由四部分构成：(i) 函数类的最佳逼近误差，(ii) 局部复杂度，(iii) 指数衰减的优化误差，(iv) 数值离散化误差。结果表明，椭圆性是使带函数逼近的强化学习在马尔可夫扩散中不比监督学习更难的关键结构属性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在连续时间马尔可夫扩散过程中面临挑战，尤其在缺乏动力学结构假设的情况下，难以实现有效的函数逼近与学习。本文旨在解决离策略学习中模型无关、函数逼近下的理论保障问题，突破传统方法对系统结构的强假设限制。

Method: 利用扩散过程的椭圆性，构建贝尔曼算子在希尔伯特空间中的正定性与有界性性质；提出Sobolev-近端拟合的Q学习算法，通过迭代最小二乘回归学习价值和优势函数；结合函数类的逼近能力、局部复杂度、优化误差与离散化误差进行理论分析。

Result: 建立了贝尔曼算子的新正定性与有界性性质；提出了具有理论保证的Sobolev-近端拟合Q学习算法；推导出包含最佳逼近误差、局部复杂度、指数衰减优化误差和数值离散化误差的预言不等式；揭示椭圆性是使该类强化学习问题复杂度等价于监督学习的关键因素。

Conclusion: 椭圆性是连续时间马尔可夫扩散过程中强化学习与函数逼近可有效实施的核心结构条件。本文提出的算法与理论框架证明，在合理条件下，此类问题的复杂度并不高于监督学习，为离策略强化学习提供了坚实的理论基础。

Abstract: We study off-policy reinforcement learning for controlling continuous-time Markov diffusion processes with discrete-time observations and actions. We consider model-free algorithms with function approximation that learn value and advantage functions directly from data, without unrealistic structural assumptions on the dynamics.
  Leveraging the ellipticity of the diffusions, we establish a new class of Hilbert-space positive definiteness and boundedness properties for the Bellman operators. Based on these properties, we propose the Sobolev-prox fitted $q$-learning algorithm, which learns value and advantage functions by iteratively solving least-squares regression problems. We derive oracle inequalities for the estimation error, governed by (i) the best approximation error of the function classes, (ii) their localized complexity, (iii) exponentially decaying optimization error, and (iv) numerical discretization error. These results identify ellipticity as a key structural property that renders reinforcement learning with function approximation for Markov diffusions no harder than supervised learning.

</details>


### [183] [When RL Meets Adaptive Speculative Training: A Unified Training-Serving System](https://arxiv.org/abs/2602.06932)
*Junxiong Wang,Fengxiang Bie,Jisen Li,Zhongzhu Zhou,Zelei Shao,Yubo Wang,Yinghui Liu,Qingyang Wu,Avner May,Sri Yanamandra,Yineng Zhang,Ce Zhang,Tri Dao,Percy Liang,Ben Athiwaratkun,Shuaiwen Leon Song,Chenfeng Xu,Xiaoxia Wu*

Main category: cs.LG

TL;DR: Aurora 是一个统一的训练-服务系统，通过从实时推理轨迹中持续学习来解决传统推测解码中训练与部署脱节的问题。它将在线学习建模为异步强化学习问题，利用接受/拒绝的令牌提供正负反馈，实现高效样本学习，并支持无中断热更新。Aurora 支持当天部署，可立即加速推理并快速适应用户流量变化，在前沿模型上实现1.5倍的初始加速，并在分布漂移场景下比静态推测器再提升1.25倍性能。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码系统将推测器训练与服务分离，导致高延迟上线、无法及时获取真实加速反馈以及因领域漂移导致推测器失效等问题。

Method: 将在线推测器学习建模为异步强化学习问题，利用接受令牌作为正反馈，拒绝提议作为隐式负反馈；结合SGLang推理服务器与异步训练服务器，实现无需中断的服务更新和快速适应。

Result: 在前沿模型（如MiniMax M2.1 229B、Qwen3-Coder-Next 80B）上实现1.5倍的天内加速；在分布漂移场景下，相比静态推测器额外获得1.25倍性能提升。

Conclusion: Aurora 通过闭环学习机制实现了推测器的即时部署与持续优化，显著缩短了时间到服务周期，提升了系统适应性与实际性能，是面向高效大模型服务的重要突破。

Abstract: Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before deployment; (2) delayed utility feedback, since the true end-to-end decoding speedup is only known after training and cannot be inferred reliably from acceptance rate alone due to model-architecture and system-level overheads; and (3) domain-drift degradation, as the target model is repurposed to new domains and the speculator becomes stale and less effective.
  To address these issues, we present Aurora, a unified training-serving system that closes the loop by continuously learning a speculator directly from live inference traces. Aurora reframes online speculator learning as an asynchronous reinforcement-learning problem: accepted tokens provide positive feedback, while rejected speculator proposals provide implicit negative feedback that we exploit to improve sample efficiency. Our design integrates an SGLang-based inference server with an asynchronous training server, enabling hot-swapped speculator updates without service interruption. Crucially, Aurora supports day-0 deployment: a speculator can be served immediately and rapidly adapted to live traffic, improving system performance while providing immediate utility feedback. Across experiments, Aurora achieves a 1.5x day-0 speedup on recently released frontier models (e.g., MiniMax M2.1 229B and Qwen3-Coder-Next 80B). Aurora also adapts effectively to distribution shifts in user traffic, delivering an additional 1.25x speedup over a well-trained but static speculator on widely used models (e.g., Qwen3 and Llama3).

</details>


### [184] [From Core to Detail: Unsupervised Disentanglement with Entropy-Ordered Flows](https://arxiv.org/abs/2602.06940)
*Daniel Galperin,Ullrich Köthe*

Main category: cs.LG

TL;DR: 提出了一种名为熵序流（EOFlows）的归一化流框架，通过按解释熵对潜在维度进行排序，实现可适应的注入式流。该方法在训练后可灵活选择保留前C个潜在变量以形成紧凑的核心表示，其余变量捕捉细节和噪声，支持推理时灵活调整压缩率。结合基于似然的训练、局部雅可比正则化和噪声增强，适用于高维数据如图像。在CelebA数据集上的实验表明，该方法能发现丰富的语义可解释特征，实现高压缩和强去噪能力。


<details>
  <summary>Details</summary>
Motivation: 现有无监督表征学习中，如何同时获得语义有意义且跨运行稳定的表征仍是挑战。传统方法通常固定压缩率，缺乏灵活性，难以兼顾核心语义与细节信息的分离。因此需要一种能够动态调节压缩程度并保持表征稳定性的新方法。

Method: 提出熵序流（EOFlows），利用潜在维度按解释熵排序的思想，类比于主成分分析中的方差解释顺序。采用基于似然的训练策略，结合局部雅可比正则化和噪声增强，提升模型稳定性与泛化性。训练完成后，可按需选择前C个主要潜变量作为核心表示，其余变量用于捕捉细节与噪声。

Result: 在CelebA数据集上，EOFlows成功揭示了多个语义可解释特征，实现了显著的数据压缩效果，并展现出强大的去噪能力。同时，其表征在不同运行间具有良好的稳定性，且支持推理阶段灵活调整压缩率。

Conclusion: EOFlows通过熵序机制实现了语义清晰、可灵活压缩的无监督表征学习，为高维数据的高效表示提供了新范式，兼具可解释性、稳定性和实用性。

Abstract: Learning unsupervised representations that are both semantically meaningful and stable across runs remains a central challenge in modern representation learning. We introduce entropy-ordered flows (EOFlows), a normalizing-flow framework that orders latent dimensions by their explained entropy, analogously to PCA's explained variance. This ordering enables adaptive injective flows: after training, one may retain only the top C latent variables to form a compact core representation while the remaining variables capture fine-grained detail and noise, with C chosen flexibly at inference time rather than fixed during training. EOFlows build on insights from Independent Mechanism Analysis, Principal Component Flows and Manifold Entropic Metrics. We combine likelihood-based training with local Jacobian regularization and noise augmentation into a method that scales well to high-dimensional data such as images. Experiments on the CelebA dataset show that our method uncovers a rich set of semantically interpretable features, allowing for high compression and strong denoising.

</details>


### [185] [Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine](https://arxiv.org/abs/2602.06955)
*Reza E. Fazel,Arash Bakhtiary,Siavash A. Bigdeli*

Main category: cs.LG

TL;DR: 该研究提出一种基于可解释增强机器（EBM）的优化工作流，通过系统性超参数调优、特征选择和预处理优化，有效解决信用卡欺诈检测中的类别不平衡问题。采用田口方法优化数据缩放器序列与模型超参数，提升模型鲁棒性与可复现性。实验表明，该方法在基准信用卡数据集上达到0.983的ROC-AUC，优于EBM基线（0.975）及Logistic Regression、Random Forest、XGBoost和决策树等模型，兼具高精度与可解释性，推动可信金融欺诈分析的发展。


<details>
  <summary>Details</summary>
Motivation: 信用卡欺诈检测面临严重的类别不平衡问题，传统采样技术易引入偏差或导致信息丢失，影响预测可靠性。因此亟需一种既能保持高准确率又能提供可解释性的解决方案，以提升金融系统中欺诈检测的可信度与实用性。

Method: 采用可解释增强机器（EBM）作为核心模型，结合系统性超参数调优、特征选择与预处理优化；运用田口方法对数据缩放顺序与模型超参数进行联合优化，实现性能的系统性提升与可复现验证。

Result: 在公开基准信用卡数据集上，所提方法获得0.983的ROC-AUC，显著优于EBM基线（0.975）以及Logistic Regression、Random Forest、XGBoost和决策树等主流模型，同时保持了良好的可解释性，能够清晰揭示特征重要性与交互效应。

Conclusion: 本研究证明了可解释机器学习与数据驱动优化相结合在信用卡欺诈检测中的有效性，为构建高精度、高可信度的金融欺诈分析系统提供了可行路径。

Abstract: Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature selection, and preprocessing refinement. Rather than relying on conventional sampling techniques that may introduce bias or cause information loss, the optimized EBM achieves an effective balance between accuracy and interpretability, enabling precise detection of fraudulent transactions while providing actionable insights into feature importance and interaction effects. Furthermore, the Taguchi method is employed to optimize both the sequence of data scalers and model hyperparameters, ensuring robust, reproducible, and systematically validated performance improvements. Experimental evaluation on benchmark credit card data yields an ROC-AUC of 0.983, surpassing prior EBM baselines (0.975) and outperforming Logistic Regression, Random Forest, XGBoost, and Decision Tree models. These results highlight the potential of interpretable machine learning and data-driven optimization for advancing trustworthy fraud analytics in financial systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [186] [Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning](https://arxiv.org/abs/2602.06107)
*Zhuoming Chen,Hongyi Liu,Yang Zhou,Haizhong Zheng,Beidi Chen*

Main category: cs.AI

TL;DR: Jackpot提出一种基于最优预算拒绝采样（OBRS）的框架，通过减少滚动模型与策略之间的分布差异，实现大语言模型强化学习中生成与优化的解耦，显著提升训练稳定性与效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的强化学习因滚动生成成本高而效率低下，尽管解耦滚动生成与策略优化可提高效率，但会引入严重的分布不匹配问题，导致学习不稳定。

Method: 采用最优预算拒绝采样（OBRS）降低分布差异，结合统一训练目标联合更新策略与滚动模型，并利用top-k概率估计和批量偏差校正实现高效系统实现。

Result: 理论分析表明OBRS能有效缩小分布差距；实验显示该方法在稳定性上优于基于重要性采样的基线，在300步更新、批量大小为64的情况下性能接近于在线策略强化学习，验证了其有效性。

Conclusion: OBRS驱动的对齐使大语言模型强化学习中滚动生成与策略优化的解耦更趋实用和高效。

Abstract: Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to directly reduce the discrepancy between the rollout model and the evolving policy. Jackpot integrates a principled OBRS procedure, a unified training objective that jointly updates the policy and rollout models, and an efficient system implementation enabled by top-$k$ probability estimation and batch-level bias correction. Our theoretical analysis shows that OBRS consistently moves the rollout distribution closer to the target distribution under a controllable acceptance budget. Empirically, \sys substantially improves training stability compared to importance-sampling baselines, achieving performance comparable to on-policy RL when training Qwen3-8B-Base for up to 300 update steps of batchsize 64. Taken together, our results show that OBRS-based alignment brings us a step closer to practical and effective decoupling of rollout generation from policy optimization for RL for LLMs.

</details>


### [187] [Large Language Model Reasoning Failures](https://arxiv.org/abs/2602.06176)
*Peiyang Song,Pengrui Han,Noah Goodman*

Main category: cs.AI

TL;DR: 本论文首次系统性地调查了大语言模型（LLM）中的推理失败问题，提出了一个新颖的分类框架，将推理分为具身与非具身两类，其中非具身推理进一步分为非正式（直觉式）和正式（逻辑式）推理。同时，将推理失败划分为三类：源于模型架构的根本性缺陷、特定应用领域的局限性以及鲁棒性问题。针对每类失败，论文提供了定义、现有研究分析、根本原因探讨及缓解策略，并整合零散的研究工作，为未来构建更强大、可靠、稳健的推理能力提供指导。此外，作者还发布了一个包含相关研究工作的GitHub仓库，便于该领域研究者入门。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理方面取得了显著进展，但仍存在大量推理失败，尤其在看似简单的场景中也频繁发生。为了系统理解并解决这些问题，亟需一个全面的调查与分类框架，以揭示其根本原因并推动后续研究。

Method: 提出一个双轴分类框架：一是按推理类型区分具身与非具身，非具身再分非正式与正式；二是按失败类型分为根本性缺陷、应用特定局限性和鲁棒性问题。结合文献分析，对每类失败进行定义、成因剖析与应对策略总结。

Result: 构建了首个系统性的大语言模型推理失败分类体系，整合了分散的研究成果，明确了各类推理失败的特征与根源，并提出有效的缓解策略。同时发布了开源资源库，助力该领域研究发展。

Conclusion: 本研究为理解大语言模型推理的系统性弱点提供了结构化视角，不仅揭示了当前技术瓶颈，也为未来提升模型推理能力指明了方向，具有重要的理论价值与实践意义。

Abstract: Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distinguishes reasoning into embodied and non-embodied types, with the latter further subdivided into informal (intuitive) and formal (logical) reasoning. In parallel, we classify reasoning failures along a complementary axis into three types: fundamental failures intrinsic to LLM architectures that broadly affect downstream tasks; application-specific limitations that manifest in particular domains; and robustness issues characterized by inconsistent performance across minor variations. For each reasoning failure, we provide a clear definition, analyze existing studies, explore root causes, and present mitigation strategies. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities. We additionally release a comprehensive collection of research works on LLM reasoning failures, as a GitHub repository at https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures, to provide an easy entry point to this area.

</details>


### [188] [Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)](https://arxiv.org/abs/2602.06227)
*Pierriccardo Olivieri,Fausto Lasca,Alessandro Gianola,Matteo Papini*

Main category: cs.AI

TL;DR: 本文提出了一种在大规模状态空间的马尔可夫决策过程（MDP）中，以逻辑形式规范非马尔可夫奖励的新框架。该方法利用有限迹线上的线性时序逻辑模理论（LTLfMT），通过一阶逻辑公式表达复杂任务，避免了手动编码谓词，提升了可重用性与统一性。针对其带来的理论与计算挑战，研究识别出一个在无限状态空间下既可处理又足够表达的LTLfMT片段，并结合奖励机器与事后经验回放（HER）方法解决奖励稀疏问题。实验在连续控制任务中使用非线性算术理论验证了该方法的有效性，结果表明定制化的HER实现对完成复杂目标至关重要。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂任务中难以有效建模非马尔可夫奖励，且依赖手动设计谓词，缺乏通用性和可扩展性；现有逻辑形式化工具表达能力有限，无法自然描述异构数据中的复杂任务。因此需要一种更强大、灵活且自动化的奖励建模方式。

Method: 采用LTLfMT作为逻辑表达语言，定义可处理的子集以保证计算可行性；结合奖励机器将逻辑规格转化为奖励函数；引入定制化的Hindsight Experience Replay（HER）机制以缓解奖励稀疏问题，并在非线性算术理论支持下实现连续控制任务的训练。

Result: 实验表明，所提方法能够自然地表达复杂任务，在连续控制环境中成功求解具有高难度目标的问题；相较于标准方法，基于定制HER的版本显著提升学习效率和成功率。

Conclusion: 该框架通过融合高阶逻辑表达与强化学习技术，实现了对复杂、非马尔可夫奖励的高效建模与学习，为大规模状态空间下的复杂任务提供了一个通用、可扩展的解决方案。

Abstract: In this work, we propose a novel framework for the logical specification of non-Markovian rewards in Markov Decision Processes (MDPs) with large state spaces. Our approach leverages Linear Temporal Logic Modulo Theories over finite traces (LTLfMT), a more expressive extension of classical temporal logic in which predicates are first-order formulas of arbitrary first-order theories rather than simple Boolean variables. This enhanced expressiveness enables the specification of complex tasks over unstructured and heterogeneous data domains, promoting a unified and reusable framework that eliminates the need for manual predicate encoding. However, the increased expressive power of LTLfMT introduces additional theoretical and computational challenges compared to standard LTLf specifications. We address these challenges from a theoretical standpoint, identifying a fragment of LTLfMT that is tractable but sufficiently expressive for reward specification in an infinite-state-space context. From a practical perspective, we introduce a method based on reward machines and Hindsight Experience Replay (HER) to translate first-order logic specifications and address reward sparsity. We evaluate this approach to a continuous-control setting using Non-Linear Arithmetic Theory, showing that it enables natural specification of complex tasks. Experimental results show how a tailored implementation of HER is fundamental in solving tasks with complex goals.

</details>


### [189] [Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems](https://arxiv.org/abs/2602.06319)
*Qifan Zhang,Jianhao Ruan,Aochuan Chen,Kang Zeng,Nuo Chen,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: GrAlgoBench 是一个针对大推理模型（LRMs）设计的图算法基准测试，旨在评估其在长上下文、复杂推理和可程序化验证方面的表现。该基准涵盖九个任务，揭示了当前LRMs在长文本处理中的显著性能下降（节点超过120时准确率低于50%），以及因过度自我验证导致的“过度思考”现象，即推理过程冗长但无效。该研究为推动大模型推理能力的研究提供了严谨、多维度且实用的测试平台。


<details>
  <summary>Details</summary>
Motivation: 现有数学、代码和常识推理基准在长上下文评估、挑战性及可程序化验证方面存在不足，无法充分检验大推理模型的真实推理能力。因此需要一个更严格、可控且可自动评估的测试框架，图算法问题因其具备长上下文需求、可调难度和标准化评估优势，成为理想选择。

Method: 构建GrAlgoBench基准，包含九类图算法任务，覆盖不同复杂度与上下文长度；通过系统实验分析主流大模型在不同条件下的表现，量化其准确性、推理效率与错误类型，并利用程序化验证机制对结果进行客观评估。

Result: 实验表明，当图规模超过120节点时，模型准确率骤降至50%以下，主要归因于执行错误、记忆能力弱和冗余推理；同时发现模型普遍存在‘过度思考’现象，即大量无效自验证导致推理轨迹膨胀而无益于正确性提升。

Conclusion: GrAlgoBench成功揭示了当前大推理模型在长上下文推理与高效推理策略上的核心缺陷，证明图算法问题是一个强大、可扩展且具有实际意义的评估工具，有助于未来推动推理模型的改进与研究。

Abstract: Large Reasoning Models (LRMs) have advanced rapidly; however, existing benchmarks in mathematics, code, and common-sense reasoning remain limited. They lack long-context evaluation, offer insufficient challenge, and provide answers that are difficult to verify programmatically. We introduce GrAlgoBench, a benchmark designed to evaluate LRMs through graph algorithm problems. Such problems are particularly well suited for probing reasoning abilities: they demand long-context reasoning, allow fine-grained control of difficulty levels, and enable standardized, programmatic evaluation. Across nine tasks, our systematic experiments reveal two major weaknesses of current LRMs. First, accuracy deteriorates sharply as context length increases, falling below 50% once graphs exceed 120 nodes. This degradation is driven by frequent execution errors, weak memory, and redundant reasoning. Second, LRMs suffer from an over-thinking phenomenon, primarily caused by extensive yet largely ineffective self-verification, which inflates reasoning traces without improving correctness. By exposing these limitations, GrAlgoBench establishes graph algorithm problems as a rigorous, multidimensional, and practically relevant testbed for advancing the study of reasoning in LRMs. Code is available at https://github.com/Bklight999/GrAlgoBench.

</details>


### [190] [Difficulty-Estimated Policy Optimization](https://arxiv.org/abs/2602.06375)
*Yu Zhao,Fan Jiang,Tianle Liu,Bo Zeng,Yu Liu,Longyue Wang,Weihua Luo*

Main category: cs.AI

TL;DR: 提出DEPO框架，通过在线难度估计动态筛选训练数据，减少低效采样带来的计算开销，在不降低模型性能的前提下实现高达2倍的采样成本降低，提升推理对齐的效率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: GRPO在处理过于简单或复杂的任务时易出现梯度信号衰减，导致收敛不稳定；现有改进方法如DAPO虽缓解梯度消失但带来高计算开销，亟需更高效的优化策略。

Method: 设计DEPO框架，引入在线难度估计器，在采样前动态评估并过滤低学习价值样本，使计算资源聚焦于高潜力样本，从而优化推理对齐过程。

Result: 实验表明DEPO可实现最高2倍的采样成本降低，同时保持模型性能，显著降低高性能推理模型训练的计算门槛。

Conclusion: DEPO通过智能数据筛选机制，实现了推理对齐中效率与稳定性的平衡，为大规模推理模型的可持续扩展提供了有效路径。

Abstract: Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are either too trivial or overly complex. In these scenarios, the disappearance of inter-group advantages makes the gradient signal susceptible to noise, thereby jeopardizing convergence stability. While variants like DAPO attempt to rectify gradient vanishing, they do not alleviate the substantial computational overhead incurred by exhaustive rollouts on low-utility samples. In this paper, we propose Difficulty-Estimated Policy Optimization (DEPO), a novel framework designed to optimize the efficiency and robustness of reasoning alignment. DEPO integrates an online Difficulty Estimator that dynamically assesses and filters training data before the rollout phase. This mechanism ensures that computational resources are prioritized for samples with high learning potential. Empirical results demonstrate that DEPO achieves up to a 2x reduction in rollout costs without compromising model performance. Our approach significantly lowers the computational barrier for training high-performance reasoning models, offering a more sustainable path for reasoning scaling. Code and data will be released upon acceptance.

</details>


### [191] [Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization](https://arxiv.org/abs/2602.06394)
*Arvid E. Gollwitzer,Paridhi Latawa,David de Gruijl,Deepak A. Subramanian,Adrián Noriega de la Colina*

Main category: cs.AI

TL;DR: 提出QA-Token，一种将数据可靠性融入词汇构建的质量感知分词方法，通过双层优化、基于质量奖励的强化学习和Gumbel-Softmax松弛实现端到端优化，在基因组学和金融领域显著提升性能，同时减少15%的标记数量，适用于大规模噪声真实数据集。


<details>
  <summary>Details</summary>
Motivation: 现有分词方法未考虑信号质量，难以有效处理噪声真实世界语料，因此需要引入数据可靠性以提升分词效果。

Method: 采用双层优化框架联合优化词汇构建与下游任务表现，利用强化学习学习融合质量感知奖励的合并策略，并通过Gumbel-Softmax松弛实现参数自适应学习，支持端到端优化。

Result: 在基因组学中相比BPE提升6.7个百分点的F1值，在金融领域提升30%的夏普比率；在1.7万亿碱基对的预训练语料上实现94.53的MCC得分，标记数减少15%，且无推理开销。

Conclusion: QA-Token成功将噪声真实世界数据（如基因组序列和金融时间序列）纳入基础模型训练，显著提升性能并降低计算成本，为大规模低质量数据的高效利用提供了新范式。

Abstract: Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization. Our experimental evaluation demonstrates consistent improvements: genomics (6.7 percentage point F1 gain in variant calling over BPE), finance (30% Sharpe ratio improvement). At foundation scale, we tokenize a pretraining corpus comprising 1.7 trillion base-pairs and achieve state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. We unlock noisy real-world corpora, spanning petabases of genomic sequences and terabytes of financial time series, for foundation model training with zero inference overhead.

</details>


### [192] [Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution](https://arxiv.org/abs/2602.06413)
*Hsien-Jyh Liao*

Main category: cs.AI

TL;DR: 本文指出大语言模型在长时程任务中性能下降的根本原因并非仅由任务复杂性导致，而是源于自回归生成过程的内在不稳定性。作者提出一个定理，证明单路径自回归推理中的决策优势随执行长度呈指数衰减，从而确立了推理链维持的结构性限制。研究建议，实现稳定长时程推理需采用离散分割，形成类似有向无环图（DAG）的结构化执行方式。实证结果在合成环境和TextWorld任务中均验证了理论预测的性能断崖现象，揭示了当前评估范式可能掩盖结构不稳定性的问题，提示未来推理系统应从单纯扩展转向结构治理。


<details>
  <summary>Details</summary>
Motivation: 现有解释将长时程推理失败归因于任务复杂性（如组合爆炸或长期信用分配困难），但作者发现即使在无语义歧义、线性且无分支的任务中，自回归生成仍存在固有稳定性极限，因此需要重新审视其根本成因。

Method: 通过理论推导建立定理A，分析自回归推理中决策优势随长度的衰减规律；结合合成环境与真实文本世界（TextWorld）任务进行实证研究，验证理论预测的性能断崖现象；从动态系统角度解析长时程推理失败机制，并提出结构化治理的新范式。

Result: 理论证明决策优势在单路径自回归推理中随执行长度呈指数衰减，实证显示性能在特定长度出现明显断崖；表明纯自回归架构难以维持长时程连贯性，必须引入结构化分割机制以实现稳定推理。

Conclusion: 长时程推理的瓶颈本质上是自回归过程的结构性不稳定性所致，而非任务复杂度。未来推理系统的发展不应仅依赖规模扩展，而需转向基于图结构（如DAG）的分段式结构治理，以保障长期推理的稳定性与一致性。

Abstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities, yet their performance often deteriorates sharply in long-horizon tasks, exhibiting systematic breakdown beyond certain scales. Conventional explanations primarily attribute this phenomenon to task complexity, such as combinatorial search explosion or long-term credit assignment challenges. In this work, we argue that these explanations are incomplete: even in linear, unbranched tasks without semantic ambiguity, autoregressive execution is subject to an intrinsic stability limit.
  We propose that the fundamental constraint on long-horizon reasoning arises from process-level instability in autoregressive generation rather than solely from search or task complexity, reframing long-horizon reasoning as a problem of structural governance. We derive Theorem~A, showing that decision advantage in single-path autoregressive reasoning decays exponentially with execution length, imposing a fundamental bound on maintainable reasoning chains. This result implies a structural consequence: stable long-horizon reasoning requires discrete segmentation, naturally inducing graph-like execution structures such as directed acyclic graphs (DAGs).
  Empirical studies in both synthetic environments and real TextWorld tasks reveal observable performance cliffs consistent with theoretical predictions. Our findings provide a dynamical perspective on long-horizon reasoning failure and suggest new limitations on maintaining long-term coherence under purely autoregressive architectures. Furthermore, we highlight that short-horizon evaluation protocols may obscure structural instability, indicating a potential shift from scaling toward structured governance in future reasoning systems.

</details>


### [193] [HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction](https://arxiv.org/abs/2602.06527)
*Shengxuan Qiu,Haochen Huang,Shuzhang Zhong,Pengfei Zuo,Meng Li*

Main category: cs.AI

TL;DR: HyPER提出一种无需训练的在线控制策略，用于混合专家模型中的多路径解码，通过动态调整探索与利用的平衡，在固定计算预算下优化推理准确率。该方法结合轻量级路径统计信息，实现高效的生成时利用和可靠的答案聚合，显著提升准确率并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法在探索与利用之间采取僵化策略：树状搜索依赖脆弱的扩展规则，干扰预训练推理；并行推理过度冗余，且答案选择能力弱。观察到最优平衡随阶段变化，且正确与错误路径常在后期才分化，因此将测试时扩展建模为动态的展开-缩减控制问题。

Method: HyPER包含一个在线控制器，根据假设池演化从探索转向利用；一个基于标记级别的精炼机制，实现生成时高效利用而无需完整路径重采样；以及一个长度与置信度感知的聚合策略，用于可靠的答案利用。

Result: 在四个混合专家语言模型上对多种推理基准的实验表明，HyPER在保持或降低计算成本的同时，准确率提升8至10个百分点，同时减少25%至40%的令牌使用量。

Conclusion: HyPER通过动态调节探索与利用，实现了更优的准确率-计算权衡，是一种高效、训练自由的多路径推理框架，适用于大规模语言模型的测试时扩展。

Abstract: Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansion rules that interfere with post-trained reasoning, while parallel reasoning over-explores redundant hypothesis paths and relies on weak answer selection. Motivated by the observation that the optimal balance is phase-dependent and that correct and incorrect reasoning paths often diverge only at late stages, we reformulate test-time scaling as a dynamic expand-reduce control problem over a pool of hypotheses. We propose HyPER, a training-free online control policy for multi-path decoding in mixture-of-experts models that reallocates computation under a fixed budget using lightweight path statistics. HyPER consists of an online controller that transitions from exploration to exploitation as the hypothesis pool evolves, a token-level refinement mechanism that enables efficient generation-time exploitation without full-path resampling, and a length- and confidence-aware aggregation strategy for reliable answer-time exploitation. Experiments on four mixture-of-experts language models across diverse reasoning benchmarks show that HyPER consistently achieves a superior accuracy-compute trade-off, improving accuracy by 8 to 10 percent while reducing token usage by 25 to 40 percent.

</details>


### [194] [SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees](https://arxiv.org/abs/2602.06554)
*Tianyi Hu,Qingxu Fu,Yanxi Chen,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: 本文提出SeeUPO，一种用于多轮交互的无评判器、具收敛保证的策略优化方法。通过将多轮交互建模为顺序执行的多智能体赌博机问题，并采用逆向执行顺序的逐轮策略更新，实现单调改进与全局最优收敛。实验表明，SeeUPO在AppWorld和BFCL v4上相比现有算法有显著提升，相对增益达24.1%-54.6%，且训练更稳定。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的大型语言模型智能体缺乏在多轮场景下的验证收敛性保证，导致训练不稳定甚至无法收敛，亟需一种兼具收敛性与高效性的新算法。

Method: 将多轮交互视为顺序执行的多智能体赌博机问题，采用逆向执行顺序进行逐轮策略更新，利用后向归纳法确保单调改进并收敛至全局最优解。

Result: SeeUPO在多个基准测试中表现出显著优于现有方法的性能，相对增益达24.1%-54.6%，同时具备更强的训练稳定性，且实现了无评判器与收敛性的统一。

Conclusion: 本文证明了主流强化学习算法难以在多轮场景中同时满足无评判器与收敛性要求，而提出的SeeUPO方法成功解决了这一难题，为大语言模型智能体的可靠训练提供了理论与实践基础。

Abstract: Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.
  In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.
  To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.
  Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.

</details>


### [195] [Same Answer, Different Representations: Hidden instability in VLMs](https://arxiv.org/abs/2602.06652)
*Farooq Ahmad Wani,Alessandro Suglia,Rohit Saxena,Aryo Pradipta Gema,Wai-Chung Kwan,Fazl Barez,Maria Sofia Bucarelli,Fabrizio Silvestri,Pasquale Minervini*

Main category: cs.AI

TL;DR: 本文提出一种新的评估框架，关注视觉语言模型（VLMs）的内部表示漂移、频谱敏感性和结构平滑性，揭示了现有输出级不变性评估的局限性。实验证明，模型在输出稳定的同时内部表示可能发生剧烈变化，且模型规模增大并未提升鲁棒性，反而可能使决策边界更脆弱。此外，不同扰动对推理与幻觉任务的影响各异。


<details>
  <summary>Details</summary>
Motivation: 现有VLM鲁棒性评估依赖输出层面的不变性，但该假设忽略了内部表示的潜在不稳定性，可能导致对模型真实性能的误判。

Method: 提出一个结合表示感知和频率感知的评估框架，测量内部嵌入漂移、谱敏感性及结构平滑性，并在SEEDBench、MMMU和POPE数据集上进行验证。

Result: 发现三种失败模式：1）输出稳定但内部表示剧烈漂移；2）模型规模扩大未提升鲁棒性，反而加剧敏感性；3）扰动对推理与幻觉任务影响不同，可能抑制虚假生成。

Conclusion: 仅依赖输出不变性评估VLM鲁棒性是不充分的，必须引入对内部表示动态的多维度分析，以更真实地反映模型的稳健性。

Abstract: The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions reflect stable multimodal processing. In this work, we argue that this assumption is insufficient. We introduce a representation-aware and frequency-aware evaluation framework that measures internal embedding drift, spectral sensitivity, and structural smoothness (spatial consistency of vision tokens), alongside standard label-based metrics. Applying this framework to modern VLMs across the SEEDBench, MMMU, and POPE datasets reveals three distinct failure modes. First, models frequently preserve predicted answers while undergoing substantial internal representation drift; for perturbations such as text overlays, this drift approaches the magnitude of inter-image variability, indicating that representations move to regions typically occupied by unrelated inputs despite unchanged outputs. Second, robustness does not improve with scale; larger models achieve higher accuracy but exhibit equal or greater sensitivity, consistent with sharper yet more fragile decision boundaries. Third, we find that perturbations affect tasks differently: they harm reasoning when they disrupt how models combine coarse and fine visual cues, but on the hallucination benchmarks, they can reduce false positives by making models generate more conservative answers.

</details>


### [196] [Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions](https://arxiv.org/abs/2602.06746)
*Alessandro Abate,Giuseppe De Giacomo,Mathias Jackermeier,Jan Kretínský,Maximilian Prokop,Christoph Weinhuber*

Main category: cs.AI

TL;DR: 本文研究多任务强化学习（RL），提出一种基于线性时序逻辑（LTL）公式的新型任务嵌入技术，利用先进的语义LTL到自动机转换方法，实现高效在线计算、表达性强的任务嵌入，并支持完整的LTL。实验表明该方法在多种场景下表现优于现有方法，且可处理复杂规范。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂、未见的任务规范时性能受限，尤其在使用完整LTL表达式时难以扩展。需要更高效、更具表达力的任务表示方式以提升多任务RL的泛化能力。

Method: 提出一种基于新世代语义LTL到自动机转换的方法，生成带有丰富结构信息的状态自动机，用于实时计算、提取任务嵌入并条件化策略。

Result: 在多个领域中实现了最先进的性能，能够处理以往方法无法应对的复杂规格，显著提升了多任务强化学习的可扩展性和泛化能力。

Conclusion: 所提出的任务嵌入方法通过结合语义自动机与多任务RL，有效提升了策略对复杂、多样化任务的适应能力，为复杂系统中的通用智能学习提供了有力支持。

Abstract: We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are commonly used in formal methods to specify properties of systems, and have recently been successfully adopted in RL. In this setting, we present a novel task embedding technique leveraging a new generation of semantic LTL-to-automata translations, originally developed for temporal synthesis. The resulting semantically labelled automata contain rich, structured information in each state that allow us to (i) compute the automaton efficiently on-the-fly, (ii) extract expressive task embeddings used to condition the policy, and (iii) naturally support full LTL. Experimental results in a variety of domains demonstrate that our approach achieves state-of-the-art performance and is able to scale to complex specifications where existing methods fail.

</details>


### [197] [Wild Guesses and Mild Guesses in Active Concept Learning](https://arxiv.org/abs/2602.06818)
*Anirudh Chari,Neil Pattanaik*

Main category: cs.AI

TL;DR: 该研究探讨了在神经符号贝叶斯学习框架下，主动概念学习中信息性与学习者稳定性之间的权衡。通过对比理性主动学习者（基于近似期望信息增益EIG选择查询）与人类常用的正向检验策略（PTS），发现EIG在需要否定性验证的复杂规则中表现良好，但在简单规则上表现不佳。问题根源在于EIG策略导致的假设生成分布与后验支持不匹配，引发粒子近似中的陷阱；而PTS虽信息效率较低，但通过选择‘安全’查询保持假设有效性，从而在简单规则上更快收敛。研究认为‘确认偏误’可能并非认知错误，而是人类在稀疏、开放假设空间中实现可计算推理的合理适应机制。


<details>
  <summary>Details</summary>
Motivation: 探究主动概念学习中如何平衡查询的信息性与学习系统的稳定性，特别是在使用大语言模型生成假设的神经符号贝叶斯框架下，理解不同查询策略的优劣及其背后机制。

Method: 构建一个基于大语言模型（LLM）生成可执行程序作为假设的神经符号贝叶斯学习器，比较两种查询策略：最大化近似期望信息增益（EIG）的理性主动学习者，以及依据当前最优假设预测为正例进行查询的正向检验策略（PTS）。在经典数字符合游戏任务中进行实验分析。

Result: EIG策略在复杂或含例外规则的任务中表现更优，但在简单规则任务中表现差，因其引发假设生成分布与后验支持之间的不匹配，导致粒子近似失效；而PTS虽然信息效率低，但因持续选择有效且合理的查询，维持了假设空间的合理性，实现更快收敛。

Conclusion: ‘确认偏误’可能并非认知缺陷，而是在稀疏、开放的假设空间中实现稳定、可计算推理的一种理性策略。主动学习中的查询选择需兼顾信息价值与假设生成的可行性，以避免支持不匹配陷阱。

Abstract: Human concept learning is typically active: learners choose which instances to query or test in order to reduce uncertainty about an underlying rule or category. Active concept learning must balance informativeness of queries against the stability of the learner that generates and scores hypotheses. We study this trade-off in a neuro-symbolic Bayesian learner whose hypotheses are executable programs proposed by a large language model (LLM) and reweighted by Bayesian updating. We compare a Rational Active Learner that selects queries to maximize approximate expected information gain (EIG) and the human-like Positive Test Strategy (PTS) that queries instances predicted to be positive under the current best hypothesis. Across concept-learning tasks in the classic Number Game, EIG is effective when falsification is necessary (e.g., compound or exception-laden rules), but underperforms on simple concepts. We trace this failure to a support mismatch between the EIG policy and the LLM proposal distribution: highly diagnostic boundary queries drive the posterior toward regions where the generator produces invalid or overly specific programs, yielding a support-mismatch trap in the particle approximation. PTS is information-suboptimal but tends to maintain proposal validity by selecting "safe" queries, leading to faster convergence on simple rules. Our results suggest that "confirmation bias" may not be a cognitive error, but rather a rational adaptation for maintaining tractable inference in the sparse, open-ended hypothesis spaces characteristic of human thought.

</details>


### [198] [ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training](https://arxiv.org/abs/2602.06820)
*Dunwei Tu,Hongyan Hao,Hansi Yang,Yihao Chen,Yi-Kai Zhang,Zhikang Xia,Yu Yang,Yueqing Sun,Xingchen Liu,Furao Shen,Qi Gu,Hui Su,Xunliang Cai*

Main category: cs.AI

TL;DR: 提出ScaleEnv框架，通过程序化测试确保环境可靠性，利用工具依赖图扩展和可执行动作验证保证任务完整性和可解性，实现从零构建完全交互式环境与可验证任务，显著提升智能体在未见多轮工具使用基准上的表现，证明其强大的泛化能力，并实证表明扩大环境多样性对模型泛化性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有交互式环境稀缺，合成方法在环境多样性和可扩展性方面存在显著局限，难以支持通用智能体的自探索学习。

Method: ScaleEnv框架通过程序化测试确保环境可靠性，利用工具依赖图扩展和可执行动作验证来保证任务的完整性和可解性，从而从零构建完全交互式环境与可验证任务。

Result: 在$τ^2$-Bench和VitaBench等未见的多轮工具使用基准上，基于ScaleEnv训练的智能体表现出显著性能提升，验证了其强大的泛化能力。

Conclusion: 扩大环境多样性是提升智能体鲁棒学习能力的关键，ScaleEnv为构建大规模、高质量交互式环境提供了有效解决方案。

Abstract: Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration. However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations regarding environmental diversity and scalability. To address these challenges, we introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. Specifically, ScaleEnv ensures environment reliability through procedural testing, and guarantees task completeness and solvability via tool dependency graph expansion and executable action verification. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $τ^2$-Bench and VitaBench, highlighting strong generalization capabilities. Furthermore, we investigate the relationship between increasing number of domains and model generalization performance, providing empirical evidence that scaling environmental diversity is critical for robust agent learning.

</details>


### [199] [POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models](https://arxiv.org/abs/2602.06822)
*Yi Chen,Wonjin Shin,Shuhong Liu,Tho Mai,Jeongmo Lee,Chuanbo Hua,Kun Wang,Jun Liu,Joo-Young Kim*

Main category: cs.AI

TL;DR: POP（Partition-guided Online Pruning）是一种轻量级、即插即用的在线结构化剪枝框架，通过上下文感知的动态剪枝，在不增加额外计算开销的前提下，实现高效推理。它将模型通道划分为保留、候选和剪枝区域，预填充阶段确定粗粒度剪枝分区，解码阶段在候选区域内生成细粒度掩码，避免全通道重新评估。该方法无需离线校准、重训练或学习预测器，适用于大型语言模型、混合专家模型和视觉-语言模型等多种基础模型，实验表明其在保持更高精度的同时，显著降低计算开销和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法在推理时采用固定剪枝决策，忽略了自回归生成过程中动态出现的稀疏模式，导致性能受限。因此需要一种能根据上下文动态调整剪枝策略的方法，以提升效率与精度。

Method: POP通过将模型通道划分为保留、候选和剪枝三类区域；预填充阶段建立粗粒度剪枝分区，保留重要权重；解码阶段在候选区域中生成细粒度掩码，实现上下文相关的动态剪枝。整个过程无需额外训练或校准，具备低延迟和高可扩展性。

Result: 在多种大型基础模型（包括LLMs、MoEs、VLMs）上进行的广泛评估显示，POP在保持更高准确率的同时，相比现有剪枝方法具有更小的计算开销和更低的推理延迟，展现出卓越的通用性和效率优势。

Conclusion: POP是一种高效的在线结构化剪枝框架，能够实现上下文感知的动态剪枝，无需额外训练或校准，显著提升大型模型推理效率与性能，适用于多类主流基础模型。

Abstract: Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions during inference, overlooking sparsity patterns that emerge in the autoregressive token generation. In this paper, we propose POP (Partition-guided Online Pruning), an efficient online structural pruning framework that enables context-conditioned dynamic pruning with minimal computational overhead. POP partitions model channels into retained, candidate, and pruned regions, where prefilling defines a coarse pruning partition, and the decoding stage generates a fine-grained mask within the candidate region, avoiding full-channel re-evaluation. The coarse pruning partition preserves consistently important weights, while the fine-grained masking provides context-conditioned variation during decoding. Moreover, POP is a lightweight, plug-and-play method that requires no preprocessing, including offline calibration, retraining, or learning predictors. Extensive evaluations across diverse LFMs, including large language models (LLMs), mixture-of-experts models (MoEs), and vision-language models (VLMs), demonstrate that POP consistently delivers higher accuracy than existing pruning approaches while incurring smaller computational overhead and minimizing inference latency.

</details>


### [200] [An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization](https://arxiv.org/abs/2602.06838)
*Jin Wang,Hui Ma,Fei Xing,Ming Yan*

Main category: cs.AI

TL;DR: 提出了一种自适应差分隐私联邦学习框架，通过客户端的轻量级压缩模块和服务器端的自适应梯度裁剪与约束感知聚合机制，有效缓解设备异构、非独立同分布数据及差分隐私带来的梯度扰动问题，提升了模型收敛稳定性和分类精度。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中因设备异构、非独立同分布数据以及差分隐私机制导致的梯度更新不稳定、噪声放大和性能下降问题。

Method: 在客户端引入轻量级局部压缩模块以正则化中间表示并控制梯度变化；在服务器端采用基于历史更新统计的自适应梯度裁剪策略，并设计约束感知聚合机制以抑制不可靠或噪声主导的客户端更新。

Result: 在CIFAR-10和SVHN数据集上的实验表明，所提方法显著提高了模型的收敛稳定性与分类准确率。

Conclusion: 该自适应差分隐私联邦学习框架能有效应对异构环境下的隐私保护训练挑战，实现更高效、稳定的模型训练。

Abstract: Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When differential privacy is enforced, conventional fixed gradient clipping and Gaussian noise injection may further amplify gradient perturbations, resulting in training oscillation and performance degradation and degraded model performance. To address these challenges, we propose an adaptive differentially private federated learning framework that explicitly targets model efficiency under heterogeneous and privacy-constrained settings. On the client side, a lightweight local compressed module is introduced to regularize intermediate representations and constrain gradient variability, thereby mitigating noise amplification during local optimization. On the server side, an adaptive gradient clipping strategy dynamically adjusts clipping thresholds based on historical update statistics to avoid over-clipping and noise domination. Furthermore, a constraint-aware aggregation mechanism is designed to suppress unreliable or noise-dominated client updates and stabilize global optimization. Extensive experiments on CIFAR-10 and SVHN demonstrate improved convergence stability and classification accuracy.

</details>
