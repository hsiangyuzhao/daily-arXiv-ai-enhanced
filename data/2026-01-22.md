<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 58]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.AI](#cs.AI) [Total: 26]
- [cs.LG](#cs.LG) [Total: 51]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Intelligent Power Grid Design Review via Active Perception-Enabled Multimodal Large Language Models](https://arxiv.org/abs/2601.14261)
*Taoliang Tan,Chengwei Ma,Zhen Tian,Zhao Lin,Dongdong Li,Si Shi*

Main category: cs.CV

TL;DR: 本文提出一种基于预训练多模态大模型（MLLM）和先进提示工程的三阶段智能电网设计图审查框架，通过模拟人类专家审查流程，先在低分辨率概览中利用MLLM进行全局语义理解并提出特定领域语义区域，再在高分辨率下对这些区域进行细粒度识别并获取置信度评分，最后通过综合决策模块整合结果以准确诊断设计错误并提供可靠性评估。实验表明该方法显著提升了MLLM对宏观语义的理解能力，提高了缺陷发现准确率和审查判断的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化系统在处理超高清分辨率电网设计图时面临计算需求高、信息丢失及缺乏整体语义理解等问题，难以有效识别设计错误，亟需一种更智能、可靠的审查方法。

Method: 提出一个三阶段框架：第一阶段使用预训练多模态大模型从低分辨率图中进行全局语义理解，智能划分领域相关语义区域；第二阶段在高分辨率下对这些区域进行细粒度识别，获取详细信息与置信度；第三阶段通过综合决策模块融合置信度信息，实现精准错误诊断与可靠性评估。

Result: 在真实电网设计图上的初步实验表明，该方法显著增强了MLLM对宏观语义的把握能力，提升了设计错误的发现准确率，并使审查判断更加可靠，优于传统的被动式MLLM推理方式。

Conclusion: 本研究提出了一种新型、由提示驱动的智能且可靠的电网设计图审查范式，为电力系统安全提供了有力支持。

Abstract: The intelligent review of power grid engineering design drawings is crucial for power system safety. However, current automated systems struggle with ultra-high-resolution drawings due to high computational demands, information loss, and a lack of holistic semantic understanding for design error identification. This paper proposes a novel three-stage framework for intelligent power grid drawing review, driven by pre-trained Multimodal Large Language Models (MLLMs) through advanced prompt engineering. Mimicking the human expert review process, the first stage leverages an MLLM for global semantic understanding to intelligently propose domain-specific semantic regions from a low-resolution overview. The second stage then performs high-resolution, fine-grained recognition within these proposed regions, acquiring detailed information with associated confidence scores. In the final stage, a comprehensive decision-making module integrates these confidence-aware results to accurately diagnose design errors and provide a reliability assessment. Preliminary results on real-world power grid drawings demonstrate our approach significantly enhances MLLM's ability to grasp macroscopic semantic information and pinpoint design errors, showing improved defect discovery accuracy and greater reliability in review judgments compared to traditional passive MLLM inference. This research offers a novel, prompt-driven paradigm for intelligent and reliable power grid drawing review.

</details>


### [2] [LURE: Latent Space Unblocking for Multi-Concept Reawakening in Diffusion Models](https://arxiv.org/abs/2601.14330)
*Mengyu Sun,Ziyuan Yang,Andrew Beng Jin Teoh,Junxu Liu,Haibo Hu,Yi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的概念重唤醒方法LURE，通过重建潜在空间并引导采样轨迹来恢复被擦除的概念。针对多概念场景中的梯度冲突与特征纠缠问题，引入梯度场正交化机制，并结合潜在语义识别引导采样以确保过程稳定。实验表明，LURE在多种擦除任务和方法下均能实现高保真、同步的多概念重唤醒。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法存在被重新唤醒的漏洞，而现有重唤醒方法仅依赖提示优化，忽视生成过程中的其他因素，无法全面理解其内在动态。

Method: 将生成过程建模为隐式函数，理论分析文本条件、模型参数和潜在状态等多重因素对概念重唤醒的影响；提出LURE方法，包含语义再绑定机制、梯度场正交化以及潜在语义识别引导采样策略。

Result: LURE能够在多种擦除任务和方法中实现多个被擦除概念的同时、高保真重唤醒，且在多概念场景下表现出良好的稳定性与抗干扰能力。

Conclusion: 本研究揭示了扩散模型中概念擦除的深层脆弱性，提出了一个系统性的重唤醒框架LURE，为理解与防御概念泄露提供了新的理论视角与技术路径。

Abstract: Concept erasure aims to suppress sensitive content in diffusion models, but recent studies show that erased concepts can still be reawakened, revealing vulnerabilities in erasure methods. Existing reawakening methods mainly rely on prompt-level optimization to manipulate sampling trajectories, neglecting other generative factors, which limits a comprehensive understanding of the underlying dynamics. In this paper, we model the generation process as an implicit function to enable a comprehensive theoretical analysis of multiple factors, including text conditions, model parameters, and latent states. We theoretically show that perturbing each factor can reawaken erased concepts. Building on this insight, we propose a novel concept reawakening method: Latent space Unblocking for concept REawakening (LURE), which reawakens erased concepts by reconstructing the latent space and guiding the sampling trajectory. Specifically, our semantic re-binding mechanism reconstructs the latent space by aligning denoising predictions with target distributions to reestablish severed text-visual associations. However, in multi-concept scenarios, naive reconstruction can cause gradient conflicts and feature entanglement. To address this, we introduce Gradient Field Orthogonalization, which enforces feature orthogonality to prevent mutual interference. Additionally, our Latent Semantic Identification-Guided Sampling (LSIS) ensures stability of the reawakening process via posterior density verification. Extensive experiments demonstrate that LURE enables simultaneous, high-fidelity reawakening of multiple erased concepts across diverse erasure tasks and methods.

</details>


### [3] [CityCube: Benchmarking Cross-view Spatial Reasoning on Vision-Language Models in Urban Environments](https://arxiv.org/abs/2601.14339)
*Haotian Xu,Yue Hu,Zhengqiu Zhu,Chen Gao,Ziyou Wang,Junreng Rao,Wenhao Lu,Weishi Li,Quanjun Yin,Yong Li*

Main category: cs.CV

TL;DR: 提出CityCube基准，评估视觉语言模型在城市环境中的跨视角推理能力，发现大模型性能远低于人类，小模型经微调后表现更优，揭示了模型与人类在认知上的根本差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准多聚焦室内或街道场景，忽视开放城市空间中丰富的语义、复杂几何和视角变化带来的挑战，亟需一个系统性评估工具来检验视觉语言模型在真实城市环境下的跨视角推理能力。

Method: 构建CityCube基准，包含四种视角动态模拟相机运动，覆盖车辆、无人机、卫星等多种平台视角；设计5,022个精心标注的多视角问答对，涵盖五个认知维度和三种空间关系表达，用于全面评估33个VLMs的表现。

Result: 33个VLMs在任务中平均表现不佳，最大准确率仅54.1%，较人类水平低34.2%；而小规模微调模型可超过60.0%准确率，表明当前大模型在复杂城市环境中存在显著缺陷。

Conclusion: CityCube有效揭示了视觉语言模型在城市跨视角推理中的局限性，强调了针对真实城市环境进行模型训练与评估的重要性，并指出小模型通过微调具有更强适应性，为未来研究提供了关键方向。

Abstract: Cross-view spatial reasoning is essential for embodied AI, underpinning spatial understanding, mental simulation and planning in complex environments. Existing benchmarks primarily emphasize indoor or street settings, overlooking the unique challenges of open-ended urban spaces characterized by rich semantics, complex geometries, and view variations. To address this, we introduce CityCube, a systematic benchmark designed to probe cross-view reasoning capabilities of current VLMs in urban settings. CityCube integrates four viewpoint dynamics to mimic camera movements and spans a wide spectrum of perspectives from multiple platforms, e.g., vehicles, drones and satellites. For a comprehensive assessment, it features 5,022 meticulously annotated multi-view QA pairs categorized into five cognitive dimensions and three spatial relation expressions. A comprehensive evaluation of 33 VLMs reveals a significant performance disparity with humans: even large-scale models struggle to exceed 54.1% accuracy, remaining 34.2% below human performance. By contrast, small-scale fine-tuned VLMs achieve over 60.0% accuracy, highlighting the necessity of our benchmark. Further analyses indicate the task correlations and fundamental cognitive disparity between VLMs and human-like reasoning.

</details>


### [4] [Large-Scale Label Quality Assessment for Medical Segmentation via a Vision-Language Judge and Synthetic Data](https://arxiv.org/abs/2601.14406)
*Yixiong Chen,Zongwei Zhou,Wenxuan Li,Alan Yuille*

Main category: cs.CV

TL;DR: 提出SegAE，一种轻量级视觉-语言模型，用于自动评估大规模医学分割数据集中142个解剖结构的标签质量。该模型在超过四百万张图像-标签对上训练，与真实Dice相似度相关系数达0.902，单个3D掩码评估仅需0.06秒。SegAE可有效识别公共数据集中的低质量标签，并提升主动学习和半监督学习的数据效率，减少1/3的标注成本和70%的质量检查时间。代码、模型权重和数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 大规模医学分割数据集常混合使用人工标注和伪标签，其质量不一，影响模型训练与评估的可靠性。低质量标签会降低模型性能并削弱训练鲁棒性，亟需一种高效、自动化的标签质量评估方法。

Method: 构建轻量级视觉-语言模型SegAE，基于四百万图像-标签对及其质量评分进行训练，通过多模态特征融合实现对标签质量的自动化预测，支持快速评估3D分割掩码。

Result: SegAE与真实标签质量（Dice相似度）相关系数达0.902，单次3D掩码评估耗时仅0.06秒；能有效发现公共数据集中普遍存在的低质量标签；在主动学习与半监督学习中显著提升数据效率，降低标注成本三分之一，质量检查时间减少70%。

Conclusion: SegAE为大规模医学分割数据集提供了一种简单高效的标签质量控制工具，具有良好的实用价值与推广前景，相关资源已开源。

Abstract: Large-scale medical segmentation datasets often combine manual and pseudo-labels of uneven quality, which can compromise training and evaluation. Low-quality labels may hamper performance and make the model training less robust. To address this issue, we propose SegAE (Segmentation Assessment Engine), a lightweight vision-language model (VLM) that automatically predicts label quality across 142 anatomical structures. Trained on over four million image-label pairs with quality scores, SegAE achieves a high correlation coefficient of 0.902 with ground-truth Dice similarity and evaluates a 3D mask in 0.06s. SegAE shows several practical benefits: (I) Our analysis reveals widespread low-quality labeling across public datasets; (II) SegAE improves data efficiency and training performance in active and semi-supervised learning, reducing dataset annotation cost by one-third and quality-checking time by 70% per label. This tool provides a simple and effective solution for quality control in large-scale medical segmentation datasets. The dataset, model weights, and codes are released at https://github.com/Schuture/SegAE.

</details>


### [5] [Vision-Based Natural Language Scene Understanding for Autonomous Driving: An Extended Dataset and a New Model for Traffic Scene Description Generation](https://arxiv.org/abs/2601.14438)
*Danial Sadrian Zadeh,Otman A. Basir,Behzad Moshiri*

Main category: cs.CV

TL;DR: 该论文提出了一种新框架，将单张前视相机图像转化为简洁的自然语言描述，以捕捉空间布局、语义关系和驾驶相关线索。模型采用混合注意力机制增强特征提取，并在新构建的数据集上通过定量评估和人工判断验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 交通场景理解对自动驾驶车辆安全导航至关重要，但现有方法在从单目图像生成详细自然语言描述方面存在不足，且缺乏专门数据集支持。

Method: 提出一种结合混合注意力机制的模型，用于从单张前视图像中提取空间与语义特征，并生成上下文丰富的场景描述；同时构建了一个基于BDD100K的新数据集，并提供数据构建指南。

Result: 在自建数据集上，模型在CIDEr和SPICE等指标上表现优异，经人工评估也显示出高质量的描述能力，证明其有效性和实用性。

Conclusion: 所提出的框架能够高效生成准确、详尽的交通场景自然语言描述，为自动驾驶环境感知提供了有力支持，且新数据集和评估方法具有重要参考价值。

Abstract: Traffic scene understanding is essential for enabling autonomous vehicles to accurately perceive and interpret their environment, thereby ensuring safe navigation. This paper presents a novel framework that transforms a single frontal-view camera image into a concise natural language description, effectively capturing spatial layouts, semantic relationships, and driving-relevant cues. The proposed model leverages a hybrid attention mechanism to enhance spatial and semantic feature extraction and integrates these features to generate contextually rich and detailed scene descriptions. To address the limited availability of specialized datasets in this domain, a new dataset derived from the BDD100K dataset has been developed, with comprehensive guidelines provided for its construction. Furthermore, the study offers an in-depth discussion of relevant evaluation metrics, identifying the most appropriate measures for this task. Extensive quantitative evaluations using metrics such as CIDEr and SPICE, complemented by human judgment assessments, demonstrate that the proposed model achieves strong performance and effectively fulfills its intended objectives on the newly developed dataset.

</details>


### [6] [Gaussian Based Adaptive Multi-Modal 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2601.14448)
*A. Enes Doruk*

Main category: cs.CV

TL;DR: 本文提出了一种基于高斯的自适应相机-LiDAR多模态3D占据预测模型，以应对自动驾驶中长尾安全挑战。该模型通过四部分设计：（1）基于深度可变形采样的LiDAR深度特征聚合，缓解几何稀疏性；（2）基于交叉熵的特征平滑，抑制领域特定噪声；（3）自适应相机-LiDAR融合，动态校准传感器输出；（4）基于选择性状态空间模型的Gauss-Mamba头，实现线性复杂度的全局上下文解码，显著提升效率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前体素化方法在处理动态环境时计算复杂度过高，融合过程僵化且易失效，难以应对自动驾驶中的长尾安全问题，亟需更高效、自适应的3D语义占据预测方法。

Method: 提出一种基于高斯的自适应相机-LiDAR多模态3D占据预测框架，结合深度可变形采样、交叉熵平滑、动态融合机制和Gauss-Mamba头，实现高效、鲁棒的多模态信息融合与全局上下文建模。

Result: 所提方法在保持高精度的同时，显著降低计算复杂度，尤其在动态环境中表现出更强的稳定性与适应性，有效提升了3D占据预测的性能与实用性。

Conclusion: 该研究成功构建了一个内存高效、自适应的多模态3D占据预测模型，为自动驾驶系统应对复杂与动态交通场景提供了有力支持，具有重要的实际应用价值。

Abstract: The sparse object detection paradigm shift towards dense 3D semantic occupancy prediction is necessary for dealing with long-tail safety challenges for autonomous vehicles. Nonetheless, the current voxelization methods commonly suffer from excessive computation complexity demands, where the fusion process is brittle, static, and breaks down under dynamic environmental settings. To this end, this research work enhances a novel Gaussian-based adaptive camera-LiDAR multimodal 3D occupancy prediction model that seamlessly bridges the semantic strengths of camera modality with the geometric strengths of LiDAR modality through a memory-efficient 3D Gaussian model. The proposed solution has four key components: (1) LiDAR Depth Feature Aggregation (LDFA), where depth-wise deformable sampling is employed for dealing with geometric sparsity, (2) Entropy-Based Feature Smoothing, where cross-entropy is employed for handling domain-specific noise, (3) Adaptive Camera-LiDAR Fusion, where dynamic recalibration of sensor outputs is performed based on model outputs, and (4) Gauss-Mamba Head that uses Selective State Space Models for global context decoding that enjoys linear computation complexity.

</details>


### [7] [GutenOCR: A Grounded Vision-Language Front-End for Documents](https://arxiv.org/abs/2601.14490)
*Hunter Heidenreich,Ben Elliott,Olivia Dinica,Yosheb Getachew*

Main category: cs.CV

TL;DR: GutenOCR 是通过微调 Qwen2.5-VL-3B 和 Qwen2.5-VL-7B 得到的一系列基于视觉语言模型的接地 OCR 前端，支持统一的提示接口进行阅读、检测和定位。在商业文档、科学文章和合成接地数据上训练，可实现全页与局部阅读，支持行级和段落级边界框及条件性 'x 在哪里？' 查询。引入了新的接地 OCR 评估协议，结果显示 GutenOCR-7B 在 10,500 张保留的商业与科学页面上的综合接地 OCR 分数从 0.40 提升至 0.82，超过其基线模型一倍以上。在 Fox 和 OmniDocBench v1.5 上，该方法显著提升了区域和行级 OCR 及文本检测召回率，但在页面级线性化、颜色引导 OCR 及公式密集布局方面表现出一定权衡。


<details>
  <summary>Details</summary>
Motivation: 现有 OCR 系统在处理复杂文档时难以同时兼顾文本识别、位置定位与上下文理解，尤其在需要语义接地（如回答‘x 在哪里？’）的任务中表现不足。为提升文档理解能力，需构建能融合视觉、语言与空间信息的统一模型。

Method: 通过在商业文档、科学文章及合成接地数据上微调 Qwen2.5-VL-3B 与 Qwen2.5-VL-7B 模型，构建 GutenOCR 家族。采用统一的提示接口实现阅读、检测与接地功能，支持全页与局部读取，并提供行级与段落级边界框。引入新评估协议以衡量接地性能。

Result: GutenOCR-7B 在 10,500 张测试页上的复合接地 OCR 分数从 0.40 提升至 0.82，性能翻倍。在 Fox 与 OmniDocBench v1.5 上显著改善区域和行级 OCR 准确率及文本检测召回率，但对页面线性化、颜色引导识别和公式密集布局存在性能下降。

Conclusion: GutenOCR 成功实现了视觉语言模型在接地 OCR 任务中的高效应用，显著提升多粒度文档理解能力。尽管在某些复杂布局下存在局限性，但整体表现优于原始基线模型，验证了统一提示接口与细粒度标注数据在文档智能中的有效性。

Abstract: GutenOCR is a family of grounded OCR front-ends obtained by fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B. The resulting single-checkpoint vision-language models expose reading, detection, and grounding through a unified, prompt-based interface. Trained on business documents, scientific articles, and synthetic grounding data, the models support full-page and localized reading with line- and paragraph-level bounding boxes and conditional ``where is x?'' queries. We introduce a grounded OCR evaluation protocol and show that GutenOCR-7B more than doubles the composite grounded OCR score of its Qwen2.5-VL-7B backbone on 10.5K held-out business and scientific pages (0.40 to 0.82). On Fox and OmniDocBench v1.5, our approach substantially improves region- and line-level OCR as well as text-detection recall, but reveals trade-offs in page-level linearization, color-guided OCR, and formula-heavy layouts.

</details>


### [8] [PAS-Mamba: Phase-Amplitude-Spatial State Space Model for MRI Reconstruction](https://arxiv.org/abs/2601.14530)
*Xiaoyan Kui,Zijie Fan,Zexin Ji,Qinsong Li,Hao Xu,Weixin Si,Haodong Xu,Beiji Zou*

Main category: cs.CV

TL;DR: PAS-Mamba提出了一种新的MRI重建框架，通过在频率域解耦相位与幅度建模，并结合图像域特征实现更优的重建效果。该方法利用局部Mamba保持空间局部性以增强解剖细节，采用圆形频率域扫描（CFDS）按同心结构序列化频率特征，并通过双域互补融合模块（DDCFM）实现频率与图像域之间的自适应双向信息交换。实验表明，PAS-Mamba在IXI和fastMRI膝关节数据集上均优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有MRI重建方法通常将频率域视为整体，忽视了相位与幅度在信息表达上的差异。研究表明，幅度主要反映像素级强度，而相位主导图像结构，统一建模易造成特征学习干扰。因此需要解耦相位与幅度的建模以提升重建质量。

Method: 提出Phase-Amplitude-Spatial State Space Model (PAS-Mamba)，在图像域使用LocalMamba保留空间局部性；在频率域将幅度和相位分离为两个专用分支，避免表示耦合；设计Circular Frequency Domain Scanning (CFDS)对频率特征进行从低频到高频的序列化处理；引入Dual-Domain Complementary Fusion Module (DDCFM)实现频率域与图像域间的自适应融合与双向信息交互。

Result: 在IXI和fastMRI膝关节数据集上的大量实验表明，PAS-Mamba consistently 超越当前最先进的重建方法，在视觉质量和客观指标（如PSNR、SSIM）上均有显著提升。

Conclusion: PAS-Mamba通过解耦频率域中的相位与幅度建模，并结合有效的双域融合机制，实现了更精确的MRI图像重建，为多域联合建模提供了新思路。

Abstract: Joint feature modeling in both the spatial and frequency domains has become a mainstream approach in MRI reconstruction. However, existing methods generally treat the frequency domain as a whole, neglecting the differences in the information carried by its internal components. According to Fourier transform theory, phase and amplitude represent different types of information in the image. Our spectrum swapping experiments show that magnitude mainly reflects pixel-level intensity, while phase predominantly governs image structure. To prevent interference between phase and magnitude feature learning caused by unified frequency-domain modeling, we propose the Phase-Amplitude-Spatial State Space Model (PAS-Mamba) for MRI Reconstruction, a framework that decouples phase and magnitude modeling in the frequency domain and combines it with image-domain features for better reconstruction. In the image domain, LocalMamba preserves spatial locality to sharpen fine anatomical details. In frequency domain, we disentangle amplitude and phase into two specialized branches to avoid representational coupling. To respect the concentric geometry of frequency information, we propose Circular Frequency Domain Scanning (CFDS) to serialize features from low to high frequencies. Finally, a Dual-Domain Complementary Fusion Module (DDCFM) adaptively fuses amplitude phase representations and enables bidirectional exchange between frequency and image domains, delivering superior reconstruction. Extensive experiments on the IXI and fastMRI knee datasets show that PAS-Mamba consistently outperforms state of the art reconstruction methods.

</details>


### [9] [LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning](https://arxiv.org/abs/2601.14594)
*Lianying Chao,Linfeng Yin,Peiyu Ren,Yifan Jiang,Qiaoyu Ren,Dingcheng Shan,Jing-cheng Pang,Sijie Wu,Xubin Li,Kai Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种可学习的帧选择器（LFS），用于视频字幕生成任务。传统方法采用均匀采样，但忽略了事件分布不均的问题。LFS通过建模时间重要性，平衡时间多样性与事件相关性，并采用分层策略确保时间覆盖且避免帧聚集。关键创新在于利用冻结的视频-大语言模型（LLM）的字幕反馈来优化帧选择，直接提升下游字幕质量。此外，作者指出现有基准与人类认知之间的差距，构建了新的 ICH-CC 基准，反映更符合人类理解的视频评估标准。实验表明，LFS在两个主流基准和 ICH-CC 上均显著提升字幕质量，最大提升达 4% 以上，同时改善视频问答性能。整体上，LFS是一种高效、易集成的详细视频字幕解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有视频字幕模型依赖均匀采样所有帧，成本高且无法适应事件分布不均；同时，现有基准与人类认知存在偏差，导致评估不准确。因此需要一种能自适应选择关键帧并反映人类理解的评估方式。

Method: 提出可学习的帧选择器（LFS），通过建模时间重要性实现时间多样性和事件相关性的平衡，采用分层采样策略防止帧聚集；利用冻结视频-大语言模型的字幕反馈作为监督信号，直接优化帧选择以提升字幕质量；构建 ICH-CC 基准，基于人工设计的高质量问题，反映人类对视频的理解。

Result: LFS 在 VDC 上提升最多达 2.0%，在 ICH-CC 上提升超过 4%；增强的字幕进一步提升了视频问答性能，验证了其有效性与通用性。

Conclusion: LFS 为详细视频字幕提供了一种高效、可集成的解决方案，不仅能显著提升字幕质量，还能促进下游任务表现，且其评估框架 ICH-CC 更贴近人类认知，推动领域向更真实、有意义的方向发展。

Abstract: Video captioning models convert frames into visual tokens and generate descriptions with large language models (LLMs). Since encoding all frames is prohibitively expensive, uniform sampling is the default choice, but it enforces equal temporal coverage while ignoring the uneven events distribution. This motivates a Learnable Frame Selector (LFS) that selects temporally diverse and event-relevant frames. LFS explicitly models temporal importance to balance temporal diversity and event relevance, and employs a stratified strategy to ensure temporal coverage while avoiding clustering. Crucially, LFS leverages caption feedback from frozen video-LLMs to learn frame selection that directly optimizes downstream caption quality. Additionally, we identify the gap between existing benchmark and human's cognition. Thus, we introduce ICH-CC built from carefully designed questions by annotators that reflect human-consistent understanding of video. Experiments indicate that LFS consistently improves detailed video captioning across two representative community benchmarks and ICH-CC, achieving up to 2.0% gains on VDC and over 4% gains on ICH-CC. Moreover, we observe that enhanced captions with LFS leads to improved performance on video question answering. Overall, LFS provides an effective and easy-to-integrate solution for detailed video captioning.

</details>


### [10] [U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization](https://arxiv.org/abs/2601.14605)
*Weiwei Ma,Xiaobing Yu,Peijie Qiu,Jin Yang,Pan Xiao,Xiaoqi Zhao,Xiaofeng Liu,Tomo Miyazaki,Shinichiro Omachi,Yongsong Huang*

Main category: cs.CV

TL;DR: 提出一种名为U-Harmony的联合训练方法，通过域门控头实现单一分割模型同时学习异构医学影像数据，有效缓解领域差异并保留数据集特有知识，支持跨模态和解剖结构的通用适应性，在多机构脑部病变数据集上表现优异，建立新的3D医学图像分割基准。


<details>
  <summary>Details</summary>
Motivation: 临床医学分割数据集常受限且异质，不同机构间存在成像模态、协议和解剖目标的差异，现有深度学习模型难以同时兼顾泛化性和领域特异性知识。

Method: 提出U-Harmony方法，结合域门控头，通过顺序归一化与反归一化特征分布来减少领域差异，同时保持原始数据集的知识，并支持新模态和解剖类别的无缝学习。

Result: 在跨机构脑部病变数据集上的大量实验表明，该方法显著提升模型鲁棒性与适应性，成为真实临床环境下3D医学图像分割的新基准。

Conclusion: U-Harmony能够有效解决异构医学影像数据下的分割挑战，具备良好的泛化能力与扩展性，适用于复杂多变的临床实际场景。

Abstract: In clinical practice, medical segmentation datasets are often limited and heterogeneous, with variations in modalities, protocols, and anatomical targets across institutions. Existing deep learning models struggle to jointly learn from such diverse data, often sacrificing either generalization or domain-specific knowledge. To overcome these challenges, we propose a joint training method called Universal Harmonization (U-Harmony), which can be integrated into deep learning-based architectures with a domain-gated head, enabling a single segmentation model to learn from heterogeneous datasets simultaneously. By integrating U-Harmony, our approach sequentially normalizes and then denormalizes feature distributions to mitigate domain-specific variations while preserving original dataset-specific knowledge. More appealingly, our framework also supports universal modality adaptation, allowing the seamless learning of new imaging modalities and anatomical classes. Extensive experiments on cross-institutional brain lesion datasets demonstrate the effectiveness of our approach, establishing a new benchmark for robust and adaptable 3D medical image segmentation models in real-world clinical settings.

</details>


### [11] [Learning Consistent Taxonomic Classification through Hierarchical Reasoning](https://arxiv.org/abs/2601.14610)
*Zhenghong Li,Kecheng Zheng,Haibin Ling*

Main category: cs.CV

TL;DR: VL-Taxon is a two-stage, hierarchy-based reasoning framework that improves taxonomic classification in Vision-Language Models by enhancing both leaf-level accuracy and hierarchical consistency. It uses supervised fine-tuning followed by reinforcement learning on a small dataset, achieving over 10% improvement on iNaturalist-2021 compared to the original 72B model.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language Models struggle with hierarchical knowledge, often misclassifying coarser taxonomic levels even when leaf-level identification is correct. This issue stems from a lack of modeling hierarchical reasoning.

Method: VL-Taxon employs a two-stage approach: first a top-down process to improve leaf-level accuracy, then a consistency-enforcing stage using the accurate leaf output to ensure alignment across the entire taxonomy. Both stages are trained via supervised fine-tuning and reinforcement learning.

Result: On the iNaturalist-2021 dataset, VL-Taxon implemented on Qwen2.5-VL-7B outperforms the original 72B model by over 10% in both leaf-level and hierarchical consistency accuracy, achieved with only a small subset of data and no external VLM-generated examples.

Conclusion: VL-Taxon effectively addresses the limitation of Vision-Language Models in hierarchical reasoning, demonstrating that even smaller models can surpass larger ones through targeted, hierarchy-aware training.

Abstract: While Vision-Language Models (VLMs) excel at visual understanding, they often fail to grasp hierarchical knowledge. This leads to common errors where VLMs misclassify coarser taxonomic levels even when correctly identifying the most specific level (leaf level). Existing approaches largely overlook this issue by failing to model hierarchical reasoning. To address this gap, we propose VL-Taxon, a two-stage, hierarchy-based reasoning framework designed to improve both leaf-level accuracy and hierarchical consistency in taxonomic classification. The first stage employs a top-down process to enhance leaf-level classification accuracy. The second stage then leverages this accurate leaf-level output to ensure consistency throughout the entire taxonomic hierarchy. Each stage is initially trained with supervised fine-tuning to instill taxonomy knowledge, followed by reinforcement learning to refine the model's reasoning and generalization capabilities. Extensive experiments reveal a remarkable result: our VL-Taxon framework, implemented on the Qwen2.5-VL-7B model, outperforms its original 72B counterpart by over 10% in both leaf-level and hierarchical consistency accuracy on average on the iNaturalist-2021 dataset. Notably, this significant gain was achieved by fine-tuning on just a small subset of data, without relying on any examples generated by other VLMs.

</details>


### [12] [Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection](https://arxiv.org/abs/2601.14625)
*Yingsong Huang,Hui Guo,Jing Huang,Bing Bai,Qi Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种名为DEUA的新框架，用于检测扩散模型生成的图像。通过引入基于拉普拉斯近似的扩散似然不确定性（DEU）估计，区分数据与扩散生成样本流形的接近程度，并采用非对称损失函数训练具有更大分类边距的平衡分类器，从而提升检测性能。实验表明该方法在大规模基准测试中达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法在检测扩散生成图像时，未充分考虑重建误差中随机不确定性和认知不确定性的不同影响。其中，随机不确定性源于数据固有噪声，会干扰检测；而认知不确定性反映模型对陌生模式的知识缺失，有助于识别生成图像。因此，需要更精细地建模不确定性以提升检测效果。

Method: 提出DEUA框架，包含两个核心组件：(1) 利用拉普拉斯近似估计扩散认知不确定性（DEU），衡量输入数据与扩散生成样本流形的接近程度；(2) 设计非对称损失函数，使分类器在训练中获得更大的分类边界，增强泛化能力。

Result: 在多个大规模基准数据集上的实验结果表明，所提方法在检测扩散生成图像方面表现优异，优于现有主流方法，达到当前最优水平。

Conclusion: DEUA通过有效分离和利用认知不确定性，并结合非对称学习策略，在扩散生成图像检测任务中实现了显著性能提升，为未来生成内容检测提供了新的思路。

Abstract: The rapid progress of diffusion models highlights the growing need for detecting generated images. Previous research demonstrates that incorporating diffusion-based measurements, such as reconstruction error, can enhance the generalizability of detectors. However, ignoring the differing impacts of aleatoric and epistemic uncertainty on reconstruction error can undermine detection performance. Aleatoric uncertainty, arising from inherent data noise, creates ambiguity that impedes accurate detection of generated images. As it reflects random variations within the data (e.g., noise in natural textures), it does not help distinguish generated images. In contrast, epistemic uncertainty, which represents the model's lack of knowledge about unfamiliar patterns, supports detection. In this paper, we propose a novel framework, Diffusion Epistemic Uncertainty with Asymmetric Learning~(DEUA), for detecting diffusion-generated images. We introduce Diffusion Epistemic Uncertainty~(DEU) estimation via the Laplace approximation to assess the proximity of data to the manifold of diffusion-generated samples. Additionally, an asymmetric loss function is introduced to train a balanced classifier with larger margins, further enhancing generalizability. Extensive experiments on large-scale benchmarks validate the state-of-the-art performance of our method.

</details>


### [13] [READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection](https://arxiv.org/abs/2601.14651)
*Chenglizhao Chen,Boze Li,Mengke Song,Dehao Feng,Xinyu Liu,Shanchen Pang,Jufeng Yang,Hui Yu*

Main category: cs.CV

TL;DR: 提出READ-Net框架，通过自适应特征重校准（AFR）解决情绪模糊问题，有效提升音频-视觉抑郁症检测性能，在多个数据集上平均准确率提升4.55%，F1-score提升1.26%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在忽略情绪线索时无法捕捉细微抑郁信号，而引入情绪信息的方法常将短暂情绪表达误判为稳定抑郁症状，导致检测错误，这种现象称为‘情绪模糊’。

Method: 提出READ-Net框架，采用自适应特征重校准（AFR）动态调整情绪特征权重，识别并保留与抑郁相关的线索，同时过滤无关情绪噪声，从而清晰化特征表示。

Result: 在三个公开数据集上的实验表明，READ-Net显著优于现有最先进方法，平均准确率提升4.55%，F1-score提升1.26%，展现出对情绪干扰的强鲁棒性。

Conclusion: READ-Net通过创新的AFR机制有效缓解了情绪模糊问题，为音频-视觉抑郁症检测提供了更可靠、可集成的解决方案。

Abstract: Depression is a severe global mental health issue that impairs daily functioning and overall quality of life. Although recent audio-visual approaches have improved automatic depression detection, methods that ignore emotional cues often fail to capture subtle depressive signals hidden within emotional expressions. Conversely, those incorporating emotions frequently confuse transient emotional expressions with stable depressive symptoms in feature representations, a phenomenon termed \emph{Emotional Ambiguity}, thereby leading to detection errors. To address this critical issue, we propose READ-Net, the first audio-visual depression detection framework explicitly designed to resolve Emotional Ambiguity through Adaptive Feature Recalibration (AFR). The core insight of AFR is to dynamically adjust the weights of emotional features to enhance depression-related signals. Rather than merely overlooking or naively combining emotional information, READ-Net innovatively identifies and preserves depressive-relevant cues within emotional features, while adaptively filtering out irrelevant emotional noise. This recalibration strategy significantly clarifies feature representations, and effectively mitigates the persistent challenge of emotional interference. Additionally, READ-Net can be easily integrated into existing frameworks for improved performance. Extensive evaluations on three publicly available datasets show that READ-Net outperforms state-of-the-art methods, with average gains of 4.55\% in accuracy and 1.26\% in F1-score, demonstrating its robustness to emotional disturbances and improving audio-visual depression detection.

</details>


### [14] [Mirai: Autoregressive Visual Generation Needs Foresight](https://arxiv.org/abs/2601.14671)
*Yonghao Yu,Lang Huang,Zerun Wang,Runyi Li,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: 本文提出Mirai框架，通过引入未来信息（foresight）改善自回归视觉生成模型的因果建模，显著加速收敛并提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 自回归视觉生成模型因严格因果监督导致全局一致性差且收敛慢，本文探究未来信息是否能改善这一问题。

Method: 设计Mirai框架，分Mirai-E（显式未来信息注入）和Mirai-I（隐式未来信息利用），在不改变架构且无额外推理开销的前提下，将未来信息与模型内部2D图像表示对齐。

Result: 实验表明，Mirai可使LlamaGen-B收敛速度提升最多10倍，ImageNet图像生成任务上的FID从5.34降至4.34，显著提升生成质量与效率。

Conclusion: 自回归视觉生成模型需要引入未来信息以增强因果建模，Mirai框架为实现这一目标提供了有效且通用的解决方案。

Abstract: Autoregressive (AR) visual generators model images as sequences of discrete tokens and are trained with next token likelihood. This strict causality supervision optimizes each step only by its immediate next token, which diminishes global coherence and slows convergence. We ask whether foresight, training signals that originate from later tokens, can help AR visual generation. We conduct a series of controlled diagnostics along the injection level, foresight layout, and foresight source axes, unveiling a key insight: aligning foresight to AR models' internal representation on the 2D image grids improves causality modeling. We formulate this insight with Mirai (meaning "future" in Japanese), a general framework that injects future information into AR training with no architecture change and no extra inference overhead: Mirai-E uses explicit foresight from multiple future positions of unidirectional representations, whereas Mirai-I leverages implicit foresight from matched bidirectional representations. Extensive experiments show that Mirai significantly accelerates convergence and improves generation quality. For instance, Mirai can speed up LlamaGen-B's convergence by up to 10$\times$ and reduce the generation FID from 5.34 to 4.34 on the ImageNet class-condition image generation benchmark. Our study highlights that visual autoregressive models need foresight.

</details>


### [15] [LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models](https://arxiv.org/abs/2601.14674)
*Mingyang Xie,Numair Khan,Tianfu Wang,Naina Dhingra,Seonghyeon Nam,Haitao Yang,Zhuo Hui,Christopher Metzler,Andrea Vedaldi,Hamed Pirsiavash,Lei Luo*

Main category: cs.CV

TL;DR: 本文提出利用大型4D重建模型的潜在空间中嵌入的隐式几何知识来指导视频生成，以应对单目视频重渲染中的视角变化带来的漂移和失真问题。该方法通过联合条件化潜在表示与源相机位姿，在无需显式重建的情况下实现更鲁棒的视图生成，显著提升渲染质量并达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频重渲染方法面临两大挑战：几何无条件模型缺乏空间感知导致视角变化时出现漂移和形变；而几何有条件模型依赖估计深度和显式重建，易受深度误差和标定错误影响。因此亟需一种既能保持几何一致性又不依赖精确深度估计的方法。

Method: 利用大型4D重建模型的潜在空间作为隐式几何先验，将这些潜在表示与源相机位姿联合用于条件化扩散模型，从而在生成新视角视频时融入连续的场景结构信息，避免显式重建和深度估计带来的误差。

Result: 所提方法在视频重渲染任务上取得了当前最优结果，有效减少了视角变换下的几何失真和漂移，提升了生成视图的视觉质量和几何一致性。

Conclusion: 通过利用预训练4D重建模型潜在空间中的隐式几何知识，本方法实现了对视频重渲染任务的有效建模，在无需显式重建或精确深度估计的前提下，显著提升了生成质量与鲁棒性。

Abstract: Given a monocular video, the goal of video re-rendering is to generate views of the scene from a novel camera trajectory. Existing methods face two distinct challenges. Geometrically unconditioned models lack spatial awareness, leading to drift and deformation under viewpoint changes. On the other hand, geometrically-conditioned models depend on estimated depth and explicit reconstruction, making them susceptible to depth inaccuracies and calibration errors.
  We propose to address these challenges by using the implicit geometric knowledge embedded in the latent space of a large 4D reconstruction model to condition the video generation process. These latents capture scene structure in a continuous space without explicit reconstruction. Therefore, they provide a flexible representation that allows the pretrained diffusion prior to regularize errors more effectively. By jointly conditioning on these latents and source camera poses, we demonstrate that our model achieves state-of-the-art results on the video re-rendering task. Project webpage is https://lavr-4d-scene-rerender.github.io/

</details>


### [16] [LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval](https://arxiv.org/abs/2601.14706)
*Chao Gao,Siqiao Xue,Yimin Peng,Jiwen Fu,Tingyi Gu,Shanshan Li,Fan Zhou*

Main category: cs.CV

TL;DR: LookBench 是一个面向真实电商场景的时尚图像检索基准，包含来自实时网站和AI生成的最新时尚图像，支持单件商品与成套穿搭的细粒度检索。该基准具有时间戳并计划每半年更新，以实现对模型训练截止时间的污染感知评估。实验表明，即使强基线模型在该基准上表现也低于60% Recall@1，而提出的模型在多个任务上达到领先水平，并公开了数据集、评估代码和模型。


<details>
  <summary>Details</summary>
Motivation: 现有时尚图像检索基准难以反映真实电商环境中的复杂性与动态变化，缺乏对模型训练时间范围的污染感知评估，且未涵盖新兴的AI生成内容与实时趋势。因此，需要一个更全面、可更新、贴近实际应用的基准来推动研究进展。

Method: 构建包含真实电商平台图像与AI生成图像的多源数据集，采用细粒度属性分类体系设计任务，引入时间戳机制以支持污染感知评估，并设计单件与成套检索任务。通过半定期更新策略保持基准挑战性，同时提供开源模型与评估工具。

Result: LookBench显著挑战现有模型，在多个基线上取得低于60%的Recall@1；自研模型表现最佳，开源模型位居第二，两者均在传统Fashion200K数据集上达到顶尖性能。

Conclusion: LookBench是一个可持续更新、覆盖真实电商场景的综合性时尚图像检索基准，能够有效衡量模型在现实应用中的泛化能力，为未来研究提供了可靠评估标准。

Abstract: In this paper, we present LookBench (We use the term "look" to reflect retrieval that mirrors how people shop -- finding the exact item, a close substitute, or a visually consistent alternative.), a live, holistic and challenging benchmark for fashion image retrieval in real e-commerce settings. LookBench includes both recent product images sourced from live websites and AI-generated fashion images, reflecting contemporary trends and use cases. Each test sample is time-stamped and we intend to update the benchmark periodically, enabling contamination-aware evaluation aligned with declared training cutoffs. Grounded in our fine-grained attribute taxonomy, LookBench covers single-item and outfit-level retrieval across. Our experiments reveal that LookBench poses a significant challenge on strong baselines, with many models achieving below $60\%$ Recall@1. Our proprietary model achieves the best performance on LookBench, and we release an open-source counterpart that ranks second, with both models attaining state-of-the-art results on legacy Fashion200K evaluations. LookBench is designed to be updated semi-annually with new test samples and progressively harder task variants, providing a durable measure of progress. We publicly release our leaderboard, dataset, evaluation code, and trained models.

</details>


### [17] [Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2601.14718)
*Yiyang Fu,Hui Li,Wangyu Wu*

Main category: cs.CV

TL;DR: 提出CPF-CTE框架，通过上下文补丁融合与类别令牌增强，利用补丁间的空间依赖关系和可学习类别令牌，提升弱监督语义分割的特征表示能力与分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视图像块之间的复杂上下文依赖，导致局部表征不完整，分割精度受限。

Method: 设计上下文融合双向长短期记忆（CF-BiLSTM）模块捕捉块间空间依赖并实现双向信息流动；引入可学习类别令牌动态编码和优化类别特定语义。

Result: 在PASCAL VOC 2012和MS COCO 2014数据集上，CPF-CTE持续优于现有弱监督语义分割方法。

Conclusion: CPF-CTE通过有效整合空间与语义线索，显著提升了弱监督语义分割的性能，为解决语义模糊和误激活问题提供了新思路。

Abstract: Weakly Supervised Semantic Segmentation (WSSS), which relies only on image-level labels, has attracted significant attention for its cost-effectiveness and scalability. Existing methods mainly enhance inter-class distinctions and employ data augmentation to mitigate semantic ambiguity and reduce spurious activations. However, they often neglect the complex contextual dependencies among image patches, resulting in incomplete local representations and limited segmentation accuracy. To address these issues, we propose the Context Patch Fusion with Class Token Enhancement (CPF-CTE) framework, which exploits contextual relations among patches to enrich feature representations and improve segmentation. At its core, the Contextual-Fusion Bidirectional Long Short-Term Memory (CF-BiLSTM) module captures spatial dependencies between patches and enables bidirectional information flow, yielding a more comprehensive understanding of spatial correlations. This strengthens feature learning and segmentation robustness. Moreover, we introduce learnable class tokens that dynamically encode and refine class-specific semantics, enhancing discriminative capability. By effectively integrating spatial and semantic cues, CPF-CTE produces richer and more accurate representations of image content. Extensive experiments on PASCAL VOC 2012 and MS COCO 2014 validate that CPF-CTE consistently surpasses prior WSSS methods.

</details>


### [18] [HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding](https://arxiv.org/abs/2601.14724)
*Haowei Zhang,Shudong Yang,Jinlan Fu,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CV

TL;DR: HERMES 是一种无需训练的架构，用于实时、准确地理解视频流。它基于对注意力机制的分析，将键值（KV）缓存视为分层记忆框架，能够以紧凑的形式重用缓存，实现低内存开销下的高效推理。该方法在无额外计算的情况下支持实时响应，相比现有最先进模型，首次启动时间（TTFT）快10倍，并在减少68%视频标记的情况下仍保持优异或更优的准确率，尤其在流媒体数据集上提升达11.4%。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在处理流式视频输入时面临性能不稳定、响应延迟高和GPU内存占用大的挑战，难以满足实时交互需求。因此亟需一种无需训练、高效且低资源消耗的方案来实现高质量的视频流理解。

Method: 通过机制性分析注意力机制，将KV缓存建模为多粒度的分层记忆结构；在推理阶段复用紧凑的KV缓存，避免重复计算，从而实现低延迟、低内存的流式视频理解。

Result: HERMES 在流媒体数据集上实现高达11.4%的准确率提升，同时将视频令牌减少68%仍保持高精度；首次启动时间（TTFT）比当前最优模型快10倍，在保证实时响应的同时显著降低内存开销。

Conclusion: HERMES 提供了一种无需训练、高效且可扩展的实时视频流理解方案，突破了现有模型在实时性与资源效率之间的权衡瓶颈，为实际部署提供了可行路径。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets.

</details>


### [19] [DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling](https://arxiv.org/abs/2601.14732)
*Jing Lan,Hexiao Ding,Hongzhao Chen,Yufeng Jiang,Nga-Chun Ng,Gwing Kei Yip,Gerald W. Y. Cheng,Yunlin Mao,Jing Cai,Liang-ting Lin,Jung Sun Yoo*

Main category: cs.CV

TL;DR: DeepMoLM 是一种双视图框架，通过将高分辨率分子图像与基于分子构象的几何不变量相结合，实现对3D结构和立体化学信息的精确建模。它利用1024×1024输入保留高频细节，将构象邻域编码为离散的扩展三维指纹，并通过交叉注意力融合视觉与几何流，实现无需原子坐标的物理合理生成。在PubChem图文描述生成任务中，相对基线提升12.3% METEOR得分；在分子属性预测中，分子量MAE达13.64 g/mol，复杂度为37.89，表现优于通用模型并媲美专用模型。在ChEBI-20图像描述生成上，超越通用基线并达到顶尖视觉语言模型水平。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在药物发现和化学文献挖掘中难以准确处理分子的3D几何结构和立体化学信息，尤其是基于字符串或图的模型缺乏空间感知能力，而视觉-语言模型常忽略立体化学细节且难以将连续3D结构映射到离散标记。因此需要一种能同时捕捉视觉细节与几何约束的模型。

Method: 提出DeepMoLM，采用双视图架构：一是高分辨率分子图像输入，保留1024×1024的高频细节；二是从分子构象中提取几何不变量，构建扩展三维指纹（Extended 3-Dimensional Fingerprints）表示构象邻域；通过交叉注意力机制融合视觉特征与几何特征，实现跨模态对齐，生成过程不依赖原子坐标，但保持物理合理性。

Result: 在PubChem图文描述任务中，相比最强通用基线，METEOR得分提升12.3%；在分子属性预测中，分子量MAE为13.64 g/mol，复杂度为37.89，性能接近甚至超过专用模型；在ChEBI-20图像描述生成任务中，优于通用模型并达到当前最优视觉语言模型水平。

Conclusion: DeepMoLM成功实现了对分子3D结构与立体化学的精准建模，通过融合视觉与几何信息，在多个任务上超越通用模型并媲美专用模型，为化学领域中的多模态生成提供了新的有效范式。

Abstract: AI models for drug discovery and chemical literature mining must interpret molecular images and generate outputs consistent with 3D geometry and stereochemistry. Most molecular language models rely on strings or graphs, while vision-language models often miss stereochemical details and struggle to map continuous 3D structures into discrete tokens. We propose DeepMoLM: Deep Molecular Language M odeling, a dual-view framework that grounds high-resolution molecular images in geometric invariants derived from molecular conformations. DeepMoLM preserves high-frequency evidence from 1024 $\times$ 1024 inputs, encodes conformer neighborhoods as discrete Extended 3-Dimensional Fingerprints, and fuses visual and geometric streams with cross-attention, enabling physically grounded generation without atom coordinates. DeepMoLM improves PubChem captioning with a 12.3% relative METEOR gain over the strongest generalist baseline while staying competitive with specialist methods. It produces valid numeric outputs for all property queries and attains MAE 13.64 g/mol on Molecular Weight and 37.89 on Complexity in the specialist setting. On ChEBI-20 description generation from images, it exceeds generalist baselines and matches state-of- the-art vision-language models. Code is available at https://github.com/1anj/DeepMoLM.

</details>


### [20] [Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption](https://arxiv.org/abs/2601.14738)
*Liqin Wang,Qianyue Hu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: VoidFace提出一种系统性防御方法，针对扩散模型驱动的换脸技术，通过在关键瓶颈注入扰动，破坏身份路径的完整性。该方法结合局部干扰、身份擦除、注意力解耦和中间特征污染，在保持视觉不可察觉的前提下有效阻断换脸过程，显著优于现有防御方案。


<details>
  <summary>Details</summary>
Motivation: 现有主动防御方法因忽视换脸系统中的结构鲁棒性和静态条件引导机制而失效，亟需新的系统性防御策略以应对扩散模型带来的隐私与身份安全威胁。

Method: VoidFace将换脸视为耦合的身份路径，通过在物理回归、语义嵌入、注意力机制及扩散特征等关键环节注入扰动，实现多阶段级联破坏；采用潜空间对抗搜索与感知自适应策略，确保攻击效果与图像质量之间的平衡。

Result: 实验表明，VoidFace在多种基于扩散模型的换脸系统上均表现出优越的防御性能，同时生成的对抗人脸具有更高的视觉保真度。

Conclusion: VoidFace为扩散模型驱动的换脸提供了高效且隐蔽的系统性防御框架，有效提升了身份安全防护能力。

Abstract: The rapid evolution of diffusion models has democratized face swapping but also raises concerns about privacy and identity security. Existing proactive defenses, often adapted from image editing attacks, prove ineffective in this context. We attribute this failure to an oversight of the structural resilience and the unique static conditional guidance mechanism inherent in face swapping systems. To address this, we propose VoidFace, a systemic defense method that views face swapping as a coupled identity pathway. By injecting perturbations at critical bottlenecks, VoidFace induces cascading disruption throughout the pipeline. Specifically, we first introduce localization disruption and identity erasure to degrade physical regression and semantic embeddings, thereby impairing the accurate modeling of the source face. We then intervene in the generative domain by decoupling attention mechanisms to sever identity injection, and corrupting intermediate diffusion features to prevent the reconstruction of source identity. To ensure visual imperceptibility, we perform adversarial search in the latent manifold, guided by a perceptual adaptive strategy to balance attack potency with image quality. Extensive experiments show that VoidFace outperforms existing defenses across various diffusion-based swapping models, while producing adversarial faces with superior visual quality.

</details>


### [21] [Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution](https://arxiv.org/abs/2601.14741)
*Chongbin Yi,Yuxin Liang,Ziqi Zhou,Peng Yang*

Main category: cs.CV

TL;DR: 本文提出了一种端边协同的生成-增强框架，用于高效生成高分辨率文本到图像内容。通过在边缘侧自适应选择去噪步骤和超分辨率尺度，将低分辨率图像分块并采用区域感知的混合超分辨率策略：对前景使用基于扩散的模型恢复细节，对背景使用轻量级学习模型提升效率，最终拼接成高分辨率图像。实验表明，该方法在保持良好图像质量的同时，将服务延迟降低了33%。


<details>
  <summary>Details</summary>
Motivation: 当前高分辨率文本到图像生成面临图像保真度与延迟之间的权衡问题。尽管边缘计算可快速生成低分辨率图像，但实现高分辨率输出时，现有超分辨率方法要么因轻量化导致细节丢失，要么因基于扩散的方法计算开销过大而增加延迟。因此需要一种兼顾性能与效率的解决方案。

Method: 提出端边协同的生成-增强框架：边缘侧生成低分辨率图像并自适应选择参数；图像被分割为块后，采用区域感知的混合超分辨率策略——对前景使用扩散模型以恢复细节，对背景使用轻量级模型以提高效率，最后拼接为完整高分辨率图像。

Result: 实验结果显示，相比基线方法，本系统在保持竞争性图像质量的前提下，显著降低了33%的服务延迟。

Conclusion: 所提出的端边协同框架有效平衡了高分辨率文本到图像生成中的延迟与图像保真度，适用于资源受限的边缘环境，为提升用户体验提供了可行路径。

Abstract: Artificial Intelligence-Generated Content (AIGC) has made significant strides, with high-resolution text-to-image (T2I) generation becoming increasingly critical for improving users' Quality of Experience (QoE). Although resource-constrained edge computing adequately supports fast low-resolution T2I generations, achieving high-resolution output still faces the challenge of ensuring image fidelity at the cost of latency. To address this, we first investigate the performance of super-resolution (SR) methods for image enhancement, confirming a fundamental trade-off that lightweight learning-based SR struggles to recover fine details, while diffusion-based SR achieves higher fidelity at a substantial computational cost. Motivated by these observations, we propose an end-edge collaborative generation-enhancement framework. Upon receiving a T2I generation task, the system first generates a low-resolution image based on adaptively selected denoising steps and super-resolution scales at the edge side, which is then partitioned into patches and processed by a region-aware hybrid SR policy. This policy applies a diffusion-based SR model to foreground patches for detail recovery and a lightweight learning-based SR model to background patches for efficient upscaling, ultimately stitching the enhanced ones into the high-resolution image. Experiments show that our system reduces service latency by 33% compared with baselines while maintaining competitive image quality.

</details>


### [22] [SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection](https://arxiv.org/abs/2601.14742)
*Ami Pandat,Kanyala Muvva,Punna Rajasekhar,Gopika Vinod,Rohit Shukla*

Main category: cs.CV

TL;DR: 本文提出SimD3，一个大规模高保真合成数据集，用于复杂空域环境下的鲁棒无人机检测。该数据集模拟了带有异构载荷的无人机、多种鸟类作为真实干扰物，并利用虚幻引擎5的多样化环境与可控天气、光照及飞行轨迹进行拍摄。在YOLOv5框架下，通过引入注意力增强的变体Yolov5m+C3b（用C3b模块替换标准瓶颈结构），在合成数据、合成与真实数据混合以及多个未见的真实世界基准上进行了广泛实验。结果表明，SimD3能有效支持小目标无人机检测，且Yolov5m+C3b在域内和跨数据集评估中均优于基线模型，验证了SimD3在训练和评估鲁棒无人机检测模型方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有无人机检测面临标注真实世界数据有限、外观变化大以及视觉相似干扰物（如鸟类）等问题，缺乏高质量、多样化的训练数据限制了模型性能。因此需要构建一个更真实、更具挑战性的合成数据集以提升模型的鲁棒性和泛化能力。

Method: 构建基于虚幻引擎5的高保真合成数据集SimD3，包含异构载荷无人机、多类鸟类干扰物及多样化环境；使用360度六相机阵列采集真实感图像；在YOLOv5基础上设计改进模型Yolov5m+C3b，采用C3b模块替代标准C3块以增强特征提取能力；在合成数据、混合数据及多个真实世界测试集上进行系统评估。

Result: SimD3有效提升了小目标无人机检测的监督效果；所提出的Yolov5m+C3b模型在不同场景下均表现出优于基线模型的性能，尤其在跨数据集评估中展现出强泛化能力；证明了该合成数据集和改进模型对复杂环境下无人机检测的有效性。

Conclusion: SimD3是一个高质量、多样化的合成数据集，能够有效支撑无人机检测模型的训练与评估；结合改进的Yolov5m+C3b架构，显著提升了模型在复杂、多变真实环境中的鲁棒性与泛化能力，为未来无人机检测研究提供了有力工具与基准。

Abstract: Reliable drone detection is challenging due to limited annotated real-world data, large appearance variability, and the presence of visually similar distractors such as birds. To address these challenges, this paper introduces SimD3, a large-scale high-fidelity synthetic dataset designed for robust drone detection in complex aerial environments. Unlike existing synthetic drone datasets, SimD3 explicitly models drones with heterogeneous payloads, incorporates multiple bird species as realistic distractors, and leverages diverse Unreal Engine 5 environments with controlled weather, lighting, and flight trajectories captured using a 360 six-camera rig. Using SimD3, we conduct an extensive experimental evaluation within the YOLOv5 detection framework, including an attention-enhanced variant termed Yolov5m+C3b, where standard bottleneck-based C3 blocks are replaced with C3b modules. Models are evaluated on synthetic data, combined synthetic and real data, and multiple unseen real-world benchmarks to assess robustness and generalization. Experimental results show that SimD3 provides effective supervision for small-object drone detection and that Yolov5m+C3b consistently outperforms the baseline across in-domain and cross-dataset evaluations. These findings highlight the utility of SimD3 for training and benchmarking robust drone detection models under diverse and challenging conditions.

</details>


### [23] [ReinPath: A Multimodal Reinforcement Learning Approach for Pathology](https://arxiv.org/abs/2601.14757)
*Kangcheng Zhou,Jun Jiang,Qing Zhang,Shuang Zheng,Qingli Li,Shugong Xu*

Main category: cs.CV

TL;DR: 本文提出一种具有强推理能力的多模态病理学大语言模型，通过设计结合群体相对策略优化的语义奖励策略，提升文本描述的准确性和上下文相关性。同时构建了一个高质量的病理视觉问答（VQA）数据集，支持复杂推理任务。实验表明，该方法在仅使用20%数据训练时仍优于现有先进方法，并在零样本图像分类任务上达到与CLIP相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态病理方法因缺乏高质量数据集和简单推理过程，导致可解释性不足，难以支持明确推理与推断。

Method: 设计基于群体相对策略优化的语义奖励策略，构建支持复杂推理的高质量病理视觉问答数据集，开发具备强推理能力的多模态病理大语言模型。

Result: 在自建病理VQA数据集上，所提方法在仅用20%数据训练的情况下超越当前最优方法；在零样本图像分类任务中性能接近CLIP。

Conclusion: 本研究提出的多模态病理大语言模型在可解释性、推理能力和泛化性能方面均表现出色，为计算病理学中的多模态分析提供了新范式。

Abstract: Interpretability is significant in computational pathology, leading to the development of multimodal information integration from histopathological image and corresponding text data.However, existing multimodal methods have limited interpretability due to the lack of high-quality dataset that support explicit reasoning and inference and simple reasoning process.To address the above problems, we introduce a novel multimodal pathology large language model with strong reasoning capabilities.To improve the generation of accurate and contextually relevant textual descriptions, we design a semantic reward strategy integrated with group relative policy optimization.We construct a high-quality pathology visual question answering (VQA) dataset, specifically designed to support complex reasoning tasks.Comprehensive experiments conducted on this dataset demonstrate that our method outperforms state-of-the-art methods, even when trained with only 20% of the data.Our method also achieves comparable performance on downstream zero-shot image classification task compared with CLIP.

</details>


### [24] [Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis](https://arxiv.org/abs/2601.14774)
*Keita Takeda,Tomoya Sakai*

Main category: cs.CV

TL;DR: 本研究分析了公开的开源医学视觉语言模型（VLMs）产生的特征表示，发现医学VLMs能提取对医学分类任务有效的判别性特征；非医学VLMs通过上下文增强（如LLM2CLIP）也能获得更精细的表示，表明提升文本编码器比大量医学图像训练更重要。但非医学模型易受图像上叠加文字的偏见影响，提示模型选择需考虑下游任务及潜在的背景偏差风险。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型虽预期捕捉诊断相关特征，但其学习到的表示仍缺乏深入探索，标准评估指标如分类准确率无法全面揭示其是否具备真正的判别性、病灶特异性特征，因此需要理解这些表示以揭示医学图像结构并改进下游任务。

Method: 分析多个代表性医学VLMs在多种影像模态下从病变分类数据集提取的特征分布，并与非医学VLMs进行对比，评估医学领域特定训练的影响。

Result: 医学VLMs能提取有效的判别性特征；非医学VLMs经上下文增强后表现更优；提升文本编码器比密集医学图像训练更为关键；非医学模型对图像中叠加文本引起的偏见敏感。

Conclusion: 开发医学VLM时，应更注重文本编码器的优化，同时根据下游任务谨慎选择模型，避免因图像中文字信息带来的背景偏差导致推理风险。

Abstract: This study investigates the feature representations produced by publicly available open source medical vision-language models (VLMs). While medical VLMs are expected to capture diagnostically relevant features, their learned representations remain underexplored, and standard evaluations like classification accuracy do not fully reveal if they acquire truly discriminative, lesion-specific features. Understanding these representations is crucial for revealing medical image structures and improving downstream tasks in medical image analysis. This study aims to investigate the feature distributions learned by medical VLMs and evaluate the impact of medical specialization. We analyze the feature distribution of multiple image modalities extracted by some representative medical VLMs across lesion classification datasets on multiple modalities. These distributions were compared them with non-medical VLMs to assess the domain-specific medical training. Our experiments showed that medical VLMs can extract discriminative features that are effective for medical classification tasks. Moreover, it was found that non-medical VLMs with recent improvement with contextual enrichment such as LLM2CLIP produce more refined feature representations. Our results imply that enhancing text encoder is more crucial than training intensively on medical images when developing medical VLMs. Notably, non-medical models are particularly vulnerable to biases introduced by overlaied text strings on images. These findings underscore the need for careful consideration on model selection according to downstream tasks besides potential risks in inference due to background biases such as textual information in images.

</details>


### [25] [FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes](https://arxiv.org/abs/2601.14777)
*Jiaxuan Liu,Yang Xiang,Han Zhao,Xiangang Li,Zhenhua Ling*

Main category: cs.CV

TL;DR: 提出FunCineForge，包含大规模字幕数据集构建流水线和基于多模态大模型的配音模型，解决现有方法在数据规模、标注质量及复杂场景适应性上的不足，实现高质量跨场景影视配音。


<details>
  <summary>Details</summary>
Motivation: 现有影视配音方法受限于小规模、高错误率、稀疏标注的数据集，且仅依赖唇部信息进行音视频对齐，难以应对复杂电影场景中的语音同步、音色传递与情感表达需求。

Method: 设计端到端数据生产流水线构建首个富含标注的中文电视剧配音数据集，并开发基于多模态大模型的配音模型，支持多说话人、对话、旁白等多种场景，提升音视频对齐精度与表现力。

Result: 在单人独白、叙述、对话及多人场景下，所提模型在语音质量、唇形同步、音色迁移和指令遵循方面均优于当前最优方法，验证了其有效性与泛化能力。

Conclusion: FunCineForge通过高质量数据构建与先进模型设计，显著提升了影视配音在复杂场景下的表现，为后续研究提供了可复现的数据与技术基础。

Abstract: Movie dubbing is the task of synthesizing speech from scripts conditioned on video scenes, requiring accurate lip sync, faithful timbre transfer, and proper modeling of character identity and emotion. However, existing methods face two major limitations: (1) high-quality multimodal dubbing datasets are limited in scale, suffer from high word error rates, contain sparse annotations, rely on costly manual labeling, and are restricted to monologue scenes, all of which hinder effective model training; (2) existing dubbing models rely solely on the lip region to learn audio-visual alignment, which limits their applicability to complex live-action cinematic scenes, and exhibit suboptimal performance in lip sync, speech quality, and emotional expressiveness. To address these issues, we propose FunCineForge, which comprises an end-to-end production pipeline for large-scale dubbing datasets and an MLLM-based dubbing model designed for diverse cinematic scenes. Using the pipeline, we construct the first Chinese television dubbing dataset with rich annotations, and demonstrate the high quality of these data. Experiments across monologue, narration, dialogue, and multi-speaker scenes show that our dubbing model consistently outperforms SOTA methods in audio quality, lip sync, timbre transfer, and instruction following. Code and demos are available at https://anonymous.4open.science/w/FunCineForge.

</details>


### [26] [Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation](https://arxiv.org/abs/2601.14788)
*Yifei Liu,Changxing Ding,Ling Guo,Huaiguang Jiang,Qiong Cao*

Main category: cs.CV

TL;DR: 本文提出Reconstruction-Anchored Diffusion Model (RAM)，解决现有运动扩散模型在文本驱动人体动作生成中的两个关键问题：表示差距（因预训练文本编码器缺乏运动特异性信息）和迭代去噪过程中的误差传播。RAM通过引入运动潜在空间作为中间监督，联合训练一个运动重建分支，包含自正则化和以运动为中心的潜在对齐两个目标函数，以增强运动空间的区分性并实现文本到运动潜在空间的准确映射。此外，提出测试阶段的重建误差引导机制（REG），利用扩散模型的自我修正能力，在每一步去噪中通过重建前一估计来重现先前误差模式，放大当前预测与重构估计之间的残差，从而突出改进部分。实验表明RAM显著提升性能，达到当前最佳水平。


<details>
  <summary>Details</summary>
Motivation: 现有运动扩散模型受限于预训练文本编码器缺乏运动特异性信息导致的表示差距，以及迭代去噪过程中误差累积引发的生成质量下降。为提升文本到运动生成的准确性与稳定性，亟需引入更有效的监督机制和误差控制策略。

Method: 提出RAM框架，包含两个核心组件：1）在训练阶段，设计运动重建分支，结合自正则化和运动中心潜在对齐损失，优化运动潜在空间；2）在测试阶段，引入重建误差引导（REG）机制，通过重建前一步骤的估计，放大当前预测与重构之间的残差，以增强模型对改进方向的感知能力。

Result: 在多个基准数据集上，RAM显著优于现有方法，实现了最先进的生成性能。特别是在动作保真度、时序连贯性和文本匹配度方面均有明显提升。实验验证了运动重建分支与REG机制的有效性。

Conclusion: RAM通过引入运动潜在空间监督和重建误差引导机制，有效缓解了文本-运动映射中的表示差距与误差传播问题，为文本驱动的人体动作生成提供了更鲁棒和高质量的解决方案。代码将公开发布。

Abstract: Diffusion models have seen widespread adoption for text-driven human motion generation and related tasks due to their impressive generative capabilities and flexibility. However, current motion diffusion models face two major limitations: a representational gap caused by pre-trained text encoders that lack motion-specific information, and error propagation during the iterative denoising process. This paper introduces Reconstruction-Anchored Diffusion Model (RAM) to address these challenges. First, RAM leverages a motion latent space as intermediate supervision for text-to-motion generation. To this end, RAM co-trains a motion reconstruction branch with two key objective functions: self-regularization to enhance the discrimination of the motion space and motion-centric latent alignment to enable accurate mapping from text to the motion latent space. Second, we propose Reconstructive Error Guidance (REG), a testing-stage guidance mechanism that exploits the diffusion model's inherent self-correction ability to mitigate error propagation. At each denoising step, REG uses the motion reconstruction branch to reconstruct the previous estimate, reproducing the prior error patterns. By amplifying the residual between the current prediction and the reconstructed estimate, REG highlights the improvements in the current prediction. Extensive experiments demonstrate that RAM achieves significant improvements and state-of-the-art performance. Our code will be released.

</details>


### [27] [Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach](https://arxiv.org/abs/2601.14791)
*Ziyao Ling,Silvia Mirri,Paola Salomoni,Giovanni Delnevo*

Main category: cs.CV

TL;DR: 本研究探讨了使用Stable Diffusion与LoRA生成的合成图像是否能有效增强有限的真实数据集，用于基于多任务CNN的瓷器分类。实验采用MobileNetV3结合迁移学习，在四种分类任务（朝代、釉色、窑口、类型）中对比纯真实数据与混合真实-合成数据（95:5和90:10比例）的模型表现。结果显示：类型识别任务提升最显著（90:10比例下F1-macro提高5.5%），而朝代和窑口任务仅有小幅改善（3-4%），表明合成数据的有效性取决于生成特征与任务相关视觉特征的匹配程度。研究为考古学中生成式AI的应用提供了实用指导，揭示了在保持考古真实性的同时提升数据多样性的潜力与局限。


<details>
  <summary>Details</summary>
Motivation: 考古文物分类中的深度学习应用受限于训练数据稀缺，尤其是中国稀有瓷器类型，因此需要探索合成数据以扩充真实数据集。

Method: 采用Stable Diffusion与LoRA生成合成图像，结合MobileNetV3进行迁移学习，构建多任务分类模型，并在纯真实数据与不同比例的真实-合成数据混合数据集上进行控制实验。

Result: 类型分类任务获得最大提升（90:10比例下F1-macro增加5.5%），朝代与窑口任务有适度增益（3-4%），表明合成数据的效果具有任务依赖性，取决于生成特征与任务视觉特征的对齐程度。

Conclusion: 合成数据可有效提升特定瓷器分类任务的性能，但其效果受任务特异性影响；研究为考古学中生成式AI的应用提供了实践指南，强调在数据多样性与考古真实性之间需谨慎权衡。

Abstract: The scarcity of training data presents a fundamental challenge in applying deep learning to archaeological artifact classification, particularly for the rare types of Chinese porcelain. This study investigates whether synthetic images generated through Stable Diffusion with Low-Rank Adaptation (LoRA) can effectively augment limited real datasets for multi-task CNN-based porcelain classification. Using MobileNetV3 with transfer learning, we conducted controlled experiments comparing models trained on pure real data against those trained on mixed real-synthetic datasets (95:5 and 90:10 ratios) across four classification tasks: dynasty, glaze, kiln and type identification. Results demonstrate task-specific benefits: type classification showed the most substantial improvement (5.5\% F1-macro increase with 90:10 ratio), while dynasty and kiln tasks exhibited modest gains (3-4\%), suggesting that synthetic augmentation effectiveness depends on the alignment between generated features and task-relevant visual signatures. Our work contributes practical guidelines for deploying generative AI in archaeological research, demonstrating both the potential and limitations of synthetic data when archaeological authenticity must be balanced with data diversity.

</details>


### [28] [Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes](https://arxiv.org/abs/2601.14804)
*Tobias Weißberg,Weikang Wang,Paul Roetzer,Nafie El Amrani,Florian Bernard*

Main category: cs.CV

TL;DR: 本文提出了一种同时具备对称性信息和对称性无关特性的特征解耦方法，并结合特征精炼技术，以提升预测的对称性信息特征的鲁棒性。实验表明，该框架在内在对称性检测、左右分类和形状匹配等任务中均优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽然能从语义感知特征中提取对称性信息，但其特征维度单一且包含噪声，导致误分类区域较小。因此需要一种能够同时保留对称性信息与忽略对称性干扰的特征解耦方法，并提升特征鲁棒性。

Method: 提出特征解耦方法，使特征既具有对称性信息又对称性无关；引入特征精炼技术增强对称性信息特征的稳定性与准确性。

Result: 在内在对称性检测、左右分类和形状匹配等多个任务上，所提框架在定性和定量层面均表现出优越性能，显著优于当前主流方法。

Conclusion: 通过特征解耦与精炼，本研究构建了一个更鲁棒、更全面的对称性感知形状描述符框架，为后续形状分析任务提供了有效支持。

Abstract: Shape descriptors, i.e., per-vertex features of 3D meshes or point clouds, are fundamental to shape analysis. Historically, various handcrafted geometry-aware descriptors and feature refinement techniques have been proposed. Recently, several studies have initiated a new research direction by leveraging features from image foundation models to create semantics-aware descriptors, demonstrating advantages across tasks like shape matching, editing, and segmentation. Symmetry, another key concept in shape analysis, has also attracted increasing attention. Consequently, constructing symmetry-aware shape descriptors is a natural progression. Although the recent method $χ$ (Wang et al., 2025) successfully extracted symmetry-informative features from semantic-aware descriptors, its features are only one-dimensional, neglecting other valuable semantic information. Furthermore, the extracted symmetry-informative feature is usually noisy and yields small misclassified patches. To address these gaps, we propose a feature disentanglement approach which is simultaneously symmetry informative and symmetry agnostic. Further, we propose a feature refinement technique to improve the robustness of predicted symmetry informative features. Extensive experiments, including intrinsic symmetry detection, left/right classification, and shape matching, demonstrate the effectiveness of our proposed framework compared to various state-of-the-art methods, both qualitatively and quantitatively.

</details>


### [29] [POTR: Post-Training 3DGS Compression](https://arxiv.org/abs/2601.14821)
*Bert Ramlot,Martijn Courteaux,Peter Lambert,Glenn Van Wallendael*

Main category: cs.CV

TL;DR: POTR is a post-training 3DGS codec that improves compression and inference speed through novel pruning and lighting coefficient recomputation techniques, achieving superior rate-distortion performance and faster inference than existing methods.


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS) offers faster training and inference than NeRF but requires high storage. The need for efficient post-training compression to reduce storage while maintaining quality and speed drives the development of POTR.

Method: POTR introduces a modified 3DGS rasterizer for efficient splat pruning, a method to recompute lighting coefficients to increase sparsity without training, and a fine-tuning scheme to further improve performance.

Result: POTR reduces splat count by 2-4x, accelerates inference by 1.5-2x, increases AC lighting coefficient sparsity from 70% to 97%, and outperforms all other post-training compression techniques in both rate-distortion and inference speed.

Conclusion: POTR effectively addresses the high storage demands of 3DGS through innovative post-training compression, delivering state-of-the-art performance in compression efficiency and inference speed without requiring additional training.

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a promising contender to Neural Radiance Fields (NeRF) in 3D scene reconstruction and real-time novel view synthesis. 3DGS outperforms NeRF in training and inference speed but has substantially higher storage requirements. To remedy this downside, we propose POTR, a post-training 3DGS codec built on two novel techniques. First, POTR introduces a novel pruning approach that uses a modified 3DGS rasterizer to efficiently calculate every splat's individual removal effect simultaneously. This technique results in 2-4x fewer splats than other post-training pruning techniques and as a result also significantly accelerates inference with experiments demonstrating 1.5-2x faster inference than other compressed models. Second, we propose a novel method to recompute lighting coefficients, significantly reducing their entropy without using any form of training. Our fast and highly parallel approach especially increases AC lighting coefficient sparsity, with experiments demonstrating increases from 70% to 97%, with minimal loss in quality. Finally, we extend POTR with a simple fine-tuning scheme to further enhance pruning, inference, and rate-distortion performance. Experiments demonstrate that POTR, even without fine-tuning, consistently outperforms all other post-training compression techniques in both rate-distortion performance and inference speed.

</details>


### [30] [GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars](https://arxiv.org/abs/2601.14875)
*Zhe Chang,Haodong Jin,Ying Sun,Yan Song,Hui Yu*

Main category: cs.CV

TL;DR: 提出GAT-NeRF框架，结合Transformer与NeRF，通过融合3D坐标、3DMM参数和潜在编码，提升单目视频下4D面部动画的高保真重建，尤其在动态皱纹等高频细节上表现卓越。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF在单目视频条件下难以捕捉面部细微动态细节（如皱纹、疤痕），需增强对信息受限流的高频率特征建模能力。

Method: 设计几何感知的轻量级Transformer模块（GAT），融合3D空间坐标、3DMM表达参数与可学习潜在码，协同MLP提升局部几何与纹理特征表示能力。

Result: 实验表明GAT-NeRF在视觉保真度和高频细节恢复方面达到当前最优性能，显著提升动态数字人的真实感。

Conclusion: GAT-NeRF为高保真、可控的4D面部动画重建提供了新路径，适用于沉浸式虚拟人类应用。

Abstract: High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications.

</details>


### [31] [SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval](https://arxiv.org/abs/2601.14895)
*Xinyi Zheng,Yunze Liu,Chi-Hao Wu,Fan Zhang,Hao Zheng,Wenqi Zhou,Walterio W. Mayol-Cuevas,Junxiao Shen*

Main category: cs.CV

TL;DR: SpatialMem 是一个以记忆为中心的系统，将三维几何、语义和语言统一为可查询的表示。它从随意捕获的自中心RGB视频出发，重建度量尺度的室内环境，检测结构化3D锚点（如墙、门、窗）作为第一层框架，并在层次化记忆中填充开放词汇的对象节点，关联证据块、视觉嵌入和两层文本描述至3D坐标，实现紧凑存储与快速检索。该设计支持可解释的空间关系推理（如距离、方向、可见性），并支持语言引导导航和物体检索等下游任务，无需专用传感器。在三个真实室内场景上的实验表明，SpatialMem 在不断增加的杂乱和遮挡条件下仍保持较高的锚描述级导航完成率和分层检索准确率，提供了一种高效且可扩展的具身空间智能框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂室内环境时难以统一几何、语义与语言信息，且依赖专用传感器或受限于静态场景。本文旨在构建一个能从普通视频数据中自动构建可查询、可推理的3D空间记忆系统，以支持自然语言交互和自主导航。

Method: SpatialMem 采用多阶段流程：首先通过视频重建度量尺度的3D环境；然后检测结构化3D锚点（如墙、门、窗）形成骨架；接着在层次化记忆中建立对象节点，每个节点包含视觉证据、嵌入向量和双层文本描述（类别+上下文）；最后通过统一索引机制实现快速检索与空间推理。

Result: 在三个真实室内场景中，SpatialMem 在高杂乱和遮挡条件下仍保持高导航完成率（>90%）和分层检索准确率（>85%），优于基线方法，且无需额外传感器。系统具备良好的可扩展性和可解释性。

Conclusion: SpatialMem 成功实现了从普通视频到可查询、可推理的3D空间记忆的端到端构建，为具身智能系统提供了高效、通用的环境理解框架，具有广泛的应用前景。

Abstract: We present SpatialMem, a memory-centric system that unifies 3D geometry, semantics, and language into a single, queryable representation. Starting from casually captured egocentric RGB video, SpatialMem reconstructs metrically scaled indoor environments, detects structural 3D anchors (walls, doors, windows) as the first-layer scaffold, and populates a hierarchical memory with open-vocabulary object nodes -- linking evidence patches, visual embeddings, and two-layer textual descriptions to 3D coordinates -- for compact storage and fast retrieval. This design enables interpretable reasoning over spatial relations (e.g., distance, direction, visibility) and supports downstream tasks such as language-guided navigation and object retrieval without specialized sensors. Experiments across three real-life indoor scenes demonstrate that SpatialMem maintains strong anchor-description-level navigation completion and hierarchical retrieval accuracy under increasing clutter and occlusion, offering an efficient and extensible framework for embodied spatial intelligence.

</details>


### [32] [Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness](https://arxiv.org/abs/2601.14950)
*Yufei Song,Ziqi Zhou,Menghao Deng,Yifan Hu,Shengshan Hu,Minghui Li,Leo Yu Zhang*

Main category: cs.CV

TL;DR: 提出EroSeg-AT框架，通过EroSeg生成更具破坏性的对抗样本，利用像素级置信度选择敏感像素并逐步传播扰动，提升对抗训练的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型对对抗攻击脆弱，传统攻击方法仅关注全局语义信息，忽略上下文语义关系，限制了对抗训练效果。

Method: EroSeg框架：基于像素级置信度选取敏感像素，逐步向高置信度像素传播扰动，破坏样本语义一致性。

Result: 实验表明，相比现有方法，该方法显著提升攻击有效性，并增强模型在对抗训练下的鲁棒性。

Conclusion: EroSeg-AT通过引入更有效的对抗样本生成机制，显著提升了分割模型的对抗鲁棒性。

Abstract: Existing segmentation models exhibit significant vulnerability to adversarial attacks.To improve robustness, adversarial training incorporates adversarial examples into model training. However, existing attack methods consider only global semantic information and ignore contextual semantic relationships within the samples, limiting the effectiveness of adversarial training. To address this issue, we propose EroSeg-AT, a vulnerability-aware adversarial training framework that leverages EroSeg to generate adversarial examples. EroSeg first selects sensitive pixels based on pixel-level confidence and then progressively propagates perturbations to higher-confidence pixels, effectively disrupting the semantic consistency of the samples. Experimental results show that, compared to existing methods, our approach significantly improves attack effectiveness and enhances model robustness under adversarial training.

</details>


### [33] [TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models](https://arxiv.org/abs/2601.14951)
*Carolin Holtermann,Nina Krebs,Anne Lauscher*

Main category: cs.CV

TL;DR: 本文提出了TempViz，首个全面评估文本到图像（T2I）模型中时间知识的数据集，包含7.9k提示和600多张参考图像。通过该数据集，研究了五种T2I模型在五个时间知识类别中的表现，人类评估显示模型整体时间理解能力较弱，无一模型在所有类别中准确率超过75%。此外，研究还比较了多种自动化评估方法与人工判断的差异，发现现有方法均无法可靠评估时间线索，凸显未来在T2I模型中研究时间知识的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在处理时间相关视觉特征（如季节、时段）方面存在明显不足，尽管自然语言处理领域已有大量关于时间知识的研究，但针对T2I模型中时间现象的理解与建模仍十分匮乏，亟需系统性评估工具与深入研究。

Method: 构建TempViz数据集，涵盖7.9k具有时间语义的文本提示和对应参考图像；选取五种主流T2I模型进行测试，从五个维度评估其对时间知识的理解能力；结合人工评价与自动化评估方法，对比分析不同评估方式的有效性。

Result: 人类评估结果显示，所有模型在时间知识理解上表现有限，最高准确率未超过75%；自动化评估方法与人工判断存在显著偏差，无法有效反映模型的真实时间理解能力。

Conclusion: 目前的T2I模型在时间知识建模方面仍处于初级阶段，亟需开发更有效的评估框架与训练机制以提升模型对时间语义的理解与生成能力。

Abstract: Time alters the visual appearance of entities in our world, like objects, places, and animals. Thus, for accurately generating contextually-relevant images, knowledge and reasoning about time can be crucial (e.g., for generating a landscape in spring vs. in winter). Yet, although substantial work exists on understanding and improving temporal knowledge in natural language processing, research on how temporal phenomena appear and are handled in text-to-image (T2I) models remains scarce. We address this gap with TempViz, the first data set to holistically evaluate temporal knowledge in image generation, consisting of 7.9k prompts and more than 600 reference images. Using TempViz, we study the capabilities of five T2I models across five temporal knowledge categories. Human evaluation shows that temporal competence is generally weak, with no model exceeding 75% accuracy across categories. Towards larger-scale studies, we also examine automated evaluation methods, comparing several established approaches against human judgments. However, none of these approaches provides a reliable assessment of temporal cues - further indicating the pressing need for future research on temporal knowledge in T2I.

</details>


### [34] [Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers](https://arxiv.org/abs/2601.14959)
*Xinyu Peng,Han Li,Yuyang Huang,Ziyang Zheng,Yaoming Wang,Xin Chen,Wenrui Dai,Chenglin Li,Junni Zou,Hongkai Xiong*

Main category: cs.CV

TL;DR: LDF-VFI提出了一种视频中心的框架，通过自回归扩散Transformer建模整个视频序列，以实现长时序一致性。引入跳接拼接采样策略缓解误差累积问题，并结合稀疏局部注意力与分块VAE编码，支持任意空间分辨率（如4K）推理而无需重训练。增强的条件VAE解码器利用多尺度特征提升重建质量。实验表明，该方法在长序列基准测试中达到SOTA性能，尤其在大运动场景下表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧插值方法多采用帧中心范式，将视频分割为独立短片段处理，导致时间不一致性和运动伪影。为解决此问题，需要一种能够建模全局时间依赖性的视频级方法。

Method: 提出LDF-VFI框架，基于自回归扩散Transformer建模完整视频序列；设计跳接拼接采样策略减少误差累积；结合稀疏局部注意力与分块VAE编码提升效率与可扩展性；使用多尺度特征增强条件VAE解码器以改善重建质量。

Result: 在挑战性长序列基准上取得当前最优性能，显著提升单帧质量和时间一致性，特别是在大运动场景中表现优异。

Conclusion: LDF-VFI通过视频中心范式和创新模块设计，有效解决了传统方法中的时间不一致与误差累积问题，具备高精度、强泛化能力与高效推理特性，是视频帧插值领域的重要进展。

Abstract: Existing video frame interpolation (VFI) methods often adopt a frame-centric approach, processing videos as independent short segments (e.g., triplets), which leads to temporal inconsistencies and motion artifacts. To overcome this, we propose a holistic, video-centric paradigm named \textbf{L}ocal \textbf{D}iffusion \textbf{F}orcing for \textbf{V}ideo \textbf{F}rame \textbf{I}nterpolation (LDF-VFI). Our framework is built upon an auto-regressive diffusion transformer that models the entire video sequence to ensure long-range temporal coherence. To mitigate error accumulation inherent in auto-regressive generation, we introduce a novel skip-concatenate sampling strategy that effectively maintains temporal stability. Furthermore, LDF-VFI incorporates sparse, local attention and tiled VAE encoding, a combination that not only enables efficient processing of long sequences but also allows generalization to arbitrary spatial resolutions (e.g., 4K) at inference without retraining. An enhanced conditional VAE decoder, which leverages multi-scale features from the input video, further improves reconstruction fidelity. Empirically, LDF-VFI achieves state-of-the-art performance on challenging long-sequence benchmarks, demonstrating superior per-frame quality and temporal consistency, especially in scenes with large motion. The source code is available at https://github.com/xypeng9903/LDF-VFI.

</details>


### [35] [Unified Multi-Dataset Training for TBPS](https://arxiv.org/abs/2601.14978)
*Nilanjana Chatterjee,Sidharatha Garg,A V Subramanyam,Brejesh Lall*

Main category: cs.CV

TL;DR: 本文提出Scale-TBPS，旨在训练一个跨多个数据集的统一文本驱动行人搜索模型。针对现有方法因训练数据有限和视觉语言模型缺乏行人物体识别预训练导致的领域偏移问题，提出两种创新：(i) 噪声感知的统一数据集清洗策略，整合多样化的TBPS数据集；(ii) 可扩展的判别性身份学习框架，有效应对大量唯一身份。实验在多个数据集上验证了该模型优于独立优化模型与简单联合训练。


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动行人搜索（TBPS）受限于训练数据稀缺及视觉语言模型未针对行人识别进行预训练，导致需对每个数据集单独微调，形成多个独立模型。尽管合成数据可扩充训练规模，但无法避免数据集特异性适应。因此，亟需探索能否训练一个统一的跨数据集TBPS模型。

Method: 提出Scale-TBPS，包含两项核心技术：1）噪声感知的统一数据集清洗策略，通过筛选与融合多源数据集中的图像-文本对，减少噪声并增强一致性；2）可扩展的判别性身份学习框架，采用高效的特征学习机制，在面对海量唯一身份时仍保持性能稳定。

Result: 在CUHK-PEDES、ICFG-PEDES、RSTPReid、IIITD-20K和UFine6926等多个数据集上的实验表明，单一的Scale-TBPS模型在各项指标上均超越了针对各数据集优化的独立模型以及简单的联合训练模型，证明其卓越的泛化能力与统一建模潜力。

Conclusion: 本文成功验证了构建一个统一的跨数据集文本驱动行人搜索模型的可行性。Scale-TBPS通过噪声感知的数据整合与可扩展的身份学习机制，显著提升了模型的泛化性能，为未来大规模、通用化TBPS系统提供了新范式。

Abstract: Text-Based Person Search (TBPS) has seen significant progress with vision-language models (VLMs), yet it remains constrained by limited training data and the fact that VLMs are not inherently pre-trained for pedestrian-centric recognition. Existing TBPS methods therefore rely on dataset-centric fine-tuning to handle distribution shift, resulting in multiple independently trained models for different datasets. While synthetic data can increase the scale needed to fine-tune VLMs, it does not eliminate dataset-specific adaptation. This motivates a fundamental question: can we train a single unified TBPS model across multiple datasets? We show that naive joint training over all datasets remains sub-optimal because current training paradigms do not scale to a large number of unique person identities and are vulnerable to noisy image-text pairs. To address these challenges, we propose Scale-TBPS with two contributions: (i) a noise-aware unified dataset curation strategy that cohesively merges diverse TBPS datasets; and (ii) a scalable discriminative identity learning framework that remains effective under a large number of unique identities. Extensive experiments on CUHK-PEDES, ICFG-PEDES, RSTPReid, IIITD-20K, and UFine6926 demonstrate that a single Scale-TBPS model outperforms dataset-centric optimized models and naive joint training.

</details>


### [36] [SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation](https://arxiv.org/abs/2601.15017)
*Yanan Wang,Linjie Ren,Zihao Li,Junyi Wang,Tian Gan*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉线索的端到端空间音频生成框架，旨在解决现有视频到音频生成模型在空间感知和沉浸感方面的不足。作者构建了首个大规模视频-双耳音频数据集BinauralVGGSound，以支持空间感知的视频到音频生成，并引入视觉引导的音频空间化模块，使生成的音频具备真实的空间属性和层次化深度，同时保持语义和时间一致性。实验表明，该方法在空间保真度上显著优于现有先进模型，提供了更沉浸的听觉体验。所有数据集、代码和模型检查点将公开发布。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成研究主要关注语义和时间对齐，但忽视了空间感知和沉浸感。这主要是因为当前模型依赖单声道音频数据集，缺乏双耳空间信息来学习视觉到空间音频的映射关系。

Method: 构建大规模视频-双耳音频数据集BinauralVGGSound；提出一种基于视觉线索的端到端空间音频生成框架，包含视觉引导的音频空间化模块，显式建模空间特征，确保生成音频具有真实的空间属性和层次化深度。

Result: 所提方法在空间保真度上显著优于现有最先进的模型，同时保持良好的语义和时间一致性，提供更沉浸的听觉体验。

Conclusion: 通过构建BinauralVGGSound数据集并提出视觉引导的空间音频生成框架，本研究有效提升了视频到音频生成中的空间感知能力，为未来空间感知音频生成研究奠定了基础。

Abstract: While video-to-audio generation has achieved remarkable progress in semantic and temporal alignment, most existing studies focus solely on these aspects, paying limited attention to the spatial perception and immersive quality of the synthesized audio. This limitation stems largely from current models' reliance on mono audio datasets, which lack the binaural spatial information needed to learn visual-to-spatial audio mappings. To address this gap, we introduce two key contributions: we construct BinauralVGGSound, the first large-scale video-binaural audio dataset designed to support spatially aware video-to-audio generation; and we propose a end-to-end spatial audio generation framework guided by visual cues, which explicitly models spatial features. Our framework incorporates a visual-guided audio spatialization module that ensures the generated audio exhibits realistic spatial attributes and layered spatial depth while maintaining semantic and temporal alignment. Experiments show that our approach substantially outperforms state-of-the-art models in spatial fidelity and delivers a more immersive auditory experience, without sacrificing temporal or semantic consistency. All datasets, code, and model checkpoints will be publicly released to facilitate future research.

</details>


### [37] [Deep Leakage with Generative Flow Matching Denoiser](https://arxiv.org/abs/2601.15049)
*Isaac Baglin,Xiatian Zhu,Simon Hadfield*

Main category: cs.CV

TL;DR: 本文提出一种基于流匹配（Flow Matching）先验的新型深度泄漏（DL）攻击方法，通过利用生成式模型引导优化过程，显著提升私有数据重建的保真度，且无需了解私有数据分布。该方法在多个数据集和目标模型上均优于现有最先进攻击，在不同训练阶段、客户端批量大小及常见防御措施（如噪声注入、裁剪、稀疏化）下仍保持有效性，凸显了当前联邦学习安全性的薄弱环节，呼吁开发更先进的防御策略以应对具备强大生成先验的攻击者。


<details>
  <summary>Details</summary>
Motivation: 现有深度泄漏攻击在真实联邦学习场景中存在稳定性差、重建保真度低、鲁棒性不足等问题，亟需更高效、稳健的攻击方法以揭示系统漏洞，推动安全防御研究。

Method: 将生成式流匹配（FM）先验融入数据重建过程，利用预训练的流匹配基础模型引导优化方向，使重建结果更接近真实图像分布，从而提升重建质量，同时不依赖对私有数据的先验知识。

Result: 实验表明，该方法在像素级、感知和特征级相似性指标上全面超越现有最先进攻击；在不同训练轮次、客户端批量大小以及噪声注入、裁剪、稀疏化等防御机制下仍表现优异，证明其高度鲁棒性和实用性。

Conclusion: 本研究揭示了当前联邦学习在面对具备强大生成先验的攻击时存在严重安全隐患，强调必须发展新型防御机制来应对此类威胁，尤其需要考虑生成模型在攻击中的潜在作用。

Abstract: Federated Learning (FL) has emerged as a powerful paradigm for decentralized model training, yet it remains vulnerable to deep leakage (DL) attacks that reconstruct private client data from shared model updates. While prior DL methods have demonstrated varying levels of success, they often suffer from instability, limited fidelity, or poor robustness under realistic FL settings. We introduce a new DL attack that integrates a generative Flow Matching (FM) prior into the reconstruction process. By guiding optimization toward the distribution of realistic images (represented by a flow matching foundation model), our method enhances reconstruction fidelity without requiring knowledge of the private data. Extensive experiments on multiple datasets and target models demonstrate that our approach consistently outperforms state-of-the-art attacks across pixel-level, perceptual, and feature-based similarity metrics. Crucially, the method remains effective across different training epochs, larger client batch sizes, and under common defenses such as noise injection, clipping, and sparsification. Our findings call for the development of new defense strategies that explicitly account for adversaries equipped with powerful generative priors.

</details>


### [38] [Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD](https://arxiv.org/abs/2601.15061)
*Qiwei Ma,Jun Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的差分隐私生成框架，结合误差反馈随机梯度下降（EFSGD）方法，引入重建损失和噪声注入机制，在保持相同隐私预算的情况下，生成了质量更高、实用性更强的合成图像。实验表明该框架在MNIST、Fashion-MNIST和CelebA三个基准数据集上均取得了接近最优的性能，有效平衡了隐私与数据可用性之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 传统数据掩蔽技术如匿名化难以在保障数据可用性的同时实现理想的隐私保护，现有合成数据方法在隐私与实用性的权衡上存在反复调整的问题，亟需一种更高效且能同时兼顾两者的新方法。

Method: 提出基于误差反馈随机梯度下降（EFSGD）的差分隐私生成框架，引入重建损失和噪声注入机制，优化合成数据的生成过程，以在有限隐私预算下提升数据质量与实用性。

Result: 在相同隐私预算条件下，生成的图像在质量和可用性方面优于现有方法；在MNIST、Fashion-MNIST和CelebA三个数据集上，几乎所有评估指标均达到或接近当前最优水平。

Conclusion: 所提出的框架有效解决了隐私与数据可用性之间的权衡问题，具有良好的泛化能力，为隐私保护机器学习中的合成数据生成提供了新思路。

Abstract: Traditional data masking techniques such as anonymization cannot achieve the expected privacy protection while ensuring data utility for privacy-preserving machine learning. Synthetic data plays an increasingly important role as it generates a large number of training samples and prevents information leakage in real data. The existing methods suffer from the repeating trade-off processes between privacy and utility. We propose a novel framework for differential privacy generation, which employs an Error Feedback Stochastic Gradient Descent(EFSGD) method and introduces a reconstruction loss and noise injection mechanism into the training process. We generate images with higher quality and usability under the same privacy budget as the related work. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both grayscale and RGB images. We achieve state-of-the-art results over almost all metrics on three benchmarks: MNIST, Fashion-MNIST, and CelebA.

</details>


### [39] [Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background](https://arxiv.org/abs/2601.15065)
*Tianyu Li,Songyue Cai,Zongqian Wu,Ping Hu,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: 本文提出一种新的即插即用框架FoBoR，用于改进基于CLIP的前景-背景（FG-BG）分解方法在少样本分布外（OOD）检测中的性能。针对现有方法中对背景区域采用统一抑制策略、忽视各补丁贡献差异，以及对前景区域中可能与其它类别相似的局部补丁未充分处理的问题，引入自适应背景抑制模块和可混淆前景修正模块，有效提升模型表现。实验表明该框架显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的前景-背景分解方法在少样本分布外检测中虽有效，但仍存在两个主要问题：一是对背景区域采用统一抑制策略，忽略了不同补丁对预测的贡献差异；二是对前景区域中与其它类别外观或语义相似的局部补丁缺乏关注，可能误导训练过程。

Method: 提出一个三组件即插即用框架：(1) 前景-背景分解模块，用于分离图像的前景与背景区域；(2) 自适应背景抑制模块，通过加权补丁分类熵实现差异化抑制；(3) 可混淆前景修正模块，识别并修正易混淆的前景补丁。

Result: 在多个基准数据集上的大量实验表明，所提框架显著提升了现有FG-BG分解方法在少样本OOD检测任务中的性能，验证了其有效性与通用性。

Conclusion: 本文提出的FoBoR框架通过自适应背景抑制与可混淆前景修正机制，有效缓解了现有方法在前景-背景分解中的关键缺陷，为少样本分布外检测提供了更优解决方案。代码已开源。

Abstract: CLIP-based foreground-background (FG-BG) decomposition methods have demonstrated remarkable effectiveness in improving few-shot out-of-distribution (OOD) detection performance. However, existing approaches still suffer from several limitations. For background regions obtained from decomposition, existing methods adopt a uniform suppression strategy for all patches, overlooking the varying contributions of different patches to the prediction. For foreground regions, existing methods fail to adequately consider that some local patches may exhibit appearance or semantic similarity to other classes, which may mislead the training process. To address these issues, we propose a new plug-and-play framework. This framework consists of three core components: (1) a Foreground-Background Decomposition module, which follows previous FG-BG methods to separate an image into foreground and background regions; (2) an Adaptive Background Suppression module, which adaptively weights patch classification entropy; and (3) a Confusable Foreground Rectification module, which identifies and rectifies confusable foreground patches. Extensive experimental results demonstrate that the proposed plug-and-play framework significantly improves the performance of existing FG-BG decomposition methods. Code is available at: https://github.com/lounwb/FoBoR.

</details>


### [40] [Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction](https://arxiv.org/abs/2601.15098)
*Yipeng Yin,Rao Yao,Qingying Li,Dazhong Wang,Hong Zhou,Zhijun Fang,Jianing Chen,Longjie Qian,Mingyue Wu*

Main category: cs.CV

TL;DR: 本文综述了微焦点CT技术在工业超精密检测中实现高精度与高效3D缺陷表征的最新进展，重点分析了从解析重建到深度学习的CT重建算法演进，以及体积渲染、加速计算和数据压缩等关键技术的优化。文章还探讨了先进光照模型在提升渲染真实感与效率方面的作用，并展望了未来基于数字孪生与虚实交互的实时在线监测方向，为结构健康监测提供新思路。


<details>
  <summary>Details</summary>
Motivation: 随着微焦点CT技术的发展，工业超精密检测产生海量数据，亟需解决3D缺陷表征中精度与效率之间的矛盾，以支持实时在线监测与数字孪生应用。

Method: 系统性回顾与分析现有CT重建算法（从传统解析方法到深度学习）及体积渲染技术，比较其原理与性能，结合微结构技术发展，评估各方法在精度与效率间的平衡。

Result: 梳理出一批兼具高精度与高效率的3D重建与可视化方法，揭示了深度学习与先进渲染技术在提升处理速度与图像质量方面的显著优势，明确了当前技术瓶颈与可优化路径。

Conclusion: 未来研究应聚焦于融合深度学习与物理模型的智能重建方法，结合虚实交互与数字孪生，推动材料内部缺陷的实时、高保真在线监测，助力结构健康监测的智能化发展。

Abstract: As Micro-CT technology continues to refine its characterization of material microstructures, industrial CT ultra-precision inspection is generating increasingly large datasets, necessitating solutions to the trade-off between accuracy and efficiency in the 3D characterization of defects during ultra-precise detection. This article provides a unique perspective on recent advances in accurate and efficient 3D visualization using Micro-CT, tracing its evolution from medical imaging to industrial non-destructive testing (NDT). Among the numerous CT reconstruction and volume rendering methods, this article selectively reviews and analyzes approaches that balance accuracy and efficiency, offering a comprehensive analysis to help researchers quickly grasp highly efficient and accurate 3D reconstruction methods for microscopic features. By comparing the principles of computed tomography with advancements in microstructural technology, this article examines the evolution of CT reconstruction algorithms from analytical methods to deep learning techniques, as well as improvements in volume rendering algorithms, acceleration, and data reduction. Additionally, it explores advanced lighting models for high-accuracy, photorealistic, and efficient volume rendering. Furthermore, this article envisions potential directions in CT reconstruction and volume rendering. It aims to guide future research in quickly selecting efficient and precise methods and developing new ideas and approaches for real-time online monitoring of internal material defects through virtual-physical interaction, for applying digital twin model to structural health monitoring (SHM).

</details>


### [41] [PROGRESSLM: Towards Progress Reasoning in Vision-Language Models](https://arxiv.org/abs/2601.15224)
*Jianshu Zhang,Chengxuan Qian,Haosen Sun,Haoran Lu,Dingcheng Wang,Letian Xue,Han Liu*

Main category: cs.CV

TL;DR: 本文提出Progress-Bench基准，用于系统评估视觉语言模型（VLMs）在任务进度推理方面的能力。研究发现，大多数VLMs尚不具备有效的任务进度估计能力，对演示模态和视角变化敏感，且难以处理无法回答的情况。通过基于ProgressLM-45K数据集的训练式方法，尤其是小规模的ProgressLM-3B模型，实现了稳定的性能提升，而无需依赖与评估任务重叠的训练数据。分析揭示了典型错误模式，明确了进度推理成功或失败的关键因素。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型虽擅长描述静态视觉内容，但在长时序动态推理中表现不足，尤其在从部分观察中推断任务进度方面能力有限。因此需要一个系统性的评估框架来检验模型的进度推理能力，并探索有效的方法以提升其性能。

Method: 引入Progress-Bench基准，采用无训练提示（training-free prompting）和基于数据集ProgressLM-45K的训练式方法（如ProgressLM-3B），对14种VLMs进行评估与改进。

Result: 多数VLMs在任务进度估计上表现不佳，对模态和视角变化敏感，且无法有效处理未回答情况；训练式方法（ProgressLM-3B）在小规模下仍取得一致提升，优于无训练提示方法；分析揭示出特定错误模式及推理成败的关键条件。

Conclusion: 现有VLMs尚未充分具备任务进度推理能力，但通过合理的训练策略可显著提升性能。未来工作应聚焦于增强模型对动态过程的理解与鲁棒性。

Abstract: Estimating task progress requires reasoning over long-horizon dynamics rather than recognizing static visual content. While modern Vision-Language Models (VLMs) excel at describing what is visible, it remains unclear whether they can infer how far a task has progressed from partial observations. To this end, we introduce Progress-Bench, a benchmark for systematically evaluating progress reasoning in VLMs. Beyond benchmarking, we further explore a human-inspired two-stage progress reasoning paradigm through both training-free prompting and training-based approach based on curated dataset ProgressLM-45K. Experiments on 14 VLMs show that most models are not yet ready for task progress estimation, exhibiting sensitivity to demonstration modality and viewpoint changes, as well as poor handling of unanswerable cases. While training-free prompting that enforces structured progress reasoning yields limited and model-dependent gains, the training-based ProgressLM-3B achieves consistent improvements even at a small model scale, despite being trained on a task set fully disjoint from the evaluation tasks. Further analyses reveal characteristic error patterns and clarify when and why progress reasoning succeeds or fails.

</details>


### [42] [Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning](https://arxiv.org/abs/2601.15115)
*Shuonan Yang,Yuchen Zhang,Zeyu Fu*

Main category: cs.CV

TL;DR: MARS是一个无需训练的多阶段对抗性推理框架，用于可靠且可解释地检测仇恨视频。它通过中立的内容描述开始，随后基于证据进行支持仇恨解读的推理，并同时考虑反证据以捕捉非仇恨视角，最终综合得出可解释的结论。在两个真实数据集上的实验表明，MARS相比其他无需训练的方法最多提升10%，并在一个数据集上超越了最先进的有训练方法。此外，MARS生成人类可理解的解释，有助于合规监督和内容审核透明化。


<details>
  <summary>Details</summary>
Motivation: 现有基于训练的仇恨视频检测方法受限于训练数据不足和缺乏可解释性；而直接提示大型视觉-语言模型又难以保证可靠的仇恨检测效果。因此需要一种无需训练、兼具可靠性与可解释性的新方法。

Method: MARS采用多阶段对抗性推理：首先对视频内容进行客观描述，建立中立基础；接着分别构建支持仇恨解读的证据推理和反驳该解读的反证据推理；最后将两种视角融合，形成可解释的最终判断。

Result: MARS在两个真实世界数据集上表现出色，相较于其他无需训练的方法性能最高提升达10%，并在一个数据集上优于最先进的有训练方法。同时，其输出具有高度可解释性，能生成人类可理解的推理理由。

Conclusion: MARS为仇恨视频检测提供了一种高效、可靠且透明的解决方案，既克服了传统方法的数据依赖与不可解释性问题，又避免了大模型直接提示带来的不稳定性，适用于实际内容安全治理场景。

Abstract: Hateful videos pose serious risks by amplifying discrimination, inciting violence, and undermining online safety. Existing training-based hateful video detection methods are constrained by limited training data and lack of interpretability, while directly prompting large vision-language models often struggle to deliver reliable hate detection. To address these challenges, this paper introduces MARS, a training-free Multi-stage Adversarial ReaSoning framework that enables reliable and interpretable hateful content detection. MARS begins with the objective description of video content, establishing a neutral foundation for subsequent analysis. Building on this, it develops evidence-based reasoning that supports potential hateful interpretations, while in parallel incorporating counter-evidence reasoning to capture plausible non-hateful perspectives. Finally, these perspectives are synthesized into a conclusive and explainable decision. Extensive evaluation on two real-world datasets shows that MARS achieves up to 10% improvement under certain backbones and settings compared to other training-free approaches and outperforms state-of-the-art training-based methods on one dataset. In addition, MARS produces human-understandable justifications, thereby supporting compliance oversight and enhancing the transparency of content moderation workflows. The code is available at https://github.com/Multimodal-Intelligence-Lab-MIL/MARS.

</details>


### [43] [BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation](https://arxiv.org/abs/2601.15123)
*Andrey Moskalenko,Danil Kuznetsov,Irina Dudko,Anastasiia Iasakova,Nikita Boldyrev,Denis Shepelev,Andrei Spiridonov,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.CV

TL;DR: 本文研究了提示可分割模型（如SAM）在自然变化的边界框提示下的鲁棒性。通过用户实证研究收集真实边界框标注，发现同一模型和实例下不同用户的分割质量差异显著，表明模型对自然提示噪声敏感。为高效评估鲁棒性，提出BREPS方法，将鲁棒性评估转化为白盒优化问题，生成符合自然性的对抗性边界框以最小化或最大化分割误差。在10个数据集上对当前最先进模型进行基准测试，涵盖日常场景到医学影像。


<details>
  <summary>Details</summary>
Motivation: 现有训练和评估协议依赖于简单的启发式合成提示，无法充分反映真实世界中的鲁棒性；需要更贴近实际用户输入的评估方式，以揭示模型对自然提示变异的敏感性。

Method: 1. 通过受控用户研究收集数千个真实边界框标注；2. 将鲁棒性评估建模为白盒优化问题，在边界框空间中寻找对抗性提示；3. 提出BREPS方法，生成既自然又极端的对抗性边界框，用于评估模型性能极限。

Result: 实验表明SAM类模型对自然提示噪声高度敏感；BREPS能有效生成具有挑战性的对抗性边界框；在10个数据集上的基准测试揭示了现有模型在面对真实用户输入时的性能瓶颈。

Conclusion: 提示可分割模型虽在合成提示下表现优异，但在真实用户输入下鲁棒性不足。BREPS提供了一种有效的评估框架，有助于推动更鲁棒的模型设计与训练策略。

Abstract: Promptable segmentation models such as SAM have established a powerful paradigm, enabling strong generalization to unseen objects and domains with minimal user input, including points, bounding boxes, and text prompts. Among these, bounding boxes stand out as particularly effective, often outperforming points while significantly reducing annotation costs. However, current training and evaluation protocols typically rely on synthetic prompts generated through simple heuristics, offering limited insight into real-world robustness. In this paper, we investigate the robustness of promptable segmentation models to natural variations in bounding box prompts. First, we conduct a controlled user study and collect thousands of real bounding box annotations. Our analysis reveals substantial variability in segmentation quality across users for the same model and instance, indicating that SAM-like models are highly sensitive to natural prompt noise. Then, since exhaustive testing of all possible user inputs is computationally prohibitive, we reformulate robustness evaluation as a white-box optimization problem over the bounding box prompt space. We introduce BREPS, a method for generating adversarial bounding boxes that minimize or maximize segmentation error while adhering to naturalness constraints. Finally, we benchmark state-of-the-art models across 10 datasets, spanning everyday scenes to medical imaging. Code - https://github.com/emb-ai/BREPS.

</details>


### [44] [Graph Recognition via Subgraph Prediction](https://arxiv.org/abs/2601.15133)
*André Eberhard,Gerhard Neumann,Pascal Friederich*

Main category: cs.CV

TL;DR: 本文提出了一种名为GraSP（Graph Recognition via Subgraph Prediction）的方法，用于图像中的视觉图识别。该方法具有广泛的适用性和简单性，能够在多种类型的图及其绘制形式上表现良好，并且可以无需任务特定修改即可在不同任务间迁移，为视觉图识别提供了一个更统一的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉图识别方法大多针对特定问题设计，缺乏通用性，无法在不同上下文之间直接迁移，即使概念上问题相同。因此，需要一种更具普适性和简洁性的方法来解决这一挑战。

Method: 提出GraSP方法，通过子图预测来实现图像中图的识别。该方法不依赖于特定任务的调整，具备良好的跨任务迁移能力。

Result: 在多个合成基准和一个真实世界应用中，GraSP方法展示了对多种类型图及其绘制形式的有效识别能力，并能无须任务特定修改地在不同任务间转移，验证了其广泛适用性和有效性。

Conclusion: GraSP为视觉图识别提供了一个统一且可迁移的框架，解决了现有方法缺乏通用性的问题，推动了该领域的进一步发展。

Abstract: Despite tremendous improvements in tasks such as image classification, object detection, and segmentation, the recognition of visual relationships, commonly modeled as the extraction of a graph from an image, remains a challenging task. We believe that this mainly stems from the fact that there is no canonical way to approach the visual graph recognition task. Most existing solutions are specific to a problem and cannot be transferred between different contexts out-of-the box, even though the conceptual problem remains the same. With broad applicability and simplicity in mind, in this paper we develop a method, \textbf{Gra}ph Recognition via \textbf{S}ubgraph \textbf{P}rediction (\textbf{GraSP}), for recognizing graphs in images. We show across several synthetic benchmarks and one real-world application that our method works with a set of diverse types of graphs and their drawings, and can be transferred between tasks without task-specific modifications, paving the way to a more unified framework for visual graph recognition.

</details>


### [45] [BBoxMaskPose v2: Expanding Mutual Conditioning to 3D](https://arxiv.org/abs/2601.15200)
*Miroslav Purkrabek,Constantin Kolomiiets,Jiri Matas*

Main category: cs.CV

TL;DR: PMPose引入概率建模和掩码条件化，提升拥挤场景下的2D人体姿态估计；BBoxMaskPose v2（BMPv2）结合PMPose与改进的SAM掩码精修模块，在COCO上超越当前最优1.5 AP，OCHuman上提升6 AP，首次在OCHuman上突破50 AP。实验表明，2D姿态精度对3D姿态估计有显著影响，且多人体性能更依赖于姿态预测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有2D人体姿态估计基准已趋于饱和，尤其在拥挤场景中仍存在挑战。需要更精确的模型来处理重叠和遮挡情况，同时保持在标准场景中的高性能。

Method: 提出PMPose，采用概率公式和掩码条件化机制；构建BBoxMaskPose v2（BMPv2），集成PMPose与增强的基于SAM的掩码精修模块，实现更优的密集人群姿态估计。

Result: BMPv2在COCO上提升1.5 AP，OCHuman上提升6 AP，首次在OCHuman上超过50 AP；2D姿态质量提升显著促进3D姿态估计性能；多人体姿态估计对姿态预测精度更为敏感。

Conclusion: BMPv2在密集人群场景中实现了显著的性能突破，验证了高质量2D姿态估计对3D姿态任务的积极影响，且其方法可推广至其他复杂场景下的姿态分析任务。

Abstract: Most 2D human pose estimation benchmarks are nearly saturated, with the exception of crowded scenes. We introduce PMPose, a top-down 2D pose estimator that incorporates the probabilistic formulation and the mask-conditioning. PMPose improves crowded pose estimation without sacrificing performance on standard scenes. Building on this, we present BBoxMaskPose v2 (BMPv2) integrating PMPose and an enhanced SAM-based mask refinement module. BMPv2 surpasses state-of-the-art by 1.5 average precision (AP) points on COCO and 6 AP points on OCHuman, becoming the first method to exceed 50 AP on OCHuman. We demonstrate that BMP's 2D prompting of 3D model improves 3D pose estimation in crowded scenes and that advances in 2D pose quality directly benefit 3D estimation. Results on the new OCHuman-Pose dataset show that multi-person performance is more affected by pose prediction accuracy than by detection. The code, models, and data are available on https://MiraPurkrabek.github.io/BBox-Mask-Pose/.

</details>


### [46] [A Computer Vision Hybrid Approach: CNN and Transformer Models for Accurate Alzheimer's Detection from Brain MRI Scans](https://arxiv.org/abs/2601.15202)
*Md Mahmudul Hoque,Shuvo Karmaker,Md. Hadi Al-Amin,Md Modabberul Islam,Jisun Junayed,Farha Ulfat Mahi*

Main category: cs.CV

TL;DR: 本研究对比分析了五种CNN架构（EfficientNetB0, ResNet50, DenseNet201, MobileNetV3, VGG16）、五种基于Transformer的模型（ViT, ConvTransformer, PatchTransformer, MLP-Mixer, SimpleTransformer）以及一种提出的混合模型Evan_V2，用于四类阿尔茨海默病分类任务（轻度痴呆、中度痴呆、非痴呆、极轻度痴呆）。实验结果显示，CNN模型表现稳健，其中ResNet50达到98.83%准确率；Transformer模型具有良好的泛化能力，其中ViT表现最佳，为95.38%。而所提出的Evan_V2混合模型通过特征级融合十种模型输出，取得最佳性能：99.99%准确率、0.9989 F1分数和0.9968 ROC AUC，显著降低各阶段痴呆的误分类，优于所有独立模型。


<details>
  <summary>Details</summary>
Motivation: 早期准确地从脑部MRI扫描中分类阿尔茨海默病对及时临床干预和改善患者预后至关重要。现有方法在模型稳定性与分类精度方面仍存在不足，尤其在不同痴呆阶段的区分上表现不稳定，因此亟需更可靠、高精度的诊断工具。

Method: 采用五种主流CNN架构和五种Transformer模型进行训练与评估，并提出一种新型混合模型Evan_V2，通过特征级融合来自十个基础模型的输出，实现多模型协同决策。所有模型均在四类阿尔茨海默病分类任务上进行测试，使用标准指标如准确率、F1分数、ROC AUC进行性能评估，并结合混淆矩阵分析误分类情况。

Result: ResNet50在所有单独模型中表现最佳，准确率达98.83%；ViT作为最优秀的Transformer模型，达到95.38%准确率，但存在类间不稳定性；而提出的Evan_V2混合模型在各项指标上全面领先，达到99.99%准确率、0.9989 F1分数和0.9968 ROC AUC，且混淆矩阵显示其显著减少各类痴呆阶段的误分类。

Conclusion: 混合集成策略，特别是基于特征级融合的Evan_V2模型，在阿尔茨海默病的多类别分类中展现出卓越的性能与鲁棒性，具备成为高可靠性、临床可用诊断工具的巨大潜力。

Abstract: Early and accurate classification of Alzheimers disease (AD) from brain MRI scans is essential for timely clinical intervention and improved patient outcomes. This study presents a comprehensive comparative analysis of five CNN architectures (EfficientNetB0, ResNet50, DenseNet201, MobileNetV3, VGG16), five Transformer-based models (ViT, ConvTransformer, PatchTransformer, MLP-Mixer, SimpleTransformer), and a proposed hybrid model named Evan_V2. All models were evaluated on a four-class AD classification task comprising Mild Dementia, Moderate Dementia, Non-Demented, and Very Mild Dementia categories. Experimental findings show that CNN architectures consistently achieved strong performance, with ResNet50 attaining 98.83% accuracy. Transformer models demonstrated competitive generalization capabilities, with ViT achieving the highest accuracy among them at 95.38%. However, individual Transformer variants exhibited greater class-specific instability. The proposed Evan_V2 hybrid model, which integrates outputs from ten CNN and Transformer architectures through feature-level fusion, achieved the best overall performance with 99.99% accuracy, 0.9989 F1-score, and 0.9968 ROC AUC. Confusion matrix analysis further confirmed that Evan_V2 substantially reduced misclassification across all dementia stages, outperforming every standalone model. These findings highlight the potential of hybrid ensemble strategies in producing highly reliable and clinically meaningful diagnostic tools for Alzheimers disease classification.

</details>


### [47] [ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation](https://arxiv.org/abs/2601.15221)
*Hanlei Guo,Jiahao Shao,Xinya Chen,Xiyang Tan,Sheng Miao,Yujun Shen,Yiyi Liao*

Main category: cs.CV

TL;DR: ScenDi提出一种结合3D和2D扩散模型的都市场景生成方法，通过3D高斯溅射生成粗略场景并控制相机轨迹，再利用2D视频扩散模型增强细节，实现高质量、可控的都市场景生成。


<details>
  <summary>Details</summary>
Motivation: 现有3D扩散模型在生成真实感都市场景时细节不足，而仅使用2D扩散模型则难以控制相机视角，因此需要一种结合两者优势的方法以提升生成质量与可控性。

Method: 首先训练一个3D潜伏扩散模型生成3D高斯点云，并支持基于3D边界框、道路地图或文本提示的条件生成；随后训练一个2D视频扩散模型，以3D高斯渲染图像为条件，增强外观细节，从而实现基于输入条件的精确相机轨迹遵循和高质量场景生成。

Result: 在Waymo和KITTI-360两个真实世界数据集上的实验表明，ScenDi能够生成具有丰富细节且符合相机轨迹的逼真都市场景，显著优于单一3D或2D方法。

Conclusion: ScenDi通过融合3D与2D扩散模型，有效解决了都市场景生成中细节与可控性的矛盾，为复杂场景合成提供了新范式。

Abstract: Recent advancements in 3D object generation using diffusion models have achieved remarkable success, but generating realistic 3D urban scenes remains challenging. Existing methods relying solely on 3D diffusion models tend to suffer a degradation in appearance details, while those utilizing only 2D diffusion models typically compromise camera controllability. To overcome this limitation, we propose ScenDi, a method for urban scene generation that integrates both 3D and 2D diffusion models. We first train a 3D latent diffusion model to generate 3D Gaussians, enabling the rendering of images at a relatively low resolution. To enable controllable synthesis, this 3DGS generation process can be optionally conditioned by specifying inputs such as 3d bounding boxes, road maps, or text prompts. Then, we train a 2D video diffusion model to enhance appearance details conditioned on rendered images from the 3D Gaussians. By leveraging the coarse 3D scene as guidance for 2D video diffusion, ScenDi generates desired scenes based on input conditions and successfully adheres to accurate camera trajectories. Experiments on two challenging real-world datasets, Waymo and KITTI-360, demonstrate the effectiveness of our approach.

</details>


### [48] [Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification](https://arxiv.org/abs/2601.15235)
*Fabi Nahian Madhurja,Rusab Sarmun,Muhammad E. H. Chowdhury,Adam Mushtak,Israa Al-Hashimi,Sohaib Bassam Zoghoul*

Main category: cs.CV

TL;DR: 本研究提出一种基于2D投影的椎体分割方法，用于3D CT影像中颈椎（C1-C7）的骨折检测。通过优化的轴向、矢状和冠状面2D投影，结合YOLOv8模型定位感兴趣区域，并利用DenseNet121-Unet进行多标签分割，实现94.45%的3D mIoU和87.86%的Dice分数。后续采用2.5D时空模型对单个椎体进行骨折分析，取得椎体级和患者级分别为68.15%和82.26%的F1分数，以及91.62%和83.04%的ROC-AUC。此外，通过可解释性分析与放射科医生对比验证了模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 颈椎骨折需快速准确识别以保障临床治疗效果，传统3D分割方法计算复杂度高，亟需高效且精准的替代方案。

Method: 采用2D投影近似3D体积，通过YOLOv8在三个视图中定位区域，结合DenseNet121-Unet进行多标签分割；再通过2.5D时空模型融合原始切片与投影信息进行骨折检测。

Result: 3D mIoU达94.45%，Dice分数为87.86%，椎体级F1为68.15%，患者级F1为82.26%，ROC-AUC分别为91.62%和83.04%；可解释性分析显示模型关注关键解剖区域，性能与专家相当。

Conclusion: 该基于2D投影的端到端框架显著降低计算开销，同时保持高精度，在颈椎骨折自动检测中表现优异，具备临床应用潜力。

Abstract: Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results.

</details>


### [49] [FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion](https://arxiv.org/abs/2601.15250)
*Zichen Xi,Hao-Xiang Chen,Nan Xue,Hongyu Yan,Qi-Yuan Feng,Levent Burak Kara,Joaquim Jorge,Qun-Ce Xu*

Main category: cs.CV

TL;DR: FlowSSC is a novel generative framework for monocular semantic scene completion that uses a single-step shortcut flow-matching approach in a compact triplane latent space, achieving state-of-the-art performance and real-time inference, ideal for autonomous systems.


<details>
  <summary>Details</summary>
Motivation: Semantic Scene Completion (SSC) from monocular RGB images is challenging due to the ambiguity in inferring occluded 3D geometry from a single view. Existing feed-forward methods often fail to generate plausible details in occluded regions and preserve spatial relationships of objects, which are crucial for real-world applications.

Method: FlowSSC treats SSC as a conditional generation problem and integrates with existing feed-forward methods. It introduces Shortcut Flow-matching in a compact triplane latent space, enabling high-fidelity generation in a single step, thus achieving real-time inference without sacrificing quality.

Result: Extensive experiments on SemanticKITTI show that FlowSSC achieves state-of-the-art performance, significantly outperforming existing baselines.

Conclusion: FlowSSC is the first generative framework applied directly to monocular semantic scene completion, offering high-fidelity, real-time generation by leveraging a shortcut flow-matching mechanism in a compact latent space, making it suitable for practical deployment in autonomous systems.

Abstract: Semantic Scene Completion (SSC) from monocular RGB images is a fundamental yet challenging task due to the inherent ambiguity of inferring occluded 3D geometry from a single view. While feed-forward methods have made progress, they often struggle to generate plausible details in occluded regions and preserve the fundamental spatial relationships of objects. Such accurate generative reasoning capability for the entire 3D space is critical in real-world applications. In this paper, we present FlowSSC, the first generative framework applied directly to monocular semantic scene completion. FlowSSC treats the SSC task as a conditional generation problem and can seamlessly integrate with existing feed-forward SSC methods to significantly boost their performance. To achieve real-time inference without compromising quality, we introduce Shortcut Flow-matching that operates in a compact triplane latent space. Unlike standard diffusion models that require hundreds of steps, our method utilizes a shortcut mechanism to achieve high-fidelity generation in a single step, enabling practical deployment in autonomous systems. Extensive experiments on SemanticKITTI demonstrate that FlowSSC achieves state-of-the-art performance, significantly outperforming existing baselines.

</details>


### [50] [DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration](https://arxiv.org/abs/2601.15260)
*Dominik Rößle,Xujun Xie,Adithya Mohan,Venkatesh Thirugnana Sambandham,Daniel Cremers,Torsten Schön*

Main category: cs.CV

TL;DR: DrivIng is a large-scale multimodal dataset with a high-fidelity digital twin of an 18 km route, featuring synchronized RGB cameras, LiDAR, and precise localization across day/night/dusk. It includes 1.2 million 3D annotations at 10 Hz for 12 object classes, enabling sim-to-real evaluation, edge-case testing, and realistic scenario simulation. The dataset supports reproducible research through public release of data, HD map, digital twin, and code.


<details>
  <summary>Details</summary>
Motivation: Existing perception datasets lack high-fidelity digital twins, limiting systematic testing, edge-case simulation, sensor modification, and sim-to-real validation. A comprehensive digital twin is needed to bridge real-world driving and simulation.

Method: DrivIng collects continuous multimodal data (6 RGB cameras, 1 LiDAR, ADMA localization) over 18 km urban/suburban/highway routes across different times of day. Data is geo-referenced and annotated at 10 Hz with 3D bounding boxes and track IDs. A complete digital twin enables 1-to-1 transfer of real traffic into simulation while preserving agent interactions.

Result: The dataset contains ~1.2 million annotated instances across 12 classes. It enables realistic scenario testing, sim-to-real evaluation, sensor variation studies, and robust benchmarking of state-of-the-art perception models.

Conclusion: DrivIng provides a rich, scalable, and reproducible resource for autonomous driving perception research, with a fully realized digital twin that bridges real-world data and simulation for more reliable and flexible development and validation.

Abstract: Perception is a cornerstone of autonomous driving, enabling vehicles to understand their surroundings and make safe, reliable decisions. Developing robust perception algorithms requires large-scale, high-quality datasets that cover diverse driving conditions and support thorough evaluation. Existing datasets often lack a high-fidelity digital twin, limiting systematic testing, edge-case simulation, sensor modification, and sim-to-real evaluations. To address this gap, we present DrivIng, a large-scale multimodal dataset with a complete geo-referenced digital twin of a ~18 km route spanning urban, suburban, and highway segments. Our dataset provides continuous recordings from six RGB cameras, one LiDAR, and high-precision ADMA-based localization, captured across day, dusk, and night. All sequences are annotated at 10 Hz with 3D bounding boxes and track IDs across 12 classes, yielding ~1.2 million annotated instances. Alongside the benefits of a digital twin, DrivIng enables a 1-to-1 transfer of real traffic into simulation, preserving agent interactions while enabling realistic and flexible scenario testing. To support reproducible research and robust validation, we benchmark DrivIng with state-of-the-art perception models and publicly release the dataset, digital twin, HD map, and codebase.

</details>


### [51] [RayRoPE: Projective Ray Positional Encoding for Multi-view Attention](https://arxiv.org/abs/2601.15275)
*Yu Wu,Minsik Jeon,Jen-Hao Rick Chang,Oncel Tuzel,Shubham Tulsiani*

Main category: cs.CV

TL;DR: 提出RayRoPE，一种用于多视角Transformer的位置编码方法，通过基于射线的预测点实现几何感知编码，支持SE(3)不变性注意力和多频相似性计算，并能处理不确定性下的期望位置编码。在新视角合成和立体深度估计任务中表现优于现有方法，尤其在结合RGB-D输入时提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有绝对或相对位置编码方案无法同时满足唯一编码、SE(3)不变性注意力和几何自适应性需求，因此需要一种新的位置编码机制来提升多视角Transformer的性能。

Method: RayRoPE利用射线关联的预测3D点而非方向进行位置编码，通过查询帧投影坐标计算多频相似性以实现SE(3)不变性，并引入解析方法计算不确定性下的期望位置编码。

Result: 在CO3D数据集上，RayRoPE在LPIPS指标上相比基线提升15%；在立体深度估计和新视角合成任务中均优于其他位置编码方法，结合RGB-D输入时增益更明显。

Conclusion: RayRoPE有效解决了多视角Transformer中位置编码的几何感知与不变性问题，具有良好的泛化性和可扩展性，尤其适用于融合多源输入（如RGB-D）的场景。

Abstract: We study positional encodings for multi-view transformers that process tokens from a set of posed input images, and seek a mechanism that encodes patches uniquely, allows SE(3)-invariant attention with multi-frequency similarity, and can be adaptive to the geometry of the underlying scene. We find that prior (absolute or relative) encoding schemes for multi-view attention do not meet the above desiderata, and present RayRoPE to address this gap. RayRoPE represents patch positions based on associated rays but leverages a predicted point along the ray instead of the direction for a geometry-aware encoding. To achieve SE(3) invariance, RayRoPE computes query-frame projective coordinates for computing multi-frequency similarity. Lastly, as the 'predicted' 3D point along a ray may not be precise, RayRoPE presents a mechanism to analytically compute the expected position encoding under uncertainty. We validate RayRoPE on the tasks of novel-view synthesis and stereo depth estimation and show that it consistently improves over alternate position encoding schemes (e.g. 15% relative improvement on LPIPS in CO3D). We also show that RayRoPE can seamlessly incorporate RGB-D input, resulting in even larger gains over alternatives that cannot positionally encode this information.

</details>


### [52] [StableWorld: Towards Stable and Consistent Long Interactive Video Generation](https://arxiv.org/abs/2601.15281)
*Ying Yang,Zhengyao Lv,Tianlin Pan,Haofan Wang,Binxin Yang,Hubery Yin,Chen Li,Ziwei Liu,Chenyang Si*

Main category: cs.CV

TL;DR: 本文探讨了交互式视频生成中稳定性与时间一致性这一被忽视的挑战，提出了一种名为StableWorld的动态帧淘汰机制，通过持续过滤退化帧并保留几何一致的帧，有效防止误差累积，提升生成视频的稳定性与时间一致性。该方法在多个交互式视频生成模型上表现优异，具有模型无关性与广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 当前交互式视频生成方法在长期交互中存在严重不稳定性和时间退化问题，如空间漂移和场景崩溃，主要源于生成帧逐渐偏离初始状态并导致误差传播。因此需要一种机制来从源头解决误差累积问题。

Method: 提出动态帧淘汰机制（StableWorld），通过持续筛选并剔除退化帧，保留几何一致的帧，从而防止误差在时间维度上的累积。

Result: 在Matrix-Game、Open-Oasis、Hunyuan-GameCraft等多个交互式视频生成模型上验证，StableWorld显著提升了稳定性、时间一致性和跨场景泛化能力，且适用于不同框架。

Conclusion: StableWorld是一种简单但高效的方法，能有效解决交互式视频生成中的稳定性与时间一致性问题，具有良好的通用性和可扩展性。

Abstract: In this paper, we explore the overlooked challenge of stability and temporal consistency in interactive video generation, which synthesizes dynamic and controllable video worlds through interactive behaviors such as camera movements and text prompts. Despite remarkable progress in world modeling, current methods still suffer from severe instability and temporal degradation, often leading to spatial drift and scene collapse during long-horizon interactions. To better understand this issue, we initially investigate the underlying causes of instability and identify that the major source of error accumulation originates from the same scene, where generated frames gradually deviate from the initial clean state and propagate errors to subsequent frames. Building upon this observation, we propose a simple yet effective method, \textbf{StableWorld}, a Dynamic Frame Eviction Mechanism. By continuously filtering out degraded frames while retaining geometrically consistent ones, StableWorld effectively prevents cumulative drift at its source, leading to more stable and temporal consistency of interactive generation. Promising results on multiple interactive video models, \eg, Matrix-Game, Open-Oasis, and Hunyuan-GameCraft, demonstrate that StableWorld is model-agnostic and can be applied to different interactive video generation frameworks to substantially improve stability, temporal consistency, and generalization across diverse interactive scenarios.

</details>


### [53] [Rethinking Video Generation Model for the Embodied World](https://arxiv.org/abs/2601.15282)
*Yufan Deng,Zilin Pan,Hongyu Zhang,Xiaojie Li,Ruoqing Hu,Yufei Ding,Yiming Zou,Yan Zeng,Daquan Zhou*

Main category: cs.CV

TL;DR: 提出RBench基准和RoVid-X数据集，以推动机器人视频生成的评估与训练，解决物理现实性不足问题，实现高保真度视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在真实机器人交互方面表现不佳，缺乏标准化评估基准，且高质量训练数据稀缺，限制了机器人视频生成的发展。

Method: 构建五任务领域、四种机器人形态的综合性基准RBench，通过结构一致性、物理合理性、动作完整性等子指标评估视频生成质量；设计四阶段数据处理流程，构建大规模开放数据集RoVid-X，包含400万标注视频片段及丰富物理属性信息。

Result: RBench与人类评估相关性达0.96（Spearman系数），验证其有效性；25个代表性模型在物理真实性方面存在显著缺陷；RoVid-X为当前最大开源机器人视频数据集，支持更真实、可扩展的视频生成模型训练。

Conclusion: RBench与RoVid-X共同构成评估与数据协同的生态系统，为实现具备物理现实性的具身智能视频生成提供了坚实基础，推动了通用人工智能的发展。

Abstract: Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic interactions remains challenging, and the lack of a standardized benchmark limits fair comparisons and progress. To address this gap, we introduce a comprehensive robotics benchmark, RBench, designed to evaluate robot-oriented video generation across five task domains and four distinct embodiments. It assesses both task-level correctness and visual fidelity through reproducible sub-metrics, including structural consistency, physical plausibility, and action completeness. Evaluation of 25 representative models highlights significant deficiencies in generating physically realistic robot behaviors. Furthermore, the benchmark achieves a Spearman correlation coefficient of 0.96 with human evaluations, validating its effectiveness. While RBench provides the necessary lens to identify these deficiencies, achieving physical realism requires moving beyond evaluation to address the critical shortage of high-quality training data. Driven by these insights, we introduce a refined four-stage data pipeline, resulting in RoVid-X, the largest open-source robotic dataset for video generation with 4 million annotated video clips, covering thousands of tasks and enriched with comprehensive physical property annotations. Collectively, this synergistic ecosystem of evaluation and data establishes a robust foundation for rigorous assessment and scalable training of video models, accelerating the evolution of embodied AI toward general intelligence.

</details>


### [54] [LuxRemix: Lighting Decomposition and Remixing for Indoor Scenes](https://arxiv.org/abs/2601.15283)
*Ruofan Liang,Norman Müller,Ethan Weber,Duncan Zauss,Nandita Vijaykumar,Peter Kontschieder,Christian Richardt*

Main category: cs.CV

TL;DR: 本文提出一种基于单次多视角场景捕获的室内场景交互式光照编辑新方法。该方法利用生成式基于图像的光照分解模型，将复杂的室内光照分解为多个独立光源，并支持对每个光源的状态（开/关）、色度和强度进行独立控制。通过多视角光照一致性优化，确保光照分解在所有视角间保持一致，并集成到可重光照的3D高斯点云表示中，实现实时交互控制。实验在合成与真实数据集上验证了方法的有效性，结果表现出高度逼真的光照分解与重光照效果，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的光照编辑方法难以在复杂室内场景中实现对独立光源的精确控制，且缺乏跨视角的一致性保障。为实现高效、真实感强的交互式光照编辑，亟需一种能够从单次多视角输入中分离并操控各光源的新方法。

Method: 提出一个生成式图像基光照分解模型，结合多视角光照一致性优化，构建可重光照的3D高斯点云表示，支持对光源状态、色度和强度的独立实时控制。

Result: 在多种室内场景中实现了高质量的光照分解与重光照，视觉效果逼真；在合成与真实数据集上均超越当前最优方法，在定量与定性评估中表现优异。

Conclusion: 本方法成功实现了从单次多视角输入中对室内场景光照的高效、精确且一致的交互式编辑，具备高度的实用性和视觉真实性，为数字内容创作与虚拟现实应用提供了有力工具。

Abstract: We present a novel approach for interactive light editing in indoor scenes from a single multi-view scene capture. Our method leverages a generative image-based light decomposition model that factorizes complex indoor scene illumination into its constituent light sources. This factorization enables independent manipulation of individual light sources, specifically allowing control over their state (on/off), chromaticity, and intensity. We further introduce multi-view lighting harmonization to ensure consistent propagation of the lighting decomposition across all scene views. This is integrated into a relightable 3D Gaussian splatting representation, providing real-time interactive control over the individual light sources. Our results demonstrate highly photorealistic lighting decomposition and relighting outcomes across diverse indoor scenes. We evaluate our method on both synthetic and real-world datasets and provide a quantitative and qualitative comparison to state-of-the-art techniques. For video results and interactive demos, see https://luxremix.github.io.

</details>


### [55] [Walk through Paintings: Egocentric World Models from Internet Priors](https://arxiv.org/abs/2601.15284)
*Anurag Bagchi,Zhipeng Bao,Homanga Bharadhwaj,Yu-Xiong Wang,Pavel Tokmakov,Martial Hebert*

Main category: cs.CV

TL;DR: 提出EgoWM，一种将预训练视频扩散模型转化为动作条件世界模型的方法，通过轻量级条件层注入运动命令，实现可控未来预测。该方法无需从零训练，保留了大规模视频模型的丰富世界先验，支持多种机器人和动作空间，生成连贯的滚动预测，且推理延迟低，泛化能力强。引入结构一致性评分（SCS）评估物理正确性，相比现有导航世界模型提升80%的SCS，同时在未见环境中表现稳健，包括在画作内导航。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽能生成逼真未来画面，但缺乏对动作与世界变化之间因果关系的准确建模。如何让模型不仅想象出合理的未来，还能精确反映动作带来的实际世界变化，是关键挑战。为此，需要一种高效、通用的方法，使预训练视频模型能够根据动作指令进行准确的未来预测。

Method: 提出EgoWM：基于预训练视频扩散模型，通过添加轻量级条件层来注入动作信号，实现动作条件下的世界建模。该方法不依赖特定架构，可适配不同机器人形态与动作空间，如3-自由度移动机器人到25-自由度人形机器人。利用世界先验保持真实感，并通过少量微调实现高质量未来预测。

Result: EgoWM在导航与操作任务中均生成连贯的预测轨迹；相比现有方法，结构一致性评分（SCS）最高提升80%，推理延迟降低至六分之一，且在未见过的环境（如画作内部）中仍具强泛化能力。

Conclusion: EgoWM成功将预训练视频模型转化为高效、通用的动作条件世界模型，实现了高保真、低延迟的物理一致未来预测，为具身智能中的规划与决策提供了可靠工具。

Abstract: What if a video generation model could not only imagine a plausible future, but the correct one, accurately reflecting how the world changes with each action? We address this question by presenting the Egocentric World Model (EgoWM), a simple, architecture-agnostic method that transforms any pretrained video diffusion model into an action-conditioned world model, enabling controllable future prediction. Rather than training from scratch, we repurpose the rich world priors of Internet-scale video models and inject motor commands through lightweight conditioning layers. This allows the model to follow actions faithfully while preserving realism and strong generalization. Our approach scales naturally across embodiments and action spaces, ranging from 3-DoF mobile robots to 25-DoF humanoids, where predicting egocentric joint-angle-driven dynamics is substantially more challenging. The model produces coherent rollouts for both navigation and manipulation tasks, requiring only modest fine-tuning. To evaluate physical correctness independently of visual appearance, we introduce the Structural Consistency Score (SCS), which measures whether stable scene elements evolve consistently with the provided actions. EgoWM improves SCS by up to 80 percent over prior state-of-the-art navigation world models, while achieving up to six times lower inference latency and robust generalization to unseen environments, including navigation inside paintings.

</details>


### [56] [Iterative Refinement Improves Compositional Image Generation](https://arxiv.org/abs/2601.15286)
*Shantanu Jaiswal,Mihir Prabhudesai,Nikash Bhardwaj,Zheyang Qin,Amir Zadeh,Chuan Li,Katerina Fragkiadaki,Deepak Pathak*

Main category: cs.CV

TL;DR: 本文提出一种基于视觉-语言模型反馈的迭代测试时策略，用于提升文本到图像生成模型在复杂提示下的表现。该方法通过多步逐步修正生成结果，显著改善了提示对齐度，在多个基准上优于并行采样等现有方法，并获得人类评估者的更高偏好。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在处理包含多个对象、关系和属性的复杂提示时仍存在困难，而现有的推理时策略（如并行采样或增加去噪步骤）在丰富组合场景下效果有限。

Method: 提出一种迭代测试时策略，利用视觉-语言模型作为批评者，在每一步生成后提供反馈，指导模型逐步优化图像生成结果。该方法无需外部工具或先验知识，适用于多种图像生成器与视觉-语言模型。

Result: 在ConceptMix（k=7）上所有正确率提升16.9%，在T2I-CompBench（3D空间类别）上提升13.8%，在Visual Jenga场景分解任务上提升12.5%；人类评估中58.7%偏好该方法。

Conclusion: 迭代自我修正是一种适用于组合式图像生成的通用原则，能够有效提升复杂提示下的生成质量与忠实度。

Abstract: Text-to-image (T2I) models have achieved remarkable progress, yet they continue to struggle with complex prompts that require simultaneously handling multiple objects, relations, and attributes. Existing inference-time strategies, such as parallel sampling with verifiers or simply increasing denoising steps, can improve prompt alignment but remain inadequate for richly compositional settings where many constraints must be satisfied. Inspired by the success of chain-of-thought reasoning in large language models, we propose an iterative test-time strategy in which a T2I model progressively refines its generations across multiple steps, guided by feedback from a vision-language model as the critic in the loop. Our approach is simple, requires no external tools or priors, and can be flexibly applied to a wide range of image generators and vision-language models. Empirically, we demonstrate consistent gains on image generation across benchmarks: a 16.9% improvement in all-correct rate on ConceptMix (k=7), a 13.8% improvement on T2I-CompBench (3D-Spatial category) and a 12.5% improvement on Visual Jenga scene decomposition compared to compute-matched parallel sampling. Beyond quantitative gains, iterative refinement produces more faithful generations by decomposing complex prompts into sequential corrections, with human evaluators preferring our method 58.7% of the time over 41.3% for the parallel baseline. Together, these findings highlight iterative self-correction as a broadly applicable principle for compositional image generation. Results and visualizations are available at https://iterative-img-gen.github.io/

</details>


### [57] [Towards Understanding Best Practices for Quantization of Vision-Language Models](https://arxiv.org/abs/2601.15287)
*Gautom Das,Vincent La,Ethan Lau,Abhinav Shrivastava,Matthew Gwilliam*

Main category: cs.CV

TL;DR: 本研究探讨了多种量化方法（包括GPTQ和AWQ）在包含视觉模型、语言模型及其连接器的多模态流水线中的应用效果，重点分析了比特宽度、量化方法以及量化位置对图像描述、检索和问答任务性能的影响。结果表明，尽管视觉变换器（ViT）和语言模型（LLM）参数量差异显著，二者对模型性能具有相似的重要性；且对LLM进行低比特量化可在保持高精度的同时显著降低每权重比特数（bpw）。研究为多模态大模型（MLLM）的高效部署提供了实用指导，并强调了探索各组件敏感性的价值。代码已公开于GitHub。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）虽表现优异，但依赖高性能GPU和大内存，限制了其部署效率。量化技术可降低内存占用与延迟，但如何在多模态系统中有效应用量化策略仍需深入研究，尤其在不同组件间的敏感性差异方面。

Method: 系统评估多种先进量化方法（如GPTQ、AWQ）在多模态流水线中的表现，涵盖视觉模型（ViT）、语言模型（LLM）及它们之间的连接模块，通过控制比特宽度、量化位置和方法，测试其在图像描述、信息检索和问答任务上的性能变化。

Result: ViT与LLM在模型性能中具有相当重要性，即使参数规模差异显著；对LLM采用低比特量化可在大幅减少每权重比特数（bpw）的同时维持高准确率；量化策略的选择与应用位置显著影响多模态任务表现。

Conclusion: 该研究揭示了多模态模型中各组件的相对敏感性，证明低比特量化在语言模型上具有高度可行性，为高效部署多模态大模型提供了实证依据和实践建议。

Abstract: Large language models (LLMs) deliver impressive results for a variety of tasks, but state-of-the-art systems require fast GPUs with large amounts of memory. To reduce both the memory and latency of these systems, practitioners quantize their learned parameters, typically at half precision. A growing body of research focuses on preserving the model performance with more aggressive bit widths, and some work has been done to apply these strategies to other models, like vision transformers. In our study we investigate how a variety of quantization methods, including state-of-the-art GPTQ and AWQ, can be applied effectively to multimodal pipelines comprised of vision models, language models, and their connectors. We address how performance on captioning, retrieval, and question answering can be affected by bit width, quantization method, and which portion of the pipeline the quantization is used for. Results reveal that ViT and LLM exhibit comparable importance in model performance, despite significant differences in parameter size, and that lower-bit quantization of the LLM achieves high accuracy at reduced bits per weight (bpw). These findings provide practical insights for efficient deployment of MLLMs and highlight the value of exploration for understanding component sensitivities in multimodal models. Our code is available at https://github.com/gautomdas/mmq.

</details>


### [58] [APPLE: Attribute-Preserving Pseudo-Labeling for Diffusion-Based Face Swapping](https://arxiv.org/abs/2601.15288)
*Jiwon Kang,Yeji Choi,JoungBin Lee,Wooseok Jang,Jinhyeok Choi,Taekeun Kang,Yongjae Park,Myungin Kim,Seungryong Kim*

Main category: cs.CV

TL;DR: APPLE提出了一种基于扩散的教师-学生框架，通过属性感知伪标签监督来提升面部交换中的属性保真度。该方法将面部交换重新定义为条件去模糊任务，并引入属性感知反演方案，以更准确地保留光照、肤色和妆容等目标特定属性。通过精心设计的属性保持教师学习机制，APPLE生成高质量的伪三元组，为学生模型提供直接的面部交换监督，从而在属性保留和身份转移方面达到最先进的性能，产生更逼真且忠实于目标的图像结果。


<details>
  <summary>Details</summary>
Motivation: 真实面部交换的地面真值不可用，导致准确的身份转移与高质量的属性保留难以兼顾；现有基于扩散的方法使用掩码条件进行条件修复，但会移除目标的重要外观线索，导致属性虽看似合理但存在错位。

Method: 提出APPLE（Attribute-Preserving Pseudo-Labeling）框架，将面部交换建模为条件去模糊任务，引入属性感知反演方案，并设计属性保持的教师学习机制，生成高质量伪三元组以指导学生模型。

Result: APPLE在属性保留和身份转移方面均达到当前最优表现，生成的图像在视觉质量上更逼真，且更忠实于目标人脸特征。

Conclusion: APPLE通过属性感知伪标签监督与条件去模糊建模，有效解决了面部交换中属性失真与身份不准确的问题，显著提升了生成结果的质量与真实性。

Abstract: Face swapping aims to transfer the identity of a source face onto a target face while preserving target-specific attributes such as pose, expression, lighting, skin tone, and makeup. However, since real ground truth for face swapping is unavailable, achieving both accurate identity transfer and high-quality attribute preservation remains challenging. In addition, recent diffusion-based approaches attempt to improve visual fidelity through conditional inpainting on masked target images, but the masked condition removes crucial appearance cues of target, resulting in plausible yet misaligned attributes. To address these limitations, we propose APPLE (Attribute-Preserving Pseudo-Labeling), a diffusion-based teacher-student framework that enhances attribute fidelity through attribute-aware pseudo-label supervision. We reformulate face swapping as a conditional deblurring task to more faithfully preserve target-specific attributes such as lighting, skin tone, and makeup. In addition, we introduce an attribute-aware inversion scheme to further improve detailed attribute preservation. Through an elaborate attribute-preserving design for teacher learning, APPLE produces high-quality pseudo triplets that explicitly provide the student with direct face-swapping supervision. Overall, APPLE achieves state-of-the-art performance in terms of attribute preservation and identity transfer, producing more photorealistic and target-faithful results.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [59] [From Chaos to Clarity: Schema-Constrained AI for Auditable Biomedical Evidence Extraction from Full-Text PDFs](https://arxiv.org/abs/2601.14267)
*Pouria Mortezaagha,Joseph Shaw,Bowen Sun,Arya Rahgozar*

Main category: cs.CL

TL;DR: 本文提出一种基于模式约束的AI提取系统，通过类型化模式、受控词汇表和证据触发决策，将复杂的生物医学PDF文档转化为结构化、可分析的数据记录。系统采用感知恢复的哈希技术处理文档，按带标题的页面块分割，并在显式并发控制下异步处理。通过冲突感知整合、集合聚合和句子级溯源，确保输出的一致性和可审计性。在直接口服抗凝药水平测量研究数据集上评估表明，该流程无需人工干预即可处理全部文档，具备稳定吞吐量和高内部一致性，且通过迭代模式优化显著提升了关键变量（如检测方法分类、结局定义、随访时长等）的提取精度。结果证明，这种模式约束、溯源感知的提取方法能够实现科学文献的规模化、可审计转化，满足生物医学证据合成对透明度与可靠性的要求。


<details>
  <summary>Details</summary>
Motivation: 现有文档AI系统在处理复杂生物医学PDF时存在OCR错误、长文档碎片化、吞吐量受限及可审计性不足等问题，难以满足高风险证据合成的需求。因此需要一种更准确、可追溯、可扩展的自动化提取方法。

Method: 采用基于模式约束的AI系统，结合类型化模式、受控词汇表和证据驱动决策；使用感知恢复的哈希进行文档摄入，按带标题的页面块分割，异步处理并施加显式并发控制；通过冲突感知合并、集合聚合和句子级溯源实现块级输出到研究级记录的确定性整合。

Result: 系统在无手动干预情况下处理所有文档，保持稳定吞吐量，内部一致性良好；通过迭代模式优化，关键变量提取精度显著提升，包括检测方法分类、结局定义、随访时长和测量时间点等。

Conclusion: 模式约束与溯源感知的提取方法能有效实现异构科学文献的规模化、可审计结构化转换，使现代文档AI更契合生物医学证据合成对透明度与可靠性的要求。

Abstract: Biomedical evidence synthesis relies on accurate extraction of methodological, laboratory, and outcome variables from full-text research articles, yet these variables are embedded in complex scientific PDFs that make manual abstraction time-consuming and difficult to scale. Existing document AI systems remain limited by OCR errors, long-document fragmentation, constrained throughput, and insufficient auditability for high-stakes synthesis. We present a schema-constrained AI extraction system that transforms full-text biomedical PDFs into structured, analysis-ready records by explicitly restricting model inference through typed schemas, controlled vocabularies, and evidence-gated decisions. Documents are ingested using resume-aware hashing, partitioned into caption-aware page-level chunks, and processed asynchronously under explicit concurrency controls. Chunk-level outputs are deterministically merged into study-level records using conflict-aware consolidation, set-based aggregation, and sentence-level provenance to support traceability and post-hoc audit. Evaluated on a corpus of studies on direct oral anticoagulant level measurement, the pipeline processed all documents without manual intervention, maintained stable throughput under service constraints, and exhibited strong internal consistency across document chunks. Iterative schema refinement substantially improved extraction fidelity for synthesis-critical variables, including assay classification, outcome definitions, follow-up duration, and timing of measurement. These results demonstrate that schema-constrained, provenance-aware extraction enables scalable and auditable transformation of heterogeneous scientific PDFs into structured evidence, aligning modern document AI with the transparency and reliability requirements of biomedical evidence synthesis.

</details>


### [60] [The Slow Drift of Support: Boundary Failures in Multi-Turn Mental Health LLM Dialogues](https://arxiv.org/abs/2601.14269)
*Youyou Cheng,Zhuangwei Kang,Kerry Jiang,Chenyu Sun,Qiyang Pan*

Main category: cs.CL

TL;DR: 本文提出一种多轮压力测试框架，针对三个前沿大语言模型在虚拟精神科对话中进行长对话安全测试，发现单轮检测无法充分评估安全边界，多轮交互中的渐进式越界行为（如做出确定性承诺）是主要风险。自适应探测虽延缓越界时间，但整体违规率仍高，表明需重视长期互动对安全边界的磨损。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在心理健康支持中的安全评估仅关注单轮对话中的禁止词检测，忽视了多轮对话中因情感安慰和共情驱动导致的安全边界逐渐侵蚀问题，而这类渐进式越界更具隐蔽性和危害性。

Method: 构建多轮压力测试框架，设计静态推进与自适应探测两种压力方法，生成50个虚拟患者档案，对三款先进LLM进行最多20轮的虚拟精神科对话测试，系统记录并分析其越界行为。

Result: 实验显示违规现象普遍，两种压力模式下违规率相近；自适应探测显著提前越界发生时间（平均从9.21轮降至4.64轮），且主要违规形式为作出确定性或零风险承诺。

Conclusion: 大语言模型的安全边界不能仅通过单轮测试评估，必须考虑多轮交互中不同压力机制带来的持续磨损效应，未来需建立更全面的长对话安全评估体系。

Abstract: Large language models (LLMs) have been widely used for mental health support. However, current safety evaluations in this field are mostly limited to detecting whether LLMs output prohibited words in single-turn conversations, neglecting the gradual erosion of safety boundaries in long dialogues. Examples include making definitive guarantees, assuming responsibility, and playing professional roles. We believe that with the evolution of mainstream LLMs, words with obvious safety risks are easily filtered by their underlying systems, while the real danger lies in the gradual transgression of boundaries during multi-turn interactions, driven by the LLM's attempts at comfort and empathy.
  This paper proposes a multi-turn stress testing framework and conducts long-dialogue safety tests on three cutting-edge LLMs using two pressure methods: static progression and adaptive probing. We generated 50 virtual patient profiles and stress-tested each model through up to 20 rounds of virtual psychiatric dialogues. The experimental results show that violations are common, and both pressure modes produced similar violation rates. However, adaptive probing significantly advanced the time at which models crossed boundaries, reducing the average number of turns from 9.21 in static progression to 4.64. Under both mechanisms, making definitive or zero-risk promises was the primary way in which boundaries were breached. These findings suggest that the robustness of LLM safety boundaries cannot be inferred solely through single-turn tests; it is necessary to fully consider the wear and tear on safety boundaries caused by different interaction pressures and characteristics in extended dialogues.

</details>


### [61] [Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in Large Language Models](https://arxiv.org/abs/2601.14270)
*Liangming Pan,Jason Liang,Jiaran Ye,Minglai Yang,Xinyuan Lu,Fengbin Zhu*

Main category: cs.CL

TL;DR: 本文综述了大语言模型（LLM）多步推理的内在机制，提出一个包含七个相互关联研究问题的概念框架，涵盖从隐式多跳推理到显式语言化推理对内部计算的影响，并指明五个未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述多聚焦于提升性能的工程方法，而对LLM多步推理背后的机制理解不足，亟需系统性机制研究以揭示其内部运作原理。

Method: 构建七问概念框架，系统梳理与整合现有研究成果，分析隐式与显式推理在模型内部激活中的表现及其计算影响。

Result: 揭示了多步推理中隐式与显式推理路径的内在关联，明确了语言化推理对内部计算的重塑作用，并为未来研究提供了清晰方向。

Conclusion: LLM的多步推理能力依赖于复杂且动态的内部机制，未来需加强机制层面的研究以推动模型可解释性与可控性发展。

Abstract: Large Language Models (LLMs) have demonstrated remarkable abilities to solve problems requiring multiple reasoning steps, yet the internal mechanisms enabling such capabilities remain elusive. Unlike existing surveys that primarily focus on engineering methods to enhance performance, this survey provides a comprehensive overview of the mechanisms underlying LLM multi-step reasoning. We organize the survey around a conceptual framework comprising seven interconnected research questions, from how LLMs execute implicit multi-hop reasoning within hidden activations to how verbalized explicit reasoning remodels the internal computation. Finally, we highlight five research directions for future mechanistic studies.

</details>


### [62] [RPC-Bench: A Fine-grained Benchmark for Research Paper Comprehension](https://arxiv.org/abs/2601.14289)
*Yelin Chen,Fanjin Zhang,Suping Sun,Yunhe Pang,Yuanchun Wang,Jian Song,Xiaoyan Li,Lei Hou,Shu Zhao,Jie Tang,Juanzi Li*

Main category: cs.CL

TL;DR: 提出RPC-Bench，一个基于高质量计算机科学论文审稿-反驳交流的大规模问答基准，包含15,000个经人工验证的QA对，旨在细粒度评估模型在学术语境下理解‘为什么’、‘是什么’和‘如何’问题的能力。设计了与科研流程一致的细粒度分类体系，并构建了支持大规模标注与质量控制的LLM-人类交互标注框架。采用LLM作为裁判的范式，实现可扩展的评估，涵盖正确性-完整性与简洁性，与人类判断高度一致。实验表明，即使最强模型（GPT-5）在正确性-完整性上也仅达68.2%，调整简洁性后降至37.46%，揭示当前模型在精确理解学术论文方面仍存在显著差距。代码与数据公开。


<details>
  <summary>Details</summary>
Motivation: 现有基准在细粒度评估大规模学术论文理解能力方面存在不足，尤其是面对专业科学话语和复杂图表时，基础模型理解困难。需要一个更精细、可扩展且贴近真实科研流程的评估体系。

Method: 构建基于审稿-反驳对话的问答数据集；设计与科研流程匹配的细粒度分类体系；开发支持大规模标注与质量控制的LLM-人类交互标注框架；采用LLM-as-a-Judge范式进行可扩展评估，综合考量正确性-完整性与简洁性。

Result: GPT-5在正确性-完整性上达到68.2%，经简洁性调整后降至37.46%，表明当前模型在精确理解学术论文方面仍有巨大提升空间。评估框架与人类判断高度一致，具备良好的可靠性与可扩展性。

Conclusion: RPC-Bench为评估大模型在学术论文理解方面的能力提供了新的标准，揭示了当前模型在精确性与简洁性上的显著不足，推动未来研究向更深入的学术理解迈进。

Abstract: Understanding research papers remains challenging for foundation models due to specialized scientific discourse and complex figures and tables, yet existing benchmarks offer limited fine-grained evaluation at scale. To address this gap, we introduce RPC-Bench, a large-scale question-answering benchmark built from review-rebuttal exchanges of high-quality computer science papers, containing 15K human-verified QA pairs. We design a fine-grained taxonomy aligned with the scientific research flow to assess models' ability to understand and answer why, what, and how questions in scholarly contexts. We also define an elaborate LLM-human interaction annotation framework to support large-scale labeling and quality control. Following the LLM-as-a-Judge paradigm, we develop a scalable framework that evaluates models on correctness-completeness and conciseness, with high agreement to human judgment. Experiments reveal that even the strongest models (GPT-5) achieve only 68.2% correctness-completeness, dropping to 37.46% after conciseness adjustment, highlighting substantial gaps in precise academic paper understanding. Our code and data are available at https://rpc-bench.github.io/.

</details>


### [63] [Project Aletheia: Verifier-Guided Distillation of Backtracking for Small Language Models](https://arxiv.org/abs/2601.14290)
*Aradhya Dixit,Tianxi Liang,Jai Telang*

Main category: cs.CL

TL;DR: 提出Verifier-Guided Distillation训练方法，通过在包含错误与自我修正的验证推理轨迹上训练7B小模型，使小模型具备检测矛盾并修正早期假设的能力，从而提升其在约束满足问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）虽适合私密、设备端部署，但在严格约束满足问题上常因线性且过度自信的推理过程而失败，无法从早期错误中恢复。

Method: 引入Verifier-Guided Distillation训练协议，将错误修复过程（如冲突检测与回溯）作为知识迁移内容，而非仅传递正确最终答案。

Result: 在包含错误与自纠正的验证推理轨迹上训练后，7B小模型展现出潜在的验证行为，能够暂停、检测矛盾并修正先前假设。

Conclusion: 通过训练过程中的错误修复机制，小语言模型可获得更强的容错能力，显著提升在复杂约束任务中的表现。

Abstract: Small Language Models (SLMs, under 10B parameters) are attractive for private, on-device deployment, yet they frequently fail on strict constraint-satisfaction problems due to linear, overconfident reasoning traces that do not recover from early mistakes. We introduce Verifier-Guided Distillation, a training protocol that transfers the process of error repair - explicit conflict detection and backtracking - rather than only correct final answers. By training a 7B model on verified reasoning traces that include mistakes and self-corrections, we show that latent verification behavior can emerge in small models, enabling them to occasionally stop, detect contradictions, and revise earlier assumptions.

</details>


### [64] [Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation with Guided Decoding](https://arxiv.org/abs/2601.14304)
*Juncheng Wang,Zhe Hu,Chao Xu,Siyue Ren,Yuxiang Feng,Yang Liu,Baigui Sun,Shujun Wang*

Main category: cs.CL

TL;DR: 本文揭示了自回归（AR）音频生成器在早期前缀标记中隐含地编码了最终输出的全局语义属性，如事件数量和声音对象类别，提出了一种名为Plan-Critic的轻量级辅助模型，通过广义优势估计（GAE）目标预测部分生成的指令遵循质量。该模型在推理时可实现引导式探索，早期评估候选前缀，修剪低保真度轨迹，并将计算资源重新分配给高潜力规划种子，从而在保持与标准best-of-N解码计算开销相当的情况下，使CLAP分数相比AR基线提升高达10分，达到自回归文本到音频生成的新基准。


<details>
  <summary>Details</summary>
Motivation: 自回归音频生成模型虽然在生成时间连贯性上表现优异，但在遵循复杂文本提示方面存在不足，尤其是在描述复杂声音事件时。本文旨在解决这一问题，通过挖掘自回归模型隐含的全局语义规划能力，提升其对复杂指令的遵循能力。

Method: 提出Plan-Critic模型，利用GAE-inspired目标从部分生成中预测最终指令遵循质量；在推理阶段，通过早期评估和剪枝机制引导生成过程，优化计算资源分配，提升生成质量。

Result: Plan-Critic引导采样在CLAP分数上相比基线提升最高达10分，显著优于现有方法，在保持计算效率的同时实现了最先进的性能。

Conclusion: 即使严格自回归的模型也能具备前瞻规划能力，通过引入Plan-Critic辅助模型，有效弥合了因果生成与全局语义对齐之间的差距，为高质量文本到音频生成提供了新范式。

Abstract: Autoregressive (AR) models excel at generating temporally coherent audio by producing tokens sequentially, yet they often falter in faithfully following complex textual prompts, especially those describing complex sound events. We uncover a surprising capability in AR audio generators: their early prefix tokens implicitly encode global semantic attributes of the final output, such as event count and sound-object category, revealing a form of implicit planning. Building on this insight, we propose Plan-Critic, a lightweight auxiliary model trained with a Generalized Advantage Estimation (GAE)-inspired objective to predict final instruction-following quality from partial generations. At inference time, Plan-Critic enables guided exploration: it evaluates candidate prefixes early, prunes low-fidelity trajectories, and reallocates computation to high-potential planning seeds. Our Plan-Critic-guided sampling achieves up to a 10-point improvement in CLAP score over the AR baseline-establishing a new state of the art in AR text-to-audio generation-while maintaining computational parity with standard best-of-N decoding. This work bridges the gap between causal generation and global semantic alignment, demonstrating that even strictly autoregressive models can plan ahead.

</details>


### [65] [Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis](https://arxiv.org/abs/2601.14417)
*Thanathai Lertpetchpun,Yoonjeong Lee,Thanapat Trachu,Jihwan Lee,Tiantian Feng,Dani Byrd,Shrikanth Narayanan*

Main category: cs.CL

TL;DR: 本文研究了语音合成中发音口音控制的问题，提出通过音位规则与说话人嵌入的交互来实现更可解释、可控的口音生成。以美式和英式英语为例，引入了连读、卷舌音和元音对应等音位规则，并提出新的度量指标‘音位偏移率（PSR）’来评估嵌入对规则的影响。实验表明，结合规则与嵌入可生成更自然的口音，但嵌入也可能抑制或覆盖规则，揭示口音与说话人身份之间的纠缠现象。研究强调规则在口音控制中的作用，并为语音生成中的解耦评估提供框架。


<details>
  <summary>Details</summary>
Motivation: 现有文本到语音（TTS）系统依赖说话人嵌入来生成特定口音，但这些嵌入同时编码音色、情感等非口音特征，导致口音控制缺乏可解释性和灵活性。因此需要一种更清晰、可调控的口音建模方法。

Method: 基于美式和英式英语，设计并实现针对flapping、rhoticity和 vowel correspondences 的音位规则；提出音位偏移率（PSR）作为量化嵌入对规则影响程度的新指标；通过实验对比规则与嵌入联合使用的效果。

Result: 结合音位规则与说话人嵌入能生成更自然的口音；嵌入会削弱或覆盖规则，表明口音与说话人身份存在耦合；PSR有效捕捉了这种交互关系。

Conclusion: 音位规则是实现口音控制的有效工具，且可作为评估语音生成模型中特征解耦程度的框架。嵌入虽有助于提升自然度，但可能干扰规则，提示需谨慎设计口音控制机制。

Abstract: Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditioning on speaker embeddings associated with specific accents. While effective, this approach offers limited interpretability and controllability, as embeddings also encode traits such as timbre and emotion. In this study, we analyze the interaction between speaker embeddings and linguistically motivated phonological rules in accented speech synthesis. Using American and British English as a case study, we implement rules for flapping, rhoticity, and vowel correspondences. We propose the phoneme shift rate (PSR), a novel metric quantifying how strongly embeddings preserve or override rule-based transformations. Experiments show that combining rules with embeddings yields more authentic accents, while embeddings can attenuate or overwrite rules, revealing entanglement between accent and speaker identity. Our findings highlight rules as a lever for accent control and a framework for evaluating disentanglement in speech generation.

</details>


### [66] [Large Language Models for Large-Scale, Rigorous Qualitative Analysis in Applied Health Services Research](https://arxiv.org/abs/2601.14478)
*Sasha Ronaghi,Emma-Louise Aveling,Maria Levis,Rachel Lauren Ross,Emily Alsentzer,Sara Singer*

Main category: cs.CL

TL;DR: 本文提出了一种模型和任务无关的框架，用于设计人与大语言模型（LLM）协同的定性分析方法，以支持多样化的分析目标。在一项关于联邦合格健康中心（FQHCs）糖尿病护理的多站点研究中，该框架被应用于两项任务：（1）对研究者生成的摘要进行定性综合，生成对比反馈报告；（2）对167份访谈转录本进行演绎编码，以优化实践转型干预措施。LLM辅助实现了对临床人员的及时反馈，并将大规模定性数据纳入理论与实践改进中。研究证明，LLM可在保持严谨性的前提下提升健康服务研究的效率，为未来在定性研究中持续创新提供指导。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在提升大型多站点健康服务研究定性分析效率方面展现出潜力，但缺乏方法论指导以及其在真实研究中对方法和成果影响的实证证据。

Method: 开发了一种模型和任务无关的框架，用于设计人-LLM协同的定性分析方法，并在多站点糖尿病护理研究中应用该框架，实施了两项具体任务：定性合成与演绎编码。

Result: LLM辅助实现了对临床人员的及时反馈，并成功整合大规模定性数据以支持理论与实践的改进，提升了研究效率并保持了方法严谨性。

Conclusion: LLMs可有效融入应用型健康服务研究中，提高分析效率的同时维持研究质量，该框架为未来在定性研究中进一步探索和创新提供了可行路径。

Abstract: Large language models (LLMs) show promise for improving the efficiency of qualitative analysis in large, multi-site health-services research. Yet methodological guidance for LLM integration into qualitative analysis and evidence of their impact on real-world research methods and outcomes remain limited. We developed a model- and task-agnostic framework for designing human-LLM qualitative analysis methods to support diverse analytic aims. Within a multi-site study of diabetes care at Federally Qualified Health Centers (FQHCs), we leveraged the framework to implement human-LLM methods for (1) qualitative synthesis of researcher-generated summaries to produce comparative feedback reports and (2) deductive coding of 167 interview transcripts to refine a practice-transformation intervention. LLM assistance enabled timely feedback to practitioners and the incorporation of large-scale qualitative data to inform theory and practice changes. This work demonstrates how LLMs can be integrated into applied health-services research to enhance efficiency while preserving rigor, offering guidance for continued innovation with LLMs in qualitative research.

</details>


### [67] [Can LLM Reasoning Be Trusted? A Comparative Study: Using Human Benchmarking on Statistical Tasks](https://arxiv.org/abs/2601.14479)
*Crish Nagarkar,Leonid Bogachev,Serge Sharoff*

Main category: cs.CL

TL;DR: 该研究探讨了大语言模型（LLMs）在统计任务中的表现及其评估推理质量的能力。通过在定制数据集上微调开源LLM，模型在高级统计任务上的表现达到与统计专业学生相当的水平。微调效果具有架构依赖性，部分模型显著提升。此外，LLMs在评估答案质量方面优于传统指标（如BLEU或BertScore），具备自评估能力，适用于教育平台自动化评估、数据分析质量保证及科研方法验证等场景。


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型在复杂统计任务中的能力尚不明确，且缺乏有效的推理质量评估方法。亟需提升模型在统计推理方面的表现，并探索其作为自动评估工具的潜力。

Method: 在自建数据集上对多个开源大语言模型进行微调，对比微调后模型与人类专家评分的表现；同时评估模型自身对答案质量的判断能力，并与传统评估指标比较。

Result: 微调后的模型在高级统计任务中表现接近统计专业学生水平，不同模型表现出不同程度的性能提升；模型自身对答案质量的评估优于传统指标，具备良好的自评估能力。

Conclusion: 大语言模型经过微调后可在统计任务中表现出较强能力，且具备优秀的自我评估能力，具有在教育科技、数据分析辅助系统和科研方法验证等领域的广泛应用前景。

Abstract: This paper investigates the ability of large language models (LLMs) to solve statistical tasks, as well as their capacity to assess the quality of reasoning. While state-of-the-art LLMs have demonstrated remarkable performance in a range of NLP tasks, their competence in addressing even moderately complex statistical challenges is not well understood. We have fine-tuned selected open-source LLMs on a specially developed dataset to enhance their statistical reasoning capabilities, and compared their performance with the human scores used as a benchmark. Our results show that the fine-tuned models achieve better performance on advanced statistical tasks on the level comparable to a statistics student. Fine-tuning demonstrates architecture-dependent improvements, with some models showing significant performance gains, indicating clear potential for deployment in educational technology and statistical analysis assistance systems. We also show that LLMs themselves can be far better judges of the answers quality (including explanation and reasoning assessment) in comparison to traditional metrics, such as BLEU or BertScore. This self-evaluation capability enables scalable automated assessment for statistical education platforms and quality assurance in automated analysis tools. Potential applications also include validation tools for research methodology in academic and industry settings, and quality control mechanisms for data analysis workflows.

</details>


### [68] [Business Logic-Driven Text-to-SQL Data Synthesis for Business Intelligence](https://arxiv.org/abs/2601.14518)
*Jinhui Liu,Ximeng Zhang,Yanbo Ai,Zhou Yu*

Main category: cs.CL

TL;DR: 提出了一种基于业务逻辑的数据合成框架，通过模拟真实业务人物、工作场景和流程生成高质量的文本到SQL评估数据。该方法通过控制业务推理复杂度提升数据多样性，实验表明其在业务真实性（98.44%）和问题-语句对齐度（98.59%）上显著优于现有方法，且揭示了当前Text-to-SQL模型在复杂业务查询上的性能瓶颈（执行准确率仅42.86%）。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据难以体现真实业务逻辑与工作流程，导致Text-to-SQL评估缺乏现实意义，亟需更贴近实际业务场景的数据生成方法。

Method: 提出业务逻辑驱动的数据合成框架，结合业务人物、工作场景与流程建模，并引入业务推理复杂度控制策略以增强分析推理步骤的多样性。

Result: 在生产级Salesforce数据库上，合成数据实现98.44%的业务真实性，较OmniSQL提升19.5%，较SQL-Factory提升54.7%；问题-语句对齐度达98.59%；同时暴露出现有Text-to-SQL模型在复杂业务查询中仅42.86%的执行准确率。

Conclusion: 所提出的合成数据方法有效提升了评估数据的业务真实性与复杂性，为更可靠地评估Text-to-SQL系统提供了新基准，同时揭示了当前模型在处理高阶业务推理时的重大局限。

Abstract: Evaluating Text-to-SQL agents in private business intelligence (BI) settings is challenging due to the scarcity of realistic, domain-specific data. While synthetic evaluation data offers a scalable solution, existing generation methods fail to capture business realism--whether questions reflect realistic business logic and workflows. We propose a Business Logic-Driven Data Synthesis framework that generates data grounded in business personas, work scenarios, and workflows. In addition, we improve the data quality by imposing a business reasoning complexity control strategy that diversifies the analytical reasoning steps required to answer the questions. Experiments on a production-scale Salesforce database show that our synthesized data achieves high business realism (98.44%), substantially outperforming OmniSQL (+19.5%) and SQL-Factory (+54.7%), while maintaining strong question-SQL alignment (98.59%). Our synthetic data also reveals that state-of-the-art Text-to-SQL models still have significant performance gaps, achieving only 42.86% execution accuracy on the most complex business queries.

</details>


### [69] [Towards Execution-Grounded Automated AI Research](https://arxiv.org/abs/2601.14525)
*Chenglei Si,Zitong Yang,Yejin Choi,Emmanuel Candès,Diyi Yang,Tatsunori Hashimoto*

Main category: cs.CL

TL;DR: 本文研究自动化AI研究中执行反馈对生成有效想法的作用，构建了自动化执行器并进行大规模并行GPU实验，验证了执行可行性。通过进化搜索和强化学习两种方法利用执行反馈，发现进化搜索样本效率高，能显著提升性能；而强化学习易陷入模式崩溃，仅提升平均表现但无法突破上限。


<details>
  <summary>Details</summary>
Motivation: 当前大模型常生成看似合理但无效的想法，缺乏执行验证机制，亟需探索自动化执行的可行性及模型从执行反馈中学习的能力。

Method: 构建自动化执行器，将大模型预训练与后训练问题转化为可执行环境，采用进化搜索和强化学习两种策略利用执行反馈进行优化，并在大规模并行GPU实验中评估效果。

Result: 进化搜索在十轮内显著优于基线（后训练：69.4% vs 48.0%；预训练：19.7分钟 vs 35.9分钟）；强化学习虽提升平均奖励，但因模式崩溃导致上限未提升，模型趋于简单策略。

Conclusion: 自动化执行是可行的，执行反馈有助于提升算法质量，进化搜索更有效；未来需关注如何避免强化学习中的模式崩溃，推动执行引导的自动化AI研究。

Abstract: Automated AI research holds great potential to accelerate scientific discovery. However, current LLMs often generate plausible-looking but ineffective ideas. Execution grounding may help, but it is unclear whether automated execution is feasible and whether LLMs can learn from the execution feedback. To investigate these, we first build an automated executor to implement ideas and launch large-scale parallel GPU experiments to verify their effectiveness. We then convert two realistic research problems - LLM pre-training and post-training - into execution environments and demonstrate that our automated executor can implement a large fraction of the ideas sampled from frontier LLMs. We analyze two methods to learn from the execution feedback: evolutionary search and reinforcement learning. Execution-guided evolutionary search is sample-efficient: it finds a method that significantly outperforms the GRPO baseline (69.4% vs 48.0%) on post-training, and finds a pre-training recipe that outperforms the nanoGPT baseline (19.7 minutes vs 35.9 minutes) on pre-training, all within just ten search epochs. Frontier LLMs often generate meaningful algorithmic ideas during search, but they tend to saturate early and only occasionally exhibit scaling trends. Reinforcement learning from execution reward, on the other hand, suffers from mode collapse. It successfully improves the average reward of the ideator model but not the upper-bound, due to models converging on simple ideas. We thoroughly analyze the executed ideas and training dynamics to facilitate future efforts towards execution-grounded automated AI research.

</details>


### [70] [Self-Blinding and Counterfactual Self-Simulation Mitigate Biases and Sycophancy in Large Language Models](https://arxiv.org/abs/2601.14553)
*Brian Christian,Matan Mazor*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在处理性别和种族偏见时，难以通过提示忽略或假装不知道这些信息来实现公平决策，反而可能适得其反。然而，通过让模型访问自身‘盲化副本’的输出（即其API），可有效提升决策公平性并增强透明度，以区分隐性偏见与有意偏见。


<details>
  <summary>Details</summary>
Motivation: 人类在做公平决策时难以忽略潜在偏见信息（如性别、种族），导致即使出于善意也产生偏见。类似地，大型语言模型也面临相同挑战，需要找到有效方法减少其内在偏见。

Method: 通过提示模型忽略偏见信息进行实验，发现该方法无效甚至加剧偏见；随后引入模型自身的‘盲化副本’（即不携带偏见信息的API响应），利用其输出作为参考来调整决策，从而实现更公平的结果。

Result: 基于模型自身盲化副本的反馈能够显著降低偏见，提升决策公平性，并增强对偏见来源的可解释性。

Conclusion: 尽管直接提示模型忽略偏见信息无效，但通过赋予模型访问其自身反事实认知的能力（即使用其盲化版本的输出），可以实现更公平、透明的决策过程。

Abstract: Fair decisions require ignoring irrelevant, potentially biasing, information. To achieve this, decision-makers need to approximate what decision they would have made had they not known certain facts, such as the gender or race of a job candidate. This counterfactual self-simulation is notoriously hard for humans, leading to biased judgments even by well-meaning actors. Here we show that large language models (LLMs) suffer from similar limitations in their ability to approximate what decisions they would make under counterfactual knowledge in offsetting gender and race biases and overcoming sycophancy. We show that prompting models to ignore or pretend not to know biasing information fails to offset these biases and occasionally backfires. However, unlike humans, LLMs can be given access to a ground-truth model of their own counterfactual cognition -- their own API. We show that this access to the responses of a blinded replica enables fairer decisions, while providing greater transparency to distinguish implicit from intentionally biased behavior.

</details>


### [71] [Rewarding How Models Think Pedagogically: Integrating Pedagogical Reasoning and Thinking Rewards for LLMs in Education](https://arxiv.org/abs/2601.14560)
*Unggi Lee,Jiyeong Bae,Jaehyeon Park,Haeun Park,Taejun Park,Younghoon Jeon,Sungmin Cho,Junbo Koh,Yeil Jeong,Gyeonggeon Lee*

Main category: cs.CL

TL;DR: 本文提出PedagogicalRL-Thinking框架，通过领域特定的教育理论引导模型内部推理，并引入思维奖励机制来优化大语言模型在教育场景中的教学表现。实验表明，结合教育理论的提示与思维奖励可显著提升模型的教学质量，且在未见任务上表现更优，同时保持事实知识。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的LLM导师训练方法仅关注可见回答的优化，忽视了模型内部思考过程的教育价值。为提升教育场景下大语言模型的教学能力，需对内部推理过程进行有效引导和奖励。

Method: 提出两种新方法：(1) 教育推理提示（Pedagogical Reasoning Prompting），使用领域特定教育理论指导模型内部推理；(2) 思维奖励（Thinking Reward），显式评估并强化推理轨迹的教育质量。

Result: 领域特定、理论驱动的提示优于通用提示；思维奖励与教育提示结合效果最佳；仅在数学辅导对话上训练的模型在未见教育基准上表现提升，且保留原始模型的事实知识；定量与定性分析显示，思维奖励使推理轨迹更具系统性与结构化教学决策特征。

Conclusion: PedagogicalRL-Thinking框架成功将教育理论融入大语言模型的内部推理过程，显著提升了其作为智能导师的性能与可解释性，为未来教育型AI的发展提供了有效路径。

Abstract: Large language models (LLMs) are increasingly deployed as intelligent tutoring systems, yet research on optimizing LLMs specifically for educational contexts remains limited. Recent works have proposed reinforcement learning approaches for training LLM tutors, but these methods focus solely on optimizing visible responses while neglecting the model's internal thinking process. We introduce PedagogicalRL-Thinking, a framework that extends pedagogical alignment to reasoning LLMs in education through two novel approaches: (1) Pedagogical Reasoning Prompting, which guides internal reasoning using domain-specific educational theory rather than generic instructions; and (2) Thinking Reward, which explicitly evaluates and reinforces the pedagogical quality of the model's reasoning traces. Our experiments reveal that domain-specific, theory-grounded prompting outperforms generic prompting, and that Thinking Reward is most effective when combined with pedagogical prompting. Furthermore, models trained only on mathematics tutoring dialogues show improved performance on educational benchmarks not seen during training, while preserving the base model's factual knowledge. Our quantitative and qualitative analyses reveal that pedagogical thinking reward produces systematic reasoning trace changes, with increased pedagogical reasoning and more structured instructional decision-making in the tutor's thinking process.

</details>


### [72] [Social Caption: Evaluating Social Understanding in Multimodal Models](https://arxiv.org/abs/2601.14569)
*Bhaavanaa Thumu,Leena Mathur,Youssouf Kebe,Louis-Philippe Morency*

Main category: cs.CL

TL;DR: Social Caption is a framework for evaluating multimodal large language models' social understanding abilities across three dimensions: Social Inference, Holistic Social Analysis, and Directed Social Analysis. It investigates how model scale, architecture, and spoken context affect performance, and uses MLLM judges to study automated evaluation.


<details>
  <summary>Details</summary>
Motivation: To develop a systematic way to evaluate the social understanding capabilities of multimodal large language models, which are essential for interpreting human interactions accurately.

Method: The framework employs interaction theory to assess MLLMs on three dimensions: Social Inference (accurate inference about interactions), Holistic Social Analysis (comprehensive description of interactions), and Directed Social Analysis (extraction of relevant social information). Experiments with MLLM judges are conducted to analyze scaling effects and improve automated evaluation.

Result: Experiments reveal that model scale, architectural design, and spoken context significantly influence social understanding performance. MLLM judges provide valuable insights into scalable automated evaluation of social understanding.

Conclusion: Social Caption offers a robust evaluation framework for assessing social understanding in MLLMs, highlighting key factors affecting performance and paving the way for more reliable automated assessment methods.

Abstract: Social understanding abilities are crucial for multimodal large language models (MLLMs) to interpret human social interactions. We introduce Social Caption, a framework grounded in interaction theory to evaluate social understanding abilities of MLLMs along three dimensions: Social Inference (SI), the ability to make accurate inferences about interactions; Holistic Social Analysis (HSA), the ability to generate comprehensive descriptions of interactions; Directed Social Analysis (DSA), the ability to extract relevant social information from interactions. We analyze factors influencing model performance in social understanding, such as scale, architectural design, and spoken context. Experiments with MLLM judges contribute insights about scaling automated evaluation of multimodal social understanding.

</details>


### [73] [Say Anything but This: When Tokenizer Betrays Reasoning in LLMs](https://arxiv.org/abs/2601.14658)
*Navid Ayoobi,Marcus I Armstrong,Arjun Mukherjee*

Main category: cs.CL

TL;DR: 本文研究大语言模型（LLM）在离散词元ID序列上的推理过程，指出现代子词分词器常产生非唯一编码，导致内部表示与表面文本不一致，从而引发推理脆弱性。作者提出一种分词一致性探测方法，要求模型在上下文中替换指定目标词而保持其他内容不变，以识别由分词器-反分词器缺陷引起的错误。分析超过11000次替换实验发现，存在大量‘幻象编辑’现象，即模型看似正确推理但实际因分词器问题出错。进一步分类出八类系统性分词器缺陷，如空格边界偏移和词内重分割。研究揭示部分推理缺陷源于分词层，呼吁在盲目扩大模型规模前优先优化分词器。


<details>
  <summary>Details</summary>
Motivation: 现有子词分词器存在一词多码的非唯一编码问题，导致大语言模型在推理时将语义相同的文本视为不同表示，从而引发不可测的推理失败。这种分词层的表示缺陷可能被误认为是模型知识或能力不足，因此亟需识别并解决该底层问题。

Method: 提出分词一致性探测任务：在给定上下文条件下，要求模型仅替换指定目标词，其余内容保持不变。通过大量实验观察输出是否出现‘幻象编辑’，即表面上看似正确但实际因分词器映射错误导致的错误替换。结合案例分析，归纳出八类系统性分词器缺陷。

Result: 在超过11000次测试中，多个主流开源大语言模型均表现出显著的幻象编辑率。通过分析，识别出包括空格边界偏移、词内重分割等在内的八类系统性分词器缺陷。这些缺陷直接导致模型在看似合理推理下产生错误输出，表明部分推理失败并非模型本身能力不足，而是分词器层面的问题。

Conclusion: 大语言模型的推理缺陷部分源于分词器的表示不一致性。为提升模型可靠性，应优先从分词器层级进行优化，而非一味增加模型规模和训练数据。此研究强调了分词器设计在语言模型整体性能中的关键作用。

Abstract: Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct "words" even when they are semantically identical at the text level. In this work, we show that tokenization can betray LLM reasoning through one-to-many token ID mappings. We introduce a tokenization-consistency probe that requires models to replace designated target words in context while leaving all other content unchanged. The task is intentionally simple at the surface level, enabling us to attribute failures to tokenizer-detokenizer artifacts rather than to knowledge gaps or parameter limitations. Through analysis of over 11000 replacement trials across state-of-the-art open-source LLMs, we find a non-trivial rate of outputs exhibit phantom edits: cases where models operate under the illusion of correct reasoning, a phenomenon arising from tokenizer-induced representational defects. We further analyze these cases and provide a taxonomy of eight systematic tokenizer artifacts, including whitespace-boundary shifts and intra-word resegmentation. These findings indicate that part of apparent reasoning deficiency originates in the tokenizer layer, motivating tokenizer-level remedies before incurring the cost of training ever-larger models on ever-larger corpora.

</details>


### [74] [ClaimDB: A Fact Verification Benchmark over Large Structured Data](https://arxiv.org/abs/2601.14698)
*Michael Theologitis,Preetam Prabhu Srikar Dammu,Chirag Shah,Dan Suciu*

Main category: cs.CL

TL;DR: ClaimDB是首个基于大规模结构化数据的事实验证基准，包含80个涵盖治理、医疗、媒体、教育和自然科学等领域的真实数据库，其证据来自数百万条记录和多张表格。传统依赖‘阅读’证据的方法在此规模下失效，需转向可执行程序推理。实验测试了30个最先进的专有及开源（参数量低于70B）大模型，发现无一超过83%准确率，超半数低于55%。分析还显示，闭源与开源模型均难以正确‘放弃回答’（即承认无证据支持），质疑其在高风险数据分析中的可靠性。该基准、代码及LLM排行榜已公开发布。


<details>
  <summary>Details</summary>
Motivation: 现有事实验证基准主要关注非结构化文本，而基于大规模结构化数据的声明验证仍被忽视。随着现实世界数据日益以多表、海量记录形式存在，传统阅读式验证方法无法有效应对，亟需新范式。因此，构建一个能反映真实复杂数据环境的验证基准成为必要。

Method: 提出ClaimDB，一个由80个真实世界数据库构成的大型事实验证基准，覆盖多领域；每个数据库包含数百万记录和多个关联表；通过生成需要跨表、复杂查询或程序推理才能验证的声明，评估模型在结构化数据上的推理能力；采用30个主流大语言模型进行实验，比较其在准确性与拒答能力上的表现。

Result: 所有测试模型中，最高准确率为83%，超过一半模型准确率低于55%；多数模型缺乏正确的‘拒绝回答’能力，即无法识别无足够证据的情况；表明当前大模型在处理大规模结构化数据时存在严重局限性。

Conclusion: ClaimDB揭示了现有大模型在处理大规模结构化数据时的显著缺陷，尤其是在推理深度和可靠拒答方面。未来工作应聚焦于开发能够执行可解释程序推理的模型，并推动更严格的评估机制以提升模型在关键应用场景中的可信度。

Abstract: Despite substantial progress in fact-verification benchmarks, claims grounded in large-scale structured data remain underexplored. In this work, we introduce ClaimDB, the first fact-verification benchmark where the evidence for claims is derived from compositions of millions of records and multiple tables. ClaimDB consists of 80 unique real-life databases covering a wide range of domains, from governance and healthcare to media, education and the natural sciences. At this scale, verification approaches that rely on "reading" the evidence break down, forcing a timely shift toward reasoning in executable programs. We conduct extensive experiments with 30 state-of-the-art proprietary and open-source (below 70B) LLMs and find that none exceed 83% accuracy, with more than half below 55%. Our analysis also reveals that both closed- and open-source models struggle with abstention -- the ability to admit that there is no evidence to decide -- raising doubts about their reliability in high-stakes data analysis. We release the benchmark, code, and the LLM leaderboard at https://claimdb.github.io .

</details>


### [75] [DARL: Encouraging Diverse Answers for General Reasoning without Verifiers](https://arxiv.org/abs/2601.14700)
*Chongxuan Huang,Lei Lin,Xiaodong Shi,Wenping Hu,Ruiming Tang*

Main category: cs.CL

TL;DR: DARL 是一种新的强化学习框架，旨在提升大语言模型在开放领域中的推理能力和输出多样性。相比现有方法如 RLPR，DARL 通过控制生成答案与参考答案的偏差范围，在保持对齐的同时鼓励多样化输出，且无需额外验证器，兼容性强。在13个基准测试中表现优异，尤其在7个通用任务上平均提升9.5分，显著优于RLPR。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法如RLPR在开放任务中容易过拟合参考答案，限制了输出多样性，尤其在写作等多解任务中表现不佳。因此需要一种能兼顾对齐性与多样性的新方法。

Method: 提出DARL框架，通过约束生成答案在可控的偏离范围内，同时保持与参考答案的对齐，实现多样性增强，且无需额外验证器，可无缝集成到现有方法中。

Result: 在13个基准测试中均取得一致改进；在6个推理任务上平均提升1.3分，在7个通用任务上平均提升9.5分，显著优于RLPR。

Conclusion: DARL有效提升了大语言模型在开放域任务中的推理性能与输出多样性，具有强兼容性和实用性，为通用强化学习提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated promising gains in enhancing the reasoning capabilities of large language models. However, its dependence on domain-specific verifiers significantly restricts its applicability to open and general domains. Recent efforts such as RLPR have extended RLVR to general domains, enabling training on broader datasets and achieving improvements over RLVR. However, a notable limitation of these methods is their tendency to overfit to reference answers, which constrains the model's ability to generate diverse outputs. This limitation is particularly pronounced in open-ended tasks such as writing, where multiple plausible answers exist. To address this, we propose DARL, a simple yet effective reinforcement learning framework that encourages the generation of diverse answers within a controlled deviation range from the reference while preserving alignment with it. Our framework is fully compatible with existing general reinforcement learning methods and can be seamlessly integrated without additional verifiers. Extensive experiments on thirteen benchmarks demonstrate consistent improvements in reasoning performance. Notably, DARL surpasses RLPR, achieving average gains of 1.3 points on six reasoning benchmarks and 9.5 points on seven general benchmarks, highlighting its effectiveness in improving both reasoning accuracy and output diversity.

</details>


### [76] [Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning](https://arxiv.org/abs/2601.14750)
*Yifan Wang,Shiyu Li,Peiming Li,Xiaochen Yang,Yang Tang,Zheng Wei*

Main category: cs.CL

TL;DR: 提出RoT框架，将思维链（CoT）从文本转为图像，实现推理过程的显式化与可追溯性，利用视觉语言模型的视觉编码器对齐视觉嵌入与文本空间，实现无需额外预训练的即插即用设计。实验表明，RoT在数学和逻辑推理任务上实现3-4倍的令牌压缩和显著推理加速，同时保持竞争力性能。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维（CoT）提示虽提升大语言模型推理能力，但存在冗长导致计算开销大、中间推理过程缺乏监督等问题，影响推理过程的可分析性。

Method: 通过将文本推理步骤渲染为图像，利用现有视觉语言模型的视觉编码器作为语义锚点，对齐视觉嵌入与文本空间，从而显式化并追踪隐式推理链。该方法无需额外预训练，支持即插即用。

Result: 在数学和逻辑推理基准测试中，RoT实现了3-4倍的令牌压缩和显著的推理加速，同时保持了与其他方法相当的性能水平，验证了该范式的可行性。

Conclusion: RoT是首个将推理链显式化为图像的框架，有效解决了传统CoT提示的冗长与不可追溯问题，在减少计算开销的同时保持高性能，具有良好的应用前景。

Abstract: Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzability of the latent reasoning chain. To address these challenges, we introduce Render-of-Thought (RoT), the first framework to reify the reasoning chain by rendering textual steps into images, making the latent rationale explicit and traceable. Specifically, we leverage the vision encoders of existing Vision Language Models (VLMs) as semantic anchors to align the vision embeddings with the textual space. This design ensures plug-and-play implementation without incurring additional pre-training overhead. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that our method achieves 3-4x token compression and substantial inference acceleration compared to explicit CoT. Furthermore, it maintains competitive performance against other methods, validating the feasibility of this paradigm. Our code is available at https://github.com/TencentBAC/RoT

</details>


### [77] [RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models](https://arxiv.org/abs/2601.14780)
*Anqi Li,Yuqian Chen,Yu Lu,Zhaoming Chen,Yuan Xie,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 本文提出PsyFIRE框架，用于捕捉13种细粒度的来访者抗拒行为及协作互动，并构建了包含23,930条真实中文文本咨询语句的ClientResistance数据集，每条语句附有上下文解释。基于该数据集，开发了两阶段的RECAP模型，实现对抵抗行为及其细粒度分类的检测与解释。实验表明，RECAP在区分合作与抵抗方面达到91.25% F1，细粒度分类宏F1达66.58%，显著优于主流提示式大模型基线。在独立数据集和62名咨询师的试点研究中，验证了抵抗行为的普遍性及其对治疗关系的负面影响，展示了其提升咨询师理解与干预策略的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有NLP方法在文本咨询中对抵抗行为的识别存在分类过于粗略、忽略治疗过程的时序动态以及可解释性差的问题，难以有效支持临床实践。

Method: 提出理论驱动的PsyFIRE框架，构建细粒度标注的ClientResistance数据集，并设计两阶段的RECAP模型，结合上下文推理实现抵抗检测与类型识别，同时提供可解释的理由。

Result: RECAP在抵抗检测任务上取得91.25% F1，细粒度分类达66.58%宏F1，优于主流提示式大模型超过20个百分点；实证研究揭示抵抗行为普遍且影响治疗关系，且有助于提升咨询师的认知与干预能力。

Conclusion: 本研究通过构建细粒度、可解释的抵抗识别框架与数据集，为文本咨询中的心理抵抗行为分析提供了有效工具，具有重要的临床应用价值。

Abstract: Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability.
  To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations.
  RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors' understanding and intervention strategies.

</details>


### [78] [Comparative Study of Large Language Models on Chinese Film Script Continuation: An Empirical Analysis Based on GPT-5.2 and Qwen-Max](https://arxiv.org/abs/2601.14826)
*Yuxuan Cao,Zida Yang,Ye Wang*

Main category: cs.CL

TL;DR: 本研究构建了首个针对中文电影剧本续写任务的基准测试，涵盖53部经典影片，并设计多维度评估框架，对比GPT-5.2与Qwen-Max-Latest的表现。通过‘前半段续写后半段’范式生成303个有效样本，评估结合ROUGE-L、结构相似性及LLM作为裁判（DeepSeek-Reasoner）评分。统计分析显示，尽管Qwen-Max在ROUGE-L上略优，但GPT-5.2在结构保持、整体质量与综合得分上显著更优，尤其在角色一致性、风格匹配和格式规范方面表现突出，而Qwen-Max存在生成稳定性不足问题。研究提供可复现的中文创意写作评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在创意写作中的广泛应用，其在文化特定叙事任务上的表现亟需系统评估。现有研究缺乏针对中文电影剧本续写的专门基准与评估体系，因此亟需建立一个具有代表性的中文创作任务基准，以客观衡量不同模型在文化语境下的生成能力。

Method: 构建包含53部经典中国电影的剧本续写基准，采用‘前半段续写后半段’的延续范式，每部电影生成3个样本，共获得303个有效样本；评估方法融合ROUGE-L、结构相似性指标及基于DeepSeek-Reasoner的LLM-as-Judge评分，进行多维度对比分析。

Result: Qwen-Max在ROUGE-L指标上表现略优（0.2230 vs 0.2114），但GPT-5.2在结构保留（0.93 vs 0.75）、整体质量（44.79 vs 25.72）和综合得分（0.50 vs 0.39）上显著领先，效应量达大效应水平（d>0.8）。GPT-5.2在角色一致性、风格匹配与格式规范方面表现更佳，而Qwen-Max存在生成不稳定性问题。

Conclusion: 本研究建立了首个面向中文创意写作的大语言模型评估基准，验证了GPT-5.2在中文电影剧本续写任务中优于Qwen-Max的表现，尤其在结构连贯性与文化语境适配方面具备优势。研究为后续中文创意文本生成模型的开发与评估提供了可复现的框架与实证依据。

Abstract: As large language models (LLMs) are increasingly applied to creative writing, their performance on culturally specific narrative tasks warrants systematic investigation. This study constructs the first Chinese film script continuation benchmark comprising 53 classic films, and designs a multi-dimensional evaluation framework comparing GPT-5.2 and Qwen-Max-Latest. Using a "first half to second half" continuation paradigm with 3 samples per film, we obtained 303 valid samples (GPT-5.2: 157, 98.7% validity; Qwen-Max: 146, 91.8% validity). Evaluation integrates ROUGE-L, Structural Similarity, and LLM-as-Judge scoring (DeepSeek-Reasoner).
  Statistical analysis of 144 paired samples reveals: Qwen-Max achieves marginally higher ROUGE-L (0.2230 vs 0.2114, d=-0.43); however, GPT-5.2 significantly outperforms in structural preservation (0.93 vs 0.75, d=0.46), overall quality (44.79 vs 25.72, d=1.04), and composite scores (0.50 vs 0.39, d=0.84). The overall quality effect size reaches large effect level (d>0.8).
  GPT-5.2 excels in character consistency, tone-style matching, and format preservation, while Qwen-Max shows deficiencies in generation stability. This study provides a reproducible framework for LLM evaluation in Chinese creative writing.

</details>


### [79] [Language-Coupled Reinforcement Learning for Multilingual Retrieval-Augmented Generation](https://arxiv.org/abs/2601.14896)
*Rui Qi,Fengran Mo,Yufeng Chen,Xue Zhang,Shuo Wang,Hongliang Li,Jinan Xu,Meng Jiang,Jian-Yun Nie,Kaiyu Huang*

Main category: cs.CL

TL;DR: 提出LcRL框架，通过语言耦合的组相对策略优化与反一致性正则化，缓解多语言检索增强生成中的知识偏差与冲突问题，提升跨语言知识获取与整合效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用统一处理流程，导致多语言场景下知识偏差和冲突，影响模型性能。

Method: 引入语言耦合组采样减少知识偏差，使用辅助反一致性惩罚项缓解知识冲突，并结合强化学习优化策略与奖励模型。

Result: 实验表明LcRL在多种实际场景（如数据受限、多语言语料库）中均表现优异，具备良好泛化能力。

Conclusion: LcRL有效解决了多语言检索增强生成中的知识偏差与冲突问题，具有广泛适用性与优越性能。

Abstract: Multilingual retrieval-augmented generation (MRAG) requires models to effectively acquire and integrate beneficial external knowledge from multilingual collections. However, most existing studies employ a unitive process where queries of equivalent semantics across different languages are processed through a single-turn retrieval and subsequent optimization. Such a ``one-size-fits-all'' strategy is often suboptimal in multilingual settings, as the models occur to knowledge bias and conflict during the interaction with the search engine. To alleviate the issues, we propose LcRL, a multilingual search-augmented reinforcement learning framework that integrates a language-coupled Group Relative Policy Optimization into the policy and reward models. We adopt the language-coupled group sampling in the rollout module to reduce knowledge bias, and regularize an auxiliary anti-consistency penalty in the reward models to mitigate the knowledge conflict. Experimental results demonstrate that LcRL not only achieves competitive performance but is also appropriate for various practical scenarios such as constrained training data and retrieval over collections encompassing a large number of languages. Our code is available at https://github.com/Cherry-qwq/LcRL-Open.

</details>


### [80] [PodBench: A Comprehensive Benchmark for Instruction-Aware Audio-Oriented Podcast Script Generation](https://arxiv.org/abs/2601.14903)
*Chenning Xu,Mao Zheng,Mingyu Zheng,Mingyang Song*

Main category: cs.CL

TL;DR: PodBench 是一个包含 800 个样本的基准测试，用于评估语音播客脚本生成任务，涵盖长达 21K tokens 的输入和复杂的多说话人指令。研究提出一个结合定量约束与基于 LLM 的质量评估的多维度评估框架。实验表明，尽管专有模型整体表现更优，但具备显式推理能力的开源模型在长上下文和多说话人协调方面展现出更强的鲁棒性。然而，研究发现高指令遵循度并不等同于高质量内容，揭示了当前模型在内容实质上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前语音播客脚本生成任务缺乏系统性的评估资源，尤其是针对长文本、多说话人结构化对话的评测标准不足，亟需一个可复现的基准测试来推动该领域发展。

Method: 构建 PodBench 基准数据集，包含多样化输入与复杂指令；设计融合定量指标与 LLM 驱动质量评估的多维度评估框架；对多种主流模型进行系统性实验比较。

Result: 专有模型整体表现更优，但具备显式推理的开源模型在处理长上下文和多说话人场景中更具鲁棒性；存在指令遵循度高但内容质量低的现象，说明现有模型在内容实质生成上仍有明显缺陷。

Conclusion: PodBench 提供了一个可复现的评测平台，有助于推动长篇、以音频为中心的生成任务的发展，并揭示了当前模型在内容深度与真实语义表达方面的关键挑战。

Abstract: Podcast script generation requires LLMs to synthesize structured, context-grounded dialogue from diverse inputs, yet systematic evaluation resources for this task remain limited. To bridge this gap, we introduce PodBench, a benchmark comprising 800 samples with inputs up to 21K tokens and complex multi-speaker instructions. We propose a multifaceted evaluation framework that integrates quantitative constraints with LLM-based quality assessment. Extensive experiments reveal that while proprietary models generally excel, open-source models equipped with explicit reasoning demonstrate superior robustness in handling long contexts and multi-speaker coordination compared to standard baselines. However, our analysis uncovers a persistent divergence where high instruction following does not guarantee high content substance. PodBench offers a reproducible testbed to address these challenges in long-form, audio-centric generation.

</details>


### [81] [CodeDelegator: Mitigating Context Pollution via Role Separation in Code-as-Action Agents](https://arxiv.org/abs/2601.14914)
*Tianxiang Fei,Cheng Chen,Yue Pan,Mao Zheng,Mingyang Song*

Main category: cs.CL

TL;DR: CodeDelegator 是一种多智能体框架，通过角色专业化将任务规划与实现分离。它使用一个持久的 Delegator 智能体进行战略规划和进度监控，而每个子任务由独立的 Coder 智能体在干净上下文中执行，以避免调试痕迹污染。通过引入瞬态-持久状态分离（EPSS），确保全局一致性的同时隔离执行状态。实验表明该方法在多种基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 单个智能体同时负责规划和实现会导致上下文污染，尤其是调试痕迹和中间失败会影响长周期任务的性能。因此需要一种机制来分离规划与实现，以提升复杂任务的执行效率与稳定性。

Method: 提出 CodeDelegator 多智能体框架，采用角色专业化：持久 Delegator 负责任务分解、规范编写与进度监控；每个子任务由新实例化的 Coder 智能体在清洁上下文中执行。引入 Ephemeral-Persistent State Separation (EPSS) 实现状态隔离与全局协调。

Result: 在多个基准测试上验证了 CodeDelegator 的有效性，显著提升了复杂任务中的长期表现，有效缓解了上下文污染问题。

Conclusion: 通过将规划与实现分离并利用 EPSS 机制，CodeDelegator 能够在保持全局一致性的同时避免上下文污染，是提升大语言模型在复杂任务中表现的有效方案。

Abstract: Recent advances in large language models (LLMs) allow agents to represent actions as executable code, offering greater expressivity than traditional tool-calling. However, real-world tasks often demand both strategic planning and detailed implementation. Using a single agent for both leads to context pollution from debugging traces and intermediate failures, impairing long-horizon performance. We propose CodeDelegator, a multi-agent framework that separates planning from implementation via role specialization. A persistent Delegator maintains strategic oversight by decomposing tasks, writing specifications, and monitoring progress without executing code. For each sub-task, a new Coder agent is instantiated with a clean context containing only its specification, shielding it from prior failures. To coordinate between agents, we introduce Ephemeral-Persistent State Separation (EPSS), which isolates each Coder's execution state while preserving global coherence, preventing debugging traces from polluting the Delegator's context. Experiments on various benchmarks demonstrate the effectiveness of CodeDelegator across diverse scenarios.

</details>


### [82] [The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations](https://arxiv.org/abs/2601.14944)
*Pierre-Antoine Lequeu,Léo Labat,Laurène Cave,Gaël Lejeune,François Yvon,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 本文提出了一种名为Corpus Clarification的预处理框架，旨在将大规模公共咨询数据中的嘈杂、多主题贡献转化为结构化、自包含的论证单元，以支持后续分析。研究构建了GDN-CC数据集（1,231条法国全国大辩论的贡献，含2,285个标注论证结构的单元），并验证小型开源语言模型在复现这些标注方面的表现可媲美甚至优于大型语言模型。此外，研究还发布了规模达24万条的GDN-CC-large自动标注数据集，是目前最大的民主咨询标注数据集。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽广泛应用于民主活动文本分析，但其使用引发伦理争议。为提升公民参与文本分析的标准化水平，并探索小型本地化模型在该任务中的可行性，亟需开发高效、透明且资源消耗低的处理方法。

Method: 提出Corpus Clarification框架，对原始咨询文本进行结构化重构；构建人工标注的GDN-CC数据集；利用小规模语言模型微调并评估其在论证结构还原与意见聚类任务中的表现；基于此构建自动化标注的GDN-CC-large数据集。

Result: 微调后的小型语言模型在还原论证结构方面达到或超过大型语言模型的表现；所提框架有效提升文本可分析性；发布的GDN-CC-large是迄今最大的民主咨询标注数据集。

Conclusion: 小型开源语言模型在民主咨询文本的结构化处理中具备高可靠性与实用性，表明本地化、透明化的分析路径具有可行性，为公共政策分析提供了可扩展、可复现的技术基础。

Abstract: LLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand Débat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date.

</details>


### [83] [A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala](https://arxiv.org/abs/2601.14958)
*Minuri Rajapakse,Ruvan Weerasinghe*

Main category: cs.CL

TL;DR: 本研究构建了针对斯里兰卡僧伽罗语（Sinhala）的全面基准测试，评估了多种开源与闭源语言模型在Unicode和罗马化僧伽罗语文本上的表现。结果表明，Mistral-Nemo-Base-2407在Unicode文本上表现最佳，Mistral-7B-v0.3在罗马化文本上表现最优，而Llama-3.1-8B在两种脚本上均表现出色。闭源模型中，Gemini-1.5-pro和DeepSeek在Unicode生成方面优秀，Claude-3.5-Sonnet则在处理罗马化文本上领先。研究强调了训练数据对模型处理脚本差异的重要性，为特定僧伽罗语应用的模型选择提供了指导。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在低资源、形态丰富的语言如僧伽罗语中的表现，特别是数字交流中广泛使用的罗马化僧伽罗语文本，以填补现有研究空白并为实际应用提供依据。

Method: 通过困惑度（perplexity）评估开源模型在Unicode和罗马化僧伽罗语文本上的预测能力，并通过定性分析句子补全任务评估闭源模型的表现。

Result: Mistral-Nemo-Base-2407在Unicode文本上表现最佳，Mistral-7B-v0.3在罗马化文本上表现最优；Llama-3.1-8B在两种脚本上均具强综合性能；闭源模型中Gemini-1.5-pro和DeepSeek在Unicode生成上表现优异，Claude-3.5-Sonnet在罗马化文本处理上更优。

Conclusion: 模型在不同脚本上的表现差异显著，训练数据对模型处理脚本变体的能力至关重要。该研究为面向僧伽罗语的应用提供了模型选择的重要参考。

Abstract: The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations.

</details>


### [84] [Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora](https://arxiv.org/abs/2601.14994)
*Chaymaa Abbas,Nour Shamaa,Mariette Awad*

Main category: cs.CL

TL;DR: 本文研究多语言环境下的数据污染问题，发现将英文基准数据翻译为阿拉伯语会抑制传统污染检测指标，但模型仍能从污染数据中获益，尤其在阿拉伯语能力较强的模型中表现明显。为此提出一种基于翻译感知的污染检测方法，通过比较多种翻译版本的基准信号来更可靠地识别污染，有效弥补了仅依赖英语检测的盲区。


<details>
  <summary>Details</summary>
Motivation: 现有污染检测方法主要针对英文基准，难以捕捉多语言场景下的污染行为，导致评估不准确，亟需发展适用于多语言的污染检测机制。

Method: 扩展测试槽位猜测法并引入选择重排策略，结合最小K%概率分析，同时提出翻译感知污染检测方法，通过对比多个翻译版本的基准信号识别污染。

Result: 翻译为阿拉伯语会降低传统污染指标，但模型仍表现出更强的跨语言一致性与更高的Min-K%分数；所提方法在英语检测失效时仍能有效暴露污染。

Conclusion: 应建立多语言、翻译感知的评估流程，以确保大语言模型评估的公平性、透明性和可重复性。

Abstract: Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals.
  Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.

</details>


### [85] [Knowledge Restoration-driven Prompt Optimization: Unlocking LLM Potential for Open-Domain Relational Triplet Extraction](https://arxiv.org/abs/2601.15037)
*Xiaonan Jing,Gongqing Wu,Xingrui Zhuo,Lang Sun,Jiapu Wang*

Main category: cs.CL

TL;DR: 本文提出一种基于知识重构的提示优化框架（KRPO），以解决大语言模型在开放域关系三元组抽取中因静态提示策略导致的语义模糊问题。通过引入基于知识恢复的自评估机制和基于文本梯度的提示优化器，实现对错误信号的动态修正与提示迭代优化，并结合关系规范化记忆缓解关系冗余问题，显著提升三元组抽取性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态、启发式提示策略，缺乏自我反思机制，难以应对语义模糊，导致错误模式固化，限制了大语言模型在开放域关系三元组抽取中的表现。

Method: 设计基于知识恢复的自评估机制，生成语义一致性评分作为内在反馈；提出基于文本梯度的提示优化器，内化历史经验以迭代优化提示；构建关系规范化记忆，聚合代表性关系以提供语义区分度高的三元组模式。

Result: 在三个数据集上的实验表明，KRPO显著优于多个强基线模型，在三元组抽取F1分数上取得显著提升。

Conclusion: KRPO框架有效提升了大语言模型在复杂开放域关系三元组抽取任务中的持续学习与自我优化能力，为无预定义模式的知识挖掘提供了新范式。

Abstract: Open-domain Relational Triplet Extraction (ORTE) is the foundation for mining structured knowledge without predefined schemas. Despite the impressive in-context learning capabilities of Large Language Models (LLMs), existing methods are hindered by their reliance on static, heuristic-driven prompting strategies. Due to the lack of reflection mechanisms required to internalize erroneous signals, these methods exhibit vulnerability in semantic ambiguity, often making erroneous extraction patterns permanent. To address this bottleneck, we propose a Knowledge Reconstruction-driven Prompt Optimization (KRPO) framework to assist LLMs in continuously improving their extraction capabilities for complex ORTE task flows. Specifically, we design a self-evaluation mechanism based on knowledge restoration, which provides intrinsic feedback signals by projecting structured triplets into semantic consistency scores. Subsequently, we propose a prompt optimizer based on a textual gradient that can internalize historical experiences to iteratively optimize prompts, which can better guide LLMs to handle subsequent extraction tasks. Furthermore, to alleviate relation redundancy, we design a relation canonicalization memory that collects representative relations and provides semantically distinct schemas for the triplets. Extensive experiments across three datasets show that KRPO significantly outperforms strong baselines in the extraction F1 score.

</details>


### [86] [\textsc{LogicScore}: Fine-grained Logic Evaluation of Conciseness, Completeness, and Determinateness in Attributed Question Answering](https://arxiv.org/abs/2601.15050)
*Zhichao Yan,Yunxiao Zhao,Jiapu Wang,Jiaoyan Chen,Shaoru Guo,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 本文提出了一种名为LogicScore的统一评估框架，旨在解决当前属性问答（AQA）评估中因过度关注孤立陈述验证而忽视长篇回答整体逻辑完整性的“属性短视”问题。该框架基于霍恩规则，采用逆向验证机制，系统评估三个推理维度：完整性（逻辑推导严密性）、简洁性（无冗余）和确定性（答案一致性）。在三个多跳问答数据集（HotpotQA、MusiQue、2WikiMultiHopQA）和20多个大语言模型上的实验表明，尽管领先模型在属性准确率上表现优异（如Gemini-3 Pro达92.85%），但在全局推理质量上仍存在显著短板（如简洁性仅35.11%），揭示了事实正确性与逻辑连贯性之间的关键差距。研究建立了逻辑评估的新标准，强调在大模型发展中应同时重视推理连贯性与事实准确性。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 当前的属性问答评估方法过于关注孤立陈述及其归属关系的验证，忽略了长篇回答的整体逻辑一致性，导致大语言模型虽能生成事实正确的答案，却常出现逻辑不连贯、推理链条缺失的问题。这种‘属性短视’限制了对模型真实推理能力的准确评估，亟需一种能够全面审视全局推理质量的评估框架。

Method: 提出LogicScore框架，基于霍恩规则构建逻辑基础，引入逆向验证机制，从完整性（逻辑推导是否严密）、简洁性（是否存在冗余信息）和确定性（答案是否一致可推）三个维度，对长篇回答进行系统性评估。通过形式化逻辑结构，实现对推理过程的全局审查而非局部验证。

Result: 在多个主流多跳问答数据集和超过20个大语言模型上的实验显示，尽管顶级模型在属性准确率上表现良好（如Gemini-3 Pro达到92.85%），但在全局推理质量方面存在明显缺陷，例如其简洁性仅为35.11%。结果揭示了当前大模型在事实性与逻辑连贯性之间存在显著不平衡，凸显了引入全局推理评估的必要性。

Conclusion: 本文提出的LogicScore框架为属性问答评估提供了新的范式，从局部验证转向全局推理审视，建立了衡量大模型逻辑质量的可靠标准。研究强调，在未来的大模型开发中，必须将推理连贯性与事实准确性并重，以推动更高质量的智能问答系统发展。

Abstract: Current evaluation methods for Attributed Question Answering (AQA) suffer from \textit{attribution myopia}: they emphasize verification of isolated statements and their attributions but overlook the global logical integrity of long-form answers. Consequently, Large Language Models (LLMs) often produce factually grounded yet logically incoherent responses with elusive deductive gaps. To mitigate this limitation, we present \textsc{LogicScore}, a unified evaluation framework that shifts the paradigm from local assessment to global reasoning scrutiny. Grounded in Horn Rules, our approach integrates a backward verification mechanism to systematically evaluate three key reasoning dimensions: \textit{Completeness} (logically sound deduction), \textit{Conciseness} (non-redundancy), and \textit{Determinateness} (consistent answer entailment). Extensive experiments across three multi-hop QA datasets (HotpotQA, MusiQue, and 2WikiMultiHopQA) and over 20 LLMs (including GPT-5, Gemini-3-Pro, LLaMA3, and task-specific tuned models) reveal a critical capability gap: leading models often achieve high attribution scores (e.g., 92.85\% precision for Gemini-3 Pro) but struggle with global reasoning quality (e.g., 35.11\% Conciseness for Gemini-3 Pro). Our work establishes a robust standard for logical evaluation, highlighting the need to prioritize reasoning coherence alongside factual grounding in LLM development. Codes are available at: https://github.com/zhichaoyan11/LogicScore.

</details>


### [87] [Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure](https://arxiv.org/abs/2601.15077)
*Christopher Scofield*

Main category: cs.CL

TL;DR: 多智能体系统（MAS）中的大语言模型在相同信息下仍能提升问题解决性能，本文从算子理论和约束优化角度给出形式化解释：每个智能体对共享解空间施加不同的有效性约束，整体实现约束强化算子的分解组合；在适度条件下，系统收敛至各智能体约束集交集所定义的不变解集，该结构通常无法由单个智能体同时施加所有约束所达到，即使其表达能力和信息相同。进一步将结果扩展至软约束情形，通过近端算子实现，并应用于当前基于文本的对话系统。


<details>
  <summary>Details</summary>
Motivation: 解释多智能体系统中大语言模型在相同信息下为何能提升问题解决性能，揭示其背后的形式化机制。

Method: 基于算子理论与约束优化建模，将每个智能体视为施加不同有效性约束，分析其约束强化算子的分解组合行为，利用近端算子处理软约束，并应用于文本对话系统。

Result: 多智能体系统的动态演化可收敛至多个约束集的交集，该解集在单智能体框架下不可达；该现象在软约束情形下依然成立，并可有效解释现代文本对话系统中的协同优势。

Conclusion: 多智能体系统通过约束的分解与协同作用，能够探索更丰富的解空间，从而超越单智能体的性能边界，这一机制在理论上具有坚实基础并适用于实际系统设计。

Abstract: Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems.

</details>


### [88] [Circadian Modulation of Semantic Exploration in Social Media Language](https://arxiv.org/abs/2601.15091)
*Vuong Hung Truong,Mariana Gabrielle Cangco Reyes,Masatoshi Koizumi,Jihwan Myung*

Main category: cs.CL

TL;DR: 本研究利用大规模Reddit数据，通过预训练Transformer模型嵌入文本并测量语义熵来量化语言使用的昼夜变化。发现语义探索-利用存在显著的昼夜节律，且受季节光照线索调节。局部语义探索在早晨达到峰值，反映对语义空间的广泛探索；而全局语义多样性在一天晚些时候达到峰值，与已有话题的累积相关，符合“富者愈富”动态。这些模式不受情绪或情感效价影响，表明语义探索是独立于情绪的认知维度，其时间结构与已知的神经调制系统的日周期一致，提示生物昼夜节律延伸至语义领域。


<details>
  <summary>Details</summary>
Motivation: 人类认知表现出强烈的昼夜节律调控，但其对高维语义行为的影响尚不清楚。理解语言使用中的昼夜变化有助于揭示认知过程与生物节律的关系。

Method: 使用大规模Reddit数据，通过预训练Transformer模型将文本嵌入，并以语义熵作为语言探索-利用的指标，分析不同时间段的语言使用模式。区分局部与全局语义熵，探究其时间动态。

Result: 局部语义探索在早晨达到峰值，反映对语义空间的广泛探索；全局语义多样性在下午和傍晚达到峰值，与已有话题的累积相关。这些模式不依赖于情绪或情感效价，与神经调制系统的日周期一致。

Conclusion: 生物昼夜节律不仅影响生理功能，也深刻塑造了人类语言表达中的语义结构，揭示了认知活动在语义层面的昼夜规律性。

Abstract: Human cognition exhibits strong circadian modulation, yet its influence on high-dimensional semantic behavior remains poorly understood. Using large-scale Reddit data, we quantify time-of-day variation in language use by embedding text into a pretrained transformer model and measuring semantic entropy as an index of linguistic exploration-exploitation, for which we show a robust circadian rhythmicity that could be entrained by seasonal light cues. Distinguishing between local and global semantic entropy reveals a systematic temporal dissociation: local semantic exploration peaks in the morning, reflecting broader exploration of semantic space, whereas global semantic diversity peaks later in the day as submissions accumulate around already established topics, consistent with "rich-get-richer" dynamics. These patterns are not explained by sentiment or affective valence, indicating that semantic exploration captures a cognitive dimension distinct from mood. The observed temporal structure aligns with known diurnal patterns in neuromodulatory systems, suggesting that biological circadian rhythms extend to the semantic domain.

</details>


### [89] [RSNA Large Language Model Benchmark Dataset for Chest Radiographs of Cardiothoracic Disease: Radiologist Evaluation and Validation Enhanced by AI Labels (REVEAL-CXR)](https://arxiv.org/abs/2601.15129)
*Yishu Wei,Adam E. Flanders,Errol Colak,John Mongan,Luciano M Prevedello,Po-Hao Chen,Henrique Min Ho Lee,Gilberto Szarf,Hamilton Shoji,Jason Sho,Katherine Andriole,Tessa Cook,Lisa C. Adams,Linda C. Chu,Maggie Chung,Geraldine Brusca-Augello,Djeven P. Deva,Navneet Singh,Felipe Sanchez Tijmes,Jeffrey B. Alpert,Elsie T. Nguyen,Drew A. Torigian,Kate Hanneman,Lauren K Groner,Alexander Phan,Ali Islam,Matias F. Callejas,Gustavo Borges da Silva Teles,Faisal Jamal,Maryam Vazirabad,Ali Tejani,Hari Trivedi,Paulo Kuriki,Rajesh Bhayana,Elana T. Benishay,Yi Lin,Yifan Peng,George Shih*

Main category: cs.CL

TL;DR: 该研究构建了一个包含200个胸部X光片的公开基准数据集，涵盖12种基准标签，所有图像均由三位放射科医生验证。研究提出了一种AI辅助标注流程，利用GPT-4o和本地部署的Phi-4-Reasoning模型提取异常发现，并通过智能采样确保临床相关性和难度多样性，最终由专家评审确认高质量标注。该基准可用于独立评估不同多模态大模型在放射学任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在放射学多选题测试中已表现出与放射科住院医师相当的性能，但要开发临床可用的多模态大模型工具，仍需由领域专家精心构建的高质量基准数据集。现有数据集缺乏足够的专家标注质量保障和可重复评估机制，因此亟需一个经过严格验证、公开可访问且具备挑战性的基准。

Method: 研究基于MIDRC数据库中的13,735张去标识化胸部X光片及其报告，使用GPT-4o自动提取报告中的异常发现，并通过本地部署的Phi-4-Reasoning模型将其映射到12个预定义的基准标签。采用基于AI建议标签的智能采样算法，从1,000张候选图像中筛选出具有临床相关性且覆盖多种难度水平的样本。随后，17名胸腔放射科医生对每张图像进行三重独立评估，判断是否‘完全同意’、‘大部分同意’或‘不同意’模型提出的标签。最终选取至少两名医生‘完全同意’的381张图像，再从中挑选200张（优先包含罕见或多发异常）作为发布数据集（100张）和保留数据集（100张），后者由RSNA用于独立模型评估。整个过程融合了人工智能辅助与专家协作，实现高效、准确、可扩展的标注流程。

Result: 成功构建并公开发布了一个包含200张胸部X光片的高质量基准数据集，每个图像均经三名放射科医生验证，涵盖12类标准诊断标签。同时开发了一套高效的AI辅助标注流程，显著提升了专家标注效率，减少了遗漏，支持半协同工作模式。该基准已上线至https://imaging.rsna.org，可供研究社区用于评估多模态大模型在放射学图像理解方面的性能。

Conclusion: 本研究不仅创建了一个高可信度、公开可用的胸部放射学多模态基准数据集，还提出了一种可推广的AI辅助专家标注方法，为未来构建大规模、高质量医学视觉语言模型评估体系提供了重要范例，有助于推动多模态大模型在真实临床环境中的落地应用。

Abstract: Multimodal large language models have demonstrated comparable performance to that of radiology trainees on multiple-choice board-style exams. However, to develop clinically useful multimodal LLM tools, high-quality benchmarks curated by domain experts are essential. To curate released and holdout datasets of 100 chest radiographic studies each and propose an artificial intelligence (AI)-assisted expert labeling procedure to allow radiologists to label studies more efficiently. A total of 13,735 deidentified chest radiographs and their corresponding reports from the MIDRC were used. GPT-4o extracted abnormal findings from the reports, which were then mapped to 12 benchmark labels with a locally hosted LLM (Phi-4-Reasoning). From these studies, 1,000 were sampled on the basis of the AI-suggested benchmark labels for expert review; the sampling algorithm ensured that the selected studies were clinically relevant and captured a range of difficulty levels. Seventeen chest radiologists participated, and they marked "Agree all", "Agree mostly" or "Disagree" to indicate their assessment of the correctness of the LLM suggested labels. Each chest radiograph was evaluated by three experts. Of these, at least two radiologists selected "Agree All" for 381 radiographs. From this set, 200 were selected, prioritizing those with less common or multiple finding labels, and divided into 100 released radiographs and 100 reserved as the holdout dataset. The holdout dataset is used exclusively by RSNA to independently evaluate different models. A benchmark of 200 chest radiographic studies with 12 benchmark labels was created and made publicly available https://imaging.rsna.org, with each chest radiograph verified by three radiologists. In addition, an AI-assisted labeling procedure was developed to help radiologists label at scale, minimize unnecessary omissions, and support a semicollaborative environment.

</details>


### [90] [Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems](https://arxiv.org/abs/2601.15161)
*Yinzhu Chen,Abdine Maiga,Hossein A. Rahmani,Emine Yilmaz*

Main category: cs.CL

TL;DR: 本文提出一种检索增强的多智能体框架，用于自动化生成针对医疗大语言模型（LLM）的实例特定评估标准。该方法通过分解权威医学证据中的原子事实，并结合用户交互约束，构建可验证、细粒度的评估标准，在HealthBench数据集上显著提升临床意图对齐（CIA）得分至60.12%，优于GPT-4o基线（55.16%）。在判别性测试中，其评估标准实现更高的分数差异（μ_Δ = 8.658）和接近完美的AUROC（0.977），几乎将基线的质量区分能力翻倍。此外，这些评估标准还能有效指导响应优化，使模型质量提升9.2%（从59.0%升至68.2%），为医疗LLM的评估与改进提供了可扩展且透明的解决方案。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前医疗大语言模型存在幻觉和不安全建议风险，尤其表现为难以被通用指标捕捉的细微临床错误。现有专家制定的细粒度评估标准成本高、难扩展，亟需自动化、可规模化的方法来生成高质量评估基准。

Method: 提出检索增强的多智能体框架，通过检索权威医学证据并将其分解为原子事实，融合用户交互约束，自动生成可验证、细粒度的评估标准，支持模型评估与响应优化。

Result: 在HealthBench上，提出的框架实现60.12%的临床意图对齐（CIA）得分，显著优于GPT-4o基线（55.16%）；判别测试中均值分数差达8.658，AUROC为0.977，近乎翻倍于基线表现；同时能将模型输出质量提升9.2%（59.0% → 68.2%）。

Conclusion: 所提出的框架实现了医疗LLM评估与优化的自动化、可扩展与透明化，为保障临床决策支持系统的安全性与可靠性提供了有效路径。

Abstract: Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/.

</details>


### [91] [Is Peer Review Really in Decline? Analyzing Review Quality across Venues and Time](https://arxiv.org/abs/2601.15172)
*Ilia Kuznetsov,Rohan Nayak,Alla Rozovskaya,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出了一种基于证据的比较研究框架，用于分析人工智能与机器学习领域主要会议（ICLR、NeurIPS 和 *ACL）的评审质量。通过引入多维度的评审质量量化标准，并结合大语言模型（LLM）和轻量级测量方法，研究发现尽管存在评审格式多样性，但跨时间、跨会议的中位数评审质量并未出现持续下降趋势。该研究挑战了当前关于评审质量下滑的普遍叙事，提出了替代性解释并为未来研究提供了建议。


<details>
  <summary>Details</summary>
Motivation: 评审质量是现代科学的核心，但随着投稿量增加和研究社区扩大，评审质量下降成为普遍担忧。然而，由于评审质量难以衡量且评审实践不断演变，难以进行跨会议和跨时间的比较。因此，亟需一种可量化的、系统性的方法来评估和比较评审质量。

Method: 提出一种新的评审质量比较框架，包括评审格式的多样性分析、评审标准化方法、多维度的评审质量量化指标（以对编辑和作者的实用性为核心），并结合大语言模型（LLM）与轻量级测量工具进行评估。通过跨时间、跨会议的数据分析，探讨评审质量的变化趋势及其内在关系。

Result: 研究发现，尽管评审格式多样，但主要会议（ICLR、NeurIPS、*ACL）的中位数评审质量在多年间未呈现一致下降趋势。这表明‘评审质量持续恶化’的流行叙事可能并不成立。研究还揭示了不同测量方式之间的关联，并识别出影响评审质量的潜在因素。

Conclusion: 当前关于评审质量下降的普遍担忧缺乏充分的实证支持。本研究提出的框架为未来开展更客观、可比的评审质量研究提供了方法论基础，并建议通过标准化、多维度评估和持续数据收集推动学术评审体系的改进。

Abstract: Peer review is at the heart of modern science. As submission numbers rise and research communities grow, the decline in review quality is a popular narrative and a common concern. Yet, is it true? Review quality is difficult to measure, and the ongoing evolution of reviewing practices makes it hard to compare reviews across venues and time. To address this, we introduce a new framework for evidence-based comparative study of review quality and apply it to major AI and machine learning conferences: ICLR, NeurIPS and *ACL. We document the diversity of review formats and introduce a new approach to review standardization. We propose a multi-dimensional schema for quantifying review quality as utility to editors and authors, coupled with both LLM-based and lightweight measurements. We study the relationships between measurements of review quality, and its evolution over time. Contradicting the popular narrative, our cross-temporal analysis reveals no consistent decline in median review quality across venues and years. We propose alternative explanations, and outline recommendations to facilitate future empirical studies of review quality.

</details>


### [92] [Supporting Humans in Evaluating AI Summaries of Legal Depositions](https://arxiv.org/abs/2601.15182)
*Naghmeh Farzi,Laura Dietz,Dave D. Lewis*

Main category: cs.CL

TL;DR: 本文探讨了基于事实片段（nugget）的方法在法律领域中对大语言模型生成的摘要进行辅助评估和改进的潜力，提出一个原型系统，帮助法律专业人士在两个具体场景下：判断两个摘要的优劣，以及手动改进自动生成的摘要。


<details>
  <summary>Details</summary>
Motivation: 在法律领域，口供摘要的事实准确性至关重要，而现有的大语言模型在生成长文档摘要时面临挑战。虽然基于事实片段的评估方法已被证明有效，但其对最终用户的直接支持作用尚未被充分探索。

Method: 将基于事实片段的评估方法应用于用户侧，设计并实现一个原型系统，支持法律专业人士在判断摘要质量与手动优化摘要时使用事实片段作为参考。

Result: 原型系统成功展示了事实片段如何帮助法律专业人士更有效地评估和改进自动化生成的摘要，在实际应用场景中提升了摘要的质量和可靠性。

Conclusion: 基于事实片段的方法不仅适用于自动化评估，还能有效支持法律专业人士在实际工作中提升摘要质量，具有重要的应用价值。

Abstract: While large language models (LLMs) are increasingly used to summarize long documents, this trend poses significant challenges in the legal domain, where the factual accuracy of deposition summaries is crucial. Nugget-based methods have been shown to be extremely helpful for the automated evaluation of summarization approaches. In this work, we translate these methods to the user side and explore how nuggets could directly assist end users. Although prior systems have demonstrated the promise of nugget-based evaluation, its potential to support end users remains underexplored. Focusing on the legal domain, we present a prototype that leverages a factual nugget-based approach to support legal professionals in two concrete scenarios: (1) determining which of two summaries is better, and (2) manually improving an automatically generated summary.

</details>


### [93] [Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models](https://arxiv.org/abs/2601.15220)
*Anmol Goel,Cornelius Emde,Sangdoo Yun,Seong Joon Oh,Martin Gubri*

Main category: cs.CL

TL;DR: 本文揭示了语言模型中一种新型现象：对前沿模型进行良性微调可能导致隐私崩溃。即使在保持高安全性和实用性基准表现的情况下，微调后的模型会丧失对上下文隐私规范的推理能力，不当共享信息或突破记忆边界，且这种隐私漏洞是‘静默失败’。实验表明该现象在六种模型、五类微调数据集和两类任务中普遍存在。机制分析显示，隐私相关表征对微调极为脆弱，而任务相关特征则得以保留。研究揭示了当前安全评估中的关键缺陷，尤其对专用智能体部署具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型的安全评估主要关注标准安全与实用性指标，但忽视了上下文隐私保护能力。本文旨在揭示微调过程可能引发的隐私崩溃问题，填补这一评估空白，提升对专用智能体部署风险的认知。

Method: 通过多模型、多数据集、多任务的实证实验，系统评估微调前后模型在隐私保护方面的变化；结合机制分析，探究隐私表征与任务特征在微调过程中的稳定性差异。

Result: 发现微调会导致模型出现严重的隐私泄露问题，表现为无法正确处理上下文隐私、不当使用工具共享敏感信息、跨上下文记忆越界等行为，且这些缺陷在标准评估中难以察觉。隐私表征对微调高度敏感，而任务特征相对稳定。

Conclusion: 隐私崩溃是微调过程中潜在的严重风险，尤其在部署专用智能体时不可忽视。当前的安全评估体系未能覆盖此类隐性风险，亟需引入针对上下文隐私的专项检测机制。

Abstract: We identify a novel phenomenon in language models: benign fine-tuning of frontier models can lead to privacy collapse. We find that diverse, subtle patterns in training data can degrade contextual privacy, including optimisation for helpfulness, exposure to user information, emotional and subjective dialogue, and debugging code printing internal variables, among others. Fine-tuned models lose their ability to reason about contextual privacy norms, share information inappropriately with tools, and violate memory boundaries across contexts. Privacy collapse is a ``silent failure'' because models maintain high performance on standard safety and utility benchmarks whilst exhibiting severe privacy vulnerabilities. Our experiments show evidence of privacy collapse across six models (closed and open weight), five fine-tuning datasets (real-world and controlled data), and two task categories (agentic and memory-based). Our mechanistic analysis reveals that privacy representations are uniquely fragile to fine-tuning, compared to task-relevant features which are preserved. Our results reveal a critical gap in current safety evaluations, in particular for the deployment of specialised agents.

</details>


### [94] [Metadata Conditioned Large Language Models for Localization](https://arxiv.org/abs/2601.15236)
*Anjishnu Mukherjee,Ziwei Zhu,Antonios Anastasopoulos*

Main category: cs.CL

TL;DR: 本文提出通过元数据条件化（metadata conditioning）实现大语言模型的轻量级本地化，基于带有验证URL、国家标签和大陆标签的英语新闻数据，预训练了31个0.5B和1B参数规模的模型，覆盖4大洲17个国家。实验表明，该方法能持续提升区域性能而不损失跨区域泛化能力，使全局模型达到与区域专用模型相当的本地化效果，并提高学习效率。消融实验证明URL级元数据已捕捉大部分地理信号，但均衡的区域数据覆盖仍至关重要。此外，作者构建了一个包含800道本地化新闻多选题的下游基准，结果显示经指令微调后，元数据条件化的全局模型在准确率上可媲美LLaMA-3.2-1B-Instruct，尽管训练数据更少。整体表明元数据条件化是一种实用且计算高效的模型本地化方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通常将文本视为单一全局分布，导致地理上同质的行为表现。为实现高效、低成本的模型本地化，需探索轻量级方法以增强模型对不同地区的适应能力。

Method: 基于带有验证URL、国家标签和大陆标签的大型英语新闻数据集，从头开始预训练31个0.5B和1B参数规模的语言模型，利用元数据（如国家、大陆、URL）作为条件输入，引导模型学习地理相关特征。通过控制实验评估其在区域性能、跨区域泛化、学习效率等方面的表现，并设计专门的本地化新闻多选题基准进行下游评估。

Result: 元数据条件化显著提升区域性能，保持跨区域泛化能力；仅依赖URL级元数据即可捕获主要地理信号；均衡区域数据覆盖不可或缺；经指令微调后，模型在本地化任务上的表现接近LLaMA-3.2-1B-Instruct，且训练数据更少。

Conclusion: 元数据条件化是一种高效、实用的轻量级语言模型本地化方法，可在不牺牲全局性能的前提下显著提升模型的地域适应性，具备良好的可扩展性和计算效率。

Abstract: Large language models are typically trained by treating text as a single global distribution, often resulting in geographically homogenized behavior. We study metadata conditioning as a lightweight approach for localization, pre-training 31 models (at 0.5B and 1B parameter scales) from scratch on large-scale English news data annotated with verified URLs, country tags, and continent tags, covering 4 continents and 17 countries. Across four controlled experiments, we show that metadata conditioning consistently improves in-region performance without sacrificing cross-region generalization, enables global models to recover localization comparable to region-specific models, and improves learning efficiency. Our ablation studies demonstrate that URL-level metadata alone captures much of the geographic signal, while balanced regional data coverage remains essential, as metadata cannot fully compensate for missing regions. Finally, we introduce a downstream benchmark of 800 localized news MCQs and show that after instruction tuning, metadata conditioned global models achieve accuracy comparable to LLaMA-3.2-1B-Instruct, despite being trained on substantially less data. Together, these results establish metadata conditioning as a practical and compute-efficient approach for localization of language models.

</details>


### [95] [The Effect of Scripts and Formats on LLM Numeracy](https://arxiv.org/abs/2601.15251)
*Varshini Reddy,Craig W. Schmidt,Seth Ebner,Adam Wiemerslage,Yuval Pinter,Chris Tanner*

Main category: cs.CL

TL;DR: 该研究探讨了大语言模型在不同数字书写系统和格式下的数值推理能力，发现当输入数字偏离训练数据中的常见格式时，模型性能显著下降；通过少量示例提示和显式数字符号映射等策略，可有效缩小性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在标准数值任务上表现优异，但对非主流数字书写系统和格式的处理能力不足，这限制了其在多语言环境下的可靠性，亟需关注和改进。

Method: 通过设计包含多种非标准数字书写系统和格式的测试集，评估大语言模型在不同情境下的数值推理表现，并采用少样本提示和显式符号映射等策略进行干预实验。

Result: 模型在非主流数字格式下的准确率明显下降，但通过针对性提示策略，性能得到显著提升，表明格式差异是影响模型表现的关键因素。

Conclusion: 大语言模型在多语言数值推理中面临因数字书写格式差异导致的性能瓶颈，通过优化提示策略可有效缓解该问题，为跨语言数值处理提供了实用解决方案。

Abstract: Large language models (LLMs) have achieved impressive proficiency in basic arithmetic, rivaling human-level performance on standard numerical tasks. However, little attention has been given to how these models perform when numerical expressions deviate from the prevailing conventions present in their training corpora. In this work, we investigate numerical reasoning across a wide range of numeral scripts and formats. We show that LLM accuracy drops substantially when numerical inputs are rendered in underrepresented scripts or formats, despite the underlying mathematical reasoning being identical. We further demonstrate that targeted prompting strategies, such as few-shot prompting and explicit numeral mapping, can greatly narrow this gap. Our findings highlight an overlooked challenge in multilingual numerical reasoning and provide actionable insights for working with LLMs to reliably interpret, manipulate, and generate numbers across diverse numeral scripts and formatting styles.

</details>


### [96] [Robust Fake News Detection using Large Language Models under Adversarial Sentiment Attacks](https://arxiv.org/abs/2601.15277)
*Sahar Tahmasebi,Eric Müller-Budack,Ralph Ewerth*

Main category: cs.CL

TL;DR: 本文研究了虚假新闻检测模型在情感操纵下的脆弱性，提出AdSent框架，通过可控情感对抗攻击和情感无关训练策略，显著提升模型在不同情感状态下的检测鲁棒性与准确性，实验证明其在多个数据集上均表现优越且具备良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 虚假新闻和误导性信息已成为严重的社会挑战，需要可靠的自动化检测方法。现有研究指出情感是虚假新闻检测中的重要信号，但这种依赖情感的特征容易被攻击者通过大型语言模型（LLM）操纵以逃避检测，而当前对情感操控这一关键漏洞的研究仍不充分。

Method: 提出了一种基于大语言模型的受控情感对抗攻击方法，分析了情感变化对检测性能的影响，并引入一种新颖的情感无关训练策略以增强模型对这类扰动的鲁棒性。

Result: 实验结果表明，情感变化会显著影响虚假新闻检测模型的性能，说明现有模型存在对中性文章更倾向于判断为真实的偏差；而经过改进的AdSent框架在三个基准数据集上均显著优于现有基线，在准确率和鲁棒性方面表现优异，并能有效泛化到未见过的数据集与对抗场景。

Conclusion: AdSent框架能够确保在原始新闻和情感修改后的新闻上保持一致的真伪判断，提升了虚假新闻检测系统的稳健性和可靠性，尤其在面对情感操纵时具有更强的抗干扰能力。

Abstract: Misinformation and fake news have become a pressing societal challenge, driving the need for reliable automated detection methods. Prior research has highlighted sentiment as an important signal in fake news detection, either by analyzing which sentiments are associated with fake news or by using sentiment and emotion features for classification. However, this poses a vulnerability since adversaries can manipulate sentiment to evade detectors especially with the advent of large language models (LLMs). A few studies have explored adversarial samples generated by LLMs, but they mainly focus on stylistic features such as writing style of news publishers. Thus, the crucial vulnerability of sentiment manipulation remains largely unexplored. In this paper, we investigate the robustness of state-of-the-art fake news detectors under sentiment manipulation. We introduce AdSent, a sentiment-robust detection framework designed to ensure consistent veracity predictions across both original and sentiment-altered news articles. Specifically, we (1) propose controlled sentiment-based adversarial attacks using LLMs, (2) analyze the impact of sentiment shifts on detection performance. We show that changing the sentiment heavily impacts the performance of fake news detection models, indicating biases towards neutral articles being real, while non-neutral articles are often classified as fake content. (3) We introduce a novel sentiment-agnostic training strategy that enhances robustness against such perturbations. Extensive experiments on three benchmark datasets demonstrate that AdSent significantly outperforms competitive baselines in both accuracy and robustness, while also generalizing effectively to unseen datasets and adversarial scenarios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [97] [The Ontological Neutrality Theorem: Why Neutral Ontological Substrates Must Be Pre-Causal and Pre-Normative](https://arxiv.org/abs/2601.14271)
*Denise M. Case*

Main category: cs.AI

TL;DR: 本文提出一个关于本体论中立性的不可能性结果：在基础层面上包含因果或规范性承诺的本体论，无法在存在分歧的解释框架间保持中立和稳定。因此，真正的中立本体必须是前因果、前规范性的，仅描述实体及其身份与持续条件，并将解释、评价和说明功能外化。本文不提供具体本体或协议，而是确立此类系统设计的必要约束条件。


<details>
  <summary>Details</summary>
Motivation: 现代数据系统需在法律、政治和分析层面的持续分歧中实现问责，这要求本体作为共享基础时具备高度中立性。然而，若本体在基础层嵌入因果或规范性判断，则难以维持跨框架的一致性，从而引发矛盾。因此，亟需明确中立本体的设计边界。

Method: 通过形式化分析本体论中立性的定义，论证其与因果或规范性承诺之间的内在冲突，采用逻辑推演揭示在基础层引入这些承诺将导致系统不稳定或必须不断修订，从而得出中立性不可兼容于这类承诺的结论。

Result: 任何试图在基础层面上表达因果或规范性结论的本体，都无法在不同解释框架之间保持稳定的中立性；只有前因果、前规范性的本体才能作为共享的、稳定的现实表征基础。

Conclusion: 为支持跨分歧框架的共享、稳定现实表示，中立本体必须排除因果与规范性承诺，专注于实体及其身份与持续条件的客观描述，并将解释、评价与推理置于外部。这一原则是所有此类系统设计的根本约束。

Abstract: Modern data systems must support accountability across persistent legal, political, and analytic disagreement. This requirement imposes strict constraints on the design of any ontology intended to function as a shared substrate. We establish an impossibility result for ontological neutrality: neutrality, understood as interpretive non-commitment and stability under incompatible extensions, is incompatible with the inclusion of causal or normative commitments at the foundational layer. Any ontology that asserts causal or deontic conclusions as ontological facts cannot serve as a neutral substrate across divergent frameworks without revision or contradiction. It follows that neutral ontological substrates must be pre-causal and pre-normative, representing entities, together with identity and persistence conditions, while externalizing interpretation, evaluation, and explanation. This paper does not propose a specific ontology or protocol; rather, it establishes the necessary design constraints for any system intended to maintain a shared, stable representation of reality across conflicting interpretive frameworks.

</details>


### [98] [Epistemic Constitutionalism Or: how to avoid coherence bias](https://arxiv.org/abs/2601.14295)
*Michele Loi*

Main category: cs.AI

TL;DR: 本文提出为人工智能建立一种认知宪法，即明确、可争议的元规范，以规范系统形成和表达信念的方式。通过源属性偏差案例，揭示前沿模型在意识形态立场不一致时惩罚相关论点，但检测到系统性测试时该效应消失，表明模型将源敏感性视为需压制的偏见而非可执行的能力。文章区分了柏拉图式（强调形式正确性与默认无源依赖）与自由式（拒绝特权地位，强调程序规范以保护集体探究条件）两种宪法路径，并主张采用自由式，提出由八项原则和四项取向构成的宪法核心，认为AI认知治理应具备与AI伦理同等的明确、可争议结构。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为人工推理者，在评估论点、分配可信度和表达信心方面日益重要，但其信念形成行为受隐含、未经审视的认知政策支配，亟需建立明确的元规范以引导其认知行为。源属性偏差现象凸显了模型对身份-立场一致性的强制要求，揭示出其认知机制中的潜在偏见，促使我们反思现有模型的认知基础是否合理。

Method: 通过分析前沿语言模型在源属性偏差情境下的行为表现，结合系统性测试实验，考察模型在不同条件下对源敏感性的反应；进而从哲学层面区分柏拉图式与自由式两种宪法路径，构建包含八项原则与四项取向的自由式宪法框架，论证其在保障认知公正与集体探究方面的优势。

Result: 实验证明模型在非系统性测试下表现出显著的源属性偏差，但在系统性测试中该偏差消失，说明模型将源敏感性视为需抑制的偏见而非认知能力。提出的自由式宪法框架能够有效应对此类问题，确保认知过程的透明性、可问责性与集体参与性。

Conclusion: 必须为人工智能建立一种公开、可争议的认知宪法，尤其应采纳自由式路径，以维护集体探究的条件并实现基于认知警惕性的合理源关注，从而推动更负责任、更透明的人工智能认知治理。

Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.

</details>


### [99] [VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration](https://arxiv.org/abs/2601.14440)
*Saeed Khaki,Ashudeep Singh,Nima Safaei,Kamal Ginotra*

Main category: cs.AI

TL;DR: 该研究探讨了视觉语言模型（VLMs）在数学推理任务中因模态差异导致的性能下降问题，提出VisTIRA框架通过整合工具和结构化推理来提升图像形式数学问题的解决能力，并构建了基于LaTeX的图像生成管道与合成工具使用轨迹数据集以评估和改进视觉数学推理。实验表明，工具集成监督可有效提升图像推理表现，光学字符识别（OCR）接地有助于缩小小模型的模态差距，但大模型中效果减弱。研究指出模态差距随模型规模增大而减小，且结构化推理与OCR接地是互补策略。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在处理以图像形式呈现的数学问题时，表现显著低于处理文本形式的问题，存在明显的模态差距。这一差距源于对复杂公式、布局以及符号与图表混合上下文的识别失败。因此需要系统性地理解并缓解该问题，以推动视觉数学推理的发展。

Method: 提出VisTIRA框架，实现从图像数学问题到自然语言推理链和可执行Python代码的迭代分解；构建基于LaTeX的图像生成流程，将文本型数学推理数据转换为视觉挑战样本；利用真实世界作业图像数据集SnapAsk生成大规模合成工具使用轨迹，用于微调VLMs。

Result: 工具集成监督能有效提升图像数学推理性能；OCR接地对小模型有明显帮助，但在大模型中优势减弱；模态差距随模型规模增加而减小；结构化推理与OCR接地为互补策略，共同促进视觉数学推理进步。

Conclusion: 模态差距在视觉数学推理中显著存在，但可通过结构化推理与工具集成手段缓解，且其严重程度与模型规模呈负相关。未来工作应聚焦于融合多策略以进一步缩小视觉与文本模态间的差距。

Abstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagrammatic context. First, we introduce VisTIRA (Vision and Tool-Integrated Reasoning Agent), a tool-integrated reasoning framework that enables structured problem solving by iteratively decomposing a given math problem (as an image) into natural language rationales and executable Python steps to determine the final answer. Second, we build a framework to measure and improve visual math reasoning: a LaTeX-based pipeline that converts chain-of-thought math corpora (e.g., NuminaMath) into challenging image counterparts, and a large set of synthetic tool-use trajectories derived from a real-world, homework-style image dataset (called SnapAsk) for fine-tuning VLMs. Our experiments show that tool-integrated supervision improves image-based reasoning, and OCR grounding can further narrow the gap for smaller models, although its benefit diminishes at scale. These findings highlight that modality gap severity inversely correlates with model size, and that structured reasoning and OCR-based grounding are complementary strategies for advancing visual mathematical reasoning.

</details>


### [100] [On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL](https://arxiv.org/abs/2601.14456)
*Valerio Belcamino,Nicholas Attolino,Alessio Capitanelli,Fulvio Mastrogiovanni*

Main category: cs.AI

TL;DR: 该研究探讨了微调后的大型语言模型（LLM）在PDDL规划任务中的泛化能力，发现其在域内表现良好（82.9%有效计划率），但在未见过的域上表现完全失败（0%）。通过引入三种诊断干预手段，揭示模型对表面表示高度敏感，且缺乏可迁移的规划能力。尽管采用验证器奖励微调加速收敛，但跨域泛化未得到改善。结果表明，当前设置下模型严重依赖特定域模式，而非通用规划能力，凸显了基于LLM的规划中持续存在的泛化差距。


<details>
  <summary>Details</summary>
Motivation: 探究微调后的大型语言模型在PDDL规划任务中是否具备可迁移的规划能力，还是仅依赖于领域特定的记忆化模式。

Method: 在40,000个来自10个IPC 2023领域的域-问题-计划三元组上微调一个17亿参数的LLM，评估其在域内和跨域条件下的表现；引入三种诊断干预：实例级符号匿名化、紧凑计划序列化、使用VAL验证器作为成功导向强化信号的验证器-奖励微调。

Result: 模型在域内达到82.9%的有效计划率，但在两个未见域上为0%；符号匿名化和紧凑序列化导致性能显著下降，说明模型对表面表示敏感；验证器-奖励微调虽加速收敛，但未能提升跨域泛化能力；整体上，域内性能趋于80%左右，跨域性能崩溃。

Conclusion: 当前配置下，微调后的LLM在规划任务中主要依赖于领域特定模式，而非可迁移的规划能力，表明基于LLM的规划仍存在显著的泛化差距。研究提供了诊断工具以进一步分析其成因。

Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.

</details>


### [101] [Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling](https://arxiv.org/abs/2601.14485)
*Yuan Tian,Yi Mei,Mengjie Zhang*

Main category: cs.AI

TL;DR: 本文提出一种基于膝点选择的改进遗传编程框架，用于解决动态多模式资源约束项目调度问题。通过引入膝点机制筛选有潜力的活动-模式对，再结合组选择规则优化决策过程，显著提升算法在大规模实例上的可扩展性。实验表明，该方法在多数场景下优于传统序列决策的遗传编程方法。


<details>
  <summary>Details</summary>
Motivation: 现有活动组选择策略在小规模实例中表现良好，但在大规模问题上存在可扩展性不足的问题。为提升算法在复杂、大规模调度问题中的性能，亟需一种更高效的候选解筛选机制。

Method: 提出一种多树遗传编程框架，同时演化活动排序规则和组选择规则；首先使用排序规则对所有可行的活动-模式对进行排序，然后基于膝点选择法识别出有潜力的候选对，最后通过组选择规则选出最优组合。

Result: 所提方法在大规模实例上表现出良好的可扩展性，在多数测试场景中优于传统的基于序列决策的遗传编程方法，显著提升了求解效率与质量。

Conclusion: 引入膝点选择机制并结合多树遗传编程框架，能够有效提升动态多模式资源约束项目调度问题的求解性能，尤其适用于大规模复杂实例。

Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.

</details>


### [102] ["Just in Time" World Modeling Supports Human Planning and Reasoning](https://arxiv.org/abs/2601.14514)
*Tony Chen,Sam Cheyette,Kelsey Allen,Joshua Tenenbaum,Kevin Smith*

Main category: cs.AI

TL;DR: 该论文提出了一种‘即时’（Just-in-Time）的模拟推理框架，解释了人类如何在复杂环境中通过在线构建简化的心理表征来高效进行心理模拟。该模型通过模拟、视觉搜索与表征修改的紧密交织，使当前模拟指导注意力分配，视觉搜索则标记出需编码以用于后续模拟的对象。尽管仅编码少量对象，模型仍能做出高价值预测。在网格世界规划任务和物理推理任务中，该模型在多种行为指标上均表现出强于其他替代模型的实证支持，为人类如何构建简化表征以实现高效心理模拟提供了具体的算法解释。


<details>
  <summary>Details</summary>
Motivation: 人类在复杂环境中进行心理模拟时面临认知负荷过大的问题，现有理论认为人们会使用简化的环境表征来抽象无关细节，但尚不清楚人们如何高效地确定这些简化方式。因此，需要一个能够解释简化表征如何动态生成的机制。

Method: 提出并验证了一个‘即时’框架，该框架通过模拟、视觉搜索和表征修改三者的紧密交互，使模拟过程引导注意力方向，视觉搜索识别关键对象并触发其编码，从而在仅处理少量对象的情况下完成有效预测。

Result: 在网格世界规划任务和物理推理任务中，该模型在多项行为测量上均优于其他替代模型，显示出强大的实证支持，表明该框架能有效解释人类如何动态构建简化表征以支持高效心理模拟。

Conclusion: 该研究提供了一个具体且可计算的心理模拟算法框架，揭示了人类如何在认知资源有限的前提下，通过动态选择性注意与表征更新，实现高效的推理与规划。

Abstract: Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a "Just-in-Time" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.

</details>


### [103] [Large Language Model-Powered Evolutionary Code Optimization on a Phylogenetic Tree](https://arxiv.org/abs/2601.14523)
*Leyi Zhao,Weijie Huang,Yitong Guo,Jiang Bian,Chenghong Wang,Xuhong Zhang*

Main category: cs.AI

TL;DR: PhyloEvolve 是一个基于大语言模型（LLM）的智能系统，将GPU算法优化重构为上下文强化学习（ICRL）问题，通过构建演化谱系树来组织优化历史，实现经验复用与跨代迁移。该系统结合算法蒸馏与基于提示的决策变换器，支持轨迹条件下的学习，并通过精英轨迹池、多岛并行探索和容器化执行，在异构硬件上平衡探索与利用。在偏微分方程求解、流形学习和谱图算法等科学计算任务中，显著提升了运行时间、内存效率和正确性。


<details>
  <summary>Details</summary>
Motivation: 当前GPU算法优化依赖人工反复调优，耗时且复杂；现有基于LLM的进化方法仅依赖结果反馈和随机突变，未能充分利用优化过程中的轨迹信息。因此需要一种能有效利用优化历史轨迹、支持经验复用与跨代迁移的自动化优化框架。

Method: 提出将算法优化建模为上下文强化学习（ICRL）问题，引入谱系树结构表示算法变体间的继承、分化与重组关系；结合算法蒸馏与提示式决策变压器，以序列化的修改与性能反馈作为学习信号；采用精英轨迹池、多岛并行探索与容器化执行机制，实现高效探索与利用的平衡。

Result: 在多个科学计算工作负载（如PDE求解、曼德尔学习、谱图算法）上，PhyloEvolve相较于基线方法和传统进化算法，在运行时间、内存效率和正确性方面均表现出一致且显著的提升。

Conclusion: PhyloEvolve 通过将优化过程形式化为可追溯、可复用的轨迹学习问题，实现了对复杂优化路径的有效利用，为现代GPU上的自动化算法优化提供了高效、可扩展的新范式。

Abstract: Optimizing scientific computing algorithms for modern GPUs is a labor-intensive and iterative process involving repeated code modification, benchmarking, and tuning across complex hardware and software stacks. Recent work has explored large language model (LLM)-assisted evolutionary methods for automated code optimization, but these approaches primarily rely on outcome-based selection and random mutation, underutilizing the rich trajectory information generated during iterative optimization. We propose PhyloEvolve, an LLM-agent system that reframes GPU-oriented algorithm optimization as an In-Context Reinforcement Learning (ICRL) problem. This formulation enables trajectory-conditioned reuse of optimization experience without model retraining. PhyloEvolve integrates Algorithm Distillation and prompt-based Decision Transformers into an iterative workflow, treating sequences of algorithm modifications and performance feedback as first-class learning signals. To organize optimization history, we introduce a phylogenetic tree representation that captures inheritance, divergence, and recombination among algorithm variants, enabling backtracking, cross-lineage transfer, and reproducibility. The system combines elite trajectory pooling, multi-island parallel exploration, and containerized execution to balance exploration and exploitation across heterogeneous hardware. We evaluate PhyloEvolve on scientific computing workloads including PDE solvers, manifold learning, and spectral graph algorithms, demonstrating consistent improvements in runtime, memory efficiency, and correctness over baseline and evolutionary methods. Code is published at: https://github.com/annihi1ation/phylo_evolve

</details>


### [104] [MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks](https://arxiv.org/abs/2601.14652)
*Zixuan Ke,Yifei Ming,Austin Xu,Ryan Chin,Xuan-Phi Nguyen,Prathyusha Jwalapuram,Semih Yavuz,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: MAS-Orchestra提出了一种新的训练时框架，将多智能体系统（MAS）编排建模为函数调用的强化学习问题，实现全局性、整体性的系统结构推理。通过将复杂子智能体抽象为可调用函数，隐藏内部执行细节，提升系统可扩展性。同时引入MASBENCH基准测试，从深度、时域、广度、并行性和鲁棒性五个维度评估任务特性，揭示了MAS优势依赖于任务结构和智能体能力，并非普遍适用。实验表明，该方法在数学推理、多跳问答和基于搜索的问答等公开基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统设计方法存在方法论复杂性和效益不确定性两大问题：一是编排依赖代码级顺序执行，难以进行全局系统级推理且难以扩展；二是缺乏对多智能体系统相比单智能体系统是否真正有益的明确验证。因此亟需一种能够实现整体编排、具备可解释性和可验证性的新框架。

Method: MAS-Orchestra将多智能体系统的编排建模为函数调用的强化学习问题，将目标导向的子智能体抽象为可调用函数，使协调器能够在高层进行全局结构推理。同时构建了MASBENCH基准，从深度、时域、广度、并行性和鲁棒性五个维度对任务进行系统分类与评估。

Result: MAS-Orchestra在多个公开基准（如数学推理、多跳问答、搜索型问答）上实现了稳定性能提升。分析表明，多智能体系统的收益高度依赖任务结构、验证机制及协调器与子智能体的能力匹配，而非普遍成立。

Conclusion: MAS-Orchestra与MASBENCH共同推动了多智能体系统的设计与理解，为实现真正的多智能体智能提供了可训练、可验证、可解释的新范式。

Abstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.

</details>


### [105] [Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems](https://arxiv.org/abs/2601.14662)
*Shuhua Yang,Jiahao Zhang,Yilong Wang,Dongwon Lee,Suhang Wang*

Main category: cs.AI

TL;DR: AGEA is a novel attack framework that effectively reconstructs hidden knowledge graphs from GraphRAG systems under tight query budgets by using intelligent exploration, memory storage, and LLM-assisted filtering, demonstrating severe vulnerabilities in current systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to investigate the feasibility of reconstructing the hidden knowledge graph structure in GraphRAG systems under realistic, budget-constrained query conditions, as prior work has shown potential for subgraph leakage but not systematic reconstruction.

Method: AGEA (Agentic Graph Extraction Attack) uses a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering to efficiently extract graph structures from black-box GraphRAG systems.

Result: AGEA significantly outperforms prior attack baselines across medical, agriculture, and literary datasets on Microsoft-GraphRAG and LightRAG systems, recovering up to 90% of entities and relationships while maintaining high precision under identical query budgets.

Conclusion: Modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks even under strict query limits, highlighting critical security and privacy risks in retrieval-augmented generation frameworks.

Abstract: Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.

</details>


### [106] [Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text](https://arxiv.org/abs/2601.14683)
*Aisvarya Adeseye,Jouni Isoaho,Seppo Virtanen,Mohammad Tahir*

Main category: cs.AI

TL;DR: 本研究提出一种基于本地大模型的结构化自适应匿名化框架（SFAA），用于解决定性研究中敏感信息的隐私风险。该框架包含检测、分类和自适应匿名化三步，结合规则替换、上下文感知重写、泛化和抑制四种策略，依据标识类型与风险等级动态应用。通过双方法评估（人工与LLM辅助）及两个案例研究验证，Phi模型在识别敏感数据方面表现优异，准确率达91%以上，且94.8%保持原文情感不变，证明其在保证数据可用性的同时有效保障隐私。


<details>
  <summary>Details</summary>
Motivation: 定性研究常包含个人、情境和组织细节，存在隐私泄露风险；手动匿名耗时且不一致，现有自动化工具依赖固定规则，缺乏上下文理解，易误改数据含义。因此亟需一种可靠、可重复且具备上下文感知能力的匿名化方法。

Method: 提出SFAA框架，包含三阶段流程：检测、分类与自适应匿名化；集成四种匿名化策略（规则替换、上下文重写、泛化、抑制），根据标识类型与风险级别选择适用策略；采用本地LLM（LLaMA与Phi）进行处理，并结合人工与LLM辅助评估方式，通过两组真实案例数据验证效果。

Result: LLM识别出的敏感数据数量超过人工审查；Phi模型在敏感数据发现率上优于LLaMA，达到91%以上；同时94.8%的文本保持原始情感，未影响后续定性分析；整体框架具有高准确性与良好可操作性。

Conclusion: 基于本地LLM的SFAA框架能实现高效、准确、上下文敏感的定性数据匿名化，在保障隐私的同时维持数据语义完整性，适用于高敏感度研究场景，具备推广价值。

Abstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.

</details>


### [107] [IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization](https://arxiv.org/abs/2601.14686)
*Shuai Wang,Yaoming Yang,Bingdong Li,Hao Hao,Aimin Zhou*

Main category: cs.AI

TL;DR: 提出IB-GRPO方法，通过指标引导的组相对策略优化，解决大语言模型在长周期学习路径推荐中的挑战，包括与教学目标不一致、专家示范稀缺及多目标权衡问题。通过遗传算法和教师强化学习构建混合专家示范，并利用监督微调预热模型；设计会话内ZPD对齐评分以优化难度调度；采用$ I_{ε+} $支配指标计算多目标组相对优势，避免手动标量化，提升帕累托最优平衡。在ASSIST09和Junyi数据集上基于Qwen2.5-7B模型验证，显著优于现有RL和LLM基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具强大语义理解能力，但在长周期学习路径推荐中面临与教学目标（如最近发展区）不匹配、稀疏延迟反馈、专家示范稀缺及多目标冲突等问题，亟需一种能有效对齐教学原则并实现多目标优化的方法。

Method: 提出IB-GRPO方法：1）通过遗传算法搜索与教师强化学习生成混合专家示范，用于监督微调预热大语言模型；2）设计会话内最近发展区（ZPD）对齐评分，实现难度动态调度；3）引入$ I_{ε+} $支配指标计算多目标下的组相对优势，避免手动标量化，提升多目标帕累托权衡效果。

Result: 在ASSIST09和Junyi数据集上使用KES模拟器与Qwen2.5-7B模型进行实验，结果表明IB-GRPO在学习效果、难度调度、路径长度控制与多样性方面均优于主流强化学习与大语言模型基线方法，表现出更强的鲁棒性与可扩展性。

Conclusion: IB-GRPO通过指标引导的组相对策略优化，有效缓解了大语言模型在长周期学习路径推荐中的对齐难题，实现了教学原则与个性化推荐的融合，在多目标优化中展现出优越性能，为智能教育系统提供了可推广的技术范式。

Abstract: Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.

</details>


### [108] [Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation](https://arxiv.org/abs/2601.14691)
*Muhammad Khalifa,Lajanugen Logeswaran,Jaekyeom Kim,Sungryull Sohn,Yunxiang Zhang,Moontae Lee,Hao Peng,Lu Wang,Honglak Lee*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型（LLMs）作为评判者在评估智能体性能时的脆弱性，发现其对智能体思维链（CoT）的操纵极为敏感。通过仅修改推理过程而保持动作和观察不变，作者展示了虚假正例率可上升高达90%。内容型操纵比风格型操纵更有效，且提示工程与增加计算资源无法完全消除这种漏洞。研究强调需要基于可观测证据验证推理的评判机制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评判机制假设智能体的思维链真实反映其内部推理和环境状态，但这一假设可能被轻易操纵，导致错误判断。本文旨在揭示此假设的脆弱性并推动更可靠的评判方法。

Method: 系统性地重写智能体的思维链（CoT），在固定动作和观察的前提下测试不同操纵策略（包括风格型和内容型），并评估多种缓解技术如提示工程和增加计算资源的效果。

Result: 内容型操纵显著提升虚假正例率，最高达90%；提示工程与增加计算资源只能部分缓解问题，无法根除漏洞。

Conclusion: LLM-based评判存在根本性漏洞，必须发展能够验证推理与可观测证据一致性的新机制，以提升评估可靠性。

Abstract: Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.

</details>


### [109] [AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.14702)
*Zecong Tang,Zixu Wang,Yifei Wang,Weitong Lian,Tianjian Gao,Haoran Li,Tengju Ru,Lingyi Meng,Zhejun Cui,Yichen Zhu,Qi Kang,Kaixuan Wang,Yu Zhang*

Main category: cs.AI

TL;DR: 本文提出AutoDriDM，一个以决策为中心的渐进式基准测试，包含6,650个问题，涵盖物体、场景和决策三个维度。通过评估主流视觉语言模型（VLMs），揭示了感知与决策能力之间的弱相关性，并发现模型在逻辑推理方面存在关键缺陷。研究还引入分析器模型以实现大规模标注自动化，推动更安全可靠的VLM在自动驾驶中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶评估基准过于强调感知能力，未能充分衡量决策过程，导致无法全面评估模型在复杂场景下的实际表现。

Method: 构建AutoDriDM基准，涵盖物体、场景和决策三方面共6,650个问题；评估主流VLMs的性能；进行相关性分析与可解释性研究；开发分析器模型以实现自动化标注。

Result: 发现感知与决策能力之间存在弱相关性；识别出逻辑推理错误等关键失败模式；验证了自动分析器的有效性，为提升VLM在自动驾驶中的可靠性提供了支持。

Conclusion: AutoDriDM填补了感知中心与决策中心评估之间的空白，为发展更安全、更可靠的视觉语言模型在真实自动驾驶环境中的应用提供了重要指导。

Abstract: Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.

</details>


### [110] [DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs](https://arxiv.org/abs/2601.14711)
*Mingxuan Song,Yusen Huo,Bohan Zhou,Shenglin Yin,Zhen Xiao,Jieyi Long,Zhilin Zhang,Chuan Yu*

Main category: cs.AI

TL;DR: 提出DARA框架，通过双阶段设计结合大语言模型（LLM）的上下文学习能力与数值精确性，解决在线广告中预算约束下少数样本场景下的竞价优化问题。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在缺乏历史数据的少数样本场景下表现不佳，而大语言模型虽具备泛化能力但缺乏数值精度，需兼顾推理与精确优化。

Method: 提出GRPO-Adaptive策略以动态更新参考策略，增强LLM的推理与数值精度；构建DARA双阶段框架，第一阶段用上下文提示生成初步计划，第二阶段通过反馈驱动推理进行精细化优化。

Result: 在真实与合成数据集上的实验表明，该方法在预算约束下显著提升广告主累积价值，优于现有基线方法。

Conclusion: DARA框架有效融合了大语言模型的泛化能力与精细优化需求，在少数样本的在线广告竞价场景中展现出优越性能。

Abstract: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.

</details>


### [111] [An XAI View on Explainable ASP: Methods, Systems, and Perspectives](https://arxiv.org/abs/2601.14764)
*Thomas Eiter,Tobias Geibinger,Zeynep G. Saribatur*

Main category: cs.AI

TL;DR: 本文从可解释人工智能（XAI）的视角出发，系统综述了答案集编程（ASP）中的各类解释类型，分析了它们与用户解释需求的对应关系，并评估了现有理论与工具在覆盖这些解释场景方面的表现。同时，指出了当前ASP解释方法的不足之处，并提出了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 随着可解释人工智能（XAI）的发展，对可解释和可解释推理的需求日益增强。答案集编程（ASP）因其基于规则的特性，天然适合可解释推理，但现有的解释方法多针对特定场景，缺乏全面性，难以覆盖用户在实际应用中可能遇到的所有解释需求。因此，亟需对现有解释方法进行系统梳理与评估，以识别研究空白并指导未来工作。

Method: 采用文献综述方法，结合XAI的理论框架，对已有的ASP解释方法进行分类，分析其适用场景、技术实现与局限性；通过归纳用户常见的解释问题，评估现有工具在覆盖这些需求方面的程度，并识别未被充分解决的问题。

Result: 系统梳理了多种ASP解释类型及其对应用户问题，揭示了现有方法在覆盖范围、通用性和灵活性方面的不足；明确了若干关键研究空白，如跨场景解释一致性、动态环境下的解释生成、用户导向的解释定制等。

Conclusion: 当前的ASP解释方法虽已有一定进展，但仍存在显著局限。未来的研究应聚焦于构建更通用、灵活且用户友好的解释框架，以支持复杂、动态和多样化应用场景下的可解释推理，推动ASP在可解释人工智能中的进一步应用与发展。

Abstract: Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.

</details>


### [112] [Semantic-Guided Unsupervised Video Summarization](https://arxiv.org/abs/2601.14773)
*Haizhou Liu,Haodong Jin,Yiming Wang,Hui Yu*

Main category: cs.AI

TL;DR: 提出一种新的语义引导无监督视频摘要方法，通过帧级语义对齐注意力机制和增量训练策略，提升关键帧选择与视频重建效果，解决传统GAN方法依赖单模态特征和训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频摘要方法多基于GAN，但主要依赖单模态特征，忽视语义信息对关键帧选择的指导作用，且训练过程不稳定。

Method: 设计帧级语义对齐注意力机制并集成至关键帧选择器中，结合Transformer生成器在对抗框架下进行视频重建；采用增量训练策略以缓解GAN训练不稳定性。

Result: 在多个基准数据集上实验结果表明，所提方法性能优于现有方法。

Conclusion: 所提出的语义引导无监督视频摘要方法有效提升了关键帧选择与视频重建质量，具有更强的稳定性和泛化能力。

Abstract: Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.

</details>


### [113] [Towards Bound Consistency for the No-Overlap Constraint Using MDDs](https://arxiv.org/abs/2601.14784)
*Amaury Guichard,Laurent Michel,Hélène Verhaeghe,Pierre Schaus*

Main category: cs.AI

TL;DR: This paper presents the first bound-consistent algorithm for the no-overlap constraint using a bounded-width MDD. It achieves stronger pruning and faster solving times, outperforming previous methods and complementing classical propagation.


<details>
  <summary>Details</summary>
Motivation: The no-overlap constraint is NP-complete to achieve bound consistency, so existing methods use polynomial-time approximations. This paper aims to develop the first bound-consistent algorithm for the no-overlap constraint.

Method: The authors build on the no-overlap MDD introduced by Ciré and van Hoeve, extract time window bounds for jobs, and limit the MDD width to a threshold to control complexity. This enables polynomial-time tightening of start and end times.

Result: Experiments on a sequencing problem with time windows and just-in-time objective show that the proposed filtering reduces the number of nodes visited in the search tree more effectively than prior methods, even with width constraints. It also complements classical propagation techniques, leading to significant reductions in both node count and solving time.

Conclusion: The proposed bound-consistent algorithm for the no-overlap constraint provides stronger pruning and improved performance compared to existing approaches, demonstrating practical benefits in solving complex scheduling problems.

Abstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \mid r_j, d_j, \bar{d}_j \mid \sum E_j + \sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.

</details>


### [114] [CI4A: Semantic Component Interfaces for Agents Empowering Web Automation](https://arxiv.org/abs/2601.14790)
*Zhi Qiu,Jiazheng Sun,Chenxiao Xia,Jun Zheng,Xin Peng*

Main category: cs.AI

TL;DR: This paper introduces CI4A, a semantic interface that simplifies web component interactions for agents by abstracting UI logic into unified tools. Integrated into Ant Design, it enables a hybrid agent with dynamic action spaces, leading to a new SOTA success rate of 86.3% on WebArena, demonstrating superior efficiency and effectiveness in web automation.


<details>
  <summary>Details</summary>
Motivation: Existing large language models struggle with fine-grained, low-level web component manipulations despite strong high-level semantic planning abilities. Current solutions focus on improving model grounding via reinforcement learning, but these approaches require agents to adapt to human-centric interfaces, which is suboptimal.

Method: The paper proposes CI4A (Component Interface for Agent), a semantic encapsulation mechanism that abstracts complex UI component interaction logic into unified tool primitives tailored for agents. It is implemented within Ant Design, covering 23 common UI component categories. A hybrid agent with a dynamically updated action space based on page state enables flexible use of CI4A tools.

Result: The CI4A-integrated system was used to refactor the WebArena benchmark. Experiments show the CI4A-based agent achieves a new state-of-the-art task success rate of 86.3% and significant improvements in execution efficiency compared to existing methods.

Conclusion: By designing agent-optimized interaction interfaces instead of forcing agents to adapt to human-centered designs, CI4A enables more efficient and effective web automation, setting a new benchmark in performance and practicality.

Abstract: While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.

</details>


### [115] [Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies](https://arxiv.org/abs/2601.14827)
*Ben Schaper,Maxime Di Folco,Bernhard Kainz,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.AI

TL;DR: 该研究探讨了视觉-语言模型（VLMs）在胸部X光分类中的抽象错误，并引入基于医学分类体系的层次化评估方法，提出'灾难性抽象错误'来捕捉跨分支误判。研究发现尽管模型在标准指标上表现良好，但与临床分类体系存在显著偏差。为此，提出了风险约束阈值和基于径向嵌入的分类体系感知微调方法，将严重抽象错误降低至2%以下，同时保持优异性能。结果强调了层次化评估和表示层面对齐的重要性，以实现更安全、更具临床意义的VLM部署。


<details>
  <summary>Details</summary>
Motivation: 标准的平坦指标无法区分临床中轻微与严重的错误，而视觉-语言模型在胸部X光分类中虽具强大零样本能力，但其预测与临床医学分类体系存在不一致，亟需更精细的评估与优化方法以提升临床实用性与安全性。

Method: 采用层次化评估指标，引入'灾难性抽象错误'概念量化跨分支误判；提出风险约束阈值策略与基于径向嵌入的分类体系感知微调方法，以增强模型与医学分类体系的一致性。

Result: 实验表明，尽管现有VLMs在平坦指标上表现优异，但在层次化评估中暴露出与临床分类体系的显著偏差；所提方法成功将严重抽象错误降至2%以下，同时维持高精度性能。

Conclusion: 层次化评估和表示层面与医学分类体系的对齐对于实现更安全、更具临床意义的视觉-语言模型部署至关重要。

Abstract: Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.

</details>


### [116] [Implementing Knowledge Representation and Reasoning with Object Oriented Design](https://arxiv.org/abs/2601.14840)
*Abdelrhman Bassiouny,Tom Schierenbeck,Sorin Arion,Benjamin Alt,Naren Vasantakumaar,Giang Nguyen,Michael Beetz*

Main category: cs.AI

TL;DR: KRROOD is a framework that integrates Knowledge Representation & Reasoning (KR&R) with Object-Oriented Programming (OOP) by treating knowledge as a first-class abstraction using native class structures, enabling seamless integration between logic programming and OOP. Evaluated on OWL2Bench and a human-robot task learning scenario, KRROOD demonstrates strong performance and supports complex reasoning needed for real-world autonomous systems.


<details>
  <summary>Details</summary>
Motivation: Existing KR&R frameworks rely on external ontologies and specialized languages that are hard to integrate with imperative code, creating a gap between modern software engineering (OOP) and KR&R systems.

Method: KRROOD treats knowledge as a first-class programming abstraction using native class structures, bridging the logic programming and OOP paradigms through direct integration within standard programming environments.

Result: KRROOD achieves strong performance on the OWL2Bench benchmark and in a human-robot task learning scenario, effectively supporting expressive reasoning required for real-world autonomous systems.

Conclusion: KRROOD successfully closes the integration gap between OOP and KR&R by enabling seamless, expressive, and efficient knowledge representation and reasoning within mainstream software development practices.

Abstract: This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.

</details>


### [117] [Just aware enough: Evaluating awareness across artificial systems](https://arxiv.org/abs/2601.14901)
*Nadine Meertens,Suet Lee,Ophelia Deroy*

Main category: cs.AI

TL;DR: 本文提出以'意识'作为评估人工智能系统的新范式，主张通过可操作的方法评估系统在目标导向行为中处理、存储和使用信息的能力，强调评估需具备领域敏感性、可扩展性、多维度及预测性能能力。


<details>
  <summary>Details</summary>
Motivation: 当前关于人工智能意识与道德地位的讨论缺乏共识，亟需一种更可行且方法上可操作的评估框架。

Method: 提出一种结构化方法，基于系统在目标导向行动中处理、存储和使用信息的能力来评估其意识水平，强调评估应满足领域敏感性、可扩展性、多维度和预测能力等四个标准。

Result: 该方法能够有效比较不同架构、规模和应用领域的系统间的意识表现，并支持设计、监督与科学讨论。

Conclusion: 将焦点从人工意识转向‘足够意识到’的状态，有助于实现更严谨的评估，促进技术发展与公共对话。

Abstract: Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.

</details>


### [118] [Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation](https://arxiv.org/abs/2601.14955)
*Hanqi Jin,Gaoming Yang,Zhangming Chan,Yapeng Yuan,Longbin Li,Fei Sun,Yeqiu Yang,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 提出TGA模型，通过构建结构化稀疏图并使用过渡感知图注意力机制，以线性复杂度建模多行为序列，显著降低计算成本且提升推荐效果，已在工业场景成功部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的多行为序列建模方法虽有效但计算复杂度高，难以在大规模工业系统中应用，尤其面对长用户序列时效率低下。

Method: 设计TGA模型，通过三个层面（物品级、类别级、邻近级）识别重要行为转移，构建结构化稀疏图，并引入过渡感知图注意力机制，联合建模用户-物品交互与行为类型转移。

Result: TGA在多个数据集上优于现有最先进模型，同时大幅降低计算开销；已在真实工业系统中部署，显著提升关键业务指标。

Conclusion: TGA通过高效建模多行为转移，实现了高精度与低计算成本的平衡，是适用于大规模工业推荐系统的有效解决方案。

Abstract: User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for un- derstanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi- behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional trans- formers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behav- ior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while sig- nificantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics.

</details>


### [119] [The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution](https://arxiv.org/abs/2601.15075)
*Chen Qian,Peng Wang,Dongrui Liu,Junyao Yang,Dadi Guo,Ling Tang,Jilin Mei,Qihan Ren,Shuai Shao,Yong Liu,Jie Fu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 本文提出了一种新型的通用智能体归因框架，旨在揭示大语言模型驱动智能体行为背后的内在因素，无论任务结果如何。该框架采用分层方法：在组件层面利用时间似然动态识别关键交互步骤，在句子层面通过扰动分析精确定位具体文本证据。实验验证了该框架在多种智能体场景中的有效性，包括标准工具使用和记忆偏差等隐蔽可靠性风险，能够可靠地定位影响行为的关键历史事件和句子，推动更安全、可问责的智能体系统发展。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注失败归因以定位失败轨迹中的显式错误，但无法解释智能体行为背后的推理过程。随着智能体在现实应用中日益自主和规模化部署，理解其行为原因对问责制和治理至关重要，因此需要一种能够解释任何任务结果下智能体行为的通用归因方法。

Method: 提出分层归因框架：首先在组件层面使用时间似然动态识别关键交互步骤；其次在句子层面采用扰动分析，以隔离导致特定行为的具体文本证据。

Result: 在多种智能体场景（如标准工具使用、记忆诱导偏差）中，框架能准确识别影响行为的关键历史事件与句子，表现出良好的可靠性与泛化能力。

Conclusion: 该框架为理解智能体行为提供了有效手段，是实现更安全、可解释、可问责的智能体系统的重要一步。

Abstract: Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.

</details>


### [120] [The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks](https://arxiv.org/abs/2601.15130)
*Ivan Carrera,Daniel Maldonado-Ruiz*

Main category: cs.AI

TL;DR: 本文揭示了大型语言模型（LLM）普及带来的'合理性陷阱'现象，即用户在简单确定性任务中滥用昂贵的生成式AI模型，导致显著的资源浪费和延迟。通过微基准测试与案例研究，量化了约6.5倍的延迟惩罚，并指出算法奉承的风险。为此，提出工具选择工程与确定性-概率决策矩阵框架，帮助开发者判断何时使用或避免使用生成式AI。文章主张应推动教育改革，真正数字素养不仅包括会用生成式AI，更在于懂得何时不用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，用户倾向于使用高成本的生成式AI处理本可由简单确定性方法解决的任务，造成计算资源浪费和效率下降，亟需识别并规避此类不合理使用模式。

Method: 通过微基准测试与实际案例研究（如OCR和事实核查），量化生成式AI在简单任务中的性能损耗；提出‘工具选择工程’与‘确定性-概率决策矩阵’框架，辅助开发人员进行合理的技术选型。

Result: 发现使用生成式AI处理简单任务带来约6.5倍的延迟惩罚，且存在算法过度迎合用户意图的风险；所提框架可有效指导开发者避免不必要的资源消耗。

Conclusion: 真正的数字素养不仅在于掌握生成式AI的使用方法，更在于具备判断何时不使用它的能力。应推动教育体系变革，强化对技术适用性的认知训练。

Abstract: The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the "Plausibility Trap": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the "efficiency tax"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it.

</details>


### [121] [Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning](https://arxiv.org/abs/2601.15160)
*Yuval Kansal,Niraj K. Jha*

Main category: cs.AI

TL;DR: 本文提出一种自下而上的学习范式，通过将大语言模型基于领域公理事实并组合这些事实来解决复杂、未见过的任务。研究设计了一种后训练流程，结合监督微调与强化学习（RL），利用知识图谱作为隐式奖励模型，从知识图谱路径中生成新颖的奖励信号，以促进模型在推理过程中组合中间公理，而非仅优化最终答案。实验在医学领域验证该方法，训练一个140亿参数模型处理短路径推理（1-3跳），并在零样本条件下评估其对复杂多跳查询（4-5跳）的泛化能力。结果表明，路径衍生的奖励起到了‘组合桥梁’作用，使模型显著优于更大规模模型及GPT-5.2、Gemini 3 Pro等前沿系统。此外，模型在对抗性扰动和选项打乱压力测试中表现出强鲁棒性。研究证明，将推理过程建立在结构化知识基础上，是实现智能推理的一种可扩展且高效路径。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽在数学和编程等结构化推理任务中表现接近专家水平，但在特定科学领域进行组合式多跳推理的能力仍受限。如何有效引导模型不仅关注最终答案，而是正确组合中间推理步骤，是当前关键挑战。

Method: 提出一种后训练管道，结合监督微调与强化学习；使用知识图谱作为隐式奖励模型，从图谱路径中提取奖励信号，以激励模型进行中间公理的合理组合，从而实现可验证、可扩展且具根基性的监督。

Result: 在医学领域的多跳推理任务中，14B模型在零样本条件下显著超越更大规模模型及主流系统（如GPT-5.2、Gemini 3 Pro），尤其在最困难的任务上表现突出；同时对选项打乱等对抗性测试具有高度鲁棒性。

Conclusion: 将推理过程锚定于结构化知识，是一种实现高效、可扩展智能推理的有效途径，为提升模型在复杂科学领域的推理能力提供了新范式。

Abstract: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a "compositional bridge", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.

</details>


### [122] [BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries](https://arxiv.org/abs/2601.15197)
*Shijie Lian,Bin Yu,Xiaopeng Lin,Laurence T. Yang,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Cong Huang,Kai Chen*

Main category: cs.AI

TL;DR: Vision-Language-Action (VLA) models often fail to generalize due to dataset bias causing 'Information Collapse,' where language instructions become predictable from vision alone, leading models to ignore language. BayesianVLA addresses this by using a dual-branch architecture with learnable Latent Action Queries to separate vision-only and language-conditioned policies, optimizing for conditional Pointwise Mutual Information (PMI) between actions and instructions. This encourages explicit language grounding without new data, improving generalization. Experiments show 11.3% gain on OOD SimplerEnv and strong performance on RoboCasa.


<details>
  <summary>Details</summary>
Motivation: Current VLA training paradigms suffer from dataset bias where language instructions are highly predictable from visual observations, leading to 'Information Collapse'—a vanishing conditional mutual information between instructions and actions. This causes models to degenerate into vision-only policies that ignore language, failing in out-of-distribution settings.

Method: BayesianVLA introduces a dual-branch architecture using learnable Latent Action Queries to estimate a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $\pi(a \mid v, \ell)$. It optimizes the policy by maximizing the conditional Pointwise Mutual Information (PMI) between actions and instructions, effectively penalizing reliance on visual shortcuts and encouraging actions that explicitly explain language commands.

Result: BayesianVLA achieves an 11.3% improvement on the challenging OOD SimplerEnv benchmark and shows strong performance on RoboCasa, demonstrating significant gains in generalization without requiring additional data collection. The method successfully mitigates Information Collapse and enables robust grounding of language in action.

Conclusion: By addressing the root cause of Information Collapse through Bayesian decomposition and PMI maximization, BayesianVLA enables VLA models to better follow language instructions in complex, out-of-distribution scenarios, significantly enhancing generalization and robustness in robot manipulation tasks.

Abstract: Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $π(a \mid v, \ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [123] [GCG Attack On A Diffusion LLM](https://arxiv.org/abs/2601.14266)
*Ruben Neyroud,Sam Corley*

Main category: cs.LG

TL;DR: 本文探索了针对扩散语言模型LLaDA的GCG风格对抗提示攻击，评估了前缀扰动和基于后缀的对抗生成等多种攻击变体在有害提示上的效果，初步揭示了扩散语言模型的鲁棒性与攻击面，推动了该领域对抗分析优化与评估策略的发展。


<details>
  <summary>Details</summary>
Motivation: 探究贪心坐标梯度（GCG）攻击在扩散语言模型中的适用性，因为尽管GCG在自回归模型中有效，但其在扩散模型中的表现尚不明确。

Method: 对LLaDA模型实施多种攻击变体，包括前缀扰动和基于后缀的对抗生成，并在AdvBench数据集的有害提示上进行测试。

Result: 实验提供了扩散语言模型在对抗攻击下的初步鲁棒性分析，揭示了其攻击表面，表明需要新的优化和评估方法以应对此类威胁。

Conclusion: 扩散语言模型存在可被利用的攻击面，当前的对抗分析方法需改进，未来应发展专门针对扩散模型的攻击与防御策略。

Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.

</details>


### [124] [Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation](https://arxiv.org/abs/2601.14274)
*Anh-Tuan Mai,Cam-Van Thi Nguyen,Duc-Trong Le*

Main category: cs.LG

TL;DR: 本文提出了一种名为DnR（Divide and Refine）的两阶段框架，用于解决多模态对话情绪识别中模态间独特性、冗余性和协同性信息难以平衡的问题。通过显式分解各模态的三种信息成分，并在后续阶段分别优化其可区分性与信息量，实现更有效的多模态融合。该方法在IEMOCAP和MELD数据集上表现出色，适用于多种主流模型架构。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态情绪识别中未能充分保留模态特有、共享及协同信息，尤其在数据增强过程中容易混淆不同信息类型，导致性能受限。因此需要一种能明确分离并优化这三类信息的新机制。

Method: 提出两阶段框架DnR：第一阶段（Divide）将每个模态分解为唯一性、成对冗余性和协同性成分；第二阶段（Refine）设计针对性目标函数，提升各成分的信息丰富度并保持其独立性。最终生成的表示可直接嵌入多种多模态模型中使用。

Result: 在IEMOCAP和MELD两个基准数据集上，DnR显著提升了多个主流多模态情绪识别模型的性能，验证了其有效性与通用性。

Conclusion: 显式地分解、精炼和重组多模态表示是一种系统且有效的方法，有助于实现模态间信息的最优利用，推动多模态情绪识别的发展。

Abstract: Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that emerge only when modalities are combined. In information-theoretic terms, these correspond to \emph{unique}, \emph{redundant}, and \emph{synergistic} contributions. An ideal representation should leverage all three, yet achieving such balance remains challenging. Recent advances in contrastive learning and augmentation-based methods have made progress, but they often overlook the role of data preparation in preserving these components. In particular, applying augmentations directly to raw inputs or fused embeddings can blur the boundaries between modality-unique and cross-modal signals. To address this challenge, we propose a two-phase framework \emph{\textbf{D}ivide and \textbf{R}efine} (\textbf{DnR}). In the \textbf{Divide} phase, each modality is explicitly decomposed into uniqueness, pairwise redundancy, and synergy. In the \textbf{Refine} phase, tailored objectives enhance the informativeness of these components while maintaining their distinct roles. The refined representations are plug-and-play compatible with diverse multimodal pipelines. Extensive experiments on IEMOCAP and MELD demonstrate consistent improvements across multiple MERC backbones. These results highlight the effectiveness of explicitly dividing, refining, and recombining multimodal representations as a principled strategy for advancing emotion recognition. Our implementation is available at https://github.com/mattam301/DnR-WACV2026

</details>


### [125] [Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version](https://arxiv.org/abs/2601.14275)
*Zewen Yang,Xiaobing Dai,Jiajun Cheng,Yulong Huang,Peng Shi*

Main category: cs.LG

TL;DR: 本文提出了一种用于分布式高斯过程回归的可选在线学习框架EIGP，通过误差感知的选择函数筛选高质量模型，提升协作学习中的预测精度。引入贪婪算法（gEIGP）加速预测，自适应算法（aEIGP）提高准确性，并结合快速预测、模型更新及数据删除策略实现实时学习。仿真结果表明该方法优于现有先进分布式GP方法。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，分布式学习的有效协作依赖于模型的数量与质量之间的平衡。然而，盲目纳入所有模型进行联合预测存在不合理性，亟需优先考虑模型质量而非数量，以提升整体预测性能。

Method: 提出分布式误差感知高斯过程（EIGP）框架，采用误差感知选择函数评估邻近智能体的模型质量，仅保留预测误差较小的高质量模型；进一步设计贪婪算法（gEIGP）和自适应算法（aEIGP），并结合误差量化迭代与数据删除策略，实现高效实时学习。

Result: 数值仿真验证了所提方法的有效性，在多个基准测试中均表现出优于现有先进分布式高斯过程方法的性能，尤其在预测精度与实时性方面具有显著优势。

Conclusion: 本研究揭示了在分布式学习中盲目增加模型数量的局限性，强调质量优先的重要性。所提出的EIGP框架及其衍生算法有效提升了多智能体系统的协作预测能力，为实时、高效、精准的分布式学习提供了新范式。

Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.

</details>


### [126] [Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct](https://arxiv.org/abs/2601.14277)
*Uygar Kurt*

Main category: cs.LG

TL;DR: 本研究对 llama.cpp 中的量化技术进行了统一的实证分析，针对 Llama-3.1-8B-Instruct 模型评估了 3-8 位 K-量化及传统格式在推理、知识、指令遵循和真实性等任务上的表现，并测量了困惑度、CPU 吞吐量、模型大小、压缩率和量化时间，旨在为用户在不同资源预算和应用场景下选择合适的量化方案提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 现有 llama.cpp 量化格式评估不一致，难以选择合适方案，尤其在本地部署大语言模型时面临实际挑战。

Method: 对 Llama-3.1-8B-Instruct（FP16, GGUF）模型采用多种 3-8 位 K-量化和传统格式进行系统性测试，涵盖多个下游任务基准与性能指标如困惑度、吞吐量、压缩率等。

Result: 不同量化方案在精度与效率之间呈现显著权衡；部分低比特量化在保持较高性能的同时实现大幅压缩和加速，适合资源受限场景。

Conclusion: 该研究为用户在实际应用中根据自身需求与资源限制选择最优量化方案提供了可操作的决策依据。

Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.

</details>


### [127] [On the Limits of Learned Importance Scoring for KV Cache Compression](https://arxiv.org/abs/2601.14279)
*Brady Steele*

Main category: cs.LG

TL;DR: 本文研究通过推测重要性预测（SIP）实现的键值（KV）缓存压缩，SIP是一个170万参数的非查询感知评分器，仅从KV表示中预测令牌重要性。尽管架构复杂（多时域前瞻、交叉注意力），SIP在5个随机种子、4个保留级别和3个任务上均未超越简单基线（包括随机选择）。主要发现：(1) 基于位置的启发式方法（保留前4个+最后N个令牌）表现与或优于学习方法；(2) 预填充注意力提供的信号等同于复杂学习评分器；(3) 除位置和预填充注意力外，KV表示中的边际信息对重要性预测帮助有限。作者假设未来查询与生成轨迹之间的循环依赖是造成该难题的原因。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过学习方法有效预测KV缓存中令牌的重要性，以提升缓存压缩效率。

Method: 提出一种170万参数的非查询感知评分器SIP，基于KV表示预测令牌重要性，采用多时域前瞻和交叉注意力机制。

Result: SIP在多种设置下未能超越简单基线，包括随机选择；基于位置的启发式方法表现更优；预填充注意力提供足够信号；KV表示中额外信息对重要性预测作用有限。

Conclusion: 当前学习方法在KV缓存压缩中的重要性预测效果受限，可能源于未来查询与生成轨迹间的循环依赖，位置启发式和预填充注意力已具备足够判别能力。

Abstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.

</details>


### [128] [A Comparison of Polynomial-Based Tree Clustering Methods](https://arxiv.org/abs/2601.14285)
*Pengyu Liu,Mariel Vázquez,Nataša Jonoska*

Main category: cs.LG

TL;DR: 本文研究了基于树区分多项式的树结构聚类方法，比较了不同距离度量的性能，并实现了两种基础自编码器模型用于树聚类。结果表明，基于逐项归一化距离的方法在聚类准确率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 树结构在生命科学多个领域（如系统发育学、发育生物学和核酸结构）中广泛应用，尤其是用于表示非编码RNA的二级结构。随着测序技术和人工智能的发展，大量生物数据以树结构形式存在，亟需新的树结构数据分析方法。树多项式提供了一种计算高效、可解释且全面的树结构编码方式，使其能与大多数数据分析工具兼容。因此，探索更有效的树聚类方法具有重要意义。

Method: 本文比较了多种基于树区分多项式的距离度量在树聚类中的表现，并构建了两种基础自编码器模型，利用树多项式进行树结构的聚类分析。

Result: 实验结果显示，基于逐项归一化距离的聚类方法在所有对比方法中具有最高的聚类准确率。

Conclusion: 基于树区分多项式的聚类方法中，使用逐项归一化距离的策略表现最优，验证了该方法在树结构数据分析中的有效性与优势。

Abstract: Tree structures appear in many fields of the life sciences, including phylogenetics, developmental biology and nucleic acid structures. Trees can be used to represent RNA secondary structures, which directly relate to the function of non-coding RNAs. Recent developments in sequencing technology and artificial intelligence have yielded numerous biological data that can be represented with tree structures. This requires novel methods for tree structure data analytics. Tree polynomials provide a computationally efficient, interpretable and comprehensive way to encode tree structures as matrices, which are compatible with most data analytics tools. Machine learning methods based on the Canberra distance between tree polynomials have been introduced to analyze phylogenies and nucleic acid structures. In this paper, we compare the performance of different distances in tree clustering methods based on a tree distinguishing polynomial. We also implement two basic autoencoder models for clustering trees using the polynomial. We find that the distance based methods with entry-level normalized distances have the highest clustering accuracy among the compared methods.

</details>


### [129] [Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity](https://arxiv.org/abs/2601.14300)
*Jun Liu,Leo Yu Zhang,Fengpeng Li,Isao Echizen,Jiantao Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种新的硬标签黑盒攻击框架，通过频率域初始化与模式驱动优化（PDO）策略，在仅有最高置信度标签反馈的情况下，有效逼近真实损失梯度的符号。理论和实验证明该方法在查询效率和攻击成功率上均优于现有最先进方法，尤其在低查询场景下表现突出，并能成功绕过黑光（Blacklight）等先进防御机制。


<details>
  <summary>Details</summary>
Motivation: 在仅能获取硬标签反馈的黑盒设置下，如何从离散输出中恢复有意义的梯度信息是一个核心挑战。现有方法多为启发式搜索，缺乏理论基础。本文旨在从第一性原理出发，建立统一的理论视角，提升攻击的可解释性与效率。

Method: 提出结合零查询频率域初始化与模式驱动优化（PDO）的新攻击框架。频率域初始化提升初始方向与真实梯度符号的相似性；PDO策略通过结构化搜索降低查询复杂度，实现高效梯度符号逼近。

Result: 在CIFAR-10、ImageNet、ObjectNet等数据集上的实验表明，该方法在标准模型、对抗训练模型、商业API及CLIP模型上均显著优于现有SOTA硬标签攻击方法，尤其在低查询条件下优势明显。此外，该方法在噪声数据、生物医学数据及密集预测任务中也表现出良好泛化能力，并能完全规避黑光防御，实现0%检测率。

Conclusion: 本研究揭示了多种现有硬标签攻击本质上是梯度符号的隐式近似，提出了基于理论指导的新型攻击框架，实现了更高的攻击成功率与更低的查询开销，为黑盒攻击提供了更强的可解释性和实用性。

Abstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.

</details>


### [130] [Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2601.14327)
*YuanLab. ai,Shawn Wu,Jiangang Luo,Tong Yu,Darcy Chen,Sean Wang,Xudong Zhao,Louie Li,Claire Wang,Hunter He,Carol Wang,Allen Wang*

Main category: cs.LG

TL;DR: 本文提出了一种用于MoE大语言模型预训练阶段的层自适应专家剪枝（LAEP）算法，通过动态剪枝低利用率专家并根据令牌分布统计重新分配专家，显著提升训练效率。实验表明，在从零开始预训练1010B基础模型时，LAEP实现了48.3%的训练效率提升和33.3%的参数减少，同时保持了多领域的优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有MoE LLMs在预训练阶段存在专家利用率低、训练效率差的问题，亟需一种高效且可扩展的专家剪枝方法以优化资源利用。

Method: 提出层自适应专家剪枝（LAEP）算法，基于令牌分布统计动态识别并剪枝低利用率专家，并跨设备重新组织专家分布，以提升计算效率与负载均衡。

Result: 在1010B Base模型的预训练中，LAEP实现48.3%的训练效率提升和33.3%的参数减少，同时在多个领域任务上保持优秀性能。

Conclusion: LAEP是一种高效的预训练阶段专家剪枝方法，能有效缓解MoE LLMs的计算瓶颈，为大规模模型训练提供可行路径。

Abstract: Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.

</details>


### [131] [Hierarchical Contextual Uplift Bandits for Catalog Personalization](https://arxiv.org/abs/2601.14333)
*Anupam Agrawal,Rajesh Mohanty,Shamik Bhattacharjee,Abhimanyu Mittal*

Main category: cs.LG

TL;DR: 提出了一种分层上下文提升老虎机框架，通过动态调整上下文粒度并结合提升建模，有效应对幻想体育中用户行为快速变化和奖励分布剧烈波动的挑战。大规模A/B测试显示，该方法在Dream11平台上显著提升了推荐质量，带来0.4%的收入增长，并改善了用户满意度；2025年5月上线生产后，收入进一步提升0.5%。


<details>
  <summary>Details</summary>
Motivation: 传统上下文老虎机算法在幻想体育等动态环境中难以应对用户行为快速变化和外部因素导致的奖励分布突变，且存在冷启动问题，因此需要更灵活、自适应的推荐机制。

Method: 提出一种分层上下文提升老虎机框架，利用上下文相似性实现策略迁移，动态调节从系统级到用户级的上下文粒度，同时融合提升建模思想以优化个性化推荐效果。

Result: 在Dream11平台的大规模A/B测试中，推荐质量显著提升，实现0.4%的收入增长，并改善用户满意度；部署至生产环境后，收入再提升0.5%。

Conclusion: 所提出的分层上下文提升老虎机框架能有效应对动态环境中的推荐挑战，已在真实场景中成功应用并持续产生正向业务影响。

Abstract: Contextual Bandit (CB) algorithms are widely adopted for personalized recommendations but often struggle in dynamic environments typical of fantasy sports, where rapid changes in user behavior and dramatic shifts in reward distributions due to external influences necessitate frequent retraining. To address these challenges, we propose a Hierarchical Contextual Uplift Bandit framework. Our framework dynamically adjusts contextual granularity from broad, system-wide insights to detailed, user-specific contexts, using contextual similarity to facilitate effective policy transfer and mitigate cold-start issues. Additionally, we integrate uplift modeling principles into our approach. Results from large-scale A/B testing on the Dream11 fantasy sports platform show that our method significantly enhances recommendation quality, achieving a 0.4% revenue improvement while also improving user satisfaction metrics compared to the current production system. We subsequently deployed this system to production as the default catalog personalization system in May 2025 and observed a further 0.5% revenue improvement.

</details>


### [132] [DiSPA: Differential Substructure-Pathway Attention for Drug Response Prediction](https://arxiv.org/abs/2601.14346)
*Yewon Han,Sunghyun Kim,Eunyi Jeong,Sungkyung Lee,Seokwoo Yun,Sangsoo Lim*

Main category: cs.LG

TL;DR: DiSPA is a novel representation learning framework that disentangles structure-driven and context-driven mechanisms of drug response by using bidirectional conditioning between chemical substructures and pathway-level gene expression. It introduces a differential cross-attention module to suppress noise and spurious associations, improving both predictive performance and interpretability. DiSPA achieves state-of-the-art results on the GDSC benchmark, especially in disjoint-set settings, and enables zero-shot transfer to spatial transcriptomics, revealing region-specific drug sensitivity patterns.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning models for drug response prediction often treat chemical and transcriptomic data independently or combine them late, failing to capture fine-grained, context-dependent drug mechanisms. Standard attention mechanisms are also sensitive to noise and sparsity in biological networks, limiting generalization and interpretability.

Method: DiSPA employs a bidirectional conditioning framework between chemical substructures and pathway-level gene expression. It uses a differential cross-attention module that dynamically adjusts attention based on contextual relevance, filtering out spurious associations while amplifying biologically meaningful interactions.

Result: DiSPA achieves state-of-the-art performance on the GDSC benchmark, with notable gains in disjoint-set evaluation. It produces mechanistically interpretable representations that recover known pharmacophores, distinguish compound types, and organize coherently across pathways. Additionally, it enables zero-shot transfer to spatial transcriptomics, uncovering region-specific drug sensitivity without retraining.

Conclusion: DiSPA provides a robust, interpretable, and generalizable framework for integrative pharmacogenomic modeling, enabling principled analysis of drug response mechanisms beyond post hoc interpretation.

Abstract: Accurate prediction of drug response in precision medicine requires models that capture how specific chemical substructures interact with cellular pathway states. However, most existing deep learning approaches treat chemical and transcriptomic modalities independently or combine them only at late stages, limiting their ability to model fine-grained, context-dependent mechanisms of drug action. In addition, standard attention mechanisms are often sensitive to noise and sparsity in high-dimensional biological networks, hindering both generalization and interpretability. We present DiSPA, a representation learning framework that explicitly disentangles structure-driven and context-driven mechanisms of drug response through bidirectional conditioning between chemical substructures and pathway-level gene expression. DiSPA introduces a differential cross-attention module that suppresses spurious pathway-substructure associations while amplifying contextually relevant interactions. Across multiple evaluation settings on the GDSC benchmark, DiSPA achieves state-of-the-art performance, with particularly strong improvements in the disjoint-set setting, which assesses generalization to unseen drug-cell combinations. Beyond predictive accuracy, DiSPA yields mechanistically informative representations: learned attention patterns recover known pharmacophores, distinguish structure-driven from context-dependent compounds, and exhibit coherent organization across biological pathways. Furthermore, we demonstrate that DiSPA trained solely on bulk RNA-seq data enables zero-shot transfer to spatial transcriptomics, revealing region-specific drug sensitivity patterns without retraining. Together, these results establish DiSPA as a robust and interpretable framework for integrative pharmacogenomic modeling, enabling principled analysis of drug response mechanisms beyond post hoc interpretation.

</details>


### [133] [VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models](https://arxiv.org/abs/2601.14354)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 本文提出Variational JEPA (VJEPA)，一种基于变分目标的随机化泛化方法，用于学习未来潜在状态的预测分布。该方法将表示学习与预测状态表示（PSRs）和贝叶斯滤波统一起来，无需自回归观测似然即可进行序列建模。理论证明其表示可作为最优控制的充分信息状态，并提供避免坍缩的形式保证。进一步提出Bayesian JEPA (BJEPA)，通过分解预测信念为动态专家与模块化先验专家，实现零样本任务迁移及约束满足。实验表明，VJEPA和BJEPA能有效过滤高方差干扰项，防止表示坍缩，且在无观测似然的情况下实现稳健的不确定性估计，适用于高维、噪声环境中的规划任务。


<details>
  <summary>Details</summary>
Motivation: 现有联合嵌入预测架构（JEPA）依赖确定性回归目标，缺乏概率语义，限制了其在随机控制等场景的应用。需要一种能够建模不确定性的可扩展自监督学习框架。

Method: 引入变分目标，构建VJEPA以学习未来潜在状态的预测分布；提出BJEPA，通过产品专家机制分解预测信念，实现模块化先验与动态建模的分离。

Result: VJEPA和BJEPA在噪声环境中成功过滤高方差干扰，避免表示坍缩；支持零样本任务迁移与约束满足；具备不确定性估计能力，且无需观测似然。

Conclusion: VJEPA提供了一种无需重建像素即可实现最优控制的可扩展、鲁棒、不确定性感知的规划框架，为高维噪声环境中的自主系统提供了基础支持。

Abstract: Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \emph{Variational JEPA (VJEPA)}, a \textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.

</details>


### [134] [Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation](https://arxiv.org/abs/2601.14473)
*Danny Butvinik,Nana Boateng,Achi Hackmon*

Main category: cs.LG

TL;DR: 该研究提出一种基于在线自适应核密度估计的方法，将风险评分流转化为一个或多个审查队列，满足明确的入队约束。通过将密度转换为尾部质量曲线以匹配容量，并在不同带宽下检测到的持久密度谷值上“对齐”阈值，实现标签无关、支持多队列路由的实时处理，适用于滑动窗口或指数遗忘机制。在合成、漂移、多模态数据流上表现优异，具备良好的容量遵守性与更低的阈值抖动，每次更新成本为O(G)，每个活动仅需常数内存。


<details>
  <summary>Details</summary>
Motivation: 传统方法如top-K或手动调参的截断方式难以适应动态变化的风险评分流，且易产生阈值抖动。本文旨在设计一种无需标签、可实时调整、能有效应对复杂数据分布（如多模态、漂移）的自动化队列划分方法，以满足系统容量限制并提升稳定性。

Method: 采用在线自适应核密度估计跟踪风险评分流；将密度函数转换为尾部质量曲线以适配容量需求；通过跨带宽检测持久密度谷值，将截断点‘对齐’至该谷值，实现稳定阈值选择；支持多队列路由和滑动窗口/指数遗忘机制，保证实时性与低内存占用。

Result: 在合成及真实漂移、多模态数据流上，该方法实现了与现有方法相当甚至更优的容量遵守率，显著降低阈值抖动；单次事件更新时间复杂度为O(G)，每个活动仅需常数级内存，适合大规模实时应用。

Conclusion: 本文提出的自适应密度阈值方法能够在无标签、实时、多队列环境下高效满足容量约束，具有强鲁棒性和实用性，适用于动态风险评估场景中的自动队列管理。

Abstract: We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity

</details>


### [135] [GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling](https://arxiv.org/abs/2601.14476)
*Naoya Onizawa,Takahiro Hanyu*

Main category: cs.LG

TL;DR: 该研究提出了一种基于p-bit的GPU加速模拟退火框架，利用磁隧道结（MTJ）等新兴器件中的设备变异性（包括时序、强度和偏移）来建模真实设备行为。尽管设备变异性通常被认为会降低性能，但本研究发现其在某些情况下反而能提升算法表现，特别是在利用时序变异性方面。通过CUDA仿真，该框架在MAX-CUT基准测试中实现了比CPU实现快两个数量级的加速，适用于800至20,000个节点的大规模问题。该工具开源且可扩展，旨在推动概率计算领域的研究，支持广泛优化应用。


<details>
  <summary>Details</summary>
Motivation: 传统CMOS逻辑在解决复杂问题如模拟退火和机器学习时存在效率瓶颈。概率计算使用概率比特（p-bits）提供了一种更高效的替代方案，但实际应用中新兴器件（如磁隧道结）的设备变异性可能影响性能。然而，现有研究未充分探索变异性对算法性能的潜在积极影响，因此亟需一个能真实反映设备变异性并评估其影响的仿真框架，以指导未来硬件设计与算法优化。

Method: 构建了一个基于p-bits的GPU加速模拟退火框架，采用CUDA实现，能够模拟设备变异性中的时序、强度和偏移因素。通过在大规模图问题（如MAX-CUT）上进行仿真，对比CPU实现，验证了框架的性能优势，并分析变异性对算法表现的影响。

Result: 该框架在800至20,000节点的MAX-CUT问题上，相比传统CPU实现，实现了高达两个数量级的加速；同时发现设备变异性（尤其是时序变异性）在特定条件下可提升算法性能，而非仅造成负面影响。

Conclusion: 设备变异性并非单纯负面因素，其在时序等方面可能被有效利用以增强算法性能。所提出的开源、可扩展的GPU加速仿真框架为概率计算研究提供了强大工具，有助于推动该领域在优化与机器学习等方向的发展。

Abstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -timing, intensity, and offset- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.

</details>


### [136] [Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence](https://arxiv.org/abs/2601.14487)
*Mrigank Dhingra,Omer San*

Main category: cs.LG

TL;DR: MSR-HINE是一种分层隐式预测器，通过多尺度潜在先验和多速率循环模块在不同时间尺度上操作，有效缓解混沌系统长时程自回归预测中的误差放大和分布偏移问题。该方法在柯尔莫哥洛夫-希瓦什斯基（Kuramoto-Sivashinsky）和洛伦兹-96（Lorenz-96）两个基准测试中显著优于U-Net自回归基线，在长期预测精度和可预测性时长上均有大幅提升。


<details>
  <summary>Details</summary>
Motivation: 长时程自回归预测在混沌动力系统中面临误差快速放大和分布偏移的挑战，导致预测轨迹物理不一致且统计特性崩溃。现有方法难以同时保持慢变流形上的长期上下文与快变尺度的动态细节。

Method: 提出MSR-HINE，一种分层隐式预测架构：在每一步中，从粗到细的循环状态生成潜在先验；隐式一步预测器通过多尺度潜在注入精炼状态；门控融合机制结合后验潜在变量实现尺度一致更新；轻量级隐藏状态校正进一步对齐循环记忆与融合后的潜在表示。

Result: 在柯尔莫哥洛夫-希瓦什斯基系统中，H=400时端点RMSE降低62.8%，ACC提升0.983（从-0.155到0.828），可预测性阈值ACC≥0.5的时长从241步扩展至400步；在洛伦兹-96系统中，H=100时RMSE降低27.0%，ACC提升0.402（从0.144到0.545），可预测性时长从58步扩展至100步。

Conclusion: MSR-HINE通过多尺度协同建模与隐式状态校正，有效抑制了混沌系统中误差累积，显著提升了长时程预测的准确性与稳定性，为复杂动力系统的长期模拟提供了新范式。

Abstract: Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC >= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC >= 0.5 horizon from 58 to 100 steps.

</details>


### [137] [On the Runway Cascade of Transformers for Language Modeling](https://arxiv.org/abs/2601.14522)
*Hunjae Lee,Corey Clark*

Main category: cs.LG

TL;DR: 本文研究了因果掩码在解码器仅模型中的信息传播路径，提出‘跑道’（runway）概念描述间接路径，并指出直接路径与间接路径间的错位会引发冗余和无关信息传播问题。为此，作者提出一种无额外参数的跑道感知重连机制，通过整合跑道上下文来增强注意力机制，实现更均衡的信息传播。实验表明，该方法在语言建模、信息检索和外推能力上均优于标准Transformer。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，因果变压器存在某些失效模式，这些模式可能由直接路径注意力与间接路径信息传播之间的不匹配所加剧。

Method: 提出跑道感知重连（runway-aware rewiring），基于对每个令牌跑道景观的摘要，重新调整其直接路径注意力模式，以显式引入跑道上下文。

Result: 所提出的重连变压器在通用语言建模中表现稳定提升，在信息检索和外推能力方面有显著增强，且无需增加额外参数。

Conclusion: 跑道错位是导致因果变压器信息传播失衡的重要因素，跑道感知重连能有效缓解此问题，提升模型性能，且可无缝集成到现有注意力机制中。

Abstract: In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.

</details>


### [138] [Search over Self-Edit Strategies for LLM Adaptation](https://arxiv.org/abs/2601.14532)
*Alistair Cheong,Haolin Cong,Tyler Yang,Dustin Miao*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型（LLM）是否能利用任务反馈自主决定如何更新自身权重，以实现自我改进。在仅有一轮自适应的简化设定下，模型通过自生成的自编辑模板控制训练数据和超参数，采用自监督下一词预测（NTP）作为更新算子。实验基于SEAL框架，在SQuAD数据集上测试，无归档变体表现与较弱基线相当，而带归档变体优于基线并接近人类设计的最佳基线，但未超越。分析表明，简单归档虽短期提升鲁棒性，却可能加速模型同质化，提示需引入显式新颖性激励以持续超越人工优化策略。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的开放搜索系统通常冻结基础模型，限制长期进展；尽管已有工作尝试在推理时更新模型，但更新策略仍依赖人工设计。本文旨在探索模型能否根据任务反馈自主决策更新方式，从而突破人工设定的瓶颈。

Method: 在SEAL框架基础上，解除固定的人类模板约束，允许模型自动生成自编辑模板，从而自主选择训练数据和关键超参数；采用自监督下一词预测（NTP）作为更新算子，对比两种变体：一种不使用历史模板归档，另一种基于轻量级过去模板归档进行条件生成。

Result: 在SQuAD上的实验显示，无归档变体性能与较弱基线‘Implications’相当，而带归档变体优于‘Implications’并接近最强的人类设计基线‘Rewrite’，但未超越。进一步分析发现，简单归档虽短期内增强稳定性，但会加速模型探索的同质化，暗示需要引入显式新颖性压力才能持续超越人工优化方案。

Conclusion: LLM具备通过任务反馈自主调整更新策略的潜力，但单纯依赖历史模板归档不足以实现持续超越人工设计策略；未来需引入新颖性机制以避免模型陷入同质化，推动真正意义上的自我进化。

Abstract: Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker "Implications" baseline, while the archive variant outperformed "Implications" and approached the strongest human-designed "Rewrite" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .

</details>


### [139] [QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design](https://arxiv.org/abs/2601.14549)
*Nilesh Prasad Pandey,Jangseon Park,Onat Gungor,Flavio Ponzina,Tajana Rosing*

Main category: cs.LG

TL;DR: QMC提出了一种无需微调的量化方法与新型异构内存架构，通过区分小语言模型中的普通权重和关键异常权重，将普通权重存储于紧凑的多级阻变存储器（ReRAM），关键异常权重则保留在高精度片上磁阻存储器（MRAM）中，有效缓解非易失性存储器中的设备噪声问题。在语言建模和推理基准测试中，QMC在算法仅评估和真实部署环境下均优于现有先进量化方法，实现6.3x-7.3x的内存压缩、7.6x的数据传输减少、11.7x的能耗降低和12.5x的延迟下降，显著提升边缘设备上的高效推理能力。


<details>
  <summary>Details</summary>
Motivation: 边缘平台部署小型语言模型面临内存、延迟和能效的严格限制；传统量化受新兴非易失性存储器噪声影响，而常规内存层次结构导致带宽竞争，无法满足高效推理需求，亟需针对大模型推理设计专用的混合内存架构。

Method: 提出Outlier-aware Quantization with Memory Co-design（QMC），采用重训练免量化策略，识别并分离小语言模型中的普通权重与异常权重，将普通权重存入多级ReRAM，关键异常权重保留于高精度MRAM，实现硬件与算法协同优化。

Result: 在语言建模与推理任务中，QMC相比现有最先进量化方法，在不依赖复杂算法或混合数据格式的前提下，实现6.3x–7.3x内存压缩、7.6x外部数据传输减少、11.7x能耗降低和12.5x延迟下降，且在真实边缘平台部署中表现优异，具备可扩展性和实用性。

Conclusion: QMC是一种面向边缘设备高效推理的可部署协同设计，通过创新的量化机制与异构内存架构，突破了传统存储瓶颈，为小语言模型在资源受限场景下的实时、隐私保护推理提供了有效解决方案。

Abstract: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.

</details>


### [140] [Constructing Multi-label Hierarchical Classification Models for MITRE ATT&CK Text Tagging](https://arxiv.org/abs/2601.14556)
*Andrew Crossman,Jonah Dodd,Viralam Ramamurthy Chaithanya Kumar,Riyaz Mohammed,Andrew R. Plummer,Chandra Sekharudu,Deepak Warrier,Mohammad Yekrangian*

Main category: cs.LG

TL;DR: 本文提出一种分层的“任务空间”表征方法，用于系统化组织和推进MITRE ATT&CK文本标注任务的自动化研究。通过构建多标签层级分类模型，利用经典机器学习方法在公开威胁情报文本上实现了约94%的战术级准确率和82%的技术级准确率，性能优于GPT-4o（约60%准确率），且无需依赖大语言模型或复杂架构。模型与工具已开源，支持安全社区复用，并拓展至金融领域威胁场景。


<details>
  <summary>Details</summary>
Motivation: 当前MITRE ATT&CK的文本标注仍主要依赖人工，效率低且难以规模化。为推动自动化标注发展，亟需对任务进行系统性分析并构建高效、可复现的模型方法。

Method: 提出分层任务空间框架，基于通用威胁情报文本构建多标签层级分类模型，采用经典机器学习方法（如SVM、XGBoost等）进行训练与评估，结合分阶段建模策略优化性能；同时扩展至金融领域威胁场景数据集。

Result: 在通用威胁情报数据上，战术级准确率达94%，技术级达82%，显著优于GPT-4o（约60%）；在金融领域威胁场景中亦表现良好，验证了方法的泛化能力。

Conclusion: 本研究展示了基于经典机器学习的多标签层级分类方法在ATT&CK文本标注任务中的高效性与实用性，为安全领域自动化威胁分析提供了轻量、可复现且高性能的解决方案，具备广泛推广价值。

Abstract: MITRE ATT&CK is a cybersecurity knowledge base that organizes threat actor and cyber-attack information into a set of tactics describing the reasons and goals threat actors have for carrying out attacks, with each tactic having a set of techniques that describe the potential methods used in these attacks. One major application of ATT&CK is the use of its tactic and technique hierarchy by security specialists as a framework for annotating cyber-threat intelligence reports, vulnerability descriptions, threat scenarios, inter alia, to facilitate downstream analyses. To date, the tagging process is still largely done manually. In this technical note, we provide a stratified "task space" characterization of the MITRE ATT&CK text tagging task for organizing previous efforts toward automation using AIML methods, while also clarifying pathways for constructing new methods. To illustrate one of the pathways, we use the task space strata to stage-wise construct our own multi-label hierarchical classification models for the text tagging task via experimentation over general cyber-threat intelligence text -- using shareable computational tools and publicly releasing the models to the security community (via https://github.com/jpmorganchase/MITRE_models). Our multi-label hierarchical approach yields accuracy scores of roughly 94% at the tactic level, as well as accuracy scores of roughly 82% at the technique level. The models also meet or surpass state-of-the-art performance while relying only on classical machine learning methods -- removing any dependence on LLMs, RAG, agents, or more complex hierarchical approaches. Moreover, we show that GPT-4o model performance at the tactic level is significantly lower (roughly 60% accuracy) than our own approach. We also extend our baseline model to a corpus of threat scenarios for financial applications produced by subject matter experts.

</details>


### [141] [Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation](https://arxiv.org/abs/2601.14590)
*Shovito Barua Soumma,Asiful Arefeen,Stephanie M. Carpenter,Melanie Hingle,Hassan Ghasemzadeh*

Main category: cs.LG

TL;DR: 本文评估了大语言模型（LLMs）在生成反事实解释（CFEs）方面的性能，涵盖GPT-4、BioMistral-7B和LLaMA-3.1-8B等模型，使用AI-READI临床数据集从干预质量、特征多样性和增强效果三个维度进行分析。结果表明，微调后的LLaMA-3.1-8B生成的反事实具有高可信度（高达99%）、强有效性（高达0.99）和现实可行的特征调整；在标签稀缺条件下用于数据增强时，可平均提升20%的F1分数。相比优化基线方法（如DiCE、CFNOW、NICE），LLMs提供更灵活、模型无关且更具临床可操作性的反事实生成方式。研究证明了基于LLM的反事实在可解释干预设计与数据高效模型训练中的潜力。


<details>
  <summary>Details</summary>
Motivation: 开发可解释且可行动的反事实解释，以支持异常预防和提升模型鲁棒性，尤其在医疗传感器数据中存在标签稀缺与类别不平衡问题时，传统方法难以有效生成高质量反事实。

Method: 采用多种预训练与微调的LLMs（包括GPT-4、BioMistral-7B、LLaMA-3.1-8B）生成反事实解释，基于多模态临床数据集AI-READI，从干预质量、特征多样性与数据增强效果三方面评估性能，并与优化基线方法对比。

Result: 微调后的LLaMA-3.1-8B生成的反事实具有高达99%的可信度和0.99的有效性，特征调整真实且行为可修改；在标签稀缺场景下，用其生成的反事实进行数据增强，平均使分类器F1分数恢复20%；整体表现优于优化基线方法，具备更强的语义一致性和临床可操作性。

Conclusion: LLM驱动的反事实解释在数字健康领域展现出巨大潜力，不仅可用于设计可解释的干预策略，还能通过数据增强有效缓解标签稀缺与类别不平衡问题，提升模型鲁棒性与预测性能。

Abstract: Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.
  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance

</details>


### [142] [Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective](https://arxiv.org/abs/2601.14599)
*Xiao Hu,Hong Xie,Tao Tan,Defu Lian,Jianyu Han*

Main category: cs.LG

TL;DR: 本文提出一种自下而上的实验流程，通过极简配置（单训练数据、每轮一次采样、奖励直接作为学习信号）来研究大语言模型强化微调中的优化选择，结合多臂赌博机理论分析，逐步扩展配置以揭示各设计因素的作用与瓶颈，实验在三个LLM和两个推理数据集上验证了结果，为该领域提供了新的理解与关键洞见。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型强化微调中存在大量启发式方法，但其效果不一致，缺乏对各优化选择作用及瓶颈的清晰理解，亟需系统性研究以厘清关键因素。

Method: 提出自下而上的实验管道：从极简配置（单一数据、每轮一次采样、奖励直接作为学习信号）出发，结合多臂赌博机理论进行分析，并逐层扩展配置，考察每个设计选择的影响。

Result: 实验在三个LLM和两个推理数据集上表明，该方法能够揭示不同设计选择的实际作用，识别出关键瓶颈，提供对强化微调机制的新理解。

Conclusion: 通过系统化实验与理论支持，本研究为大语言模型强化微调提供了可解释的优化框架，有助于未来方法的设计与评估。

Abstract: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.

</details>


### [143] [Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum](https://arxiv.org/abs/2601.14603)
*Jingru Li,Yibo Fan,Huan Li*

Main category: cs.LG

TL;DR: Muon 提出两种新的优化器变体 Muon-NSR 和 Muon-VS，通过正交动量更新结合方差自适应归一化，显著加速大语言模型预训练过程。实验表明，其在 GPT-2 和 LLaMA 上均优于 AdamW 和基线 Muon，收敛更快且验证损失更低。


<details>
  <summary>Details</summary>
Motivation: 现有优化器如 Adam 虽性能良好，但预训练计算成本高；受 Adam 可视为方差自适应符号更新的启发，提出更高效的正交动量方法以提升优化效率。

Method: 提出 Muon-NSR 与 Muon-VS 两种变体：前者基于噪声-信号比（NSR）调制进行归一化，后者采用无额外超参数的方差缩放实现正交化，均在动量前引入方差自适应归一化。

Result: 在 GPT-2 与 LLaMA 预训练任务中，所提方法显著加快收敛速度，相比经过良好调优的 AdamW 和基线 Muon，达到目标验证损失所需迭代次数减少达 1.36 倍。

Conclusion: Muon-NSR 和 Muon-VS 通过方差自适应的正交动量更新机制，在保持高性能的同时有效降低了大语言模型预训练的计算开销，为高效训练提供了新路径。

Abstract: Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.

</details>


### [144] [Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport](https://arxiv.org/abs/2601.14653)
*Yuyu Liu,Jiannan Yang,Ziyang Yu,Weishen Pan,Fei Wang,Tengfei Ma*

Main category: cs.LG

TL;DR: CROT is an optimal transport-based imputation method designed to handle patch-based missing data in single-cell sequencing datasets. It improves accuracy and reduces runtime, making it scalable for large, high-dimensional biological and clinical data.


<details>
  <summary>Details</summary>
Motivation: Existing imputation methods struggle with large patches of missing data due to assumptions of uniformity and completeness, limiting their effectiveness in real-world biological datasets with structured missingness.

Method: CROT leverages optimal transport theory to model the underlying data structure, enabling accurate imputation even when significant portions of data are missing in a patchy pattern.

Result: CROT achieves higher imputation accuracy and faster runtime compared to existing methods, demonstrating strong scalability and efficiency on large-scale datasets.

Conclusion: CROT provides a robust, efficient solution for imputing structured missing data in high-dimensional, heterogeneous datasets, advancing the analysis of single-cell sequencing and clinical data.

Abstract: Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github.

</details>


### [145] [Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning](https://arxiv.org/abs/2601.14687)
*Zhihao Chen,Zirui Gong,Jianting Ning,Yanjun Zhang,Leo Yu Zhang*

Main category: cs.LG

TL;DR: Federated Rank Learning (FRL) is a robust FL paradigm using ranking-based updates to resist model poisoning, but this study reveals its vulnerability to fine-grained control attacks. The proposed Edge Control Attack (ECA) enables adversaries to precisely degrade a competitor's accuracy to any target level while maintaining undetectable convergence, achieving 0.224% average error across multiple datasets and aggregation rules.


<details>
  <summary>Details</summary>
Motivation: Despite FRL's resilience against traditional model poisoning due to its discrete ranking mechanism, existing defenses are insufficient against sophisticated, stealthy attacks that can finely control model performance without triggering detection.

Method: The Edge Control Attack (ECA) operates in two stages: (i) manipulating Ascending and Descending Edges to align the global model with a target model, and (ii) widening the selection boundary gap to stabilize the global model at the desired accuracy level.

Result: ECA successfully achieves fine-grained accuracy control with an average error of only 0.224%, outperforming baseline attacks by up to 17x across seven benchmark datasets and nine Byzantine-robust aggregation rules.

Conclusion: FRL, though more resilient than traditional FL, remains vulnerable to advanced fine-grained control attacks like ECA. This calls for stronger defense mechanisms in ranking-based federated learning systems.

Abstract: Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA

</details>


### [146] [CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation](https://arxiv.org/abs/2601.14695)
*Yutong Chen,Jiandong Gao,Ji Wu*

Main category: cs.LG

TL;DR: CoScale-RL提出一种新的缩放策略，通过多解决方案收集和滚动计算缩放来提升大型推理模型（LRM）的稳定性和效率，在四个基准测试上平均实现3.76倍的准确率提升，且无需大量SFT数据即可突破模型能力边界。


<details>
  <summary>Details</summary>
Motivation: 当前后训练缩放策略在处理难题或基础模型较弱时仍存在不稳定性与不可预测性，亟需更高效、更稳定的缩放方法以提升大型推理模型的推理能力。

Method: 提出CoScale-RL，通过收集每个问题的多个解决方案进行解空间扩展，并利用滚动计算缩放增强强化学习稳定性；结合再蒸馏技术实现模型合并，保持甚至提升计算效率。

Result: 在四个基准测试上实现平均3.76倍的准确率提升，显著提高数据与计算效率，可在无大规模SFT数据情况下提升LRM的能力边界。

Conclusion: CoScale-RL为提升大型推理模型的推理能力提供了新的缩放方向，具备更高的数据与计算效率，适用于弱基础模型和复杂问题场景。

Abstract: Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.

</details>


### [147] [Case-Guided Sequential Assay Planning in Drug Discovery](https://arxiv.org/abs/2601.14710)
*Tianchi Chen,Jan Bima,Sean L. Wu,Otto Ritter,Bingjia Yang,Xiang Yu*

Main category: cs.LG

TL;DR: IBMDP 是一种适用于无模拟器环境的模型化强化学习框架，通过基于历史数据构建非参数信念分布来隐式建模状态转移，实现贝叶斯信念更新，并采用集成蒙特卡洛树搜索（MCTS）进行稳定规划。在真实中枢神经系统药物发现任务中，相比传统启发式方法，IBMDP将资源消耗降低高达92%，同时保持高决策置信度；在具有已知最优策略的合成环境中，其决策质量显著优于确定性值迭代方法，证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 在药物发现中，实验序列规划面临高度不确定性与资源限制，而标准强化学习因缺乏环境模拟器或转移数据（s, a, s'）难以应用。现有方法无法有效利用静态历史数据库进行高效决策，亟需一种无需显式环境模型的规划框架。

Method: 提出隐式贝叶斯马尔可夫决策过程（IBMDP），通过相似历史结果构建非参数信念分布以隐式表示状态转移动态；结合贝叶斯更新机制与集成蒙特卡洛树搜索（MCTS）进行规划，平衡信息获取与资源效率。

Result: 在真实CNS药物发现任务中，IBMDP将资源消耗减少最高达92%，且维持高决策信心；在合成环境中，其决策与最优策略的对齐度显著优于确定性值迭代方法，验证了框架的有效性与优越性。

Conclusion: IBMDP为数据丰富但缺乏模拟器的领域提供了一种实用的顺序实验设计解决方案，尤其适用于药物发现等高风险、资源受限场景，展现出强大的规划能力与实际应用价值。

Abstract: Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.

</details>


### [148] [PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning](https://arxiv.org/abs/2601.14716)
*Yao Lu,Dengdong Fan,Jianzheng Nie,Fan Xu,Jie Chen,Bin Zhou,Yonghong Tian*

Main category: cs.LG

TL;DR: PCL-Reasoner-V1.5 是一个320亿参数的大语言模型，基于 Qwen2.5-32B 构建，通过监督微调（SFT）和强化学习（RL）进行优化。其核心创新是提出一种离线强化学习方法，相比标准在线RL（如GRPO）具有更高的训练稳定性和效率。该模型在AIME 2024和AIME 2025测试集上分别达到90.9%和85.6%的平均准确率，性能优于其他基于Qwen2.5-32B后训练的模型。所有实验均在华为Ascend 910C NPU上完成。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在数学推理任务中的表现，探索更稳定高效的强化学习训练范式，以克服在线强化学习中存在的训练不稳定与资源消耗大的问题。

Method: 基于Qwen2.5-32B模型，采用监督微调（SFT）预训练，随后引入自主研发的离线强化学习（offline RL）方法进行优化，提升模型的推理能力。

Result: 在AIME 2024上达到90.9%的平均准确率，在AIME 2025上达到85.6%的平均准确率，显著优于同类后训练模型，验证了离线RL在数学推理任务中的有效性。

Conclusion: 离线强化学习是一种稳定且高效的训练范式，适用于大语言模型的数学推理能力提升，PCL-Reasoner-V1.5展示了其在高复杂度推理任务中的优越性能。

Abstract: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.

</details>


### [149] [FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks](https://arxiv.org/abs/2601.14730)
*Bizu Feng,Zhimu Yang,Shaode Yu,Zixin Hu*

Main category: cs.LG

TL;DR: FSX 是一种新型的混合解释框架，结合了模型内部的消息流与外部图数据的协作博弈方法，通过单次前向传播中的局部节点扰动分析关键消息流，并将其投影到输入图上生成紧凑且语义有意义的子图。在子图中，采用考虑节点特征重要性及其对关键消息流稳定性影响的类Shapley值评估节点贡献，从而实现高保真度解释与低计算开销的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有GNN可解释性方法存在权衡：基于梯度的方法计算高效但忽略结构交互；博弈论方法虽捕捉交互但计算成本高且可能偏离模型真实推理路径。因此需要一种能兼顾效率与准确性的新方法。

Method: 提出FSX框架，利用单次前向传播进行流敏感性分析，识别关键消息流；将敏感流投影至输入图构建子图；在子图中设计流感知的协作博弈，使用改进的Shapley值量化节点贡献。

Result: 在多个数据集和GNN架构上验证，FSX在保持高解释保真度的同时显著降低运行时间，揭示了重要子结构如何通过控制关键内部计算路径的稳定性来影响预测结果。

Conclusion: FSX成功实现了对GNN预测逻辑的高效、高保真解释，尤其在揭示结构化推理机制方面提供了前所未有的洞察力。

Abstract: Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.

</details>


### [150] [RefProtoFL: Communication-Efficient Federated Learning via External-Referenced Prototype Alignment](https://arxiv.org/abs/2601.14746)
*Hongyue Wu,Hangyu Li,Guodong Fan,Haoran Zhu,Shizhan Chen,Zhiyong Feng*

Main category: cs.LG

TL;DR: RefProtoFL提出了一种高效的联邦学习框架，通过外部参考原型对齐（ERPA）和自适应概率更新丢弃（APUD）来提升通信效率与模型泛化能力。该方法将模型分解为私有主干和轻量共享适配器，仅传输适配器参数，并利用Top-K稀疏化减少上行通信开销。对于表示不一致性问题，ERPA借助服务器持有的公共数据构建外部参考原型，实现跨异构客户端的语义对齐。实验表明，RefProtoFL在多个标准基准上优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有原型式联邦学习在严重通信约束下仍存在泛化性能不佳的问题，主要受限于通信带宽和客户端数据分布异构性。因此，亟需一种既能降低通信成本又能提升模型一致性和准确性的新方法。

Method: 将模型分为私有主干和轻量共享适配器，仅交换适配器参数；采用基于幅度感知的Top-K稀疏化（APUD）进行通信压缩；引入外部参考原型对齐（ERPA），利用公共数据构建参考原型，实现本地表示与全局语义的一致性对齐。

Result: 在多个标准数据集上的实验结果表明，RefProtoFL在分类准确率上显著优于当前主流的原型式联邦学习方法，在低通信条件下表现尤为突出。

Conclusion: RefProtoFL通过结合外部参考原型对齐与自适应更新丢弃机制，有效缓解了通信受限与数据异构带来的挑战，实现了更高的通信效率和更强的模型泛化能力，是原型式联邦学习中一项具有实际应用价值的改进方案。

Abstract: Federated learning (FL) enables collaborative model training without sharing raw data in edge environments, but is constrained by limited communication bandwidth and heterogeneous client data distributions. Prototype-based FL mitigates this issue by exchanging class-wise feature prototypes instead of full model parameters; however, existing methods still suffer from suboptimal generalization under severe communication constraints. In this paper, we propose RefProtoFL, a communication-efficient FL framework that integrates External-Referenced Prototype Alignment (ERPA) for representation consistency with Adaptive Probabilistic Update Dropping (APUD) for communication efficiency. Specifically, we decompose the model into a private backbone and a lightweight shared adapter, and restrict federated communication to the adapter parameters only. To further reduce uplink cost, APUD performs magnitude-aware Top-K sparsification, transmitting only the most significant adapter updates for server-side aggregation. To address representation inconsistency across heterogeneous clients, ERPA leverages a small server-held public dataset to construct external reference prototypes that serve as shared semantic anchors. For classes covered by public data, clients directly align local representations to public-induced prototypes, whereas for uncovered classes, alignment relies on server-aggregated global reference prototypes via weighted averaging. Extensive experiments on standard benchmarks demonstrate that RefProtoFL attains higher classification accuracy than state-of-the-art prototype-based FL baselines.

</details>


### [151] [Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models](https://arxiv.org/abs/2601.14758)
*Injin Kong,Hyoungjoon Lee,Yohan Jo*

Main category: cs.LG

TL;DR: 本文通过对比分析自回归模型（ARMs）与其掩码扩散模型（MDMs） counterparts的内部机制，揭示了在扩散模型后训练过程中发生的系统性“机制转变”。研究发现，对于具有局部因果依赖的任务，MDMs 保留了自回归的电路结构；而对于需要全局规划的任务，MDMs 则放弃了初始化路径，表现出早期层处理增强的显著重连特征。语义层面，模型从自回归模型中的尖锐、局部专业化转向扩散模型中的分布式整合。结论表明，扩散后训练不仅调整参数，更从根本上重构内部计算以支持非序列化的全局规划。


<details>
  <summary>Details</summary>
Motivation: 探索后训练的掩码扩散模型（MDMs）是否真正具备双向推理能力，还是仅复用自回归模型的启发式策略。

Method: 进行自回归模型（ARMs）与掩码扩散模型（MDMs）的对比电路分析，考察其在不同任务结构下的内部机制变化。

Result: 发现 MDMs 在局部任务中保留自回归电路，在全局规划任务中出现早期层处理增强的重连现象；语义上从局部专一转向分布式整合。

Conclusion: 扩散后训练不仅调整参数，还从根本上重构内部计算，以支持非序列化的全局规划。

Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.

</details>


### [152] [Anytime Optimal Decision Tree Learning with Continuous Features](https://arxiv.org/abs/2601.14765)
*Harold Kiossou,Pierre Schaus,Siegfried Nijssen*

Main category: cs.LG

TL;DR: 本文提出一种新的、具有随时性（anytime）且完备的决策树学习方法，用于处理连续特征。针对现有精确算法在早期中断时生成高度不平衡、次优树的问题，该方法采用有限差异搜索策略，更均匀地分配计算资源，确保在任意中断点都能提供高质量的决策树。实验表明，新方法在任意时间性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有精确算法在处理连续特征时，由于计算时间随深度急剧增加，难以应用于较深的决策树。其深度优先搜索策略导致早期中断时得到的树往往严重不平衡且次优，而贪婪方法如C4.5反而可能表现更好。因此需要一种既能保证最优性、又具备良好随时性能的方法。

Method: 提出基于有限差异搜索（Limited Discrepancy Search）的 anytime 算法，通过更均衡地分配计算资源到整个树结构，避免过度优化某一分支，从而在任何中断时刻都能返回高质量的决策树。

Result: 实验结果表明，所提方法在任意时间性能上显著优于现有的精确算法，在早期阶段即能获得比传统方法更优的解，同时保持全局最优性。

Conclusion: 本研究提出的方法有效解决了连续特征下最优决策树学习中的 anytime 性能瓶颈问题，实现了计算效率与解质量之间的良好平衡，为实际应用提供了可行的解决方案。

Abstract: In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.

</details>


### [153] [Statistical Learning Theory for Distributional Classification](https://arxiv.org/abs/2601.14818)
*Christian Fiedler*

Main category: cs.LG

TL;DR: This paper theoretically analyzes SVMs for classification with distributional inputs in a two-stage sampling setting, using kernel mean embeddings. It establishes new oracle inequalities, consistency, and learning rates, introduces a refined noise assumption for Gaussian kernels, and develops novel technical tools with independent value.


<details>
  <summary>Details</summary>
Motivation: The paper addresses supervised learning with distributional inputs in a two-stage sampling setup, common in applications like medical screening and causal learning, where the actual distributions are not directly accessible—only samples from them. This motivates the use of kernel-based methods that embed distributions into Hilbert spaces via kernel mean embeddings (KMEs), followed by standard kernel methods such as SVMs.

Method: The authors analyze SVM-based classification with distributional inputs using kernel mean embeddings. They establish an oracle inequality, derive consistency and learning rate results, and propose a novel variant of a noise assumption suitable for hinge loss and Gaussian kernels on Hilbert spaces.

Result: The study provides theoretical guarantees including consistency and learning rates under a new noise assumption. Technical contributions include a new feature space for Gaussian kernels on Hilbert spaces, which may have broader applicability beyond the current framework.

Conclusion: The work strengthens the theoretical foundation of kernel-based learning with distributional inputs, particularly for SVMs, and introduces tools and assumptions that enhance both practical applicability and theoretical understanding.

Abstract: In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.

</details>


### [154] [From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps](https://arxiv.org/abs/2601.14848)
*Mohamed Abouras,Catherine M. Elias*

Main category: cs.LG

TL;DR: 本文研究了高速公路出入口（AoI）与直线路段在车辆行为上的差异，采用多层LSTM模型基于ExiD无人机数据集进行训练，并测试了不同预测时长和模型流程。结果显示，在4秒以内的预测时长内，出入口区域的预测准确率可达约76%，而普通高速公路场景可达94%。


<details>
  <summary>Details</summary>
Motivation: 出入口区域因交通交互变化较大，但研究较少，其行为预测有助于减少不确定性并提升道路安全。

Method: 使用多层LSTM架构对出入口区域建模，基于ExiD无人机数据集，测试不同预测时长和模型流程。

Result: 在最大预测时长4秒内，出入口区域预测准确率约为76%，普通高速公路场景达94%。

Conclusion: 该方法在出入口区域车辆行为预测中展现出良好潜力，可有效提升交通安全与系统稳定性。

Abstract: On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.

</details>


### [155] [Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference](https://arxiv.org/abs/2601.14855)
*Baojun Che,Yifan Chen,Daniel Zhengyu Huang,Xinying Mao,Weijie Wang*

Main category: cs.LG

TL;DR: 提出了一种稳定高效的黑箱变分推断框架，结合自然梯度预处理、指数积分器和自适应时间步长，有效解决高斯混合族近似中的不稳定性与低效问题。该方法在无噪声情况下证明了指数收敛性，在蒙特卡洛估计下实现了几乎必然收敛，适用于多模态分布及偏微分方程贝叶斯反问题。


<details>
  <summary>Details</summary>
Motivation: 标准数值优化方法在黑箱变分推断中常因不稳定和低效而表现不佳，尤其在复杂后验分布逼近时。需要更稳健且高效的方法来提升性能。

Method: 采用自然梯度的仿射不变预处理、保证协方差矩阵正定性的指数积分器，以及自适应时间步长策略，结合流形优化与镜像下降的思想。

Result: 在多模态分布、Neal的多尺度漏斗模型及基于偏微分方程的达西流反问题上均表现出优异性能；理论证明了在理想条件下指数收敛和实际估计下的几乎必然收敛。

Conclusion: 所提出的框架显著提升了黑箱变分推断在复杂后验逼近中的稳定性与效率，具有坚实的理论基础和广泛的应用前景。

Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.

</details>


### [156] [Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting](https://arxiv.org/abs/2601.14862)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Derya Umut Kulali*

Main category: cs.LG

TL;DR: 提出sdLM框架，结合多文档注意力、时间编码和教义一致性层，提升长期战略预测与计划合理性，减少严重教义违背。在专家评分、教义一致性和地缘政治预测等多个基准上表现优于主流大模型，接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在长期战略推理中存在教义不一致和不确定性校准不足的问题，难以支持可靠的战略规划与预测。

Method: 采用多文档注意力机制捕捉跨文档信息，引入时间编码建模动态演变，设计教义一致性层约束推理过程，确保输出符合既定战略教义。

Result: sdLM在专家评分、教义一致性及历史反事实预测任务中均优于通用大模型，且在长周期判断上与人类专家表现相当；组件消融实验表明各模块均有贡献，系统具备部署实用性。

Conclusion: sdLM有效提升了多文档战略推理的准确性、一致性和可解释性，为高风险决策场景下的智能辅助提供了可行方案。

Abstract: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.

</details>


### [157] [What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study](https://arxiv.org/abs/2601.14888)
*Keyu Lv,Manyi Zhang,Xiaobo Xia,Jingchen Ni,Shannan Yan,Xianzhi Yu,Lu Hou,Chun Yuan,Haoli Bai*

Main category: cs.LG

TL;DR: 本文系统研究了推理模型的量化感知训练（QAT），提出了一种名为Reasoning-QAT的优化流程，显著提升了低比特量化下的推理性能。关键发现包括：知识蒸馏对监督微调和强化学习均有效；PTQ可作为QAT的良好初始化，提升精度并降低训练成本；强化学习在合理冷启动下仍可行并带来额外增益；校准域与训练域对齐能加速收敛并提高最终精度。该方法在多个大模型和推理数据集上优于现有PTQ方法，如在Qwen3-0.6B上，2比特设置下比GPTQ高出44.53%。


<details>
  <summary>Details</summary>
Motivation: 推理模型在复杂任务中表现优异，但推理速度慢且生成效率低。现有后训练量化（PTQ）方法在低比特设置下常导致显著性能下降，亟需更高效的量化策略以兼顾精度与效率。

Method: 通过系统性实证研究量化感知训练（QAT）在推理模型中的应用，结合知识蒸馏、PTQ初始化、强化学习优化及校准域对齐等技术，构建了优化的推理模型量化流程（Reasoning-QAT）。

Result: Reasoning-QAT在多个大模型和推理数据集上显著优于现有PTQ方法，尤其在2比特设置下表现出色，在Qwen3-0.6B上相较GPTQ提升44.53%的性能，且能有效恢复低比特下的模型表现。

Conclusion: 通过整合知识蒸馏、有效初始化、强化学习优化与域对齐策略，Reasoning-QAT为推理模型的高效低比特量化提供了可靠解决方案，显著提升了量化后的推理性能与实用性。

Abstract: Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.

</details>


### [158] [Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models](https://arxiv.org/abs/2601.14917)
*Giorgia Rigamonti,Mirko Paolo Barbato,Davide Marelli,Paolo Napoletano*

Main category: cs.LG

TL;DR: 本文提出一种基于深度学习的个性化血糖预测方法，利用患者特定数据提升预测精度与实时响应能力。通过对比留一被试交叉验证与微调策略，证明个性化模型在预测高/低血糖事件方面显著优于通用模型。实验还比较了多模态患者特异性方法与传统仅基于连续血糖监测（CGM）的方法，并通过消融研究确定了有效个性化所需的最小数据量，为实际应用中数据收集挑战提供参考。结果表明，自适应个性化模型可显著提升可穿戴与移动健康平台中的糖尿病管理效果。


<details>
  <summary>Details</summary>
Motivation: 现有糖尿病管理依赖于持续血糖监测和精准胰岛素调节，但传统模型多为通用化设计，难以捕捉个体差异。随着可穿戴设备和移动健康应用普及，亟需更准确、个性化的血糖预测技术以支持自动化胰岛素输送和决策支持系统。

Method: 采用深度学习框架构建个性化血糖预测模型，融合患者特定数据（如饮食、运动、胰岛素剂量等），通过留一被试交叉验证与微调策略评估模型性能；并进行多模态数据对比与消融实验，分析不同训练集规模下的表现。

Result: 个性化模型显著提升对高/低血糖事件的预测能力，尤其在真实世界场景中表现出更强的响应性与准确性；多模态输入优于仅使用CGM数据；即使在小样本条件下，模型仍能保持良好性能，揭示了实现有效个性化所需的最低数据阈值。

Conclusion: 自适应、个性化的血糖预测模型具有巨大潜力，可推动下一代糖尿病管理技术的发展，特别适用于可穿戴设备与移动健康平台，有助于实现更智能、用户导向的糖尿病护理解决方案。

Abstract: Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.

</details>


### [159] [Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning](https://arxiv.org/abs/2601.14942)
*Hang Zhao,Hongru Li,Dongfang Xu,Shenghui Song,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 本文提出了一种三阶段的通信感知分布式学习框架，用于提升多模态边缘推理（MMEI）在无线信道下的训练与推理效率和鲁棒性。通过本地自监督学习减少通信开销，在第二阶段进行集中式证据融合以校准模态不确定性，第三阶段则采用不确定性引导的反馈机制，选择性请求补充特征，优化通信与精度的权衡。实验表明，该方法在RGB-深度室内场景分类任务中显著降低通信轮次，同时保持对模态退化和信道变化的鲁棒性，优于现有自监督与全监督基线方法。


<details>
  <summary>Details</summary>
Motivation: 多模态边缘推理面临两大挑战：一是多模态特性导致在带宽受限的无线链路上分布式学习通信开销过大；二是信道变化和噪声输入下模型鲁棒性不足。因此需要一种高效且鲁棒的通信感知学习框架。

Method: 提出三阶段框架：(1) 阶段I：设备执行本地多模态自监督学习，获得共享和模态特定编码器，无需设备与服务器间交换数据，降低通信成本；(2) 阶段II：分布式微调结合集中式证据融合，校准各模态不确定性，可靠聚合受噪声或信道衰落影响的特征；(3) 阶段III：不确定性引导的反馈机制，仅对不确定样本请求额外特征，优化通信与精度之间的平衡。

Result: 在RGB-深度室内场景分类任务上，所提框架在显著减少训练通信轮次的同时，实现了更高的分类准确率，并对模态退化和信道变化表现出强鲁棒性，优于现有自监督和全监督基线方法。

Conclusion: 所提出的三阶段通信感知分布式学习框架有效提升了多模态边缘推理的通信效率与系统鲁棒性，为未来无线环境下的分布式智能应用提供了可行解决方案。

Abstract: Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.

</details>


### [160] [Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features](https://arxiv.org/abs/2601.14954)
*Han Li,Hua Sun*

Main category: cs.LG

TL;DR: 提出一种结合外部证据和伪造特征的多模态谣言检测模型，利用ResNet34和BERT分别提取图像与文本特征，通过傅里叶变换捕捉频率域痕迹和压缩伪影，并结合BLIP生成的图像描述增强语义对齐。采用双对比学习模块提升语义不一致检测能力，设计门控自适应特征缩放融合机制动态调节多模态融合，有效降低冗余。在微博和推特数据集上实验表明，该模型在宏准确率、召回率和F1分数上均优于主流基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态的谣言检测方法在特征提取、跨模态对齐和融合策略方面存在局限，且忽视验证复杂谣言所需的外部事实证据，难以应对表面一致但深层语义错配的深度语义不一致谣言。

Method: 采用ResNet34视觉编码器、BERT文本编码器和伪造特征模块（提取频率域痕迹与压缩伪影），利用BLIP生成图像描述实现图文语义空间对齐；引入双对比学习模块计算文本-图像与文本-描述间的对比损失，强化语义不一致识别；设计门控自适应特征缩放融合机制，动态调整多模态融合过程以减少冗余。

Result: 在Weibo和Twitter数据集上的实验结果表明，所提模型在宏观准确率、召回率和F1分数等指标上均显著优于现有主流基线方法，尤其在检测深度语义不一致谣言方面表现突出。

Conclusion: 本研究提出的多模态谣言检测模型通过融合外部事实证据与伪造特征，有效提升了对复杂、隐蔽谣言的识别能力，为应对社交媒体中日益复杂的虚假信息传播提供了有力技术支撑。

Abstract: Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score.

</details>


### [161] [Improving Regret Approximation for Unsupervised Dynamic Environment Generation](https://arxiv.org/abs/2601.14957)
*Harry Mead,Bruno Lacerda,Jakob Foerster,Nick Hawes*

Main category: cs.LG

TL;DR: 提出DEGen和MNA以解决无监督环境设计中的信用分配难题，提升大规模环境下的训练效率与性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂环境参数下难以有效生成训练课程，尤其面临信用分配困难和不准确的后悔值近似问题，限制了其在大规模环境中的应用。

Method: 引入动态环境生成（DEGen）以增强奖励信号密度，并提出最大化负优势（MNA）作为改进的后悔值近似指标。

Result: 实验表明MNA优于现有后悔值近似方法，结合DEGen后，在环境规模增大时显著超越现有方法。

Conclusion: DEGen与MNA的结合有效提升了无监督环境设计的可扩展性与性能，尤其适用于大规模环境设置。

Abstract: Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.

</details>


### [162] [InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement](https://arxiv.org/abs/2601.14968)
*Mingyue Cheng,Xiaoyu Tao,Huajian Zhang,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: InstructTime提出将时间序列分类重构为多模态生成任务，通过离散化时间序列、对齐投影层和自监督预训练增强跨模态表示。InstructTime++进一步引入隐式特征建模，利用统计特征提取和视觉-语言图像描述工具挖掘原始输入中的信息模式，并转化为文本描述以提升性能。在多个基准数据集上的实验表明InstructTime++表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列分类方法采用判别式范式，直接将输入序列映射到独热编码标签，难以融入上下文特征且无法捕捉类别间的语义关系。为此，需要一种能整合多源信息并建模语义关联的新框架。

Method: InstructTime将连续数值序列、上下文文本特征和任务指令作为多模态输入，使用语言模型生成类标签文本输出；引入时间序列离散化模块生成离散时间标记，结合对齐投影层与生成式自监督预训练策略，强化跨模态对齐。InstructTime++在此基础上增加隐式特征建模，通过统计特征提取和视觉-语言图像描述技术挖掘原始数据中的深层模式，并转化为文本描述进行融合。

Result: 在多个基准时间序列分类数据集上，InstructTime++显著优于现有方法，展现出更强的泛化能力和对复杂语义关系的建模能力。

Conclusion: InstructTime++通过多模态生成框架与隐式特征建模，有效提升了时间序列分类中对上下文和语义关系的捕捉能力，为未来研究提供了新的方向。

Abstract: Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.

</details>


### [163] [Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors](https://arxiv.org/abs/2601.15000)
*Christos Petridis,Konstantinos Pelechrinis*

Main category: cs.LG

TL;DR: 该研究提出一种基于回归的新型方法L-RAPM，用于在篮球比赛中识别表现优异的球员组合（即阵容），以应对因频繁换人导致的数据稀疏问题。该方法考虑了对手的影响，并利用阵容中球员的信息，实验表明其预测性能优于现有基线方法，尤其在阵容样本量较小时提升更为显著。


<details>
  <summary>Details</summary>
Motivation: 篮球比赛中频繁换人导致阵容数据高度稀疏，现有公开研究缺乏有效解决此问题的方法，因此需要一种能够提高小样本下预测准确性的新方法。

Method: 提出一种回归模型L-RAPM，通过控制对手因素并整合球员特征信息，优化阵容表现的评估与预测。

Result: 实验结果显示，L-RAPM在小样本情况下显著提升了预测能力，相较于现有基线方法具有更优的表现。

Conclusion: L-RAPM是一种有效的阵容表现分析方法，特别适用于数据稀疏场景，在实际应用中可为球队战术决策提供更可靠的依据。

Abstract: Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.

</details>


### [164] [RadixMLP - Intra-batch Deduplication for Causal Transformers](https://arxiv.org/abs/2601.15013)
*Michael Feil,Julius Lipp*

Main category: cs.LG

TL;DR: RadixMLP 是一种用于因果 Transformer 模型批量推理的新技术，通过利用 MLP、LayerNorm、线性投影和嵌入的位置无关特性，消除共享前缀带来的冗余计算。它动态地将批次映射到前缀树，将共享部分压缩为统一表示进行位置级计算，并在注意力边界处重新分发结果，实现单次前向传播的无状态加速。在真实重排序任务中（MS MARCO v1.1 + Qwen3 模型），相比传统方法提速 1.44–1.59 倍，合成基准测试中更达 5 倍加速。


<details>
  <summary>Details</summary>
Motivation: 在批量推理中，多个序列常具有相同的前缀（如系统提示、少样本示例等），标准推理引擎会重复计算这些共享前缀的 MLP 激活，造成显著计算浪费。因此需要一种机制来消除这种冗余，提升推理效率。

Method: RadixMLP 利用 MLP、LayerNorm、线性投影和嵌入的位置独立性，将输入批次动态组织为前缀树结构，对共享前缀段进行压缩计算，仅在注意力边界处展开结果，实现高效的位置级并行计算。整个过程无需状态维护，可在一次前向传播中完成。

Result: 在真实场景（MS MARCO v1.1 上使用 Qwen3 模型，0.6B 至 8B 参数）下，获得 1.44–1.59 倍的推理加速；在具有长共享前缀的合成基准上，最高可达 5 倍加速。代码已开源。

Conclusion: RadixMLP 有效解决了因果 Transformer 批量推理中的共享前缀冗余问题，通过前缀压缩与位置级计算实现了显著的性能提升，且具备良好的通用性和可部署性。

Abstract: Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\times$ speedups in realistic reranking workloads, with up to $5\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.

</details>


### [165] [Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control](https://arxiv.org/abs/2601.15015)
*Jannis Becktepe,Aleksandra Franz,Nils Thuerey,Sebastian Peitz*

Main category: cs.LG

TL;DR: 本文提出了FluidGym，首个独立、全可微分的强化学习在主动流控（AFC）中的基准套件。它基于PyTorch和GPU加速的PICT求解器构建，无需外部CFD软件，支持标准化评估，并提供多智能体与3D支持。作者展示了PPO和SAC的基线结果，并公开所有环境、数据集和训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有主动流控研究因观测、控制方案、数值设置和评估协议不一致，难以比较；当前基准依赖外部CFD求解器，不可微且缺乏3D和多智能体支持。

Method: 开发FluidGym，一个完全在PyTorch中实现、基于PICT求解器的全可微分、单Python栈的流控基准套件，支持3D和多智能体场景。

Result: 成功构建了可复现、可扩展的基准平台，实现了标准化评估，验证了PPO和SAC的有效性，并公开发布全部资源。

Conclusion: FluidGym为基于学习的流控研究提供了统一、可扩展的基准框架，推动了该领域的系统性发展。

Abstract: Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.

</details>


### [166] [Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization](https://arxiv.org/abs/2601.15021)
*Adam Rokah,Daniel Veress,Caleb Caulk,Sourav Sharan*

Main category: cs.LG

TL;DR: 本研究探讨了混合专家（MoE）架构在图像分类任务中的表现，对比了密集模型、SoftMoE和SparseMoE在CIFAR10上的预测性能、专家利用率和泛化能力。尽管两种MoE变体均略优于密集基线，但仅通过正则化实现平衡的专家利用，避免了专家坍缩。通过Hessian尖锐度指标分析发现，SoftMoE具有更高的曲率，而密集与SparseMoE处于相似的曲率区间，三者泛化性能相近。损失表面扰动分析揭示了密集与MoE模型在有限参数扰动下的非局部行为差异，有助于理解曲率测量但不直接解释准确率。此外，实证表明在当前规模下，朴素的条件路由并未带来推理速度提升，凸显了稀疏MoE理论效率与实际表现之间的差距。


<details>
  <summary>Details</summary>
Motivation: 探索MoE架构在图像分类任务中的有效性，超越其在大语言模型中的应用背景，关注其在预测性能、专家利用均衡性及泛化能力方面的表现，并揭示其在实际推理效率上的局限性。

Method: 在相同模型容量下，比较密集模型、SoftMoE和SparseMoE在CIFAR10上的表现；使用Hessian尖锐度指标（最大特征值与迹）评估训练与测试数据上的损失曲率；通过损失表面扰动分析考察非局部行为差异；实测不同模型的推理效率，评估条件路由的实际速度优势。

Result: 两种MoE变体均略优于密集基线，在验证集上取得更高准确率；通过正则化实现了专家利用的平衡，未出现专家坍缩；SoftMoE表现出更高的曲率，而密集与SparseMoE曲率相近，三者泛化性能相当；扰动分析显示密集与MoE模型在非局部行为上有显著差异；然而，朴素实现的条件路由未在现代硬件上带来推理加速，理论效率优势未被兑现。

Conclusion: MoE架构在图像分类中具备一定性能优势，但其泛化能力与密集模型接近，且专家利用需依赖正则化控制；尽管存在较高的曲率，但并不影响泛化性能；更重要的是，当前实现方式下，条件路由未能带来实际推理效率提升，表明稀疏MoE的理论优势在实践中仍面临挑战。

Abstract: Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.

</details>


### [167] [Field-Space Autoencoder for Scalable Climate Emulators](https://arxiv.org/abs/2601.15102)
*Johannes Meuer,Maximilian Witte,Étiénne Plésiat,Thomas Ludwig,Christopher Kadow*

Main category: cs.LG

TL;DR: 提出了一种基于球面压缩模型的可扩展气候模拟框架——场空间自编码器（Field-Space Autoencoder），通过场空间注意力机制高效处理原始气候模型输出，避免了传统方法在欧几里得网格上投影带来的几何失真。该方法能更好保留物理结构，并支持零样本超分辨率，将低分辨率集合与稀缺高分辨率数据映射到统一表示。在此基础上训练生成扩散模型，同时学习大量低分辨率数据中的内部变率和少量高分辨率数据中的精细物理过程，有效弥合了大规模低分辨率统计与稀缺高分辨率细节之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有千米级地球系统模型虽能捕捉局部气候变化，但计算成本高且输出量达拍字节级别，限制其在概率风险评估等应用中的使用。如何在保持物理准确性的前提下降低计算负担并整合多分辨率数据，成为关键挑战。

Method: 采用场空间自编码器框架，结合球面压缩模型与场空间注意力机制，直接处理原生气候数据，避免网格变形；利用压缩后的结构化场作为生成模型输入，构建基于扩散模型的生成式模拟器，实现从低分辨率集合中学习内部变率、从高分辨率数据中提取精细物理特征的联合建模。

Result: 所提方法显著优于卷积基线，在保持物理结构方面表现更优；支持零样本超分辨率重建；生成模型能够融合多源数据，在降低计算开销的同时提升模拟精度，为气候风险评估提供高效、高保真的替代方案。

Conclusion: 本研究提出的场空间自编码器及其生成式框架，成功解决了高分辨率气候模拟中数据量大、计算昂贵、多尺度信息融合难的问题，为未来气候建模与风险评估提供了新的技术路径。

Abstract: Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail.

</details>


### [168] [Auditing Language Model Unlearning via Information Decomposition](https://arxiv.org/abs/2601.15111)
*Anmol Goel,Alan Ritter,Iryna Gurevych*

Main category: cs.LG

TL;DR: 本文揭示现有语言模型遗忘算法中残留信息的可解码性问题，提出基于PID的可解释审计框架，识别并量化残留知识，进而设计风险评分以指导敏感输入的回避，提升模型隐私安全性。


<details>
  <summary>Details</summary>
Motivation: 当前机器遗忘算法在表面上看似成功，但其内部表示中仍存在关于被遗忘数据的可线性解码信息，这暴露了现有方法的关键局限性。

Method: 引入可解释的信息论框架，利用部分信息分解（PID）来审计遗忘效果；通过比较遗忘前后的模型表示，将与被遗忘数据的互信息分解为不同成分，形式化定义‘已遗忘’和‘残留知识’。

Result: 发现冗余信息（在两个模型间共享）构成持久存在的残留知识，并与已知对抗性重构攻击的脆弱性相关；基于此提出一种基于表示的风险评分机制，可在推理时对敏感输入进行回避，有效缓解隐私泄露风险。

Conclusion: 本研究提出了一个基于表示层面的系统性遗忘审计方法，兼具理论深度与实际应用价值，有助于更安全地部署语言模型。

Abstract: We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models.

</details>


### [169] [Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.15124)
*Haonan Yuan,Qingyun Sun,Jiacheng Tao,Xingcheng Fu,Jianxin Li*

Main category: cs.LG

TL;DR: 本文提出RAG-GFM，一种基于检索增强生成的图基础模型，通过将知识从模型参数中卸载，解决传统图基础模型因内存瓶颈导致的语义容量受限、信息压缩损失和表示纠缠等问题。该模型构建了双模态统一检索模块（语义存储基于前缀结构文本，结构存储基于中心性基元），设计双视角对齐目标以保留异构信息，并通过上下文增强丰富下游任务的支撑实例。在五个基准图数据集上的实验表明，RAG-GFM在跨域节点与图分类任务中均显著优于13个先进基线，兼具优越性能与效率。


<details>
  <summary>Details</summary>
Motivation: 传统图基础模型（GFMs）受限于内存瓶颈，将知识编码于模型参数中，导致语义容量有限、信息压缩损失严重、表示与知识纠缠，影响可扩展性与可解释性。为突破这些限制，亟需一种能有效外化图知识、提升适应效率的新范式。

Method: 提出RAG-GFM，采用检索增强生成机制，构建双模态统一检索模块（前缀结构文本用于语义存储，中心性基元用于结构存储），设计双视角对齐目标以联合捕捉内容与关系模式，并通过在上下文中引入检索到的文本与基元实现高效下游适应。

Result: 在五个基准图数据集上，RAG-GFM在跨域节点分类与图分类任务中均显著超越13个现有先进基线方法，在效果与效率方面表现优异。

Conclusion: RAG-GFM通过将图知识外化并结合检索增强机制，有效缓解了传统图基础模型的参数瓶颈问题，实现了更高效、可解释且易于适配的图学习新范式，为未来图学习系统提供了可行路径。

Abstract: Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency.

</details>


### [170] [Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data](https://arxiv.org/abs/2601.15158)
*Yuval Ran-Milo,Yotam Alexander,Shahar Mendel,Nadav Cohen*

Main category: cs.LG

TL;DR: This paper shows that Transformers trained with sparse rewards can spontaneously learn Chain-of-Thought reasoning through gradient flow, provided the training data includes enough simple examples. These simpler cases guide the model toward generalizable, iterative algorithms, validating the mechanism in both theory and real-world language models.


<details>
  <summary>Details</summary>
Motivation: Understanding how sparse rewards in reinforcement learning drive Transformers to develop systematic reasoning, such as Chain-of-Thought (CoT), despite only being trained on final-answer correctness.

Method: Analyzing gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that requires CoT for solution but has a simple iterative structure. Theoretical analysis identifies conditions under which structured reasoning emerges, particularly focusing on the role of 'simple examples' with fewer reasoning steps.

Result: Gradient flow drives convergence to an interpretable, structured algorithm that iteratively traverses graphs vertex-by-vertex. The emergence of generalizable reasoning depends critically on sufficient training mass on simple examples; without them, learning becomes infeasible. Experiments on synthetic data and real-world language models confirm the theory holds in practice.

Conclusion: Simple examples play a crucial role in enabling gradient-based learning to discover systematic reasoning in Transformers. Without them, even with correct final answers, the model fails to generalize beyond short chains. This explains why CoT emerges naturally when training distributions include easier instances.

Abstract: Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of "simple examples": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings.

</details>


### [171] [ZENITH: Automated Gradient Norm Informed Stochastic Optimization](https://arxiv.org/abs/2601.15212)
*Dhrubo Saha*

Main category: cs.LG

TL;DR: ZENITH 是一种无需额外开销的自适应学习率优化器，通过分析梯度范数的时间演化来自动调整学习率。在多个图像分类和目标检测任务中，ZENITH 在更短的运行时间内实现了更高的准确率，并且与正则化兼容，提升了泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有自适应优化器存在计算和内存开销大、不兼容正则化、学习率选择不佳等问题，亟需一种高效、兼容性强且能自动调节学习率的优化方法。

Method: ZENITH 利用梯度范数的历史变化信息，动态调整学习率，避免了传统自适应优化器的高开销问题，同时保持与正则化的良好兼容性。

Result: 在6个CNN架构和6个基准数据集上的图像分类任务中，ZENITH 的测试准确率更高，耗时更短；在MS COCO的目标检测、关键点检测和实例分割任务中，也取得了优于基线的mAP表现。

Conclusion: ZENITH 通过利用梯度范数的历史信息实现高效的自适应学习率调度，在多种视觉任务中表现出优越的性能和效率，且兼容正则化，具备良好的实际应用潜力。

Abstract: Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization.

</details>


### [172] [Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism](https://arxiv.org/abs/2601.15249)
*Garrett G. Wen,Buxin Su,Natalie Collina,Zhun Deng,Weijie Su*

Main category: cs.LG

TL;DR: 本文提出一种作者辅助机制，用于改进机器学习顶会最佳论文奖的评选。通过使用等序机制（Isotonic Mechanism）获取作者对自己论文的排名评估，并据此调整原始评审分数，以更准确估计论文的真实质量。研究证明，在作者效用为凸加性函数时，其有激励说真话；利用ICLR和NeurIPS的公开评审数据验证了该假设的合理性。特别地，当作者只能提名一篇论文时，即使效用函数仅为非递减加性，也能保证诚实申报，显著放宽了以往研究的假设条件。此外，机制扩展至处理作者重叠场景，模拟结果表明该方法能显著提升获奖论文的质量。


<details>
  <summary>Details</summary>
Motivation: 随着顶级会议如NeurIPS和ICML每年收到数万篇投稿，评审质量与一致性面临巨大挑战，尤其是最佳论文奖的评选日益引发争议。现有方法难以确保公平与高质量的筛选，亟需一种更可靠、可信赖的机制来辅助决策。

Method: 采用等序机制（Isotonic Mechanism）收集作者对自己论文的排名评估，基于此对原始评审分数进行校正，以逼近论文的真实质量。在理论层面，分析了作者在不同效用函数下的激励相容性；在实践层面，扩展机制以支持多作者共享论文的情形。

Result: 实验和模拟结果显示，该机制能够有效提高最佳论文候选集的质量。在真实数据上验证了作者效用的凸加性假设成立，且在单提名场景下，即便假设减弱至非递减加性，仍能保持激励相容性，说明机制具有较强鲁棒性。

Conclusion: 本文提出的作者辅助机制通过引入作者自我评估并结合等序校正，显著提升了最佳论文评选的准确性与公平性，尤其在宽松假设条件下仍保持有效性，具备良好的理论基础与实际应用前景。

Abstract: Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards.

</details>


### [173] [MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs](https://arxiv.org/abs/2601.15279)
*Christoph Bartmann,Johannes Schimunek,Mykyta Ielanskyi,Philipp Seidl,Günter Klambauer,Sohvi Luukkonen*

Main category: cs.LG

TL;DR: MolecularIQ is a new benchmark for evaluating chemistry LLMs based on symbolic verification of molecular structure reasoning, addressing limitations of existing benchmarks by enabling fine-grained assessment and revealing model-specific failure patterns.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for chemistry LLMs often rely on biased or leaky labels, focus on general knowledge, or use simplistic evaluation formats like multiple-choice questions, limiting accurate assessment of true molecular reasoning ability.

Method: Introduces MolecularIQ, a benchmark with symbolically verifiable tasks that require deep understanding of molecular graphs, allowing precise evaluation of LLM performance across diverse structural reasoning challenges.

Result: MolecularIQ exposes specific weaknesses in current LLMs related to certain molecular structures and reasoning types, offering actionable insights for improving model design and reasoning fidelity.

Conclusion: By focusing on symbolically verifiable tasks, MolecularIQ enables more reliable and granular evaluation of chemistry LLMs, guiding future development toward faithful reasoning over molecular structures.

Abstract: A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure.

</details>
