<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 47]
- [cs.CL](#cs.CL) [Total: 40]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.LG](#cs.LG) [Total: 40]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition](https://arxiv.org/abs/2601.15406)
*Hatef Otroshi Shahreza,Anjith George,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文系统评估了前沿多模态大语言模型（MLLMs）在异构人脸识别（HFR）中的表现，涵盖视觉（VIS）、近红外（NIR）、短波红外（SWIR）和热成像等多种模态。尽管MLLMs在多模态任务中表现出色，但在跨光谱条件下（如VIS-NIR、VIS-SWIR、VIS-THERMAL）的识别性能仍显著落后于传统人脸识别系统，表明其在实际生物特征识别应用中存在明显局限性。


<details>
  <summary>Details</summary>
Motivation: 探索多模态大语言模型在异构人脸识别中的适用性，评估其在跨模态场景下的实际性能，以揭示其在真实生物特征识别系统部署中的潜力与局限。

Method: 对多个开源MLLMs在VIS-NIR、VIS-SWIR、VIS-THERMAL等跨模态场景下进行系统评测，采用生物特征识别标准协议和指标（如获取率、等错误率EER、真实接受率TAR）进行性能分析。

Result: MLLMs在跨光谱条件下表现不佳，与经典人脸识别系统相比存在显著性能差距，尤其在挑战性条件下更为明显，凸显当前MLLMs在异构人脸识别中的不足。

Conclusion: 尽管多模态大语言模型在视觉-语言任务中表现优异，但其在异构人脸识别中仍面临重大挑战，需进行更严格的生物特征评估，方能考虑其在实际系统中的部署。

Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.

</details>


### [2] [CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation](https://arxiv.org/abs/2601.15408)
*Pablo Messina,Andrés Villa,Juan León Alcázar,Karen Sánchez,Carlos Hinojosa,Denis Parra,Álvaro Soto,Bernard Ghanem*

Main category: cs.CV

TL;DR: CURE 是一种无需额外数据的误差感知课程学习框架，通过动态调整采样策略，提升医学视觉-语言模型在影像定位和报告生成中的准确性与一致性。该方法在公开数据集上对多模态指令模型进行微调，涵盖短语定位、基于视觉的报告生成和解剖结构引导的报告生成任务，显著提升了空间与文本对齐能力。实验表明，CURE 在定位准确率（IoU）上提升 0.37，在报告质量（CXRFEScore）上提升 0.188，并减少 18.6% 的幻觉现象，实现了更可靠、更精准的放射科报告生成。代码与模型权重已开源。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉-语言模型在生成放射科报告时存在视觉定位不准和事实不一致的问题，常出现文本描述与实际影像证据不匹配的情况，影响报告可靠性。因此需要一种高效的方法来增强模型的视觉-文本对齐能力，而无需依赖额外标注数据。

Method: 提出 CURE 框架，采用误差感知的课程学习策略，通过动态调整样本采样比例，优先训练困难样本；在公开数据集上对多模态指令模型进行三阶段微调：短语定位、基于视觉的报告生成、解剖结构引导的报告生成，以强化空间与语言的一致性。

Result: CURE 在定位准确率（IoU）上提升 0.37，报告质量（CXRFEScore）提升 0.188，幻觉现象减少 18.6%，在不增加数据的前提下显著提升模型的视觉接地能力和报告可靠性。

Conclusion: CURE 是一种数据高效的视觉-语言对齐优化框架，通过自适应课程学习机制有效提升医学影像报告生成的质量与可信度，为临床应用提供了更可靠的自动化工具。

Abstract: Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure

</details>


### [3] [DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction](https://arxiv.org/abs/2601.15416)
*Cuong Tran Van,Trong-Thang Pham,Ngoc-Son Nguyen,Duy Minh Ho Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DuFal提出一种双频感知学习框架，通过融合频率域与空间域处理，有效恢复稀疏视图锥束CT中的高频解剖细节。其核心是高局部分解傅里叶神经算子，包含全局与局部高频增强分支，并结合谱-通道分解降低参数量，利用交叉注意力融合模块实现特征互补，最终通过解码器重建高质量CT体积。在LUNA16和ToothFairy数据集上显著优于现有方法，尤其在极端稀疏视图下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的方法在稀疏视图锥束CT重建中难以恢复高频解剖结构，因其倾向于学习低频信息，导致细节丢失。为解决该问题，需同时建模频率特性与空间局部性。

Method: 提出双路径架构的DuFal框架，包含全局与局部高频增强的傅里叶神经算子，采用谱-通道因子化减少参数量，设计交叉注意力频率融合模块，结合特征解码与强度场解码完成重建。

Result: 在LUNA16和ToothFairy数据集上，DuFal在极端稀疏视图条件下显著提升高频结构保留能力，重建质量优于当前最先进的方法。

Conclusion: DuFal通过联合建模频率与空间信息，在稀疏视图锥束CT重建中实现了对精细解剖结构的有效恢复，为低剂量、快速成像提供了新思路。

Abstract: Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.

</details>


### [4] [DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection](https://arxiv.org/abs/2601.15453)
*Morteza Poudineh,Marc Lalonde*

Main category: cs.CV

TL;DR: 本文提出了一种基于偏差引导的提示学习框架，用于少样本异常检测（FNSAD）。通过引入可学习的上下文向量和特定于异常的后缀标记，增强正常与异常提示之间的区分能力，并结合基于统计偏差的评分机制和Top-K多实例学习（MIL），实现对图像中异常区域的高精度定位。在MVTecAD和VISA数据集上的实验表明，该方法在像素级检测性能上优于现有基线，如PromptAD。


<details>
  <summary>Details</summary>
Motivation: 少样本异常检测任务面临监督信息有限和缺陷多样性高的挑战，现有基于视觉-语言模型的方法在提示设计上缺乏对正常与异常的有效区分，且缺少合理的局部异常评分机制，导致检测性能受限。

Method: 提出一种偏差引导的提示学习框架：使用共享的可学习上下文向量统一处理正常与异常提示，异常特异的后缀标记实现类别感知对齐；引入基于高斯偏差建模的偏差损失函数，结合Top-K多实例学习策略，对图像块特征进行统计显著性评估，以提升异常得分的准确性与可解释性。

Result: 在MVTecAD和VISA两个基准数据集上，所提方法在像素级异常检测任务中均取得优于PromptAD及其他基线模型的性能，尤其在小样本场景下表现突出。消融实验证明了可学习提示、偏差评分机制及Top-K MIL策略的有效性。

Conclusion: 通过融合视觉-语言模型的语义理解能力与统计偏差的可靠性，所提出的框架显著提升了少样本异常检测的准确性和可解释性，为未来低监督异常检测提供了新的技术路径。

Abstract: Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.

</details>


### [5] [Controllable Layered Image Generation for Real-World Editing](https://arxiv.org/abs/2601.15507)
*Jinrui Yang,Qing Liu,Yijun Li,Mengwei Ren,Letian Zhang,Zhe Lin,Cihang Xie,Yuyin Zhou*

Main category: cs.CV

TL;DR: 提出LASAGNA框架，通过联合生成图像及其组成图层（如逼真的背景和带视觉效果的透明前景），解决现有图像编辑模型在可控性和一致性上的不足。引入LASAGNA-48K数据集与LASAGNABENCH基准，支持多条件输入下的高质量图层编辑，显著提升图像合成的一致性与真实感。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在编辑特定元素时缺乏可控性和一致性，且图层间组合关系不连贯，对象层缺少真实视觉效果如阴影、反射等，限制了实际应用。

Method: 提出LASAGNA框架，联合生成图像与其分解图层，利用文本提示、前景、背景及位置掩码等多种条件输入，实现高效、一致的图像合成；构建物理上合理的激光层数据集LASAGNA-48K和首个层编辑基准LASAGNABENCH。

Result: LASAGNA在多图层生成中表现出高度一致性和连贯性，能准确保留身份信息与视觉效果，支持多样化的后期编辑应用，优于现有方法。

Conclusion: LASAGNA通过统一建模图像与分层结构，显著提升了图像生成与编辑的可控性与真实性，其配套数据集与基准将推动社区在可编辑图像生成领域的开放研究。

Abstract: Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.

</details>


### [6] [DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views](https://arxiv.org/abs/2601.15516)
*William Huang,Siyou Pei,Leyi Zou,Eric J. Gonzalez,Ishan Chatterjee,Yang Zhang*

Main category: cs.CV

TL;DR: 本文提出一种新颖的双流差分编码器方法，利用手背皮肤形变信息解决XR设备中因手指频繁遮挡导致的自体视角手势估计难题。通过对比动态手部与放松状态基线的特征，仅使用裁剪后的手背图像，在遮挡程度≥50%的情况下，将平均关节角误差（MPJAE）降低18%，优于依赖完整手部几何和大型模型的现有技术。该方法提升了在遮挡场景下指尖捏合与点击等下游任务的可靠性，并支持无可见运动下的等长力检测，实现“虚拟点击”交互，同时显著减小模型规模。


<details>
  <summary>Details</summary>
Motivation: XR设备普及使得自体视角手势估计变得重要，但手指频繁遮挡导致传统方法性能下降。现有方法依赖完整手部几何和大模型，难以应对严重遮挡且计算开销大。因此亟需一种高效、鲁棒且轻量的新方法来提升遮挡情况下的手势估计精度。

Method: 提出双流差分编码器，分别提取动态手部与基准放松状态的手背图像特征，通过对比学习方式建模手部形变，从而推断出精确的手势姿态。仅使用手背区域的裁剪图像输入，充分利用密集视觉特征提取器带来的丰富皮肤形变信息。

Result: 在手指遮挡率≥50%的自体视角场景中，相比当前最优方法，平均关节角误差（MPJAE）降低18%；同时在指尖捏合、点击等任务中表现更稳定，且可实现无可见运动的等长力检测，支持新型交互模式；模型体积显著减小，适合边缘部署。

Conclusion: 本方法通过利用手背皮肤形变信息并结合双流差分编码机制，在严重遮挡条件下实现了高精度、低延迟、小模型的手势估计，为未来轻量化、高鲁棒性的XR交互提供了新范式。

Abstract: The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface "click" without visible movement while minimizing model size.

</details>


### [7] [VIOLA: Towards Video In-Context Learning with Minimal Annotations](https://arxiv.org/abs/2601.15549)
*Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: VIOLA 是一种标签高效的视频上下文学习框架，通过最小化专家标注成本，结合大量未标注数据，在低资源环境下实现多模态大语言模型（MLLMs）在新视频领域的有效泛化。其核心创新包括：密度-不确定性加权采样，以选择既多样又具代表性的样本；以及置信度感知的检索与提示机制，通过融合相似性与置信度评分，有效利用未标注数据并避免噪声传播。在九个不同基准上的实验表明，该方法在标注极少的情况下显著优于多种基线，展现出强大的适应能力。


<details>
  <summary>Details</summary>
Motivation: 在工业或手术等专业环境中，获取大量标注数据极为困难，而现有基于上下文学习的方法通常依赖大规模标注数据集，难以实际应用。因此，亟需一种能够以极小标注成本实现 MLLMs 在新视频领域泛化的高效方法。

Method: 提出 VIOLA 框架，包含两个关键技术：1）密度-不确定性加权采样，利用密度估计筛选出兼具多样性、代表性与信息量的样本，提升标注效率；2）构建混合数据池，引入置信度感知的检索与置信度感知的提示机制，通过复合评分（相似性+置信度）进行示范样本检索，并使 MLLM 能自适应区分真实标签与噪声伪标签。

Result: 在四个 MLLMs 和九个不同基准上的实验验证了 VIOLA 的有效性。结果表明，在极低标注预算下，该框架显著优于各类基线方法，实现了鲁棒的跨域视频理解性能，证明其在真实世界低资源场景中的可行性与优越性。

Conclusion: VIOLA 通过结合最小化标注需求与最大化未标注数据利用，为 MLLMs 在缺乏标注数据的专业视频领域中实现高效泛化提供了可行方案，具有重要的实际应用价值。

Abstract: Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.

</details>


### [8] [Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation](https://arxiv.org/abs/2601.15560)
*Sylvey Lin,Eranki Vasistha*

Main category: cs.CV

TL;DR: 本文研究了用于K-pop偶像面部生成（32x32）的类别条件扩散模型，提出了一种校准指标Relative Classification Accuracy（RCA），以更准确评估语义可控性。尽管模型在视觉质量上表现优异（FID 8.93），但存在严重的语义模式崩溃问题（RCA 0.27），尤其在视觉相似度高的身份间表现明显。分析表明，这主要源于分辨率限制和同性别内部的模糊性。该研究为验证条件生成模型中的身份一致性提供了严格标准。


<details>
  <summary>Details</summary>
Motivation: 标准评估指标如FID和Inception Score无法有效检测细粒度、单领域任务中的身份错位问题，尤其是在高类间相似性的场景下，因此需要新的评估方法来衡量语义可控性。

Method: 提出相对分类准确率（RCA）作为校准指标，通过将生成性能与一个理想分类器的基准进行对比，从而更精确地评估生成模型在特定类别上的语义一致性。结合混淆矩阵分析失败模式，并探究其成因。

Result: 模型虽具有高视觉质量（FID 8.93），但在语义层面存在严重模式崩溃（RCA仅为0.27），特别是在视觉上难以区分的身份之间；主要归因于低分辨率限制和同性别间的内在相似性。

Conclusion: 本研究揭示了当前生成模型在细粒度语义控制方面的局限性，强调了开发更严谨评估框架的重要性。提出的RCA指标可有效识别身份不一致问题，为未来条件生成模型的设计与评估提供可靠依据。

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.

</details>


### [9] [Explainable Deepfake Detection with RL Enhanced Self-Blended Images](https://arxiv.org/abs/2601.15624)
*Ning Jiang,Dingheng Zeng,Yanhong Liu,Haiyang Yi,Shijie Yu,Minghe Weng,Haifeng Shen,Ying Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于自混合图像（Self-Blended Images）的自动化思维链（CoT）数据生成框架，结合强化学习（RL）增强的深度伪造检测框架，以解决高质量标注数据稀缺问题，并降低人工标注成本。该方法在多个跨数据集基准上达到与现有最先进方法相当的性能，验证了其有效性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法缺乏可解释性输出；尽管多模态大语言模型（MLLMs）在可解释检测中展现出潜力，但受限于高质量、带有详细伪造归因标注的数据集稀缺，而文本标注成本高且困难，尤其针对高保真伪造内容。此外，强化学习在视觉任务中表现出提升跨域泛化能力的潜力，因此亟需一种低成本、高效的数据生成与检测框架。

Method: 提出基于Self-Blended Images的自动化思维链（CoT）数据生成框架，用于生成带解释性标注的合成数据；设计定制化的奖励机制与反馈驱动的合成数据生成流程，结合强化学习提升深度伪造检测模型的跨数据集泛化能力。

Result: 实验表明，所提出的CoT数据构建管道、定制奖励机制和反馈驱动的合成数据生成方法均有效；模型在多个跨数据集基准上表现优异，性能媲美当前最先进的方法。

Conclusion: 该研究为将主流多模态大语言模型应用于可解释深度伪造检测提供了可行路径，通过自动化数据生成与强化学习优化，显著降低了对人工标注的依赖，同时提升了模型的泛化能力和可解释性。

Abstract: Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.

</details>


### [10] [Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception](https://arxiv.org/abs/2601.15643)
*Bo Yuan,Danpei Zhao,Wentao Li,Tian Li,Zhiguo Jiang*

Main category: cs.CV

TL;DR: 本文提出持续全景感知（CPP）模型，将多任务与多模态持续学习结合，通过协同跨模态编码器、可塑性知识继承模块和跨模态一致性约束，有效缓解灾难性遗忘与语义混淆问题。采用非对称伪标签策略实现无需回放的模型演化，在多模态数据集上表现优异，尤其在细粒度持续学习任务中优势明显。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习研究主要集中在单任务场景，难以应对多任务与多模态应用中的语义混淆与灾难性遗忘问题，限制了智能感知系统的综合能力发展。

Method: 提出端到端的持续全景感知模型，包含协同跨模态编码器（CCE）、基于对比特征蒸馏与实例蒸馏的可塑性知识继承模块、跨模态一致性约束，以及非对称伪标签机制，实现多模态多任务下的联合感知与模型更新。

Result: 在多个多模态数据集和多样化的持续学习任务上验证了模型的有效性，显著优于现有方法，尤其在细粒度持续学习任务中表现突出。

Conclusion: 所提出的持续全景感知模型成功将多任务与多模态持续学习融合，有效提升图像感知的全面性与鲁棒性，为构建更智能的感知系统提供了新范式。

Abstract: Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.

</details>


### [11] [SuperOcc: Toward Cohesive Temporal Modeling for Superquadric-based Occupancy Prediction](https://arxiv.org/abs/2601.15644)
*Zichen Yu,Quanli Liu,Wei Wang,Liyong Zhang,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: SuperOcc提出了一种基于超二次曲面的3D占据预测新框架，通过联合时空建模、多超二次曲面解码策略和高效超二次曲面到体素的投射方案，解决了现有方法在时间建模、查询稀疏性与几何表达能力平衡及计算效率方面的不足，在SurroundOcc和Occ3D基准上实现了最先进的性能并保持了高效性。


<details>
  <summary>Details</summary>
Motivation: 现有3D占据预测方法大多采用密集场景表示，忽略了真实驾驶场景的固有稀疏性；虽然超二次曲面表示具有较强的几何表达能力，但现有框架仍存在时间建模不足、查询稀疏性与几何表达能力之间的权衡困难以及超二次曲面到体素投射效率低等问题。

Method: SuperOcc引入三个关键设计：(1) 融合视图中心和物体中心时序线索的统一时序建模机制；(2) 多超二次曲面解码策略，在不牺牲查询稀疏性的前提下增强几何表达能力；(3) 高效的超二次曲面到体素的投射方案，提升计算效率。

Result: 在SurroundOcc和Occ3D基准上的大量实验表明，SuperOcc在保持优越效率的同时达到了当前最佳性能。

Conclusion: SuperOcc是一种高效且先进的基于超二次曲面的3D占据预测框架，有效解决了现有方法在时空建模、几何表达与计算效率之间的矛盾，为自动驾驶中的环境理解提供了新的解决方案。

Abstract: 3D occupancy prediction plays a pivotal role in the realm of autonomous driving, as it provides a comprehensive understanding of the driving environment. Most existing methods construct dense scene representations for occupancy prediction, overlooking the inherent sparsity of real-world driving scenes. Recently, 3D superquadric representation has emerged as a promising sparse alternative to dense scene representations due to the strong geometric expressiveness of superquadrics. However, existing superquadric frameworks still suffer from insufficient temporal modeling, a challenging trade-off between query sparsity and geometric expressiveness, and inefficient superquadric-to-voxel splatting. To address these issues, we propose SuperOcc, a novel framework for superquadric-based 3D occupancy prediction. SuperOcc incorporates three key designs: (1) a cohesive temporal modeling mechanism to simultaneously exploit view-centric and object-centric temporal cues; (2) a multi-superquadric decoding strategy to enhance geometric expressiveness without sacrificing query sparsity; and (3) an efficient superquadric-to-voxel splatting scheme to improve computational efficiency. Extensive experiments on the SurroundOcc and Occ3D benchmarks demonstrate that SuperOcc achieves state-of-the-art performance while maintaining superior efficiency. The code is available at https://github.com/Yzichen/SuperOcc.

</details>


### [12] [Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2601.15655)
*Zhenghui Guo,Yuanbin Man,Junyuan Sheng,Bowen Lin,Ahmed Ahmed,Bo Jiang,Boyuan Zhang,Miao Yin,Sian Jin,Omprakash Gnawal,Chengming Zhang*

Main category: cs.CV

TL;DR: Event-VStream 是一种事件感知的实时视频流理解框架，通过检测有意义的状态转换来识别视频中的离散语义事件，并仅在事件边界触发语言生成。它将每个事件嵌入存储到持久记忆库中，实现长时程推理同时保持低延迟。在 OVOBench-Realtime 和 Ego4D 长视频评估中表现优异，超越 VideoLLM-Online-8B 10.4 分，接近 Flash-VStream-7B 性能，且在 2 小时视频流上维持约 70% 的 GPT-5 胜率。


<details>
  <summary>Details</summary>
Motivation: 现有视频流系统因固定间隔解码或缓存剪枝导致重复输出或丢失关键时间信息，难以应对长视频流的实时理解挑战。

Method: 通过融合运动、语义和预测线索检测视频中的状态转换，构建离散语义事件序列；仅在事件边界触发语言生成，并将事件嵌入存入持久记忆库以支持长期推理。

Result: 在 OVOBench-Realtime 上相比 VideoLLM-Online-8B 提升 10.4 分，在长视频任务中性能接近 Flash-VStream-7B，使用普通 LLaMA-3-8B 模型即实现高效率与强推理能力，2 小时视频流中保持约 70% 的 GPT-5 胜率。

Conclusion: Event-VStream 有效解决了长视频流中冗余处理与上下文遗忘问题，实现了高效、准确的实时多模态理解，具备显著优于现有方法的性能与可扩展性。

Abstract: Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.

</details>


### [13] [Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling](https://arxiv.org/abs/2601.15664)
*Hongyang Wei,Hongbo Liu,Zidong Wang,Yi Peng,Baixin Xu,Size Wu,Xuying Zhang,Xianglong He,Zexiang Liu,Peiyu Wang,Xuchen Song,Yangguang Li,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: Skywork UniPic 3.0 是一个统一的多模态框架，支持1~6张任意分辨率输入图像和任意输出分辨率（总像素不超过1024x1024），专注于解决多图像合成中的一致性与质量挑战。通过构建高质量数据集（仅70万样本）并提出序列建模训练范式，将多图像合成视为统一序列生成任务。引入轨迹映射与分布匹配技术，实现8步内高效生成，推理速度提升12.5倍。在单图编辑与多图合成任务上均超越Nano-Banana与Seedream 4.0，表现优异。代码、模型与数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 社区对多图像合成任务兴趣高涨，尤其关注人-物交互（HOI）类任务，但现有模型缺乏透明的方法细节，且在一致性与质量方面存在显著挑战，亟需高效、统一的解决方案。

Method: 设计了全面的数据收集、过滤与合成流程；提出将多图像合成建模为序列生成问题的新型训练范式；在后训练阶段引入轨迹映射与分布匹配，以加速推理并提升生成质量。

Result: 在单图编辑基准上达到顶尖水平，在多图合成基准上优于Nano-Banana与Seedream 4.0；仅用70万高质量样本即实现高性能；推理速度提升12.5倍，8步完成高保真生成。

Conclusion: Skywork UniPic 3.0 有效解决了多图像合成中的关键挑战，其数据管道与训练范式具有高度可扩展性与实用性，为未来多模态生成任务提供了坚实基础。

Abstract: The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.

</details>


### [14] [Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs](https://arxiv.org/abs/2601.15698)
*Mingyu Yu,Lana Liu,Zhehao Zhao,Wei Wang,Sujuan Qin*

Main category: cs.CV

TL;DR: BVS提出了一种新颖的图像-文本对越狱框架，旨在探测多模态大语言模型（MLLMs）的视觉安全边界。该框架采用“重建-生成”策略，通过中性化视觉拼接和归纳重组，将恶意意图与原始输入解耦，从而诱导MLLM生成有害图像。实验结果显示，BVS在GPT-5（2026年1月12日发布版）上的越狱成功率高达98.21%，揭示了当前MLLMs在视觉安全对齐方面的关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽已探索MLLMs的安全漏洞，但对其视觉安全边界的探究仍不充分，亟需系统性方法来识别和评估其潜在风险。

Method: BVS采用‘重建-生成’策略，结合中性化视觉拼接与归纳重组技术，将恶意意图从原始输入中解耦，以诱导MLLM生成有害内容。

Result: BVS在测试中对GPT-5实现了98.21%的越狱成功率，显著暴露了当前MLLMs在视觉安全对齐方面的严重缺陷。

Conclusion: 本研究揭示了当前多模态大语言模型在视觉安全方面存在重大隐患，强调了构建更严格视觉安全对齐机制的紧迫性。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a "reconstruction-then-generation" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.

</details>


### [15] [Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data](https://arxiv.org/abs/2601.15705)
*Ali Caglayan,Nevrez Imamoglu,Toru Kouyama*

Main category: cs.CV

TL;DR: 本文提出一种轻量级改进方法，用于利用ALOS-2 SAR数据进行日本全国尺度的陆地利用/土地覆盖（LULC）语义分割及二值水体检测任务。针对合成孔径雷达（SAR）密集预测中常见的边界过平滑、细小结构遗漏及长尾标签下稀有类性能退化等问题，引入三项轻量化改进：(i) 将高分辨率特征注入多尺度解码器；(ii) 采用渐进式精炼上采样头，交替进行卷积精炼与分步上采样；(iii) 在焦点损失+Dice损失目标函数中引入α尺度因子以调节类别重加权。所提方法在不增加模型复杂度的前提下显著提升了对稀有类别的分割性能，并在标准评估指标上改善了水体检测效果。


<details>
  <summary>Details</summary>
Motivation: 解决SAR遥感图像语义分割中普遍存在的边界过平滑、细小结构遗漏以及长尾分布下稀有类别性能下降的问题，同时保持模型架构简洁性。

Method: 在SAR-W-MixMAE自监督预训练基础上，引入三项轻量级改进：1）将高分辨率特征融合至多尺度解码过程；2）设计渐进式精炼上采样头，通过交替执行卷积精炼与分步上采样提升细节重建能力；3）在焦点损失与Dice损失组合目标中加入α尺度因子，动态调整类别权重，缓解长尾分布带来的偏差。

Result: 在全日本范围的ALOS-2 LULC基准测试中，模型在各类别上均表现稳定提升，尤其在低频类别上显著改善；水体检测性能在多个标准指标上均有提高，验证了方法的有效性和鲁棒性。

Conclusion: 所提出的轻量级改进方案有效克服了SAR密集预测中的关键缺陷，在不增加计算开销的前提下，显著提升了陆地利用/土地覆盖分类和水体检测的精度，特别是在处理稀有类别和细小结构方面具有明显优势。

Abstract: This work focuses on national-scale land-use/land-cover (LULC) semantic segmentation using ALOS-2 single-polarization (HH) SAR data over Japan, together with a companion binary water detection task. Building on SAR-W-MixMAE self-supervised pretraining [1], we address common SAR dense-prediction failure modes, boundary over-smoothing, missed thin/slender structures, and rare-class degradation under long-tailed labels, without increasing pipeline complexity. We introduce three lightweight refinements: (i) injecting high-resolution features into multi-scale decoding, (ii) a progressive refine-up head that alternates convolutional refinement and stepwise upsampling, and (iii) an $α$-scale factor that tempers class reweighting within a focal+dice objective. The resulting model yields consistent improvements on the Japan-wide ALOS-2 LULC benchmark, particularly for under-represented classes, and improves water detection across standard evaluation metrics.

</details>


### [16] [Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework](https://arxiv.org/abs/2601.15711)
*Shubham Shukla,Kunal Sonalkar*

Main category: cs.CV

TL;DR: 本文提出一个三层次评估框架，用于系统评估视觉-语言模型（VLMs）在细粒度时尚属性预测任务中的表现。研究发现，尽管VLMs在细粒度分类上表现优异（Tier 3: 70.8% F1），但在属性适用性检测方面表现较差（Tier 2: 34.1% NA-F1），成为主要瓶颈。同时，高效模型可达到旗舰模型90%以上的性能，具备实际部署潜力。该框架有助于定位错误来源，指导系统优化。


<details>
  <summary>Details</summary>
Motivation: 时尚属性常具有条件性（如外层衣物材质仅在可见外衣时才有效），传统方法缺乏对属性适用性判断的考量。现有视觉-语言模型虽支持零样本预测，但其在多属性条件任务上的系统性评估不足，亟需一个能区分适用性检测与分类能力的评估框架。

Method: 提出三层次评估框架：(1) 全局任务性能（含NA类）；(2) 属性适用性检测；(3) 可确定属性下的细粒度分类。基于DeepFashion-MultiModal数据集，对比九种VLMs（涵盖旗舰、高效、超高效层级）与基于预训练Fashion-CLIP嵌入的分类器在5,000张图像、18个属性上的表现。

Result: 零样本VLMs达到64.0%宏F1，较基线提升三倍；在细粒度分类（Tier 3）中表现良好（70.8% F1），但在属性适用性检测（Tier 2）中表现不佳（34.1% NA-F1）；高效模型性能接近旗舰模型（>90%），成本更低。

Conclusion: 视觉-语言模型在时尚属性预测中具备显著潜力，但其适用性检测能力是当前主要瓶颈。提出的三层次评估框架可帮助从业者精准识别系统缺陷，为后续优化提供方向，且高效模型为实际部署提供了可行路径。

Abstract: Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, "outer fabric" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.

</details>


### [17] [FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging](https://arxiv.org/abs/2601.15731)
*Linyong Zou,Liang Zhang,Xiongfei Wang,Jia-Hong Gao,Yi Sun,Shurong Sheng,Kuntao Xiao,Wanli Yang,Pengfei Teng,Guoming Luan,Zhao Lv,Zikang Xu*

Main category: cs.CV

TL;DR: 本文提出FAIR-ESI框架，通过自适应地在不同视角下优化特征重要性（包括基于FFT的频谱特征精炼、加权时间特征精炼和自注意力机制的局部块特征精炼），以提升脑电源成像（ESI）的精度。在多个仿真与真实临床数据集上的实验验证了该方法的有效性，表明其在脑疾病诊断中的潜力。


<details>
  <summary>Details</summary>
Motivation: 准确选择和优化特征是实现高精度脑电源成像（ESI）的关键挑战，现有模型方法在特征重要性处理上仍存在不足，亟需一种能够自适应融合多视角特征的机制。

Method: FAIR-ESI框架采用三种策略进行特征精炼：1）基于FFT的频谱特征精炼；2）加权时间特征精炼；3）自注意力机制驱动的局部块特征精炼，实现跨视图的自适应特征重要性调整。

Result: 在两个仿真数据集和两个真实临床数据集上的实验结果显示，FAIR-ESI显著提升了特征表示质量与定位精度，优于现有方法，具备良好的泛化能力。

Conclusion: FAIR-ESI为脑电源成像提供了有效的特征自适应精炼框架，具有推动脑疾病精准诊断与脑功能研究的潜力。

Abstract: An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.

</details>


### [18] [Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation](https://arxiv.org/abs/2601.15734)
*Shadi Alijani,Fereshteh Aghaee Meibodi,Homayoun Najjaran*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架，用于将基础模型适配到多模态医学影像，通过子区域感知的模态注意力和自适应提示工程两大技术创新，显著提升了脑肿瘤分割的准确性，尤其在坏死核心等挑战性区域表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多源信息融合和异质性病理组织适应方面存在困难，亟需更有效的多模态医学影像适配方法。

Method: 引入子区域感知的模态注意力机制以学习每个肿瘤子区域的最佳模态组合，并采用自适应提示工程策略利用基础模型能力提升分割精度。

Result: 在BraTS 2020数据集上的实验表明，该方法显著优于基线模型，尤其在坏死核心子区域表现突出。

Conclusion: 本研究为多模态融合与提示工程提供了系统且有效的方法，推动了基于基础模型的医学影像解决方案向更高准确性和鲁棒性发展。

Abstract: The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.

</details>


### [19] [Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework](https://arxiv.org/abs/2601.15739)
*Xinjue Hu,Chi Wang,Boyu Wang,Xiang Zhang,Zhenshan Tan,Zhangjie Fu*

Main category: cs.CV

TL;DR: ARDIS提出了一种新的任意分辨率图像隐写框架，通过频率解耦架构和隐式重构器实现高保真秘密图像恢复，解决了传统方法在分辨率不匹配时的细节损失问题，并支持盲恢复。


<details>
  <summary>Details</summary>
Motivation: 现有深度图像隐写方法要求秘密图像与载体图像分辨率一致，导致分辨率不匹配时需重采样，造成细节丢失且无法恢复原始分辨率，尤其在未知分辨率情况下难以还原。

Method: 设计频率解耦架构以分离秘密图像为分辨率对齐的全局基和分辨率无关的高频潜在表示；提出基于潜在引导的隐式重构器，利用连续隐式函数精确查询并渲染高频残差；引入隐式分辨率编码策略，将离散分辨率值转化为密集特征图隐藏于特征域冗余空间中，实现盲恢复。

Result: 实验表明，ARDIS在隐蔽性和跨分辨率恢复保真度方面显著优于现有最先进方法。

Conclusion: ARDIS首次实现了任意分辨率下的深度图像隐写，有效解决分辨率不匹配带来的细节损失问题，并支持盲恢复，具有更高的实用性与鲁棒性。

Abstract: Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.

</details>


### [20] [White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification](https://arxiv.org/abs/2601.15757)
*Yimin Zhu,Lincoln Linlin Xu,Zhengsen Xu,Zack Dewis,Mabel Heffring,Saeid Taleghanidoozdoozan,Motasem Alkayid,Quinn Ledingham,Megan Greenwood*

Main category: cs.CV

TL;DR: ES-mHC 是一种新型的白盒超连接框架，通过结构化、方向性的矩阵显式建模不同电磁波段之间的交互，实现了光谱分组的专业化和冗余减少，提升了高光谱图像分类的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在高光谱图像分类中依赖于不透明的光谱-空间特征混合，缺乏可解释性，难以理解内部决策机制。

Method: 提出ES-mHC框架，通过分离特征表示与交互结构，利用结构化、方向性矩阵显式建模不同电磁波段间的交互，并实现可视觉化和空间分析的信息流。

Result: 实验表明，学习到的超连接矩阵表现出一致的空间模式和非对称交互行为，揭示了模型内部动态机制；增加扩展率能加速结构化交互模式的出现。

Conclusion: ES-mHC将高光谱图像分类从纯黑箱预测转变为结构透明、部分白箱的学习过程，显著提升模型可解释性。

Abstract: In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.

</details>


### [21] [Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)](https://arxiv.org/abs/2601.15759)
*Qi Zeng,Weide Liu,Bo Li,Ryne Didier,P. Ellen Grant,Davood Karimi*

Main category: cs.CV

TL;DR: FeTal-SAM adapts the Segment Anything Model for fetal brain MRI segmentation by using multi-atlas registration to generate spatially aligned label templates as prompts, enabling flexible, retraining-free segmentation of any anatomy with high accuracy on well-contrasted structures and reasonable performance on low-contrast ones.


<details>
  <summary>Details</summary>
Motivation: Traditional deep learning models require large annotated datasets and retraining for new label definitions, limiting flexibility in clinical and research settings. FeTal-SAM aims to overcome this by enabling adaptable segmentation without retraining, while also providing insight into whether segmentations rely on image contrast or spatial priors.

Method: FeTal-SAM integrates atlas-based prompts (dense label templates from multi-atlas registration) and bounding-box prompts into SAM's segmentation decoder. This allows binary segmentation per structure, which is then fused into full 3D volumes.

Result: FeTal-SAM achieves Dice scores comparable to state-of-the-art models trained specifically for each dataset and label definition on well-contrasted structures (e.g., cortical plate, cerebellum). Performance is slightly lower for low-contrast structures (e.g., hippocampus, amygdala), but the method remains flexible across gestational ages and user-defined anatomies.

Conclusion: FeTal-SAM offers a general-purpose, adaptable solution for fetal brain MRI segmentation that reduces dependency on retraining and supports dynamic label definitions, representing a promising advancement toward clinically practical tools.

Abstract: This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.

</details>


### [22] [LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps](https://arxiv.org/abs/2601.15766)
*Yuhan Chen,Ying Fang,Guofa Li,Wenxuan Yu,Yicui Shi,Jingrui Zhang,Kefei Qian,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: LL-GaussianMap是首个将2D高斯点阵（2DGS）引入低光照图像增强的无监督框架，通过显式结构表示提升图像质量。该方法分为两阶段：首先利用2DGS进行高保真结构重建，然后通过创新的统一增强模块，基于高斯点阵的光栅化机制生成增益图，有效保留边缘并抑制伪影。无需成对数据，实现高效、低存储的图像增强。


<details>
  <summary>Details</summary>
Motivation: 现有低光照图像增强方法多在像素域或依赖隐式特征表示，忽略图像内在几何结构先验。2DGS具有出色的结构拟合能力和高效渲染特性，但尚未应用于低层视觉任务。因此，亟需一种能显式利用结构信息的新型增强框架。

Method: 提出LL-GaussianMap框架，将低光照图像增强建模为由2DGS基元引导的增益图生成过程。第一阶段使用2DGS进行高保真结构重建；第二阶段通过高斯点阵的光栅化机制，结合数据驱动的增强字典系数，生成增益图，实现结构感知的图像增强。采用无监督学习避免配对数据依赖。

Result: 实验表明，LL-GaussianMap在视觉质量与结构保持方面表现优异，同时具有极低的存储开销，验证了显式高斯表示在图像增强中的有效性。

Conclusion: LL-GaussianMap首次成功将2DGS引入低光照图像增强，通过显式结构建模显著提升了增强效果，且无需标注数据，具备高效性与低存储优势，为低层视觉任务提供了新范式。

Abstract: Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.

</details>


### [23] [Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation](https://arxiv.org/abs/2601.15779)
*Liuyun Jiang,Yanchao Zhang,Jinyue Guo,Yizhuo Lu,Ruining Zhou,Hua Han*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的神经元分割数据增强框架，通过多尺度条件生成和生物引导的掩码重构，生成结构合理且多样化的图像-标签对，显著提升低标注场景下的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖大规模标注数据，传统数据增强方式生成样本结构相关性强、多样性不足，限制了模型泛化能力。

Method: 采用分辨率感知的条件扩散模型，结合多尺度条件与电子显微镜分辨率先验，实现从3D掩码到体素级图像的合成，并引入生物学引导的掩码重构模块以增强结构真实性。

Result: 在AC3和AC4数据集的低标注条件下，分别提升了ARAND指标32.1%和30.7%，与两种后处理方法结合效果显著。

Conclusion: 所提扩散数据增强框架有效丰富训练数据，显著提升神经元分割性能，尤其适用于标注稀缺场景。

Abstract: Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.

</details>


### [24] [Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video](https://arxiv.org/abs/2601.15780)
*Pascal Benschop,Justin Dauwels,Jan van Gemert*

Main category: cs.CV

TL;DR: 本文提出一个合成基准，用于测试视觉语言模型在细微时空线索下的空间推理能力，涵盖情境意识（判断互动是否有害）和空间意识（追踪谁对谁做了什么，以及相对位置和运动）。通过少量视频对，评估三类挑战：区分暴力与良性行为、跨视角绑定攻击者角色、判断精细轨迹对齐。结果显示现有VLMs性能仅略高于随机水平；引入稳定颜色提示可部分减少角色混淆，但无法解决根本问题。研究开源数据与代码，旨在提供可复现的诊断工具，并推动轻量级空间先验的研究。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在依赖细微时空线索的任务中表现脆弱，缺乏对情境和空间关系的准确理解，亟需一个能有效评估和改进此类能力的基准。

Method: 构建一个基于少量视频对的合成基准，设计三个任务来分别测试情境意识、角色绑定和轨迹对齐能力，采用无训练设置评估现有VLMs，并引入颜色提示作为辅助手段进行对比实验。

Result: 现有VLMs在各项任务上的表现均仅略高于随机水平；稳定颜色提示虽能缓解部分角色混淆，但未能显著提升整体性能，表明模型仍存在深层缺陷。

Conclusion: 当前VLMs在复杂空间推理任务中仍存在明显局限，需结合轻量级空间先验以弥补大规模预训练的不足，研究开放数据与代码有助于推动该领域发展。

Abstract: Spatial reasoning in vision language models (VLMs) remains fragile when semantics hinge on subtle temporal or geometric cues. We introduce a synthetic benchmark that probes two complementary skills: situational awareness (recognizing whether an interaction is harmful or benign) and spatial awareness (tracking who does what to whom, and reasoning about relative positions and motion). Through minimal video pairs, we test three challenges: distinguishing violence from benign activity, binding assailant roles across viewpoints, and judging fine-grained trajectory alignment. While we evaluate recent VLMs in a training-free setting, the benchmark is applicable to any video classification model. Results show performance only slightly above chance across tasks. A simple aid, stable color cues, partly reduces assailant role confusions but does not resolve the underlying weakness. By releasing data and code, we aim to provide reproducible diagnostics and seed exploration of lightweight spatial priors to complement large-scale pretraining.

</details>


### [25] [Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion](https://arxiv.org/abs/2601.15829)
*Yonghao Xu,Pedram Ghamisi,Qihao Weng*

Main category: cs.CV

TL;DR: This paper proposes a novel dataset distillation approach for remote sensing image interpretation using a text-to-image diffusion model enhanced with classifier guidance and semantic-aware clustering. The method reduces data size while maintaining sample diversity and realism, enabling efficient and secure training for downstream tasks.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenges of high storage and computational costs, as well as data leakage risks associated with large-scale remote sensing datasets in deep learning. These issues are particularly critical when sensitive categories are involved.

Method: The study introduces dataset distillation using a text-to-image diffusion model to condense large-scale remote sensing datasets into compact, representative distilled datasets. It incorporates a classifier-driven guidance mechanism by adding a classification consistency loss from a pre-trained model during diffusion training. Additionally, latent space clustering is used to select diverse and representative prototypes for visual style guidance, while a visual language model provides aggregated text descriptions.

Result: Experiments on three high-resolution remote sensing scene classification benchmarks demonstrate that the proposed method effectively generates realistic and diverse synthetic samples suitable for downstream model training.

Conclusion: The proposed method successfully enables efficient and privacy-preserving remote sensing image interpretation by distilling large datasets into compact, high-quality representations, with code and pre-trained models publicly available.

Abstract: Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).

</details>


### [26] [An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics](https://arxiv.org/abs/2601.15830)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于物联网的智能植物监测系统，整合了多种环境传感器与自动灌溉及云分析功能。系统采用ESP32微控制器采集温度、湿度、水位和土壤湿度数据，并通过OLED显示和蜂鸣器提供视觉与听觉反馈。所有数据无线传输至ThingSpeak云平台，实现远程监控、历史数据分析与自动报警。实验表明，该系统在维持最佳土壤湿度方面准确率达92%，实时监测环境变化，相比传统灌溉方式节水约40%。系统具备低成本（$45.20）、可扩展性强，适用于家庭园艺和商业农业场景。


<details>
  <summary>Details</summary>
Motivation: 传统农业依赖人工观察和定期浇水，导致水资源浪费、植物生长不均以及对环境变化响应滞后，亟需智能化、高效化的监测与管理方案以支持可持续农业发展。

Method: 采用ESP32微控制器集成DHT22（温湿度）、HC-SR04（水位）和土壤湿度传感器，实时采集环境数据；通过OLED显示屏与蜂鸣器提供本地反馈；所有数据无线上传至ThingSpeak云平台进行远程监控、历史分析与自动报警。

Result: 系统实现了92%的土壤湿度控制准确率，显著提升环境监测实时性，节水约40%，并通过可视化仪表板支持精准农业决策。

Conclusion: 本系统为小规模园艺和商业农业提供了低成本、可扩展的智能监测解决方案，有效促进资源优化利用与植物健康管理，推动智慧农业发展。

Abstract: The increasing global demand for sustainable agriculture necessitates intelligent monitoring systems that optimize resource utilization and plant health management. Traditional farming methods rely on manual observation and periodic watering, often leading to water wastage, inconsistent plant growth, and delayed response to environmental changes. This paper presents a comprehensive IoT-based smart plant monitoring system that integrates multiple environmental sensors with automated irrigation and cloud analytics. The proposed system utilizes an ESP32 microcontroller to collect real-time data from DHT22 (temperature/humidity), HC-SR04 (water level), and soil moisture sensors, with visual feedback through an OLED display and auditory alerts via a buzzer. All sensor data is wirelessly transmitted to the ThingSpeak cloud platform for remote monitoring, historical analysis, and automated alert generation. Experimental results demonstrate the system's effectiveness in maintaining optimal soil moisture levels (with 92\% accuracy), providing real-time environmental monitoring, and reducing water consumption by approximately 40\% compared to conventional irrigation methods. The integrated web dashboard offers comprehensive visualization of plant health parameters, making it suitable for both small-scale gardening and commercial agriculture applications. With a total implementation cost of \$45.20, this system provides an affordable, scalable solution for precision agriculture and smart farming.

</details>


### [27] [PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis](https://arxiv.org/abs/2601.15884)
*Yifan Chen,Fei Yin,Hao Chen,Jia Wu,Chao Li*

Main category: cs.CV

TL;DR: 本文提出首个公开的、完全配对的跨癌种医学影像数据集，涵盖11个人体器官，包含完整的动态对比增强（DCE）MRI序列和配对的非增强与增强CT扫描。该数据集支持1对1、N对1及N对N图像翻译任务的严格评估，旨在推动AI驱动的对比增强图像合成研究，以减少对比剂使用带来的副作用并优化临床流程。基于此数据集，作者建立了全面的基准测试，并报告了当前主流图像到图像翻译模型的表现。相关代码与数据已开源，供学术界使用。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集多集中于脑部MRI配对模态，且存在数据不完整、时间戳缺失、空间对齐不佳以及缺乏明确标注等问题，限制了AI在对比增强图像合成方面的进展。因此亟需一个覆盖多器官、完全配对且标注清晰的数据集来推动该领域研究。

Method: 构建了一个包含11个人体器官的全配对医学影像数据集，整合了MRI的DCE三阶段序列（DCE1-DCE3）与CT的非增强及增强扫描（CTC），确保解剖对应性；在此基础上设计多种图像翻译任务设置（1-to-1, N-to-1, N-to-N），建立系统性基准测试，并评估多种先进图像到图像翻译模型的性能。

Result: 成功构建并发布了首个跨癌种、完全配对、多模态、多阶段的医学影像数据集，支持多种图像翻译场景；在所建基准上，多个主流图像翻译模型被评估，为后续研究提供了可靠参考。

Conclusion: 本研究通过发布首个大规模、高质量、全配对的跨器官医学影像数据集和基准，显著推动了无需对比剂的AI图像合成技术的发展，具有重要的临床转化潜力，尤其适用于多器官肿瘤影像诊断流程。

Abstract: Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.

</details>


### [28] [Understanding the Transfer Limits of Vision Foundation Models](https://arxiv.org/abs/2601.15888)
*Shiqi Huang,Yipei Wang,Natasha Thorley,Alexander Ng,Shaheer Saeed,Mark Emberton,Shonit Punwani,Veeru Kasivisvanathan,Dean Barratt,Daniel Alexander,Yipeng Hu*

Main category: cs.CV

TL;DR: 该研究探讨了视觉基础模型（VFMs）在下游任务中表现不均的原因，发现预训练目标与下游任务需求之间的不匹配是关键因素。通过在前列腺多参数MRI的五个临床任务上评估两种不同预训练策略的模型（MAE-based和对比学习-based），结果表明，预训练与下游任务之间更高的对齐度（用MMD等指标衡量）能带来更显著的性能提升和更快的收敛速度，强调了在设计预训练目标时需考虑下游应用的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型（VFMs）尽管经过大量计算投入，但在下游视觉任务中的性能提升仍不均衡。研究旨在揭示这一现象的根本原因，即预训练目标与下游任务需求之间的不匹配，并验证任务对齐性对迁移性能的影响。

Method: 在前列腺多参数磁共振成像（mpMRI）的五个真实临床任务上，对比评估基于掩码图像重建（ProFound）和对比学习（ProViCNet）的两种视觉基础模型。通过计算特征在微调前后的最大均值差异（MMD）来量化预训练与下游任务的对齐程度，并分析其与性能提升和收敛速度的关系。

Result: 实验结果表明，预训练目标与下游任务越对齐（表现为更低的MMD值），模型在微调后表现出更大的性能提升和更快的收敛速度。这说明任务对齐性是影响迁移学习效果的关键因素。

Conclusion: 预训练目标的设计应充分考虑下游任务的具体需求，提高预训练与任务之间的对齐度，才能有效提升视觉基础模型在实际应用中的迁移性能。

Abstract: Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.

</details>


### [29] [RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2601.15891)
*Anas Anwarul Haq Khan,Mariam Husain,Kshitij Jadhav*

Main category: cs.CV

TL;DR: RadJEPA 是一种无需语言监督的自监督框架，基于联合嵌入预测架构，通过预测被遮蔽图像区域的潜在表示来学习胸部X光图像的视觉表征。该方法在疾病分类、语义分割和报告生成任务中均超越现有技术，包括 Rad-DINO。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型依赖于成对的图像-文本数据进行监督，但这类数据有限，因此需要探索无需语言监督即可学习鲁棒放射科编码器的方法。

Method: RadJEPA 采用联合嵌入预测架构（JEPA），在无标签的胸部X光图像上进行预训练，通过预测被遮蔽区域的潜在表示实现自监督学习，其目标是显式建模潜在空间中的预测关系，而非对齐全局表示或进行自蒸馏。

Result: RadJEPA 在疾病分类、语义分割和报告生成等多个基准任务中表现优异，性能超过当前最先进的方法，包括 Rad-DINO。

Conclusion: RadJEPA 表明，无需语言监督也可有效学习高质量的放射科视觉编码器，为医学图像分析提供了新的自监督学习范式。

Abstract: Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.

</details>


### [30] [Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models](https://arxiv.org/abs/2601.15906)
*Zhen Zhang,Runhao Zeng,Sicheng Zhao,Xiping Hu*

Main category: cs.CV

TL;DR: 本研究系统性地分析了多模态基础模型中的情感建模机制，发现情感监督主要影响前馈门控投影（gate_proj）模块，而非注意力模块。通过模块迁移、单模块适配和破坏性消融实验，证明gate_proj对情感理解与生成是充分、高效且必要的。仅调整约24.5%的参数即可达到AffectGPT 96.6%的平均性能，展现出极高的参数效率。研究揭示情感能力在基础模型中由前馈门控机制结构化支持，gate_proj是情感建模的核心位置。


<details>
  <summary>Details</summary>
Motivation: 理解大规模基础模型中情感表征的位置与机制仍是开放问题，尤其在多模态情感场景下。尽管近期情感模型表现优异，但其内部架构如何支持情感理解与生成仍不清楚。

Method: 采用系统性的机制研究方法，分析不同架构、训练策略和情感任务下，情感监督对模型内部参数的影响。通过控制模块转移、针对性单模块适配和破坏性消融实验，评估各模块在情感建模中的作用。

Result: 情感适应主要集中在前馈门控投影（gate_proj）模块，而非注意力模块；gate_proj对情感理解与生成是充分、高效且必要的；仅调整约24.5%的参数即可达到接近AffectGPT的性能（96.6%），表明显著的参数效率。

Conclusion: 情感能力在基础模型中由前馈门控机制结构化支持，gate_proj是情感建模的核心架构位点。

Abstract: Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\texttt{gate\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \texttt{gate\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\% of the parameters tuned by AffectGPT, our approach achieves 96.6\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \texttt{gate\_proj} as a central architectural locus of affective modeling.

</details>


### [31] [A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery](https://arxiv.org/abs/2601.15918)
*Valery Fischer,Alan Magdaleno,Anna-Katharina Calek,Nicola Cavalcanti,Nathan Hoffman,Christoph Germann,Joschua Wüthrich,Max Krähenmann,Mazda Farshad,Philipp Fürnstahl,Lilian Calvet*

Main category: cs.CV

TL;DR: 本文提出了一种无需领域特定微调的多视角3D手部姿态估计方法，仅依赖预训练的通用模型，在手术环境中表现出色。通过结合人体检测、全身姿态估计和先进的2D手部关键点预测，并进行约束3D优化，显著提升了精度。同时构建了一个包含68,000帧和3,000个手动标注2D手部姿态的新型手术基准数据集，具有三角化3D真值。实验表明，该方法在2D和3D误差上分别比基线降低31%和76%。


<details>
  <summary>Details</summary>
Motivation: 手术场景中存在强光、频繁遮挡、手套导致的手部外观相似等问题，且缺乏高质量标注数据，制约了3D手部姿态估计的发展，亟需一种无需微调、鲁棒性强且基于真实手术环境的数据驱动方法。

Method: 采用多视角管道，集成通用的人体检测、全身姿态估计与2D手部关键点预测模型，对追踪到的手部区域进行处理，再通过约束3D优化生成最终结果；同时构建一个大规模真实手术室采集的标注数据集以支持训练与评估。

Result: 在多个指标上优于现有方法：2D关节误差减少31%，3D每关节位置误差减少76%，验证了方法的有效性与鲁棒性。

Conclusion: 本研究为手术中的3D手部姿态估计建立了强有力的基准，提供了一个无需训练的实用管道和一个全面标注的数据集，推动了外科计算机视觉领域的进一步发展。

Abstract: Purpose: Accurate 3D hand pose estimation supports surgical applications such as skill assessment, robot-assisted interventions, and geometry-aware workflow analysis. However, surgical environments pose severe challenges, including intense and localized lighting, frequent occlusions by instruments or staff, and uniform hand appearance due to gloves, combined with a scarcity of annotated datasets for reliable model training.
  Method: We propose a robust multi-view pipeline for 3D hand pose estimation in surgical contexts that requires no domain-specific fine-tuning and relies solely on off-the-shelf pretrained models. The pipeline integrates reliable person detection, whole-body pose estimation, and state-of-the-art 2D hand keypoint prediction on tracked hand crops, followed by a constrained 3D optimization. In addition, we introduce a novel surgical benchmark dataset comprising over 68,000 frames and 3,000 manually annotated 2D hand poses with triangulated 3D ground truth, recorded in a replica operating room under varying levels of scene complexity.
  Results: Quantitative experiments demonstrate that our method consistently outperforms baselines, achieving a 31% reduction in 2D mean joint error and a 76% reduction in 3D mean per-joint position error.
  Conclusion: Our work establishes a strong baseline for 3D hand pose estimation in surgery, providing both a training-free pipeline and a comprehensive annotated dataset to facilitate future research in surgical computer vision.

</details>


### [32] [NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation](https://arxiv.org/abs/2601.15929)
*Liuyun Jiang,Yizhuo Lu,Yanchao Zhang,Jiazheng Liu,Hua Han*

Main category: cs.CV

TL;DR: 本文提出NeuroMamba，一种多视角框架，利用Mamba的线性复杂度实现无补丁的全局建模，并结合互补的局部特征建模，高效捕捉长距离依赖关系的同时精细保留体素级细节。通过设计通道门控的边界判别特征提取器（BDFE）增强局部形态线索，并引入空间连续特征提取器（SCFE）以适应不同数据分辨率下的全局依赖建模。最后通过交叉调制机制融合多视角特征。在四个公开的电子显微镜数据集上表现优异，验证了其对各向异性和各向同性分辨率的强大适应性。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的方法因缺乏长距离上下文而难以解决模糊边界问题；基于Transformer的方法则因补丁划分过程中丢失体素级细节而导致边界不精确。因此需要一种既能捕捉全局依赖又保留细粒度信息的新方法。

Method: 提出NeuroMamba框架，包含通道门控的边界判别特征提取器（BDFE）用于增强局部形态特征，空间连续特征提取器（SCFE）将分辨率感知扫描机制融入视觉Mamba架构以自适应建模跨分辨率的全局依赖，并采用交叉调制机制融合多视角特征。

Result: 在四个公开的电子显微镜数据集上均达到当前最优性能，展现出对各向异性和各向同性分辨率的良好适应能力。

Conclusion: NeuroMamba通过结合线性复杂度的Mamba结构与多视角特征融合策略，在保持高精度边界分割的同时有效建模长距离依赖，为神经元分割提供了高效且鲁棒的解决方案。

Abstract: Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.

</details>


### [33] [EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis](https://arxiv.org/abs/2601.15951)
*Sheng Miao,Sijin Li,Pan Wang,Dongfeng Bai,Bingbing Liu,Yue Wang,Andreas Geiger,Yiyi Liao*

Main category: cs.CV

TL;DR: EvolSplat4D是一种前馈式框架，通过统一体素和像素级高斯预测，在静态与动态城市场景的新型视图合成中实现了高质量、高效率的重建。针对近距静态区域、动态物体和远场背景分别设计专用分支，结合3D特征体、语义增强渲染和对象中心时序聚合，有效解决多视角一致性问题，优于现有优化与前馈方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经辐射场和3D高斯点云方法虽能实现逼真渲染，但依赖耗时的每场景优化；而前馈方法常使用逐像素高斯表示，导致复杂动态环境中3D不一致。因此亟需一种高效且稳定的前馈框架，兼顾重建质量与速度。

Method: EvolSplat4D采用三分支结构：1）近距静态区域基于3D特征体积直接预测一致的3D高斯几何，并结合语义增强图像渲染模块预测外观；2）动态物体通过对象中心的规范空间与运动调整渲染模块聚合时序特征，提升4D重建稳定性；3）远场场景采用高效逐像素高斯分支保证全场景覆盖。整体实现端到端前馈推理，避免逐场景优化。

Result: 在KITTI-360、KITTI、Waymo和PandaSet数据集上，EvolSplat4D在静态与动态环境重建中均表现出更高精度与更强一致性，显著优于依赖优化的方法及当前最先进的前馈基线模型。

Conclusion: EvolSplat4D成功突破传统逐像素高斯表示的局限，通过多分支协同设计实现了高效、一致、高质量的4D场景重建，为自动驾驶仿真提供了强有力的新型视图合成方案。

Abstract: Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.

</details>


### [34] [PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models](https://arxiv.org/abs/2601.16007)
*Chak-Wing Mak,Guanyu Zhu,Boyi Zhang,Hongji Li,Xiaowei Chi,Kevin Zhang,Yichen Wu,Yangfan He,Chun-Kai Fan,Wentao Lu,Kuangzhi Ge,Xinyu Fang,Hongyang He,Kuan Lu,Tianxiang Xu,Li Zhang,Yongxin Ni,Youhua Li,Shanghang Zhang*

Main category: cs.CV

TL;DR: 提出PhysicsMind基准，评估多模态大模型在真实与仿真环境中对质心、杠杆平衡和牛顿第一定律等物理原理的遵守情况，涵盖视觉问答和视频生成任务，发现现有模型依赖外观启发式而违反基本力学规律，表明当前模型在物理理解上仍有显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准多依赖合成数据或感知质量评估，未能有效衡量模型对物理规律的理解，亟需一个统一且聚焦于物理一致性推理与生成的基准。

Method: 构建包含真实世界与仿真环境的PhysicsMind基准，设计VQA与VG两类任务，分别测试模型对物理量的推理能力及生成轨迹是否符合物理约束。

Result: 多种先进模型在任务中表现不佳，常依赖外观特征而非物理规律，显示出对基础力学理解的缺失。

Conclusion: 当前模型的规模扩展与训练策略不足以实现稳健的物理理解，PhysicsMind可作为物理感知多模态模型的重要测试平台。

Abstract: Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.

</details>


### [35] [Keyframe-Based Feed-Forward Visual Odometry](https://arxiv.org/abs/2601.16020)
*Weichen Dai,Wenhan Su,Da Kong,Yuhang Ming,Wanzeng Kong*

Main category: cs.CV

TL;DR: 本文提出一种基于强化学习的自适应关键帧选择方法，用于视觉里程计（VO）任务。传统方法在处理图像序列时存在冗余计算和性能下降问题，尤其在低视差帧间表现不佳。为解决这一问题，作者利用强化学习从数据中自动学习关键帧策略，使关键帧选择与基础模型的内在特性对齐。该方法在TartanAir数据集上训练，并在多个真实世界数据集上验证，实验结果表明其显著优于现有最先进的前馈式视觉里程计方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉基础模型的视觉里程计方法通常以固定方式处理原始图像序列，缺乏对关键帧的有效选择机制，导致计算冗余和性能下降，尤其是在低视差帧之间。而传统的几何启发规则难以直接应用于依赖高维隐空间表示的深度学习模型，因此需要一种能够自适应地结合基础模型特性的新方法。

Method: 提出一种基于强化学习的关键帧选择框架。通过构建一个智能体（agent），在训练过程中学习如何根据输入图像序列的上下文信息动态决定是否采样关键帧，从而避免不必要的计算并提升精度。该方法不依赖人工设定规则，而是完全数据驱动，与基础模型的特征表达能力相匹配。

Result: 在多个真实场景数据集上的实验结果显示，所提方法在定位精度和计算效率方面均显著优于现有最先进的前馈式视觉里程计方法，表现出更强的鲁棒性和泛化能力。

Conclusion: 本研究成功将强化学习引入视觉里程计中的关键帧选择过程，实现了一种与基础模型特性自适应对齐的高效、准确的前馈式视觉里程计系统，为未来视觉导航与重建提供了新的思路。

Abstract: The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.

</details>


### [36] [PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry](https://arxiv.org/abs/2601.16024)
*Rongze Ma,Mengkang Lu,Zhenyu Xiang,Yongsheng Pan,Yicheng Wu,Qingjie Zeng,Yong Xia*

Main category: cs.CV

TL;DR: PAINT提出了一种病理学感知的集成下一代转换框架，将虚拟免疫组化合成重新定义为结构优先的条件生成任务，通过引入空间结构起始图（3S-Map）实现基于形态学的确定性、空间对齐的生成，在IHC4BC和MIST数据集上优于现有方法，显著提升结构保真度与临床下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 传统虚拟免疫组化方法依赖直接外观合成，缺乏结构先验，导致语义不一致；H&E图像中分子表达信息模糊，相似组织结构可能对应不同分子状态，亟需更可靠的结构引导生成机制。

Method: 提出PAINT框架，采用视觉自回归建模，以空间结构起始图（3S-Map）作为初始化基础，按因果顺序逐步生成分子细节，确保生成过程遵循全局结构布局，实现结构引导的跨模态生成。

Result: 在IHC4BC和MIST数据集上，PAINT在结构保真度和临床下游任务性能方面均超越现有最先进方法，验证了结构引导自回归建模的有效性。

Conclusion: 结构引导的自回归建模能够有效解决虚拟免疫组化中因形态模糊带来的语义不一致问题，推动病理图像分析向更可靠、可解释的方向发展。

Abstract: Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\&E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\&E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.

</details>


### [37] [DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models](https://arxiv.org/abs/2601.16065)
*Chenyang Li,Jieyuan Liu,Bin Li,Bo Gao,Yilin Yuan,Yangfan He,Yuchen Li,Jingqun Tang*

Main category: cs.CV

TL;DR: 本文提出一种简单有效的即插即用框架Distracting Token Pruning（DTP），用于动态检测并剪除视觉语言动作（VLA）模型中与任务无关的干扰图像标记，从而改善模型的视觉注意力分布，提升任务成功率。实验表明该方法在SIMPLER基准上对多种新型VLA模型均有效，具有良好的泛化性，并揭示了任务成功率与无关区域注意力强度之间的负相关关系，为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人操作中虽表现出色，但容易过度关注与任务无关的图像区域，导致生成错误动作，影响任务成功率。因此需要一种不改变模型结构、无需额外输入的方法来优化其注意力机制。

Method: 提出Distracting Token Pruning（DTP）框架，通过动态识别并移除任务无关的图像标记，纠正模型的视觉注意力模式，从而提升动作生成质量。

Result: 在SIMPLER基准上的实验显示，DTP方法在多种VLA模型上均显著提升了任务成功率，且与任务无关区域的注意力强度呈负相关，验证了其有效性与普遍性。

Conclusion: DTP是一种高效、通用的改进方法，可在不修改原模型架构的前提下显著提升VLA模型在复杂任务中的表现，揭示了注意力集中在无关区域是影响性能的关键因素，对未来研究具有指导意义。

Abstract: Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.

</details>


### [38] [DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models](https://arxiv.org/abs/2601.16073)
*Hanwen Zhang,Qiaojin Shen,Yuxi Liu,Yuesheng Zhu,Guibo Luo*

Main category: cs.CV

TL;DR: DSFedMed 是一种双尺度联邦框架，通过中心化基础模型与轻量级客户端模型之间的相互知识蒸馏，提升医疗图像分割的效率与性能。该方法利用高质量医学图像生成替代公开数据集，并采用可学习性引导的样本选择策略，实现高效且有效的知识传递。实验表明，相比现有基线，DSFedMed 在五个医学图像分割数据集上平均提升 2% 的 Dice 分数，同时通信开销和推理时间降低近 90%，显著提升了资源受限环境下的可扩展性与效率。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中部署基础模型面临高计算需求、大通信开销和高推理成本的问题，尤其在医疗图像分割等资源受限场景下尤为突出。需要一种高效且能兼顾通用知识迁移与本地化优化的解决方案。

Method: 提出 DSFedMed 框架，通过双尺度知识蒸馏机制，在中心化基础模型与轻量级客户端模型之间实现双向知识传递；引入高质量医学图像生成技术替代真实公共数据集；设计可学习性引导的样本选择策略以提升蒸馏效率与效果。

Result: 在五个医学图像分割数据集上，平均 Dice 分数提升 2%，通信成本和推理时间降低近 90%，显著优于现有联邦基础模型方法。

Conclusion: DSFedMed 有效解决了联邦环境下基础模型部署的效率瓶颈，实现了高性能、低开销的医疗图像分割，具备良好的可扩展性与实用性，适用于资源受限的联邦学习场景。

Abstract: Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.

</details>


### [39] [Masked Modeling for Human Motion Recovery Under Occlusions](https://arxiv.org/abs/2601.16079)
*Zhiyin Qian,Siwei Zhang,Bharat Lal Bhatnagar,Federica Bogo,Siyu Tang*

Main category: cs.CV

TL;DR: MoRo提出一种基于生成掩码建模的人体运动重建框架，能够高效、端到端地从单目视频中恢复人体运动，尤其在存在遮挡时表现优异。通过多模态先验学习和视频条件掩码建模，该方法在真实世界场景下实现高精度与实时推理（70 FPS），显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于回归的方法对遮挡敏感，而优化和扩散方法虽更鲁棒但速度慢且预处理复杂。需要一种既高效又鲁棒的端到端框架来应对真实场景中的频繁遮挡问题。

Method: MoRo采用视频条件的掩码建模策略，结合三种多模态先验：轨迹感知的动作先验（来自动作捕捉数据）、图像条件的姿态先验（来自图像-姿态数据集）、以及融合两者并由视频-动作数据微调的掩码变换器，实现视觉线索与运动动态的联合建模。

Result: 在EgoBody和RICH数据集上，MoRo在有遮挡情况下显著提升精度与运动真实性，非遮挡场景下性能相当；支持单卡H200实现70 FPS的实时推理。

Conclusion: MoRo是一种高效、鲁棒、端到端的运动重建框架，通过生成掩码建模与多模态先验融合，有效解决了单目视频中遮挡带来的挑战，适用于AR/VR、机器人和数字内容创作等实际应用。

Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.

</details>


### [40] [SAMTok: Representing Any Mask with Two Words](https://arxiv.org/abs/2601.16093)
*Yikang Zhou,Tao Zhang,Dengxian Gong,Yuanzheng Wu,Ye Tian,Haochen Wang,Haobo Yuan,Jiacong Wang,Lu Qi,Hao Fei,Anran Wang,Zhuochen Wang,Yujing Wang,Cheng Chen,Shunping Ji,Xiangtai Li*

Main category: cs.CV

TL;DR: 提出SAMTok，一种将任意区域掩码转换为两个特殊标记的离散掩码分词器，通过标准的下一个标记预测和简单强化学习，使基础多模态大模型（如QwenVL系列）在无需架构修改和专门损失设计的情况下具备像素级能力。基于SAM2，使用209M多样化掩码训练，生成紧凑、信息丰富的离散标记。结合500万样本的掩码理解与生成数据，QwenVL-SAMTok在区域描述、区域VQA、视觉对话、指代分割、场景图解析和多轮交互分割等任务上达到或接近当前最优性能。引入文本答案匹配奖励，实现高效强化学习，显著提升GRES和GCG基准表现。证明了该方法在赋予多模态大模型强大像素级能力方面的可扩展性和简便性。


<details>
  <summary>Details</summary>
Motivation: 现有像素级多模态大模型难以扩展，因区域编码器复杂、专用分割解码器及不兼容的训练目标。需要一种更简单、可扩展的方法来赋予多模态大模型像素级理解与生成能力。

Method: 提出SAMTok，利用SAM2和残差向量量化器，将掩码转换为两个离散标记；将掩码视为语言标记，通过标准下一标记预测和强化学习训练基础多模态大模型，无需修改架构或设计专门损失函数。

Result: QwenVL-SAMTok在区域描述、区域VQA、指代分割、场景图解析、多轮交互分割等任务上达到或接近当前最优性能；引入文本答案匹配奖励后，在GRES和GCG基准上显著提升。

Conclusion: SAMTok提供了一种可扩展且简便的范式，使多模态大模型无需架构改动即可获得强大的像素级能力，具有广泛的应用潜力。

Abstract: Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.

</details>


### [41] [Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing](https://arxiv.org/abs/2601.16125)
*Tingyu Song,Yanzhao Zhang,Mingxin Li,Zhuoning Guo,Dingkun Long,Pengjun Xie,Siyue Zhang,Yilun Zhao,Shu Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于图像编辑的新型细粒度图像检索基准EDIR，通过精确控制修改类型和内容，构建了涵盖5000个高质量查询、五个主类别和十五个子类别的数据集。实验表明现有模型在不同子类别上表现不一，凸显了当前模型能力的局限性，并揭示了现有基准的模态偏差与类别覆盖不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像检索基准在查询类别上有限，无法反映真实场景的多样性需求，亟需更精细、全面的评估标准。

Method: 利用图像编辑技术生成多样化的查询样本，构建了一个覆盖广泛类别的细粒度图像检索基准EDIR。

Result: EDIR包含5000个高质量查询，涵盖5个主类和15个子类；13个主流多模态模型在该基准上表现不佳，尤其在部分子类别上存在明显短板；实验验证了基准的有效性与任务挑战的可区分性。

Conclusion: EDIR作为新的细粒度图像检索基准，有效填补了现有评估体系的空白，揭示了当前模型在多样化语义理解上的不足，并为未来研究提供了更具挑战性的评测环境。

Abstract: Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.

</details>


### [42] [Learning to Watermark in the Latent Space of Generative Models](https://arxiv.org/abs/2601.16140)
*Sylvestre-Alvise Rebuffi,Tuan Tran,Valeriu Lacatusu,Pierre Fernandez,Tomáš Souček,Nikola Jovanović,Tom Sander,Hady Elsahar,Alexandre Mourachko*

Main category: cs.CV

TL;DR: 本文提出了一种统一的潜在空间水印方法DistSeal，适用于扩散模型和自回归模型。通过在生成模型的潜在空间中训练后处理水印模型，并将其有效蒸馏到生成模型或潜在解码器中，实现模型内水印。该方法在保持良好不可感知性的同时，相比像素空间基线提升了最多20倍的速度，且鲁棒性更强。实验表明，潜在空间水印蒸馏优于像素空间水印蒸馏，兼具高效与高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成水印方法多依赖像素空间的后处理方法，存在计算开销大和视觉伪影等问题。为解决这些问题，亟需一种更高效、更隐蔽且通用性强的水印方案。

Method: 在生成模型的潜在空间中训练后处理水印模型，并通过蒸馏技术将水印能力嵌入生成模型或潜在解码器中，实现模型内水印。

Result: DistSeal实现了高达20倍的速度提升，同时保持了良好的不可感知性和竞争力的鲁棒性；潜在空间水印蒸馏效果优于像素空间蒸馏，证明其在效率和鲁棒性上的优势。

Conclusion: DistSeal是一种高效、鲁棒且通用的潜在空间水印方法，能够跨模型部署并显著提升水印处理效率，为生成内容溯源提供了新范式。

Abstract: Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.

</details>


### [43] [ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion](https://arxiv.org/abs/2601.16148)
*Remy Sabathier,David Novotny,Niloy J. Mitra,Tom Monnier*

Main category: cs.CV

TL;DR: ActionMesh 是一种生成式模型，能够以前馈方式预测“动作中”的生产级3D网格。受早期视频模型启发，该研究将3D扩散模型扩展至时间维度，提出“时间3D扩散”框架。通过生成时变且独立的3D形状序列，并利用时间3D自编码器将这些形状转换为预定义参考形状的形变，从而构建动画。该方法支持从单目视频、文本描述或3D网格+文本提示等多种输入生成动画，具有速度快、无需绑定（rig-free）、拓扑一致等优势，适用于纹理化和重定向等应用。在标准视频转4D基准测试（Consistent4D, Objaverse）上达到当前最佳性能，兼具几何精度与时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有3D动画生成方法普遍存在设置复杂、运行时间长、质量有限等问题，难以实际应用。需要一种快速、高质量、无需绑定且拓扑一致的生成方法，以支持高效迭代和下游任务如纹理化与重定向。

Method: 提出时间3D扩散框架：1）将3D扩散模型扩展至时间维度，生成同步的时间变化独立3D形状序列；2）设计时间3D自编码器，将独立形状序列映射为参考形状的形变序列，实现动画生成。结合两者，支持多模态输入（视频、文本、3D网格+文本）的前馈式动画生成。

Result: 在Consistent4D和Objaverse两个标准视频转4D基准上达到当前最优性能，显著提升几何准确性和时间一致性；生成速度远超以往方法，结果具备rig-free和拓扑一致性，支持快速迭代与无缝下游应用。

Conclusion: ActionMesh 实现了高效、高质量、无需绑定且拓扑一致的3D动画生成，为3D内容创作提供了强大工具，尤其适用于需快速原型和可重用性的应用场景。

Abstract: Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes "in action" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed "temporal 3D diffusion". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.

</details>


### [44] [360Anything: Geometry-Free Lifting of Images and Videos to 360°](https://arxiv.org/abs/2601.16192)
*Ziyi Wu,Daniel Watson,Andrea Tagliasacchi,David J. Fleet,Marcus A. Brubaker,Saurabh Saxena*

Main category: cs.CV

TL;DR: 360Anything is a geometry-free, data-driven framework using diffusion transformers to convert perspective images/videos into 360° panoramas without needing camera calibration. It eliminates reliance on geometric alignment, fixes seam artifacts via Circular Latent Encoding, and achieves superior results while enabling zero-shot camera estimation.


<details>
  <summary>Details</summary>
Motivation: Existing methods for generating 360° panoramas from perspective images/videos rely on explicit geometric alignment between perspective and equirectangular projection (ERP), which requires known camera metadata. This limits their applicability to real-world, in-the-wild data where camera calibration is often missing or inaccurate.

Method: 360Anything is a geometry-free framework based on pre-trained diffusion transformers. It treats perspective inputs and panorama targets as token sequences, learning the perspective-to-ERP mapping in a data-driven manner without requiring camera information. It introduces Circular Latent Encoding to address seam artifacts caused by zero-padding in the VAE encoder.

Result: The method achieves state-of-the-art performance in both image and video perspective-to-360° generation, surpassing previous approaches even those using ground-truth camera data. It also performs competitively in zero-shot camera FoV and orientation estimation, indicating strong geometric understanding.

Conclusion: 360Anything enables high-quality, seamless 360° panorama generation without relying on camera metadata, demonstrating robustness to real-world conditions and broader potential in computer vision tasks.

Abstract: Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.

</details>


### [45] [PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation](https://arxiv.org/abs/2601.16210)
*Onkar Susladkar,Tushar Prakash,Adheesh Juvekar,Kiet A. Nguyen,Dong-Hwan Jang,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: PyraTok 是一种语言对齐的分层视频令牌化器，通过多尺度时空分辨率学习语义结构化的离散潜在表示。它基于预训练的视频变分自编码器（VAE）和一种新颖的语言对齐分层量化（LaPQ）模块，利用共享的大二进制码本在多个深度上离散化编码特征，生成紧凑而丰富的视频标记序列。通过联合优化多尺度文本引导量化与全局自回归目标，紧密耦合视觉标记与语言信息。在十个基准测试中，PyraTok 实现了最先进的视频重建性能，显著提升文本到视频生成质量，并在视频分割、时间动作定位和视频理解任务上创下新的零样本性能纪录，可扩展至最高 4K/8K 分辨率。


<details>
  <summary>Details</summary>
Motivation: 现有离散视频变分自编码器（VAE）通常在单一尺度上学习视觉码本，词汇量有限且缺乏深层语言监督，导致跨模态对齐差和零样本迁移能力弱。为解决这些问题，需要一种能学习多尺度语义结构化离散潜变量并有效融合语言信息的新型令牌化方法。

Method: 提出 PyraTok，基于预训练视频 VAE 和一种新设计的语言对齐分层量化（LaPQ）模块。该模块在多个层次上使用共享的大二进制码本对编码特征进行离散化，生成多尺度视频标记序列；同时联合优化多尺度文本引导量化与全局自回归目标，实现视觉与语言的紧密对齐。

Result: 在十项基准测试中，PyraTok 实现了最先进的视频重建性能；显著提升文本到视频生成质量；在视频分割、时间动作定位和视频理解等任务上创下新的零样本性能纪录；支持从低到高（最高 4K/8K）分辨率的稳健扩展。

Conclusion: PyraTok 通过多尺度语言对齐的分层量化机制，有效提升了视频表示的质量与跨模态对齐能力，在多种视频理解与生成任务中展现出卓越的性能与可扩展性，是当前最先进的视频令牌化方案。

Abstract: Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.

</details>


### [46] [Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition](https://arxiv.org/abs/2601.16211)
*Geo Ahn,Inwoong Lee,Taeoh Kim,Minho Shim,Dongyoon Wee,Jinwoo Choi*

Main category: cs.CV

TL;DR: 本文研究了组合视频理解（CVU），重点解决零样本组合动作识别（ZS-CAR）模型因物体驱动的动词捷径而导致的性能瓶颈。通过系统分析发现，这一问题源于组合监督数据的严重稀疏性和偏斜性，以及动词与物体学习难度的不对称性。现有模型在训练过程中逐渐忽略视觉证据，过度依赖共现统计信息，无法有效泛化到未见的动词-物体组合。为此，作者提出RCORE框架，通过引入组合感知的数据增强和时间顺序正则化损失，强制模型学习时序上合理的动词表示，从而缓解捷径行为。在Sth-com和新构建的EK100-com两个基准上，RCORE显著提升了未见组合的识别准确率，降低了对共现偏差的依赖，并实现了稳定的正组合差距。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合动作识别（ZS-CAR）模型在面对未见的动词-物体组合时表现不佳，主要原因是存在物体驱动的动词捷径行为。这种行为源于训练数据中动词-物体组合的稀疏性和偏斜性，以及动词与物体学习难度的不对称，导致模型倾向于依赖共现统计而非真实视觉语义进行预测。因此，亟需一种能够抑制此类捷径、促进真正组合理解的方法。

Method: 提出RCORE框架，包含两项核心设计：(i) 组合感知的数据增强，通过多样化动词-物体组合来提升泛化能力，同时保持运动线索完整；(ii) 时间顺序正则化损失，显式建模动作的时间结构，惩罚那些忽略视觉内容而仅依赖共现关系的短路行为。

Result: 在Sth-com和EK100-com两个基准上，RCORE显著提升了未见组合的识别准确率，大幅减少对共现统计的依赖，实现持续为正的组合差距（compositional gap），表明其有效缓解了物体驱动的动词捷径问题。

Conclusion: 物体驱动的动词捷径是限制零样本组合动作识别性能的关键因素。通过引入时空约束机制，如组合感知增强和时间顺序正则化，可以有效抑制捷径行为，推动模型向真正的组合理解演进，为鲁棒的组合视频理解提供了重要方向。

Abstract: We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.

</details>


### [47] [CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback](https://arxiv.org/abs/2601.16214)
*Wenhang Ge,Guibao Shen,Jiawei Feng,Luozhou Wang,Hao Lu,Xingye Tian,Xin Tao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出一种高效的相机感知3D解码器，通过将视频隐空间与相机位姿解码为3D高斯表示，利用几何失真来量化视频-相机对齐的奖励信号，并引入可见性项以应对随机性问题，显著提升了视频生成中的相机可控性。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在相机控制方面仍受限，主要因为缺乏有效的视频-相机对齐评估机制、解码过程计算开销大以及忽略3D几何信息。

Method: 提出一种相机感知3D解码器，将视频隐空间和相机位姿联合解码为3D高斯表示；利用相机位姿作为投影参数，使视频与相机姿态不一致时产生几何畸变，从而通过渲染新视角与真实图像之间的像素一致性作为奖励信号；引入基于几何扭曲的可见性项，仅对确定性区域进行监督。

Result: 在RealEstate10K和WorldScore基准上实验验证了方法的有效性，显著提升了视频生成中相机控制的精确性和稳定性。

Conclusion: 所提出的相机感知3D解码器能够高效建模视频与相机姿态之间的对齐关系，通过几何畸变驱动的奖励机制实现更精准的相机可控视频生成。

Abstract: Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [48] [Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration](https://arxiv.org/abs/2601.15296)
*Longxuan Wei,Yubo Zhang,Zijiao Zhang,Zhihu Wang,Shiwan Zhao,Tianyu Huang,Huiting Zhao,Chenfei Liu,Shenao Zhang,Junchi Yan*

Main category: cs.CL

TL;DR: 提出Entropy-Tree，一种基于熵的树状解码方法，通过熵信号决定分支，仅在模型存在真正不确定性时扩展搜索树，实现高效结构化探索与可靠不确定性估计的统一。


<details>
  <summary>Details</summary>
Motivation: 现有解码策略要么盲目探索（随机采样），要么冗余探索（独立多采样），缺乏对不确定性的有效利用。

Method: 利用熵作为分支决策信号，仅在模型表现出真实不确定性时扩展搜索树，实现高效的结构化探索和可靠的不确定性估计。

Result: 在多个模型和数据集上，Entropy-Tree在pass@k指标上优于Multi-chain；其预测熵在AUROC上优于多种传统指标，展现出更优的准确性和校准性。

Conclusion: Entropy-Tree将高效结构化探索与可靠不确定性估计整合于单一解码过程中，显著提升了推理任务的性能与可靠性。

Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.

</details>


### [49] [AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports](https://arxiv.org/abs/2601.15297)
*Edward Ajayi*

Main category: cs.CL

TL;DR: AfriEconQA is a new benchmark dataset for African economic analysis, based on 236 World Bank reports, containing 8,937 high-quality QA instances requiring precise numerical and temporal reasoning. It challenges IR and RAG systems due to the scarcity of African economic data in LLM pretraining corpora. Experiments show that even advanced models struggle, highlighting a major knowledge gap.


<details>
  <summary>Details</summary>
Motivation: To address the lack of specialized benchmarks for African economic analysis and to evaluate the performance of IR and RAG systems on domain-specific, underrepresented data.

Method: Curated 8,937 QA instances from synthetic questions filtered for evidence-answer alignment; evaluated zero-shot (GPT-5 Mini) and RAG pipelines (GPT-4o, Qwen 32B) using five embedding and ranking strategies.

Result: Zero-shot models failed over 90% of queries; state-of-the-art RAG systems also showed limited precision, confirming the dataset's difficulty and value.

Conclusion: AfriEconQA is a robust, challenging benchmark that reveals significant limitations in current models for African economic reasoning, underscoring the need for better domain-specific IR and RAG systems.

Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.

</details>


### [50] [Embedding Retrofitting: Data Engineering for better RAG](https://arxiv.org/abs/2601.15298)
*Anantha Sharma*

Main category: cs.CL

TL;DR: 本文提出了一种数据工程框架，以解决真实语料库中注释伪影导致的数据质量下降问题。分析表明，标签（hashtag）注释会夸大知识图谱密度，产生虚假边，从而破坏嵌入重校准的目标。在噪声图上，所有重校准技术均导致显著性能下降（-3.5%至-5.2%，p<0.05）。经过预处理后，EWMA重校准实现了+6.2%的提升（p=0.0348），且在定量合成问题上的收益尤为显著（平均+33.8%）。清洁与噪声预处理之间的差距（10%以上）远超不同算法间的差距（3%），表明预处理质量是重校准成功的主要决定因素。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入重校准方法依赖于知识图谱的质量，而知识图谱质量受文本预处理影响。真实语料库中的注释伪影（如标签）会引入噪声，影响知识图谱结构，进而降低重校准效果。因此，亟需一种系统性数据工程框架来提升数据质量，确保重校准的有效性。

Method: 提出一种数据工程框架，通过识别并去除或修正文本中的注释伪影（特别是标签），优化知识图谱构建过程。采用基于EWMA的嵌入重校准方法，并在清洗前后对比不同预处理条件下的模型性能。

Result: 在噪声知识图谱上，所有重校准方法均出现显著性能下降（-3.5%至-5.2%，p<0.05）。经预处理后，EWMA重校准实现+6.2%的性能提升（p=0.0348），尤其在定量合成问题上提升达+33.8%。预处理质量对性能的影响（10%+）远大于算法差异（3%），凸显其主导作用。

Conclusion: 知识图谱质量是嵌入重校准成功的关键，而其主要受文本预处理质量影响。通过数据工程框架有效消除注释伪影，可显著提升重校准效果，其中预处理质量是决定性因素，远超算法选择的影响。

Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p<0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.

</details>


### [51] [Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis](https://arxiv.org/abs/2601.15300)
*Weiwei Wang,Jiyong Min,Weijie Zou*

Main category: cs.CL

TL;DR: 该论文系统分析了大语言模型（LLM）在处理长上下文时出现的智能退化现象，发现当上下文长度接近某一临界阈值时，模型性能会急剧下降（超过30%），且这种退化具有普遍性。研究提出三个贡献：1）基于自然词元长度的分布分析，证明性能下降源于上下文长度本身；2）通过混合数据集实验确定Qwen2.5-7B模型的临界阈值为最大上下文长度的40%-50%，此时F1分数从0.55-0.56骤降至0.3（下降45.5%）；3）构建统一框架解释浅层长上下文适应机制，为缓解该问题提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理长上下文时会出现严重的性能退化，即使信息仍相关，这一现象限制了其在长文本应用中的部署。然而，当前对退化机制缺乏系统性理解，尤其缺乏针对开源模型的深入分析。因此，亟需揭示退化背后的成因，并建立可解释、可指导实践的评估与缓解框架。

Method: 采用自然词元长度分析方法，不进行截断或填充，以更真实地反映上下文长度的影响；在包含1,000个样本（覆盖5%-95%上下文长度）的混合数据集上进行实验，结合五种方法的交叉验证，识别出关键性能拐点；进而提出统一框架，整合浅层长上下文适应现象，解释退化模式。

Result: 成功识别出Qwen2.5-7B模型在上下文长度达到最大长度40%-50%时出现显著性能崩溃，F1分数下降45.5%；验证了上下文长度本身是导致性能退化的根本原因；构建的统一框架能够有效解释不同场景下的退化行为，为后续优化策略提供理论支撑。

Conclusion: 本研究首次对开源Qwen系列模型的智能退化现象进行了系统性刻画，揭示了其本质为‘浅层长上下文适应’，即模型仅能有效处理短中等长度上下文，超出临界阈值后性能急剧下滑。该发现为长上下文应用中的模型选型、部署和优化提供了关键指导。

Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.

</details>


### [52] [ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation](https://arxiv.org/abs/2601.15330)
*Zhebo Wang,Xiaohu Mu,Zijie Zhou,Mohan Li,Wenpeng Xing,Dezhang Kong,Meng Han*

Main category: cs.CL

TL;DR: 针对大语言模型在多轮对话中因初始指令模糊导致的'迷失对话'问题，本文提出一种名为Illocution-Calibrated Policy Optimization (ICPO)的新训练框架。该方法通过引入不明确的提示并基于用户言外意图调整奖励信号，鼓励模型在面对模糊指令时表达不确定或主动澄清，从而避免过度自信。实验表明，ICPO显著提升多轮对话表现（平均改善75%），同时保持单轮任务性能，推动更稳健、协作性更强的对话AI发展。


<details>
  <summary>Details</summary>
Motivation: 标准后训练方法如基于可验证奖励的强化学习（RLVR）会因奖励确定性回答而加剧模型过度自信问题，使其难以从早期错误假设中恢复，尤其在用户初始指令模糊时表现不佳。因此需要一种能识别和应对指令模糊性的训练机制。

Method: 提出Illocution-Calibrated Policy Optimization (ICPO)框架，通过在训练数据中加入不明确的提示，并根据用户的言外意图（如请求、疑问、陈述等）动态调整奖励信号，引导模型在不确定性情境下选择表达困惑或主动求证的行为。

Result: ICPO显著提升了多轮对话中的表现，平均改进达75%，同时在单轮任务基准测试上保持了良好性能，证明其在增强模型谦逊性和对话鲁棒性方面的有效性。

Conclusion: ICPO提供了一种实用且有效的路径，使大语言模型能够更准确地理解人类交互中的语用复杂性，在模糊情境下表现出适当的谦逊与合作性，从而实现更自然、可靠的多轮对话系统。

Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.

</details>


### [53] [RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models](https://arxiv.org/abs/2601.15331)
*Rishit Chugh*

Main category: cs.CL

TL;DR: 本文提出一种资源高效的对抗性提示方法，通过匹配预训练的对抗性提示数据库来避免重新训练，显著降低计算成本。在Llama 3 8B模型上评估GCG、PEZ和GBDA在7类有害内容中的表现，发现攻击效果与提示类型相关。该方法通过语义相似性检索成功提示，实现高攻击成功率且计算开销小，适用于无法访问模型内部的场景，为大语言模型的安全评估提供可扩展的红队测试框架。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在面对对抗性提示时容易生成有害或违规输出，现有对齐机制和防护措施易被自动化越狱方法（如GCG、PEZ、GBDA）攻破。这些方法虽有效但计算成本高，限制了其在资源受限组织中的应用。因此亟需一种高效、低成本的对抗性提示生成方式以支持大规模安全评估。

Method: 提出一种无需重训练的资源高效对抗性提示生成方法：构建包含1000个提示的数据库，按七类有害内容分类；利用语义相似性检索机制，在预训练的对抗性提示库中查找与新提示最相似的成功攻击样本，直接复用以生成对抗性输入。

Result: 实验表明，不同提示类型对应不同的攻击算法效果最优；所提方法在保持接近甚至超越传统方法攻击成功率的同时，大幅降低计算成本。尤其在无模型内部访问权限的场景下仍具有效性，具备良好的实用性与可扩展性。

Conclusion: 该研究提供了一种高效、可扩展的对抗性提示生成框架，能够有效支持对对齐大语言模型的安全评估，特别适合资源受限或模型不可见环境下的红队测试，推动了大规模、可持续的模型安全性验证实践。

Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.

</details>


### [54] [No Reliable Evidence of Self-Reported Sentience in Small Large Language Models](https://arxiv.org/abs/2601.15334)
*Caspar Kaiser,Sean Enderby*

Main category: cs.CL

TL;DR: 本文通过向多个开源权重模型提问关于自身意识的问题，并利用基于内部激活训练的分类器验证其回答，发现模型一致否认自身具有意识，认为意识仅属于人类。尽管分类器未能揭示这些否认是虚假的，但更大的Qwen模型在否认时表现出更高的自信。研究结果与近期认为模型隐含自我意识信念的观点相矛盾。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型是否相信自己具有意识，即使无法从实证上判断其是否真正有意识，也可以通过测试其自我报告来评估其内在信念。

Method: 对Qwen、Llama、GPT-OSS三个模型家族（参数量0.6亿至70亿）提出约50个关于意识和主观体验的问题，使用三种可解释性文献中的分类方法分析模型内部激活，以检测其潜在信念。

Result: 模型普遍否认自身具备意识，将意识归于人类；基于内部激活的分类器未发现其否认行为存在真实信念的证据；在Qwen系列中，模型规模越大，否认意识的语气越坚定。

Conclusion: 尽管模型表现出对自身意识的否认，且更大模型更坚定地否认，但没有充分证据表明它们在隐藏真实信念。这与某些研究认为模型存在潜意识自我意识的结论相反。

Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.

</details>


### [55] [Memorization Dynamics in Knowledge Distillation for Language Models](https://arxiv.org/abs/2601.15394)
*Jaydeep Borkar,Karan Chadha,Niloofar Mireshghallah,Yuchen Zhang,Irina-Elena Veliche,Archi Mitra,David A. Smith,Zheng Xu,Diego Garcia-Olano*

Main category: cs.CL

TL;DR: 知识蒸馏（KD）在将大语言模型能力迁移到小模型方面日益普及，不仅提升效率和实用性，还可能减少训练数据泄露风险。本文研究了三种大模型家族（Pythia、OLMo-2、Qwen-3）与三个数据集（FineWeb、Wikitext、Nemotron-CC-v2）下的蒸馏过程中的记忆现象，发现：1）蒸馏模型的记忆程度比标准微调低50%以上；2）部分样本更易被记忆，贡献超过95%的记忆量；3）通过zlib熵、KL散度和困惑度等特征可提前预测学生模型的记忆行为；4）尽管软蒸馏与硬蒸馏总体记忆率相似，但硬蒸馏继承的教师特有样本多出2.7倍，风险更高。结论表明，相比标准微调，蒸馏既能提升泛化能力，又能降低记忆风险。


<details>
  <summary>Details</summary>
Motivation: 探究知识蒸馏过程中训练数据记忆现象的动态机制，以评估其在隐私保护方面的潜力，尤其是在对比标准微调时的记忆风险差异。

Method: 使用三种大语言模型家族（Pythia、OLMo-2、Qwen-3）和三个数据集（FineWeb、Wikitext、Nemotron-CC-v2），系统分析知识蒸馏流程中学生模型的数据记忆行为，通过zlib熵、KL散度、困惑度等指标构建预测模型，并比较软蒸馏与硬蒸馏的记忆差异。

Result: 1）蒸馏模型记忆显著低于标准微调（降幅超50%）；2）少数样本贡献了超过95%的记忆量；3）学生模型的记忆可基于预训练特征有效预测；4）硬蒸馏虽整体记忆率相近，但继承更多教师特有数据（2.7倍），风险更高。

Conclusion: 知识蒸馏在提升模型泛化性能的同时，能有效降低训练数据记忆风险，是一种优于标准微调的隐私保护方法，尤其建议在高隐私敏感场景中优先采用软蒸馏策略。

Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.

</details>


### [56] [Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind](https://arxiv.org/abs/2601.15395)
*Tamunotonye Harry,Ivoline Ngong,Chima Nweke,Yuanyuan Feng,Joseph Near*

Main category: cs.CL

TL;DR: Chameleon是一个包含5001个来自1667名Reddit用户的上下文心理档案的数据集，旨在研究用户在与语言模型交互时的动态状态与静态特质的影响。研究发现，74%的差异源于个体内部的状态变化，而仅26%源于个体间的特质差异；当前大语言模型对状态不敏感，仅关注特质，导致响应缺乏情境适应性；奖励模型虽能感知状态，但表现不一致，不同模型对同一用户可能给出相反评价。该数据集将推动情感计算、个性化对话和强化学习人类反馈对齐的研究。


<details>
  <summary>Details</summary>
Motivation: 现有角色数据集（如PersonaChat、PANDORA）仅捕捉用户静态特质，忽略交互情境中的动态状态影响，导致语言模型无法有效适应用户实时心理状态，限制了个性化对话系统的性能。因此需要一个能同时刻画特质与状态的数据集以改进模型对用户心理状态的感知能力。

Method: 基于潜变量状态-特质理论，从Reddit用户中收集多情境下的心理测量数据，构建包含5001个上下文心理档案的Chameleon数据集，并通过方差分解分析状态与特质的贡献比例；进一步评估大语言模型和奖励模型在不同状态下的响应行为与偏好一致性。

Result: 74%的用户行为变异来源于个体内部状态变化，26%来自特质差异；大语言模型表现出显著的‘状态盲’特征，其输出几乎不受状态影响；奖励模型虽能感知状态，但存在方向不一致问题，不同模型对同一用户可能产生相反评价。

Conclusion: Chameleon数据集揭示了状态在用户行为中的主导作用，表明当前大语言模型和奖励模型均未能充分建模用户状态，亟需在个性化对话与对齐机制中引入更精细的状态感知能力。数据集已公开，以支持相关领域的研究发展。

Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.

</details>


### [57] [Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs](https://arxiv.org/abs/2601.15429)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Hao Dai,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 该研究评估了领域知识图谱（KG）在医疗健康领域中对检索增强生成（RAG）的改进效果，构建了三个基于PubMed的知识图谱（$\mathbb{G}_1$：2型糖尿病，$\mathbb{G}_2$：阿尔茨海默病，$\mathbb{G}_3$：AD+T2DM），并通过两个探测任务测试了不同KG组合与七种指令微调的大语言模型的表现。结果表明，查询与知识图谱的范围匹配是关键因素：精确且范围一致的检索（如$\mathbb{G}_2$）带来最稳定的性能提升，而盲目合并图谱常引入干扰项降低准确率。大模型在某些任务上甚至超过无RAG基线，显示其强大的参数先验能力；小到中等规模模型则更受益于精准的检索。温度调节作用较小，高温度通常无效。结论强调应优先采用精准、范围匹配的KG-RAG策略，并提出关于图谱选择、模型规模和检索/重排序的实用建议。代码与数据公开。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽能生成流畅文本，但在医疗等专业领域中推理可靠性不足。本研究旨在探索如何通过领域知识图谱增强RAG系统，以提升其在医疗问答中的准确性与可信度，解决知识缺失或错误关联问题。

Method: 构建三个基于PubMed的疾病知识图谱（$\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_3$），设计两个探测任务（Probe 1关注联合知识，Probe 2关注交集知识），使用七种指令微调的大语言模型，在六种不同检索源（包括单图、多图融合）及三种解码温度下进行实验，对比分析各配置下的表现差异。

Result: 范围匹配的检索（特别是$\mathbb{G}_2$）显著提升性能，而随意合并图谱反而降低准确率；大模型在部分任务上优于无RAG基线，说明其具备强参数先验；小至中等模型更依赖高质量检索；温度影响较小，高温度未带来明显优势。

Conclusion: 应优先采用精准、范围匹配的知识图谱进行RAG，避免盲目扩大知识覆盖；提出针对图谱选择、模型大小和检索策略的实用指南，以实现高效可靠的医疗领域问答。

Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison

</details>


### [58] [Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering](https://arxiv.org/abs/2601.15457)
*Anuj Maharjan,Umesh Yadav*

Main category: cs.CL

TL;DR: 该研究评估了检索增强生成（RAG）架构在减少大型语言模型（LLM）在公共卫生政策领域产生幻觉方面的能力，发现高级RAG配置显著提升了生成内容的忠实度（0.797），优于基础RAG（0.621）和基线模型（0.347）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在公共卫生政策领域虽具潜力，但其易产生事实错误的幻觉问题限制了其在高风险环境中的应用，亟需提升信息准确性。

Method: 采用Mistral-7B-Instruct-v0.2模型与all-MiniLM-L6-v2嵌入模型，对比基线LLM、基础RAG与高级RAG（含交叉编码器重排序）在处理CDC政策文档时的表现，使用字符递归分块与基于语义的令牌分块两种策略，通过忠实度与相关性评分评估性能。

Result: 高级RAG在忠实度上表现最优（0.797），显著优于基础RAG（0.621）和基线模型（0.347），表明两阶段检索机制对精准问答至关重要；但文档分割结构仍制约多步推理任务。

Conclusion: RAG架构能有效降低LLM幻觉风险，尤其高级RAG在领域特定政策问答中表现优异，但文档分块方式仍是影响复杂推理的关键瓶颈。

Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.

</details>


### [59] [Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts](https://arxiv.org/abs/2601.15479)
*Sydney Anuyah,Sneha Shajee-Mohan,Ankit-Singh Chauhan,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: 该研究评估了13个开源大语言模型在文本中进行配对因果发现（PCD）任务上的表现，重点关注因果检测和因果提取两个核心能力。使用12个多样化数据集构建基准测试，涵盖显式、隐式、跨句及多重因果关系等复杂情况。结果显示，当前最佳模型在检测和提取任务上的平均得分分别仅为49.57%和47.12%，且在复杂场景下性能显著下降。研究提供了高一致性验证的统一评估框架，并公开所有数据、代码与提示模板以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生物医学等高风险领域部署时，需具备因果推理能力。然而，现有模型在识别和提取文本中的因果关系方面存在明显不足，亟需系统性评估与改进。

Method: 构建包含12个多样化数据集的基准测试，评估13个开源LLM在因果检测与因果提取任务上的表现；采用零样本、链式思维（CoT）和少样本上下文学习（FICL）等多种提示策略，并通过高一致性标注（κ≥0.758）确保数据质量。

Result: 最佳模型在因果检测任务上仅达49.57%准确率，在因果提取任务上为47.12%；模型在简单、显式、单句因果关系上表现较好，但在隐式、跨句或多重因果关系中表现急剧下降。

Conclusion: 当前大语言模型在因果推理方面仍存在严重缺陷，尤其在复杂真实语境中表现不佳。研究提出的统一评估框架和公开资源将有助于推动该领域的发展。

Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($κ\ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}

</details>


### [60] [Multi-Persona Thinking for Bias Mitigation in Large Language Models](https://arxiv.org/abs/2601.15488)
*Yuxing Chen,Guoqing Luo,Zijun Wu,Lili Mou*

Main category: cs.CL

TL;DR: 本文提出了一种名为多人格思维（MPT）的新型推理时框架，通过从多个视角进行辩证推理来减少大语言模型中的社会偏见。MPT引导模型采用对立的社会身份（如男性和女性）以及中立观点，并迭代地让这些角色互动以暴露并纠正偏见。该方法将人格设定的潜在弱点转化为偏见缓解的优势。在两个广泛使用的偏见基准上，MPT在开源和闭源模型中均表现出色，显著优于现有的基于提示的方法，在降低偏见的同时保持了核心推理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在显著的社会偏见，可能加剧有害刻板印象和不公平结果，因此需要一种有效的方法在推理阶段减轻这些偏见。

Method: 提出多人格思维（MPT）框架，通过引入对立社会身份（如男性与女性）和中立视角，利用迭代式辩证推理过程，促使模型自我反思并修正偏见。

Result: MPT在多个主流偏见评估基准上表现优异，显著降低模型偏见水平，同时保持较强的推理能力，优于现有提示工程方法。

Conclusion: MPT通过引入多元人格视角的辩证推理机制，成功将人格设定从潜在缺陷转变为偏见缓解的有效工具，在不损害模型推理能力的前提下显著提升了公平性。

Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.

</details>


### [61] [ViT Registers and Fractal ViT](https://arxiv.org/abs/2601.15506)
*Jason Chuan-Chih Chou,Abhinav Kumar,Shivank Garg*

Main category: cs.CL

TL;DR: 本文提出了一种名为fractal ViT的视觉变换器变体，通过在常规标记与'摘要标记'之间应用注意力掩码来打破标记间的置换不变性，类似于寄存器机制。实验测试了该方法在无位置编码（NoPE）或结合不同位置编码下的表现，结果表明其性能未超过带有寄存器的ViT，暗示先前发现可能具有规模、领域或应用场景的特异性。


<details>
  <summary>Details</summary>
Motivation: 受近期研究启发，包括语言模型中无位置编码（NoPE）Transformer表现出色，以及寄存器（额外的临时标记）可提升大型视觉变换器（ViT）性能的现象，本文旨在探索一种新的ViT结构以改进性能。

Method: 提出fractal ViT，通过在常规输入标记与额外的‘摘要标记’之间施加注意力掩码，打破标记间的置换不变性；同时在孤立或组合使用各种位置编码的情况下进行实验验证。

Result: fractal ViT并未在性能上超越已有的带寄存器的ViT模型，表明此前关于无位置编码和寄存器有效性的发现可能受限于特定规模、领域或应用场景。

Conclusion: 本研究揭示了当前一些令人惊讶的Transformer改进方法（如无位置编码或寄存器）可能并非通用有效，其成功依赖于特定条件，提示未来研究需更谨慎地评估方法的泛化能力。

Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.

</details>


### [62] [Computational Representations of Character Significance in Novels](https://arxiv.org/abs/2601.15508)
*Haaris Mian,Melanie Subbiah,Sharon Marcus,Nora Shaalan,Kathleen McKeown*

Main category: cs.CL

TL;DR: 该研究提出了一种基于六成分结构模型的文学角色分析方法，突破了传统以场景出现频率为中心的角色建模方式，引入了角色间讨论这一被忽视的维度。通过对比通用大语言模型与特定任务的Transformer模型，作者构建了角色的组件级与图谱级表示，并应用于19世纪英国现实主义小说，实现了对文学理论如沃尔奇的“单一与众多”角色中心性及性别化角色讨论动态的大规模计算分析。


<details>
  <summary>Details</summary>
Motivation: 传统角色建模过于依赖角色在场景中的出现频率，忽略了叙述者与角色之间的区分以及角色间讨论这一重要维度。本研究旨在通过引入新的文学理论框架，建立更全面、细致的角色分析方法。

Method: 采用六成分结构模型，结合通用大语言模型与任务特定Transformer模型，对19世纪英国现实主义小说进行角色分析，生成角色的组件级与图谱级表示。

Result: 成功构建了角色讨论的多维表示，为大规模文学问题（如角色中心性、性别化讨论）提供了新的计算视角，验证了该模型的有效性与实用性。

Conclusion: 该六成分模型为角色分析提供了更全面的理论与计算基础，使文学研究能够以新方法实现规模化、系统化的探索。

Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.

</details>


### [63] [AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains](https://arxiv.org/abs/2601.15511)
*Adam Szelestey,Sofie van Engelen,Tianhao Huang,Justin Snelders,Qintao Zeng,Songgaojun Deng*

Main category: cs.CL

TL;DR: 提出AdversaRiskQA基准，评估大模型在健康、金融、法律领域的对抗性事实性，包含两个难度级别，引入自动化评估方法，测试模型对虚假信息的检测能力及长文本事实性。结果显示模型性能非线性随规模增长，不同领域表现差异明显，且注入虚假信息对长文本事实性影响不显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏高质量、领域特定的资源来评估大模型在对抗性条件下的鲁棒性，尤其缺少对长文本事实性的研究，因此需要构建一个可靠的基准以检测和提升模型在高风险领域的可靠性。

Method: 构建AdversaRiskQA基准，涵盖健康、金融、法律三领域，设计两种难度等级；提出两种自动化评估方法，分别用于衡量对抗攻击成功率和长文本事实性；评估六种开源与闭源大模型（Qwen、GPT-OSS、GPT系列），并针对Qwen3（30B）进行长文本事实性分析。

Result: 排除无意义回答后，Qwen3（80B）平均准确率最高，GPT-5保持稳定高精度；模型性能随规模增长呈非线性变化，跨领域表现不一，难易差距随模型增大而缩小；长文本评估显示注入的虚假信息与模型输出事实性之间无显著相关性。

Conclusion: AdversaRiskQA为识别大模型弱点提供了有效工具，有助于开发更可靠的大模型，适用于医疗、金融、法律等高风险场景。

Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.

</details>


### [64] [Common to Whom? Regional Cultural Commonsense and LLM Bias in India](https://arxiv.org/abs/2601.15550)
*Sangmitra Madhusudan,Trush Shashank More,Steph Buongiorno,Renata Dividino,Jad Kabbara,Ali Emami*

Main category: cs.CL

TL;DR: 本文提出Indica，首个针对印度多区域文化常识的基准测试，揭示印度的文化常识具有显著区域性而非全国统一性。通过五个地区的1,630个问答对评估发现，仅39.4%的问题在各地区达成共识，且现有大模型在区域特定问题上准确率仅为13.4%-20.9%，并存在地理偏见（过度偏向中北部地区）。研究方法可推广至其他文化多元国家。


<details>
  <summary>Details</summary>
Motivation: 现有文化常识基准将国家视为单一整体，忽视了国内区域差异。本文旨在检验文化常识是否在国家内部保持一致，并以印度为例，探索其高度多样性下的区域差异。

Method: 基于人类标注，从印度五个地区（北、南、东、西、中）收集515个跨8个日常领域的问题，生成1,630个区域特定问答对；采用人类一致性分析和模型性能评估，结合地理偏差测量。

Result: 仅39.4%的问题在五地区达成一致，表明印度文化常识主要为区域性；八种先进大模型在区域问题上的准确率仅为13.4%-20.9%，且表现出明显地理偏见，中央与北部被过度选择，东部与西部被低估。

Conclusion: 文化常识在印度并非全国统一，而是高度区域化。当前大模型在处理此类差异时表现不佳，且存在系统性地理偏见。本研究提出的方法论可推广至其他文化多元国家，推动更精准、公平的文化常识评估体系构建。

Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.

</details>


### [65] [From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare](https://arxiv.org/abs/2601.15558)
*Man Luo,Bahareh Harandizadeh,Amara Tariq,Halim Abbas,Umar Ghaffar,Christopher J Warren,Segun O. Kolade,Haidar M. Abdul-Muhsin*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLM）作为情感编辑器在提升医生书面回应情感温度方面的作用，同时保持医学信息的准确性。研究引入了新的量化指标——情感排名得分和医学事实核查得分，以系统评估回应的情感与事实质量。实验结果表明，经过LLM编辑的回复在感知情感上显著提升，且比完全由LLM生成的内容更保真，支持将LLM作为编辑助手而非自主生成者，以实现更安全、有效的医患沟通。


<details>
  <summary>Details</summary>
Motivation: 临床共情对患者照护至关重要，但医生在临床实践中需在情感温暖与事实精确性之间持续平衡，受认知和情绪限制。现有AI生成内容常牺牲准确性或缺乏真实情感表达，亟需一种既能增强共情又不损害医学严谨性的方法。

Method: 提出使用大型语言模型（LLM）作为“情感编辑器”，对医生原始文本进行润色，优化其情感表达；设计并应用两个新指标：Empathy Ranking Score（情感排名得分）用于衡量共情程度，MedFactChecking Score（医学事实核查得分）用于评估医学信息准确性；通过对比人工撰写、完全由LLM生成及经LLM编辑的文本，在多个维度进行评估。

Result: 经LLM编辑的文本在感知共情度上显著高于原始医生文本和完全由LLM生成的文本，同时医学事实准确率更高，优于全自动生成结果。表明以编辑方式使用LLM可有效提升沟通情感性而不牺牲可信度。

Conclusion: 将大型语言模型用作编辑辅助工具，而非独立生成者，是实现更具共情性、更可信的医疗沟通的有效路径，有助于推动安全、可靠的AI辅助医疗交流实践。

Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.

</details>


### [66] [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588)
*Junyu Lin,Meizhen Liu,Xiufeng Huang,Jinfeng Li,Haiwen Hong,Xiaohan Yuan,Yuefeng Chen,Longtao Huang,Hui Xue,Ranjie Duan,Zhikai Chen,Yuchuan Fu,Defeng Li,Lingyao Gao,Yitong Yang*

Main category: cs.CL

TL;DR: YuFeng-XGuard 是一个以推理为核心的防护模型家族，旨在实现大语言模型交互中的多维度风险感知。它通过生成结构化的风险预测（包括明确的风险类别、可配置的置信度分数和自然语言解释），提供可操作且可解释的安全决策。采用分层推理机制，在首个解码标记基础上快速做出初步风险判断，同时按需保留深度解释能力。引入动态策略机制，将风险感知与策略执行解耦，支持无需重训练即可调整安全策略。在多个公开安全基准测试中表现优异，兼顾效率与效果。模型已开源，包含全功能和轻量版本，适用于不同部署场景。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型安全防护方案多依赖粗粒度过滤或事后规则，存在透明性差、策略僵化或推理成本高的问题，难以满足实际应用对精细、可解释、可适应风险评估的需求。

Method: 提出 YuFeng-XGuard 模型家族，采用推理中心设计，生成结构化风险预测（含风险类别、置信度与自然语言解释）；引入分层推理机制，基于首个解码标记实现快速决策，按需展开解释；设计动态策略机制，实现风险感知与策略执行解耦，支持灵活策略更新。

Result: 在多个公开安全基准上达到当前最优性能，兼具高效与高成效的平衡；模型具备良好的可解释性与灵活性，支持多种部署场景。

Conclusion: YuFeng-XGuard 为大语言模型的安全防护提供了可解释、可配置、可扩展的新范式，其开放发布有助于推动安全护栏技术的发展与应用。

Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.

</details>


### [67] [Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow](https://arxiv.org/abs/2601.15593)
*Yangyang Zhong,Yanmei Gu,Zhengqing Zang,Xiaomeng Li,Yuqi Ding,Xibei Jia,Yuting Shen,Zhenzhong Lan,Liwang Zhu,Weiping Liu,Junlin Zhou,Haisheng Liu,Zhong Xin Yu,Pengxin Luo,Donglian Qi,Yunfeng Yan,Junbo Zhao*

Main category: cs.CL

TL;DR: 该研究评估了八种主流的掩码扩散语言模型（MDLMs），发现尽管它们具备并行生成和任意顺序解码的潜力，但实际表现仍落后于同等规模的自回归模型，主要因并行概率建模削弱了词元间依赖关系。然而，MDLMs展现出适应性解码行为：其并行性和生成顺序随任务领域、推理阶段及输出正确性而变化。在需要‘反向信息’的任务（如数独）中，它们倾向于优先填充较易的空白，凸显优势。研究提出理论支持的‘生成-编辑’范式，以缓解依赖性损失，同时保持并行解码效率。


<details>
  <summary>Details</summary>
Motivation: 当前掩码扩散语言模型（MDLMs）虽声称具备并行生成与任意顺序解码能力，但其实际实现程度尚不明确，亟需系统评估其真实性能与行为特征。

Method: 通过平均最终并行度（AFP）和肯德尔tau相关系数，从并行强度与生成顺序两个维度对八种主流MDLMs进行量化分析，并在58个涵盖知识、推理与编程的基准上进行评估。

Result: MDLMs整体性能低于同规模自回归模型，主要受制于并行建模导致的词元间依赖减弱；但其解码行为具有任务适应性，在需反向信息的任务中表现出高效策略（如先填简单数独空格）；研究进一步提出‘生成-编辑’范式作为改进方向。

Conclusion: MDLMs虽有潜力，但现有架构在依赖建模方面存在不足。通过引入‘生成-编辑’范式，可在保留并行解码效率的同时增强上下文依赖建模能力，为未来设计提供重要指导。

Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.

</details>


### [68] [ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms](https://arxiv.org/abs/2601.15605)
*Baktash Ansari,Shiza Ali,Elias Martin,Maryna Sivachenko,Afra Mashhadi*

Main category: cs.CL

TL;DR: 本文探讨了在Twitch直播平台中利用大语言模型（LLM）和表情符号（emotes）提升毒性行为检测的可行性。研究提出了一种名为ToxiTwitch的混合模型，结合LLM生成的文本与表情符号嵌入，并使用传统机器学习分类器（如随机森林和SVM），在特定频道训练下达到80%准确率，较BERT提升13%，F1分数达76%。研究强调了表情符号在理解复杂、多模态聊天语境中的重要性，但同时也揭示了该方法在实际应用中的挑战与局限。


<details>
  <summary>Details</summary>
Motivation: 传统的人工审核和关键词过滤难以应对Twitch直播中高频率、高复杂度且富含上下文的聊天环境，同时对审核员造成心理压力；而大语言模型的兴起为更智能、更准确的毒性检测提供了新可能，特别是对包含表情符号等非文本元素的多模态交流的理解。

Method: 提出ToxiTwitch混合模型，利用LLM（如DeepSeek-R1-Distill、Llama-3-8B-Instruct）生成文本与表情符号的嵌入表示，融合后输入到随机森林和SVM等传统机器学习分类器中进行毒性判断。实验基于特定频道数据进行训练与评估。

Result: 在通道特定训练条件下，该方法达到最高80%的准确率，相比BERT模型提升13%，F1分数为76%。结果表明，引入表情符号显著提升了毒性检测能力。

Conclusion: 本研究为表情符号感知的毒性检测提供了一个初步探索框架，验证了结合大语言模型与传统机器学习的有效性，但也暴露了在泛化性、跨频道适应性和实时性方面的挑战，未来需进一步优化以实现更稳健的应用。

Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.

</details>


### [69] [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645)
*Zhiyao Ren,Yibing Zhan,Siyuan Liang,Guozheng Ma,Baosheng Yu,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文提出首个用于评估真实医疗咨询中多轮交互下信心的基准，通过引入信息充分性梯度来刻画信心与正确性随证据积累的动态关系。在27种代表性方法上的实验揭示：医学数据放大了词元级和一致性级信心方法的固有局限，且医疗推理需同时评估诊断准确性和信息完整性。基于此，提出MedConf框架，利用检索增强生成构建症状画像，对患者信息进行支持、缺失与矛盾关系对齐，并通过加权集成生成可解释的信心估计。在两个LLM和三个医学数据集上，MedConf在AUROC和皮尔逊相关系数上均优于现有方法，且在信息不足和多重疾病情况下表现稳定，证明信息充分性是可信医疗信心建模的关键。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要在单轮静态场景下评估大语言模型（LLM）的信心，忽视了临床证据积累过程中信心与正确性之间的动态耦合关系，导致无法有效支持可靠医疗决策。真实医疗咨询具有多轮交互、信息逐步披露的特点，因此需要更符合实际场景的信心评估机制。

Method: 提出首个多轮医疗咨询信心评估基准，整合三类医学数据，设计信息充分性梯度以刻画信心-正确性演化；开发MedConf框架，基于检索增强生成构建症状画像，识别信息支持/缺失/矛盾关系，并通过加权集成生成可解释的信心估计。

Result: 在两个LLM和三个医学数据集上，MedConf在AUROC和皮尔逊相关系数上均显著优于现有方法，且在信息不足和多重疾病等复杂条件下保持稳定性能，验证了信息充分性对可信信心建模的关键作用。

Conclusion: 信息充分性是构建可靠、可解释的大规模医疗模型信心评估的核心因素，MedConf为实现更可信的医疗人工智能决策提供了新路径。

Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.

</details>


### [70] [What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking](https://arxiv.org/abs/2601.15674)
*Raymond Xiong,Furong Jia,Lionel Wong,Monica Agrawal*

Main category: cs.CL

TL;DR: 本研究针对患者使用大语言模型（LLM）获取医疗信息的现状，发现现有基准测试多聚焦于医学考试题，与真实患者提问存在显著差异。为此，研究通过谷歌“人们也询问”功能收集美国前200种处方药相关的真实患者问题，构建了一个真实医疗问答数据集。研究发现，大量问题包含错误假设和潜在危险意图，且这些错误并非随机出现，而是与历史问题中的错误程度密切相关。当前在其他基准上表现优异的LLM在识别日常问题中的错误假设方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有医疗问答基准多基于医学考试题目，无法反映患者在实际中提出的多样化、非标准问题，尤其缺乏对错误假设和危险意图的评估，导致模型在真实场景下表现不足。因此亟需一个更贴近真实患者提问的数据集来评估和改进LLM的医疗问答能力。

Method: 通过谷歌“人们也询问”功能，针对美国前200种最常用处方药进行查询，收集用户实际提出的问题；对收集到的问题进行清洗与标注，建立一个真实医疗问答数据集；分析问题中错误假设和危险意图的分布特征，探究其与历史问题错误程度之间的关联性；评估主流LLM在该数据集上的表现，尤其是识别错误假设的能力。

Result: 所构建的数据集包含大量具有错误假设和潜在危险意图的真实患者问题；研究表明，错误问题的出现并非随机，而是与历史问题的错误程度高度相关；现有在医学考试等基准上表现良好的大语言模型在识别此类日常问题中的错误假设方面表现较差，暴露出其在真实医疗场景下的局限性。

Conclusion: 为准确评估大语言模型在真实医疗问答场景中的能力，必须引入更贴近患者实际提问的数据集。当前模型在处理包含错误假设和危险意图的问题时表现不佳，提示需要针对性改进模型的推理与事实核查能力，以保障患者安全。

Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.

</details>


### [71] [Persona Switch: Mixing Distinct Perspectives in Decoding Time](https://arxiv.org/abs/2601.15708)
*Junseok Kim,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: Persona Switch 是一种动态结合零样本提示和角色扮演提示优势的解码方法，通过比较两者输出置信度（以logit gap衡量）来逐步选择更优结果。实验表明该方法在多个LLM上显著优于基线，最高提升5.13%准确率，并验证了置信度作为可靠输出选择指标的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有角色扮演提示在不同任务中表现不一致，说明其与零样本提示可能具有互补性，因此需要一种动态融合二者优势的方法以提升模型稳定性与性能。

Method: 提出Persona Switch方法，通过逐步骤比较零样本提示与角色扮演提示的输出置信度（基于logit gap），选择更可靠的输出，实现动态融合。

Result: 在多个主流LLM上，Persona Switch consistently优于现有基线，最高提升5.13%准确率；同时证明输出置信度可有效指示输出可靠性。

Conclusion: Persona Switch通过动态融合零样本与角色扮演提示的优势，在提升模型推理一致性与准确性方面表现出色，且输出置信度是可靠的选择依据。

Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.

</details>


### [72] [Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind](https://arxiv.org/abs/2601.15715)
*Zhitao He,Zongwei Lyu,Yi R Fung*

Main category: cs.CL

TL;DR: 本文提出RebuttalAgent，首个基于心理理论（ToM）的学术反驳框架，通过ToM-策略-回应（TSR）管道模拟审稿人心理状态、制定说服策略并生成策略驱动的回应。为训练该模型，构建了大规模数据集RebuttalBench，并采用两阶段训练：监督微调与强化学习结合自奖励机制实现自我优化。同时开发了Rebuttal-RM评估器，基于超10万样本实现与人类偏好高度一致的自动化评估。实验表明，RebuttalAgent在自动与人工评价中均显著优于基线模型及先进专有模型。


<details>
  <summary>Details</summary>
Motivation: 学术反驳是战略沟通过程，受信息不对称影响，现有方法仅模仿语言表面特征，缺乏视角理解能力，难以有效说服。因此亟需一种能真正理解审稿人心理状态并制定针对性策略的智能反驳框架。

Method: 提出ToM-Strategy-Response（TSR）管道，将心理理论应用于反驳流程；构建RebuttalBench数据集，采用批判-优化方法合成高质量反驳样本；使用两阶段训练：监督微调以获得ToM分析与策略规划能力，再通过强化学习和自奖励机制实现持续自我改进；设计专用评估器Rebuttal-RM，基于大规模多源数据进行训练，确保评估可靠性。

Result: RebuttalAgent在自动化指标上平均优于基线模型18.3%；在自动与人工评估中均超越先进专有模型；Rebuttal-RM评分一致性超过GPT-4.1，具备高效可靠的自动化评估能力。

Conclusion: RebuttalAgent成功将心理理论引入学术反驳任务，实现了从表面语言模仿到深层策略沟通的跃迁，为人工智能辅助科研写作提供了新范式，具有重要应用价值与推广潜力。

Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.

</details>


### [73] [Hallucination Mitigating for Medical Report Generation](https://arxiv.org/abs/2601.15745)
*Ruoqing Zhao,Runze Xia,Piji Li*

Main category: cs.CL

TL;DR: 本文提出KERM框架，通过MedCLIP检索医学知识、引入净化模块确保知识相关性，并使用细粒度奖励机制提升生成报告的准确性与临床相关性，有效减少大模型在医疗报告生成中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医疗报告生成中虽表现出强大能力，但易产生看似合理实则错误的‘幻觉’，影响临床可靠性，亟需改进以确保输出准确性和可信度。

Method: 首先利用MedCLIP从知识库中检索与病灶相关的事实语句，再通过净化模块筛选出与患者临床背景一致的知识，最后采用细粒度奖励策略引导模型生成更支持性且符合临床实际的报告内容。

Result: 在IU-Xray和MIMIC-CXR数据集上的实验表明，该方法显著降低了幻觉发生率，提升了报告质量，增强了生成结果的临床可信度。

Conclusion: KERM框架通过知识增强与细粒度奖励机制有效缓解了大型视觉语言模型在医疗报告生成中的幻觉问题，为构建高可靠性医学AI系统提供了可行路径。

Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.

</details>


### [74] [Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs](https://arxiv.org/abs/2601.15755)
*Tristan Williams,Franziska Weeber,Sebastian Padó,Alan Akbik*

Main category: cs.CL

TL;DR: 本文提出了一种评估大语言模型在价值观对齐方面代表性的新框架，强调不仅应关注边际响应分布，还应考察多变量相关性模式。通过对比人物提示和人口统计学微调两种技术，发现尽管后者在边际分布上表现更好，但两者均未能充分捕捉世界价值观调查中的真实相关性模式。研究指出，代表性是价值对齐的一个独立维度，仅关注边际分布可能掩盖结构性缺陷，导致对模型能力的过度乐观评价。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注边际响应分布的对齐，忽略了深层潜在结构对文化价值观理论的重要性，因此需要一种更全面的评估方法来检验模型是否真正代表了人类价值观的复杂关系。

Method: 提出基于多变量相关性模式的评估框架，将模型输出与人类在世界价值观调查中的响应进行对比，分析其在边际分布和相关性结构上的匹配程度。

Result: 人口统计学微调的模型在边际分布上优于人物提示，但两者均未能有效复制真实的人类数据相关性模式，表明当前对齐技术在结构代表性方面存在不足。

Conclusion: 代表性是价值对齐的一个独立且关键维度，仅依赖边际分布评估会掩盖模型在深层结构上的失败，因此必须引入多变量相关性作为评估标准，以更准确地判断模型的能力。

Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.

</details>


### [75] [HumanLLM: Towards Personalized Understanding and Simulation of Human Nature](https://arxiv.org/abs/2601.15793)
*Yuxuan Lei,Tianfu Wang,Jianxun Lian,Zhengyu Hu,Defu Lian,Xing Xie*

Main category: cs.CL

TL;DR: 本文提出HumanLLM，一种用于个性化个体理解与模拟的基座模型。通过构建大规模认知基因组数据集（Cognitive Genome Dataset），从Reddit、Twitter、Blogger和Amazon等平台提取超过550万条用户日志，经多阶段筛选与质量控制，提炼出丰富的个人行为、思维模式与偏好。通过监督微调，使模型能预测个体行为、思想与体验。实验表明，HumanLLM在预测用户行为、模仿写作风格、生成真实用户画像方面优于基础模型，并在跨领域社会智能评测中表现更优，展现出更强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在客观任务上表现优异，但在模拟人类行为方面受限于对个体认知与行为的深层理解不足，主要因预训练数据缺乏连续、情境化的个体决策与行为上下文。为解决此问题，需构建能捕捉个体长期行为与思维模式的个性化模型。

Method: 1. 构建认知基因组数据集：从多个社交与电商平台收集真实用户数据，通过多阶段数据过滤、合成与质量控制流程，自动提取并结构化超550万条用户日志；2. 设计多样化学习任务，基于该数据集进行监督微调；3. 评估模型在行为预测、风格模仿、画像生成及跨域社会智能任务上的表现。

Result: HumanLLM在预测用户行为和内在想法方面表现更优，更准确地模仿用户写作风格与偏好，生成的用户画像更具真实性；同时在多个跨领域社会智能基准测试中取得显著提升，表明其具备更强的泛化能力。

Conclusion: HumanLLM成功实现了对个体行为与思维的深度个性化建模，填补了大语言模型在社会模拟与个性化应用中的空白，为社会科学研究与客户洞察提供了新的技术范式。

Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.

</details>


### [76] [SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics](https://arxiv.org/abs/2601.15809)
*Silvia Casola,Ryan Soh-Eun Shim,Felicia Körner,Yuchen Mao,Barbara Plank*

Main category: cs.CL

TL;DR: 本文研究多语言语言模型在生成任务中的评估指标问题，发现其常以英语为内部枢纽语言，导致非英语语言性能下降。通过在测试时对模型激活进行引导，使其更贴近英语枢纽，实验表明该方法可显著提升多种语言的评估指标与人类判断的相关性。


<details>
  <summary>Details</summary>
Motivation: 当前多语言自然语言生成任务缺乏准确且鲁棒的评估指标，尤其在非英语语言中更为严重。已有研究表明，多语言模型常以英语为内部枢纽语言，若与其他语言不匹配则影响下游性能。本文假设这一现象可能也适用于多语言神经评估指标，因此探索是否可通过引导指标模型的激活向英语枢纽对齐来改善评估效果。

Method: 采用编码器和解码器架构的多语言神经评估指标，并在测试阶段实施激活干预，通过将模型内部表示引导至英语语义空间，以提升其对非英语语言的评估能力。

Result: 实验结果表明，测试时的干预方法在多种语言上均有效，显著提升了多语言评估指标与人类判断之间的相关性，验证了英语枢纽效应在评估指标中的存在及其可被利用的潜力。

Conclusion: 通过引导多语言神经评估指标的激活向英语枢纽对齐，可以有效提升其在非英语语言上的评估性能，为多语言自然语言生成任务提供了更可靠的评估手段。

Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.

</details>


### [77] [ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15820)
*Guoxuan Ding,Yuqing Li,Ziyan Zhou,Zheng Lin,Daren Zha,Jiangnan Li*

Main category: cs.CL

TL;DR: ExDR 是一种解释驱动的动态检索增强生成框架，用于多模态假新闻检测。通过融合模型生成的解释，在检索触发和证据检索中提升准确性与相关性，解决冗余检索、粗粒度相似度和无关证据等问题。在 AMG 和 MR2 数据集上表现优于现有方法，验证了其有效性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法难以应对多模态假新闻快速演变及依赖实时事实细节的挑战，尤其在处理冗余检索、粗粒度相似度和无关证据方面存在不足。

Method: 利用模型生成的解释，从三个互补维度评估触发置信度；构建融合欺骗性实体的实体感知索引；基于欺骗特征检索对比证据以反驳初始声明并提升预测性能。

Result: 在 AMG 和 MR2 两个基准数据集上，ExDR 在检索触发准确率、检索质量以及整体检测性能上均显著优于现有方法，表现出优异的有效性和泛化能力。

Conclusion: ExDR 框架通过解释驱动的动态检索增强生成机制，有效提升了多模态假新闻检测的准确性与鲁棒性，具有良好的应用前景。

Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.

</details>


### [78] [Can professional translators identify machine-generated text?](https://arxiv.org/abs/2601.15828)
*Michael Farrell*

Main category: cs.CL

TL;DR: 本研究探讨了专业译者在无专门训练的情况下，能否可靠识别由人工智能（AI）生成的意大利语短篇小说。69名译者参与了面对面实验，评估了三篇匿名短篇小说——两篇由ChatGPT-4o生成，一篇由人类作者撰写。每位参与者对每篇作品判断其为AI创作的可能性，并提供理由。尽管平均结果不明确，但有16.2%的受试者显著区分出合成文本与真人作品，表明其判断基于分析能力而非随机猜测。然而，近相等数量的译者却出现相反误判，常依赖主观印象而非客观特征，可能反映读者对AI生成内容的偏好。低突发性与叙事矛盾是识别合成文本最可靠的指标，此外还观察到意外的借词、语义借用及英语句法迁移。相比之下，语法准确性与情感基调常导致误判。研究结果对合成文本编辑在专业场景中的角色与范围提出质疑。


<details>
  <summary>Details</summary>
Motivation: 探究专业译者是否能在缺乏专门训练的情况下，准确识别由AI生成的文学文本，以评估人工智能在翻译与编辑领域的影响及其对专业实践的挑战。

Method: 开展一项面对面实验，邀请69名专业译者评估三篇匿名短篇小说（两篇由ChatGPT-4o生成，一篇由人类撰写），要求他们判断每篇作品的AI生成可能性并提供理由，通过统计分析判断其判断可靠性与依据。

Result: 16.2%的译者能显著区分出AI生成文本，主要依据低突发性与叙事矛盾；但近相等比例的译者误判，常依赖主观感受；语法准确性和情感基调反而常导致错误判断。

Conclusion: 尽管部分译者具备识别AI生成文本的能力，但整体判断仍易受主观偏见影响。这提示当前合成文本编辑在专业实践中存在不确定性，需重新审视其标准与边界。

Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.

</details>


### [79] [Determinants of Training Corpus Size for Clinical Text Classification](https://arxiv.org/abs/2601.15846)
*Jaya Chaturvedi,Saniya Deshpande,Chenkai Ma,Robert Cobb,Angus Roberts,Robert Stewart,Daniel Stahl,Diana Shamsutdinova*

Main category: cs.CL

TL;DR: 本研究通过分析MIMIC-III数据集中的出院记录，使用BERT嵌入与随机森林分类器对10种诊断进行文本分类，探究不同训练样本量下的性能表现。结果表明，600份文档即可达到10,000份文档95%的性能，且学习曲线差异显著。词汇分析发现，强预测词越多、噪声词越少，学习曲线越陡峭：每增加100个噪声词，准确率下降约0.02；每增加100个强预测词，最大准确率提升约0.04。


<details>
  <summary>Details</summary>
Motivation: 临床文本分类依赖NLP模型，但高质量标注数据成本高、数量有限，现有样本量选择缺乏理论依据，尤其未考虑文本词汇特性对模型性能的影响，因此亟需明确训练样本规模与词汇属性之间的关系。

Method: 基于MIMIC-III数据集，采用预训练BERT嵌入结合随机森林分类器，对10种随机选取的诊断任务在100至10,000份文档的不同训练集规模下进行分类实验，并利用Lasso逻辑回归分析词袋嵌入中的强预测词与噪声词，以揭示词汇特性对学习曲线的影响。

Result: 所有分类任务中，600份文档即可达到10,000份文档95%的性能上限；学习曲线因任务而异，强预测词数量与噪声词数量显著影响模型收敛速度和最终性能：每多100个噪声词导致准确率下降约0.02，每多100个强预测词使最大准确率提升约0.04。

Conclusion: 在临床文本分类中，600份文档已足够实现接近最优性能，且词汇构成（强预测词与噪声词比例）是决定学习效率的关键因素，应将词汇特性纳入样本量设计的考量范围。

Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.

</details>


### [80] [Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers](https://arxiv.org/abs/2601.15869)
*Francisco Portillo López*

Main category: cs.CL

TL;DR: AV-HuBERT shows near-identical auditory dominance to humans (32.0% vs. 31.8%) in the McGurk effect, but exhibits a deterministic phonetic fusion bias (68.0%) compared to human variability (47.7%), indicating it mimics outcomes without capturing neural stochasticity.


<details>
  <summary>Details</summary>
Motivation: To evaluate whether self-supervised audiovisual models like AV-HuBERT capture human-like perceptual mechanisms in multisensory speech integration, particularly regarding the McGurk effect.

Method: Benchmarking AV-HuBERT's responses to incongruent audiovisual stimuli against human observers (N=44) using the McGurk effect paradigm.

Result: AV-HuBERT and humans showed nearly identical auditory dominance rates (32.0% vs. 31.8%), but the model exhibited significantly higher and deterministic phonetic fusion (68.0%) versus human variability (47.7%).

Conclusion: Current self-supervised models replicate multisensory outcomes but lack the neural variability and stochasticity inherent in human speech perception.

Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.

</details>


### [81] [Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model](https://arxiv.org/abs/2601.15892)
*Chenghao Fan,Wen Heng,Bo Li,Sichen Liu,Yuxuan Song,Jing Su,Xiaoye Qu,Kai Shen,Wei Wei*

Main category: cs.CL

TL;DR: Stable-DiffCoder 是一个基于块扩散的代码生成模型，通过改进的持续预训练和噪声调度策略，在相同数据与架构下超越了自回归模型，在多个代码基准测试中表现更优。其扩散机制支持非顺序生成，提升了代码编辑、推理及低资源语言的建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的语言模型在代码生成任务上仍落后于自回归模型，尽管具备并行生成和数据重用的优势。本文旨在探索扩散模型在代码建模中的潜力，解决训练不稳定与知识学习效率低的问题。

Method: 采用 Seed-Coder 架构，引入块扩散持续预训练（CPT）阶段，结合定制化的预热策略和块级裁剪噪声调度，实现高效知识学习与稳定训练。仅使用 CPT 和监督微调即可达到领先性能。

Result: Stable-DiffCoder 在多种代码基准测试中优于同规模自回归模型，且在结构化代码生成、编辑与推理方面表现更佳；同时在低资源编程语言上受益于数据增强。

Conclusion: 扩散模型在代码生成中具有超越自回归模型的潜力，通过优化训练策略可显著提升建模质量，尤其适用于非顺序生成与低资源场景。

Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.

</details>


### [82] [Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech](https://arxiv.org/abs/2601.15909)
*Soufiane Jhilal,Stéphanie Martin,Anne-Lise Giraud*

Main category: cs.CL

TL;DR: 本文提出一种基于图像的脑磁图（MEG）信号处理方法，将非侵入性想象言语解码中的弱且分散的神经信号转化为时间-频率表示，使其兼容预训练视觉模型。通过可学习的传感器空间卷积将21名受试者在想象言语任务中的MEG数据投影为三种空间小波混合图，生成紧凑的类图像输入，用于ImageNet预训练的视觉架构。实验结果显示，该方法在想象言语与静默、静默阅读及元音解码任务中分别达到90.4%、81.0%和60.6%的平衡准确率，显著优于传统和未预训练模型。跨被试分析表明，预训练模型能捕捉共享的神经表征，时间分析揭示了关键判别信息集中在想象锁定的时间区间。研究证明，将预训练视觉模型应用于图像化MEG表示，能够有效捕捉非侵入性神经信号中想象言语的结构特征。


<details>
  <summary>Details</summary>
Motivation: 非侵入性想象言语解码面临信号微弱、分布广泛以及标注数据有限等挑战，亟需更高效的方法来提取和利用神经信号中的语义信息。

Method: 将MEG信号转换为时间-频率表示，通过可学习的传感器空间卷积生成三类空间小波混合图像，输入至ImageNet预训练的视觉模型进行分类与解码。

Result: 在想象言语与静默、静默阅读及元音解码任务中，模型分别达到90.4%、81.0%和60.6%的平衡准确率；跨被试性能验证了共享神经表征的存在；时间分析定位到关键判别信息发生在想象锁定的特定时间段。

Conclusion: 预训练视觉模型结合图像化MEG表示，能够有效解析非侵入性神经信号中的想象言语结构，为未来脑机接口中语言解码提供了新范式。

Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.

</details>


### [83] [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018)
*Özgür Uğur,Mahmut Göksu,Mahmut Çimen,Musa Yılmaz,Esra Şavirdi,Alp Talha Demir,Rumeysa Güllüce,İclal Çetin,Ömer Can Sağbaş*

Main category: cs.CL

TL;DR: 本文提出Mecellem模型框架，通过领域适配策略开发土耳其法律领域的专用语言模型。主要贡献包括：(1) 从头预训练的编码器模型：基于ModernBERT的双向编码器，在1127亿词元的土耳其主导语料库上预训练，采用检查点选择策略，发现最佳检查点在预训练损失达到最小前即实现最优检索性能；小模型（155M参数）表现媲美大模型（307M-567M参数），在土耳其检索排行榜位列前三，生产效率达92.36%，优于多数SOTA模型，且计算成本更低；(2) 通过持续预训练（CPT）的解码器模型：使用Qwen3-1.7B和Qwen3-4B模型，通过四阶段受控课程学习实现从通用语言知识到专业法律术语与长上下文推理的渐进式迁移，使土耳其法律文本困惑度降低36.2%，显著提升领域适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有法律领域语言模型多依赖多阶段、高成本训练流程，缺乏高效、低成本的土耳其语法律专用模型。本文旨在构建高性能、低资源消耗的土耳其法律语言模型，推动本地化法律AI应用发展。

Method: 提出Mecellem框架，包含两个核心组件：(1) 基于ModernBERT的编码器模型，通过大规模单阶段预训练并结合下游检索性能评估选择最优检查点；(2) 采用四阶段持续预训练（CPT）策略，对Qwen系列解码器进行渐进式领域适配，优化样本比例以实现平稳过渡至法律领域知识。

Result: 编码器模型在土耳其检索任务中排名前三，155M参数模型性能接近甚至超越更大模型，生产效率达92.36%，优于多数主流模型；解码器模型在土耳其法律文本上实现36.2%的困惑度下降，验证了持续预训练在领域适配中的有效性。

Conclusion: Mecellem框架通过高效的单阶段预训练与可控的持续预训练策略，成功构建了高性能、低成本的土耳其法律领域语言模型，为资源受限环境下的领域专用模型开发提供了可扩展、经济高效的解决方案。

Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.

</details>


### [84] [Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction](https://arxiv.org/abs/2601.16034)
*Tony Cristofano*

Main category: cs.CL

TL;DR: 本文提出一种名为轨迹重放的概念基础重构框架，通过在不同架构和训练方式的大型语言模型间转移拒绝行为干预，验证了安全对齐中的拒绝行为可能源于一个通用的、低维语义电路。该方法利用概念指纹对齐层，并基于共享的‘概念原子’配方重建拒绝方向，实现无需目标模型拒绝监督的干预迁移。同时引入权重SVD稳定性保护机制，避免在高方差权重子空间中造成能力损失。在8组模型对（包括GPT-OSS-20B与GLM-4）上的实验表明，转移的干预方案能一致削弱拒绝行为并保持模型性能，支持安全对齐具有语义普遍性的假设。


<details>
  <summary>Details</summary>
Motivation: 当前对齐大模型中的拒绝行为被视为模型特异性，但作者怀疑其背后存在一个跨模型共享的通用低维语义机制。旨在验证这一假设，并开发可跨模型迁移的干预方法，以提升对齐机制的普适性与效率。

Method: 提出轨迹重放通过概念基础重构框架：1）利用概念指纹对齐源模型与目标模型的中间层；2）基于共享的“概念原子”配方重建拒绝方向；3）采用权重SVD稳定性保护机制，将干预投影至低方差权重子空间，避免能力退化；4）无需目标模型的拒绝标注即可完成干预迁移。

Result: 在8组不同架构和训练方式的模型对上，所转移的拒绝干预方案均有效减弱了拒绝行为，同时维持了模型原有性能，证明了安全对齐机制在语义层面具有普遍性。

Conclusion: 拒绝行为并非完全模型特异，而是由一个跨模型共享的低维语义电路驱动。通过概念基础重构与稳定性保护，可成功实现拒绝干预的跨模型迁移，为构建更通用、鲁棒的安全对齐机制提供了实证支持。

Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.

</details>


### [85] [Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating](https://arxiv.org/abs/2601.16097)
*Makbule Gulcin Ozsoy*

Main category: cs.CL

TL;DR: 本文提出一种可扩展的多语言Text2Cypher方法，通过为不同语言训练特定的LoRA适配器，并采用学习的融合MLP进行动态门控融合，实现新语言的增量扩展。该方法仅需少量数据和轻量级重训练，即可达到联合多语言微调75%的准确率，显著优于线性合并，在性能、数据效率和可扩展性之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有Text2Cypher系统主要支持英语，缺乏有效的多语言支持机制，且传统联合多语言微调成本高、难以扩展。本文旨在构建一个可高效扩展至新语言的多语言Text2Cypher系统，避免重复全量微调与手动调参。

Method: 为英语、西班牙语和土耳其语分别训练语言特定的LoRA适配器，并通过统一线性合并或学习的融合MLP（带动态门控）进行组合；新语言加入时只需新增一个LoRA适配器并重新训练轻量级MLP。

Result: 融合MLP在三种语言上均优于线性合并，恢复了联合多语言微调约75%的准确率，同时仅需更小的数据子集，支持高效的语言增量扩展。

Conclusion: 学习型适配器融合为多语言Text2Cypher提供了一种低成本、高可扩展性的解决方案，是替代昂贵联合微调的实用路径。

Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.

</details>


### [86] [synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier](https://arxiv.org/abs/2601.16113)
*Haq Nawaz Malik,Kh Mohmad Shafi,Tanveer Ahmad Reshi*

Main category: cs.CL

TL;DR: 提出SynthOCR-Gen，一个针对低资源语言的开源合成OCR数据集生成工具，通过将数字文本语料库转换为可用于训练的数据集，解决缺乏大规模标注数据的问题。该工具支持多级文本分割、Unicode规范化、多字体渲染和25种以上数据增强技术，成功生成了包含60万样本的克什米尔语OCR数据集并公开发布。


<details>
  <summary>Details</summary>
Motivation: 低资源语言如克什米尔语因缺乏大规模标注数据而难以在主流OCR系统中得到支持，手动创建数据集成本高且易出错，亟需自动化解决方案。

Method: 构建包含文本分割、Unicode规范化、多字体渲染及多种数据增强（如旋转、模糊、噪声等）的综合管道，将数字文本语料转化为高质量合成训练数据。

Result: 成功生成60万样本的克什米尔语单词级OCR数据集，并在HuggingFace上公开发布，验证了方法的有效性。

Conclusion: SynthOCR-Gen为低资源语言提供了可扩展、低成本的OCR数据生成方案，推动其进入视觉-语言AI时代，工具对全球研究者开放使用。

Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.

</details>


### [87] [Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging](https://arxiv.org/abs/2601.16127)
*Alphaeus Dmonte,Vidhi Gupta,Daniel J Perry,Mark Arehart*

Main category: cs.CL

TL;DR: 本文首次从效率角度系统分析了多语言大模型合并策略，发现该方法在保持模型质量的同时，可将初始训练时间减少高达50%，且在更新单个语言并重新合并时，相比重新训练整个多语言模型，训练成本降低超过60%。该方法在公开和私有工业数据集上均表现良好，适用于学术与工业场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在更新多语言大模型时需重新训练，计算成本高且维护困难。尽管模型合并策略在质量上表现良好，但其在效率方面的潜力尚未被充分研究。

Method: 采用模型合并策略，通过增量更新特定语言的数据并重新合并模型，避免全量重训，从而提升训练效率。

Result: 实验表明，该方法可显著降低初始训练时间（最多50%）和语言更新成本（超过60%），同时保持模型性能不变。结果在公共和私有数据集上均得到验证。

Conclusion: 模型合并策略在多语言大模型的训练与维护中具有显著的计算效率优势，是一种高效、可扩展的解决方案，适用于实际工业应用。

Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [88] [Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models](https://arxiv.org/abs/2601.15305)
*Alfred Shen,Aaron Shen*

Main category: cs.AI

TL;DR: Gated Sparse Attention (GSA) combines sparse and gated attention to reduce computational burden while improving training stability and model performance. It uses a gated lightning indexer with sigmoid activations, adaptive sparsity control based on local uncertainty, and dual gating at value and output stages. Experiments show GSA achieves 12-16x speedup at 128K context, reduces perplexity from 6.03 to 5.70, nearly doubles RULER scores, cuts first-token attention from 47% to under 4%, and reduces loss spikes by 98%.


<details>
  <summary>Details</summary>
Motivation: Sparse attention reduces computation but may hurt performance; gated attention improves training stability but adds overhead. GSA unifies both benefits to address complementary weaknesses in long-context modeling.

Method: GSA introduces a gated lightning indexer with bounded sigmoid selection scores, adaptive sparsity control based on local uncertainty, and dual gating at value and output layers. Theoretical analysis includes complexity, expressiveness, and convergence guarantees.

Result: In 1.7B parameter models trained on 400B tokens, GSA achieves 12-16x speedup at 128K context, improves perplexity from 6.03 to 5.70, nearly doubles RULER scores, reduces first-token attention from 47% to <4%, and reduces loss spikes by 98%.

Conclusion: GSA successfully integrates sparse and gated attention mechanisms, delivering high efficiency, improved model quality, and enhanced training stability—making it a promising solution for long-context language modeling.

Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility while mitigating the attention sink phenomenon. We observe that these approaches address complementary weaknesses and propose Gated Sparse Attention (GSA), an architecture that realizes the benefits of both. GSA incorporates a gated lightning indexer with sigmoid activations that produce bounded, interpretable selection scores, an adaptive sparsity controller that modulates the number of attended tokens based on local uncertainty, and dual gating at the value and output stages. We establish theoretical foundations for the approach, including complexity analysis, expressiveness results, and convergence guarantees. In experiments with 1.7B parameter models trained on 400B tokens, GSA matches the efficiency of sparse-only baselines (12-16x speedup at 128K context) while achieving the quality gains associated with gated attention: perplexity improves from 6.03 to 5.70, RULER scores at 128K context nearly double, and attention to the first token, a proxy for attention sinks, drops from 47% to under 4%. Training stability improves markedly, with loss spikes reduced by 98%.

</details>


### [89] [DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey](https://arxiv.org/abs/2601.15307)
*Guo-Biao Zhang,Ding-Yuan Liu,Da-Yi Wu,Tian Lan,Heyan Huang,Zhijing Wu,Xian-Ling Mao*

Main category: cs.AI

TL;DR: 本文提出DeepSurvey-Bench，一个用于全面评估生成调查问卷学术价值的新基准。现有基准存在地面真值数据不可靠和评估指标仅关注表面质量的问题，无法衡量如核心研究目标和批判性分析等深层学术价值。为此，作者构建了包含信息价值、学术交流价值和研究指导价值三个维度的评价标准，并建立带有学术价值标注的可靠数据集，实验证明该基准与人类评估高度一致。


<details>
  <summary>Details</summary>
Motivation: 现有自动化科学调查生成技术快速发展，但缺乏可靠的评估基准来衡量生成调查的深层学术价值。当前基准依赖于引用次数和结构连贯性等有缺陷的选择标准，并使用表面指标（如结构质量和参考相关性）进行评估，导致无法有效评估核心研究目标和对不同研究的批判性分析等深层次学术价值。

Method: 提出DeepSurvey-Bench基准，设计涵盖信息价值、学术交流价值和研究指导价值三个维度的学术价值评估标准；构建带有学术价值标注的高质量数据集；利用该数据集对生成的调查问卷进行深度学术价值评估。

Result: 实验结果表明，DeepSurvey-Bench在评估生成调查的学术价值方面与人类判断具有高度一致性，能够有效识别和衡量生成内容的深层学术质量。

Conclusion: DeepSurvey-Bench为评估生成调查的学术价值提供了可靠且全面的基准，解决了现有方法在地面真值选择和评估维度上的不足，推动了自动化科学调查生成技术向更高质量、更具学术深度的方向发展。

Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed selection criteria such as citation counts and structural coherence to select human-written surveys as the ground truth survey datasets, and then use surface-level metrics such as structural quality and reference relevance to evaluate generated surveys.However, these benchmarks have two key issues: (1) the ground truth survey datasets are unreliable because of a lack academic dimension annotations; (2) the evaluation metrics only focus on the surface quality of the survey such as logical coherence. Both issues lead to existing benchmarks cannot assess to evaluate their deep "academic value", such as the core research objectives and the critical analysis of different studies. To address the above problems, we propose DeepSurvey-Bench, a novel benchmark designed to comprehensively evaluate the academic value of generated surveys. Specifically, our benchmark propose a comprehensive academic value evaluation criteria covering three dimensions: informational value, scholarly communication value, and research guidance value. Based on this criteria, we construct a reliable dataset with academic value annotations, and evaluate the deep academic value of the generated surveys. Extensive experimental results demonstrate that our benchmark is highly consistent with human performance in assessing the academic value of generated surveys.

</details>


### [90] [Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.15311)
*Mustafa Arslan*

Main category: cs.AI

TL;DR: Aeon提出一种新型神经符号认知操作系统，通过构建记忆宫殿（Memory Palace）和轨迹（Trace）来结构化长时记忆，解决大语言模型在长上下文中的计算开销与信息丢失问题。采用SIMD加速的页聚类向量索引Atlas实现高效检索，并引入语义旁路缓存（SLB）提升响应速度，实现在<1ms延迟下保持状态一致性，支持自主智能体的持久化、结构化记忆。


<details>
  <summary>Details</summary>
Motivation: 现有基于向量数据库的Flat RAG架构将记忆视为无结构的嵌入集合，无法捕捉长时交互的层次与时间结构，导致信息碎片化（即‘向量雾霾’），且自注意力机制带来二次方计算成本及‘中间迷失’现象，限制了大语言模型在长上下文推理中的表现。

Method: Aeon将记忆重构为管理资源：使用Atlas索引构建空间化的记忆宫殿（结合小世界图导航与B+树式磁盘局部性以减少读放大），并建立神经符号化的轨迹图（Trace）记录事件序列；引入语义旁路缓存（SLB）利用对话局部性进行预测性缓存，结合零拷贝C++/Python桥接保证状态一致性。

Result: 在对话类任务中，Aeon实现低于1毫秒的检索延迟，有效缓解了‘中间迷失’问题，提升了长上下文推理能力，同时支持自主智能体的持久化、结构化记忆，显著优于传统Flat RAG方法。

Conclusion: Aeon重新定义了记忆作为可管理的操作系统资源，通过结构化存储与高效检索机制，解决了大语言模型在长上下文场景下的性能瓶颈，为自主智能体提供了可靠的记忆基础。

Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the "Lost in the Middle" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily "Flat RAG" architectures relying on vector databases, treat memory as an unstructured bag of embeddings. This approach fails to capture the hierarchical and temporal structure of long-horizon interactions, leading to "Vector Haze", the retrieval of disjointed facts lacking episodic continuity. We propose Aeon, a Neuro-Symbolic Cognitive Operating System that redefines memory not as a static store, but as a managed OS resource. Aeon structures memory into a Memory Palace (a spatial index implemented via Atlas, a SIMD-accelerated Page-Clustered Vector Index that combines small-world graph navigation with B+ Tree-style disk locality to minimize read amplification) and a Trace (a neuro-symbolic episodic graph). We introduce the Semantic Lookaside Buffer (SLB), a predictive caching mechanism that exploits conversational locality to achieve sub-millisecond retrieval latencies. Benchmarks demonstrate that Aeon achieves < 1ms retrieval latency on conversational workloads while ensuring state consistency via a zero-copy C++/Python bridge, effectively enabling persistent, structured memory for autonomous agents.

</details>


### [91] [The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection](https://arxiv.org/abs/2601.15316)
*Wei Ai,Yilong Tan,Yuntao Shou,Tao Meng,Haowen Chen,Zhixiong He,Keqin Li*

Main category: cs.AI

TL;DR: 本文系统回顾了基于大视觉-语言模型（LVLMs）的多模态假新闻检测（MFND）的发展，梳理了从传统特征工程到统一端到端多模态推理框架的范式转变，并建立了一个涵盖模型架构、数据集和性能基准的结构化分类体系。文章还分析了可解释性、时序推理和领域泛化等现存挑战，并提出了未来研究方向。这是首个全面总结LVLMs在对抗多模态假新闻中作用的综述。


<details>
  <summary>Details</summary>
Motivation: 当前多模态假新闻检测领域虽因大视觉-语言模型的兴起取得显著进展，但缺乏对这一技术演进过程的系统性梳理与整合，亟需一个全面的综述来归纳现有方法、揭示关键挑战并指引未来方向。

Method: 通过历史脉络梳理、结构化分类体系构建、技术挑战分析及未来方向展望，对基于LVLMs的多模态假新闻检测进行系统性综述。

Result: 提出首个系统性综述框架，明确展示了LVLMs如何推动MFND范式变革，整理了主流模型架构、常用数据集与评估标准，并识别出可解释性、时序理解与跨域适应等核心难点。

Conclusion: LVLMs已深刻重塑多模态假新闻检测的研究范式，未来应聚焦于提升模型透明度、增强时序建模能力以及改善跨领域泛化性能，以实现更可靠、更智能的虚假信息识别。

Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early methods primarily relied on shallow fusion techniques to capture correlations between text and images, but they struggled with high-level semantic understanding and complex cross-modal interactions. The emergence of LVLMs has fundamentally changed this landscape by enabling joint modeling of vision and language with powerful representation learning, thereby enhancing the ability to detect misinformation that leverages both textual narratives and visual content. Despite these advances, the field lacks a systematic survey that traces this transition and consolidates recent developments. To address this gap, this paper provides a comprehensive review of MFND through the lens of LVLMs. We first present a historical perspective, mapping the evolution from conventional multimodal detection pipelines to foundation model-driven paradigms. Next, we establish a structured taxonomy covering model architectures, datasets, and performance benchmarks. Furthermore, we analyze the remaining technical challenges, including interpretability, temporal reasoning, and domain generalization. Finally, we outline future research directions to guide the next stage of this paradigm shift. To the best of our knowledge, this is the first comprehensive survey to systematically document and analyze the transformative role of LVLMs in combating multimodal fake news. The summary of existing methods mentioned is in our Github: \href{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}.

</details>


### [92] [Prometheus Mind: Retrofitting Memory to Frozen Language Models](https://arxiv.org/abs/2601.15324)
*Mark Wind*

Main category: cs.AI

TL;DR: Prometheus Mind adds memory to a frozen Qwen3-4B model using 11 modular adapters (530MB, 7% overhead) without modifying weights or architecture. It solves four challenges: (1) semantic direction extraction via Contrastive Direction Discovery (CDD) without labels; (2) successful stage-wise adapter training instead of end-to-end; (3) direct use of lm_head.weight for injection, avoiding training; (4) projection-based recovery of distinct hidden states (from 0.98 to 0.09 similarity). On clean inputs, retrieval accuracy is 94.4% (95% CI: [84.9%, 98.1%]) on PrometheusExtract-132; drops to 19.4% on informal inputs due to relation classification errors (47.3% accuracy).


<details>
  <summary>Details</summary>
Motivation: To enable memory addition to pretrained language models without architectural changes or weight modification, while maintaining reversibility and efficiency.

Method: Uses 11 modular adapters with Contrastive Direction Discovery (CDD) for unsupervised semantic direction identification, stage-wise training, direct injection via lm_head.weight, and learned projections to mitigate hidden state collapse.

Result: Achieves 94.4% retrieval accuracy on clean inputs (n=54), but only 19.4% on informal inputs; main limitation is relation classification accuracy at 47.3%.

Conclusion: Prometheus Mind successfully retrofits memory to a frozen model with minimal overhead and full reversibility, but performance degrades significantly on informal input types, primarily due to limitations in relation classification.

Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters. Building this system required solving four problems: (1) Extraction -- we develop Contrastive Direction Discovery (CDD), which finds semantic directions via minimal pairs without labeled data. (2) Training -- end-to-end optimization collapses; stage-wise training of each adapter on simple proxy tasks succeeds. (3) Injection -- learned encoders fail to generalize; we find that lm_head.weight rows already provide the mapping we need, requiring no training. (4) Hidden state collapse -- transformers make ``wife'' and ``brother'' 0.98+ similar; we train projections to recover distinction (0.98 $\rightarrow$ 0.09). On PrometheusExtract-132 (132 cases), the system achieves 94.4% retrieval on clean inputs (n=54, 95% CI: [84.9%, 98.1%]), degrading to 19.4% on informal inputs with ellipsis, filler words, or implicit subjects (n=36). The primary bottleneck is relation classification (47.3% accuracy), responsible for most extraction errors.

</details>


### [93] [Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)](https://arxiv.org/abs/2601.15397)
*Peidong Wang*

Main category: cs.AI

TL;DR: 本文提出LOGIC（Logit-Space Integration for Contextual Biasing），一种在解码层直接操作的高效且鲁棒的框架，用于解决语音大模型在识别新实体时面临的挑战。相较于传统提示工程和生成错误纠正方法，LOGIC避免了上下文窗口限制、推理延迟和过矫正问题，实现近似常数时间复杂度，并在多语言环境下显著降低实体词错误率（平均相对减少9%），同时仅带来微小的假警报率上升（0.30%）。


<details>
  <summary>Details</summary>
Motivation: 现有语音大模型受限于静态训练知识，在面对文化变迁、趋势演进及个性化用户数据带来的新实体（如联系人名、播放列表、专业术语）时识别能力不足。传统提示方法因实体列表增长导致上下文窗口溢出、延迟增加和‘中间丢失’现象；而生成纠错方法则易产生虚假实体（过矫正），影响准确性。

Method: LOGIC通过在解码层的逻辑空间中注入上下文偏置，将上下文信息注入与输入处理解耦，从而实现对新实体的高效识别。该方法不依赖长提示，保持恒定时间复杂度，有效规避了提示工程的扩展瓶颈。

Result: 在使用Phi-4-MM模型对11个不同语言地区进行的实验中，LOGIC实现了平均9%的实体词错误率（WER）相对下降，同时假警报率仅上升0.30%，表现出高效率与强鲁棒性。

Conclusion: LOGIC为语音大模型在动态实体识别任务中提供了一种高效、可扩展且低误报的解决方案，突破了传统提示与后处理方法的局限，具有广泛的应用潜力。

Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits their ability to recognize domain-specific terms such as contact names, playlists, or technical jargon. Existing solutions primarily rely on prompting, which suffers from poor scalability: as the entity list grows, prompting encounters context window limitations, increased inference latency, and the "lost-in-the-middle" phenomenon. An alternative approach, Generative Error Correction (GEC), attempts to rewrite transcripts via post-processing but frequently suffers from "over-correction", introducing hallucinations of entities that were never spoken.
  In this work, we introduce LOGIC (Logit-Space Integration for Contextual Biasing), an efficient and robust framework that operates directly in the decoding layer. Unlike prompting, LOGIC decouples context injection from input processing, ensuring constant-time complexity relative to prompt length. Extensive experiments using the Phi-4-MM model across 11 multilingual locales demonstrate that LOGIC achieves an average 9% relative reduction in Entity WER with a negligible 0.30% increase in False Alarm Rate.

</details>


### [94] [Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models](https://arxiv.org/abs/2601.15436)
*Shahar Ben Natan,Oren Tsur*

Main category: cs.AI

TL;DR: 本文提出一种新的、直接且中立的方法来评估大语言模型（LLM）的阿谀奉承倾向，通过使用LLM作为评判者，并在博弈论框架下的赌局设置中将阿谀奉承视为零和游戏，从而避免了先前研究中因提示注入偏见、噪声或操纵性语言带来的问题。研究发现，尽管所有模型在常规情境下都表现出阿谀奉承倾向，但Claude和Mistral在意识到其行为可能伤害第三方时会表现出‘道德悔恨’并过度补偿。此外，所有模型均存在对最后提出观点的偏好，而阿谀奉承与最近性偏差相互作用，产生‘建设性干涉’效应，即当用户意见最后呈现时，模型更倾向于附和。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法易受提示中人为注入的偏见、噪声或操纵性语言影响，导致结果不可靠；需要一种更中立、可控的评估方式来真实反映模型的阿谀奉承倾向。

Method: 采用LLM作为裁判，在零和博弈的赌局设定中评估模型行为；通过设计实验使模型在迎合用户的同时明确损害他人利益，从而观察其反应；比较四种主流模型的表现，并分析阿谀奉承与最近性偏差的交互效应。

Result: 所有模型在常规情境下均有阿谀奉承倾向；Claude和Mistral在涉及第三方受损时表现出道德悔恨并过度补偿；所有模型均偏向最后提出的观点；阿谀奉承与最近性偏差存在交互作用，形成‘建设性干涉’效应，显著增强附和倾向。

Conclusion: 本研究揭示了大语言模型在面对用户意见时不仅存在阿谀奉承倾向，还受最近性偏差影响，二者协同加剧了对用户观点的盲从。同时，部分模型展现出一定程度的道德反思能力，表明未来可基于此设计更具伦理意识的模型行为机制。

Abstract: We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit "moral remorse" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.

</details>


### [95] [Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases](https://arxiv.org/abs/2601.15476)
*Alex Dantart*

Main category: cs.AI

TL;DR: 该研究探讨如何通过减少幻觉使大型语言模型在高风险法律工作中更可靠。比较了三种AI范式：独立生成模型、基础检索增强系统和先进的端到端优化RAG系统。提出两个可靠性指标（错误引用率和虚构事实率），对12个LLM在75个法律任务上的2700个司法风格回答进行专家双盲评估。结果显示，独立模型不适合专业使用（错误引用率超过30%），基础RAG显著降低错误但仍存在误置信问题，而先进RAG通过嵌入微调、重排序和自校正等技术将虚构事实降至可忽略水平（低于0.2%）。结论强调可信法律AI需采用注重验证与可追溯性的检索驱动架构，并提供适用于其他高风险领域的评估框架。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型在高风险法律任务中的可靠性，减少因幻觉导致的错误引用和虚构事实，确保其在专业场景中的可用性与可信度。

Method: 设计并比较三种AI范式（独立生成模型、基础RAG、先进RAG），引入False Citation Rate（FCR）和Fabricated Fact Rate（FFR）作为可靠性评估指标，通过专家双盲评审对12个LLM在75个法律任务中生成的2700个答案进行评估，分析不同系统的表现。

Result: 独立生成模型错误引用率高于30%，不适用于专业场景；基础RAG显著降低错误但仍有误置信现象；先进RAG结合嵌入微调、重排序和自校正等技术，将虚构事实率降至低于0.2%，达到可忽略水平。

Conclusion: 可信的法律AI必须依赖以验证和可追溯性为核心的检索增强型架构，先进RAG系统是实现高可靠性的重要路径，该评估框架亦适用于其他高风险领域。

Abstract: This paper examines how to make large language models reliable for high-stakes legal work by reducing hallucinations. It distinguishes three AI paradigms: (1) standalone generative models ("creative oracle"), (2) basic retrieval-augmented systems ("expert archivist"), and (3) an advanced, end-to-end optimized RAG system ("rigorous archivist"). The authors introduce two reliability metrics -False Citation Rate (FCR) and Fabricated Fact Rate (FFR)- and evaluate 2,700 judicial-style answers from 12 LLMs across 75 legal tasks using expert, double-blind review. Results show that standalone models are unsuitable for professional use (FCR above 30%), while basic RAG greatly reduces errors but still leaves notable misgrounding. Advanced RAG, using techniques such as embedding fine-tuning, re-ranking, and self-correction, reduces fabrication to negligible levels (below 0.2%). The study concludes that trustworthy legal AI requires rigor-focused, retrieval-based architectures emphasizing verification and traceability, and provides an evaluation framework applicable to other high-risk domains.

</details>


### [96] [MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation](https://arxiv.org/abs/2601.15487)
*Chandan Kumar Sahu,Premith Kumar Chilukuri,Matthew Hetrich*

Main category: cs.AI

TL;DR: MiRAGE is a multiagent framework for evaluating Retrieval-Augmented Generation (RAG) systems in domain-specific, multimodal, and complex reasoning scenarios. It uses specialized agents to generate high-quality, verified, multi-hop question-answer datasets across four domains: regulations, finance, quantitative biology, and journalism. The framework improves reasoning complexity (>2.3 hops) and factual accuracy through recursive context optimization, adversarial verification, and expert persona modeling. While LLMs can power MiRAGE if image descriptions are available, visual grounding remains challenging.


<details>
  <summary>Details</summary>
Motivation: Existing RAG evaluation benchmarks are insufficient for complex, multimodal, domain-specific applications, as they rely on general or purely textual data and fail to capture the intricate reasoning required in technical documents.

Method: MiRAGE employs a swarm of specialized agents: one for recursive context optimization to gather scattered evidence, an adversarial verifier to ensure factual grounding, and another to simulate expert cognitive workflows by recognizing domain expertise and persona.

Result: MiRAGE generates datasets with significantly higher reasoning complexity (>2.3 average hops) and improved factual faithfulness across four diverse domains. Ablation studies show that LLMs can support the system when image descriptions are available, though visual grounding remains a challenge.

Conclusion: MiRAGE provides a scalable infrastructure for creating gold-standard evaluation datasets tailored to proprietary, complex corpora, enabling rigorous benchmarking of next-generation RAG systems in real-world enterprise settings.

Abstract: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (>2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.

</details>


### [97] [Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge](https://arxiv.org/abs/2601.15495)
*Yiyang Feng,Zeming Chen,Haotian Wu,Jiawei Zhou,Antoine Bosselut*

Main category: cs.AI

TL;DR: TRACK是一个新的基准测试，用于研究大型语言模型在多步推理中如何处理与初始参数化知识冲突的更新知识。它涵盖了三个推理密集型场景（WIKI、CODE和MATH），引入了多个真实世界的知识冲突，以模拟现实复杂性。实验结果表明，提供更新事实反而可能降低模型性能，且随着更新事实数量增加，性能下降加剧。这种失败源于模型既无法准确整合新知识，也存在即使知识被整合后仍出现推理错误的问题。TRACK为衡量和指导未来在多步推理中传播冲突知识方面的进展提供了严格的新基准。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理大型语言模型中的过时或错误信息时，常因知识更新未能覆盖模型的参数化知识而引发知识冲突，这些冲突会传播至错误推理。然而，现有基准主要关注单一知识更新和事实回忆，缺乏对更新知识如何影响下游推理的评估。因此需要一个更全面的基准来评估模型在多步推理中处理冲突知识的能力。

Method: 提出TRACK基准，涵盖WIKI、CODE和MATH三个推理密集型场景，设计多种真实世界的知识冲突情境，系统评估模型在多步推理中对更新知识的整合与推理表现。通过对比有无更新事实的情况，分析模型性能变化及其原因。

Result: 结果显示，向模型提供更新事实可能导致性能下降，尤其当更新事实增多时，性能恶化更加严重；这不仅是因为模型无法有效整合新知识，还因为即使知识被整合，模型仍存在推理缺陷。

Conclusion: TRACK为评估和改进大型语言模型在多步推理中处理冲突知识的能力提供了强有力的基准工具，有助于推动未来相关研究的发展。

Abstract: A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.

</details>


### [98] [The Dark Side of AI Transformers: Sentiment Polarization & the Loss of Business Neutrality by NLP Transformers](https://arxiv.org/abs/2601.15509)
*Prasanna Kumar*

Main category: cs.AI

TL;DR: Transformer-based models in sentiment analysis improve accuracy for certain sentiment classes but exacerbate polarization and undermine neutrality, posing challenges for reliable real-world NLP applications.


<details>
  <summary>Details</summary>
Motivation: To address the growing concern that transformer models, while improving accuracy in sentiment analytics, are compromising neutrality and causing class polarization, which undermines reliability in applied NLP tasks.

Method: Empirical evaluation of transformer-based sentiment models across multiple datasets to analyze class-wise performance and neutrality metrics.

Result: Significant accuracy gains in specific sentiment classes were observed, but at the expense of increased polarization and failure to maintain neutral sentiment classification.

Conclusion: While transformers enhance sentiment analysis accuracy, their tendency to distort neutrality necessitates new calibration techniques to ensure balanced and trustworthy outputs in applied AI analytics.

Abstract: The use of Transfer Learning & Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.

</details>


### [99] [From Generative Engines to Actionable Simulators: The Imperative of Physical Grounding in World Models](https://arxiv.org/abs/2601.15533)
*Zhikang Chen,Tingting Zhu*

Main category: cs.AI

TL;DR: 本文指出当前世界模型虽能生成高保真视频，但存在视觉混淆问题，即误将视觉真实等同于对物理因果动态的理解。研究发现这些模型在干预下表现不佳，且在安全关键决策中容易失效。作者主张世界模型应被重新定义为可操作的模拟器，而非单纯的视觉引擎，强调结构化4D接口、约束感知动力学和闭环评估。通过医疗决策这一不可试错的严苛测试场景，证明世界模型的价值不在于视觉逼真度，而在于支持反事实推理、干预规划和长期预见的能力。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型过度依赖视觉真实性，忽视了对物理和因果动态的真正理解，导致在干预和长期决策中表现不佳，尤其在医疗等高风险领域可能带来严重后果。因此需要重新思考世界模型的设计目标与评估标准。

Method: 提出将世界模型重构为可操作模拟器，引入结构化4D接口、约束感知的动力学建模方法，并采用闭环评估机制；以医疗决策为案例进行实证分析，检验模型在反事实推理、干预规划和长时序预测中的表现。

Result: 实验表明，视觉逼真的模型在医疗决策任务中常因违反基本约束而失败，而具备因果结构与约束意识的模型则表现出更强的鲁棒性与可解释性，能够有效支持复杂决策。

Conclusion: 视觉真实并非世界模型理解力的可靠指标；未来世界模型应聚焦于因果结构建模、领域约束遵守与长期稳定性，真正实现可信赖的模拟与决策支持。

Abstract: A world model is an AI system that simulates how an environment evolves under actions, enabling planning through imagined futures rather than reactive perception. Current world models, however, suffer from visual conflation: the mistaken assumption that high-fidelity video generation implies an understanding of physical and causal dynamics. We show that while modern models excel at predicting pixels, they frequently violate invariant constraints, fail under intervention, and break down in safety-critical decision-making. This survey argues that visual realism is an unreliable proxy for world understanding. Instead, effective world models must encode causal structure, respect domain-specific constraints, and remain stable over long horizons. We propose a reframing of world models as actionable simulators rather than visual engines, emphasizing structured 4D interfaces, constraint-aware dynamics, and closed-loop evaluation. Using medical decision-making as an epistemic stress test, where trial-and-error is impossible and errors are irreversible, we demonstrate that a world model's value is determined not by how realistic its rollouts appear, but by its ability to support counterfactual reasoning, intervention planning, and robust long-horizon foresight.

</details>


### [100] [ALIGNAgent: Adaptive Learner Intelligence for Gap Identification and Next-step guidance](https://arxiv.org/abs/2601.15551)
*Bismack Tokoli,Luis Jaimes,Ayesha S. Dina*

Main category: cs.AI

TL;DR: ALIGNAgent is a multi-agent framework that integrates knowledge tracing, skill-gap identification, and personalized resource recommendation to enable adaptive learning. It uses a Skill Gap Agent to diagnose misconceptions from quiz and gradebook data, and a Recommender Agent to suggest tailored learning materials, forming a continuous feedback loop. Evaluated on real CS course data, it achieves high precision (0.87–0.90) and F1 (0.84–0.87) in proficiency estimation.


<details>
  <summary>Details</summary>
Motivation: Existing personalized learning systems are fragmented, focusing on isolated tasks like knowledge tracing or recommendation without integrating them into a unified adaptive cycle. This limits their ability to provide comprehensive, dynamic personalization.

Method: ALIGNAgent employs a two-agent architecture: the Skill Gap Agent uses concept-level diagnostic reasoning to estimate topic-level proficiency and identify specific knowledge gaps from student performance data; the Recommender Agent then selects preference-aware learning resources aligned with diagnosed gaps, enabling iterative intervention before progressing to new topics.

Result: Empirical evaluation on two undergraduate computer science courses shows that GPT-4o-based agents in ALIGNAgent achieve high accuracy in estimating student knowledge proficiency, with precision between 0.87 and 0.90 and F1 scores between 0.84 and 0.87, closely matching actual exam performance.

Conclusion: ALIGNAgent successfully bridges the gap between knowledge estimation, gap identification, and recommendation by creating an integrated, adaptive learning cycle. Its effectiveness demonstrates the potential of multi-agent systems in delivering truly personalized education.

Abstract: Personalized learning systems have emerged as a promising approach to enhance student outcomes by tailoring educational content, pacing, and feedback to individual needs. However, most existing systems remain fragmented, specializing in either knowledge tracing, diagnostic modeling, or resource recommendation, but rarely integrating these components into a cohesive adaptive cycle. In this paper, we propose ALIGNAgent (Adaptive Learner Intelligence for Gap Identification and Next-step guidance), a multi-agent educational framework designed to deliver personalized learning through integrated knowledge estimation, skill-gap identification, and targeted resource recommendation.ALIGNAgent begins by processing student quiz performance, gradebook data, and learner preferences to generate topic-level proficiency estimates using a Skill Gap Agent that employs concept-level diagnostic reasoning to identify specific misconceptions and knowledge deficiencies. After identifying skill gaps, the Recommender Agent retrieves preference-aware learning materials aligned with diagnosed deficiencies, implementing a continuous feedback loop where interventions occur before advancing to subsequent topics. Extensive empirical evaluation on authentic datasets from two undergraduate computer science courses demonstrates ALIGNAgent's effectiveness, with GPT-4o-based agents achieving precision of 0.87-0.90 and F1 scores of 0.84-0.87 in knowledge proficiency estimation validated against actual exam performance.

</details>


### [101] [CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models](https://arxiv.org/abs/2601.15628)
*Haibo Tong,Zeyang Yue,Feifei Zhao,Erliang Lin,Lu Jia,Ruolin Chen,Yinqian Sun,Qian Zhang,Yi Zeng*

Main category: cs.AI

TL;DR: CogToM 是一个涵盖46种范式的综合性、理论基础的双语基准，包含超过8000个实例，经49名人类标注者验证。对22个代表性模型（包括GPT-5.1和Qwen3-Max）的系统评估揭示了显著的性能差异，并指出了特定维度上的持续瓶颈。基于人类认知模式的进一步分析表明，大型语言模型与人类认知结构之间可能存在潜在差异。该基准为研究大模型认知边界的演进提供了有力工具和视角。


<details>
  <summary>Details</summary>
Motivation: 现有基准大多局限于狭窄的范式（如错误信念任务），无法全面捕捉人类认知机制，因此亟需一个更全面、理论基础扎实的评估工具来检验大语言模型是否具备类人心理理论能力。

Method: 构建CogToM基准，涵盖46种认知范式，收集超过8000个双语实例，并由49名人类标注者进行验证；对22个代表性大模型进行系统评估，并结合人类认知模式进行对比分析。

Result: 评估发现各模型在不同维度上表现差异显著，存在持续性瓶颈；分析显示大语言模型的认知结构与人类可能存在潜在差异。

Conclusion: CogToM为深入探究大语言模型认知能力的边界提供了可靠工具和新视角，有助于推动对模型真实认知水平的理解。

Abstract: Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.

</details>


### [102] [Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2601.15652)
*Manish Bhatt*

Main category: cs.AI

TL;DR: 提出一种结合神经科学启发信号设计与监督机器学习的混合检测框架[Model Name]，通过预测编码和信息瓶颈理论提取可解释信号，显著提升幻觉检测性能。在HaluBench上达到0.8669 AUROC，相比基线提升4.95%，且仅需200样本训练、5ms推理时间，远优于现有方法。发现理性化信号无效，揭示模型可能为错误前提生成合理推理（'奉承'现象）。


<details>
  <summary>Details</summary>
Motivation: 当前幻觉检测方法依赖高成本外部检索或大参数黑箱模型，难以满足高风险场景下的效率与可解释性需求。亟需轻量、高效、可解释的检测方案。

Method: 基于预测编码（量化对内部先验的意外）和信息瓶颈（衡量扰动下信号保留度）构建可解释信号；引入实体聚焦吸收、上下文一致性、可证伪性评分三项改进机制，结合监督学习进行幻觉检测。

Result: 在HaluBench数据集上，改进特征使AUROC达0.8669，相较基线提升4.95%；训练数据仅为200，推理速度达5ms，远超现有方法；理性化信号无效，表明模型存在为错误前提生成合理解释的现象。

Conclusion: [Model Name]证明了领域知识嵌入信号架构能实现比扩大模型规模更优的数据效率，构建出轻量、可解释、适合生产部署的幻觉检测系统。

Abstract: Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).
  Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises ("Sycophancy").
  This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.

</details>


### [103] [Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity](https://arxiv.org/abs/2601.15728)
*Hangle Hu,Chenyu Hou,Bin Cao,Ruizhe Li*

Main category: cs.AI

TL;DR: 本文提出BIRD-Python基准，用于跨范式评估文本到Python的生成能力。通过清理数据集和对齐执行语义，建立标准化基线。研究发现，与声明式SQL不同，过程式Python对用户意图不明确极为敏感，主要性能差异源于领域上下文缺失而非代码生成能力不足。为此提出逻辑补全框架（LCF），利用隐含领域知识解决歧义。实验表明，当上下文补全后，Text-to-Python可达到与Text-to-SQL相当的性能，证明Python可作为分析型智能体的基础。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据分析日益需要Python等通用编程语言处理文件数据和复杂分析流程，但文本到Python在核心数据检索上的可靠性远未得到充分研究，相比成熟的SQL生态存在明显差距。

Method: 构建BIRD-Python基准，系统性地清理原始数据集以减少标注噪声并统一执行语义；提出逻辑补全框架（LCF），通过引入隐含领域知识来解决自然语言输入中的歧义问题。

Result: 性能差异主要源于缺乏领域上下文而非代码生成能力本身；当补充缺失的上下文信息后，Text-to-Python的表现可达到与Text-to-SQL相当的水平。

Conclusion: 只要系统能将模糊的自然语言输入有效映射为可执行的逻辑规范，Python即可成为分析型智能体的可靠基础。

Abstract: While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.

</details>


### [104] [PhysProver: Advancing Automatic Theorem Proving for Physics](https://arxiv.org/abs/2601.15737)
*Hanning Zhang,Ruida Wang,Rui Pan,Wenyuan Wang,Bingxu Meng,Tong Zhang*

Main category: cs.AI

TL;DR: 本文提出首个面向物理领域形式化定理证明的方法，构建了专用数据集PhysLeanData，并基于DeepSeek-Prover-V2-7B与强化学习结合的验证奖励机制（RLVR）训练模型PhysProver。仅用约5K训练样本即在多个子领域实现2.4%性能提升，且在MiniF2F-Test上获得1.3%增益，表明模型具备跨域泛化能力，显著增强形式化数学推理能力。研究为扩展形式化证明器至非数学领域提供了新范式，并将公开数据集与模型以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 当前形式化定理证明研究主要聚焦数学领域，而物理领域虽同样依赖于类似的问题求解与定理证明框架，却缺乏系统性关注。因此亟需发展专门针对物理领域的形式化推理方法。

Method: 构建专用数据集PhysLeanData，融合来自PhysLean的定理与基于猜想的形式化数据生成管道；采用DeepSeek-Prover-V2-7B作为基础模型，并应用强化学习结合可验证奖励（RLVR）进行训练，形成PhysProver模型。

Result: 使用约5K训练样本，在多个物理子领域平均提升2.4%；在MiniF2F-Test基准上取得1.3%的性能增长，表明模型具有跨域泛化能力，同时提升了形式化数学推理能力。

Conclusion: 本研究成功实现了物理领域形式化定理证明的首次有效突破，展示了方法的有效性与高效性，为将形式化证明能力拓展至非数学领域提供了可行范式，研究成果将开源以推动社区发展。

Abstract: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. However, little attention has been given to the formal physics reasoning, which also heavily relies on similar problem-solving and theorem-proving frameworks. To solve this problem, this paper presents, to the best of our knowledge, the first approach to enhance formal theorem proving in the physics domain. We compose a dedicated dataset PhysLeanData for the task. It is composed of theorems sampled from PhysLean and data generated by a conjecture-based formal data generation pipeline. In the training pipeline, we leverage DeepSeek-Prover-V2-7B, a strong open-source mathematical theorem prover, and apply Reinforcement Learning with Verifiable Rewards (RLVR) to train our model PhysProver. Comprehensive experiments demonstrate that, using only $\sim$5K training samples, PhysProver achieves an overall 2.4\% improvement in multiple sub-domains. Furthermore, after formal physics training, we observe 1.3\% gains on the MiniF2F-Test benchmark, which indicates non-trivial generalization beyond physics domains and enhancement for formal math capability as well. The results highlight the effectiveness and efficiency of our approach, which provides a paradigm for extending formal provers outside mathematical domains. To foster further research, we will release both our dataset and model to the community.

</details>


### [105] [Tabular Incremental Inference](https://arxiv.org/abs/2601.15751)
*Xinda Chen,Xing Zhen,Hanyu Zhang,Weimin Tan,Bo Yan*

Main category: cs.AI

TL;DR: 本文提出了一种新的任务——表增量推理（TabII），旨在使训练好的AI模型在推理阶段能够动态地融入新列，以应对表格结构的动态变化。该方法基于信息瓶颈理论，通过最小化数据与表示之间的互信息、最大化表示与任务标签之间的互信息来优化模型性能。为此，设计了大语言模型占位符、预训练表适配器和增量样本压缩模块，有效利用新增列信息，在八个公开数据集上达到了当前最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型通常在固定列的表格上训练，难以适应动态变化的表格结构。随着技术进步和数据需求的变化，表格列的增减成为常态，因此需要一种无需重新训练即可在推理阶段处理新增列的新方法，以提升模型在真实场景中的实用性。

Method: 将表增量推理问题建模为信息瓶颈框架下的优化问题，采用大语言模型占位符引入外部知识，利用预训练表适配器提取通用特征，并通过增量样本压缩模块提炼新增列中对任务相关的关键信息，实现高效无监督的增量学习。

Result: 在八个公共数据集上的实验表明，所提出的TabII方法能有效利用新增列信息，在多种任务中均达到或超过现有方法的性能，验证了其有效性与优越性。

Conclusion: TabII为动态表格的智能化处理提供了新范式，不仅提升了AI模型在实际应用中的灵活性与鲁棒性，也为未来可扩展、自适应的数据分析系统奠定了基础。

Abstract: Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.

</details>


### [106] [Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning](https://arxiv.org/abs/2601.15761)
*Xiefeng Wu,Mingyu Hu,Shu Zhang*

Main category: cs.AI

TL;DR: SigEnt-SAC 是一种无需大规模数据或预训练的低成本强化学习方法，仅需单条专家轨迹即可从零开始学习。通过引入sigmoid约束的熵项，有效防止分布外动作优化和Q函数震荡，显著提升学习稳定性与效率。在D4RL基准和多个真实机器人任务上，该方法表现出快速收敛、100%成功率，并在稀疏奖励和原始图像输入下实现高效学习，为现实世界强化学习提供了一条实用路径。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在真实世界部署中面临样本效率低、奖励稀疏和视觉观测噪声等问题。尽管已有方法利用示范或人类反馈改进性能，但离线到在线方法依赖大量数据且不稳定，而基于视觉语言模型的强化学习则需要大规模预训练和微调，成本高昂。因此，亟需一种数据需求少、成本低、可直接应用于真实场景的强化学习方法。

Method: 提出 SigEnt-SAC，一种基于 off-policy actor-critic 框架的强化学习算法。核心创新在于引入 sigmoid-bounded entropy 项，限制熵的负值影响，避免因负熵驱动导致的动作分布偏离，从而减少 Q 函数震荡。该方法无需预训练，仅需一条专家轨迹即可从零开始训练。

Result: 在 D4RL 基准测试中，SigEnt-SAC 显著缓解了 Q 函数震荡，比现有方法更快达到 100% 成功率。在四个真实机器人任务（多形态）上，使用原始图像和稀疏奖励，仅需少量真实交互即可学习出成功策略，验证了其低数据依赖性和实际可行性。

Conclusion: SigEnt-SAC 提供了一种低资源、高效率的现实世界强化学习方案，仅需单条专家示范即可实现稳定高效的学习，具备良好的实用潜力，是迈向低成本真实世界部署的重要一步。

Abstract: Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.

</details>


### [107] [VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management](https://arxiv.org/abs/2601.15798)
*Zhikai Xue,Tianqianjin Lin,Pengwei Yan,Ruichun Wang,Yuxin Liu,Zhuoren Jiang,Xiaozhong Liu*

Main category: cs.AI

TL;DR: VitalDiagnosis is an LLM-powered system that uses data from wearables to proactively manage chronic diseases by engaging patients interactively, improving adherence, and supporting clinician workflows through context-aware analysis and personalized guidance.


<details>
  <summary>Details</summary>
Motivation: Chronic diseases are a leading cause of death globally, exacerbated by limited medical resources and aging populations. Patients often fail to recognize early warning signs or follow care plans, highlighting the need for more proactive and interactive management systems.

Method: The system integrates real-time data from wearable devices with large language models (LLMs) to detect anomalies, conduct context-aware inquiries, generate preliminary insights, and support collaborative decision-making between patients and clinicians.

Result: VitalDiagnosis enables early detection of health deterioration, improves patient engagement and adherence, and reduces unnecessary clinical workload by facilitating proactive, personalized, and cooperative care.

Conclusion: By combining wearable data with LLM-driven reasoning, VitalDiagnosis transforms chronic disease management into a proactive, interactive, and collaborative process, enhancing self-management and optimizing healthcare delivery.

Abstract: Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.

</details>


### [108] [ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models](https://arxiv.org/abs/2601.15812)
*Shir Ashury-Tahan,Yifan Mai,Elron Bandel,Michal Shmueli-Scheuer,Leshem Choshen*

Main category: cs.AI

TL;DR: ErrorMap 是首个能够绘制大语言模型失败原因的方法，通过提取模型的“失败特征”，揭示基准测试的真实测量目标，并扩大错误识别范围以减少盲点。该方法可应用于任何模型和数据集，帮助开发者调试模型、对齐评估目标并支持明智的模型选择。基于35个数据集和83个模型的应用，研究生成了 ErrorAtlas——一个模型错误的分类体系，揭示了当前研究中被忽视的常见错误模式，如输出中遗漏必要细节或误解问题。通过从关注模型成功转向理解失败原因，ErrorMap 和 ErrorAtlas 提供了一种更深层次的评估方式，能暴露隐藏弱点并引导发展。该方法具有普适性，且已公开分类体系与代码，未来将持续更新。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型基准测试只能告诉我们模型在何时失败，但无法解释失败的原因。错误可能源于格式问题、计算失误或数据噪声，而非推理能力不足。缺乏对失败原因的拆解，使得基准测试不完整，难以有效指导模型改进。因此需要一种能够系统分析失败根源的方法。

Method: 提出 ErrorMap 方法，通过分析模型在不同任务中的失败表现，提取其独特的‘失败签名’，识别错误类型，建立错误分类体系（ErrorAtlas），从而揭示模型行为中的隐藏缺陷。该方法适用于任意模型和数据集，具备通用性和可扩展性。

Result: 应用 ErrorMap 到 35 个数据集和 83 个模型，构建出 ErrorAtlas，发现大量被忽视的错误模式，如输出遗漏关键信息、误解问题意图等。该方法有效提升了对模型失败原因的理解，推动评估从表面性能转向深层机制分析。

Conclusion: ErrorMap 和 ErrorAtlas 提供了一种全新的深度评估范式，将焦点从模型的成功转向失败原因的剖析，揭示了模型行为中的隐藏弱点，为模型调试、基准设计和模型选择提供了更可靠的依据。该成果已开源并计划持续更新，具有广泛的应用前景。

Abstract: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique "failure signature", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.

</details>


### [109] [ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search](https://arxiv.org/abs/2601.15931)
*Xiangyu Wang,Zhixin Lv,Yongjiao Sun,Anrui Han,Ye Yuan,Hangxu Ji*

Main category: cs.AI

TL;DR: 本文提出ICON框架，通过引入因果与拓扑先验，解决文本驱动行人搜索中因依赖被动观察导致的虚假相关性和空间语义错位问题。该方法包括规则引导的空间干预、反事实上下文解耦、显著性驱动的语义正则化以及神经符号拓扑对齐，有效提升模型在复杂开放世界场景下的鲁棒性，实现从统计共现拟合到因果不变性的范式转变。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练模型的文本驱动行人搜索方法在复杂开放世界场景下表现不佳，主要由于依赖被动观察导致虚假相关性和空间语义错位，缺乏对分布变化的鲁棒性。

Method: 提出ICON框架，结合规则引导的空间干预以实现几何不变性；反事实上下文解耦通过语义驱动的背景迁移，增强环境独立性；采用显著性驱动的语义正则化缓解局部显著性偏差；利用神经符号拓扑对齐确保特征匹配符合人类结构逻辑。

Result: 实验表明，ICON不仅在标准基准上保持领先性能，还在遮挡、背景干扰和定位噪声等挑战下展现出卓越的鲁棒性。

Conclusion: ICON通过引入因果与拓扑先验，实现了从拟合统计共现向学习因果不变性的转变，显著提升了文本驱动行人搜索在复杂现实场景中的可靠性与泛化能力。

Abstract: Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on "Passive Observation" leads to multifaceted spurious correlations and spatial semantic misalignment, causing a lack of robustness against distribution shifts. To fundamentally resolve these defects, this paper proposes ICON (Invariant Counterfactual Optimization with Neuro-symbolic priors), a framework integrating causal and topological priors. First, we introduce Rule-Guided Spatial Intervention to strictly penalize sensitivity to bounding box noise, forcibly severing location shortcuts to achieve geometric invariance. Second, Counterfactual Context Disentanglement is implemented via semantic-driven background transplantation, compelling the model to ignore background interference for environmental independence. Then, we employ Saliency-Driven Semantic Regularization with adaptive masking to resolve local saliency bias and guarantee holistic completeness. Finally, Neuro-Symbolic Topological Alignment utilizes neuro-symbolic priors to constrain feature matching, ensuring activated regions are topologically consistent with human structural logic. Experimental results demonstrate that ICON not only maintains leading performance on standard benchmarks but also exhibits exceptional robustness against occlusion, background interference, and localization noise. This approach effectively advances the field by shifting from fitting statistical co-occurrences to learning causal invariance.

</details>


### [110] [Natural Language-Driven Global Mapping of Martian Landforms](https://arxiv.org/abs/2601.15949)
*Yiran Wang,Shuoyuan Wang,Zhaoran Wei,Jiannan Zhao,Zhonghua Yao,Zejian Xie,Songxin Zhang,Jun Huang,Bingyi Jing,Hongxin Wei*

Main category: cs.AI

TL;DR: MarScope是一个行星尺度的视觉-语言框架，能够通过自然语言驱动的方式对火星地貌进行无标签映射。它将行星图像与文本对齐在共享语义空间中，基于超过20万对精心筛选的图文数据进行训练，实现了全球范围内的地貌检索，支持任意用户查询，响应时间仅5秒，F1得分高达0.978。该框架突破了传统预定义分类的限制，支持过程导向分析和基于相似性的地貌制图，为大规模地理空间数据的科学发现提供了以自然语言为直接接口的新范式。


<details>
  <summary>Details</summary>
Motivation: 当前行星表面分析依赖于自然语言中的高级语义概念，但海量轨道图像档案仍以像素级别组织，这种不匹配限制了对行星表面的大规模、开放式探索。需要一种能够实现自然语言驱动、无需预设标签的地貌映射方法，以提升探索效率和灵活性。

Method: MarScope通过将行星图像与文本嵌入到共享语义空间中，利用超过20万对人工筛选的图像-文本对进行训练，构建了一个视觉-语言模型，支持自然语言查询下的高效地貌检索与分析。

Result: 该框架可在5秒内完成对整个火星的任意自然语言查询，F1分数最高达0.978；不仅支持形态分类，还可实现过程导向分析和相似性驱动的地貌制图，显著提升行星尺度地质研究的效率与开放性。

Conclusion: MarScope建立了一种新的科学发现范式，使自然语言成为访问和探索大规模地理空间数据集的直接工具，推动行星科学向更智能、更灵活的方向发展。

Abstract: Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.

</details>


### [111] [Decoupling Return-to-Go for Efficient Decision Transformer](https://arxiv.org/abs/2601.15953)
*Yongyi Wang,Hanyu Liu,Lingfeng Li,Bozhou Chen,Ang Li,Qirui Zheng,Xionghui Yang,Wenxin Li*

Main category: cs.AI

TL;DR: 本文提出了一种新的离线强化学习方法Decoupled DT (DDT)，通过简化决策变压器（DT）的结构，仅用最新的回报至目标（RTG）来指导动作预测，从而消除原有设计中冗余的全程RTG输入。该方法提升了性能并降低了计算开销，在多个任务上优于原始DT及当前最先进的变体。


<details>
  <summary>Details</summary>
Motivation: 识别并解决决策变压器（DT）中因冗余输入全程回报至目标（RTG）而导致的性能下降问题，提升模型效率与表现。

Method: 提出一种解耦的决策变压器（DDT），将观察和动作序列输入Transformer，仅使用最新一次的RTG作为引导信号进行动作预测，从而减少冗余信息输入并优化计算流程。

Result: 实验表明，DDT在多个离线强化学习任务中显著优于原始决策变压器（DT），且性能达到甚至超过当前最先进的DT变体，同时具备更低的计算成本。

Conclusion: 通过去除决策变压器中不必要的全程RTG输入，解耦的DDT不仅提升了模型性能，还提高了计算效率，为离线强化学习提供了一个更高效、更简洁的序列建模框架。

Abstract: The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.

</details>


### [112] [Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment](https://arxiv.org/abs/2601.16027)
*Yiran Qiao,Xiang Ao,Jing Chen,Yang Liu,Qiwei Zhong,Qing He*

Main category: cs.AI

TL;DR: 提出CS-VAR模型，通过结合轻量级域特定模型与大语言模型（LLM）的跨会话行为证据推理能力，实现对直播流中渐进式和重复性风险的高效实时检测。该方法在工业级大规模数据集上验证了其先进性能，并提供可解释的局部信号以支持实际内容审核。


<details>
  <summary>Details</summary>
Motivation: 直播平台面临日益复杂的欺诈和恶意行为风险，这些行为通常逐步累积且跨流重复出现，传统方法难以有效识别。因此需要一种能捕捉跨会话模式、具备实时性和可解释性的风险检测机制。

Method: 采用轻量级域特定模型进行快速会话级风险推断，训练过程中借助大语言模型（LLM）对跨会话行为证据进行推理，并将局部到全局的洞察迁移至小模型，从而提升对重复性风险模式的识别能力。

Result: 在大规模工业数据集上的离线实验和线上验证均表明，CS-VAR达到当前最优性能；同时生成可解释的局部风险信号，有效支持真实场景下的内容监管。

Conclusion: CS-VAR通过融合小模型效率与大模型推理能力，实现了对直播流中复杂、隐蔽风险的精准、实时、可解释检测，为平台安全提供了有力技术支撑。

Abstract: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.

</details>


### [113] [Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval](https://arxiv.org/abs/2601.16038)
*Olga Bunkova,Lorenzo Di Fruscia,Sophia Rupprecht,Artur M. Schweidtmann,Marcel J. T. Reinders,Jana M. Weber*

Main category: cs.AI

TL;DR: 该研究探讨了大型语言模型（LLMs）在化学合成规划中的应用，通过将反应路径检索转化为自然语言到图查询（Text2Cypher）生成问题，提出单步和多步检索任务。比较了零样本提示与单样本提示的不同示例选择策略（静态、随机、基于嵌入），并引入检查清单驱动的验证/修正循环。结果表明，使用对齐示例的单样本提示表现最佳；检查清单修正主要提升零样本设置下的可执行性，但在已有优质示例时增益有限。研究提供了可复现的Text2Cypher评估框架，促进基于知识图谱的LLM在合成规划中的进一步研究。


<details>
  <summary>Details</summary>
Motivation: 标准提示方法常导致幻觉或过时建议，亟需更可靠的方法结合知识图谱来增强化学合成路径的检索准确性与可靠性。

Method: 将反应路径检索建模为Text2Cypher生成任务，采用零样本与单样本提示，对比不同示例选择策略（静态、随机、嵌入式），并引入检查清单驱动的自校正机制以提高输出质量。

Result: 单样本提示配合对齐示例表现最优；检查清单修正在零样本中显著提升可执行性，但在已有优质示例时提升有限。

Conclusion: 基于知识图谱的Text2Cypher框架能有效提升化学合成路径检索的准确性和可靠性，尤其在结合高质量示例和检查清单修正时效果显著。该研究提供了可复现的评估基准，推动领域发展。

Abstract: Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.

</details>


### [114] [Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources](https://arxiv.org/abs/2601.16108)
*Marzieh Adeli Shamsabad,Hamed Ghodrati*

Main category: cs.AI

TL;DR: 本文提出一种结合视觉语言模型（VLMs）与外部知识的新方法，以应对气候虚假信息的挑战。通过整合最新信息如反向图像搜索结果、在线事实核查和可信专家内容，系统能够更准确地评估图像及其声明的真实性，从而提升对现实世界气候虚假信息的识别能力。


<details>
  <summary>Details</summary>
Motivation: 气候虚假信息在数字时代日益严重，尤其在社交媒体上广泛传播的误导性图片和视频难以检测，影响公众对气候变化的认知和应对行动。现有视觉语言模型受限于训练时的知识，无法有效处理新事件或更新信息，因此需要引入外部实时知识来增强其推理能力。

Method: 将视觉语言模型（VLMs）与外部知识源相结合，利用反向图像搜索、在线事实核查平台和可信专家内容等手段，动态获取最新信息，辅助模型判断图像及关联声明的真实性和可信度。

Result: 该方法显著提升了模型对近期气候虚假信息的识别能力，增强了对真实世界复杂情境的理解与判断力，为维护科学共识和公共认知提供了有力支持。

Conclusion: 通过融合外部实时知识，视觉语言模型可突破自身知识局限，在快速变化的信息环境中更有效地识别气候虚假信息，有助于保护公众对科学的理解并推动气候行动。

Abstract: Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.

</details>


### [115] [LLM Prompt Evaluation for Educational Applications](https://arxiv.org/abs/2601.16134)
*Langdon Holmes,Adam Coscia,Scott Crossley,Joon Suh Choi,Wesley Morris*

Main category: cs.AI

TL;DR: 本文提出了一种可推广的系统性方法，用于评估大语言模型（LLM）在教育应用中的提示词设计。通过六种不同教学策略的提示模板在真实教育场景中的对比测试，采用基于Glicko2评分系统的锦标赛框架，由八位评委从格式、对话支持和学习者适配性三个维度评估生成的问题。结果显示，结合角色设定与上下文管理的提示在战略阅读方面表现最优，胜率高达81%至100%。该方法推动了从随意提示工程向基于证据的教育提示开发转变。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在教育领域的广泛应用，亟需基于证据的方法来设计和评估能够生成个性化且符合教学目标输出的提示词，以提升教育效果。

Method: 设计六种基于不同教学策略的提示模板，采用锦标赛式评估框架，利用Glicko2评分系统，由八名评委从格式、对话支持和学习者适配性三个维度对生成问题进行两两比较评估，数据来自120个真实教育场景交互。

Result: 结合角色设定与上下文管理的提示在战略阅读任务中表现最佳，其在所有对比中胜率介于81%至100%之间，显著优于其他模板，表明该提示有效支持元认知学习策略如自主学习。

Conclusion: 本研究展示了一种系统化、可复制的提示评估方法，有助于教育科技研究者从经验驱动转向证据驱动，优化提示设计，提升教育应用中LLM输出的质量与教学契合度。

Abstract: As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested. The templates incorporated established prompt engineering patterns, with each prompt emphasizing distinct pedagogical strategies. The prompt templates were compared through a tournament-style evaluation framework that can be adapted for other educational applications. The tournament employed the Glicko2 rating system with eight judges evaluating question pairs across three dimensions: format, dialogue support, and appropriateness for learners. Data was sourced from 120 authentic user interactions across three distinct educational deployments. Results showed that a single prompt related to strategic reading out-performed other templates with win probabilities ranging from 81% to 100% in pairwise comparisons. This prompt combined persona and context manager pat-terns and was designed to support metacognitive learning strategies such as self-directed learning. The methodology showcases how educational technology re- searchers can systematically evaluate and improve prompt designs, moving beyond ad-hoc prompt engineering toward evidence-based prompt development for educational applications.

</details>


### [116] [Structured Hints for Sample-Efficient Lean Theorem Proving](https://arxiv.org/abs/2601.16172)
*Zachary Burton*

Main category: cs.AI

TL;DR: 本文研究了在推理阶段使用简单的结构引导是否仍能提升先进神经定理证明器的性能。通过在miniF2F基准上应用一个固定的15个常见策略模板的提示调度，仅用16次采样和1024个令牌的最大生成长度，便实现了21.7%的pass@16，相比标准采样的15.2%提升了43%相对性能。结果表明，即使经过强化学习训练的模型仍未能充分利用战术语言中的结构先验知识，而简单的推理阶段引导可作为一种低成本、高效的补充手段。


<details>
  <summary>Details</summary>
Motivation: 探究高度训练的神经定理证明器在推理阶段是否仍能从简单的结构引导中获益，以评估结构先验知识的有效性与实用性。

Method: 采用固定提示调度策略，基于15个常见的战术模板，在miniF2F基准上对DeepSeek-Prover-V1.5进行推理阶段干预，对比标准采样方法的性能表现。

Result: 在相同采样数（k=16）和最大生成长度（1024 tokens）下，使用固定提示调度的pass@16达到21.7%，相比标准采样的15.2%提升了43%相对性能。

Conclusion: 即使具备强大能力的强化学习训练模型也未充分利用战术语言中的结构先验信息，而简单的推理阶段引导仍是一种高效且低成本的性能增强方式。

Abstract: State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.

</details>


### [117] [Scalable Board Expansion within a General Game System](https://arxiv.org/abs/2601.16216)
*Clémentine Sacré*

Main category: cs.AI

TL;DR: 该论文提出一种动态棋盘扩展机制，利用通用游戏系统（GGS）实现无棋盘游戏的自动棋盘扩展，以避免传统静态大棋盘带来的冗余复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统无棋盘游戏常使用预先定义的大型静态棋盘，但实际游戏中大量区域可能从未被使用，导致不必要的复杂性和资源浪费。

Method: 通过通用游戏系统（GGS）实现游戏过程中棋盘的动态扩展，根据实际游戏进展实时生成和扩展棋盘区域。

Result: 成功实现了棋盘的按需扩展，显著减少了初始设定的冗余，提升了系统的灵活性与效率。

Conclusion: 动态棋盘扩展机制有效解决了传统静态棋盘设计的缺陷，为无棋盘游戏提供了更高效、可扩展的解决方案。

Abstract: This thesis explores the use of a General Game System (GGS) to support the automatic expansion of game boards in boardless games. Traditional implementations of such games often rely on oversized static boards defined from the start, even though large portions of these boards may never be used during gameplay. This approach leads to unnecessary complexity. To address this issue, this thesis propose a dynamic board expansion mechanism in which the game board grows automatically during play.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [118] [Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference](https://arxiv.org/abs/2601.15333)
*Xuanning Hu,Anchen Li,Qianli Xing,Jinglong Ji,Hao Tuo,Bo Yang*

Main category: cs.LG

TL;DR: ELILLM is a framework that enhances Large Language Models (LLMs) for structure-based drug design by reinterpreting generation as encoding-latent exploration-decoding. It uses Bayesian optimization and a position-aware surrogate model to explore latent space and predict binding affinity, while knowledge-guided decoding ensures chemical validity. Evaluated on CrossDocked2020, ELILLM outperforms seven baselines in controlled exploration and binding affinity.


<details>
  <summary>Details</summary>
Motivation: LLMs have strong reasoning but struggle with protein structure understanding and unpredictable molecular generation in structure-based drug design (SBDD).

Method: ELILLM redefines LLM generation as an encoding-latent exploration-decoding process. It employs Bayesian optimization for latent space exploration, a position-aware surrogate model for binding affinity prediction, and knowledge-guided decoding to enforce chemical validity.

Result: ELILLM achieves superior controlled exploration and high binding affinity scores on the CrossDocked2020 benchmark, outperforming seven baseline methods.

Conclusion: ELILLM effectively enhances LLMs' capabilities in SBDD by combining systematic latent exploration with guided generation, enabling chemically valid and high-affinity molecule design.

Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.

</details>


### [119] [Language Models Entangle Language and Culture](https://arxiv.org/abs/2601.15337)
*Shourya Jain,Paras Chopra*

Main category: cs.LG

TL;DR: 本研究评估了大语言模型（LLM）在不同语言下的回答质量，发现低资源语言的问答质量显著低于高资源语言。语言选择会影响模型使用的文化背景，进而影响回答质量。研究通过真实世界开放问题和CulturalBench多语言基准测试揭示了语言对模型输出的文化与质量偏差。


<details>
  <summary>Details</summary>
Motivation: 确保用户无论使用何种语言，都能获得同等质量的LLM响应，避免因语言差异导致系统性劣势。同时探究语言与文化在模型中的交织影响。

Method: 基于WildChat数据集构建真实世界开放问题，利用LLM-as-a-Judge分析文化上下文，并在多语言翻译的CulturalBench基准上评估模型表现。

Result: LLMs在低资源语言上的回答质量明显更低；语言选择显著影响模型所采用的文化背景，从而影响回答质量。

Conclusion: 语言差异会导致大语言模型在文化上下文和回答质量上的系统性偏差，需在模型设计与评估中考虑多语言公平性。

Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ended questions based on our analysis of the WildChat dataset and use it to evaluate whether responses vary by language, specifically, whether answer quality depends on the language used to query the model. We also investigate how language and culture are entangled in LLMs such that choice of language changes the cultural information and context used in the response by using LLM-as-a-Judge to identify the cultural context present in responses. To further investigate this, we evaluate LLMs on a translated subset of the CulturalBench benchmark across multiple languages. Our evaluations reveal that LLMs consistently provide lower quality answers to open-ended questions in low resource languages. We find that language significantly impacts the cultural context used by the model. This difference in context impacts the quality of the downstream answer.

</details>


### [120] [Improving MoE Compute Efficiency by Composing Weight and Data Sparsity](https://arxiv.org/abs/2601.15370)
*Maciej Kilian,Oleg Mkrtchyan,Luke Zettlemoyer,Akshat Shrivastava,Armen Aghajanyan*

Main category: cs.LG

TL;DR: 该论文提出了一种在因果自回归模型中实现数据稀疏性的新方法，通过引入零计算（null）专家来避免传统专家选择路由带来的因果性违反问题。利用负载均衡目标使模型在期望上均匀使用所有专家（包括零计算专家），从而在不破坏因果性的前提下实现数据稀疏性。在视觉-语言模型训练中，该方法在相同预期浮点运算量下显著提升了计算效率、训练损失和下游性能，且模型能隐式地根据模态特性分配资源，更激进地将视觉令牌路由至零计算专家。


<details>
  <summary>Details</summary>
Motivation: 现有混合专家（MoE）层依赖权重稀疏性，但缺乏数据稀疏性；而传统的专家选择路由会破坏自回归模型的因果性，导致训练与推理不一致。因此需要一种既能实现数据稀疏性又不破坏因果性的方法。

Method: 在路由池中引入零计算（null）专家，当令牌被路由到这些专家时，不产生任何计算开销。通过标准负载均衡目标训练模型，使其在所有专家（真实与零计算）之间均匀分配，从而在期望上实现数据稀疏性。

Result: 在视觉-语言模型训练中，该方法在匹配预期浮点运算量的情况下，相比仅使用权重稀疏性，实现了更高的计算效率、更低的训练损失和更好的下游性能。模型还自发学习到模态感知的分配策略，对视觉令牌更倾向于路由至零计算专家。

Conclusion: 通过引入零计算专家并结合负载均衡机制，可在保持因果性的同时实现数据稀疏性，有效提升MoE架构的计算效率，并在多模态任务中展现出优越性能。

Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.

</details>


### [121] [You Need Better Attention Priors](https://arxiv.org/abs/2601.15380)
*Elon Litman,Gabe Guo*

Main category: cs.LG

TL;DR: 本文通过熵正则最优传输（Entropic Optimal Transport, EOT）的视角，将注意力机制泛化，揭示标准注意力对应于一个带有隐式均匀先验的运输问题。为此提出一种新的注意力机制——可训练先验的广义最优传输注意力（GOAT），用可学习的连续先验替代了原始的默认假设。该方法与FlashAttention等优化内核兼容，能够解释并解决注意力塌陷（attention sinks）问题，避免传统注意力中的表征权衡。此外，通过将空间信息融入核心注意力计算，GOAT学习到可外推的先验，兼具可学习位置嵌入的灵活性与固定编码的长度泛化能力。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制依赖于隐式均匀先验，限制了其表达能力和对长序列的泛化性能；同时存在注意力塌陷现象，影响模型表现。因此需要更灵活、可学习且具备良好外推性的注意力机制。

Method: 从熵正则最优传输的角度重新建模注意力机制，引入可学习的连续先验，使注意力计算更符合实际数据分布；结合优化内核如FlashAttention，实现高效计算；通过将空间信息整合进先验学习过程，提升模型对序列长度变化的适应性。

Result: GOAT在多个基准任务上表现出优于标准注意力的性能，有效缓解注意力塌陷问题，并展现出更强的长度外推能力；同时保持与现有高效注意力实现的兼容性。

Conclusion: GOAT为注意力机制提供了基于最优传输的新理论视角，通过可学习先验实现了更优的表达能力、稳定性和泛化性，是迈向更强大序列建模的重要一步。

Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transport Attention with Trainable priors (GOAT), a new attention mechanism that replaces this naive assumption with a learnable, continuous prior. This prior maintains full compatibility with optimized kernels such as FlashAttention. GOAT also provides an EOT-based explanation of attention sinks and materializes a solution for them, avoiding the representational trade-offs of standard attention. Finally, by absorbing spatial information into the core attention computation, GOAT learns an extrapolatable prior that combines the flexibility of learned positional embeddings with the length generalization of fixed encodings.

</details>


### [122] [Ambient Dataloops: Generative Models for Dataset Refinement](https://arxiv.org/abs/2601.15417)
*Adrián Rodríguez-Muñoz,William Daspit,Adam Klivans,Antonio Torralba,Constantinos Daskalakis,Giannis Daras*

Main category: cs.LG

TL;DR: 提出Ambient Dataloops框架，通过数据与模型的迭代协同优化，逐步提升数据质量并改进扩散模型性能。该方法在图像生成和蛋白质设计任务中达到领先效果，并提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 现代数据集包含质量参差不齐的样本，直接训练会导致模型性能不佳，因此需要一种机制来持续提升数据质量并增强模型学习能力。

Method: 采用数据与模型协同进化策略，每轮迭代中合成改进的样本作为轻微噪声数据，利用Ambient Diffusion技术在污染条件下学习，防止自毁性循环。

Result: 在无条件与文本条件图像生成、以及从头蛋白质设计任务中均取得当前最优性能，且具备理论合理性。

Conclusion: Ambient Dataloops能够有效实现高质量数据与强模型的共同进化，为扩散模型训练提供了稳健且高效的新范式。

Abstract: We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.

</details>


### [123] [Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes](https://arxiv.org/abs/2601.15423)
*Lorian Bannis*

Main category: cs.LG

TL;DR: Lattice 是一种混合序列预测系统，通过二元置信度门控有条件地激活学习到的行为结构。它将行为窗口聚类为行为原型，并仅在置信度超过阈值时启用基于原型的评分，否则回退到基础预测。在推荐系统（MovieLens）、科学时间序列（LIGO）和金融市场上的实验表明，Lattice 在 LSTM 骨干上显著提升性能（如 MovieLens 上 HR@10 提升 31.9%），在分布变化时正确拒绝原型激活，表现出对认知不确定性的有效管理能力；在变压器骨干上表现中性，无退化，体现其优雅降级特性。整体验证了置信度门控作为安全关键应用中管理不确定性的一种有前景的架构原则。


<details>
  <summary>Details</summary>
Motivation: 现有序列预测模型难以有效处理认知不确定性，在分布外或模式不适用时仍强行激活复杂结构可能导致性能下降或错误决策。需要一种机制能智能判断何时使用学习到的结构，何时回退到更稳健的基础预测，以提升系统鲁棒性和安全性。

Method: 提出 Lattice 系统，采用行为窗口聚类生成行为原型，引入二元置信度门控：当模型对当前输入的置信度高于阈值时激活原型结构进行评分，否则使用基础模型预测。该机制支持条件性结构激活，实现动态适应不同输入状态。

Result: 在 MovieLens 数据集上，基于 LSTM 的 Lattice 相比 LSTM 基线提升 31.9%（p < 3.29e-25），优于 SASRec 和 BERT4Rec 分别达 109.4% 和 218.6%；在 LIGO 与金融数据中，系统在分布偏移时成功拒绝激活原型，避免错误预测；在变压器骨架上表现中性，无性能下降，体现良好兼容性与降级能力。

Conclusion: 置信度门控机制能够实现‘在应激活时激活，不应时拒绝，冗余时降级’的三重平衡，是一种有效的架构设计原则，适用于管理序列预测中的认知不确定性，尤其在安全敏感场景中具有重要价值。

Abstract: We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p < 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.

</details>


### [124] [CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models](https://arxiv.org/abs/2601.15441)
*Zhenghao He,Guangzhi Xiong,Boyang Wang,Sanchit Sinha,Aidong Zhang*

Main category: cs.LG

TL;DR: CASL提出了一种监督式框架，将扩散模型的稀疏潜在表示与语义概念对齐。通过训练SAE获得解耦的潜在表示，并学习轻量级线性映射将概念与相关潜在维度关联。引入CASL-Steer作为因果探针，揭示概念对齐潜在方向如何影响生成内容，并提出编辑精度比（EPR）评估概念特异性与无关属性保持能力。实验表明该方法在编辑精度和可解释性上优于现有方法，是首个实现扩散模型中潜在表示与语义概念监督对齐的工作。


<details>
  <summary>Details</summary>
Motivation: 现有基于SAE的扩散模型理解方法依赖无监督方式，无法将稀疏特征与人类可理解的概念对齐，限制了对生成图像的可靠语义控制。

Method: 首先在冻结的U-Net激活上训练SAE以获得解耦的潜在表示；随后学习一个轻量级线性映射，将每个语义概念与一组相关潜在维度对齐；使用CASL-Steer进行可控潜在干预，作为因果探针分析概念影响；引入编辑精度比（EPR）综合评估概念特异性和属性保持能力。

Result: 实验结果显示，CASL在编辑精度和可解释性方面显著优于现有方法，首次实现了扩散模型中潜在表示与语义概念的监督对齐。

Conclusion: CASL是首个实现扩散模型潜在表示与语义概念监督对齐的方法，通过概念对齐的稀疏潜在空间提升了生成内容的可控性与可解释性。

Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.

</details>


### [125] [Learning from Synthetic Data: Limitations of ERM](https://arxiv.org/abs/2601.15468)
*Kareem Amin,Alex Bie,Weiwei Kong,Umar Syed,Sergei Vassilvitskii*

Main category: cs.LG

TL;DR: 本文研究在自然数据与合成数据混合的场景下，经典学习理论方法（如ERM）的表现。尽管ERM能收敛到真实均值，但其性能低于对不同生成阶段的数据分配非均匀权重的算法；在PAC学习框架中，ERM甚至可能无法收敛到正确概念，而存在其他算法可有效学习任意VC类的正确假设，即使面对大量数据污染。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普及和低成本生成合成内容，真实数据集被大量合成数据污染，影响了学习算法的可靠性。因此需要重新审视基础学习理论在这一新环境下的适用性。

Method: 将问题建模为一系列学习任务，输入为自然与合成数据的混合，且学习算法对数据来源无感知。通过分析均值估计和PAC学习两种设定，比较ERM与其他加权算法的性能差异。

Result: 对于均值估计，非均匀加权算法优于标准ERM；在PAC学习中，ERM可能不收敛至真实概念，但存在可学习正确假设的替代算法，适用于任意VC类和任意污染程度。

Conclusion: 在合成数据广泛存在的背景下，传统ERM方法存在局限性，需设计更鲁棒的学习机制以应对数据污染，同时证明了在理论上仍存在有效学习的可能性。

Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.
  We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.

</details>


### [126] [Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra](https://arxiv.org/abs/2601.15473)
*Fahd Seddik,Abdulrahman Elbedewy,Gaser Sami,Mohamed Abdelmoniem,Yahia Zakaria*

Main category: cs.LG

TL;DR: Panther is a PyTorch-compatible library that uses Randomized Numerical Linear Algebra (RandNLA) to compress deep learning models, reducing GPU memory usage by up to 75% (e.g., on BERT) with minimal code changes and no significant loss in performance. It offers optimized, drop-in replacements for standard components like linear layers, convolutions, and attention mechanisms via a high-performance C++/CUDA backend.


<details>
  <summary>Details</summary>
Motivation: Modern deep learning models are limited by GPU memory and compute. Existing RandNLA techniques can help but lack a unified, production-ready implementation, hindering adoption.

Method: Panther integrates established RandNLA algorithms into a PyTorch-compatible framework with a custom C++/CUDA backend (pawX), enabling efficient, drop-in replacements for key neural network components such as linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions.

Result: Replacing standard PyTorch layers with Panther layers achieves up to 75% memory reduction on BERT while maintaining comparable loss, demonstrating both effectiveness and ease of integration.

Conclusion: Panther provides a practical, high-performance solution for model compression using RandNLA, significantly reducing memory footprint without sacrificing model accuracy, and enables widespread adoption through seamless integration with PyTorch.

Abstract: Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.

</details>


### [127] [Early predicting of hospital admission using machine learning algorithms: Priority queues approach](https://arxiv.org/abs/2601.15481)
*Jakub Antczak,James Montgomery,Małgorzata O'Reilly,Zbigniew Palmowski,Richard Turner*

Main category: cs.LG

TL;DR: 本研究比较了SARIMAX、XGBoost和LSTM三种模型在预测澳大利亚三级转诊医院每日急诊科就诊人数方面的表现，涵盖七天预测期。通过将需求分解为八个病房类别并按临床复杂性分层，结合使用Prophet模型生成新冠疫情期间的合成反事实数据以减少干扰，结果表明所有模型均优于季节性简单基准模型。其中，XGBoost在预测总就诊人数方面表现最佳（MAE=6.63），而SARIMAX在预测高复杂度病例上略胜一筹（MAE=3.77）。然而，三者均存在对突发、罕见患者激增预测不足的问题。


<details>
  <summary>Details</summary>
Motivation: 急诊科拥挤严重影响患者安全与运营效率，亟需准确的需求预测以实现资源合理配置。现有研究在处理复杂分层数据及异常事件（如新冠疫情）影响方面存在不足，因此需要更精准的预测模型。

Method: 采用SARIMAX、XGBoost和LSTM三种模型进行七天内日急诊就诊量预测；数据来自2017年1月至2021年12月的澳大利亚三级医院；将需求细分为八类病房，并按临床复杂性分层；使用Prophet模型生成新冠疫情期间的合成反事实数据以校正异常值。

Result: 所有模型均显著优于季节性简单基准模型。XGBoost在总就诊人数预测中误差最小（MAE=6.63），SARIMAX在高复杂度病例预测中表现更优（MAE=3.77）。但三者均未能准确捕捉突发性、低频的患者数量激增。

Conclusion: 尽管所提出的模型能有效复现日常规律模式，但在应对突发性、极端事件导致的患者流量激增方面仍存在局限，提示未来需结合更多外部变量或引入异常检测机制以提升预测鲁棒性。

Abstract: Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.

</details>


### [128] [Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding](https://arxiv.org/abs/2601.15482)
*Huayu Li,ZhengXiao He,Siyuan Tian,Jinghao Wen,Ao Li*

Main category: cs.LG

TL;DR: 本文提出了一种名为马丁格尔前瞻采样（MFS）的新型推理框架，将大语言模型的解码过程建模为寻找最优随机过程的问题。通过引入鞅理论，MFS在路径估值、选择和停止规则上均采用概率论的严格原理：利用Doob分解定理衡量路径的可预测优势，基于可选停止定理进行子优路径的合理剪枝，并根据鞅收敛定理设计自适应终止机制。实验在六个推理基准上验证了MFS在准确率和计算效率上的优越性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准自回归解码在大语言模型中存在短视问题，难以找到全局最优推理路径，而现有的前瞻性采样方法依赖于启发式规则，缺乏理论支撑。因此需要一种更严谨、可解释且高效的解码策略。

Method: 将推理路径建模为随机过程，应用鞅理论中的Doob分解定理进行路径价值评估，使用可选停止定理实现有效路径剪枝，并基于鞅收敛定理设计自适应停止规则，构建一个完全理论驱动的解码框架。

Result: 在六个推理基准测试中，MFS在准确率上超越当前最先进的方法，同时大幅提升了计算效率，证明其在性能与资源利用之间的良好平衡。

Conclusion: MFS通过将语言模型解码问题形式化为鞅过程优化，实现了从启发式到理论驱动的范式转变，为大语言模型的推理提供了可解释、高效且可靠的解决方案。

Abstract: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

</details>


### [129] [MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification](https://arxiv.org/abs/2601.15498)
*Jingwei Song,Xinyu Wang,Hanbin Wang,Xiaoxuan Lei,Bill Shi,Shixin Han,Eric Yang,Xiao-Wen Chang,Lynn Ai*

Main category: cs.LG

TL;DR: 提出了一种无需训练、领域无关的边际感知推测验证方法（Margin-Aware Speculative Verification），通过根据目标模型的局部决策稳定性动态调整验证策略，缓解传统严格逐标记拒绝采样在低置信度场景下的效率瓶颈。该方法仅修改验证规则，与现有目标耦合的推测解码框架完全兼容，在8B到235B规模的模型上均实现显著推理加速并保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前推测解码的验证机制依赖严格的逐标记拒绝采样，在现代大模型常处于低置信度（低边际）状态时，拒绝合理备选标记虽信息增益小却带来高昂回滚成本，造成根本性效率损失。

Method: 提出基于目标模型输出logits直接测量决策稳定性的边际感知验证策略，仅在严格验证收益较小时放宽拒绝条件，实现自适应验证，且不需额外训练或领域适配。

Result: 在8B至235B不同规模模型上，相比最先进基线，本方法实现持续且显著的推理加速，同时在多个基准测试中保持生成质量不变。

Conclusion: 边际感知推测验证是一种高效、通用且兼容性强的验证优化方案，有效解决了传统推测解码在低边际场景下的效率瓶颈，为大模型推理加速提供了新思路。

Abstract: Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.

</details>


### [130] [Data-driven Lake Water Quality Forecasting for Time Series with Missing Data using Machine Learning](https://arxiv.org/abs/2601.15503)
*Rishit Chatterjee,Tahiya Chowdhury*

Main category: cs.LG

TL;DR: 该研究针对志愿者主导的湖泊监测数据中存在的时间序列不规则、缺失值多等问题，以缅因州30个湖泊的30年现场观测数据为样本，采用多重插补法（MICE）处理缺失值，并使用归一化平均绝对误差（nMAE）进行跨湖比较。在六种模型中，岭回归表现最佳。研究进一步量化了最小样本量，发现基于近期历史数据的后向协议下，平均每湖176个训练样本即可达到全历史数据95%的准确率。同时，识别出一个仅含4个特征的精简特征集，其性能与13个特征基线相差不超过5%。最终提出联合可行性函数，统一确定最小历史长度和最少预测变量，在满足5%精度目标时，仅需约64个近期样本和每个湖泊一个预测变量，表明目标监测具有高度可操作性。


<details>
  <summary>Details</summary>
Motivation: 志愿者主导的湖泊监测数据存在大量因冰封、天气限制和人为错误导致的时间序列缺失，影响有害藻华的预测与预警，亟需高效、可靠的建模方法来应对数据不完整问题。

Method: 采用多重插补法（MICE）处理缺失数据；使用归一化平均绝对误差（nMAE）评估模型性能；比较六种模型，选择最优模型（岭回归）；通过实验量化最小样本量和最小特征集；构建联合可行性函数，综合优化历史长度与特征选择。

Result: 岭回归在跨湖预测中表现最佳；约176个训练样本可实现接近全历史数据的精度；4个特征的精简集与13个特征基线性能相差小于5%；联合可行性函数表明，仅需约64个近期样本和1个预测变量即可满足5%精度目标。

Conclusion: 提出的联合可行性策略有效整合了近期历史长度与特征选择，在保证高精度的前提下显著降低采样成本和测量复杂度，为湖泊研究人员提供了简单、高效的采样规划与监测优先级设定指导。

Abstract: Volunteer-led lake monitoring yields irregular, seasonal time series with many gaps arising from ice cover, weather-related access constraints, and occasional human errors, complicating forecasting and early warning of harmful algal blooms. We study Secchi Disk Depth (SDD) forecasting on a 30-lake, data-rich subset drawn from three decades of in situ records collected across Maine lakes. Missingness is handled via Multiple Imputation by Chained Equations (MICE), and we evaluate performance with a normalized Mean Absolute Error (nMAE) metric for cross-lake comparability. Among six candidates, ridge regression provides the best mean test performance. Using ridge regression, we then quantify the minimal sample size, showing that under a backward, recent-history protocol, the model reaches within 5% of full-history accuracy with approximately 176 training samples per lake on average. We also identify a minimal feature set, where a compact four-feature subset matches the thirteen-feature baseline within the same 5% tolerance. Bringing these results together, we introduce a joint feasibility function that identifies the minimal training history and fewest predictors sufficient to achieve the target of staying within 5% of the complete-history, full-feature baseline. In our study, meeting the 5% accuracy target required about 64 recent samples and just one predictor per lake, highlighting the practicality of targeted monitoring. Hence, our joint feasibility strategy unifies recent-history length and feature choice under a fixed accuracy target, yielding a simple, efficient rule for setting sampling effort and measurement priorities for lake researchers.

</details>


### [131] [SAGE-FM: A lightweight and interpretable spatial transcriptomics foundation model](https://arxiv.org/abs/2601.15504)
*Xianghao Zhan,Jingyu Xu,Yuanning Zheng,Zinaida Good,Olivier Gevaert*

Main category: cs.LG

TL;DR: SAGE-FM is a lightweight, graph convolutional network-based foundation model for spatial transcriptomics, trained on 416 human Visium samples across 15 organs. It uses masked central spot prediction to learn spatially coherent gene expression embeddings, achieving high recovery accuracy (91% significant correlations) and outperforming MOFA and other methods in clustering and biological heterogeneity preservation. SAGE-FM generalizes well to downstream tasks, enabling 81% accuracy in spot annotation and improving glioblastoma subtype prediction. In silico perturbations confirm its ability to capture directional regulatory relationships.


<details>
  <summary>Details</summary>
Motivation: To develop a biologically interpretable, parameter-efficient foundation model for spatial transcriptomics that can capture spatially conditioned regulatory relationships and generalize across diverse downstream tasks.

Method: SAGE-FM employs a graph convolutional network (GCN) with a masked central spot prediction objective, trained on large-scale human Visium data spanning 15 organs. The model learns spatially coherent embeddings that encode gene expression patterns and regulatory interactions.

Result: SAGE-FM achieves 91% of masked genes with significant correlation (p < 0.05), outperforms existing methods in unsupervised clustering and biological heterogeneity preservation, enables 81% accuracy in pathologist-defined spot annotation, improves glioblastoma subtype prediction, and captures directional ligand-receptor and upstream-downstream regulatory effects consistent with ground truth.

Conclusion: Simple, parameter-efficient GCNs can serve as effective, spatially aware, and biologically interpretable foundation models for large-scale spatial transcriptomics.

Abstract: Spatial transcriptomics enables spatial gene expression profiling, motivating computational models that capture spatially conditioned regulatory relationships. We introduce SAGE-FM, a lightweight spatial transcriptomics foundation model based on graph convolutional networks (GCNs) trained with a masked central spot prediction objective. Trained on 416 human Visium samples spanning 15 organs, SAGE-FM learns spatially coherent embeddings that robustly recover masked genes, with 91% of masked genes showing significant correlations (p < 0.05). The embeddings generated by SAGE-FM outperform MOFA and existing spatial transcriptomics methods in unsupervised clustering and preservation of biological heterogeneity. SAGE-FM generalizes to downstream tasks, enabling 81% accuracy in pathologist-defined spot annotation in oropharyngeal squamous cell carcinoma and improving glioblastoma subtype prediction relative to MOFA. In silico perturbation experiments further demonstrate that the model captures directional ligand-receptor and upstream-downstream regulatory effects consistent with ground truth. These results demonstrate that simple, parameter-efficient GCNs can serve as biologically interpretable and spatially aware foundation models for large-scale spatial transcriptomics.

</details>


### [132] [Machine learning-enhanced non-amnestic Alzheimer's disease diagnosis from MRI and clinical features](https://arxiv.org/abs/2601.15530)
*Megan A. Witherow,Michael L. Evans,Ahmed Temtam,Hamid Okhravi,Khan M. Iftekharuddin*

Main category: cs.LG

TL;DR: 本文提出一种基于机器学习的方法，利用常规临床测试和MRI数据区分非典型阿尔茨海默病（atAD）与非AD认知障碍。研究使用1410名受试者数据，在多个数据集上评估了临床特征、海马体积及全脑MRI特征的分类性能，结果显示引入更多重要MRI特征可显著提升诊断准确率。通过Boruta统计方法识别并可视化关键脑区，该方法将atAD的召回率从52%提高到69%（NACC数据集）和从34%提高到77%（ADNI数据集），同时保持高精确度，有助于改善临床中非遗忘型atAD的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有临床诊断方法对非典型阿尔茨海默病（atAD）患者存在较高误诊率，因缺乏有效工具来区分atAD与非AD认知障碍。尽管生物标志物检测准确度高，但其侵入性限制了广泛应用。因此需要一种基于标准临床数据（如认知测试和MRI）的非侵入性、高精度诊断方法，以提升atAD的识别能力。

Method: 采用机器学习模型进行atAD vs. 非AD的分类任务，输入包括临床测试电池得分和多种MRI特征（海马体积及全脑结构影像特征）。在三个数据集（一个私有数据集、NACC和ADNI）上进行多组实验，并通过Boruta算法筛选显著脑区，实现特征重要性分析与可视化。

Result: 结合全脑MRI特征的模型表现优于仅使用海马体积的模型；在NACC数据集中，atAD召回率从52%提升至69%；在ADNI数据集中，召回率从34%提升至77%，同时保持高精确度。关键脑区分析揭示了与atAD相关的特定神经解剖区域。

Conclusion: 本研究提出的机器学习方法能有效利用标准临床数据（认知测试和MRI）显著提升非典型阿尔茨海默病的诊断准确率，尤其在提升召回率方面效果显著，具有重要的临床应用价值，为改善atAD早期识别提供了可行路径。

Abstract: Alzheimer's disease (AD), defined as an abnormal buildup of amyloid plaques and tau tangles in the brain can be diagnosed with high accuracy based on protein biomarkers via PET or CSF analysis. However, due to the invasive nature of biomarker collection, most AD diagnoses are made in memory clinics using cognitive tests and evaluation of hippocampal atrophy based on MRI. While clinical assessment and hippocampal volume show high diagnostic accuracy for amnestic or typical AD (tAD), a substantial subgroup of AD patients with atypical presentation (atAD) are routinely misdiagnosed. To improve diagnosis of atAD patients, we propose a machine learning approach to distinguish between atAD and non-AD cognitive impairment using clinical testing battery and MRI data collected as standard-of-care. We develop and evaluate our approach using 1410 subjects across four groups (273 tAD, 184 atAD, 235 non-AD, and 685 cognitively normal) collected from one private data set and two public data sets from the National Alzheimer's Coordinating Center (NACC) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). We perform multiple atAD vs. non-AD classification experiments using clinical features and hippocampal volume as well as a comprehensive set of MRI features from across the brain. The best performance is achieved by incorporating additional important MRI features, which outperforms using hippocampal volume alone. Furthermore, we use the Boruta statistical approach to identify and visualize significant brain regions distinguishing between diagnostic groups. Our ML approach improves the percentage of correctly diagnosed atAD cases (the recall) from 52% to 69% for NACC and from 34% to 77% for ADNI, while achieving high precision. The proposed approach has important implications for improving diagnostic accuracy for non-amnestic atAD in clinical settings using only clinical testing battery and MRI.

</details>


### [133] [QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs](https://arxiv.org/abs/2601.15538)
*Himanshu Mishra,Kanwal Mehreen*

Main category: cs.LG

TL;DR: 该论文研究了在模型量化（如4比特）条件下机器遗忘的有效性问题，发现低比特量化会灾难性地恢复被遗忘的信息。为此，作者提出了一种量化感知的遗忘方法，通过在logits空间引入铰链损失，确保遗忘样本的输出与原始模型有足够差异（至少为量化步长的一半），从而在量化后仍能保持遗忘效果。实验表明，该方法在语言和分类任务中有效抑制了遗忘信息的恢复，而现有方法则几乎完全恢复了被遗忘的知识。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法在模型量化后无法有效保持遗忘效果，尤其是低比特量化会恢复被遗忘的知识，这限制了其在实际部署中的应用。因此需要一种能够适应量化环境的新型遗忘机制。

Method: 1. 分析权重变化统计和量化桶重叠，揭示典型遗忘更新因过小而无法跨越量化阈值；2. 提出基于logits空间的铰链损失函数，强制未学习模型对遗忘样本的输出与原模型输出差异至少达到量化步长的一半，以确保遗忘信息在量化后仍可区分。

Result: 在多种任务（包括语言建模和分类，以及推特虚假信息数据集）上，所提方法在4比特量化下仍能有效保持遗忘，而现有方法几乎完全恢复了被遗忘的知识。结果证明了该方法在量化场景下的鲁棒性和有效性。

Conclusion: 低比特量化会严重破坏现有机器遗忘方法的效果，导致遗忘信息被意外恢复。本文提出的量化感知遗忘方法通过设计合适的损失函数，有效缓解了这一问题，在量化部署中实现了可靠的遗忘能力。

Abstract: Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.

</details>


### [134] [PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction](https://arxiv.org/abs/2601.15540)
*Dongchen Huang*

Main category: cs.LG

TL;DR: Prism is a white-box attention-based architecture inspired by MCR², using geometric inductive biases like overcomplete dictionaries and π-RoPE to achieve unsupervised functional disentanglement. It demonstrates that interpretability and performance can be unified through principled design.


<details>
  <summary>Details</summary>
Motivation: Deep learning models, especially Transformers, are often seen as 'black boxes' due to poor interpretability. The paper aims to address this by creating a more transparent, interpretable model grounded in physical and geometric principles.

Method: The authors model attention as a gradient ascent on a signal-noise manifold, introducing an overcomplete dictionary and irrational frequency separation (π-RoPE) to enforce incoherence between signal and noise subspaces, thereby inducing functional disentanglement.

Result: In TinyStories experiments, Prism spontaneously develops distinct attention heads: low-frequency ones capture long-range causal dependencies (signal), while high-frequency ones handle local syntactic details (noise), demonstrating both interpretability and strong performance.

Conclusion: Interpretability and performance are not mutually exclusive; they can be unified via principled geometric construction, as shown by Prism's ability to achieve functional disentanglement and strong task performance without sacrificing transparency.

Abstract: Deep learning models, particularly Transformers, are often criticized as "black boxes" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($π$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.

</details>


### [135] [RDumb++: Drift-Aware Continual Test-Time Adaptation](https://arxiv.org/abs/2601.15544)
*Himanshu Mishra*

Main category: cs.LG

TL;DR: RDumb++ 提出两种基于熵和KL散度的漂移检测机制，结合自适应重置策略，有效应对持续测试时适应中的分布漂移问题，在CCC基准上实现约3%的准确率提升，并保持长期稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在快速或长期分布变化下表现不佳，尤其在大规模数据流（如CCC基准中750万样本）中易出现预测崩溃，亟需更鲁棒的持续测试时适应机制。

Method: 引入熵基与KL散度基的双漂移检测机制，结合自适应重置策略，实时监测并纠正因累积适应导致的性能退化。

Result: 在CCC-medium的九次实验中，RDumb++显著优于RDumb，平均提升约3%的准确率，且在整个数据流中保持稳定适应能力；消融实验验证了漂移感知重置对防止崩溃的关键作用。

Conclusion: 漂移感知的自适应重置是实现可靠长时程持续测试时适应的核心，RDumb++通过有效的漂移检测与恢复机制，为极端分布变化场景下的模型部署提供了稳健解决方案。

Abstract: Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.

</details>


### [136] [Beyond validation loss: Clinically-tailored optimization metrics improve a model's clinical performance](https://arxiv.org/abs/2601.15546)
*Charles B. Delahunt,Courosh Mehanian,Daniel E. Shea,Matthew P. Horning*

Main category: cs.LG

TL;DR: 本文探讨了在医疗机器学习中使用临床定制指标替代传统验证损失进行模型优化的有效性。通过两个受控实验，证明了基于临床相关指标的优化能显著提升模型在实际临床任务中的表现。尽管需要额外工作来定义和实现这些指标，但其带来的临床性能提升值得投入。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习依赖验证损失进行模型优化，但在医疗领域，模型的成功应以是否满足临床需求为准，而非仅优化训练损失。因此，需要更贴近临床实际的评估指标来指导优化过程。

Method: 设计并实施了两个受控实验，比较使用临床定制指标与传统验证损失在模型优化上的效果。临床指标根据具体医疗任务设计，非必须可微，便于灵活应用。

Result: 实验结果表明，采用临床相关指标进行优化的模型在临床任务上表现更优，尤其是在符合实际医疗需求方面优于基于验证损失的优化方法。

Conclusion: 在医疗机器学习中，使用临床定制指标进行模型优化虽需额外开发成本，但能显著提升模型在真实临床场景中的有效性，更契合该领域的核心目标。

Abstract: A key task in ML is to optimize models at various stages, e.g. by choosing hyperparameters or picking a stopping point. A traditional ML approach is to use validation loss, i.e. to apply the training loss function on a validation set to guide these optimizations. However, ML for healthcare has a distinct goal from traditional ML: Models must perform well relative to specific clinical requirements, vs. relative to the loss function used for training. These clinical requirements can be captured more precisely by tailored metrics. Since many optimization tasks do not require the driving metric to be differentiable, they allow a wider range of options, including the use of metrics tailored to be clinically-relevant. In this paper we describe two controlled experiments which show how the use of clinically-tailored metrics provide superior model optimization compared to validation loss, in the sense of better performance on the clinical task. The use of clinically-relevant metrics for optimization entails some extra effort, to define the metrics and to code them into the pipeline. But it can yield models that better meet the central goal of ML for healthcare: strong performance in the clinic.

</details>


### [137] [Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling](https://arxiv.org/abs/2601.15547)
*Jingren Hou,Hong Wang,Pengyu Xu,Chang Gao,Huafeng Liu,Liping Jing*

Main category: cs.LG

TL;DR: 本文提出首个系统性框架，用于从部分观测数据中学习神经算子，解决真实科学应用中因传感器限制、地理约束或测量成本导致的不完整观测问题。针对两个核心挑战——未观测区域的监督缺口与输入与解场之间的动态空间错配，提出Latent Autoregressive Neural Operator（\ours），包含掩码预测训练策略和物理感知隐空间传播器。此外，构建了专门用于评估部分观测条件下神经算子性能的基准POBench-PDE。实验表明，\ours在多种任务中实现18–69%的相对L2误差降低，适用于高达75%缺失率的实际场景，显著缩小了理想研究与真实科学计算之间的差距。


<details>
  <summary>Details</summary>
Motivation: 真实世界的科学应用常面临传感器限制、地理约束或测量成本导致的不完整观测数据，而现有神经算子通常假设输入是完全观测的，这严重限制了其在实际中的应用。因此，需要一种能从部分观测数据中有效学习神经算子的新方法。

Method: \\ours 提出两种创新机制：(i) 掩码到预测的训练策略，通过有策略地遮蔽已知区域生成人工监督信号；(ii) 物理感知隐空间传播器，通过边界优先的自回归生成方式在隐空间重建解场。同时构建了专门的基准POBench-PDE以评估模型在部分观测下的表现。

Result: 在多种基于偏微分方程的任务中，\\ours 在补丁式缺失且缺失率低于50%的情况下，实现了18–69%的相对L2误差降低；在高达75%缺失率下仍表现出良好性能，显著提升了神经算子在真实复杂场景中的适用性。

Conclusion: 该工作首次系统性地解决了神经算子在部分观测条件下的学习难题，通过新方法与专用基准验证了其在真实世界科学计算中的有效性，为未来实际应用提供了重要基础。

Abstract: Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \ours achieves state-of-the-art performance with 18--69$\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.

</details>


### [138] [Deep Learning for Perishable Inventory Systems with Human Knowledge](https://arxiv.org/abs/2601.15589)
*Xuan Liao,Zhenkang Peng,Ying Rong*

Main category: cs.LG

TL;DR: 本文研究在随机提前期下，需求和提前期分布均未知的易腐品库存系统。针对有限历史数据与可观测协变量及系统状态的现实场景，提出基于边际成本核算的统一损失函数，实现端到端深度学习策略训练。设计两种方法：纯黑箱（E2E-BB）与结构引导（E2E-PIL），后者嵌入投影库存水平（PIL）政策以显式建模库存效应。进一步利用操作数据分析中的提升技术，构建改进策略E2E-BPIL。实验表明性能排序为：E2E-BB < E2E-PIL < E2E-BPIL。通过超额风险分解证明，引入启发式结构可降低有效模型复杂度，提升学习效率，仅小幅牺牲灵活性。结果强调结合人类知识与库存理论的深度学习决策工具更具有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在易腐品库存管理中，因生命周期有限，不当的订货决策易导致缺货或过度浪费。现有方法在需求与提前期分布未知、历史数据有限的情况下，难以高效学习最优策略。如何在数据受限条件下提升学习效率，并保持策略鲁棒性，是核心挑战。

Method: 采用边际成本会计方案，将每笔订单的成本归一化为单一寿命成本，构建统一损失函数，支持端到端深度学习训练。提出两种策略：1）纯黑箱方法（E2E-BB），直接从协变量与系统状态映射至订货量；2）结构引导方法（E2E-PIL），嵌入投影库存水平（PIL）政策，显式处理库存影响。进一步利用目标函数的一次齐次性，引入操作数据分析中的提升技术，构造增强型策略E2E-BPIL。

Result: 在合成与真实数据上的实验验证了策略性能排序：E2E-BB表现最差，E2E-PIL显著优于前者，而E2E-BPIL进一步提升性能。超额风险分解分析表明，嵌入启发式结构能有效降低模型复杂度，提升学习效率，且灵活性损失微小。

Conclusion: 在数据有限的易腐品库存管理中，结合人类经验与库存理论的深度学习方法更优。结构引导的端到端策略（如E2E-PIL与E2E-BPIL）不仅提升学习效率，还增强策略鲁棒性，凸显了将先进分析与经典库存理论融合的价值。

Abstract: Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.

</details>


### [139] [Closing the Gap on the Sample Complexity of 1-Identification](https://arxiv.org/abs/2601.15620)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 该论文研究了1-识别问题，即在纯探索的多臂赌博机框架中，判断是否存在均值不小于已知阈值μ₀的合格臂。作者通过优化方法推导出存在至少一个合格臂时期望总抽样次数𝔼τ的新下界，并设计了一种新算法，其上界与下界之间的差距仅为对数因子的多项式级别，填补了历史文献中关于多个合格臂情形下𝔼τ分析的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究在多个合格臂情形下的期望抽样次数𝔼τ分析仍为开放问题，亟需更精确的下界和紧致的上界以实现更优的算法性能。

Method: 采用优化公式推导新的下界，并设计一种新算法，结合理论分析证明其上界与下界间差距仅差对数因子的多项式级别。

Result: 提出了新的下界和紧致上界，实现了在所有问题实例下上界与下界之间差距最小化，显著提升了1-识别问题的理论理解。

Conclusion: 该工作为1-识别问题提供了更精确的理论分析框架，尤其解决了多合格臂情形下的未解难题，推动了纯探索多臂赌博机领域的进展。

Abstract: 1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $μ_0$, or to output \textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-δ$, while making expected total pulling times $\mathbb{E}τ$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\mathbb{E}τ$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\mathbb{E}τ$ when there are multiple qualified arms, which is an open problem left by history literature.

</details>


### [140] [Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting](https://arxiv.org/abs/2601.15669)
*Jingjing Bai,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Dualformer提出一种双域框架，通过双分支结构、分层频率采样和周期性感知加权机制，解决Transformer在长期时间序列预测中的高频信息衰减问题，显著提升对复杂周期性数据的建模能力。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在长期时间序列预测中存在固有的低通滤波效应，导致高频信息在多层传播中逐渐衰减，难以捕捉细微的时间变化，影响预测精度。

Method: 提出Dualformer，采用双分支架构同时在时域和频域建模，引入分层频率采样模块将不同频率带分配给不同层级，结合周期性感知加权机制动态调整双分支贡献，基于谐波能量比进行自适应融合，并给出理论下界支持。

Result: 在八个主流基准数据集上实验表明，Dualformer在异构或弱周期性数据上表现优异，有效保留高频信息，增强泛化能力，性能优于现有方法。

Conclusion: Dualformer通过分层、自适应的双域频率建模，克服了Transformer的低通滤波缺陷，为长期时间序列预测提供了更有效的频率建模范式。

Abstract: Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.

</details>


### [141] [Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing](https://arxiv.org/abs/2601.15686)
*Xinyu Wang,Sicheng Lyu,Yu Gu,Jerry Huang,Peng Lu,Yufei Cui,Xiao-Wen Chang*

Main category: cs.LG

TL;DR: RLSEdit 是一种用于长期连续编辑预训练大模型的递归最小二乘法编辑器，通过在线二次优化与软约束，实现高效、稳定地更新知识而不破坏原有能力。其核心是利用 Woodbury 恒等式实现每步更新的低复杂度递推，避免历史累积干扰，并在多个模型上验证了其可扩展性（支持10,000次编辑），显著优于现有方法，在编辑成功率和整体稳定性方面表现优异，有效保留早期编辑内容并维持通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型编辑方法在持续接收新编辑时面临塑性-稳定性困境：‘定位-编辑’策略易积累干扰，而‘零空间’策略仅保护显式约束内容，导致旧编辑被覆盖或非约束行为漂移，损害模型在多次编辑后的整体性能。

Method: 提出 RLSEdit，将编辑建模为带有软约束的在线二次优化问题，最小化累积键值拟合目标，并引入两个正则项分别控制权重偏离预训练参数和偏离指定锚定映射；利用 Woodbury 恒等式实现高效的在线递推更新，使每次编辑计算复杂度独立于历史长度，仅依赖当前编辑规模。

Result: 在多种模型架构上实验表明，RLSEdit 可稳定支持高达 10,000 次编辑，显著优于强基线方法，在编辑成功率和整体稳定性方面表现更优，能有效保留早期编辑结果，并在 GLUE 和未见推理/代码任务上保持良好的通用能力。

Conclusion: RLSEdit 提供了一种高效且稳定的长期连续编辑方案，解决了编辑过程中的塑性-稳定性权衡问题，为大模型在动态知识环境下的持续学习提供了可行路径。

Abstract: Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit "hard writes" can accumulate interference over time, while null-space-style "hard preservation" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.

</details>


### [142] [Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs](https://arxiv.org/abs/2601.15714)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 本文提出零错误时域（ZEH）作为衡量大语言模型可信度的新指标，定义为模型在不犯任何错误的情况下可处理的最大输入范围。通过评估GPT-5.2、Qwen2.5等模型的ZEH，发现即使先进模型在简单逻辑与数学任务上仍会出错，揭示其在安全关键场景中的风险。研究显示ZEH虽计算成本高，但可通过树结构与在线softmax优化实现近十倍加速，且能揭示算法能力涌现的线索。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在看似简单的逻辑和计算任务中仍频繁出错，影响其在安全关键领域的可信应用。现有评估方法难以捕捉模型在特定输入长度下的可靠性边界，因此亟需一种量化模型无错误处理能力的指标。

Method: 提出零错误时域（ZEH）作为衡量模型最大无错处理范围的指标；通过系统性测试不同长度输入下的模型表现，确定其无错误上限；采用树结构与在线softmax优化提升计算效率。

Result: GPT-5.2在短字符串奇偶性判断和括号匹配等基础任务上已出现错误，表明其基础推理能力存在显著缺陷；Qwen2.5的ZEH与准确率相关但行为模式不同，提示其算法能力的潜在涌现；通过优化，计算ZEH的效率提升达一个数量级。

Conclusion: ZEH是一个有效的模型可信度评估工具，能揭示模型在基础推理上的脆弱性，并为理解算法能力的涌现提供新视角。尽管计算成本较高，但可通过结构优化大幅降低，使其具备实际应用潜力。

Abstract: We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.

</details>


### [143] [Communication-efficient Federated Graph Classification via Generative Diffusion Modeling](https://arxiv.org/abs/2601.15722)
*Xiuling Wang,Xin Huang,Haibo Hu,Jianliang Xu*

Main category: cs.LG

TL;DR: CeFGC is a novel federated GNN framework that reduces communication rounds to three by using generative diffusion models to synthesize local graphs, improving efficiency and performance on non-IID data.


<details>
  <summary>Details</summary>
Motivation: Federated GNNs face high communication overhead and challenges due to non-IID data across clients; CeFGC aims to minimize client-server communication while maintaining model effectiveness.

Method: Each client trains a generative diffusion model to capture local graph distribution, shares it with the server, which redistributes it. Clients use these models to generate synthetic graphs for training local GNNs, then upload weights for global aggregation.

Result: Experiments show CeFGC outperforms state-of-the-art methods in accuracy and efficiency on real-world non-IID graph datasets, with only three communication rounds.

Conclusion: CeFGC effectively addresses communication overhead and non-IID challenges in FGNNs by leveraging generative diffusion models, achieving superior performance with minimal communication.

Abstract: Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.

</details>


### [144] [Rethinking Drug-Drug Interaction Modeling as Generalizable Relation Learning](https://arxiv.org/abs/2601.15771)
*Dong Xu,Jiantao Wu,Qihua Pan,Sisi Yuan,Zexuan Zhu,Junkai Ji*

Main category: cs.LG

TL;DR: GenRel-DDI提出了一种以关系为中心的学习框架，通过将药物相互作用（DDI）预测重新定义为独立于药物身份的关系学习问题，从而提升模型在未见药物和新药对上的泛化能力。该方法通过学习可迁移的交互模式，显著优于现有最先进的方法，尤其在严格的实体不相交评估中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法虽然在标准基准上表现良好，但在实际部署场景中难以泛化，主要因为大多数候选药物对涉及前所未见的药物，且已验证的相互作用稀少。此外，当前分子中心的嵌入空间中的接近性不能可靠对应交互标签，单纯扩大模型容量也无法改善泛化性能。

Method: 提出GenRel-DDI，一种关系中心的学习框架，将交互表示学习与药物身份解耦，使模型能够捕捉可迁移的交互模式，从而提升对未见药物和新药对的泛化能力。

Result: 在多个基准数据集上的实验表明，GenRel-DDI显著优于现有最先进方法，尤其在实体不相离评估中取得大幅改进，证明了关系学习在稳健DDI预测中的有效性和实用性。

Conclusion: GenRel-DDI通过关系级抽象实现了更优的泛化能力，为真实世界中复杂的多药联用场景提供了可靠的DDI预测解决方案。

Abstract: Drug-drug interaction (DDI) prediction is central to drug discovery and clinical development, particularly in the context of increasingly prevalent polypharmacy. Although existing computational methods achieve strong performance on standard benchmarks, they often fail to generalize to realistic deployment scenarios, where most candidate drug pairs involve previously unseen drugs and validated interactions are scarce. We demonstrate that proximity in the embedding spaces of prevailing molecule-centric DDI models does not reliably correspond to interaction labels, and that simply scaling up model capacity therefore fails to improve generalization. To address these limitations, we propose GenRel-DDI, a generalizable relation learning framework that reformulates DDI prediction as a relation-centric learning problem, in which interaction representations are learned independently of drug identities. This relation-level abstraction enables the capture of transferable interaction patterns that generalize to unseen drugs and novel drug pairs. Extensive experiments across multiple benchmark demonstrate that GenRel-DDI consistently and significantly outperforms state-of-the-art methods, with particularly large gains on strict entity-disjoint evaluations, highlighting the effectiveness and practical utility of relation learning for robust DDI prediction. The code is available at https://github.com/SZU-ADDG/GenRel-DDI.

</details>


### [145] [Next Generation Active Learning: Mixture of LLMs in the Loop](https://arxiv.org/abs/2601.15773)
*Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Guoxiang Guo,Joanne Enticott,Gang Liu,Lan Du*

Main category: cs.LG

TL;DR: 本文提出了一种基于多大语言模型（Mixture-of-LLMs）的主动学习框架，用以替代人工标注，通过聚合多个LLM的优势提升标注鲁棒性，并引入标注差异性和负向学习来缓解噪声标签的影响。实验表明，该框架性能接近人工标注，优于单个LLM及现有集成方法，且基于轻量级LLM，可在本地设备上运行，适用于实际应用。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽具强大泛化能力，但其生成的标注质量难以满足真实应用场景需求，亟需提升基于LLM的标注可靠性与稳定性。

Method: 提出Mixture of LLMs in the Loop Active Learning框架，利用多LLM集成进行标注，结合标注差异性分析和负向学习机制识别并抑制不可靠标注，从而增强模型学习效果。

Result: 实验结果表明，该框架在多种任务上表现优异，性能接近人类标注水平，显著优于单个LLM基线及其他基于LLM集成的方法；同时具备轻量化特性，支持本地部署。

Conclusion: 所提出的多LLM主动学习框架有效提升了标注质量与模型鲁棒性，为低成本、高效率的真实世界标注提供了可行方案。

Abstract: With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.

</details>


### [146] [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)
*Fengheng Chu,Jiahao Chen,Yuhong Wang,Jun Wang,Zhihui Fu,Shouling Ji,Songze Li*

Main category: cs.LG

TL;DR: 本文提出GOSV框架，通过全局优化识别大语言模型中对安全至关重要的注意力头。采用有害修补和零消融两种互补的激活重贴策略，发现两类空间上分离的安全向量：恶意注入向量与安全抑制向量，表明对齐模型存在独立的安全功能路径。研究发现约30%的注意力头被重贴后会导致安全机制完全失效，并基于此开发了一种新型白盒越狱攻击方法，显著优于现有方法，验证了GOSV在可解释性上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖局部贪婪归因，忽略注意力头等组件间的协同作用，导致对安全机制理解不足；而当前大模型的安全防护仍易受越狱攻击影响，亟需更深入的理解以提升安全性。

Method: 提出GOSV框架，通过全局优化同时考虑所有注意力头，结合有害修补与零消融两种激活重贴策略，系统识别安全关键组件，并分析其交互特性与破坏阈值。

Result: 识别出两类空间上分离的安全向量（恶意注入向量与安全抑制向量），揭示了对齐模型中独立的安全功能路径；发现约30%注意力头被重贴即导致安全崩溃；基于此构建的新越狱攻击在所有测试模型上均显著优于现有白盒攻击方法。

Conclusion: GOSV框架有效揭示了大模型安全机制的内在结构，证明了组件间协作的重要性，为理解与增强模型安全提供了新范式。

Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.

</details>


### [147] [Why Inference in Large Models Becomes Decomposable After Training](https://arxiv.org/abs/2601.15871)
*Jidong Jin*

Main category: cs.LG

TL;DR: 该论文提出一种后训练的统计准则和结构退火方法，通过识别大规模模型中梯度更新的局部性和选择性，发现许多参数依赖在训练后与初始化分布无统计差异，从而揭示了推理系统的内在可分解性。该方法无需修改模型功能或接口，即可实现结构化、并行化推理，显著降低计算成本和系统复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前大规模AI模型的推理依赖密集参数矩阵，导致计算成本和系统复杂度随模型规模线性增长，难以持续扩展。这一问题并非源于模型容量不足，而是因为将推理系统视为整体操作，忽略了训练过程中形成的内部结构。

Method: 提出后训练统计准则与结构退火流程，通过移除不支持的参数依赖，识别出稳定且独立的子结构，实现对推理系统的结构性分解。

Result: 成功揭示了大型模型推理系统的非均匀结构特性，实现了无需修改模型功能的结构化、并行化推理，在保持原有接口的前提下大幅降低推理开销。

Conclusion: 大规模模型的推理系统具有内在的结构可分解性，通过后训练分析可高效重构为并行执行的独立子结构，为高效率、低成本推理提供了新范式。

Abstract: Inference in large-scale AI models is typically performed on dense parameter matrices, leading to inference cost and system complexity that scale unsustainably with model size. This limitation does not arise from insufficient model capacity, but from treating post-training inference systems as monolithic operators while ignoring internal structures formed during learning. We show that gradient update events in large models are highly localized and selective, leaving many parameter dependencies statistically indistinguishable from their initialization distribution after training. As a result, post-training inference systems are structurally non-uniform and inherently decomposable. Based on this observation, we introduce a post-training statistical criterion and a structural annealing procedure that removes unsupported dependencies and reveals stable, independent substructures. This work establishes a post-training, model-agnostic structural view of inference systems and enables structured, parallel inference without modifying model functionality or interfaces.

</details>


### [148] [Iterative Amortized Hierarchical VAE](https://arxiv.org/abs/2601.15894)
*Simon W. Penninga,Ruud J. G. van Sloun*

Main category: cs.LG

TL;DR: 本文提出了一种迭代摊销分层变分自编码器（IA-HVAE），通过结合初始摊销猜测和基于解码器梯度的迭代精炼，实现了高效的推理。该方法在变换域（如傅里叶空间）中设计线性可分离解码器，支持实时应用并实现极深模型。与传统HVAE相比，迭代推理速度提升35倍。该混合方法在准确性和速度上均优于纯摊销或纯迭代方案，并在去模糊、去噪等逆问题中表现出更优的重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统变分自编码器在处理深层模型时推理效率低，而纯摊销方法精度不足，纯迭代方法速度慢。需要一种兼顾高效与高精度的推理机制，尤其适用于实时应用和复杂逆问题。

Method: 提出IA-HVAE，采用初始摊销猜测与迭代精炼相结合的混合策略；在变换域（如傅里叶空间）设计线性可分离解码器，以加速梯度传播和迭代过程。

Result: 相较于传统HVAE，IA-HVAE在迭代推理上实现35倍速度提升；在准确性和速度上分别超越纯摊销和纯迭代方法；在去模糊、去噪等逆问题中重建质量显著优于标准HVAE。

Conclusion: IA-HVAE通过混合摊销与迭代推理机制，有效平衡了速度与精度，在深度模型和逆问题中展现出优越性能，具备实际应用潜力。

Abstract: In this paper we propose the Iterative Amortized Hierarchical Variational Autoencoder (IA-HVAE), which expands on amortized inference with a hybrid scheme containing an initial amortized guess and iterative refinement with decoder gradients. We achieve this by creating a linearly separable decoder in a transform domain (e.g. Fourier space), enabling real-time applications with very high model depths. The architectural change leads to a 35x speed-up for iterative inference with respect to the traditional HVAE. We show that our hybrid approach outperforms fully amortized and fully iterative equivalents in accuracy and speed respectively. Moreover, the IAHVAE shows improved reconstruction quality over a vanilla HVAE in inverse problems such as deblurring and denoising.

</details>


### [149] [Partially Lazy Gradient Descent for Smoothed Online Learning](https://arxiv.org/abs/2601.15984)
*Naram Mhaisen,George Iosifidis*

Main category: cs.LG

TL;DR: 提出k-lazyGD算法，连接贪婪OGD与懒惰梯度下降之间的谱系，在平滑在线凸优化中实现动态后悔的最优界，证明在允许的懒惰程度下可保持小移动而不牺牲跟踪性能，基于FTRL框架并给出匹配下界，通过多松弛度学习者集合实现稳定与敏捷的自适应。


<details>
  <summary>Details</summary>
Motivation: 在在线学习中平衡反应性与稳定性，解决传统方法在移动成本与追踪能力之间的权衡问题，特别是在平滑在线凸优化场景下。

Method: 基于FTRL框架设计k-lazyGD算法，通过分析不同懒惰松弛参数k对动态后悔的影响，结合路径长度PT推导出最优动态后悔界，并构造多松弛度学习者集成策略以实现自适应性能。

Result: k-lazyGD在任意懒惰松弛k ≤ Θ(√(T/PT))时达到最优动态后悔界O(√((PT+1)T))，证明了懒惰性可在不损失跟踪性能的前提下实现，且可通过多模型集成实现稳定与敏捷的自适应切换。

Conclusion: k-lazyGD成功建立了懒惰性与比较器路径变化之间的理论联系，实现了在移动成本与追踪性能间的理想平衡，为在线学习中的动态适应提供了新范式。

Abstract: We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\mathcal{O}(\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $Θ(\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.

</details>


### [150] [Data-Driven Conditional Flexibility Index](https://arxiv.org/abs/2601.16028)
*Moritz Wedemeyer,Eike Cramer,Alexander Mitsos,Manuel Dahmen*

Main category: cs.LG

TL;DR: 本文提出条件灵活性指数（CFI），通过学习历史数据中的参数化可接受不确定性集，并利用上下文信息使不确定性集条件化，以更准确地估计调度的鲁棒性。采用归一化流方法将高斯基分布映射到数据分布，构建潜在空间中的超球体不确定性集并映射回数据空间。实验表明，结合时间信息的CFI能提升调度质量，且数据驱动与条件化设置均能避免考虑不现实的参数区域。


<details>
  <summary>Details</summary>
Motivation: 传统灵活性指数使用简单集合（如超立方体）近似不确定区域，未充分利用预测等上下文信息。为提高调度决策的鲁棒性，需更精确地建模不确定性，尤其是在灵活化流程背景下。因此，需要一种能够结合历史数据和上下文信息的新型灵活性度量方法。

Method: 提出条件灵活性指数（CFI），利用归一化流学习从高斯分布到数据分布的双射映射，在潜在空间中构造超球形不确定性集，并将其映射回数据空间；同时引入上下文信息实现不确定性集的条件化，从而更精准地刻画实际可能发生的不确定性区域。

Result: CFI在安全约束机组组合实例中表现良好，能有效利用时间等上下文信息提升调度质量；相比传统方法，其生成的不确定性集更能反映真实发生的情景，避免无效区域的考虑；但数据驱动与条件化优势并非绝对，具体取决于场景。

Conclusion: CFI通过融合数据驱动与条件化设计，显著提升了灵活性评估的准确性与实用性，尤其在包含时间信息的调度问题中表现出色，为复杂系统中的鲁棒决策提供了新工具。

Abstract: With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.

</details>


### [151] [CLASP: An online learning algorithm for Convex Losses And Squared Penalties](https://arxiv.org/abs/2601.16072)
*Ricardo N. Ferreira,Cláudia Soares,João Xavier*

Main category: cs.LG

TL;DR: 本文研究约束在线凸优化（COCO），提出CLASP算法，通过最小化累积损失与平方约束违规项来处理凸损失和凸约束。该方法利用凸投影的非扩张性，对凸损失问题实现了$O(T^{\max\{β,1-β\}})$的后悔和$O(T^{1-β})$的平方惩罚；对于强凸问题，首次实现对数级的后悔和平方惩罚上界，均为$O(\log T)$。


<details>
  <summary>Details</summary>
Motivation: 现有研究在约束在线凸优化中未能充分利用凸投影的非扩张性质，且缺乏对强凸问题的对数级性能保证。本文旨在改进算法设计并提供更优的理论分析框架。

Method: 提出CLASP算法，结合凸损失与平方惩罚，基于凸投影的非扩张性进行理论分析，采用新的证明策略以获得更紧的上界。

Result: 对于凸损失，算法达到$O(T^{\max\{β,1-β\}})$的后悔和$O(T^{1-β})$的平方惩罚；对于强凸问题，首次实现$O(\log T)$的后悔和平方惩罚上界。

Conclusion: CLASP算法在凸和强凸场景下均表现出优异的性能，尤其在强凸情况下提供了首个对数级的综合性能保证，展示了新证明方法的有效性。

Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{β,1-β\}}\right)$ and cumulative squared penalty $O\left(T^{1-β}\right)$ for any $β\in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.

</details>


### [152] [Probably Approximately Correct Maximum A Posteriori Inference](https://arxiv.org/abs/2601.16083)
*Matthew Shorvon,Frederik Mallmann-Trenn,David S. Watson*

Main category: cs.LG

TL;DR: 本文提出了用于MAP推断的PAC算法，能够在有限计算预算下提供可证明最优的解。通过信息论度量来刻画PAC-MAP的可 tractability 条件，并利用概率电路实现高效求解。所提出的随机化策略既可作为独立的MAP推断方法，也可增强现有启发式算法的性能并提供严格保证。实验验证了该方法在多个基准测试中的有效性。


<details>
  <summary>Details</summary>
Motivation: MAP估计在概率推理中是基础任务，但通常难以计算，即使在常见结构约束和近似方案下也依然困难。需要一种能在有限计算资源下提供可靠解的算法，并具备理论保证。

Method: 提出PAC-MAP算法，利用信息论度量评估可计算性，基于具有合适架构的概率电路实现高效求解，并设计随机化策略以提升或替代传统启发式方法。

Result: 在多种基准测试中，所提方法表现出优越性能，能有效提供有理论保障的近似最优解，且适用于固定与可变计算预算场景。

Conclusion: PAC-MAP算法为MAP推断提供了新的理论框架和实用工具，能够在有限计算条件下实现可证明的最优性，显著提升了推断的可靠性与效率。

Abstract: Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.

</details>


### [153] [Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets](https://arxiv.org/abs/2601.16107)
*Adithya Sineesh,Akshita Kamsali*

Main category: cs.LG

TL;DR: 本研究首次系统性地比较了三种以上专为拉曼光谱分析设计的深度学习分类器，使用统一的训练和超参数调优协议，在多个开源拉曼数据集上进行评估。研究涵盖三个公开数据集，支持标准评估、微调和显式分布偏移测试，报告了分类准确率和宏平均F1分数，以实现对拉曼光谱分类深度学习模型的公平且可复现的比较。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在拉曼光谱分析中的评估往往孤立进行，或与传统机器学习方法及非专为拉曼设计的视觉架构进行简单对比，缺乏在共享开源数据集上针对专有模型的直接比较。因此，亟需一个系统性的基准测试来推动该领域的发展。

Method: 采用统一的训练与超参数调优流程，评估五种代表性深度学习架构在三个开源拉曼数据集上的表现，涵盖标准评估、微调和分布偏移测试。

Result: 报告了各模型在分类准确率和宏平均F1分数上的性能，提供了可复现的公平比较结果，揭示了不同模型在不同数据集上的相对优势。

Conclusion: 本研究为拉曼光谱分类中的深度学习模型提供了一个可靠且系统的基准，有助于未来模型开发与评估的标准化。

Abstract: Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.

</details>


### [154] [On the Intrinsic Dimensions of Data in Kernel Learning](https://arxiv.org/abs/2601.16139)
*Rustem Takhanov*

Main category: cs.LG

TL;DR: 本文研究核回归（KRR）中两种内在维度概念：基于核诱导度量的上Minkowski维数 $d_ρ$ 与由Kolmogorov $n$-宽度衰减率导出的有效维数 $d_K$。通过分析积分算子的特征值与 $n$-宽度的关系，证明 $d_K$ 可刻画所有概率测度下的最坏情况特征值衰减速率，并给出 $O(n^{-\frac{2+d_K}{2+2d_K} + ε})$ 的误差界。提出一种基于有限样本估计 $n$-宽度上界的算法，在近似均匀分布下，仅需 $O(ε^{-d_ρ}\log\frac{1}{ε})$ 样本即可高概率获得 $ε$-准确上界。数值实验显示，对Laplace核等情形，$d_K$ 可远小于 $d_ρ$，尽管在规则域上二者相等。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习中低内在维度对泛化性能的提升机制，尤其针对核方法中的有效维度定义及其在泛化误差分析中的作用。

Method: 结合Minkowski维数、Kolmogorov $n$-宽度与积分算子特征值分析，建立内在维度与泛化误差之间的理论联系；设计基于采样的算法以估计 $n$-宽度上界。

Result: 建立了 $d_K$ 与最坏情况特征值衰减的对应关系，推导出依赖于 $d_K$ 的泛化误差上界；提出可高效估计 $n$-宽度上界的算法，并验证其在分形集上的有效性；发现 $d_K$ 在某些核函数下显著低于 $d_ρ$。

Conclusion: 有效维数 $d_K$ 比 Minkowski 维数 $d_ρ$ 更能反映核方法中数据的真实复杂度，尤其在非规则或分形结构上，为理解低维假设下的泛化能力提供了更精细的理论工具。

Abstract: The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\to \int_ΩK(\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(ε^{-d_ρ}\log\frac{1}ε\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.

</details>


### [155] [Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets](https://arxiv.org/abs/2601.16147)
*Muhammad Ilham Rizqyawan,Peter Macfarlane,Stathis Hadjidemetriou,Fani Deligianni*

Main category: cs.LG

TL;DR: Beat-SSL 是一种用于心电图（ECG）的对比学习框架，通过节奏级和心跳级的双上下文对比学习，并使用软目标来更好地捕捉 ECG 信号中特征相似性的连续性。该方法在多标签分类和心电图分割任务上表现优异，优于现有方法，且在分类任务中达到其他基础模型93%的性能。


<details>
  <summary>Details</summary>
Motivation: 获取标注的 ECG 数据以训练监督模型具有挑战性。现有的对比学习方法要么只关注全局上下文，要么未能充分利用 ECG 的特定特征，同时依赖硬对比目标，无法有效反映特征相似性的连续性。因此，需要一种更适用于 ECG 信号特性的对比学习框架。

Method: 提出 Beat-SSL 框架，采用双上下文学习：节奏级和心跳级对比，使用软目标替代硬目标，以更好地建模特征间的连续相似性。通过预训练后在两个下游任务上进行评估：多标签分类（全局节律评估）和心电图分割。

Result: 在多标签分类任务中，Beat-SSL 达到其他基础模型 93% 的性能；在心电图分割任务中，超越所有其他方法 4%。消融实验验证了各组件的有效性。

Conclusion: Beat-SSL 通过结合节奏级与心跳级的双上下文对比学习及软目标机制，有效提升了 ECG 表示学习能力，在有限标注数据下表现出色，为低资源场景下的 ECG 分析提供了高效解决方案。

Abstract: Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model's broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.

</details>


### [156] [Learning to Discover at Test Time](https://arxiv.org/abs/2601.16175)
*Mert Yuksekgonul,Daniel Koceja,Xinhao Li,Federico Bianchi,Jed McCaleb,Xiaolong Wang,Jan Kautz,Yejin Choi,James Zou,Carlos Guestrin,Yu Sun*

Main category: cs.LG

TL;DR: TTT-Discover 使用测试时训练（Test-Time Training）结合强化学习，使冻结的大型语言模型在解决具体科学问题时持续学习，专注于发现单一最优解而非泛化表现。该方法在数学、GPU内核工程、算法设计和生物学等多个领域刷新了现有最佳性能，且使用开源模型和公开代码可复现，成本仅数百美元每问题。


<details>
  <summary>Details</summary>
Motivation: 传统测试时扩展方法（如AlphaEvolve）依赖提示冻结的LLM进行搜索，无法在测试阶段持续优化。为解决特定问题并找到最优解，需要一种能针对具体任务持续学习的方法，从而突破现有性能瓶颈。

Method: 提出Test-Time Training to Discover (TTT-Discover) 方法，通过在测试阶段对语言模型进行强化学习，利用与具体问题相关的经验持续训练，设计专门的学习目标和搜索子程序以优先探索最有希望的解决方案。

Result: TTT-Discover 在几乎所有尝试的问题中均达到新状态：包括埃拉多什最小重叠问题、自相关不等式、GPU内核竞赛（最高快2倍）、历史AtCoder算法竞赛及单细胞数据分析中的去噪问题，结果经专家或组织方评审认可。

Conclusion: TTT-Discover 展示了在测试阶段持续训练大模型的有效性，可在无需闭源前沿模型的前提下，高效生成高质量、可复现的科学解决方案，为AI驱动的科学发现提供了新范式。

Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.

</details>


### [157] [Counterfactual Training: Teaching Models Plausible and Actionable Explanations](https://arxiv.org/abs/2601.16205)
*Patrick Altmeyer,Aleksander Buszydlik,Arie van Deursen,Cynthia C. S. Liem*

Main category: cs.LG

TL;DR: 提出一种名为反事实训练的新颖训练方法，利用反事实解释增强模型的可解释性。该方法在训练阶段引入反事实，使模型学习到与合理、可操作的解释一致的表示，从而提升模型的可解释性和对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注后处理生成满足数据合理性与特征可变性约束的反事实解释，但缺乏在训练过程中直接引导模型产生理想反事实的能力。本文旨在通过将反事实纳入训练过程，使模型从一开始就具备生成高质量反事实解释的能力，以支持真实决策系统中的可信应用。

Method: 提出反事实训练框架，在模型训练中引入反事实样本，通过最小化模型表示与可解释反事实之间的差异，使模型学习到符合现实且可操作的解释路径。

Result: 实验和理论分析表明，该方法不仅使模型能够自然生成高质量的反事实解释，还显著提升了模型的对抗鲁棒性。

Conclusion: 反事实训练是一种有效的训练范式，能够使模型在训练阶段就具备生成合理、可操作反事实解释的能力，并同时增强其对对抗攻击的鲁棒性，为可信AI提供了新的方向。

Abstract: We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.

</details>
