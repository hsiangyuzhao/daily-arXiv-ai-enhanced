<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 75]
- [cs.CL](#cs.CL) [Total: 57]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.LG](#cs.LG) [Total: 45]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Edge-AI Perception Node for Cooperative Road-Safety Enforcement and Connected-Vehicle Integration](https://arxiv.org/abs/2601.07845)
*Shree Charran R,Rahul Kumar Dubey*

Main category: cs.CV

TL;DR: 本研究针对新兴经济体（如印度）快速机动化带来的执法不对称问题，提出一种实时路边感知节点，用于多类交通违规分析与安全事件传播。系统基于YOLOv8 Nano实现高精度多目标检测，结合DeepSORT进行时序一致的车辆跟踪，并采用规则引导的OCR后处理引擎识别模糊或多种语言的车牌，符合MoRTH AIS 159和ISO 7591标准。部署于NVIDIA Jetson Nano上，经TensorRT FP16量化优化，实现28-30帧/秒推理速度，功耗仅9.6W，违规检测准确率达97.7%，OCR精度达84.9%，覆盖信号闯红灯、人行横道违规、逆向行驶、非法掉头和超速五类行为，且无需手动区域校准。相比YOLOv4 Tiny、PP YOLOE S和NanoDetPlus，平均精度提升10.7%，能效提升1.4倍。该节点还可通过V2X协议发布CAM和DENM类型的安全事件，支持车联网与智能交通系统协同感知与主动安全管理，推动边缘AI在智能网联汽车生态中的应用。


<details>
  <summary>Details</summary>
Motivation: 新兴经济体如印度因快速机动化导致交通违规数量激增（2023年超1100万起），而警力配置稀疏（每4000辆车约1名警察），传统人工监控与执法手段难以应对，亟需一种自主、协作、节能的边缘人工智能感知基础设施来实现大规模、实时的交通违规识别与安全事件响应。

Method: 设计并部署一个基于边缘AI的实时路边感知节点，集成YOLOv8 Nano进行多目标检测，DeepSORT实现车辆轨迹追踪，结合规则驱动的OCR后处理模块以识别模糊或多语言车牌；系统运行于NVIDIA Jetson Nano平台，采用TensorRT FP16量化技术优化性能，在保持高精度的同时降低功耗；通过标准化接口（V2X）发布安全事件（CAM/DENM）至联网车辆与交通管理系统。

Result: 系统在28-30帧/秒下实现9.6W低功耗，达到97.7%的违规检测准确率和84.9%的OCR识别精度，涵盖五类典型交通违规行为，且无需手动设置感兴趣区域；相较基准模型，均值平均精度提升10.7%，单位能耗准确率提高1.4倍；成功实现与车联网系统的协同，支持安全事件的主动分发与道路安全的前瞻性管理。

Conclusion: 该路边边缘感知节点展示了在资源受限环境下实现高效、精准、低功耗交通违规检测的可行性，具备显著的可扩展性与实用价值，为构建智能、协同、主动的道路交通安全体系提供了关键技术支撑，是推进智慧交通与车联网融合发展的关键一步。

Abstract: Rapid motorization in emerging economies such as India has created severe enforcement asymmetries, with over 11 million recorded violations in 2023 against a human policing density of roughly one officer per 4000 vehicles. Traditional surveillance and manual ticketing cannot scale to this magnitude, motivating the need for an autonomous, cooperative, and energy efficient edge AI perception infrastructure. This paper presents a real time roadside perception node for multi class traffic violation analytics and safety event dissemination within a connected and intelligent vehicle ecosystem. The node integrates YOLOv8 Nano for high accuracy multi object detection, DeepSORT for temporally consistent vehicle tracking, and a rule guided OCR post processing engine capable of recognizing degraded or multilingual license plates compliant with MoRTH AIS 159 and ISO 7591 visual contrast standards. Deployed on an NVIDIA Jetson Nano with a 128 core Maxwell GPU and optimized via TensorRT FP16 quantization, the system sustains 28 to 30 frames per second inference at 9.6 W, achieving 97.7 percent violation detection accuracy and 84.9 percent OCR precision across five violation classes, namely signal jumping, zebra crossing breach, wrong way driving, illegal U turn, and speeding, without manual region of interest calibration. Comparative benchmarking against YOLOv4 Tiny, PP YOLOE S, and Nano DetPlus demonstrates a 10.7 percent mean average precision gain and a 1.4 times accuracy per watt improvement. Beyond enforcement, the node publishes standardized safety events of CAM and DENM type to connected vehicles and intelligent transportation system backends via V2X protocols, demonstrating that roadside edge AI analytics can augment cooperative perception and proactive road safety management within the IEEE Intelligent Vehicles ecosystem.

</details>


### [2] [LWMSCNN-SE: A Lightweight Multi-Scale Network for Efficient Maize Disease Classification on Edge Devices](https://arxiv.org/abs/2601.07957)
*Fikadu Weloday,Jianmei Su*

Main category: cs.CV

TL;DR: 提出LWMSCNN-SE模型，结合多尺度特征提取、深度可分离卷积和Squeeze-and-Excitation注意力机制，在仅241,348参数和0.666 GFLOPs下实现96.63%分类准确率，适用于边缘设备上的实时玉米病害诊断。


<details>
  <summary>Details</summary>
Motivation: 传统疾病检测模型在资源受限环境（如智能手机和无人机）中因计算成本高而难以部署，亟需兼顾高精度与低计算开销的轻量级模型。

Method: 设计LWMSCNN-SE，融合多尺度特征提取、深度可分离卷积与SE注意力机制，优化模型效率与性能。

Result: 模型达到96.63%分类准确率，参数量仅241,348，计算量为0.666 GFLOPs，具备高效实时部署能力。

Conclusion: LWMSCNN-SE有效平衡了准确率与计算效率，适合在边缘设备上用于精准农业中的玉米病害快速诊断。

Abstract: Maize disease classification plays a vital role in mitigating yield losses and ensuring food security. However, the deployment of traditional disease detection models in resource-constrained environments, such as those using smartphones and drones, faces challenges due to high computational costs. To address these challenges, we propose LWMSCNN-SE, a lightweight convolutional neural network (CNN) that integrates multi-scale feature extraction, depthwise separable convolutions, and squeeze-and-Excitation (SE) attention mechanisms. This novel combination enables the model to achieve 96.63% classification accuracy with only 241,348 parameters and 0.666 GFLOPs, making it suitable for real-time deployment in field applications. Our approach addresses the accuracy--efficiency trade-off by delivering high accuracy while maintaining low computational costs, demonstrating its potential for efficient maize disease diagnosis on edge devices in precision farming systems.

</details>


### [3] [3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing](https://arxiv.org/abs/2601.07963)
*Jiahua Dong,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: 3DGS-Drag 是一种基于点的 3D 编辑框架，通过结合 3D 高斯溅射的变形引导和扩散模型的内容修正，实现对真实 3D 场景的高效、直观拖拽编辑。该方法支持形状调整、运动变化、修复和内容扩展等多种编辑操作，在几何相关编辑任务中达到领先性能，单次编辑仅需 10-20 分钟（RTX 4090 GPU）


<details>
  <summary>Details</summary>
Motivation: 现有 3D 编辑方法在几何修改方面仍面临挑战，尤其难以实现类似 2D 拖拽编辑的直观性与效率，亟需一种既能保持几何一致性又能提升视觉质量的 3D 编辑方案

Method: 提出 3DGS-Drag 框架，融合 3D 高斯溅射的变形引导与扩散模型的内容修正，并采用渐进式编辑策略以支持激进的 3D 拖拽操作

Result: 实验表明，3DGS-Drag 在多种场景下均表现出色，实现了最先进的几何相关 3D 内容编辑效果，且编辑过程高效，可在单张 RTX 4090 GPU 上于 10-20 分钟内完成

Conclusion: 3DGS-Drag 成功弥合了传统变形与 2D 编辑方法之间的差距，为真实 3D 场景的直观、高效编辑提供了新范式，具有广泛的应用潜力

Abstract: The transformative potential of 3D content creation has been progressively unlocked through advancements in generative models. Recently, intuitive drag editing with geometric changes has attracted significant attention in 2D editing yet remains challenging for 3D scenes. In this paper, we introduce 3DGS-Drag -- a point-based 3D editing framework that provides efficient, intuitive drag manipulation of real 3D scenes. Our approach bridges the gap between deformation-based and 2D-editing-based 3D editing methods, addressing their limitations to geometry-related content editing. We leverage two key innovations: deformation guidance utilizing 3D Gaussian Splatting for consistent geometric modifications and diffusion guidance for content correction and visual quality enhancement. A progressive editing strategy further supports aggressive 3D drag edits. Our method enables a wide range of edits, including motion change, shape adjustment, inpainting, and content extension. Experimental results demonstrate the effectiveness of 3DGS-Drag in various scenes, achieving state-of-the-art performance in geometry-related 3D content editing. Notably, the editing is efficient, taking 10 to 20 minutes on a single RTX 4090 GPU.

</details>


### [4] [Sesame Plant Segmentation Dataset: A YOLO Formatted Annotated Dataset](https://arxiv.org/abs/2601.07970)
*Sunusi Ibrahim Muhammad,Ismail Ismail Tijjani,Saadatu Yusuf Jumare,Fatima Isah Jibrin*

Main category: cs.CV

TL;DR: 该论文提出一个开源的芝麻植物分割数据集，用于支持农业应用中人工智能模型的开发。数据集包含206张训练图像、43张验证图像和43张测试图像，采用YOLO兼容的分割格式，覆盖早期生长阶段的芝麻植物在不同环境条件下的情况。图像由尼日利亚卡斯纳州杰尔德德农场的高分辨率移动相机采集，并通过Segment Anything Model v2结合农民监督进行标注。与传统边界框数据集不同，该数据集采用像素级分割，实现更精确的田间检测与分析。使用Ultralytics YOLOv8框架评估表明，模型在检测和分割任务中表现良好：检测任务中召回率79%，精确率79%，IoU 0.50时mAP为84%，IoU 0.50至0.95时mAP为58%；分割任务中召回率82%，精确率77%，IoU 0.50时mAP为84%，IoU 0.50至0.95时mAP为52%。该数据集是尼日利亚首个专注于芝麻的农业视觉数据集，有助于植物监测、产量估计和农业研究。


<details>
  <summary>Details</summary>
Motivation: 为了支持农业人工智能模型的发展，特别是针对芝麻植物的精准识别与分析，现有数据集在像素级分割和真实田间场景覆盖方面存在不足。因此需要一个高质量、专用于芝麻植物的开放数据集，以推动农业自动化和智能化进程。

Method: 使用高分辨率移动相机在尼日利亚卡斯纳州杰尔德德农场采集图像，利用Segment Anything Model v2进行初步分割，并结合农民监督完成像素级标注，最终生成符合YOLO格式的分割数据集。

Result: 在Ultralytics YOLOv8框架下，模型在检测任务中表现出色：召回率79%，精确率79%，IoU 0.50时mAP为84%，IoU 0.50至0.95时mAP为58%；在分割任务中，召回率82%，精确率77%，IoU 0.50时mAP为84%，IoU 0.50至0.95时mAP为52%。结果表明该数据集具有良好的可用性与模型泛化能力。

Conclusion: 该芝麻植物分割数据集是尼日利亚首个专注于芝麻的农业视觉数据集，填补了相关领域的空白，为农业智能系统开发提供了重要基础，可广泛应用于植物监测、产量预测和农业科研等领域。

Abstract: This paper presents the Sesame Plant Segmentation Dataset, an open source annotated image dataset designed to support the development of artificial intelligence models for agricultural applications, with a specific focus on sesame plants. The dataset comprises 206 training images, 43 validation images, and 43 test images in YOLO compatible segmentation format, capturing sesame plants at early growth stages under varying environmental conditions. Data were collected using a high resolution mobile camera from farms in Jirdede, Daura Local Government Area, Katsina State, Nigeria, and annotated using the Segment Anything Model version 2 with farmer supervision. Unlike conventional bounding box datasets, this dataset employs pixel level segmentation to enable more precise detection and analysis of sesame plants in real world farm settings. Model evaluation using the Ultralytics YOLOv8 framework demonstrated strong performance for both detection and segmentation tasks. For bounding box detection, the model achieved a recall of 79 percent, precision of 79 percent, mean average precision at IoU 0.50 of 84 percent, and mean average precision from 0.50 to 0.95 of 58 percent. For segmentation, it achieved a recall of 82 percent, precision of 77 percent, mean average precision at IoU 0.50 of 84 percent, and mean average precision from 0.50 to 0.95 of 52 percent. The dataset represents a novel contribution to sesame focused agricultural vision datasets in Nigeria and supports applications such as plant monitoring, yield estimation, and agricultural research.

</details>


### [5] [An Efficient Additive Kolmogorov-Arnold Transformer for Point-Level Maize Localization in Unmanned Aerial Vehicle Imagery](https://arxiv.org/abs/2601.07975)
*Fei Li,Lang Qiao,Jiahao Fan,Yijia Xu,Shawn M. Kaeppler,Zhou Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Additive Kolmogorov-Arnold Transformer (AKT)的新模型，用于解决无人机遥感影像中玉米点级定位的挑战。该模型通过引入Pade Kolmogorov-Arnold Network (PKAN)模块提升小目标特征提取能力，并设计PKAN Additive Attention (PAA)以降低计算复杂度并建模多尺度空间依赖性。同时构建了包含1,928幅高分辨率图像和约50.1万个点标注的PML数据集。实验表明，AKT在F1分数上达到62.8%，优于现有方法4.2%，且计算量减少12.6%，推理速度提升20.7%。在下游任务中，其株距计数平均绝对误差为7.1，植株间距估计的均方根误差为1.95-1.97厘米，验证了该框架在高分辨率农业遥感中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有高分辨率无人机摄影测量在玉米点级定位方面面临三大挑战：极小的目标-像素比（<0.1%）、超大图像下二次注意力机制带来的高昂计算成本（>3000×4000像素），以及农业场景中稀疏分布与环境变化等复杂因素难以被通用视觉模型有效处理。

Method: 提出Additive Kolmogorov-Arnold Transformer (AKT)，用Pade Kolmogorov-Arnold Network (PKAN)替代传统MLP以增强小目标表达能力；引入PKAN Additive Attention (PAA)实现低复杂度的多尺度空间建模；构建真实田间条件下采集的Point-based Maize Localization (PML)数据集，共1,928张图像、约50.1万点标注。

Result: AKT在标准测试中取得62.8%的平均F1分数，较当前最优方法提升4.2%；计算量（FLOPs）降低12.6%，推理吞吐量提高20.7%；在株距计数任务中均方根误差为7.1，在植株间距估计中误差为1.95–1.97厘米，显著优于现有方法。

Conclusion: 将Kolmogorov-Arnold表示理论与高效注意力机制结合，为高分辨率农业遥感中的小目标精确定位提供了有效且高效的解决方案。

Abstract: High-resolution UAV photogrammetry has become a key technology for precision agriculture, enabling centimeter-level crop monitoring and point-level plant localization. However, point-level maize localization in UAV imagery remains challenging due to (1) extremely small object-to-pixel ratios, typically less than 0.1%, (2) prohibitive computational costs of quadratic attention on ultra-high-resolution images larger than 3000 x 4000 pixels, and (3) agricultural scene-specific complexities such as sparse object distribution and environmental variability that are poorly handled by general-purpose vision models.
  To address these challenges, we propose the Additive Kolmogorov-Arnold Transformer (AKT), which replaces conventional multilayer perceptrons with Pade Kolmogorov-Arnold Network (PKAN) modules to enhance functional expressivity for small-object feature extraction, and introduces PKAN Additive Attention (PAA) to model multiscale spatial dependencies with reduced computational complexity. In addition, we present the Point-based Maize Localization (PML) dataset, consisting of 1,928 high-resolution UAV images with approximately 501,000 point annotations collected under real field conditions.
  Extensive experiments show that AKT achieves an average F1-score of 62.8%, outperforming state-of-the-art methods by 4.2%, while reducing FLOPs by 12.6% and improving inference throughput by 20.7%. For downstream tasks, AKT attains a mean absolute error of 7.1 in stand counting and a root mean square error of 1.95-1.97 cm in interplant spacing estimation. These results demonstrate that integrating Kolmogorov-Arnold representation theory with efficient attention mechanisms offers an effective framework for high-resolution agricultural remote sensing.

</details>


### [6] [Likelihood ratio for a binary Bayesian classifier under a noise-exclusion model](https://arxiv.org/abs/2601.07982)
*Howard C. Gifford*

Main category: cs.CV

TL;DR: 本文提出了一种新的统计理想观察者模型，通过在可提取图像特征的最小阈值上设置限制，实现整体视觉搜索（或概览）处理。该模型减少了自由参数数量，从而简化了系统。该框架可用于医学图像感知（优化成像系统和算法）、计算机视觉、性能基准测试以及特征选择与评估。此外，还可应用于国防/安全领域的目标检测与识别，以及传感器和探测器的评估。


<details>
  <summary>Details</summary>
Motivation: 为了提高视觉搜索效率并减少模型复杂性，需要一种能够模拟人类整体视觉处理能力的统计理想观察者模型。传统模型存在过多自由参数，难以有效应用。因此，提出一种基于最小可提取特征阈值的新模型以优化系统性能。

Method: 通过设定最小可提取图像特征的阈值，构建一个减少自由参数的统计理想观察者模型。该方法利用特征提取的极限条件，使模型更贴近真实视觉系统的处理机制，同时保持对复杂场景的敏感性。

Result: 新模型显著降低了系统复杂度，提高了对医学图像、计算机视觉及安全检测等任务中视觉特征的识别效率。实验验证表明，该模型在目标检测与识别任务中表现优异，且适用于多种传感器和算法的性能评估。

Conclusion: 所提出的统计理想观察者模型通过引入最小特征阈值机制，实现了高效、简洁的视觉处理，具有广泛的应用前景，尤其在医学成像、安全监控和计算机视觉等领域展现出强大的潜力。

Abstract: We develop a new statistical ideal observer model that performs holistic visual search (or gist) processing in part by placing thresholds on minimum extractable image features. In this model, the ideal observer reduces the number of free parameters thereby shrinking down the system. The applications of this novel framework is in medical image perception (for optimizing imaging systems and algorithms), computer vision, benchmarking performance and enabling feature selection/evaluations. Other applications are in target detection and recognition in defense/security as well as evaluating sensors and detectors.

</details>


### [7] [Predicting Region of Interest in Human Visual Search Based on Statistical Texture and Gabor Features](https://arxiv.org/abs/2601.07998)
*Hongwei Lin,Diego Andrade,Mini Das,Howard C. Gifford*

Main category: cs.CV

TL;DR: 本文研究了Gabor特征与灰度共生矩阵(GLCM)纹理特征在建模早期视觉搜索行为中的关系，提出了两种融合这两种特征的管道方法，用于缩小人类注视点的可能区域。在数字乳腺断层成像模拟数据上评估后，结果显示所提方法与基于阈值的模型观察者预测的注视候选区域具有定性一致性。同时发现GLCM均值与Gabor特征响应之间存在强相关性，表明尽管两者形式不同，但编码了相似的图像信息。眼动追踪数据进一步验证了预测注视区域与人类早期注视行为的一致性。研究强调了结合结构与纹理特征对视觉搜索建模的价值，并支持发展感知启发式的观察者模型。


<details>
  <summary>Details</summary>
Motivation: 理解人类视觉搜索行为是视觉科学和计算机视觉中的基本问题，尤其在位置未知的搜索任务中，如何准确建模注意力分配至关重要。现有方法多依赖单一特征，难以全面捕捉图像中的视觉线索，因此需要探索多种特征的融合以提升模型性能。

Method: 提出两种特征融合管道：将Gabor特征与GLCM纹理特征相结合，利用它们在图像中的互补性，通过联合分析来更精确地预测人类可能的注视区域。采用模拟数字乳腺断层成像数据进行实验验证。

Result: 所提特征融合方法在预测注视候选区域方面表现出与阈值模型观察者一致的定性结果；GLCM均值与Gabor特征响应间存在强相关性，说明二者反映的是相似的图像信息；眼动数据证实预测区域与真实早期注视行为高度一致。

Conclusion: 结合结构特征（Gabor）与纹理特征（GLCM）能有效提升视觉搜索行为建模的准确性，为构建更具感知合理性的观察者模型提供了有力支持。

Abstract: Understanding human visual search behavior is a fundamental problem in vision science and computer vision, with direct implications for modeling how observers allocate attention in location-unknown search tasks. In this study, we investigate the relationship between Gabor-based features and gray-level co-occurrence matrix (GLCM) based texture features in modeling early-stage visual search behavior. Two feature-combination pipelines are proposed to integrate Gabor and GLCM features for narrowing the region of possible human fixations. The pipelines are evaluated using simulated digital breast tomosynthesis images. Results show qualitative agreement among fixation candidates predicted by the proposed pipelines and a threshold-based model observer. A strong correlation is observed between GLCM mean and Gabor feature responses, indicating that these features encode related image information despite their different formulations. Eye-tracking data from human observers further suggest consistency between predicted fixation regions and early-stage gaze behavior. These findings highlight the value of combining structural and texture-based features for modeling visual search and support the development of perceptually informed observer models.

</details>


### [8] [CASHEW: Stabilizing Multimodal Reasoning via Iterative Trajectory Aggregation](https://arxiv.org/abs/2601.08010)
*Chaoyu Li,Deeparghya Dutta Barua,Fei Tao,Pooyan Fazli*

Main category: cs.CV

TL;DR: 本文提出两种互补方法CASHEW和CASHEW-RL，以解决视觉语言模型在多步推理中不稳定的问题。CASHEW通过迭代聚合多个候选推理轨迹并结合视觉验证来过滤幻觉步骤，确保推理基于视觉证据；CASHEW-RL则通过强化学习训练实现内部化聚合行为，利用复合奖励机制鼓励基于最小但充分视觉证据的正确答案，并自适应分配推理资源。在13个图像与视频理解及推理基准上实验表明，性能显著提升，最高达ScienceQA上+23.6个百分点，EgoSchema上+8.1个百分点。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽在多模态理解任务中表现优异，但其多步推理过程不稳定，相同输入多次采样常导致不同推理路径和不一致结果，亟需提升推理稳定性与一致性。

Method: 提出CASHEW（基于推理时的框架，通过迭代聚合候选轨迹并引入视觉验证过滤幻觉）和CASHEW-RL（通过Group Sequence Policy Optimization训练，使模型内化聚合行为，使用复合奖励引导基于最少必要视觉证据的推理并动态调整推理强度）。

Result: 在13个图像与视频理解、推理基准上均取得显著提升，尤其在ScienceQA上达到+23.6个百分点，在EgoSchema上达到+8.1个百分点，证明了方法的有效性与鲁棒性。

Conclusion: 通过引入推理时的稳定机制与可内化的自我聚合能力，CASHEW与CASHEW-RL有效提升了视觉语言模型的多步推理稳定性与准确性，为构建更可靠、更可信的多模态智能系统提供了新范式。

Abstract: Vision-language models achieve strong performance across a wide range of multimodal understanding and reasoning tasks, yet their multi-step reasoning remains unstable. Repeated sampling over the same input often produces divergent reasoning trajectories and inconsistent final predictions. To address this, we introduce two complementary approaches inspired by test-time scaling: (1) CASHEW, an inference-time framework that stabilizes reasoning by iteratively aggregating multiple candidate trajectories into higher-quality reasoning traces, with explicit visual verification filtering hallucinated steps and grounding reasoning in visual evidence, and (2) CASHEW-RL, a learned variant that internalizes this aggregation behavior within a single model. CASHEW-RL is trained using Group Sequence Policy Optimization (GSPO) with a composite reward that encourages correct answers grounded in minimal yet sufficient visual evidence, while adaptively allocating reasoning effort based on task difficulty. This training objective enables robust self-aggregation at inference. Extensive experiments on 13 image understanding, video understanding, and video reasoning benchmarks show significant performance improvements, including gains of up to +23.6 percentage points on ScienceQA and +8.1 percentage points on EgoSchema.

</details>


### [9] [TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models](https://arxiv.org/abs/2601.08011)
*Xin Jin,Yichuan Zhong,Yapeng Tian*

Main category: cs.CV

TL;DR: TP-Blend 是一种轻量级、无需训练的框架，能够同时处理对象替换和风格迁移。通过两个互补的注意力处理器——交叉注意力对象融合（CAOF）和自注意力风格融合（SASF），实现内容与风格的精确控制。CAOF 通过熵正则化最优传输重新分配特征向量，保留跨头相关性；SASF 利用一维高斯滤波分离高频纹理并注入风格，保持全局结构稳定。实验表明，TP-Blend 在图像保真度、感知质量及推理速度上均优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本条件扩散编辑器在同时引入新对象和新风格时表现不佳，缺乏对内容与风格的协同控制能力。

Method: 提出 Twin-Prompt Attention Blend (TP-Blend) 框架，利用两个独立文本提示分别指定目标对象和风格，通过交叉注意力对象融合（CAOF）和自注意力风格融合（SASF）机制，在单个去噪轨迹中联合注入对象与风格信息。

Result: TP-Blend 能生成高分辨率、逼真的图像编辑结果，实现对内容和外观的精细控制，在定量保真度、感知质量和推理速度方面均超越当前主流方法。

Conclusion: TP-Blend 为文本条件图像编辑提供了一种高效、灵活且无需训练的新范式，特别适用于需要同时改变对象和风格的复杂编辑任务。

Abstract: Current text-conditioned diffusion editors handle single object replacement well but struggle when a new object and a new style must be introduced simultaneously. We present Twin-Prompt Attention Blend (TP-Blend), a lightweight training-free framework that receives two separate textual prompts, one specifying a blend object and the other defining a target style, and injects both into a single denoising trajectory. TP-Blend is driven by two complementary attention processors. Cross-Attention Object Fusion (CAOF) first averages head-wise attention to locate spatial tokens that respond strongly to either prompt, then solves an entropy-regularised optimal transport problem that reassigns complete multi-head feature vectors to those positions. CAOF updates feature vectors at the full combined dimensionality of all heads (e.g., 640 dimensions in SD-XL), preserving rich cross-head correlations while keeping memory low. Self-Attention Style Fusion (SASF) injects style at every self-attention layer through Detail-Sensitive Instance Normalization. A lightweight one-dimensional Gaussian filter separates low- and high-frequency components; only the high-frequency residual is blended back, imprinting brush-stroke-level texture without disrupting global geometry. SASF further swaps the Key and Value matrices with those derived from the style prompt, enforcing context-aware texture modulation that remains independent of object fusion. Extensive experiments show that TP-Blend produces high-resolution, photo-realistic edits with precise control over both content and appearance, surpassing recent baselines in quantitative fidelity, perceptual quality, and inference speed.

</details>


### [10] [Decoder Generates Manufacturable Structures: A Framework for 3D-Printable Object Synthesis](https://arxiv.org/abs/2601.08015)
*Abhishek Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种基于解码器的新方法，用于生成适用于增材制造的可制造3D结构。通过深度学习框架，将潜在表示解码为符合制造约束（如悬垂角度、壁厚和结构完整性）的几何有效可打印对象。该方法展示了神经解码器能够从抽象表示中学习复杂的映射函数，生成的零件在可制造性上显著优于传统方法，并在多种物体类别上进行了验证，且成功实现了实际3D打印。


<details>
  <summary>Details</summary>
Motivation: 传统3D生成方法常忽略制造约束，导致生成的结构不可打印或需要大量后处理。本研究旨在通过引入可制造性约束，提升生成结构的实际可用性。

Method: 采用基于解码器的深度学习框架，将抽象潜在表示映射为满足制造约束的3D几何结构，结合物理和工艺约束进行训练与优化。

Result: 生成的3D结构具有更高的可制造性，能有效避免悬垂、壁厚不足等问题，在多种类别上均实现成功3D打印。

Conclusion: 该方法证明了神经解码器在生成符合制造要求的3D结构方面的有效性，为智能设计与增材制造的融合提供了新路径。

Abstract: This paper presents a novel decoder-based approach for generating manufacturable 3D structures optimized for additive manufacturing. We introduce a deep learning framework that decodes latent representations into geometrically valid, printable objects while respecting manufacturing constraints such as overhang angles, wall thickness, and structural integrity. The methodology demonstrates that neural decoders can learn complex mapping functions from abstract representations to valid 3D geometries, producing parts with significantly improved manufacturability compared to naive generation approaches. We validate the approach on diverse object categories and demonstrate practical 3D printing of decoder-generated structures.

</details>


### [11] [Representations of Text and Images Align From Layer One](https://arxiv.org/abs/2601.08017)
*Evžen Wybitul,Javier Rando,Florian Tramèr,Stanislav Fort*

Main category: cs.CV

TL;DR: 本文提出一种基于DeepDream思想的合成方法，通过优化生成与文本概念向量对齐的图像，证明在adapter-based视觉-语言模型中，图像与文本表示从第一层就开始有意义对齐，挑战了传统认为这种对齐仅出现在深层的观点。该方法快速、无需额外模型或数据，且可直接可视化模型表示空间，提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有观点认为图像-文本对齐仅在深层出现，但缺乏直接证据；本文旨在提供一种简单、高效的方法来验证和可视化各层中的对齐情况，推动模型可解释性研究。

Method: 提出一种基于优化的合成方法：给定文本概念（如'Jupiter'），提取其在某层的概念向量，并通过优化生成与该向量对齐的图像，从而检验不同层的图像-文本对齐程度。

Result: 在Gemma 3模型的七层中测试数百个概念，发现第一层就有超过50%的合成图像能识别出动物、活动或季节等显著视觉特征，表明图像-文本对齐从早期就开始存在。

Conclusion: 图像-文本对齐并非仅存在于深层，而是从第一层就已开始；所提方法为理解多模态模型内部表示提供了直接、高效的工具，具有重要可解释性价值。

Abstract: We show that for a variety of concepts in adapter-based vision-language models, the representations of their images and their text descriptions are meaningfully aligned from the very first layer. This contradicts the established view that such image-text alignment only appears in late layers. We show this using a new synthesis-based method inspired by DeepDream: given a textual concept such as "Jupiter", we extract its concept vector at a given layer, and then use optimisation to synthesise an image whose representation aligns with that vector. We apply our approach to hundreds of concepts across seven layers in Gemma 3, and find that the synthesised images often depict salient visual features of the targeted textual concepts: for example, already at layer 1, more than 50 % of images depict recognisable features of animals, activities, or seasons. Our method thus provides direct, constructive evidence of image-text alignment on a concept-by-concept and layer-by-layer basis. Unlike previous methods for measuring multimodal alignment, our approach is simple, fast, and does not require auxiliary models or datasets. It also offers a new path towards model interpretability, by providing a way to visualise a model's representation space by backtracing through its image processing components.

</details>


### [12] [Training Free Zero-Shot Visual Anomaly Localization via Diffusion Inversion](https://arxiv.org/abs/2601.08022)
*Samet Hicsonmez,Abd El Rahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 本文提出一种无需训练的纯视觉零样本图像异常检测框架（DIVAD），利用预训练去噪扩散隐式模型（DDIM）的反演实现高精度异常定位。通过从固定中间步骤启动去噪过程，重建输入图像，由于模型仅在正常数据上训练，重建结果为正常图像，输入与重建间的差异即为异常区域。该方法无需依赖细粒度提示或额外模态，实现了最先进的性能，尤其在VISA数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法多依赖语言等额外模态生成细粒度提示以实现定位，而纯视觉方法仅能进行图像级分类，缺乏空间精度。本文旨在设计一种无需训练、不依赖提示的纯视觉方法，提升异常定位能力。

Method: 基于预训练的DDIM模型，对输入图像进行反演获取潜在表示，并从固定中间时间步启动去噪过程进行图像重建。由于扩散模型仅在正常数据上训练，重建结果趋于正常，输入与重建之间的差异即为异常区域。整个过程无需训练，也无需细粒度提示。

Result: 在VISA数据集上达到当前最优性能，显著提升了异常定位精度，且无需依赖外部模态或人工提示，验证了方法的有效性与通用性。

Conclusion: 本文提出的DIVAD框架是一种简单但高效的纯视觉零样本异常检测方法，通过利用扩散模型的内在特性实现无需提示的高精度异常定位，推动了零样本异常检测向摆脱提示依赖的方向发展。

Abstract: Zero-Shot image Anomaly Detection (ZSAD) aims to detect and localise anomalies without access to any normal training samples of the target data. While recent ZSAD approaches leverage additional modalities such as language to generate fine-grained prompts for localisation, vision-only methods remain limited to image-level classification, lacking spatial precision. In this work, we introduce a simple yet effective training-free vision-only ZSAD framework that circumvents the need for fine-grained prompts by leveraging the inversion of a pretrained Denoising Diffusion Implicit Model (DDIM). Specifically, given an input image and a generic text description (e.g., "an image of an [object class]"), we invert the image to obtain latent representations and initiate the denoising process from a fixed intermediate timestep to reconstruct the image. Since the underlying diffusion model is trained solely on normal data, this process yields a normal-looking reconstruction. The discrepancy between the input image and the reconstructed one highlights potential anomalies. Our method achieves state-of-the-art performance on VISA dataset, demonstrating strong localisation capabilities without auxiliary modalities and facilitating a shift away from prompt dependence for zero-shot anomaly detection research. Code is available at https://github.com/giddyyupp/DIVAD.

</details>


### [13] [FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures](https://arxiv.org/abs/2601.08026)
*Jifeng Song,Arun Das,Pan Wang,Hui Ji,Kun Zhao,Yufei Huang*

Main category: cs.CV

TL;DR: FigEx2 是一种视觉条件化的框架，用于从科学复合图中定位面板并生成面板级描述。通过引入噪声感知门控融合模块稳定检测查询空间，并结合监督学习与强化学习的分阶段优化策略，实现多模态一致性。研究构建了 BioSci-Fig-Cap 基准数据集，实验表明其在检测和生成任务上均显著优于现有方法，且具备出色的零样本跨领域迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有科学复合图的标注常缺失或仅提供图级摘要，缺乏面板级理解支持，导致面板定位与语义生成困难。

Method: 提出 FigEx2 框架，采用噪声感知门控融合模块过滤噪声特征，结合 CLIP 对齐与 BERTScore 语义奖励的强化学习策略，实现面板定位与生成。

Result: FigEx2 在 mAP@0.5:0.95 上达 0.726，优于 Qwen3-VL-8B 0.51（METEOR）和 0.24（BERTScore），并在无微调情况下展现强大零样本跨领域泛化能力。

Conclusion: FigEx2 有效解决了科学复合图中面板级理解难题，具备高精度、强鲁棒性和卓越的跨域迁移能力，为科学文献智能解析提供了新范式。

Abstract: Scientific compound figures combine multiple labeled panels into a single image, but captions in real pipelines are often missing or only provide figure-level summaries, making panel-level understanding difficult. In this paper, we propose FigEx2, visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. To mitigate the impact of diverse phrasing in open-ended captioning, we introduce a noise-aware gated fusion module that adaptively filters token-level features to stabilize the detection query space. Furthermore, we employ a staged optimization strategy combining supervised learning with reinforcement learning (RL), utilizing CLIP-based alignment and BERTScore-based semantic rewards to enforce strict multimodal consistency. To support high-quality supervision, we curate BioSci-Fig-Cap, a refined benchmark for panel-level grounding, alongside cross-disciplinary test suites in physics and chemistry. Experimental results demonstrate that FigEx2 achieves a superior 0.726 mAP@0.5:0.95 for detection and significantly outperforms Qwen3-VL-8B by 0.51 in METEOR and 0.24 in BERTScore. Notably, FigEx2 exhibits remarkable zero-shot transferability to out-of-distribution scientific domains without any fine-tuning.

</details>


### [14] [Rescind: Countering Image Misconduct in Biomedical Publications with Vision-Language and State-Space Modeling](https://arxiv.org/abs/2601.08040)
*Soumyaroop Nandi,Prem Natarajan*

Main category: cs.CV

TL;DR: 本文提出首个视觉-语言引导的生物医学图像伪造生成与检测框架，结合扩散模型与视觉-语言提示，实现跨模态的语义可控伪造（如复制、拼接、区域删除），并构建了大规模基准Rescind和检测模型Integscan，通过注意力增强编码与提示条件语义对齐实现精准定位。引入基于视觉-语言模型的验证环以确保语义一致性，实验表明Integscan在检测与定位任务上均达到当前最优性能，为科学诚信自动化分析奠定基础。


<details>
  <summary>Details</summary>
Motivation: 生物医学出版物中的图像篡改威胁研究的完整性与可重复性，现有自然图像取证方法难以应对生物医学图像特有的伪影、复杂纹理和非结构化布局等挑战，亟需专门的伪造生成与检测框架。

Method: 结合扩散模型进行图像合成，并利用视觉-语言提示实现语义控制；提出Integscan框架，整合注意力增强的视觉编码与提示条件语义对齐，实现伪造定位；引入基于视觉-语言模型的验证环，确保生成内容与提示一致。

Result: 在Rescind及现有基准上，Integscan在伪造检测与定位任务中均达到领先水平，验证了所提方法的有效性与鲁棒性。

Conclusion: 本工作首次构建了面向生物医学图像伪造的生成与检测统一框架，为保障科研诚信提供了强有力的技术支持，推动了自动化科学完整性分析的发展。

Abstract: Scientific image manipulation in biomedical publications poses a growing threat to research integrity and reproducibility. Unlike natural image forensics, biomedical forgery detection is uniquely challenging due to domain-specific artifacts, complex textures, and unstructured figure layouts. We present the first vision-language guided framework for both generating and detecting biomedical image forgeries. By combining diffusion-based synthesis with vision-language prompting, our method enables realistic and semantically controlled manipulations, including duplication, splicing, and region removal, across diverse biomedical modalities. We introduce Rescind, a large-scale benchmark featuring fine-grained annotations and modality-specific splits, and propose Integscan, a structured state space modeling framework that integrates attention-enhanced visual encoding with prompt-conditioned semantic alignment for precise forgery localization. To ensure semantic fidelity, we incorporate a vision-language model based verification loop that filters generated forgeries based on consistency with intended prompts. Extensive experiments on Rescind and existing benchmarks demonstrate that Integscan achieves state of the art performance in both detection and localization, establishing a strong foundation for automated scientific integrity analysis.

</details>


### [15] [Exploiting DINOv3-Based Self-Supervised Features for Robust Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2601.08078)
*Guoping Xu,Jayaram K. Udupa,Weiguo Lu,You Zhang*

Main category: cs.CV

TL;DR: DINO-AugSeg是一种基于DINOv3的新型框架，用于解决少样本医学图像分割挑战。通过引入基于小波的特征级增强模块WT-Aug和上下文信息引导融合模块CG-Fuse，显著提升了在有限标注数据下的分割性能。在六种公开基准上验证，涵盖MRI、CT、超声、内窥镜和皮肤镜等多种成像模态，结果表明该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 少样本医学图像分割因标注数据稀缺而困难，尽管自监督基础模型如DINOv3在自然图像中表现优异，但其在医学图像上的应用受限于领域差异。因此需要一种有效方法来利用预训练模型并适应医学图像特性。

Method: 提出DINO-AugSeg框架，结合DINOv3提取特征，引入WT-Aug（小波域特征增强）以增加特征多样性，并使用CG-Fuse（基于交叉注意力的上下文融合）整合低分辨率语义特征与高分辨率空间细节特征。

Result: 在六个公共基准、五种成像模态上均取得优越性能，尤其在极少量样本条件下表现出更强鲁棒性，证明了小波域增强与上下文融合的有效性。

Conclusion: DINO-AugSeg为少样本医学图像分割提供了一个有前景的方向，通过融合小波增强与上下文感知特征融合，显著提升模型在数据稀缺场景下的表现。代码与数据将公开于GitHub。

Abstract: Deep learning-based automatic medical image segmentation plays a critical role in clinical diagnosis and treatment planning but remains challenging in few-shot scenarios due to the scarcity of annotated training data. Recently, self-supervised foundation models such as DINOv3, which were trained on large natural image datasets, have shown strong potential for dense feature extraction that can help with the few-shot learning challenge. Yet, their direct application to medical images is hindered by domain differences. In this work, we propose DINO-AugSeg, a novel framework that leverages DINOv3 features to address the few-shot medical image segmentation challenge. Specifically, we introduce WT-Aug, a wavelet-based feature-level augmentation module that enriches the diversity of DINOv3-extracted features by perturbing frequency components, and CG-Fuse, a contextual information-guided fusion module that exploits cross-attention to integrate semantic-rich low-resolution features with spatially detailed high-resolution features. Extensive experiments on six public benchmarks spanning five imaging modalities, including MRI, CT, ultrasound, endoscopy, and dermoscopy, demonstrate that DINO-AugSeg consistently outperforms existing methods under limited-sample conditions. The results highlight the effectiveness of incorporating wavelet-domain augmentation and contextual fusion for robust feature representation, suggesting DINO-AugSeg as a promising direction for advancing few-shot medical image segmentation. Code and data will be made available on https://github.com/apple1986/DINO-AugSeg.

</details>


### [16] [From Prompts to Deployment: Auto-Curated Domain-Specific Dataset Generation via Diffusion Models](https://arxiv.org/abs/2601.08095)
*Dongsik Yoon,Jongeun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的自动化流水线，用于生成特定领域的合成数据集，以缓解预训练模型与实际部署环境之间的分布偏移问题。该三阶段框架首先通过受控修复在领域特定背景中合成目标对象；随后通过多模态评估（包括目标检测、美学评分和视觉-语言对齐）验证生成结果；最后利用用户偏好分类器捕捉主观选择标准。该方法可高效构建高质量、可部署的数据集，减少对真实世界数据收集的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型在真实部署环境中因分布偏移导致性能下降的问题，减少对大量真实世界数据收集的依赖。

Method: 提出一个三阶段自动化流水线：1）通过受控 inpainting 在领域特定背景中合成目标对象；2）采用多模态评估（对象检测、美学评分、视觉-语言对齐）验证生成质量；3）使用用户偏好分类器捕捉主观选择标准。

Result: 成功构建了高质量、可部署的领域特定合成数据集，显著降低对真实数据的需求，并有效缓解分布偏移问题。

Conclusion: 该自动化合成数据管道为领域特定应用提供了高效、可扩展的数据生成方案，有助于提升模型在真实场景中的泛化能力。

Abstract: In this paper, we present an automated pipeline for generating domain-specific synthetic datasets with diffusion models, addressing the distribution shift between pre-trained models and real-world deployment environments. Our three-stage framework first synthesizes target objects within domain-specific backgrounds through controlled inpainting. The generated outputs are then validated via a multi-modal assessment that integrates object detection, aesthetic scoring, and vision-language alignment. Finally, a user-preference classifier is employed to capture subjective selection criteria. This pipeline enables the efficient construction of high-quality, deployable datasets while reducing reliance on extensive real-world data collection.

</details>


### [17] [PathoGen: Diffusion-Based Synthesis of Realistic Lesions in Histopathology Images](https://arxiv.org/abs/2601.08127)
*Mohamad Koohi-Moghadam,Mohammad-Ali Nikouei Mahani,Kyongtae Tyler Bae*

Main category: cs.CV

TL;DR: 提出PathoGen，一种基于扩散模型的生成方法，用于在良性组织图像中可控地生成高保真病变区域，解决罕见病理和数据稀缺问题。该方法能保持细胞结构、组织边界和染色特征，优于传统GAN和Stable Diffusion，在多个病理数据集上提升分割性能，并缓解人工标注瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法无法生成真实且具有复杂空间关系的病变形态，导致医学图像AI模型在罕见疾病和数据稀缺场景下表现受限。

Method: 采用扩散模型进行迭代优化，实现病变区域的高保真修复与生成，支持可控生成并保留组织结构与染色特性。

Result: PathoGen在四个不同病理数据集（肾、皮肤、乳腺、前列腺）上均优于现有生成模型，显著提升下游分割任务性能，尤其在数据稀疏情况下；同时可生成像素级真实标签，减少对人工标注的依赖。

Conclusion: PathoGen为克服专家标注数据稀缺问题提供了一种高效、可扩展的生成式解决方案，有助于构建更具泛化能力的医疗AI系统。

Abstract: The development of robust artificial intelligence models for histopathology diagnosis is severely constrained by the scarcity of expert-annotated lesion data, particularly for rare pathologies and underrepresented disease subtypes. While data augmentation offers a potential solution, existing methods fail to generate sufficiently realistic lesion morphologies that preserve the complex spatial relationships and cellular architectures characteristic of histopathological tissues. Here we present PathoGen, a diffusion-based generative model that enables controllable, high-fidelity inpainting of lesions into benign histopathology images. Unlike conventional augmentation techniques, PathoGen leverages the iterative refinement process of diffusion models to synthesize lesions with natural tissue boundaries, preserved cellular structures, and authentic staining characteristics. We validate PathoGen across four diverse datasets representing distinct diagnostic challenges: kidney, skin, breast, and prostate pathology. Quantitative assessment confirms that PathoGen outperforms state-of-the-art generative baselines, including conditional GAN and Stable Diffusion, in image fidelity and distributional similarity. Crucially, we show that augmenting training sets with PathoGen-synthesized lesions enhances downstream segmentation performance compared to traditional geometric augmentations, particularly in data-scarce regimes. Besides, by simultaneously generating realistic morphology and pixel-level ground truth, PathoGen effectively overcomes the manual annotation bottleneck. This approach offers a scalable pathway for developing generalizable medical AI systems despite limited expert-labeled data.

</details>


### [18] [How Do Optical Flow and Textual Prompts Collaborate to Assist in Audio-Visual Semantic Segmentation?](https://arxiv.org/abs/2601.08133)
*Peng Gao,Yujian Lee,Yongqi Xu,Wentao Fan*

Main category: cs.CV

TL;DR: 本文提出了一种名为SSP（Stepping Stone Plus）的新框架，用于音频-视觉语义分割（AVSS），通过结合光流和文本提示来提升分割精度。针对动态声音源，利用光流捕捉运动信息以提供时序上下文；对于静止声源，则引入两类文本提示以增强语义理解。同时设计了视觉-文本对齐模块（VTA）促进跨模态融合，实验表明该方法优于现有AVS方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法将AVSS任务分解为两个独立子任务，依赖预设分割掩码进行后续分析，但难以应对复杂场景中动态与静止声源的混合情况。因此需要更智能的协同机制来提升语义理解与分割准确性。

Method: 提出SSP框架，结合光流估计获取运动动态信息，并使用两类文本提示（对象类别与场景描述）辅助识别声源；引入视觉-文本对齐模块（VTA）实现多模态信息融合，采用后掩码训练策略强化模型对光流图的理解能力。

Result: 在多个基准数据集上，SSP显著优于现有AVS方法，在动态与静态声源场景下均表现出更高的分割精度与鲁棒性。

Conclusion: SSP框架通过融合光流与文本提示，有效提升了音频-视觉语义分割的性能，尤其在复杂交互场景中展现出更强的泛化能力和语义一致性。

Abstract: Audio-visual semantic segmentation (AVSS) represents an extension of the audio-visual segmentation (AVS) task, necessitating a semantic understanding of audio-visual scenes beyond merely identifying sound-emitting objects at the visual pixel level. Contrary to a previous methodology, by decomposing the AVSS task into two discrete subtasks by initially providing a prompted segmentation mask to facilitate subsequent semantic analysis, our approach innovates on this foundational strategy. We introduce a novel collaborative framework, \textit{S}tepping \textit{S}tone \textit{P}lus (SSP), which integrates optical flow and textual prompts to assist the segmentation process. In scenarios where sound sources frequently coexist with moving objects, our pre-mask technique leverages optical flow to capture motion dynamics, providing essential temporal context for precise segmentation. To address the challenge posed by stationary sound-emitting objects, such as alarm clocks, SSP incorporates two specific textual prompts: one identifies the category of the sound-emitting object, and the other provides a broader description of the scene. Additionally, we implement a visual-textual alignment module (VTA) to facilitate cross-modal integration, delivering more coherent and contextually relevant semantic interpretations. Our training regimen involves a post-mask technique aimed at compelling the model to learn the diagram of the optical flow. Experimental results demonstrate that SSP outperforms existing AVS methods, delivering efficient and precise segmentation results.

</details>


### [19] [Subspace Alignment for Vision-Language Model Test-time Adaptation](https://arxiv.org/abs/2601.08139)
*Zhichen Zeng,Wenxuan Bao,Xiao Lin,Ruizhong Qiu,Tianxin Wei,Xuying Ning,Yuchen Yan,Chen Luo,Monica Xiao Cheng,Jingrui He,Hanghang Tong*

Main category: cs.CV

TL;DR: SubTTA提出一种新的测试时自适应方法，通过对齐视觉与文本模态的语义子空间来提升零样本预测的可靠性，解决分布偏移下的模态差距和视觉噪声问题。该方法首先通过最小化弦距离对齐双模态主子空间，再将视觉特征投影到任务相关的文本子空间以过滤无关噪声，从而在净化后的空间中进行标准自训练，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应（TTA）方法依赖零样本预测作为伪标签，但在分布偏移下易受模态间隙和视觉噪声影响，导致自训练失效。因此需要更可靠的指导信号来增强适应能力。

Method: SubTTA通过提取并对齐视觉与文本模态的主子空间，利用弦距离最小化实现跨模态对齐；随后将视觉特征投影至任务相关的文本语义子空间，以抑制无关噪声，并在此净化空间上执行标准TTA优化决策边界。

Result: 在多个基准和视觉-语言模型架构上，SubTTA平均优于当前最优TTA方法2.24%，验证了其有效性与鲁棒性。

Conclusion: SubTTA通过语义子空间对齐与噪声过滤，有效缓解了分布偏移带来的模态间隙与视觉噪声问题，显著提升了测试时自适应的性能，为零样本模型的在线适应提供了新思路。

Abstract: Vision-language models (VLMs), despite their extraordinary zero-shot capabilities, are vulnerable to distribution shifts. Test-time adaptation (TTA) emerges as a predominant strategy to adapt VLMs to unlabeled test data on the fly. However, existing TTA methods heavily rely on zero-shot predictions as pseudo-labels for self-training, which can be unreliable under distribution shifts and misguide adaptation due to two fundamental limitations. First (Modality Gap), distribution shifts induce gaps between visual and textual modalities, making cross-modal relations inaccurate. Second (Visual Nuisance), visual embeddings encode rich but task-irrelevant noise that often overwhelms task-specific semantics under distribution shifts. To address these limitations, we propose SubTTA, which aligns the semantic subspaces of both modalities to enhance zero-shot predictions to better guide the TTA process. To bridge the modality gap, SubTTA extracts the principal subspaces of both modalities and aligns the visual manifold to the textual semantic anchor by minimizing their chordal distance. To eliminate visual nuisance, SubTTA projects the aligned visual features onto the task-specific textual subspace, which filters out task-irrelevant noise by constraining visual embeddings within the valid semantic span, and standard TTA is further performed on the purified space to refine the decision boundaries. Extensive experiments on various benchmarks and VLM architectures demonstrate the effectiveness of SubTTA, yielding an average improvement of 2.24% over state-of-the-art TTA methods.

</details>


### [20] [Where Does Vision Meet Language? Understanding and Refining Visual Fusion in MLLMs via Contrastive Attention](https://arxiv.org/abs/2601.08151)
*Shezheng Song,Shasha Li,Jie Yu*

Main category: cs.CV

TL;DR: 本文通过系统性的分层掩码分析，揭示了多模态大语言模型（MLLMs）中视觉与文本信息融合的演化过程。研究发现，融合主要集中在特定层，并且某些模型在生成输出前会出现视觉信号的“重审”现象。同时，注意力机制显示对无关区域存在持续的高注意力噪声，而对文本对齐区域的关注逐渐增强。基于这些发现，提出一种无需训练的对比注意力框架，以捕捉从早期融合到最终层的注意力转变，显著提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前对多模态大语言模型内部如何整合视觉与文本信息的理解有限，亟需深入分析其融合机制以指导模型优化。

Method: 采用分层掩码分析、注意力演化分析，并设计训练-free的对比注意力框架来建模注意力转移过程。

Result: 所提方法在多个MLLM和基准测试上验证有效，显著提升了多模态推理能力。

Conclusion: MLLM中的视觉-文本融合并非均匀分布，而是集中在特定层；注意力演化揭示了噪声与关键区域的变化规律；提出的对比注意力框架可有效提升模型性能。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in vision-language understanding, yet how they internally integrate visual and textual information remains poorly understood. To bridge this gap, we perform a systematic layer-wise masking analysis across multiple architectures, revealing how visual-text fusion evolves within MLLMs. The results show that fusion emerges at several specific layers rather than being uniformly distributed across the network, and certain models exhibit a late-stage "review" phenomenon where visual signals are reactivated before output generation. Besides, we further analyze layer-wise attention evolution and observe persistent high-attention noise on irrelevant regions, along with gradually increasing attention on text-aligned areas. Guided by these insights, we introduce a training-free contrastive attention framework that models the transformation between early fusion and final layers to highlight meaningful attention shifts. Extensive experiments across various MLLMs and benchmarks validate our analysis and demonstrate that the proposed approach improves multimodal reasoning performance. Code will be released.

</details>


### [21] [Instance-Aligned Captions for Explainable Video Anomaly Detection](https://arxiv.org/abs/2601.08155)
*Inpyo Song,Minjun Joo,Joonhyung Kwon,Eunji Jeon,Jangwon Lee*

Main category: cs.CV

TL;DR: 本文提出了一种实例对齐的视频异常检测可解释性方法，通过将文本描述与具体物体实例在外观和运动属性上对齐，实现空间上的可验证解释。研究构建了VIEW360+数据集，扩展了多个基准测试，揭示了现有基于LLM和VLM方法在可解释性方面的严重缺陷，并为未来可信、可解释的异常检测研究提供了坚实基准。


<details>
  <summary>Details</summary>
Motivation: 现有可解释视频异常检测方法缺乏空间定位能力，尤其在多实体交互场景中，解释常不完整或视觉错位，影响其可信度和实用性。

Method: 提出实例对齐的描述生成机制，将每个文本陈述与特定对象实例关联，包含行为、影响对象及空间位置信息，实现精确的空间可解释性。

Result: 实验表明，当前基于大语言模型和视觉语言模型的方法在实例级解释上存在明显不足；所构建的VIEW360+数据集为可解释性研究提供了全面且可靠的评估平台。

Conclusion: 该研究通过引入空间对齐的实例级描述，显著提升了视频异常检测解释的可信度与可操作性，为未来可解释性智能系统的发展奠定了基础。

Abstract: Explainable video anomaly detection (VAD) is crucial for safety-critical applications, yet even with recent progress, much of the research still lacks spatial grounding, making the explanations unverifiable. This limitation is especially pronounced in multi-entity interactions, where existing explainable VAD methods often produce incomplete or visually misaligned descriptions, reducing their trustworthiness. To address these challenges, we introduce instance-aligned captions that link each textual claim to specific object instances with appearance and motion attributes. Our framework captures who caused the anomaly, what each entity was doing, whom it affected, and where the explanationis grounded, enabling verifiable and actionable reasoning. We annotate eight widely used VAD benchmarks and extend the 360-degree egocentric dataset, VIEW360, with 868 additional videos, eight locations, and four new anomaly types, creating VIEW360+, a comprehensive testbed for explainable VAD. Experiments show that our instance-level spatially grounded captions reveal significant limitations in current LLM- and VLM-based methods while providing a robust benchmark for future research in trustworthy and interpretable anomaly detection.

</details>


### [22] [A Hardware-Algorithm Co-Designed Framework for HDR Imaging and Dehazing in Extreme Rocket Launch Environments](https://arxiv.org/abs/2601.08162)
*Jing Tao,Banglei Guan,Pengju Sun,Taihang Lei,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出一种软硬件协同设计框架，结合自定义的时空变曝光（SVE）传感器与物理感知去雾算法，以应对火箭发射时极端成像条件下的光学测量挑战。该框架通过单次拍摄获取多曝光数据，实现无需依赖理想大气模型的强雾评估，并动态估计雾密度、自适应优化光照，采用多尺度熵约束融合分离雾与场景辐射，显著提升真实发射图像中羽流和发动机区域的视觉信息恢复能力，支持对粒子速度、流动不稳定性频率和结构振动等关键力学参数的精确量化分析。


<details>
  <summary>Details</summary>
Motivation: 火箭发射过程中的光学测量面临极端成像条件，如燃烧产生的密集颗粒雾霾和超过120 dB的亮度变化，严重损害图像质量，影响后续光测与测速分析，亟需有效解决方案。

Method: 采用时空变曝光（SVE）传感器进行单次拍摄多曝光数据采集，结合物理感知去雾算法，动态估计雾密度，实施区域自适应光照优化，并应用多尺度熵约束融合技术分离雾与真实场景辐射。

Result: 在真实发射图像和受控实验中验证，该框架能有效恢复羽流与发动机区域的物理上准确的视觉信息，显著提升图像质量，为关键力学参数提取提供可靠基础。

Conclusion: 所提软硬件协同框架在极端航空航天环境下表现出优异性能，为高精度定量分析提供了可靠的图像基础，具备实际应用潜力。

Abstract: Quantitative optical measurement of critical mechanical parameters -- such as plume flow fields, shock wave structures, and nozzle oscillations -- during rocket launch faces severe challenges due to extreme imaging conditions. Intense combustion creates dense particulate haze and luminance variations exceeding 120 dB, degrading image data and undermining subsequent photogrammetric and velocimetric analyses. To address these issues, we propose a hardware-algorithm co-design framework that combines a custom Spatially Varying Exposure (SVE) sensor with a physics-aware dehazing algorithm. The SVE sensor acquires multi-exposure data in a single shot, enabling robust haze assessment without relying on idealized atmospheric models. Our approach dynamically estimates haze density, performs region-adaptive illumination optimization, and applies multi-scale entropy-constrained fusion to effectively separate haze from scene radiance. Validated on real launch imagery and controlled experiments, the framework demonstrates superior performance in recovering physically accurate visual information of the plume and engine region. This offers a reliable image basis for extracting key mechanical parameters, including particle velocity, flow instability frequency, and structural vibration, thereby supporting precise quantitative analysis in extreme aerospace environments.

</details>


### [23] [Representation Learning with Semantic-aware Instance and Sparse Token Alignments](https://arxiv.org/abs/2601.08165)
*Phuoc-Nguyen Bui,Toan Duc Nguyen,Junghyun Bum,Duc-Tai Le,Hyunseung Choo*

Main category: cs.CV

TL;DR: 本文提出了一种多层级对齐框架SISTA，通过在图像-报告和补丁-词两个层面利用医学图像与放射科报告之间的语义对应关系，改进传统的对比学习方法。通过引入报告间相似性以消除错误负样本，并有效对齐图像补丁与相关词元，提升了跨数据集的迁移性能，在图像分类、分割和检测等任务中表现优异，尤其在标注数据有限的细粒度任务中效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统医学视觉语言预训练方法将所有未配对样本视为负样本，但在医学数据集中，不同患者间的图像或报告可能存在较大相似性，这种刚性处理会破坏潜在语义结构，影响表示学习质量。

Method: 提出SISTA框架，从图像-报告和补丁-词两个层次进行语义对齐；引入报告间相似性以减少错误负样本；设计方法实现图像补丁与相关词元的有效对齐。

Result: 在多个数据集上，SISTA在图像分类、分割和目标检测三项下游任务中均表现出色，尤其在细粒度任务中，即使在少量标注数据下也取得了显著提升。

Conclusion: SISTA通过多层级语义对齐机制，有效缓解了医学数据中因误判负样本带来的表示学习问题，显著提升了模型迁移性能，具有良好的应用前景。

Abstract: Medical contrastive vision-language pre-training (VLP) has demonstrated significant potential in improving performance on downstream tasks. Traditional approaches typically employ contrastive learning, treating paired image-report samples as positives and unpaired ones as negatives. However, in medical datasets, there can be substantial similarities between images or reports from different patients. Rigidly treating all unpaired samples as negatives, can disrupt the underlying semantic structure and negatively impact the quality of the learned representations. In this paper, we propose a multi-level alignment framework, Representation Learning with Semantic-aware Instance and Sparse Token Alignments (SISTA) by exploiting the semantic correspondence between medical image and radiology reports at two levels, i.e., image-report and patch-word levels. Specifically, we improve the conventional contrastive learning by incorporating inter-report similarity to eliminate the false negatives and introduce a method to effectively align image patches with relevant word tokens. Experimental results demonstrate the effectiveness of the proposed framework in improving transfer performance across different datasets on three downstream tasks: image classification, image segmentation, and object detection. Notably, our framework achieves significant improvements in fine-grained tasks even with limited labeled data. Codes and pre-trained models will be made available.

</details>


### [24] [Towards Cross-Platform Generalization: Domain Adaptive 3D Detection with Augmentation and Pseudo-Labeling](https://arxiv.org/abs/2601.08174)
*Xiyan Feng,Wenbo Zhang,Lu Zhang,Yunzhi Zhuge,Huchuan Lu,You He*

Main category: cs.CV

TL;DR: 本技术报告展示了在RoboSense2025挑战赛中跨平台3D目标检测任务的获奖解决方案。该方法基于PVRCNN++框架，融合点云与体素特征，并通过定制化数据增强和伪标签自训练策略缩小域差距，显著提升跨平台泛化能力。最终在阶段1目标域上实现Car类62.67%的3D AP，阶段2目标域上Car和Pedestrian类分别达到58.76%和49.81%的3D AP，取得第三名成绩。


<details>
  <summary>Details</summary>
Motivation: 解决跨平台3D目标检测中的域差异问题，提升模型在不同传感器或平台间的泛化性能，以应对实际部署中数据分布不一致的挑战。

Method: 基于PVRCNN++框架，结合点云与体素特征；采用定制化数据增强策略以模拟多样场景；引入基于伪标签的自训练机制，持续优化模型在目标域的表现。

Result: 在阶段1目标域上，Car类3D AP达62.67%；在阶段2目标域上，Car类3D AP为58.76%，Pedestrian类为49.81%，整体表现优异，获得挑战赛第3名。

Conclusion: 通过融合多模态特征、设计针对性数据增强及自训练策略，有效缩小跨平台域差距，显著提升3D目标检测模型的泛化能力，验证了所提方法在真实复杂场景下的有效性。

Abstract: This technical report represents the award-winning solution to the Cross-platform 3D Object Detection task in the RoboSense2025 Challenge. Our approach is built upon PVRCNN++, an efficient 3D object detection framework that effectively integrates point-based and voxel-based features. On top of this foundation, we improve cross-platform generalization by narrowing domain gaps through tailored data augmentation and a self-training strategy with pseudo-labels. These enhancements enabled our approach to secure the 3rd place in the challenge, achieving a 3D AP of 62.67% for the Car category on the phase-1 target domain, and 58.76% and 49.81% for Car and Pedestrian categories respectively on the phase-2 target domain.

</details>


### [25] [CogniMap3D: Cognitive 3D Mapping and Rapid Retrieval](https://arxiv.org/abs/2601.08175)
*Feiran Wang,Junyi Wu,Dawen Cai,Yuan Hong,Yan Yan*

Main category: cs.CV

TL;DR: CogniMap3D 是一种受生物启发的动态3D场景理解与重建框架，模拟人类认知过程。它通过持久记忆库存储静态场景，实现高效的空间知识存储与快速检索。该框架包含三个核心能力：多阶段运动线索框架用于识别动态物体，认知映射系统用于在多次访问中存储、回忆和更新静态场景，以及因子图优化策略以精炼相机位姿。基于图像流，模型利用运动线索结合深度和相机位姿先验识别动态区域，并与记忆库中的静态元素匹配。在重访熟悉位置时，系统可检索已存储场景，定位相机并用新观测更新记忆。在视频深度估计、相机位姿重建和3D建图任务上表现优异，支持长时间序列与多次访问下的连续场景理解。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景重建方法难以有效处理动态环境中的持续学习与场景记忆，尤其在多次访问同一场景时缺乏对静态结构的长期保持与更新能力。为解决这一问题，本文提出受人类认知启发的框架，实现对静态场景的持久记忆与动态变化的精准感知。

Method: CogniMap3D采用多阶段运动线索分析识别动态物体，结合深度和相机位姿先验；利用认知映射系统构建并维护静态场景的持久记忆库；通过因子图优化进行相机位姿精炼；在重访时基于记忆库实现场景召回与更新。

Result: 在视频深度估计、相机位姿重建和3D建图任务中均达到当前最优性能，且在长时间序列和多次访问下表现出卓越的连续场景理解能力。

Conclusion: CogniMap3D成功实现了类人化的动态3D场景理解，具备持久记忆、快速检索与持续更新能力，为长期视觉导航与智能机器人场景建模提供了有效解决方案。

Abstract: We present CogniMap3D, a bioinspired framework for dynamic 3D scene understanding and reconstruction that emulates human cognitive processes. Our approach maintains a persistent memory bank of static scenes, enabling efficient spatial knowledge storage and rapid retrieval. CogniMap3D integrates three core capabilities: a multi-stage motion cue framework for identifying dynamic objects, a cognitive mapping system for storing, recalling, and updating static scenes across multiple visits, and a factor graph optimization strategy for refining camera poses. Given an image stream, our model identifies dynamic regions through motion cues with depth and camera pose priors, then matches static elements against its memory bank. When revisiting familiar locations, CogniMap3D retrieves stored scenes, relocates cameras, and updates memory with new observations. Evaluations on video depth estimation, camera pose reconstruction, and 3D mapping tasks demonstrate its state-of-the-art performance, while effectively supporting continuous scene understanding across extended sequences and multiple visits.

</details>


### [26] [Instruction-Driven 3D Facial Expression Generation and Transition](https://arxiv.org/abs/2601.08179)
*Anh H. Vo,Tae-Seok Kim,Hulin Jin,Soo-Mi Choi,Yong-Guk Kim*

Main category: cs.CV

TL;DR: 本文提出一种指令驱动的3D面部表情生成框架，通过文本指令实现从一个面部表情到另一个的平滑过渡。引入IFED模块以学习多模态数据并捕捉文本描述与面部表情特征之间的关联，提出I2FET方法结合顶点重建损失来优化潜在向量的语义理解，从而生成符合指令的面部表情序列。最终模型在CK+和CelebV-HQ数据集上优于现有方法，可基于文本提示扩展面部表情及过渡的多样性，具备广泛实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了实现更真实的面部表情变化，需要能够根据任意指令生成从一个表情到另一个表情的自然过渡。传统方法难以有效融合文本描述与面部表情特征，限制了表达的多样性与可控性。因此，亟需一种能基于文本指令生成连贯、自然表情转换的系统。

Method: 提出Instruction-driven Facial Expression Decomposer (IFED) 模块，用于多模态学习和文本-表情关联建模；设计Instruction to Facial Expression Transition (I2FET) 方法，利用IFED与顶点重建损失优化潜在表示；构建面部表情过渡模型，生成平滑的表情变化序列。

Result: 在CK+和CelebV-HQ数据集上的实验表明，该方法在表情生成质量与过渡自然度方面均优于当前最先进的方法。模型能够根据文本指令生成多样化的面部表情轨迹，显著扩展了表情库与表达能力。

Conclusion: 本研究提出的框架实现了基于文本指令的3D面部表情生成与自然过渡，具备高度可控性和表达多样性，为虚拟角色、情感计算、人机交互等领域提供了有力支持。

Abstract: A 3D avatar typically has one of six cardinal facial expressions. To simulate realistic emotional variation, we should be able to render a facial transition between two arbitrary expressions. This study presents a new framework for instruction-driven facial expression generation that produces a 3D face and, starting from an image of the face, transforms the facial expression from one designated facial expression to another. The Instruction-driven Facial Expression Decomposer (IFED) module is introduced to facilitate multimodal data learning and capture the correlation between textual descriptions and facial expression features. Subsequently, we propose the Instruction to Facial Expression Transition (I2FET) method, which leverages IFED and a vertex reconstruction loss function to refine the semantic comprehension of latent vectors, thus generating a facial expression sequence according to the given instruction. Lastly, we present the Facial Expression Transition model to generate smooth transitions between facial expressions. Extensive evaluation suggests that the proposed model outperforms state-of-the-art methods on the CK+ and CelebV-HQ datasets. The results show that our framework can generate facial expression trajectories according to text instruction. Considering that text prompts allow us to make diverse descriptions of human emotional states, the repertoire of facial expressions and the transitions between them can be expanded greatly. We expect our framework to find various practical applications More information about our project can be found at https://vohoanganh.github.io/tg3dfet/

</details>


### [27] [Second-order Gaussian directional derivative representations for image high-resolution corner detection](https://arxiv.org/abs/2601.08182)
*Dongbo Xie,Junjie Qiu,Changming Sun,Weichuan Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于二阶高斯方向导数（SOGDD）滤波的新高分辨率角点检测方法，解决了现有方法中相邻角点间灰度信息相互干扰的理论缺陷。通过分析END型和L型角点模型的SOGDD表示，揭示了高分辨率角点的多种特性，并指导了高斯滤波尺度的选择，实现了对相邻角点的精确检测。实验表明，该方法在定位误差、抗模糊性、图像匹配和三维重建方面均优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有角点检测方法在处理相邻角点时存在理论缺陷，特别是由于两个相邻角点的灰度信息会相互影响，导致检测不准确。因此需要一种更精确的方法来解决这一问题。

Method: 采用二阶高斯方向导数（SOGDD）滤波器对两种典型高分辨率角点模型（END型和L型）进行平滑处理，分别推导其SOGDD表示，挖掘出高分辨率角点的多个特征，并据此设计新的角点检测方法。

Result: 所提方法能够准确检测相邻角点，在定位精度、抗图像模糊能力、图像匹配性能以及三维重建效果方面均优于当前最先进的方法。

Conclusion: 本研究提出了一种新型高分辨率角点检测方法，克服了传统方法在相邻角点检测中的局限性，具有更高的精度与鲁棒性，适用于多种计算机视觉任务。

Abstract: Corner detection is widely used in various computer vision tasks, such as image matching and 3D reconstruction. Our research indicates that there are theoretical flaws in Zhang et al.'s use of a simple corner model to obtain a series of corner characteristics, as the grayscale information of two adjacent corners can affect each other. In order to address the above issues, a second-order Gaussian directional derivative (SOGDD) filter is used in this work to smooth two typical high-resolution angle models (i.e. END-type and L-type models). Then, the SOGDD representations of these two corner models were derived separately, and many characteristics of high-resolution corners were discovered, which enabled us to demonstrate how to select Gaussian filtering scales to obtain intensity variation information from images, accurately depicting adjacent corners. In addition, a new high-resolution corner detection method for images has been proposed for the first time, which can accurately detect adjacent corner points. The experimental results have verified that the proposed method outperforms state-of-the-art methods in terms of localization error, robustness to image blur transformation, image matching, and 3D reconstruction.

</details>


### [28] [GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards](https://arxiv.org/abs/2601.08183)
*Yan Zhu,Te Luo,Pei-Yao Fu,Zhen Zhang,Zi-Long Wang,Yi-Fan Qu,Zi-Han Geng,Jia-Qi Xu,Lu Yao,Li-Yun Ma,Wei Su,Wei-Feng Chen,Quan-Lin Li,Shuo Wang,Ping-Hong Zhou*

Main category: cs.CV

TL;DR: 本研究构建了GI-Bench基准，评估12个先进的多模态大语言模型（MLLMs）在胃肠道内镜全流程中的表现，涵盖五个临床阶段。结果显示，Gemini-3-Pro表现最佳，其诊断推理能力优于住院医师并接近初级内镜医生；但模型在空间定位方面存在显著瓶颈，远低于人类表现。此外，模型生成报告虽语言流畅度更高，但事实准确性较差，存在过度解读和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 验证多模态大语言模型在真实胃肠道内镜临床工作流程中的性能，并评估其与人类医生的临床实用性差异，以推动AI在消化内科领域的可靠应用。

Method: 构建包含20种细粒度病变类别的GI-Bench基准，评估12个MLLMs在五个临床阶段的表现：解剖定位、病灶识别、诊断、发现描述和管理建议。采用Macro-F1、mIoU及多维李克特量表与三名初级内镜医生和三名住院医师进行对比分析。

Result: Gemini-3-Pro达到最优性能；顶级模型在诊断推理上优于住院医师（Macro-F1 0.641 vs 0.492），接近初级医生（0.727，p>0.05）。但模型在空间定位上显著落后于人类（mIoU 0.345 vs >0.506，p<0.05）。且模型报告更流畅但事实错误更多，表现出‘流畅性-准确性悖论’。

Conclusion: 尽管顶级多模态大语言模型在诊断推理方面已具备临床潜力，但在空间定位和事实准确性方面仍存在关键瓶颈，需进一步优化以实现与人类医生的可比性。GI-Bench将持续追踪模型进展，促进临床AI的可信发展。

Abstract: Multimodal Large Language Models (MLLMs) show promise in gastroenterology, yet their performance against comprehensive clinical workflows and human benchmarks remains unverified. To systematically evaluate state-of-the-art MLLMs across a panoramic gastrointestinal endoscopy workflow and determine their clinical utility compared with human endoscopists. We constructed GI-Bench, a benchmark encompassing 20 fine-grained lesion categories. Twelve MLLMs were evaluated across a five-stage clinical workflow: anatomical localization, lesion identification, diagnosis, findings description, and management. Model performance was benchmarked against three junior endoscopists and three residency trainees using Macro-F1, mean Intersection-over-Union (mIoU), and multi-dimensional Likert scale. Gemini-3-Pro achieved state-of-the-art performance. In diagnostic reasoning, top-tier models (Macro-F1 0.641) outperformed trainees (0.492) and rivaled junior endoscopists (0.727; p>0.05). However, a critical "spatial grounding bottleneck" persisted; human lesion localization (mIoU >0.506) significantly outperformed the best model (0.345; p<0.05). Furthermore, qualitative analysis revealed a "fluency-accuracy paradox": models generated reports with superior linguistic readability compared with humans (p<0.05) but exhibited significantly lower factual correctness (p<0.05) due to "over-interpretation" and hallucination of visual features.GI-Bench maintains a dynamic leaderboard that tracks the evolving performance of MLLMs in clinical endoscopy. The current rankings and benchmark results are available at https://roterdl.github.io/GIBench/.

</details>


### [29] [Route, Retrieve, Reflect, Repair: Self-Improving Agentic Framework for Visual Detection and Linguistic Reasoning in Medical Imaging](https://arxiv.org/abs/2601.08192)
*Md. Faiyaz Abdullah Sayeedi,Rashedur Rahman,Siam Tahsin Bhuiyan,Sefatul Wasi,Ashraful Islam,Saadia Binte Alam,AKM Mahbubur Rahman*

Main category: cs.CV

TL;DR: R^4 is an agentic framework for medical image analysis that enhances vision-language models (VLMs) through four coordinated agents: Router, Retriever, Reflector, and Repairer. It improves report generation and detection accuracy without fine-tuning by enabling iterative refinement, critical reflection, and spatial grounding.


<details>
  <summary>Details</summary>
Motivation: Existing VLM-based medical image analysis systems are often single-pass black boxes with limited control over reasoning, safety, and spatial accuracy. There is a need for more reliable, interpretable, and clinically grounded models.

Method: R^4 decomposes medical imaging workflows into four agents: (1) Router configures task-specific prompts using image, history, and metadata; (2) Retriever generates reports and bounding boxes using exemplar memory and pass@k sampling; (3) Reflector critiques outputs for clinical errors such as negation, contradictions, and localization issues; (4) Repairer iteratively revises narrative and spatial outputs under constraints while curating high-quality exemplars.

Result: R^4 improves LLM-as-a-Judge scores by +1.7 to +2.5 points and mAP50 by +2.5 to +3.5 absolute points across multiple VLM backbones on chest X-ray tasks, outperforming strong single-VLM baselines without gradient-based fine-tuning.

Conclusion: Agentic routing, reflection, and repair can significantly enhance the reliability, grounding, and clinical safety of large vision-language models in medical imaging, transforming them from brittle tools into robust, interpretable assistants.

Abstract: Medical image analysis increasingly relies on large vision-language models (VLMs), yet most systems remain single-pass black boxes that offer limited control over reasoning, safety, and spatial grounding. We propose R^4, an agentic framework that decomposes medical imaging workflows into four coordinated agents: a Router that configures task- and specialization-aware prompts from the image, patient history, and metadata; a Retriever that uses exemplar memory and pass@k sampling to jointly generate free-text reports and bounding boxes; a Reflector that critiques each draft-box pair for key clinical error modes (negation, laterality, unsupported claims, contradictions, missing findings, and localization errors); and a Repairer that iteratively revises both narrative and spatial outputs under targeted constraints while curating high-quality exemplars for future cases. Instantiated on chest X-ray analysis with multiple modern VLM backbones and evaluated on report generation and weakly supervised detection, R^4 consistently boosts LLM-as-a-Judge scores by roughly +1.7-+2.5 points and mAP50 by +2.5-+3.5 absolute points over strong single-VLM baselines, without any gradient-based fine-tuning. These results show that agentic routing, reflection, and repair can turn strong but brittle VLMs into more reliable and better grounded tools for clinical image interpretation. Our code can be found at: https://github.com/faiyazabdullah/MultimodalMedAgent

</details>


### [30] [Unified Multi-Site Multi-Sequence Brain MRI Harmonization Enriched by Biomedical Semantic Style](https://arxiv.org/abs/2601.08193)
*Mengqi Wu,Yongheng Sun,Qianqian Wang,Pew-Thian Yap,Mingxia Liu*

Main category: cs.CV

TL;DR: MMH 是一个统一的多站点多序列脑 MRI 归一化框架，通过利用生物医学语义先验实现序列感知的风格对齐。其分为两个阶段：(1) 基于扩散的全局归一化器，使用无风格梯度条件将 MRI 图像映射到序列特定的统一域；(2) 面向目标的微调器，将全局对齐图像适配至期望的目标域。采用三平面注意力 BiomedCLIP 编码器聚合多视角嵌入以表征体积风格信息，实现风格与解剖结构的显式解耦，且无需成对数据。在 4,163 例 T1 和 T2 加权 MRI 上的评估显示，MMH 在图像特征聚类、体素级比较、组织分割及下游年龄和站点分类任务中均优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 多站点脑 MRI 数据聚合可提升深度学习模型训练效果，但站点间的非生物学异质性（如扫描仪厂商、采集参数、成像协议差异）会损害模型泛化能力。现有回顾性 MRI 归一化方法通常依赖有限的配对旅行者数据，或无法有效解耦风格与解剖结构，且多数仅支持单序列归一化，难以适应真实世界中多序列 MRI 的常规采集场景。

Method: 提出 MMH 框架，包含两个阶段：(1) 扩散基全局归一化器，通过风格无关梯度条件将图像映射至序列特定统一域；(2) 目标特定微调器，用于将全局对齐图像适配至目标域。采用三平面注意力 BiomedCLIP 编码器提取多视角嵌入，实现风格与解剖结构的显式分离，无需配对数据。

Result: 在 4,163 例 T1- 和 T2-加权 MRI 上验证，MMH 在图像特征聚类、体素级比较、组织分割以及年龄和站点分类等任务中表现优于当前最先进的方法，证明其在多站点多序列场景下的高效性和鲁棒性。

Conclusion: MMH 提供了一种无需配对数据、可处理多序列多站点脑 MRI 的统一归一化框架，通过引入生物医学语义先验与三平面注意力机制，实现了风格与解剖结构的有效解耦，在多种评估指标上展现出优越性能，为大规模多中心神经影像研究提供了有力工具。

Abstract: Aggregating multi-site brain MRI data can enhance deep learning model training, but also introduces non-biological heterogeneity caused by site-specific variations (e.g., differences in scanner vendors, acquisition parameters, and imaging protocols) that can undermine generalizability. Recent retrospective MRI harmonization seeks to reduce such site effects by standardizing image style (e.g., intensity, contrast, noise patterns) while preserving anatomical content. However, existing methods often rely on limited paired traveling-subject data or fail to effectively disentangle style from anatomy. Furthermore, most current approaches address only single-sequence harmonization, restricting their use in real-world settings where multi-sequence MRI is routinely acquired. To this end, we introduce MMH, a unified framework for multi-site multi-sequence brain MRI harmonization that leverages biomedical semantic priors for sequence-aware style alignment. MMH operates in two stages: (1) a diffusion-based global harmonizer that maps MR images to a sequence-specific unified domain using style-agnostic gradient conditioning, and (2) a target-specific fine-tuner that adapts globally aligned images to desired target domains. A tri-planar attention BiomedCLIP encoder aggregates multi-view embeddings to characterize volumetric style information, allowing explicit disentanglement of image styles from anatomy without requiring paired data. Evaluations on 4,163 T1- and T2-weighted MRIs demonstrate MMH's superior harmonization over state-of-the-art methods in image feature clustering, voxel-level comparison, tissue segmentation, and downstream age and site classification.

</details>


### [31] [MobiDiary: Autoregressive Action Captioning with Wearable Devices and Wireless Signals](https://arxiv.org/abs/2601.08204)
*Fei Deng,Yinghui He,Chuntong Chu,Ge Wang,Han Ding,Jinsong Han,Fei Wang*

Main category: cs.CV

TL;DR: MobiDiary 是一种从异构物理信号（如 IMU 和 Wi-Fi）中直接生成自然语言活动描述的框架，通过统一传感器编码器捕捉运动动力学特征，结合 Transformer 解码器实现连贯语义生成，在多个基准上达到 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 传统视觉方法存在隐私问题和环境限制，而现有 HAR 模型输出受限于预定义标签，缺乏可读性；因此需要一种能生成自然语言描述、兼顾多模态信号融合与语义表达的通用框架。

Method: 提出统一传感器编码器，利用基于补丁的机制捕获局部时间相关性，并引入异构放置嵌入统一不同传感器的空间上下文；将融合后的信号标记输入 Transformer 解码器，采用自回归方式逐词生成活动描述。

Result: 在 XRF V2、UWash 和 WiFiTAD 多个公开数据集上表现优异，显著提升文本生成指标（如 BLEU@4、CIDEr、RMC），优于专用基线模型，在连续动作理解任务中展现出强泛化能力。

Conclusion: MobiDiary 成功实现了从多源物理信号到自然语言描述的端到端映射，为智能家庭中的健康监测与辅助生活提供了更人性化、隐私友好的解决方案。

Abstract: Human Activity Recognition (HAR) in smart homes is critical for health monitoring and assistive living. While vision-based systems are common, they face privacy concerns and environmental limitations (e.g., occlusion). In this work, we present MobiDiary, a framework that generates natural language descriptions of daily activities directly from heterogeneous physical signals (specifically IMU and Wi-Fi). Unlike conventional approaches that restrict outputs to pre-defined labels, MobiDiary produces expressive, human-readable summaries. To bridge the semantic gap between continuous, noisy physical signals and discrete linguistic descriptions, we propose a unified sensor encoder. Instead of relying on modality-specific engineering, we exploit the shared inductive biases of motion-induced signals--where both inertial and wireless data reflect underlying kinematic dynamics. Specifically, our encoder utilizes a patch-based mechanism to capture local temporal correlations and integrates heterogeneous placement embedding to unify spatial contexts across different sensors. These unified signal tokens are then fed into a Transformer-based decoder, which employs an autoregressive mechanism to generate coherent action descriptions word-by-word. We comprehensively evaluate our approach on multiple public benchmarks (XRF V2, UWash, and WiFiTAD). Experimental results demonstrate that MobiDiary effectively generalizes across modalities, achieving state-of-the-art performance on captioning metrics (e.g., BLEU@4, CIDEr, RMC) and outperforming specialized baselines in continuous action understanding.

</details>


### [32] [Knowledge-based learning in Text-RAG and Image-RAG](https://arxiv.org/abs/2601.08226)
*Alexander Shim,Khalil Saieh,Samuel Clarke*

Main category: cs.CV

TL;DR: 该研究比较了基于EVA-ViT图像编码器的多模态方法与LlaMA或ChatGPT等大语言模型在减少胸部X光图像幻觉问题和疾病检测中的表现。使用NIH胸部X光数据集进行训练，对比了基于图像的RAG、基于文本的RAG和基线模型。结果表明，基于文本的RAG通过引入外部知识有效降低了幻觉，基于图像的RAG则通过KNN方法提升了预测置信度和校准性能。GPT类模型在性能、幻觉率和预期校准误差（ECE）方面优于Llama模型。研究揭示了数据不平衡和复杂多阶段结构的挑战，但建议构建大规模经验环境并使用平衡样本。


<details>
  <summary>Details</summary>
Motivation: 减少胸部X光图像分析中大语言模型的幻觉问题，提升疾病检测的准确性和可靠性，同时探索多模态融合在医学影像理解中的潜力。

Method: 采用EVA-ViT作为图像编码器，结合LlaMA或ChatGPT等大语言模型，构建多模态框架；在NIH胸部X光数据集上训练模型，并对比图像基础RAG、文本基础RAG与基线模型的表现；利用KNN方法增强图像检索，通过外部知识注入降低幻觉。

Result: 文本基础RAG显著降低幻觉，图像基础RAG提升预测置信度与校准性能；GPT类模型在整体表现、幻觉控制和ECE指标上优于Llama模型；数据不平衡和复杂结构仍是主要挑战。

Conclusion: 多模态融合有助于缓解医学影像分析中的幻觉问题，文本引导与图像检索协同可提升模型可靠性；未来应构建更均衡的数据环境以支持模型训练。

Abstract: This research analyzed and compared the multi-modal approach in the Vision Transformer(EVA-ViT) based image encoder with the LlaMA or ChatGPT LLM to reduce the hallucination problem and detect diseases in chest x-ray images. In this research, we utilized the NIH Chest X-ray image to train the model and compared it in image-based RAG, text-based RAG, and baseline. [3] [5] In a result, the text-based RAG[2] e!ectively reduces the hallucination problem by using external knowledge information, and the image-based RAG improved the prediction con"dence and calibration by using the KNN methods. [4] Moreover, the GPT LLM showed better performance, a low hallucination rate, and better Expected Calibration Error(ECE) than Llama Llama-based model. This research shows the challenge of data imbalance, a complex multi-stage structure, but suggests a large experience environment and a balanced example of use.

</details>


### [33] [Improving Zero-shot ADL Recognition with Large Language Models through Event-based Context and Confidence](https://arxiv.org/abs/2601.08241)
*Michele Fiori,Gabriele Civitarese,Marco Colussi,Claudio Bettini*

Main category: cs.CV

TL;DR: 本文提出一种基于事件的分割方法和新的置信度估计方法，以改进零样本活动识别。与依赖时间分段的传统方法相比，该方法在复杂真实数据集上表现更优，并且即使使用较小的LLM（如Gemma 3 27B）也超越了监督学习方法。置信度估计能有效区分正确与错误预测。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的零样本活动识别方法依赖于时间分段，这与LLM的上下文推理能力不匹配，且缺乏有效的预测置信度估计方法。

Method: 采用事件驱动的分割策略，结合新型置信度估计机制，提升零样本活动识别性能。

Result: 实验表明，事件分割方法在复杂数据集上优于时间分割方法，且在小规模模型下仍可超越传统监督学习方法；所提置信度估计能有效识别预测准确性。

Conclusion: 事件驱动的分割与置信度估计相结合，显著提升了零样本ADL识别的准确性和可靠性，为智能家庭中的无感监测提供了新思路。

Abstract: Unobtrusive sensor-based recognition of Activities of Daily Living (ADLs) in smart homes by processing data collected from IoT sensing devices supports applications such as healthcare, safety, and energy management. Recent zero-shot methods based on Large Language Models (LLMs) have the advantage of removing the reliance on labeled ADL sensor data. However, existing approaches rely on time-based segmentation, which is poorly aligned with the contextual reasoning capabilities of LLMs. Moreover, existing approaches lack methods for estimating prediction confidence. This paper proposes to improve zero-shot ADL recognition with event-based segmentation and a novel method for estimating prediction confidence. Our experimental evaluation shows that event-based segmentation consistently outperforms time-based LLM approaches on complex, realistic datasets and surpasses supervised data-driven methods, even with relatively small LLMs (e.g., Gemma 3 27B). The proposed confidence measure effectively distinguishes correct from incorrect predictions.

</details>


### [34] [HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding](https://arxiv.org/abs/2601.08273)
*Qitan Lv,Tianyu Liu,Wen Wu,Xuenan Xu,Bowen Zhou,Feng Wu,Chao Zhang*

Main category: cs.CV

TL;DR: HIPPO is a holistic-aware parallel speculative decoding framework for video-LLMs that improves inference speed by preserving key visual semantic tokens and enabling parallel draft generation and verification, achieving up to 3.51x speedup.


<details>
  <summary>Details</summary>
Motivation: Existing speculative decoding methods for video-LLMs fail to achieve speedups comparable to text-only LLMs due to poor preservation of semantic visual tokens and high residual inference cost after pruning.

Method: HIPPO introduces a semantic-aware token preservation strategy using global attention and local visual semantics, and a video parallel SD algorithm that decouples and overlaps draft generation and target verification phases.

Result: Experiments on four video-LLMs across six benchmarks show HIPPO achieves up to 3.51x speedup over vanilla autoregressive decoding.

Conclusion: HIPPO effectively addresses the limitations of current speculative decoding in video-LLMs by enhancing draft quality and enabling efficient parallel processing, leading to significant inference acceleration.

Abstract: Speculative decoding (SD) has emerged as a promising approach to accelerate LLM inference without sacrificing output quality. Existing SD methods tailored for video-LLMs primarily focus on pruning redundant visual tokens to mitigate the computational burden of massive visual inputs. However, existing methods do not achieve inference acceleration comparable to text-only LLMs. We observe from extensive experiments that this phenomenon mainly stems from two limitations: (i) their pruning strategies inadequately preserve visual semantic tokens, degrading draft quality and acceptance rates; (ii) even with aggressive pruning (e.g., 90% visual tokens removed), the draft model's remaining inference cost limits overall speedup. To address these limitations, we propose HIPPO, a general holistic-aware parallel speculative decoding framework. Specifically, HIPPO proposes (i) a semantic-aware token preservation method, which fuses global attention scores with local visual semantics to retain semantic information at high pruning ratios; (ii) a video parallel SD algorithm that decouples and overlaps draft generation and target verification phases. Experiments on four video-LLMs across six benchmarks demonstrate HIPPO's effectiveness, yielding up to 3.51x speedup compared to vanilla auto-regressive decoding.

</details>


### [35] [KidVis: Do Multimodal Large Language Models Possess the Visual Perceptual Capabilities of a 6-Year-Old?](https://arxiv.org/abs/2601.08292)
*Xianfeng Wang,Kaiwei Zhang,Qi Jia,Zijian Chen,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 该研究提出KidVis基准，评估多模态大模型在基础视觉能力上的表现，发现尽管模型在高级推理任务中表现出色，但在类似6-7岁儿童的基础视觉能力上仍存在显著差距，且模型参数增加并未带来线性提升，揭示了当前MLLMs缺乏基本的生理感知原语。


<details>
  <summary>Details</summary>
Motivation: 探究多模态大语言模型是否具备与人类直觉相当的基础视觉能力，尤其是与6-7岁儿童已具备的原始视觉认知能力相比。

Method: 基于人类视觉发展理论构建KidVis基准，将视觉智能分解为六种原子能力（集中、追踪、区分、记忆、空间、闭合），涵盖10类低语义依赖的视觉任务，并对20个最先进的多模态大模型进行评估，与人类儿童生理基准对比。

Result: 人类儿童平均得分95.32，而最先进模型GPT-5仅得67.33；模型规模扩大并未带来基础视觉能力的线性提升，呈现‘缩放定律悖论’。

Conclusion: 当前多模态大语言模型虽在复杂推理中表现优异，但缺乏实现通用视觉智能所必需的基本生理感知原语。

Abstract: While Multimodal Large Language Models (MLLMs) have demonstrated impressive proficiency in high-level reasoning tasks, such as complex diagrammatic interpretation, it remains an open question whether they possess the fundamental visual primitives comparable to human intuition. To investigate this, we introduce KidVis, a novel benchmark grounded in the theory of human visual development. KidVis deconstructs visual intelligence into six atomic capabilities - Concentration, Tracking, Discrimination, Memory, Spatial, and Closure - already possessed by 6-7 year old children, comprising 10 categories of low-semantic-dependent visual tasks. Evaluating 20 state-of-the-art MLLMs against a human physiological baseline reveals a stark performance disparity. Results indicate that while human children achieve a near-perfect average score of 95.32, the state-of-the-art GPT-5 attains only 67.33. Crucially, we observe a "Scaling Law Paradox": simply increasing model parameters fails to yield linear improvements in these foundational visual capabilities. This study confirms that current MLLMs, despite their reasoning prowess, lack the essential physiological perceptual primitives required for generalized visual intelligence.

</details>


### [36] [M3SR: Multi-Scale Multi-Perceptual Mamba for Efficient Spectral Reconstruction](https://arxiv.org/abs/2601.08293)
*Yuze Zhang,Lingjie Li,Qiuzhen Lin,Zhong Ming,Fei Yu,Victor C. M. Leung*

Main category: cs.CV

TL;DR: 提出M3SR，一种用于光谱重建的多尺度、多感知Mamba架构，通过多感知融合模块和U-Net结构实现全局、中间和局部特征的有效提取与融合，显著提升重建精度并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有Mamba架构在光谱重建中因单一空间感知和单尺度特征提取导致的对高光谱图像复杂结构和细节捕捉能力不足的问题。

Method: 设计多感知融合块，将其集成到U-Net结构中，以实现多尺度、多感知特征的提取与融合。

Result: 实验表明M3SR在定量和定性评估上均优于现有最先进方法，且计算开销更低。

Conclusion: M3SR有效提升了光谱重建性能，具备更强的特征表达能力和更低的计算成本，适用于复杂高光谱图像重建任务。

Abstract: The Mamba architecture has been widely applied to various low-level vision tasks due to its exceptional adaptability and strong performance. Although the Mamba architecture has been adopted for spectral reconstruction, it still faces the following two challenges: (1) Single spatial perception limits the ability to fully understand and analyze hyperspectral images; (2) Single-scale feature extraction struggles to capture the complex structures and fine details present in hyperspectral images. To address these issues, we propose a multi-scale, multi-perceptual Mamba architecture for the spectral reconstruction task, called M3SR. Specifically, we design a multi-perceptual fusion block to enhance the ability of the model to comprehensively understand and analyze the input features. By integrating the multi-perceptual fusion block into a U-Net structure, M3SR can effectively extract and fuse global, intermediate, and local features, thereby enabling accurate reconstruction of hyperspectral images at multiple scales. Extensive quantitative and qualitative experiments demonstrate that the proposed M3SR outperforms existing state-of-the-art methods while incurring a lower computational cost.

</details>


### [37] [Enhancing Image Quality Assessment Ability of LMMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.08311)
*Kang Fu,Huiyu Duan,Zicheng Zhang,Yucheng Zhu,Jun Zhao,Xiongkuo Min,Jia Wang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一种名为IQARAG的无训练框架，通过检索增强生成（RAG）技术，利用语义相似但质量不同的参考图像及其对应的平均意见分数（MOS），来提升大型多模态模型（LMM）在图像质量评估（IQA）任务中的表现。该方法无需昂贵的微调，仅通过构建特定提示即可显著增强模型的零样本性能，已在多个主流IQA数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型多模态模型（LMMs）在图像质量评估（IQA）任务中展现出强大的零样本能力，但要达到顶尖性能通常需要计算成本高昂的微调过程。为减少训练开销并保持高性能，本文旨在探索一种无需训练的高效替代方案。

Method: IQARAG采用三阶段流程：1）检索特征提取，从数据库中提取参考图像的视觉特征；2）基于特征匹配进行图像检索，获取与输入图像语义相似但质量各异的参考图像及其MOS值；3）将这些参考图像与输入图像整合进特定提示中，引导LMM生成更准确的质量评分。通过引入质量差异明显的参考图像作为视觉锚点，增强模型对质量感知的理解。

Result: 在KADID、KonIQ、LIVE Challenge和SPAQ等多个多样化的IQA数据集上，IQARAG均显著提升了LMM的性能，达到了接近甚至超过部分微调方法的效果，同时避免了复杂的训练过程，表现出极高的资源效率。

Conclusion: IQARAG是一种高效、无需训练的图像质量评估框架，通过检索增强生成机制有效提升了大型多模态模型在低层次视觉感知任务中的表现，为未来轻量化高质量评估系统提供了可行路径。

Abstract: Large Multimodal Models (LMMs) have recently shown remarkable promise in low-level visual perception tasks, particularly in Image Quality Assessment (IQA), demonstrating strong zero-shot capability. However, achieving state-of-the-art performance often requires computationally expensive fine-tuning methods, which aim to align the distribution of quality-related token in output with image quality levels. Inspired by recent training-free works for LMM, we introduce IQARAG, a novel, training-free framework that enhances LMMs' IQA ability. IQARAG leverages Retrieval-Augmented Generation (RAG) to retrieve some semantically similar but quality-variant reference images with corresponding Mean Opinion Scores (MOSs) for input image. These retrieved images and input image are integrated into a specific prompt. Retrieved images provide the LMM with a visual perception anchor for IQA task. IQARAG contains three key phases: Retrieval Feature Extraction, Image Retrieval, and Integration & Quality Score Generation. Extensive experiments across multiple diverse IQA datasets, including KADID, KonIQ, LIVE Challenge, and SPAQ, demonstrate that the proposed IQARAG effectively boosts the IQA performance of LMMs, offering a resource-efficient alternative to fine-tuning for quality assessment.

</details>


### [38] [YOLOBirDrone: Dataset for Bird vs Drone Detection and Classification and a YOLO based enhanced learning architecture](https://arxiv.org/abs/2601.08319)
*Dapinder Kaur,Neeraj Battish,Arnav Bhavsar,Shashi Poddar*

Main category: cs.CV

TL;DR: 该研究提出了一种名为YOLOBirDrone的新架构，用于提高无人机和鸟类的检测与分类准确率。该架构结合了自适应扩展层聚合（AELAN）、多尺度渐进双注意力模块（MPDA）和反向MPDA（RMPDA），以增强局部和全局的空间及通道信息，并保留形状特征。同时，研究引入了一个大规模数据集BirDrone，专门用于挑战性小目标的空中物体识别。实验结果表明，该方法在多种场景下检测准确率可达约85%，优于现有先进算法。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉的无人机检测系统在区分无人机与鸟类方面存在准确率限制，尤其在鸟类尺寸较小时表现不佳，因此亟需一种更精确的检测与分类方法。

Method: 提出YOLOBirDrone架构，包含AELAN、MPDA和RMPDA模块，结合大规模数据集BirDrone进行训练与测试，提升小目标识别能力。

Result: 在多种场景下，该方法的检测准确率达到约85%，显著优于现有先进算法。

Conclusion: YOLOBirDrone架构有效提升了无人机与鸟类的检测与分类性能，为复杂环境下的空中目标识别提供了有力解决方案。

Abstract: The use of aerial drones for commercial and defense applications has benefited in many ways and is therefore utilized in several different application domains. However, they are also increasingly used for targeted attacks, posing a significant safety challenge and necessitating the development of drone detection systems. Vision-based drone detection systems currently have an accuracy limitation and struggle to distinguish between drones and birds, particularly when the birds are small in size. This research work proposes a novel YOLOBirDrone architecture that improves the detection and classification accuracy of birds and drones. YOLOBirDrone has different components, including an adaptive and extended layer aggregation (AELAN), a multi-scale progressive dual attention module (MPDA), and a reverse MPDA (RMPDA) to preserve shape information and enrich features with local and global spatial and channel information. A large-scale dataset, BirDrone, is also introduced in this article, which includes small and challenging objects for robust aerial object identification. Experimental results demonstrate an improvement in performance metrics through the proposed YOLOBirDrone architecture compared to other state-of-the-art algorithms, with detection accuracy reaching approximately 85% across various scenarios.

</details>


### [39] [UM-Text: A Unified Multimodal Model for Image Understanding](https://arxiv.org/abs/2601.08321)
*Lichen Ma,Xiaolong Fu,Gaojing Zhou,Zipeng Guo,Ting Zhu,Yichun Liu,Yu Shi,Jason Li,Junshi Huang*

Main category: cs.CV

TL;DR: 提出UM-Text，一个统一的多模态模型，用于根据自然语言指令进行视觉文本编辑。通过引入视觉语言模型（VLM）理解指令与参考图像，并设计UM-Encoder自动融合条件信息以生成风格一致的文本图像。采用区域一致性损失和三阶段训练策略提升生成质量，并构建了大规模数据集UM-DATA-200K。在多个公开基准上验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉文本编辑中需手动指定字体、颜色、布局等属性，缺乏对参考图像风格的一致性考虑，导致生成结果不协调。因此需要一种能自动理解上下文并保持风格一致性的统一模型。

Method: 引入视觉语言模型（VLM）处理指令与图像，生成上下文相关的文本内容与布局；设计UM-Encoder自动融合多种条件嵌入；采用区域一致性损失在潜在空间与RGB空间进行监督；使用三阶段训练策略优化模型性能。

Result: 在多个公开基准上实现了最先进的性能，生成的视觉文本在内容准确性、布局合理性与风格一致性方面均有显著提升。

Conclusion: UM-Text成功实现了基于自然语言指令的高效、风格一致的视觉文本编辑，为复杂场景下的文本生成提供了新范式。

Abstract: With the rapid advancement of image generation, visual text editing using natural language instructions has received increasing attention. The main challenge of this task is to fully understand the instruction and reference image, and thus generate visual text that is style-consistent with the image. Previous methods often involve complex steps of specifying the text content and attributes, such as font size, color, and layout, without considering the stylistic consistency with the reference image. To address this, we propose UM-Text, a unified multimodal model for context understanding and visual text editing by natural language instructions. Specifically, we introduce a Visual Language Model (VLM) to process the instruction and reference image, so that the text content and layout can be elaborately designed according to the context information. To generate an accurate and harmonious visual text image, we further propose the UM-Encoder to combine the embeddings of various condition information, where the combination is automatically configured by VLM according to the input instruction. During training, we propose a regional consistency loss to offer more effective supervision for glyph generation on both latent and RGB space, and design a tailored three-stage training strategy to further enhance model performance. In addition, we contribute the UM-DATA-200K, a large-scale visual text image dataset on diverse scenes for model training. Extensive qualitative and quantitative results on multiple public benchmarks demonstrate that our method achieves state-of-the-art performance.

</details>


### [40] [From Local Windows to Adaptive Candidates via Individualized Exploratory: Rethinking Attention for Image Super-Resolution](https://arxiv.org/abs/2601.08341)
*Chunyu Meng,Wei Long,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种名为IET的新型Transformer架构，通过引入个体化探索注意力（IEA）机制，使每个令牌能够自适应地选择内容感知且独立的注意力候选，从而实现更精确的信息聚合并保持计算效率。在标准超分辨率基准测试中，IET在相近计算复杂度下达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的单图像超分辨率方法虽然能建模长距离依赖关系，但其特征密集型注意力计算带来高计算成本。大多数方法采用固定分组方式限制注意力范围，忽略了令牌间相似性的内在不对称性，导致无法实现灵活、自适应的注意力计算。

Method: 提出个体化探索注意力（IEA）机制，允许每个令牌根据内容自适应选择独立的注意力候选，实现令牌自适应和非对称的注意力计算设计。

Result: 在多个标准超分辨率基准上，IET实现了优于现有方法的性能，同时保持了相近的计算复杂度。

Conclusion: IET通过引入个体化探索注意力机制，有效提升了注意力计算的灵活性与精度，在不显著增加计算开销的前提下，显著增强了单图像超分辨率的性能。

Abstract: Single Image Super-Resolution (SISR) is a fundamental computer vision task that aims to reconstruct a high-resolution (HR) image from a low-resolution (LR) input. Transformer-based methods have achieved remarkable performance by modeling long-range dependencies in degraded images. However, their feature-intensive attention computation incurs high computational cost. To improve efficiency, most existing approaches partition images into fixed groups and restrict attention within each group. Such group-wise attention overlooks the inherent asymmetry in token similarities, thereby failing to enable flexible and token-adaptive attention computation. To address this limitation, we propose the Individualized Exploratory Transformer (IET), which introduces a novel Individualized Exploratory Attention (IEA) mechanism that allows each token to adaptively select its own content-aware and independent attention candidates. This token-adaptive and asymmetric design enables more precise information aggregation while maintaining computational efficiency. Extensive experiments on standard SR benchmarks demonstrate that IET achieves state-of-the-art performance under comparable computational complexity.

</details>


### [41] [Semantic Misalignment in Vision-Language Models under Perceptual Degradation](https://arxiv.org/abs/2601.08355)
*Guo Cheng*

Main category: cs.CV

TL;DR: 该研究系统分析了视觉语言模型（VLMs）在感知退化情况下的语义不一致问题，发现即使在视觉分割任务中表现尚可，下游VLM仍会出现幻觉、关键实体遗漏和安全判断不一致等严重错误。研究提出了语言层面的不一致度量标准，并揭示了像素级鲁棒性与多模态语义可靠性之间的显著脱节，强调了在安全关键应用中考虑感知不确定性的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前VLM在多模态基准上表现良好，但其在真实感知退化条件下的鲁棒性尚不明确，尤其是在自动驾驶和具身AI等安全关键场景中，可靠感知对语义推理至关重要。

Method: 通过在Cityscapes数据集上使用语义分割作为感知模块，引入现实感知退化的扰动，评估多个对比式和生成式VLM在不同退化条件下的行为；提出语言层面的语义不一致度量指标，包括幻觉、关键信息遗漏和安全误判。

Result: 尽管分割任务的常规指标下降有限，但下游VLM表现出严重的语义错误，如幻觉对象提及、安全关键实体遗漏和不一致的安全判断；结果显示像素级鲁棒性与多模态语义可靠性之间存在明显脱节。

Conclusion: 当前VLM系统在感知不确定性下存在重大局限，亟需建立能够显式考虑感知不确定性的评估框架，以确保其在安全关键应用中的可靠性。

Abstract: Vision-Language Models (VLMs) are increasingly deployed in autonomous driving and embodied AI systems, where reliable perception is critical for safe semantic reasoning and decision-making. While recent VLMs demonstrate strong performance on multimodal benchmarks, their robustness to realistic perception degradation remains poorly understood. In this work, we systematically study semantic misalignment in VLMs under controlled degradation of upstream visual perception, using semantic segmentation on the Cityscapes dataset as a representative perception module. We introduce perception-realistic corruptions that induce only moderate drops in conventional segmentation metrics, yet observe severe failures in downstream VLM behavior, including hallucinated object mentions, omission of safety-critical entities, and inconsistent safety judgments. To quantify these effects, we propose a set of language-level misalignment metrics that capture hallucination, critical omission, and safety misinterpretation, and analyze their relationship with segmentation quality across multiple contrastive and generative VLMs. Our results reveal a clear disconnect between pixel-level robustness and multimodal semantic reliability, highlighting a critical limitation of current VLM-based systems and motivating the need for evaluation frameworks that explicitly account for perception uncertainty in safety-critical applications.

</details>


### [42] [Geo-NVS-w: Geometry-Aware Novel View Synthesis In-the-Wild with an SDF Renderer](https://arxiv.org/abs/2601.08371)
*Anastasios Tsalakopoulos,Angelos Kanlis,Evangelos Chatzis,Antonis Karakottas,Dimitrios Zarpalas*

Main category: cs.CV

TL;DR: Geo-NVS-w 是一种几何感知的框架，用于从非结构化、真实场景图像集合中实现高保真新视角合成。它通过基于有符号距离函数（SDF）的几何表示和新颖的几何保持损失，显著提升了复杂表面的几何一致性，同时在渲染性能上表现优异，并将能耗降低4-5倍。


<details>
  <summary>Details</summary>
Motivation: 现有真实场景新视角合成方法虽已具备良好性能，但在复杂表面的几何一致性方面仍存在不足，常导致结果不一致，因此需要引入更强的几何引导机制。

Method: 利用有符号距离函数（SDF）构建底层几何表示，并设计几何保持损失来约束渲染过程，确保细节结构的准确保留。

Result: Geo-NVS-w 在保持高保真度的同时，显著提升了几何一致性，实现了更清晰、更真实的视觉效果，并将能量消耗降低4-5倍。

Conclusion: Geo-NVS-w 是一种鲁棒且高效的在真实场景下进行新视角合成的方法，能够生成具有精细几何一致性的逼真图像。

Abstract: We introduce Geo-NVS-w, a geometry-aware framework for high-fidelity novel view synthesis from unstructured, in-the-wild image collections. While existing in-the-wild methods already excel at novel view synthesis, they often lack geometric grounding on complex surfaces, sometimes producing results that contain inconsistencies. Geo-NVS-w addresses this limitation by leveraging an underlying geometric representation based on a Signed Distance Function (SDF) to guide the rendering process. This is complemented by a novel Geometry-Preservation Loss which ensures that fine structural details are preserved. Our framework achieves competitive rendering performance, while demonstrating a 4-5x reduction reduction in energy consumption compared to similar methods. We demonstrate that Geo-NVS-w is a robust method for in-the-wild NVS, yielding photorealistic results with sharp, geometrically coherent details.

</details>


### [43] [Source-Free Domain Adaptation for Geospatial Point Cloud Semantic Segmentation](https://arxiv.org/abs/2601.08375)
*Yuan Gao,Di Cao,Xiaohuan Xi,Sheng Nie,Shaobo Xia,Cheng Wang*

Main category: cs.CV

TL;DR: 本文提出LoGo（Local-Global Dual-Consensus），一种针对地理空间点云的源域无关无监督域适应（SFUDA）框架。通过局部类平衡原型估计和全局基于最优传输的分布对齐，有效解决长尾分布与头类主导问题，并结合双一致性伪标签过滤机制提升自训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有域适应方法依赖源域数据，但在遥感场景中受限于隐私、法规和传输限制，难以获取；因此需要在仅有预训练模型和目标域无标签数据的情况下实现有效适应，推动源域无关无监督域适应（SFUDA）的发展。

Method: 提出局部-全局双共识框架：局部采用类平衡原型估计，通过类内独立锚点挖掘生成稳健特征原型；全局引入基于最优传输的分布对齐，将伪标签分配建模为全局优化问题，纠正局部贪婪分配导致的头类偏倚；最后设计双一致性伪标签过滤机制，仅保留局部多增强预测与全局最优传输结果一致的高置信度伪标签用于自训练。

Result: 实验表明，该方法在多个地理空间点云数据集上显著优于现有SFUDA方法，在长尾分布和域偏移条件下表现更稳定，有效缓解了特征坍塌与类别偏倚问题。

Conclusion: LoGo框架通过局部与全局协同优化，实现了无需源域数据的高效域适应，为实际遥感应用中的模型泛化提供了可行方案。

Abstract: Semantic segmentation of 3D geospatial point clouds is pivotal for remote sensing applications. However, variations in geographic patterns across regions and data acquisition strategies induce significant domain shifts, severely degrading the performance of deployed models. Existing domain adaptation methods typically rely on access to source-domain data. However, this requirement is rarely met due to data privacy concerns, regulatory policies, and data transmission limitations. This motivates the largely underexplored setting of source-free unsupervised domain adaptation (SFUDA), where only a pretrained model and unlabeled target-domain data are available. In this paper, we propose LoGo (Local-Global Dual-Consensus), a novel SFUDA framework specifically designed for geospatial point clouds. At the local level, we introduce a class-balanced prototype estimation module that abandons conventional global threshold filtering in favor of an intra-class independent anchor mining strategy. This ensures that robust feature prototypes can be generated even for sample-scarce tail classes, effectively mitigating the feature collapse caused by long-tailed distributions. At the global level, we introduce an optimal transport-based global distribution alignment module that formulates pseudo-label assignment as a global optimization problem. By enforcing global distribution constraints, this module effectively corrects the over-dominance of head classes inherent in local greedy assignments, preventing model predictions from being severely biased towards majority classes. Finally, we propose a dual-consistency pseudo-label filtering mechanism. This strategy retains only high-confidence pseudo-labels where local multi-augmented ensemble predictions align with global optimal transport assignments for self-training.

</details>


### [44] [An Explainable Two Stage Deep Learning Framework for Pericoronitis Assessment in Panoramic Radiographs Using YOLOv8 and ResNet-50](https://arxiv.org/abs/2601.08401)
*Ajo Babu George,Pranav S,Kunal Agarwal*

Main category: cs.CV

TL;DR: 本文提出了一种结合解剖定位、病理分类和可解释性的AI辅助系统，用于改善全景牙片上智齿冠周炎的诊断。采用两阶段深度学习架构：第一阶段使用YOLOv8检测智齿并根据Winter分类法进行位置与角度分类；第二阶段使用改进的ResNet-50模型识别提示冠周炎的放射影像特征，并通过Grad-CAM增强可解释性。YOLOv8实现92%精度和92.5%平均精度；ResNet-50在正常和冠周炎病例中分别获得88%和86%的F1分数，且放射科医生对Grad-CAM热图与自身判断的一致性达84%，验证了其临床相关性。


<details>
  <summary>Details</summary>
Motivation: 当前在全景牙片上诊断智齿冠周炎存在挑战，尤其在缺乏明确影像学标志物时，临床诊断易受主观影响。因此需要一种能够自动识别解剖结构、分类病变状态并提供可解释结果的AI辅助系统，以提升诊断准确性和临床可信度。

Method: 采用两阶段深度学习框架：第一阶段基于YOLOv8模型实现第三磨牙的检测与解剖位置（按Winter分类）及角度分类；第二阶段利用改进的ResNet-50模型对疑似冠周炎的放射影像特征进行分类；同时引入Grad-CAM技术生成可视化热图，以增强诊断过程的可解释性。

Result: YOLOv8组件在检测与分类任务中达到92%的精度和92.5%的平均精度；第二阶段的ResNet-50分类器在正常与冠周炎样本上的F1得分分别为88%和86%；放射科医生评估显示，Grad-CAM生成的热点区域与他们诊断判断有84%的一致性，表明该系统具有良好的临床可解释性与实用性。

Conclusion: 该AI辅助系统在全景牙片分析中展现出良好潜力，尤其在结合解剖定位、病理分类与可解释性输出方面，有助于提高诊断准确性并增强临床医生对AI决策的信任。

Abstract: Objectives: To overcome challenges in diagnosing pericoronitis on panoramic radiographs, an AI-assisted assessment system integrating anatomical localization, pathological classification, and interpretability. Methods: A two-stage deep learning pipeline was implemented. The first stage used YOLOv8 to detect third molars and classify their anatomical positions and angulations based on Winter's classification. Detected regions were then fed into a second-stage classifier, a modified ResNet-50 architecture, for detecting radiographic features suggestive of pericoronitis. To enhance clinical trust, Grad-CAM was used to highlight key diagnostic regions on the radiographs. Results: The YOLOv8 component achieved 92% precision and 92.5% mean average precision. The ResNet-50 classifier yielded F1-scores of 88% for normal cases and 86% for pericoronitis. Radiologists reported 84% alignment between Grad-CAM and their diagnostic impressions, supporting the radiographic relevance of the interpretability output. Conclusion: The system shows strong potential for AI-assisted panoramic assessment, with explainable AI features that support clinical confidence.

</details>


### [45] [Edge-Optimized Multimodal Learning for UAV Video Understanding via BLIP-2](https://arxiv.org/abs/2601.08408)
*Yizhan Feng,Hichem Snoussi,Jing Teng,Jian Liu,Yuyang Wang,Abel Cherouat,Tian Wang*

Main category: cs.CV

TL;DR: 本文提出一种基于BLIP-2的轻量化多模态任务平台，集成YOLO-World和YOLOv8-Seg模型，以应对无人机边缘设备计算资源有限与大视觉语言模型高算力需求之间的矛盾。通过深度集成提升感知精度，设计基于K-Means的关键帧采样机制实现视频级交互，结合统一提示优化方案注入结构化事件日志并约束输出，实现无需特定微调的多任务适配。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在复杂场景中实时视觉理解与交互需求与边缘设备算力受限之间的矛盾，尤其针对大视觉语言模型计算成本高、难以部署于资源受限的无人机平台的问题。

Method: 1. 深度集成BLIP-2与YOLO系列模型，利用其精确的检测与分割结果增强视觉注意力与推理能力；2. 设计基于K-Means聚类的内容感知关键帧采样机制，结合时间特征拼接，支持视频级任务处理；3. 提出统一提示优化方案，将YOLO模型生成的结构化事件日志作为上下文注入，配合输出约束，引导模型生成准确且上下文相关的结果。

Result: 所提平台在无需任务特定微调的情况下，实现了对象检测、实例分割及视频级交互等多任务的高效运行，显著降低计算开销，同时保持高精度与实时性，适用于资源受限的无人机边缘计算环境。

Conclusion: 该轻量化多模态平台有效平衡了性能与效率，为无人机在复杂动态环境中实现高效、实时的视觉理解与交互提供了可行解决方案，具有良好的可扩展性和部署潜力。

Abstract: The demand for real-time visual understanding and interaction in complex scenarios is increasingly critical for unmanned aerial vehicles. However, a significant challenge arises from the contradiction between the high computational cost of large Vision language models and the limited computing resources available on UAV edge devices. To address this challenge, this paper proposes a lightweight multimodal task platform based on BLIP-2, integrated with YOLO-World and YOLOv8-Seg models. This integration extends the multi-task capabilities of BLIP-2 for UAV applications with minimal adaptation and without requiring task-specific fine-tuning on drone data. Firstly, the deep integration of BLIP-2 with YOLO models enables it to leverage the precise perceptual results of YOLO for fundamental tasks like object detection and instance segmentation, thereby facilitating deeper visual-attention understanding and reasoning. Secondly, a content-aware key frame sampling mechanism based on K-Means clustering is designed, which incorporates intelligent frame selection and temporal feature concatenation. This equips the lightweight BLIP-2 architecture with the capability to handle video-level interactive tasks effectively. Thirdly, a unified prompt optimization scheme for multi-task adaptation is implemented. This scheme strategically injects structured event logs from the YOLO models as contextual information into BLIP-2's input. Combined with output constraints designed to filter out technical details, this approach effectively guides the model to generate accurate and contextually relevant outputs for various tasks.

</details>


### [46] [SPARK: Scalable Real-Time Point Cloud Aggregation with Multi-View Self-Calibration](https://arxiv.org/abs/2601.08414)
*Chentian Sun*

Main category: cs.CV

TL;DR: SPARK是一种自校准的实时多相机点云重建框架，通过联合处理点云融合与外参不确定性，在动态场景中实现稳定、高精度的3D重建。其核心包括：基于多视图先验和跨视图/时序一致性的几何感知在线外参估计模块，以及基于置信度的点云融合策略，有效抑制噪声与视角依赖性不一致。该方法无需累积帧，支持线性扩展至大规模相机系统，实验证明其在外参精度、几何一致性、时间稳定性及实时性能方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角融合、相机外参不确定性以及大规模相机系统的可扩展性方面存在挑战，难以满足真实场景下对高精度、实时、稳定3D重建的需求。

Method: SPARK包含两个核心组件：(1) 几何感知的在线外参估计模块，利用多视图先验并强制跨视图和时间一致性以实现稳定自校准；(2) 基于置信度的点云融合策略，从像素和点级建模深度可靠性与可见性，抑制噪声和视差不一致。采用逐帧融合机制，避免累积误差。

Result: 在真实多相机系统上的大量实验表明，SPARK在相机外参估计精度、几何一致性、时间稳定性以及实时性能方面均显著优于现有方法，且具有良好的线性扩展能力，适用于大规模多相机3D重建任务。

Conclusion: SPARK成功实现了高精度、实时、可扩展的多相机3D点云重建，为复杂动态场景下的3D感知与交互提供了有效解决方案。

Abstract: Real-time multi-camera 3D reconstruction is crucial for 3D perception, immersive interaction, and robotics. Existing methods struggle with multi-view fusion, camera extrinsic uncertainty, and scalability for large camera setups. We propose SPARK, a self-calibrating real-time multi-camera point cloud reconstruction framework that jointly handles point cloud fusion and extrinsic uncertainty. SPARK consists of: (1) a geometry-aware online extrinsic estimation module leveraging multi-view priors and enforcing cross-view and temporal consistency for stable self-calibration, and (2) a confidence-driven point cloud fusion strategy modeling depth reliability and visibility at pixel and point levels to suppress noise and view-dependent inconsistencies. By performing frame-wise fusion without accumulation, SPARK produces stable point clouds in dynamic scenes while scaling linearly with the number of cameras. Extensive experiments on real-world multi-camera systems show that SPARK outperforms existing approaches in extrinsic accuracy, geometric consistency, temporal stability, and real-time performance, demonstrating its effectiveness and scalability for large-scale multi-camera 3D reconstruction.

</details>


### [47] [MMLGNet: Cross-Modal Alignment of Remote Sensing Data using CLIP](https://arxiv.org/abs/2601.08420)
*Aditya Chaudhary,Sneha Barman,Mainak Singha,Ankit Jha,Girish Mishra,Biplab Banerjee*

Main category: cs.CV

TL;DR: 本文提出一种新型多模态框架MMLGNet，通过CLIP等视觉-语言模型将高光谱成像（HSI）和激光雷达（LiDAR）等异构遥感模态与自然语言语义对齐，利用双方向对比学习在共享潜在空间中实现视觉特征与手工文本嵌入的对齐，仅用简单的CNN编码器即在两个基准数据集上超越多个现有纯视觉多模态方法，验证了语言监督的显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着多模态地球观测数据日益丰富，亟需有效融合光谱、空间和几何信息并实现语义级理解的方法，现有方法难以充分结合语言引导的解释能力。

Method: 采用模态特定编码器，通过双向对比学习将视觉特征与手工文本嵌入对齐于共享潜在空间，借鉴CLIP训练范式实现遥感数据与语言语义的跨模态对齐。

Result: MMLGNet在两个基准数据集上表现优异，仅使用简单CNN编码器即超越多个成熟的纯视觉多模态方法，证明语言监督对提升性能的关键作用。

Conclusion: MMLGNet成功实现了遥感数据与自然语言之间的语义对齐，展示了语言引导在多模态遥感分析中的强大潜力，为未来遥感智能解译提供了新思路。

Abstract: In this paper, we propose a novel multimodal framework, Multimodal Language-Guided Network (MMLGNet), to align heterogeneous remote sensing modalities like Hyperspectral Imaging (HSI) and LiDAR with natural language semantics using vision-language models such as CLIP. With the increasing availability of multimodal Earth observation data, there is a growing need for methods that effectively fuse spectral, spatial, and geometric information while enabling semantic-level understanding. MMLGNet employs modality-specific encoders and aligns visual features with handcrafted textual embeddings in a shared latent space via bi-directional contrastive learning. Inspired by CLIP's training paradigm, our approach bridges the gap between high-dimensional remote sensing data and language-guided interpretation. Notably, MMLGNet achieves strong performance with simple CNN-based encoders, outperforming several established multimodal visual-only methods on two benchmark datasets, demonstrating the significant benefit of language supervision. Codes are available at https://github.com/AdityaChaudhary2913/CLIP_HSI.

</details>


### [48] [Deep Learning Based Facial Retargeting Using Local Patches](https://arxiv.org/abs/2601.08429)
*Yeonsoo Choi,Inyup Lee,Sihun Cha,Seonghyeon Kim,Sunjin Jung,Junyong Noh*

Main category: cs.CV

TL;DR: 提出一种基于局部块的面部动作重定向方法，用于将源表演视频中的面部动画成功迁移至具有显著面部结构差异的风格化3D角色上，通过自动提取局部块、重演模块和权重估计模块实现语义保留的高质量动画生成。


<details>
  <summary>Details</summary>
Motivation: 现有面部动作重定向方法在相似形状模型间表现良好，但在处理风格化或夸张的3D角色时，因面部结构差异大，难以保持原始表情的语义，因此需要一种能考虑目标角色面部结构与运动范围的新方法。

Method: 提出三模块方法：1）自动局部块提取模块从源视频帧中提取局部面部区域；2）重演模块对提取的局部块进行重新演绎，生成目标角色对应的局部块；3）权重估计模块在每帧计算目标角色的动画参数，以构建完整的面部动画序列。

Result: 大量实验表明，该方法能够有效将源面部表情的语义传递到面部比例差异较大的风格化角色上，生成自然且语义一致的动画。

Conclusion: 所提出的局部块基重定向方法可有效解决风格化3D角色面部动画迁移中的语义失真问题，为非真实感角色的高保真表情动画提供了可行方案。

Abstract: In the era of digital animation, the quest to produce lifelike facial animations for virtual characters has led to the development of various retargeting methods. While the retargeting facial motion between models of similar shapes has been very successful, challenges arise when the retargeting is performed on stylized or exaggerated 3D characters that deviate significantly from human facial structures. In this scenario, it is important to consider the target character's facial structure and possible range of motion to preserve the semantics assumed by the original facial motions after the retargeting. To achieve this, we propose a local patch-based retargeting method that transfers facial animations captured in a source performance video to a target stylized 3D character. Our method consists of three modules. The Automatic Patch Extraction Module extracts local patches from the source video frame. These patches are processed through the Reenactment Module to generate correspondingly re-enacted target local patches. The Weight Estimation Module calculates the animation parameters for the target character at every frame for the creation of a complete facial animation sequence. Extensive experiments demonstrate that our method can successfully transfer the semantic meaning of source facial expressions to stylized characters with considerable variations in facial feature proportion.

</details>


### [49] [Incentivizing Cardiologist-Like Reasoning in MLLMs for Interpretable Echocardiographic Diagnosis](https://arxiv.org/abs/2601.08440)
*Yi Qin,Lehan Wang,Chenxu Zhao,Alex P. W. Lee,Xiaomeng Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为Cardiac Reasoning Template (CRT) 和 CardiacMind 的新方法，旨在提升多模态大语言模型（MLLM）在超声心动图诊断中的推理能力。CRT 提供了针对复杂心脏疾病的标准化诊断步骤，简化了推理路径的构建；CardiacMind 则引入三种新型奖励机制（PQtR、PQlR、ESR），分别鼓励详细推理、跨视图与模态证据整合以及视觉内容语义对齐。该方法在15种复杂心脏疾病上实现了48%的诊断性能提升，并在CardiacNet-PAH数据集上提升5%。临床医生评估显示93.33%的推理逻辑与心脏病专家一致。


<details>
  <summary>Details</summary>
Motivation: 现有超声心动图基础模型难以捕捉定量测量与临床表现之间的关系，而医学推理多模态大语言模型需要高昂成本构建详细推理路径，且无法有效融入超声心动图先验知识。

Method: 提出Cardiac Reasoning Template (CRT)，提供标准化诊断流程以简化推理路径；设计CardiacMind，基于三种奖励（PQtR、PQlR、ESR）的强化学习框架，激励模型生成符合临床思维的推理过程。

Result: 在15种复杂心脏疾病上实现48%的诊断性能提升，在CardiacNet-PAH上提升5%；用户研究显示93.33%的推理结果与心脏病专家逻辑一致。

Conclusion: 所提方法通过引入类心脏病专家的推理范式，显著提升了多模态大语言模型在超声心动图诊断中的准确性与可解释性，具备临床应用潜力。

Abstract: Echocardiographic diagnosis is vital for cardiac screening yet remains challenging. Existing echocardiography foundation models do not effectively capture the relationships between quantitative measurements and clinical manifestations, whereas medical reasoning multimodal large language models (MLLMs) require costly construction of detailed reasoning paths and remain ineffective at directly incorporating such echocardiographic priors into their reasoning. To address these limitations, we propose a novel approach comprising Cardiac Reasoning Template (CRT) and CardiacMind to enhance MLLM's echocardiographic reasoning by introducing cardiologist-like mindset. Specifically, CRT provides stepwise canonical diagnostic procedures for complex cardiac diseases to streamline reasoning path construction without the need for costly case-by-case verification. To incentivize reasoning MLLM under CRT, we develop CardiacMind, a new reinforcement learning scheme with three novel rewards: Procedural Quantity Reward (PQtR), Procedural Quality Reward (PQlR), and Echocardiographic Semantic Reward (ESR). PQtR promotes detailed reasoning; PQlR promotes integration of evidence across views and modalities, while ESR grounds stepwise descriptions in visual content. Our methods show a 48% improvement in multiview echocardiographic diagnosis for 15 complex cardiac diseases and a 5% improvement on CardiacNet-PAH over prior methods. The user study on our method's reasoning outputs shows 93.33% clinician agreement with cardiologist-like reasoning logic. Our code will be available.

</details>


### [50] [Noise-Adaptive Regularization for Robust Multi-Label Remote Sensing Image Classification](https://arxiv.org/abs/2601.08446)
*Tom Burgert,Julia Henkel,Begüm Demir*

Main category: cs.CV

TL;DR: 本文提出了一种名为NAR的噪声自适应正则化方法，用于解决遥感多标签分类中由主题产品或众包标注引入的标签噪声问题。该方法在半监督学习框架下区分加性噪声与减性噪声，通过置信度机制动态处理标签：高置信度保留、中等置信度暂时禁用、低置信度通过翻转修正。结合早期学习正则化（ELR）以稳定训练并缓解对污染标签的过拟合。实验表明，在加性、减性和混合噪声场景下，NAR均显著提升鲁棒性，尤其在减性和混合噪声下表现更优，验证了其自适应抑制与选择性修正策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 遥感数据规模扩大导致标注成本上升，依赖主题产品或众包标注虽降低成本，但引入部分错误的多标签噪声。现有方法未区分噪声类型，将所有噪声视为监督信号，缺乏针对不同噪声类型的自适应学习机制，影响模型鲁棒性。

Method: 提出NAR方法，基于置信度动态处理标签：高置信度标签保留，中等置信度标签暂时禁用，低置信度标签通过翻转修正；结合早期学习正则化（ELR），在半监督学习框架下实现对不同类型噪声的自适应调节。

Result: 在加性、减性和混合噪声场景下，NAR均优于现有方法，尤其在减性和混合噪声下性能提升显著，证明其在噪声鲁棒学习中的有效性。

Conclusion: NAR通过区分和自适应处理加性与减性噪声，有效提升了遥感多标签分类在噪声环境下的鲁棒性，是一种高效且可扩展的噪声应对策略。

Abstract: The development of reliable methods for multi-label classification (MLC) has become a prominent research direction in remote sensing (RS). As the scale of RS data continues to expand, annotation procedures increasingly rely on thematic products or crowdsourced procedures to reduce the cost of manual annotation. While cost-effective, these strategies often introduce multi-label noise in the form of partially incorrect annotations. In MLC, label noise arises as additive noise, subtractive noise, or a combination of both in the form of mixed noise. Previous work has largely overlooked this distinction and commonly treats noisy annotations as supervised signals, lacking mechanisms that explicitly adapt learning behavior to different noise types. To address this limitation, we propose NAR, a noise-adaptive regularization method that explicitly distinguishes between additive and subtractive noise within a semi-supervised learning framework. NAR employs a confidence-based label handling mechanism that dynamically retains label entries with high confidence, temporarily deactivates entries with moderate confidence, and corrects low confidence entries via flipping. This selective attenuation of supervision is integrated with early-learning regularization (ELR) to stabilize training and mitigate overfitting to corrupted labels. Experiments across additive, subtractive, and mixed noise scenarios demonstrate that NAR consistently improves robustness compared with existing methods. Performance improvements are most pronounced under subtractive and mixed noise, indicating that adaptive suppression and selective correction of noisy supervision provide an effective strategy for noise robust learning in RS MLC.

</details>


### [51] [Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.08448)
*Kexin Bao,Daichi Zhang,Yong Li,Dan Zeng,Shiming Ge*

Main category: cs.CV

TL;DR: 本文提出一种名为静态-动态协同（SDC）的框架，用于解决少样本类增量学习（FSCIL）中的稳定性-可塑性困境。该方法将学习过程分为静态保留阶段（SRS）和动态学习阶段（DLS），分别利用静态旧知识记忆和动态增量信息。在SRS中，使用充足数据训练初始模型并保存关键部分作为静态记忆；在DLS中，引入一个与静态记忆联合训练的动态投影器，以增强对新类别的适应能力。实验表明，该方法在多个公开基准和真实数据集上均达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 少样本类增量学习面临如何在保持旧知识的同时有效学习新类别的挑战，即稳定性-可塑性困境。现有方法难以平衡这两者，因此需要新的框架来提升性能。

Method: 将FSCIL流程分为两个阶段：静态保留阶段（SRS）和动态学习阶段（DLS）。SRS通过充分数据训练初始模型并保存关键部分作为静态记忆；DLS引入动态投影器与静态记忆联合训练，实现对新类别的持续适应。

Result: 在三个公开基准和一个真实世界应用数据集上的大量实验表明，所提方法在保持旧知识和学习新类别方面表现优异，显著优于现有方法，达到当前最优水平。

Conclusion: 所提出的静态-动态协同（SDC）框架有效缓解了FSCIL中的稳定性-可塑性矛盾，通过分阶段设计实现了更好的知识保留与增量学习平衡，具有较强的泛化能力和实际应用价值。

Abstract: Few-shot class-incremental learning (FSCIL) aims to continuously recognize novel classes under limited data, which suffers from the key stability-plasticity dilemma: balancing the retention of old knowledge with the acquisition of new knowledge. To address this issue, we divide the task into two different stages and propose a framework termed Static-Dynamic Collaboration (SDC) to achieve a better trade-off between stability and plasticity. Specifically, our method divides the normal pipeline of FSCIL into Static Retaining Stage (SRS) and Dynamic Learning Stage (DLS), which harnesses old static and incremental dynamic class information, respectively. During SRS, we train an initial model with sufficient data in the base session and preserve the key part as static memory to retain fundamental old knowledge. During DLS, we introduce an extra dynamic projector jointly trained with the previous static memory. By employing both stages, our method achieves improved retention of old knowledge while continuously adapting to new classes. Extensive experiments on three public benchmarks and a real-world application dataset demonstrate that our method achieves state-of-the-art performance against other competitors.

</details>


### [52] [Developing Predictive and Robust Radiomics Models for Chemotherapy Response in High-Grade Serous Ovarian Carcinoma](https://arxiv.org/abs/2601.08455)
*Sepideh Hatamikia,Geevarghese George,Florian Schwarzhans,Amirreza Mahbod,Marika AV Reinius,Ali Abbasian Ardakani,Mercedes Jimenez-Linan,Satish Viswanath,Mireia Crispin-Ortuzar,Lorena Escudero Sanchez,Evis Sala,James D Brenton,Ramona Woitek*

Main category: cs.CV

TL;DR: 本研究通过整合多种特征选择方法，利用影像组学与机器学习技术，基于CT影像数据提升高级别浆液性卵巢癌（HGSOC）患者接受新辅助化疗（NACT）反应的预测能力。研究采用自动化随机化算法模拟观察者间变异性，确保特征鲁棒性与预测准确性之间的平衡。使用四种响应指标（CRS、RECIST、VolR、DiaR）分析不同解剖部位病灶，结果显示总体病灶联合在VolR预测中表现最佳（AUC 0.83），网膜病灶对CRS预测最优（AUC 0.77），盆腔病灶对DiaR预测表现最好（AUC 0.76）。结论指出，将鲁棒性纳入特征选择流程有助于构建可靠的影像组学模型，推动其在临床中的应用。未来可探索影像组学在卵巢癌实时临床场景中的进一步应用。


<details>
  <summary>Details</summary>
Motivation: HGSOC通常在晚期诊断，伴有广泛腹膜转移，治疗困难。尽管新辅助化疗（NACT）可减少肿瘤负荷，但约40%患者反应有限。因此，亟需一种非侵入性、精准的预测方法以优化治疗决策。影像组学结合机器学习为实现这一目标提供了潜力，但现有方法受限于特征选择的稳定性和可重复性。本研究旨在通过引入鲁棒性评估机制，提升影像组学模型在预测NACT反应方面的可靠性与临床适用性。

Method: 提出一种集成鲁棒性评估的影像组学特征选择框架，采用自动化随机化算法模拟不同观察者间的影像解读差异，从而筛选出具有高稳定性与预测能力的特征。基于预处理和术后CT扫描提取影像特征，分别以化疗反应评分（CRS）、RECIST、体积减少率（VolR）和直径减少率（DiaR）作为响应指标，分析不同解剖部位（如网膜、盆腔等）病灶的预测性能。在训练队列中建模，并在独立外部队列中进行验证，评估模型泛化能力。

Result: 在所有病变联合分析中，VolR预测达到最高性能，AUC为0.83；网膜病变对CRS预测表现最佳，AUC为0.77；盆腔病变在DiaR预测中表现最优，AUC为0.76。结果表明，不同解剖部位对不同响应指标的预测能力存在差异，且引入鲁棒性筛选显著提升了模型的稳定性和准确性。外部验证队列中模型仍保持良好泛化能力。

Conclusion: 将特征鲁棒性纳入选择流程，能够有效提升影像组学模型的可靠性和临床转化潜力，为HGSOC患者新辅助化疗反应的精准预测提供有力支持。未来应进一步探索影像组学在真实临床环境中的动态应用，推动个体化治疗发展。

Abstract: Objectives: High-grade serous ovarian carcinoma (HGSOC) is typically diagnosed at an advanced stage with extensive peritoneal metastases, making treatment challenging. Neoadjuvant chemotherapy (NACT) is often used to reduce tumor burden before surgery, but about 40% of patients show limited response. Radiomics, combined with machine learning (ML), offers a promising non-invasive method for predicting NACT response by analyzing computed tomography (CT) imaging data. This study aimed to improve response prediction in HGSOC patients undergoing NACT by integration different feature selection methods. Materials and methods: A framework for selecting robust radiomics features was introduced by employing an automated randomisation algorithm to mimic inter-observer variability, ensuring a balance between feature robustness and prediction accuracy. Four response metrics were used: chemotherapy response score (CRS), RECIST, volume reduction (VolR), and diameter reduction (DiaR). Lesions in different anatomical sites were studied. Pre- and post-NACT CT scans were used for feature extraction and model training on one cohort, and an independent cohort was used for external testing. Results: The best prediction performance was achieved using all lesions combined for VolR prediction, with an AUC of 0.83. Omental lesions provided the best results for CRS prediction (AUC 0.77), while pelvic lesions performed best for DiaR (AUC 0.76). Conclusion: The integration of robustness into the feature selection processes ensures the development of reliable models and thus facilitates the implementation of the radiomics models in clinical applications for HGSOC patients. Future work should explore further applications of radiomics in ovarian cancer, particularly in real-time clinical settings.

</details>


### [53] [Modality-Decoupled RGB-Thermal Object Detector via Query Fusion](https://arxiv.org/abs/2601.08458)
*Chao Tian,Zikun Zhou,Chao Yang,Guoqing Zhu,Fu'an Zhong,Zhenyu He*

Main category: cs.CV

TL;DR: 提出一种基于查询融合的解耦式RGB-T检测框架（MDQF），通过在DETR-like检测器中分离RGB和TIR分支，并在每个优化阶段进行高质量查询的跨模态融合，有效排除劣质模态干扰，提升极端条件下的检测鲁棒性。同时支持使用非配对数据训练，减少对成对数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T检测方法在极端光照或天气条件下，由于某一模态质量下降导致噪声干扰，影响检测性能；因此需要在保持模态互补的同时实现模态分离，以提升系统鲁棒性。

Method: 采用解耦式架构，分别处理RGB与TIR图像，利用查询选择与适配机制，将高质量分支的查询注入另一分支进行预测修正；通过多阶段查询融合策略，在不依赖配对数据的情况下实现高效模态融合与分离。

Result: 实验表明，该方法在多种复杂环境下均优于现有RGB-T检测器，具备更强的模态独立性和检测性能，且可使用未配对数据进行训练，提升了实际应用灵活性。

Conclusion: 所提出的MDQF框架能够有效平衡模态互补与分离，在极端条件下实现更鲁棒的检测性能，同时降低对成对数据的依赖，具有良好的实用价值。

Abstract: The advantage of RGB-Thermal (RGB-T) detection lies in its ability to perform modality fusion and integrate cross-modality complementary information, enabling robust detection under diverse illumination and weather conditions. However, under extreme conditions where one modality exhibits poor quality and disturbs detection, modality separation is necessary to mitigate the impact of noise. To address this problem, we propose a Modality-Decoupled RGB-T detection framework with Query Fusion (MDQF) to balance modality complementation and separation. In this framework, DETR-like detectors are employed as separate branches for the RGB and TIR images, with query fusion interspersed between the two branches in each refinement stage. Herein, query fusion is performed by feeding the high-quality queries from one branch to the other one after query selection and adaptation. This design effectively excludes the degraded modality and corrects the predictions using high-quality queries. Moreover, the decoupled framework allows us to optimize each individual branch with unpaired RGB or TIR images, eliminating the need for paired RGB-T data. Extensive experiments demonstrate that our approach delivers superior performance to existing RGB-T detectors and achieves better modality independence.

</details>


### [54] [CoMa: Contextual Massing Generation with Vision-Language Models](https://arxiv.org/abs/2601.08464)
*Evgenii Maslov,Valentin Khrulkov,Anastasia Volkova,Anton Gusarov,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CV

TL;DR: 本文提出了一种基于功能需求和场地背景的建筑体量自动生成框架，解决了设计阶段依赖直觉与人力的问题。为支持数据驱动方法，作者构建了CoMa-20K数据集，包含详细的体量几何、经济与功能数据及场地视觉上下文信息。通过将体量生成建模为视觉-语言模型（VLM）的条件任务，对微调与零样本大模型进行评估，结果表明该任务具有复杂性，但VLM在生成符合上下文的建筑方案方面展现出潜力。该数据集与分析建立了基础基准，揭示了未来数据驱动建筑设计研究的重要机遇。


<details>
  <summary>Details</summary>
Motivation: 当前建筑体量设计阶段高度依赖设计师直觉和手动操作，缺乏系统化、数据驱动的方法支持，尤其受限于高质量数据集的缺失，亟需构建可支撑自动化设计的基准数据集与评估体系。

Method: 提出一种基于视觉-语言模型（VLM）的建筑体量生成框架，将任务建模为条件生成问题；利用新构建的CoMa-20K数据集，对微调模型与零样本大模型进行对比实验，以评估其生成能力与上下文敏感性。

Result: 实验表明，建筑体量生成任务具有显著复杂性，但VLM能够生成具有上下文感知特性的合理方案；所提出的CoMa-20K数据集有效支撑了基准测试，为后续研究提供了可靠基础。

Conclusion: 本研究通过构建大规模、多维度的建筑体量数据集并验证VLM在生成任务中的潜力，为数据驱动的建筑与城市设计奠定了重要基础，指明了未来研究方向。

Abstract: The conceptual design phase in architecture and urban planning, particularly building massing, is complex and heavily reliant on designer intuition and manual effort. To address this, we propose an automated framework for generating building massing based on functional requirements and site context. A primary obstacle to such data-driven methods has been the lack of suitable datasets. Consequently, we introduce the CoMa-20K dataset, a comprehensive collection that includes detailed massing geometries, associated economical and programmatic data, and visual representations of the development site within its existing urban context. We benchmark this dataset by formulating massing generation as a conditional task for Vision-Language Models (VLMs), evaluating both fine-tuned and large zero-shot models. Our experiments reveal the inherent complexity of the task while demonstrating the potential of VLMs to produce context-sensitive massing options. The dataset and analysis establish a foundational benchmark and highlight significant opportunities for future research in data-driven architectural design.

</details>


### [55] [Zero-Shot Distracted Driver Detection via Vision Language Models with Double Decoupling](https://arxiv.org/abs/2601.08467)
*Takamichi Miyata,Sumiko Miyata,Andrew Morris*

Main category: cs.CV

TL;DR: 本文针对视觉-语言模型（VLM）在检测分心驾驶时因受驾驶员个体外观特征（如衣着、年龄、性别）干扰而表现不佳的问题，提出一种主体解耦框架。该框架通过提取驾驶员外观嵌入并消除其对图像嵌入的影响，使模型更关注行为相关线索。同时，通过在Stiefel流形上进行度量投影来正交化文本嵌入，提升语义可分性且保持原意。实验表明该方法显著优于现有基线，具备实际道路安全应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉-语言模型的分心驾驶检测方法在真实场景中表现不佳，主要因为模型将驾驶员的个体外观特征（如衣着、年龄、性别）与行为线索混淆，导致判断依据偏向‘谁在开车’而非‘在做什么’，亟需解决这一偏差问题。

Method: 提出主体解耦框架，先提取驾驶员外观嵌入，并从图像嵌入中移除其影响；同时采用度量投影技术在Stiefel流形上正交化文本嵌入，以增强不同行为类别的可区分性，同时保持语义一致性。

Result: 实验结果显示，所提方法在多个基准上均取得一致性能提升，显著优于现有基线模型，验证了其在真实场景下检测分心驾驶的有效性和鲁棒性。

Conclusion: 通过解耦驾驶员外观与行为特征，并优化文本表示，本方法有效提升了VLM在分心驾驶检测任务中的零样本性能，为智能交通系统的道路安全应用提供了可行的技术路径。

Abstract: Distracted driving is a major cause of traffic collisions, calling for robust and scalable detection methods. Vision-language models (VLMs) enable strong zero-shot image classification, but existing VLM-based distracted driver detectors often underperform in real-world conditions. We identify subject-specific appearance variations (e.g., clothing, age, and gender) as a key bottleneck: VLMs entangle these factors with behavior cues, leading to decisions driven by who the driver is rather than what the driver is doing. To address this, we propose a subject decoupling framework that extracts a driver appearance embedding and removes its influence from the image embedding prior to zero-shot classification, thereby emphasizing distraction-relevant evidence. We further orthogonalize text embeddings via metric projection onto Stiefel manifold to improve separability while staying close to the original semantics. Experiments demonstrate consistent gains over prior baselines, indicating the promise of our approach for practical road-safety applications.

</details>


### [56] [Towards Safer Mobile Agents: Scalable Generation and Evaluation of Diverse Scenarios for VLMs](https://arxiv.org/abs/2601.08470)
*Takara Taniguchi,Kuniaki Saito,Atsushi Hashimoto*

Main category: cs.CV

TL;DR: HazardForge 是一个利用图像编辑模型生成复杂危险场景的可扩展管道，用于构建 MovSafeBench 基准测试，涵盖 7,254 张图像和问答对，评估视觉语言模型在异常与动态场景下的表现。结果显示，当面对异常物体或需要细致运动理解时，VLM 性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分覆盖复杂环境中多样的危险情况，特别是具有时空动态特征的异常场景，而图像编辑模型虽有潜力但难以生成包含移动、侵入和远距离物体的真实场景。

Method: 提出 HazardForge 管道，结合图像编辑模型、布局决策算法和验证模块，系统化生成具有真实感的复杂危险场景，并基于此构建 MovSafeBench 多选题基准。

Result: MovSafeBench 包含 13 类物体的 7,254 张图像与问答对；实验表明，视觉语言模型在异常物体存在或需精细运动理解的场景中性能显著下降。

Conclusion: HazardForge 能有效生成多样且真实的危险场景，所构建的 MovSafeBench 为评估 VLM 在复杂驾驶环境中的安全性提供了有力工具，揭示了当前模型在动态与异常情况下的局限性。

Abstract: Vision Language Models (VLMs) are increasingly deployed in autonomous vehicles and mobile systems, making it crucial to evaluate their ability to support safer decision-making in complex environments. However, existing benchmarks inadequately cover diverse hazardous situations, especially anomalous scenarios with spatio-temporal dynamics. While image editing models are a promising means to synthesize such hazards, it remains challenging to generate well-formulated scenarios that include moving, intrusive, and distant objects frequently observed in the real world. To address this gap, we introduce \textbf{HazardForge}, a scalable pipeline that leverages image editing models to generate these scenarios with layout decision algorithms, and validation modules. Using HazardForge, we construct \textbf{MovSafeBench}, a multiple-choice question (MCQ) benchmark comprising 7,254 images and corresponding QA pairs across 13 object categories, covering both normal and anomalous objects. Experiments using MovSafeBench show that VLM performance degrades notably under conditions including anomalous objects, with the largest drop in scenarios requiring nuanced motion understanding.

</details>


### [57] [An IoT-Enabled Smart Aquarium System for Real-Time Water Quality Monitoring and Automated Feeding](https://arxiv.org/abs/2601.08484)
*MD Fatin Ishraque Ayon,Sabrin Nahar,Ataur Rahman,Md. Taslim Arif,Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种基于物联网的智能鱼缸系统，利用ESP32微控制器集成多种传感器（pH、TDS、温度、浊度）和执行器（伺服喂食器、水泵），实现水质量的实时监测与自动控制。系统具备边缘计算能力、云连接（通过Blynk平台）及可配置的智能报警机制，有效减少误报。实验表明，系统平均传感器精度达96%，异常检测响应时间仅1.2秒，喂食与循环模块可靠性达97%，显著降低人工干预，提升管理效率。


<details>
  <summary>Details</summary>
Motivation: 传统鱼缸水质管理依赖人工操作，效率低、易出错，难以维持稳定水环境。为解决这一问题，亟需一种自动化、智能化的监控与调控方案。

Method: 采用ESP32作为核心控制器，集成多参数传感器与执行器，构建具备边缘处理与云端通信能力的IoT系统；通过Blynk平台实现远程监控，并引入可配置报警冷却期机制以避免通知泛滥。

Result: 在10升鱼缸环境中测试，系统实现96%的平均传感器精度，异常检测响应时间仅为1.2秒；自动喂食与水循环模块运行可靠性达97%，大幅减少人工干预，保障水质稳定。

Conclusion: 低成本物联网方案可有效革新鱼缸维护方式，使水族生态系统管理更高效、可靠且易于普及，适用于家庭及商业场景。

Abstract: Maintaining optimal water quality in aquariums is critical for aquatic health but remains challenging due to the need for continuous monitoring of multiple parameters. Traditional manual methods are inefficient, labor-intensive, and prone to human error, often leading to suboptimal aquatic conditions. This paper presents an IoT-based smart aquarium system that addresses these limitations by integrating an ESP32 microcontroller with multiple sensors (pH, TDS, temperature, turbidity) and actuators (servo feeder, water pump) for comprehensive real-time water quality monitoring and automated control. The system architecture incorporates edge processing capabilities, cloud connectivity via Blynk IoT platform, and an intelligent alert mechanism with configurable cooldown periods to prevent notification fatigue. Experimental evaluation in a 10-liter aquarium environment demonstrated the system's effectiveness, achieving 96\% average sensor accuracy and 1.2-second response time for anomaly detection. The automated feeding and water circulation modules maintained 97\% operational reliability throughout extended testing, significantly reducing manual intervention while ensuring stable aquatic conditions. This research demonstrates that cost-effective IoT solutions can revolutionize aquarium maintenance, making aquatic ecosystem management more accessible, reliable, and efficient for both residential and commercial applications.

</details>


### [58] [EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers](https://arxiv.org/abs/2601.08499)
*Wenwen Liao,Hang Ruan*

Main category: cs.CV

TL;DR: EfficientFSL 是一种专为视觉变压器（ViT）设计的仅查询微调框架，旨在解决大型模型在少样本分类中计算开销大的问题。通过引入轻量级可训练的 Forward Block、Combine Block 和 Support-Query Attention Block，仅需极少可训练参数即可实现高性能，显著降低内存占用和训练时间，在多个领域内与跨域数据集上均达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 大型模型如 ViT 在少样本分类中表现优异，但其微调需要大量 GPU 内存和长时间训练，难以应用于资源受限的实际场景。因此亟需一种高效且低开销的微调方法。

Method: 提出 EfficientFSL 框架，包含三个核心组件：1）轻量级 Forward Block 用于生成任务特定查询以提取中间表示中的信息；2）Combine Block 融合多层输出以增强特征深度与鲁棒性；3）Support-Query Attention Block 通过调整原型对齐查询分布，缓解分布偏移问题。整个过程仅微调极少量参数。

Result: EfficientFSL 在四个领域内少样本数据集和六个跨域数据集上均达到或超过现有方法的性能，同时大幅减少可训练参数和计算资源消耗，证明了其在真实场景中的有效性与实用性。

Conclusion: EfficientFSL 通过仅查询微调策略，充分利用预训练模型的知识与理解能力，在保持高分类精度的同时显著降低计算成本，是一种适用于低资源环境的高效少样本学习方案。

Abstract: Large models such as Vision Transformers (ViTs) have demonstrated remarkable superiority over smaller architectures like ResNet in few-shot classification, owing to their powerful representational capacity. However, fine-tuning such large models demands extensive GPU memory and prolonged training time, making them impractical for many real-world low-resource scenarios. To bridge this gap, we propose EfficientFSL, a query-only fine-tuning framework tailored specifically for few-shot classification with ViT, which achieves competitive performance while significantly reducing computational overhead. EfficientFSL fully leverages the knowledge embedded in the pre-trained model and its strong comprehension ability, achieving high classification accuracy with an extremely small number of tunable parameters. Specifically, we introduce a lightweight trainable Forward Block to synthesize task-specific queries that extract informative features from the intermediate representations of the pre-trained model in a query-only manner. We further propose a Combine Block to fuse multi-layer outputs, enhancing the depth and robustness of feature representations. Finally, a Support-Query Attention Block mitigates distribution shift by adjusting prototypes to align with the query set distribution. With minimal trainable parameters, EfficientFSL achieves state-of-the-art performance on four in-domain few-shot datasets and six cross-domain datasets, demonstrating its effectiveness in real-world applications.

</details>


### [59] [CD^2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.08519)
*Kexin Bao,Daichi Zhang,Hansong Zhang,Yong Li,Yutao Yue,Shiming Ge*

Main category: cs.CV

TL;DR: 提出一种名为CD²的框架，用于解决少样本类增量学习中的灾难性遗忘问题。该框架包含数据集蒸馏模块（DDM）和蒸馏约束模块（DCM），通过生成紧凑的合成样本并约束先前类别分布，有效保留历史知识，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少样本类增量学习中因灾难性遗忘导致旧知识丢失，且对增量类别同等处理，无法有效保护关键历史知识。

Method: 提出CD²框架，包含数据集蒸馏模块（DDM）和蒸馏约束模块（DCM）。DDM通过分类器引导生成紧凑的合成样本，使模型从少量增量样本中学习关键特征；DCM引入特定损失函数，约束先前类别分布，以更充分地保留蒸馏知识。

Result: 在三个公开数据集上的大量实验表明，该方法优于其他最先进的竞争方法，显著提升了少样本类增量学习的性能。

Conclusion: CD²框架通过有效的知识蒸馏与约束机制，成功缓解了少样本类增量学习中的灾难性遗忘问题，为持续学习提供了高效且鲁棒的解决方案。

Abstract: Few-shot class-incremental learning (FSCIL) receives significant attention from the public to perform classification continuously with a few training samples, which suffers from the key catastrophic forgetting problem. Existing methods usually employ an external memory to store previous knowledge and treat it with incremental classes equally, which cannot properly preserve previous essential knowledge. To solve this problem and inspired by recent distillation works on knowledge transfer, we propose a framework termed \textbf{C}onstrained \textbf{D}ataset \textbf{D}istillation (\textbf{CD$^2$}) to facilitate FSCIL, which includes a dataset distillation module (\textbf{DDM}) and a distillation constraint module~(\textbf{DCM}). Specifically, the DDM synthesizes highly condensed samples guided by the classifier, forcing the model to learn compacted essential class-related clues from a few incremental samples. The DCM introduces a designed loss to constrain the previously learned class distribution, which can preserve distilled knowledge more sufficiently. Extensive experiments on three public datasets show the superiority of our method against other state-of-the-art competitors.

</details>


### [60] [VideoHEDGE: Entropy-Based Hallucination Detection for Video-VLMs via Semantic Clustering and Spatiotemporal Perturbations](https://arxiv.org/abs/2601.08557)
*Sushant Gautam,Cise Midoglu,Vajira Thambawita,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: VideoHEDGE is a modular framework for detecting hallucinations in video question answering by extending entropy-based reliability estimation to temporal inputs. It uses multiple perturbed video clips and generates diverse answers, clustering them into semantic hypotheses via NLI or embedding methods. Three scores—Semantic Entropy (SE), RadFlag, and Vision-Amplified Semantic Entropy (VASE)—are derived from cluster-level probabilities. VASE outperforms others on SoccerChat benchmark with LLM-as-a-judge labels, especially under large distortions. Embedding-based clustering matches NLI performance at lower cost; domain fine-tuning reduces hallucinations but improves calibration only slightly. Code and resources available via hedge-bench PyPI and GitHub.


<details>
  <summary>Details</summary>
Motivation: Existing uncertainty metrics in Video-VLMs often fail to align with answer correctness, and hallucinations remain frequent and high-confidence. There's a need for reliable, scalable methods to detect hallucinations in video-question answering tasks.

Method: VideoHEDGE generates baseline and high-temperature answers from clean and perturbed video clips (photometric and spatiotemporal). Textual outputs are clustered using either NLI or embedding-based methods into semantic hypotheses. Reliability scores—SE, RadFlag, and VASE—are computed from cluster probability masses. Evaluation uses an LLM-as-a-judge on SoccerChat with binary hallucination labels.

Result: VASE achieves the highest ROC-AUC across three 7B Video-VLMs, particularly effective under larger distortion budgets. SE and RadFlag perform near chance. Embedding-based clustering matches NLI-based performance with significantly lower computational cost. Domain fine-tuning reduces hallucination frequency but offers only modest gains in calibration.

Conclusion: VideoHEDGE provides a robust, efficient, and extensible framework for hallucination detection in Video-VLMs. VASE emerges as a strong reliability metric, and embedding-based clustering offers a practical alternative to NLI. The results highlight that while fine-tuning helps reduce hallucinations, better calibration remains a challenge.

Abstract: Hallucinations in video-capable vision-language models (Video-VLMs) remain frequent and high-confidence, while existing uncertainty metrics often fail to align with correctness. We introduce VideoHEDGE, a modular framework for hallucination detection in video question answering that extends entropy-based reliability estimation from images to temporally structured inputs. Given a video-question pair, VideoHEDGE draws a baseline answer and multiple high-temperature generations from both clean clips and photometrically and spatiotemporally perturbed variants, then clusters the resulting textual outputs into semantic hypotheses using either Natural Language Inference (NLI)-based or embedding-based methods. Cluster-level probability masses yield three reliability scores: Semantic Entropy (SE), RadFlag, and Vision-Amplified Semantic Entropy (VASE). We evaluate VideoHEDGE on the SoccerChat benchmark using an LLM-as-a-judge to obtain binary hallucination labels. Across three 7B Video-VLMs (Qwen2-VL, Qwen2.5-VL, and a SoccerChat-finetuned model), VASE consistently achieves the highest ROC-AUC, especially at larger distortion budgets, while SE and RadFlag often operate near chance. We further show that embedding-based clustering matches NLI-based clustering in detection performance at substantially lower computational cost, and that domain fine-tuning reduces hallucination frequency but yields only modest improvements in calibration. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE#videohedge .

</details>


### [61] [End-to-End Video Character Replacement without Structural Guidance](https://arxiv.org/abs/2601.08587)
*Zhengbo Xu,Jie Ma,Ziheng Wang,Zhan Peng,Jun Liang,Jing Li*

Main category: cs.CV

TL;DR: MoCha提出一种无需成对视频数据的可控视频角色替换框架，仅需单帧任意掩码，通过条件感知的RoPE和基于强化学习的后训练阶段提升身份保真度，并构建了三个专用数据集以解决高质量训练数据稀缺问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖逐帧分割掩码和显式结构引导（如骨架、深度），在复杂场景（如遮挡、人物-物体交互、异常姿态、光照挑战）下泛化能力差，易产生视觉伪影和时间不一致。

Method: 提出MoCha框架，仅需单帧任意掩码；引入条件感知的RoPE以适应多模态输入；采用基于强化学习的后训练阶段增强面部身份一致性；设计三类数据集：UE5高保真渲染数据集、表达驱动的动画合成数据集、基于现有视频-掩码对的增强数据集。

Result: 大量实验表明，MoCha在视频角色替换任务中显著超越现有最先进方法，在复杂场景下表现更优，具备更强的鲁棒性和生成质量。

Conclusion: MoCha成功实现了仅需单帧掩码的可控视频角色替换，克服了传统方法对精细标注和结构引导的依赖，提升了在复杂场景下的性能与一致性，为未来研究提供了可复现的代码和数据支持。

Abstract: Controllable video character replacement with a user-provided identity remains a challenging problem due to the lack of paired video data. Prior works have predominantly relied on a reconstruction-based paradigm that requires per-frame segmentation masks and explicit structural guidance (e.g., skeleton, depth). This reliance, however, severely limits their generalizability in complex scenarios involving occlusions, character-object interactions, unusual poses, or challenging illumination, often leading to visual artifacts and temporal inconsistencies. In this paper, we propose MoCha, a pioneering framework that bypasses these limitations by requiring only a single arbitrary frame mask. To effectively adapt the multi-modal input condition and enhance facial identity, we introduce a condition-aware RoPE and employ an RL-based post-training stage. Furthermore, to overcome the scarcity of qualified paired-training data, we propose a comprehensive data construction pipeline. Specifically, we design three specialized datasets: a high-fidelity rendered dataset built with Unreal Engine 5 (UE5), an expression-driven dataset synthesized by current portrait animation techniques, and an augmented dataset derived from existing video-mask pairs. Extensive experiments demonstrate that our method substantially outperforms existing state-of-the-art approaches. We will release the code to facilitate further research. Please refer to our project page for more details: orange-3dv-team.github.io/MoCha

</details>


### [62] [Interpretability and Individuality in Knee MRI: Patient-Specific Radiomic Fingerprint with Reconstructed Healthy Personas](https://arxiv.org/abs/2601.08604)
*Yaxi Chen,Simin Ni,Shuai Li,Shaheer U. Saeed,Aleksandra Ivanova,Rikin Hargunani,Jie Huang,Chaozong Liu,Yipeng Hu*

Main category: cs.CV

TL;DR: 本文提出两种互补策略——放射组学指纹（radiomic fingerprints）和健康人格（healthy personas），以提升膝关节MRI自动评估中的准确性与可解释性。前者通过动态构建患者特异性特征集，基于图像条件预测特征重要性，实现个性化且可解释的分类；后者利用扩散模型生成每位患者的健康基线，通过对比病理图像与健康人格来识别异常，提供直观的病变解释。实验表明，两种方法在多项临床任务中性能媲美或超越先进深度学习模型，同时支持多层次可解释性，助力人类可理解的生物标志物发现与病灶定位。


<details>
  <summary>Details</summary>
Motivation: 传统放射组学依赖于群体层面预设特征，虽具可解释性但难以捕捉个体差异，性能受限；而端到端深度学习虽准确但缺乏可解释性。因此亟需兼顾个体化、可解释性与高性能的新方法，以推动MRI自动化评估在临床中的应用。

Method: 提出放射组学指纹：基于图像条件的特征重要性预测，结合透明逻辑回归进行分类；引入健康人格：使用扩散模型重建健康膝关节MRI作为个体化基准，通过对比分析病理图像与健康人格实现病变解释。

Result: 在三个临床任务中，放射组学指纹、健康人格及其组合均达到或超过现有深度学习模型的性能水平，同时保持了多层级可解释性。案例研究显示该方法有助于发现人类可理解的生物标志物并精确定位病理变化。

Conclusion: 所提方法有效融合了个体化建模与可解释性，在保证高精度的同时提升了临床可用性，为医学影像智能诊断提供了新范式。

Abstract: For automated assessment of knee MRI scans, both accuracy and interpretability are essential for clinical use and adoption. Traditional radiomics rely on predefined features chosen at the population level; while more interpretable, they are often too restrictive to capture patient-specific variability and can underperform end-to-end deep learning (DL). To address this, we propose two complementary strategies that bring individuality and interpretability: radiomic fingerprints and healthy personas. First, a radiomic fingerprint is a dynamically constructed, patient-specific feature set derived from MRI. Instead of applying a uniform population-level signature, our model predicts feature relevance from a pool of candidate features and selects only those most predictive for each patient, while maintaining feature-level interpretability. This fingerprint can be viewed as a latent-variable model of feature usage, where an image-conditioned predictor estimates usage probabilities and a transparent logistic regression with global coefficients performs classification. Second, a healthy persona synthesises a pathology-free baseline for each patient using a diffusion model trained to reconstruct healthy knee MRIs. Comparing features extracted from pathological images against their personas highlights deviations from normal anatomy, enabling intuitive, case-specific explanations of disease manifestations. We systematically compare fingerprints, personas, and their combination across three clinical tasks. Experimental results show that both approaches yield performance comparable to or surpassing state-of-the-art DL models, while supporting interpretability at multiple levels. Case studies further illustrate how these perspectives facilitate human-explainable biomarker discovery and pathology localisation.

</details>


### [63] [SfMamba: Efficient Source-Free Domain Adaptation via Selective Scan Modeling](https://arxiv.org/abs/2601.08608)
*Xi Chen,Hongxun Yao,Sicheng Zhao,Jiankun Zhu,Jing Jiang,Kui Jiang*

Main category: cs.CV

TL;DR: SfMamba提出一种新的无源域适应框架，通过引入通道感知的视觉状态空间块和语义一致打乱策略，有效解决现有方法在域不变特征学习中感知范围与计算效率之间的权衡问题，同时提升对通道频率特性的捕捉能力与空间鲁棒性，在多个基准测试中表现优于现有方法且参数效率高。


<details>
  <summary>Details</summary>
Motivation: 现有无源域适应方法在域不变特征学习中面临感知范围与计算效率的权衡，且难以有效捕捉通道级频率特征和维持空间鲁棒性，尤其在显著域偏移下表现不佳。

Method: 提出SfMamba框架，包含通道感知视觉状态空间块（实现通道-序列扫描以提取域不变特征）和语义一致打乱策略（扰乱2D选择性扫描中的背景补丁序列，保持预测一致性以减少误差累积）。

Result: 在多个基准上，SfMamba均取得优于现有方法的一致性更强性能，同时保持了良好的参数效率，为实际应用提供可行解决方案。

Conclusion: SfMamba通过创新的结构设计，有效提升了无源域适应中特征学习的稳定性与泛化能力，是当前最先进且高效的解决方案之一。

Abstract: Source-free domain adaptation (SFDA) tackles the critical challenge of adapting source-pretrained models to unlabeled target domains without access to source data, overcoming data privacy and storage limitations in real-world applications. However, existing SFDA approaches struggle with the trade-off between perception field and computational efficiency in domain-invariant feature learning. Recently, Mamba has offered a promising solution through its selective scan mechanism, which enables long-range dependency modeling with linear complexity. However, the Visual Mamba (i.e., VMamba) remains limited in capturing channel-wise frequency characteristics critical for domain alignment and maintaining spatial robustness under significant domain shifts. To address these, we propose a framework called SfMamba to fully explore the stable dependency in source-free model transfer. SfMamba introduces Channel-wise Visual State-Space block that enables channel-sequence scanning for domain-invariant feature extraction. In addition, SfMamba involves a Semantic-Consistent Shuffle strategy that disrupts background patch sequences in 2D selective scan while preserving prediction consistency to mitigate error accumulation. Comprehensive evaluations across multiple benchmarks show that SfMamba achieves consistently stronger performance than existing methods while maintaining favorable parameter efficiency, offering a practical solution for SFDA. Our code is available at https://github.com/chenxi52/SfMamba.

</details>


### [64] [SoC: Semantic Orthogonal Calibration for Test-Time Prompt Tuning](https://arxiv.org/abs/2601.08617)
*Leo Fillioux,Omprakash Chakraborty,Ismail Ben Ayed,Paul-Henry Cournède,Stergios Christodoulidis,Maria Vakalopoulou,Jose Dolz*

Main category: cs.CV

TL;DR: 本文提出了一种名为语义正交校准（SoC）的新方法，旨在解决视觉-语言模型在测试时提示调优（TPT）中不确定性估计校准不足的问题。现有方法通过强制文本提示嵌入完全正交以提升可分性，但理论分析表明这会导致语义相关类别被过度分离，从而引发模型过自信。为此，SoC采用基于Huber的正则化器，在保持语义相近性的同时实现平滑的原型分离，显著改善了校准性能，同时保持了良好的判别能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型在医疗、自动驾驶等关键决策系统中的应用日益广泛，其不确定性估计的校准至关重要。然而，现有测试时提示调优研究主要关注提升判别性能，忽视了校准问题。特别是，现有基于完全正交性的方法虽能增强类别可分性，但会因梯度作用导致语义相关类别被错误地过度分离，造成模型过自信，亟需一种既能保证可分性又不破坏语义结构的校准方法。

Method: 提出基于Huber损失的语义正交校准（SoC）正则化器，通过在提示嵌入空间中施加平滑的正交约束，避免完全正交带来的极端分离问题。该方法在保持语义相关类别的接近性的同时，实现有效的原型分离，从而改善模型输出的概率校准效果。

Result: 在多个基准数据集上的全面实证验证表明，SoC在提升模型校准性能方面显著优于现有的正交性方法，且未牺牲判别能力，实现了校准与性能之间的良好平衡。

Conclusion: SoC为视觉-语言模型的测试时提示调优提供了一种有效且稳健的校准机制，解决了传统正交约束带来的语义失真问题，推动了模型在高风险应用场景中的可信部署。

Abstract: With the increasing adoption of vision-language models (VLMs) in critical decision-making systems such as healthcare or autonomous driving, the calibration of their uncertainty estimates becomes paramount. Yet, this dimension has been largely underexplored in the VLM test-time prompt-tuning (TPT) literature, which has predominantly focused on improving their discriminative performance. Recent state-of-the-art advocates for enforcing full orthogonality over pairs of text prompt embeddings to enhance separability, and therefore calibration. Nevertheless, as we theoretically show in this work, the inherent gradients from fully orthogonal constraints will strongly push semantically related classes away, ultimately making the model overconfident. Based on our findings, we propose Semantic Orthogonal Calibration (SoC), a Huber-based regularizer that enforces smooth prototype separation while preserving semantic proximity, thereby improving calibration compared to prior orthogonality-based approaches. Across a comprehensive empirical validation, we demonstrate that SoC consistently improves calibration performance, while also maintaining competitive discriminative capabilities.

</details>


### [65] [CtrlFuse: Mask-Prompt Guided Controllable Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.08619)
*Yiming Sun,Yuan Ruan,Qinghua Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出CtrlFuse框架，通过掩码提示实现红外与可见光图像的可控制动态融合，结合多模态特征提取器、参考提示编码器（RPE）和提示-语义融合模块（PSFM），实现任务自适应的图像融合，显著提升融合可控性与分割精度，且任务分支性能优于原始分割模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法在像素级融合中忽视下游任务适应性，或通过级联检测/分割模型隐式学习固定语义，无法灵活响应多样化的语义目标感知需求。

Method: 设计了包含多模态特征提取器、参考提示编码器（RPE）和提示-语义融合模块（PSFM）的框架；RPE通过输入掩码引导微调预训练分割模型，动态编码任务特定语义提示；PSFM显式将这些语义注入融合特征；通过并行分割与融合分支的协同优化，实现任务性能与融合质量的相互增强。

Result: 实验表明，该方法在融合可控性和分割准确率方面均达到当前最优水平，且适配后的任务分支性能甚至超过原始分割模型。

Conclusion: CtrlFuse实现了基于掩码提示的交互式动态图像融合，有效提升了智能无人系统在复杂环境下的感知能力，具有良好的任务适应性与性能表现。

Abstract: Infrared and visible image fusion generates all-weather perception-capable images by combining complementary modalities, enhancing environmental awareness for intelligent unmanned systems. Existing methods either focus on pixel-level fusion while overlooking downstream task adaptability or implicitly learn rigid semantics through cascaded detection/segmentation models, unable to interactively address diverse semantic target perception needs. We propose CtrlFuse, a controllable image fusion framework that enables interactive dynamic fusion guided by mask prompts. The model integrates a multi-modal feature extractor, a reference prompt encoder (RPE), and a prompt-semantic fusion module (PSFM). The RPE dynamically encodes task-specific semantic prompts by fine-tuning pre-trained segmentation models with input mask guidance, while the PSFM explicitly injects these semantics into fusion features. Through synergistic optimization of parallel segmentation and fusion branches, our method achieves mutual enhancement between task performance and fusion quality. Experiments demonstrate state-of-the-art results in both fusion controllability and segmentation accuracy, with the adapted task branch even outperforming the original segmentation model.

</details>


### [66] [SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models](https://arxiv.org/abs/2601.08623)
*Renyang Liu,Kangjie Chen,Han Qiu,Jie Zhang,Kwok-Yan Lam,Tianwei Zhang,See-Kiong Ng*

Main category: cs.CV

TL;DR: SafeRedir 是一种轻量级的推理时框架，通过提示嵌入重定向实现鲁棒去记忆。它无需修改底层图像生成模型（IGMs），通过在嵌入空间中进行标记级干预，将不安全提示引导至安全语义区域。该框架包含两个核心组件：一个用于识别不安全生成轨迹的潜在感知多模态安全分类器，以及一个用于精确语义重定向的标记级增量生成器，配备辅助预测器以实现标记掩码和自适应缩放，从而定位并调控干预。实验表明，SafeRedir 在多个代表性去记忆任务中表现出有效的去记忆能力、高语义和感知保真度、优异的图像质量，并对对抗攻击具有更强的抵抗力。此外，其在多种扩散模型主干和现有去记忆模型上均表现良好，验证了其即插即用的兼容性和广泛适用性。代码与数据已公开。


<details>
  <summary>Details</summary>
Motivation: 图像生成模型常从训练数据中记忆不良概念，导致生成不安全内容（如NSFW图像、受版权保护的艺术风格），带来持续的安全与合规风险。现有后处理过滤机制鲁棒性差，难以实现细粒度控制；而现有的去记忆方法存在需昂贵重训练、损害良性生成质量或无法抵御提示改写与对抗攻击等问题。因此亟需一种高效、鲁棒且无需修改模型的去记忆方案。

Method: SafeRedir 采用推理时的轻量级框架，在不修改底层 IGM 的前提下，通过提示嵌入空间中的标记级干预实现安全重定向。其核心包括：1）潜在意图感知的多模态安全分类器，用于检测潜在不安全生成路径；2）标记级增量生成器，结合辅助预测器（用于标记掩码与自适应缩放），精准调整嵌入向量，引导提示进入安全语义区域。整个过程在推理阶段完成，无需重新训练。

Result: SafeRedir 在多个去记忆任务中展现出卓越性能：有效消除不安全内容生成，同时保持良好的语义一致性和图像质量；对提示改写和对抗攻击具有显著鲁棒性；支持多种扩散模型主干及已有去记忆模型，具备良好的泛化能力与即插即用特性。

Conclusion: SafeRedir 提供了一种高效、可扩展、无需重训练的推理时去记忆解决方案，能够有效应对图像生成模型中的安全风险，兼具强鲁棒性与广泛适用性，为现实场景中的安全部署提供了可靠保障。

Abstract: Image generation models (IGMs), while capable of producing impressive and creative content, often memorize a wide range of undesirable concepts from their training data, leading to the reproduction of unsafe content such as NSFW imagery and copyrighted artistic styles. Such behaviors pose persistent safety and compliance risks in real-world deployments and cannot be reliably mitigated by post-hoc filtering, owing to the limited robustness of such mechanisms and a lack of fine-grained semantic control. Recent unlearning methods seek to erase harmful concepts at the model level, which exhibit the limitations of requiring costly retraining, degrading the quality of benign generations, or failing to withstand prompt paraphrasing and adversarial attacks. To address these challenges, we introduce SafeRedir, a lightweight inference-time framework for robust unlearning via prompt embedding redirection. Without modifying the underlying IGMs, SafeRedir adaptively routes unsafe prompts toward safe semantic regions through token-level interventions in the embedding space. The framework comprises two core components: a latent-aware multi-modal safety classifier for identifying unsafe generation trajectories, and a token-level delta generator for precise semantic redirection, equipped with auxiliary predictors for token masking and adaptive scaling to localize and regulate the intervention. Empirical results across multiple representative unlearning tasks demonstrate that SafeRedir achieves effective unlearning capability, high semantic and perceptual preservation, robust image quality, and enhanced resistance to adversarial attacks. Furthermore, SafeRedir generalizes effectively across a variety of diffusion backbones and existing unlearned models, validating its plug-and-play compatibility and broad applicability. Code and data are available at https://github.com/ryliu68/SafeRedir.

</details>


### [67] [Além do Desempenho: Um Estudo da Confiabilidade de Detectores de Deepfakes](https://arxiv.org/abs/2601.08674)
*Lucas Lopes,Rayson Laroca,André Grégio*

Main category: cs.CV

TL;DR: 本文提出了一种基于可迁移性、鲁棒性、可解释性和计算效率四个支柱的深度伪造内容可靠性评估框架，分析了五种前沿检测方法，揭示了其进展与关键局限。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测技术虽有进步，但缺乏超越分类性能的综合性评估方法，亟需建立更全面的可靠性评价体系以应对虚假信息带来的风险。

Method: 提出一个涵盖可迁移性、鲁棒性、可解释性和计算效率四个维度的可靠性评估框架，并对五种先进检测方法进行系统分析。

Result: 分析表明现有方法在某些方面取得显著进展，但在可迁移性、鲁棒性及可解释性等方面仍存在明显不足，凸显了构建综合评估体系的必要性。

Conclusion: 需要发展更加全面和可靠的评估框架，以提升深度伪造检测技术的实际应用价值和可信度。

Abstract: Deepfakes are synthetic media generated by artificial intelligence, with positive applications in education and creativity, but also serious negative impacts such as fraud, misinformation, and privacy violations. Although detection techniques have advanced, comprehensive evaluation methods that go beyond classification performance remain lacking. This paper proposes a reliability assessment framework based on four pillars: transferability, robustness, interpretability, and computational efficiency. An analysis of five state-of-the-art methods revealed significant progress as well as critical limitations.

</details>


### [68] [Salience-SGG: Enhancing Unbiased Scene Graph Generation with Iterative Salience Estimation](https://arxiv.org/abs/2601.08728)
*Runfeng Qu,Ole Hall,Pia K Bideau,Julie Ouerfelli-Ethier,Martin Rolfs,Klaus Obermayer,Olaf Hellwich*

Main category: cs.CV

TL;DR: Salience-SGG 提出一种基于迭代显著性解码器（ISD）的新框架，通过引入语义无关的显著性标签，增强具有显著空间结构的三元组建模，有效缓解场景图生成中的长尾分布问题，同时提升模型的空间理解能力，在多个基准数据集上实现领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有无偏场景图生成方法虽能缓解长尾分布带来的偏差，但过度依赖语义先验，削弱了对空间关系的理解能力。因此，亟需在去偏的同时保持或提升空间感知能力。

Method: 提出迭代显著性解码器（ISD），结合语义无关的显著性标签，引导模型关注具有显著空间结构的三元组，从而平衡去偏与空间理解之间的矛盾。

Result: 在Visual Genome、Open Images V6和GQA-200数据集上均取得当前最优性能，且显著提升了现有无偏方法的空间定位精度，如Pairwise Localization Average Precision指标明显改善。

Conclusion: Salience-SGG 通过显式建模空间显著性，实现了在去偏与空间理解之间的良好平衡，为长尾场景图生成提供了新范式。

Abstract: Scene Graph Generation (SGG) suffers from a long-tailed distribution, where a few predicate classes dominate while many others are underrepresented, leading to biased models that underperform on rare relations. Unbiased-SGG methods address this issue by implementing debiasing strategies, but often at the cost of spatial understanding, resulting in an over-reliance on semantic priors. We introduce Salience-SGG, a novel framework featuring an Iterative Salience Decoder (ISD) that emphasizes triplets with salient spatial structures. To support this, we propose semantic-agnostic salience labels guiding ISD. Evaluations on Visual Genome, Open Images V6, and GQA-200 show that Salience-SGG achieves state-of-the-art performance and improves existing Unbiased-SGG methods in their spatial understanding as demonstrated by the Pairwise Localization Average Precision

</details>


### [69] [ISLA: A U-Net for MRI-based acute ischemic stroke lesion segmentation with deep supervision, attention, domain adaptation, and ensemble learning](https://arxiv.org/abs/2601.08732)
*Vincent Roca,Martin Bretzner,Hilde Henon,Laurent Puy,Grégory Kuchcinski,Renaud Lopes*

Main category: cs.CV

TL;DR: ISLA is a deep learning model for acute ischemic stroke lesion segmentation in diffusion MRI, trained on over 1500 patients across three multicenter databases. It optimizes loss functions, architecture, deep supervision, and attention mechanisms, and incorporates unsupervised domain adaptation for better generalization. ISLA outperforms existing methods on external data and will be publicly released for reproducibility.


<details>
  <summary>Details</summary>
Motivation: Accurate segmentation of acute ischemic stroke lesions in MRI is crucial for diagnosis and treatment, but current deep learning models lack consistency in design and are often not publicly available, making optimal configurations unclear.

Method: Systematic optimization of loss function, convolutional architecture, deep supervision, and attention mechanisms; use of unsupervised domain adaptation to enhance generalization across datasets.

Result: ISLA achieved superior performance compared to two state-of-the-art methods on an external test dataset and is designed for broad applicability and reuse.

Conclusion: ISLA provides a robust, optimized, and publicly available solution for automatic acute ischemic stroke lesion segmentation, advancing reproducibility and clinical utility in stroke imaging.

Abstract: Accurate delineation of acute ischemic stroke lesions in MRI is a key component of stroke diagnosis and management. In recent years, deep learning models have been successfully applied to the automatic segmentation of such lesions. While most proposed architectures are based on the U-Net framework, they primarily differ in their choice of loss functions and in the use of deep supervision, residual connections, and attention mechanisms. Moreover, many implementations are not publicly available, and the optimal configuration for acute ischemic stroke (AIS) lesion segmentation remains unclear. In this work, we introduce ISLA (Ischemic Stroke Lesion Analyzer), a new deep learning model for AIS lesion segmentation from diffusion MRI, trained on three multicenter databases totaling more than 1500 AIS participants. Through systematic optimization of the loss function, convolutional architecture, deep supervision, and attention mechanisms, we developed a robust segmentation framework. We further investigated unsupervised domain adaptation to improve generalization to an external clinical dataset. ISLA outperformed two state-of-the-art approaches for AIS lesion segmentation on an external test set. Codes and trained models will be made publicly available to facilitate reuse and reproducibility.

</details>


### [70] [DentalX: Context-Aware Dental Disease Detection with Radiographs](https://arxiv.org/abs/2601.08797)
*Zhi Qin Tan,Xiatian Zhu,Owen Addison,Yunpeng Li*

Main category: cs.CV

TL;DR: DentalX是一种基于上下文感知的牙科疾病检测方法，利用口腔结构信息缓解牙科放射影像中视觉模糊的问题。通过引入一个结构上下文提取模块，学习牙科解剖结构的语义分割作为辅助任务，从而提取有意义的结构上下文并融入主要疾病检测任务中，提升对细微牙科疾病的检测能力。实验表明，DentalX在专用基准上显著优于现有方法，且两个任务在优化过程中自然产生互惠效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于自然图像目标检测模型的方法难以应对牙科放射影像中诊断证据微弱、视觉支持不足的问题，因此需要一种能够利用口腔结构信息来增强检测能力的新方法。

Method: 提出DentalX框架，包含一个结构上下文提取模块，通过语义分割牙科解剖结构来学习辅助任务，并将提取的结构上下文整合到主疾病检测任务中，以增强对细微病变的识别能力。

Result: 在专用基准上的大量实验表明，DentalX在疾病检测任务上显著优于先前方法，且辅助任务与主任务之间存在自然的相互促进关系。

Conclusion: DentalX通过利用口腔结构上下文有效提升了牙科疾病检测性能，尤其在处理视觉线索微弱的病例时表现突出，为临床诊断提供了有力支持。

Abstract: Diagnosing dental diseases from radiographs is time-consuming and challenging due to the subtle nature of diagnostic evidence. Existing methods, which rely on object detection models designed for natural images with more distinct target patterns, struggle to detect dental diseases that present with far less visual support. To address this challenge, we propose {\bf DentalX}, a novel context-aware dental disease detection approach that leverages oral structure information to mitigate the visual ambiguity inherent in radiographs. Specifically, we introduce a structural context extraction module that learns an auxiliary task: semantic segmentation of dental anatomy. The module extracts meaningful structural context and integrates it into the primary disease detection task to enhance the detection of subtle dental diseases. Extensive experiments on a dedicated benchmark demonstrate that DentalX significantly outperforms prior methods in both tasks. This mutual benefit arises naturally during model optimization, as the correlation between the two tasks is effectively captured. Our code is available at https://github.com/zhiqin1998/DentYOLOX.

</details>


### [71] [Near-perfect photo-ID of the Hula painted frog with zero-shot deep local-feature matching](https://arxiv.org/abs/2601.08798)
*Maayan Yesharim,R. G. Bina Perl,Uri Roll,Sarig Gafny,Eli Geffen,Yoav Ram*

Main category: cs.CV

TL;DR: 本研究评估了先进的计算机视觉方法在无标记情况下对濒危的胡拉彩蛙进行照片重识别的性能，发现基于深度局部特征匹配的方法在零样本设置下表现最佳，准确率达98%。通过两阶段流程结合全局特征模型与局部特征匹配，显著提升效率，将处理时间从6.5-7.8小时缩短至约38分钟，同时保持约96%的识别准确率。该系统已部署为网页应用，支持非侵入式、快速、标准化的个体识别，适用于野外保护监测。


<details>
  <summary>Details</summary>
Motivation: 传统标记方法对极度濒危物种不适用，亟需一种非侵入性、高精度的个体识别技术以支持种群监测和捕获-再捕获分析。

Method: 采用深度局部特征匹配（零样本）与深度全局特征嵌入模型进行对比；设计两阶段工作流：先用微调后的全局特征模型筛选候选列表，再由局部特征匹配重新排序，实现高效且准确的识别。

Result: 局部特征匹配在闭集识别中达到98%的top-1准确率，优于所有全局模型；两阶段流程将运行时间从6.5-7.8小时降至约38分钟，保持96%以上准确率；分离的匹配分数支持开放集识别阈值设定，可有效处理新个体。

Conclusion: 在该物种中，零样本深度局部特征匹配优于全局特征嵌入方法，是照片识别的强默认方案，且可实际应用于野外保护监测。

Abstract: Accurate individual identification is essential for monitoring rare amphibians, yet invasive marking is often unsuitable for critically endangered species. We evaluate state-of-the-art computer-vision methods for photographic re-identification of the Hula painted frog (Latonia nigriventer) using 1,233 ventral images from 191 individuals collected during 2013-2020 capture-recapture surveys. We compare deep local-feature matching in a zero-shot setting with deep global-feature embedding models. The local-feature pipeline achieves 98% top-1 closed-set identification accuracy, outperforming all global-feature models; fine-tuning improves the best global-feature model to 60% top-1 (91% top-10) but remains below local matching. To combine scalability with accuracy, we implement a two-stage workflow in which a fine-tuned global-feature model retrieves a short candidate list that is re-ranked by local-feature matching, reducing end-to-end runtime from 6.5-7.8 hours to ~38 minutes while maintaining ~96% top-1 closed-set accuracy on the labeled dataset. Separation of match scores between same- and different-individual pairs supports thresholding for open-set identification, enabling practical handling of novel individuals. We deploy this pipeline as a web application for routine field use, providing rapid, standardized, non-invasive identification to support conservation monitoring and capture-recapture analyses. Overall, in this species, zero-shot deep local-feature matching outperformed global-feature embedding and provides a strong default for photo-identification.

</details>


### [72] [Reasoning Matters for 3D Visual Grounding](https://arxiv.org/abs/2601.08811)
*Hsiang-Wei Huang,Kuang-Ming Chen,Wenhao Chai,Cheng-Yen Yang,Jen-Hao Cheng,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: 本文提出了一种自动合成3D视觉定位数据及其对应推理过程的数据流水线，利用生成数据对LLM进行微调，构建了Reason3DVG-8B模型，在仅使用3D-GRAND 1.6%训练数据的情况下超越其性能，验证了该数据方法的有效性及推理在3D视觉定位中的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前3D视觉定位模型受限于推理能力，多数方法依赖大量标注数据进行监督训练，而基于合成数据的扩展虽被探索但性能提升有限且与数据成本不成比例。

Method: 设计自动化3D视觉定位数据合成流水线，生成包含推理过程的合成数据，并用于训练3D视觉定位大语言模型（Reason3DVG-8B）。

Result: Reason3DVG-8B在仅使用1.6%训练数据的情况下，性能超过先前基于LLM的方法3D-GRAND，证明了所提数据生成方法的有效性和推理能力的重要性。

Conclusion: 通过自动生成带推理过程的3D视觉定位数据并用于模型训练，显著提升了模型性能，表明推理能力在3D视觉理解中的关键作用。

Abstract: The recent development of Large Language Models (LLMs) with strong reasoning ability has driven research in various domains such as mathematics, coding, and scientific discovery. Meanwhile, 3D visual grounding, as a fundamental task in 3D understanding, still remains challenging due to the limited reasoning ability of recent 3D visual grounding models. Most of the current methods incorporate a text encoder and visual feature encoder to generate cross-modal fuse features and predict the referring object. These models often require supervised training on extensive 3D annotation data. On the other hand, recent research also focus on scaling synthetic data to train stronger 3D visual grounding LLM, however, the performance gain remains limited and non-proportional to the data collection cost. In this work, we propose a 3D visual grounding data pipeline, which is capable of automatically synthesizing 3D visual grounding data along with corresponding reasoning process. Additionally, we leverage the generated data for LLM fine-tuning and introduce Reason3DVG-8B, a strong 3D visual grounding LLM that outperforms previous LLM-based method 3D-GRAND using only 1.6% of their training data, demonstrating the effectiveness of our data and the importance of reasoning in 3D visual grounding.

</details>


### [73] [Motion Attribution for Video Generation](https://arxiv.org/abs/2601.08828)
*Xindi Wu,Despoina Paschalidou,Jun Gao,Antonio Torralba,Laura Leal-Taixé,Olga Russakovsky,Sanja Fidler,Jonathan Lorraine*

Main category: cs.CV

TL;DR: Motive 是首个专注于视频生成模型中运动属性归因的梯度框架，通过运动加权损失掩码分离时序动态与静态外观，实现高效可扩展的运动影响计算。该方法能识别对运动有显著影响的微调片段，并用于数据筛选，提升视频的时间一致性与物理合理性。使用 Motive 选中的高影响力数据后，模型在 VBench 上的人类偏好胜率达 74.1%，显著优于预训练基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型中数据对运动的影响机制尚不清晰，缺乏有效工具来量化和优化运动相关数据的作用，亟需一种能够分离并分析运动成分的数据归因方法。

Method: 提出 Motive 框架，采用基于梯度的归因方法，结合运动加权损失掩码，将时序动态与静态外观解耦，实现对视频生成模型中运动影响的精确追踪与量化。

Result: Motive 能有效识别对运动具有强影响力的微调片段；基于其筛选的数据进行微调后，模型在运动平滑性、动态程度和物理合理性方面均有显著提升，在 VBench 测试中获得 74.1% 的人类偏好胜率。

Conclusion: Motive 是首个针对视频生成模型中运动属性进行归因的框架，成功实现了运动影响的精准计算与数据优化，为高质量视频生成提供了可解释且有效的数据筛选新路径。

Abstract: Despite the rapid progress of video generation models, the role of data in influencing motion is poorly understood. We present Motive (MOTIon attribution for Video gEneration), a motion-centric, gradient-based data attribution framework that scales to modern, large, high-quality video datasets and models. We use this to study which fine-tuning clips improve or degrade temporal dynamics. Motive isolates temporal dynamics from static appearance via motion-weighted loss masks, yielding efficient and scalable motion-specific influence computation. On text-to-video models, Motive identifies clips that strongly affect motion and guides data curation that improves temporal consistency and physical plausibility. With Motive-selected high-influence data, our method improves both motion smoothness and dynamic degree on VBench, achieving a 74.1% human preference win rate compared with the pretrained base model. To our knowledge, this is the first framework to attribute motion rather than visual appearance in video generative models and to use it to curate fine-tuning data.

</details>


### [74] [3AM: Segment Anything with Geometric Consistency in Videos](https://arxiv.org/abs/2601.08831)
*Yang-Che Sun,Cheng Sun,Chin-Yang Lin,Fu-En Yang,Min-Hung Chen,Yen-Yu Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 3AM 提升了 SAM2 在大视角变化下的视频对象分割性能，通过在训练时融合来自 MUSt3R 的 3D 味觉特征，结合轻量级特征融合模块和视场感知采样策略，仅需 RGB 输入即可实现几何一致的识别，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: SAM2 等基于记忆的视频对象分割方法在大视角变化下表现不佳，因过度依赖外观特征；而传统 3D 实例分割方法需要相机位姿、深度图等复杂预处理。本文旨在解决这一问题，在不增加推理复杂度的前提下提升模型对视角变化的鲁棒性。

Method: 引入 3AM，利用训练阶段的 3D-aware 特征（来自 MUSt3R），设计轻量级 Feature Merger 融合多层级几何对应特征，并提出视场感知采样策略以确保学习可靠的 3D 对应关系，最终与 SAM2 的外观特征联合使用。

Result: 在包含宽基线运动的挑战性数据集（ScanNet++、Replica）上，3AM 显著超越 SAM2 及其扩展方法，达到 90.6% IoU 和 71.7% Positive IoU（ScanNet++ Selected Subset），相比当前最佳 VOS 方法提升 +15.9 和 +30.4 个百分点。

Conclusion: 3AM 无需推理时的相机位姿或额外预处理，仅用 RGB 输入即可实现强几何一致性，为视频对象分割提供了高效且鲁棒的新范式。

Abstract: Video object segmentation methods like SAM2 achieve strong performance through memory-based architectures but struggle under large viewpoint changes due to reliance on appearance features. Traditional 3D instance segmentation methods address viewpoint consistency but require camera poses, depth maps, and expensive preprocessing. We introduce 3AM, a training-time enhancement that integrates 3D-aware features from MUSt3R into SAM2. Our lightweight Feature Merger fuses multi-level MUSt3R features that encode implicit geometric correspondence. Combined with SAM2's appearance features, the model achieves geometry-consistent recognition grounded in both spatial position and visual similarity. We propose a field-of-view aware sampling strategy ensuring frames observe spatially consistent object regions for reliable 3D correspondence learning. Critically, our method requires only RGB input at inference, with no camera poses or preprocessing. On challenging datasets with wide-baseline motion (ScanNet++, Replica), 3AM substantially outperforms SAM2 and extensions, achieving 90.6% IoU and 71.7% Positive IoU on ScanNet++'s Selected Subset, improving over state-of-the-art VOS methods by +15.9 and +30.4 points. Project page: https://jayisaking.github.io/3AM-Page/

</details>


### [75] [RAVEN: Erasing Invisible Watermarks via Novel View Synthesis](https://arxiv.org/abs/2601.08832)
*Fahad Shamshad,Nils Lukas,Karthik Nandakumar*

Main category: cs.CV

TL;DR: 本文将隐形水印移除问题重新定义为视图合成任务，提出一种基于扩散模型的零样本框架，在不依赖水印知识或检测器的情况下，通过潜在空间中的可控几何变换与视图引导对应注意力，实现对15种水印方法的先进抑制效果，同时保持优异的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有隐形水印虽在像素空间和频域攻击下表现出一定鲁棒性，但对语义保持的视角变换攻击仍存在显著脆弱性，亟需评估其真实可靠性并指导更鲁棒的设计。

Method: 提出一种零样本扩散框架，利用潜在空间中的可控几何变换，并引入视图引导对应注意力机制以维持重建过程中的结构一致性，无需水印知识或检测器即可有效去除水印。

Result: 该方法在15种主流水印方案上均达到当前最佳的水印抑制性能，优于14个基线攻击方法，且在多个数据集上保持了优秀的感知质量。

Conclusion: 隐形水印在面对语义保持的视角变换时存在根本性漏洞，本文提出的扩散框架有效揭示并利用这一弱点，为水印安全评估与防御设计提供了新思路。

Abstract: Invisible watermarking has become a critical mechanism for authenticating AI-generated image content, with major platforms deploying watermarking schemes at scale. However, evaluating the vulnerability of these schemes against sophisticated removal attacks remains essential to assess their reliability and guide robust design. In this work, we expose a fundamental vulnerability in invisible watermarks by reformulating watermark removal as a view synthesis problem. Our key insight is that generating a perceptually consistent alternative view of the same semantic content, akin to re-observing a scene from a shifted perspective, naturally removes the embedded watermark while preserving visual fidelity. This reveals a critical gap: watermarks robust to pixel-space and frequency-domain attacks remain vulnerable to semantic-preserving viewpoint transformations. We introduce a zero-shot diffusion-based framework that applies controlled geometric transformations in latent space, augmented with view-guided correspondence attention to maintain structural consistency during reconstruction. Operating on frozen pre-trained models without detector access or watermark knowledge, our method achieves state-of-the-art watermark suppression across 15 watermarking methods--outperforming 14 baseline attacks while maintaining superior perceptual quality across multiple datasets.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [76] [EmbeddingRWKV: State-Centric Retrieval with Reusable States](https://arxiv.org/abs/2601.07861)
*Haowen Hou,Jie Yang*

Main category: cs.CL

TL;DR: 提出了一种名为State-Centric Retrieval的统一检索范式，通过引入“状态”作为连接嵌入模型与重排序器的桥梁，解决了传统两阶段RAG系统中信息不共享、计算冗余的问题。该方法基于RWKV架构的LLM进行微调，构建了可同时充当嵌入模型和状态提取骨干的EmbeddingRWKV模型，并设计了基于状态的重排序器，仅处理查询令牌即可实现推理成本与文档长度解耦，带来5.4×–44.8×的速度提升。此外，通过均匀层选择策略，仅使用25%的层即可保持98.62%的全模型性能。实验表明，该方法在保证高质量检索与重排序的同时显著提升了系统效率。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统采用两阶段管道（嵌入模型+重排序器），由于两阶段间缺乏信息共享，导致大量冗余计算，效率低下。为解决这一问题，需要一种能够整合两个阶段并减少重复计算的新范式。

Method: 1. 通过微调基于RWKV的LLM，构建EmbeddingRWKV模型，使其兼具嵌入模型与状态提取功能；2. 提出状态表示学习，生成紧凑且可复用的状态；3. 设计基于状态的重排序器，仅处理查询令牌，实现推理成本与文档长度解耦；4. 采用均匀层选择策略，在仅使用25%层的情况下维持近似全模型性能。

Result: 在保持98.62%全模型性能的前提下，推理速度提升5.4×–44.8×；系统整体效率显著增强，同时在检索与重排序任务中取得高质量结果。

Conclusion: State-Centric Retrieval通过引入状态作为信息桥梁，实现了嵌入与重排序的统一，有效减少了冗余计算，大幅提升了RAG系统的效率，且在性能上无明显损失，具有良好的实用价值。

Abstract: Current Retrieval-Augmented Generation (RAG) systems typically employ a traditional two-stage pipeline: an embedding model for initial retrieval followed by a reranker for refinement. However, this paradigm suffers from significant inefficiency due to the lack of shared information between stages, leading to substantial redundant computation. To address this limitation, we propose \textbf{State-Centric Retrieval}, a unified retrieval paradigm that utilizes "states" as a bridge to connect embedding models and rerankers. First, we perform state representation learning by fine-tuning an RWKV-based LLM, transforming it into \textbf{EmbeddingRWKV}, a unified model that serves as both an embedding model and a state backbone for extracting compact, reusable states. Building upon these reusable states, we further design a state-based reranker to fully leverage precomputed information. During reranking, the model processes only query tokens, decoupling inference cost from document length and yielding a 5.4$\times$--44.8$\times$ speedup. Furthermore, we observe that retaining all intermediate layer states is unnecessary; with a uniform layer selection strategy, our model maintains 98.62\% of full-model performance using only 25\% of the layers. Extensive experiments demonstrate that State-Centric Retrieval achieves high-quality retrieval and reranking results while significantly enhancing overall system efficiency. Code is available at \href{https://github.com/howard-hou/EmbeddingRWKV}{our GitHub repository}.

</details>


### [77] [A Human-Centric Pipeline for Aligning Large Language Models with Chinese Medical Ethics](https://arxiv.org/abs/2601.07954)
*Haoan Jin,Han Ying,Jiacheng Ji,Hanhui Xu,Mengyue Wu*

Main category: cs.CL

TL;DR: 本文提出MedES，一个基于260个权威中文医学、伦理和法律资料构建的动态、场景中心基准，用于评估大语言模型在复杂临床决策中的伦理表现。通过引入‘守护者在环’框架，利用高精度自动评估器生成针对性提示并提供结构化伦理反馈，对7B参数模型进行监督微调和领域特定偏好优化。实验表明，该对齐模型在中文医疗伦理任务中显著优于更大规模基线模型，在质量和综合评估指标上均有提升。研究为中文医疗领域大语言模型的伦理对齐提供了可复用框架，并指出该方法可推广至其他法律与文化环境。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在医疗任务中应用广泛，但其在复杂真实场景下的医疗伦理对齐仍缺乏深入研究，尤其在中文语境下相关工作不足。需要构建符合本地规范的评估基准与对齐机制以提升模型的伦理合规性与实用性。

Method: 构建MedES基准，整合260个权威中文来源；设计‘守护者在环’框架，使用基于专家标注数据训练的高精度自动评估器生成提示与反馈；采用监督微调与领域特定偏好优化对7B参数模型进行对齐。

Result: 在完全基于中文医疗伦理背景的实验中，对齐后的模型在核心伦理任务上显著优于更大规模基线模型，质量与综合评估指标均得到提升。

Conclusion: 本研究提出了一套可实践且可扩展的中文医疗伦理对齐框架，证明了通过场景化基准与自动化反馈机制实现模型对齐的有效性；该方法可通过替换规范语料库，推广至其他法律与文化背景。

Abstract: Recent advances in large language models have enabled their application to a range of healthcare tasks. However, aligning LLMs with the nuanced demands of medical ethics, especially under complex real world scenarios, remains underexplored. In this work, we present MedES, a dynamic, scenario-centric benchmark specifically constructed from 260 authoritative Chinese medical, ethical, and legal sources to reflect the challenges in clinical decision-making. To facilitate model alignment, we introduce a guardian-in-the-loop framework that leverages a dedicated automated evaluator (trained on expert-labeled data and achieving over 97% accuracy within our domain) to generate targeted prompts and provide structured ethical feedback. Using this pipeline, we align a 7B-parameter LLM through supervised fine-tuning and domain-specific preference optimization. Experimental results, conducted entirely within the Chinese medical ethics context, demonstrate that our aligned model outperforms notably larger baselines on core ethical tasks, with observed improvements in both quality and composite evaluation metrics. Our work offers a practical and adaptable framework for aligning LLMs with medical ethics in the Chinese healthcare domain, and suggests that similar alignment pipelines may be instantiated in other legal and cultural environments through modular replacement of the underlying normative corpus.

</details>


### [78] [Knowing But Not Doing: Convergent Morality and Divergent Action in LLMs](https://arxiv.org/abs/2601.07972)
*Jen-tse Huang,Jiantong Qin,Xueli Qiu,Sharon Levy,Michelle R. Kaufman,Mark Dredze*

Main category: cs.CL

TL;DR: 该研究构建了ValAct-15k数据集，包含3000个来自Reddit的求助场景，用于评估大型语言模型（LLMs）在十种基本人类价值观上的表现。研究发现，尽管不同模型在情景决策中表现出近乎完美的一致性（相关系数r≈1.0），但人类个体间差异显著（r∈[-0.79, 0.98]）。同时，无论是人类还是模型，自我报告的价值与实际行为之间均存在较弱的相关性（r=0.4, 0.3），揭示出“知行不一”的普遍现象。当被要求‘坚持’某一价值时，模型表现下降最多达6.6%，表明其存在角色扮演回避倾向。结果表明，对齐训练虽使模型在规范层面趋同，但仍保留类似人类的价值认知与行动间的不一致。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在真实决策情境中如何表征和践行人类价值观，揭示其与人类在价值一致性及知行关系上的异同，以推动安全且社会兼容的人工智能发展。

Method: 基于Reddit的3000个现实场景设计情景化问题，并结合传统的价值观问卷，评估10个前沿大模型（中美各5个）及55名人类参与者。通过比较模型间、人与模型间以及自报与行为之间的价值一致性，分析其价值表达模式与知行差距。

Result: LLMs在情景决策中表现出极高的内部一致性（Pearson r ≈ 1.0），而人类个体间差异大（r ∈ [-0.79, 0.98]）；人类与模型均显示自报值与行为值之间相关性弱（r = 0.4, 0.3）；当被指令‘坚持’某价值时，模型性能下降最高达6.6%，反映角色扮演回避。

Conclusion: 尽管对齐训练促使大模型在规范层面达成价值共识，但其仍未能消除类似于人类的“知行不一”现象，说明当前模型在价值内化与实践层面仍存在根本性局限。

Abstract: Value alignment is central to the development of safe and socially compatible artificial intelligence. However, how Large Language Models (LLMs) represent and enact human values in real-world decision contexts remains under-explored. We present ValAct-15k, a dataset of 3,000 advice-seeking scenarios derived from Reddit, designed to elicit ten values defined by Schwartz Theory of Basic Human Values. Using both the scenario-based questions and the traditional value questionnaire, we evaluate ten frontier LLMs (five from U.S. companies, five from Chinese ones) and human participants ($n = 55$). We find near-perfect cross-model consistency in scenario-based decisions (Pearson $r \approx 1.0$), contrasting sharply with the broad variability observed among humans ($r \in [-0.79, 0.98]$). Yet, both humans and LLMs show weak correspondence between self-reported and enacted values ($r = 0.4, 0.3$), revealing a systematic knowledge-action gap. When instructed to "hold" a specific value, LLMs' performance declines up to $6.6%$ compared to merely selecting the value, indicating a role-play aversion. These findings suggest that while alignment training yields normative value convergence, it does not eliminate the human-like incoherence between knowing and acting upon values.

</details>


### [79] [Explaining Generalization of AI-Generated Text Detectors Through Linguistic Analysis](https://arxiv.org/abs/2601.07974)
*Yuxi Xia,Kinga Stańczak,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文通过系统性语言学分析，研究AI文本检测器在不同生成条件下的泛化能力问题。构建了一个涵盖6种提示策略、7个大语言模型和4个领域数据集的综合性基准，评估检测器在跨提示、跨模型和跨数据集场景下的表现，并通过80个语言特征的特征偏移分析揭示了影响泛化性能的关键因素，如时态使用和代词频率。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测器在特定领域内表现良好，但在面对未见过的提示、模型家族或领域时泛化能力差，但其根本原因尚不明确，亟需深入理解以提升检测器的鲁棒性。

Method: 构建涵盖多种提示策略、大语言模型和领域数据集的综合基准；对分类型检测器进行不同生成设置下的微调与评估；计算训练与测试条件下80个语言特征的特征偏移，并分析其与泛化准确率的相关性。

Result: 发现检测器的泛化性能与特定语言特征（如时态使用、代词频率）的分布变化显著相关，表明语言层面的差异是导致泛化失败的重要原因。

Conclusion: 语言特征的分布偏移是影响AI文本检测器泛化性能的核心因素，未来检测器设计应考虑对关键语言特征的鲁棒性建模，以增强跨场景适应能力。

Abstract: AI-text detectors achieve high accuracy on in-domain benchmarks, but often struggle to generalize across different generation conditions such as unseen prompts, model families, or domains. While prior work has reported these generalization gaps, there are limited insights about the underlying causes. In this work, we present a systematic study aimed at explaining generalization behavior through linguistic analysis. We construct a comprehensive benchmark that spans 6 prompting strategies, 7 large language models (LLMs), and 4 domain datasets, resulting in a diverse set of human- and AI-generated texts. Using this dataset, we fine-tune classification-based detectors on various generation settings and evaluate their cross-prompt, cross-model, and cross-dataset generalization. To explain the performance variance, we compute correlations between generalization accuracies and feature shifts of 80 linguistic features between training and test conditions. Our analysis reveals that generalization performance for specific detectors and evaluation conditions is significantly associated with linguistic features such as tense usage and pronoun frequency.

</details>


### [80] [Multilingual, Multimodal Pipeline for Creating Authentic and Structured Fact-Checked Claim Dataset](https://arxiv.org/abs/2601.07985)
*Z. Melce Hüsünbeyi,Virginie Mouilleron,Leonie Uhling,Daniel Foppe,Tatjana Scheffler,Djamé Seddah*

Main category: cs.CL

TL;DR: 本文提出了一种全面的数据收集与处理流程，构建了法语和德语的多模态事实核查数据集。通过聚合ClaimReview信息源、抓取完整辟谣文章、标准化不一致的声明结论，并引入结构化元数据与对齐的视觉内容，结合先进的大语言模型（LLM）与多模态大语言模型，实现证据提取与理由生成。评估显示该方法可支持跨机构或媒体市场的细粒度比较，促进更可解释、基于证据的事实核查模型发展，为未来多语言、多模态虚假信息验证研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查数据集在范围、多模态证据、结构化标注及声明-证据-结论之间的关联性方面存在局限，难以满足实时、可解释、多语言的事实核查需求。

Method: 采用数据聚合、网页抓取、结论标准化、元数据结构化与视觉内容对齐的方法构建数据集；利用大语言模型（LLM）和多模态大语言模型进行证据分类提取与理由生成。

Result: 所构建的数据集支持跨组织、跨市场的细粒度分析，提升了事实核查模型的可解释性与证据依赖性，并为多语言、多模态虚假信息验证研究提供了坚实基础。

Conclusion: 本研究提出的管道有效克服了现有数据集的局限性，推动了多语言、多模态事实核查资源的发展，为构建更透明、可信的自动事实核查系统提供了关键支持。

Abstract: The rapid proliferation of misinformation across online platforms underscores the urgent need for robust, up-to-date, explainable, and multilingual fact-checking resources. However, existing datasets are limited in scope, often lacking multimodal evidence, structured annotations, and detailed links between claims, evidence, and verdicts. This paper introduces a comprehensive data collection and processing pipeline that constructs multimodal fact-checking datasets in French and German languages by aggregating ClaimReview feeds, scraping full debunking articles, normalizing heterogeneous claim verdicts, and enriching them with structured metadata and aligned visual content. We used state-of-the-art large language models (LLMs) and multimodal LLMs for (i) evidence extraction under predefined evidence categories and (ii) justification generation that links evidence to verdicts. Evaluation with G-Eval and human assessment demonstrates that our pipeline enables fine-grained comparison of fact-checking practices across different organizations or media markets, facilitates the development of more interpretable and evidence-grounded fact-checking models, and lays the groundwork for future research on multilingual, multimodal misinformation verification.

</details>


### [81] [VULCA-Bench: A Multicultural Vision-Language Benchmark for Evaluating Cultural Understanding](https://arxiv.org/abs/2601.07986)
*Haorui Yu,Ramon Ruiz-Dolz,Diji Yang,Hang He,Fengrui Zhang,Qiufeng Yi*

Main category: cs.CL

TL;DR: VULCA-Bench is a multicultural art-critique benchmark designed to evaluate Vision-Language Models' (VLMs) cultural understanding beyond basic visual perception. It includes 7,410 image-critique pairs across eight cultural traditions with bilingual (Chinese-English) coverage, organized via a five-layer framework (L1-L5) from visual perception to philosophical aesthetics. The benchmark reveals that higher-level cultural reasoning (L3-L5) is significantly more challenging than lower-level tasks (L1-L2). Resources are publicly available under CC BY 4.0.


<details>
  <summary>Details</summary>
Motivation: Existing VLM benchmarks primarily assess basic visual and factual capabilities (L1-L2), but fail to measure deeper cultural understanding required for nuanced art interpretation, which demands higher-order reasoning across cultural contexts.

Method: The study introduces a five-layer cultural understanding framework (L1-L5), constructs 225 culture-specific dimensions, and creates expert-written bilingual critiques paired with images. The dataset is curated across eight cultural traditions with Chinese-English bilingual coverage.

Result: Pilot evaluations show that L3–L5 reasoning tasks (cultural interpretation, aesthetic judgment, philosophical reflection) are consistently more difficult for current VLMs than L1–L2 tasks (object recognition and technical description).

Conclusion: VULCA-Bench provides a robust, culturally diverse benchmark for assessing advanced cultural understanding in VLMs, highlighting the need for models to go beyond surface-level perception toward deeper, context-sensitive interpretation.

Abstract: We introduce VULCA-Bench, a multicultural art-critique benchmark for evaluating Vision-Language Models' (VLMs) cultural understanding beyond surface-level visual perception. Existing VLM benchmarks predominantly measure L1-L2 capabilities (object recognition, scene description, and factual question answering) while under-evaluate higher-order cultural interpretation. VULCA-Bench contains 7,410 matched image-critique pairs spanning eight cultural traditions, with Chinese-English bilingual coverage. We operationalise cultural understanding using a five-layer framework (L1-L5, from Visual Perception to Philosophical Aesthetics), instantiated as 225 culture-specific dimensions and supported by expert-written bilingual critiques. Our pilot results indicate that higher-layer reasoning (L3-L5) is consistently more challenging than visual and technical analysis (L1-L2). The dataset, evaluation scripts, and annotation tools are available under CC BY 4.0 in the supplementary materials.

</details>


### [82] [From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP](https://arxiv.org/abs/2601.07988)
*Adithya V Ganesan,Vasudha Varadarajan,Oscar NE Kjell,Whitney R Ringwald,Scott Feltman,Benjamin J Luft,Roman Kotov,Ryan L Boyd,H Andrew Schwartz*

Main category: cs.CL

TL;DR: 本文提出了一种纵向建模与评估范式，以应对NLP中传统文档独立且无序的假设在纵向研究中的局限性。针对作者嵌套和时间有序的行为序列，提出了四个改进：跨人（cross-sectional）和跨时（prospective）的评估划分、区分个体间差异与个体内部动态的准确率指标、默认包含历史信息的序列输入，以及支持不同粒度隐状态（汇总、显式动态或交互式模型）的模型内部结构。在包含238名参与者17,000条日记文本与PTSD症状严重程度的数据集上验证，传统文档级评估可能导致与生态有效建模相反的结论。研究呼吁从词序列评估转向行为序列范式。


<details>
  <summary>Details</summary>
Motivation: 传统NLP假设文档独立且无序，但在纵向研究中，文档通常由同一作者随时间生成，具有嵌套和时序特性，因此需要新的建模与评估框架来更真实地反映人类行为的动态变化。

Method: 提出纵向建模范式，包括四方面改进：（1）基于人群和时间的评估划分；（2）分离个体间差异与个体内部动态的度量方式；（3）使用序列输入以默认纳入历史信息；（4）设计支持不同粒度隐状态的模型结构。

Result: 在17,000条日记文本与PTSD症状数据上，传统文档级评估得出的结论与生态有效建模结果存在显著差异，甚至方向相反，证明了新范式的必要性和有效性。

Conclusion: 应推动NLP从词序列评估向行为序列范式转变，以更好地捕捉人类行为的长期动态特征，提升模型在真实场景中的泛化能力。

Abstract: While NLP typically treats documents as independent and unordered samples, in longitudinal studies, this assumption rarely holds: documents are nested within authors and ordered in time, forming person-indexed, time-ordered $\textit{behavioral sequences}$. Here, we demonstrate the need for and propose a longitudinal modeling and evaluation paradigm that consequently updates four parts of the NLP pipeline: (1) evaluation splits aligned to generalization over people ($\textit{cross-sectional}$) and/or time ($\textit{prospective}$); (2) accuracy metrics separating between-person differences from within-person dynamics; (3) sequence inputs to incorporate history by default; and (4) model internals that support different $\textit{coarseness}$ of latent state over histories (pooled summaries, explicit dynamics, or interaction-based models). We demonstrate the issues ensued by traditional pipeline and our proposed improvements on a dataset of 17k daily diary transcripts paired with PTSD symptom severity from 238 participants, finding that traditional document-level evaluation can yield substantially different and sometimes reversed conclusions compared to our ecologically valid modeling and evaluation. We tie our results to a broader discussion motivating a shift from word-sequence evaluation toward $\textit{behavior-sequence}$ paradigms for NLP.

</details>


### [83] [DYCP: Dynamic Context Pruning for Long-Form Dialogue with LLMs](https://arxiv.org/abs/2601.07994)
*Nayoung Choi,Jonathan Zhang,Jinho D. Choi*

Main category: cs.CL

TL;DR: DyCP is a lightweight, dynamic context management method for Large Language Models (LLMs) that improves response quality and reduces latency in long dialogues by adaptively segmenting and retrieving relevant memory at query time. It preserves dialogue sequence without predefined topic boundaries and outperforms existing methods across multiple benchmarks and LLMs.


<details>
  <summary>Details</summary>
Motivation: Existing context management methods for LLMs suffer from inefficiencies due to extra LLM calls or offline memory construction, often ignoring the current user utterance, leading to degraded performance and disrupted conversational flow in long dialogues.

Method: DyCP dynamically segments dialogue history and retrieves relevant memory at query time using a lightweight mechanism that maintains sequential structure and adapts to current context without relying on predefined topics or external LLM calls.

Result: DyCP consistently improves answer quality and reduces response latency across three long-form dialogue benchmarks—LoCoMo, MT-Bench+, and SCM4LLMs—and multiple LLMs, demonstrating superior performance compared to existing approaches.

Conclusion: Despite expanded context windows in modern LLMs, effective context management remains crucial. DyCP offers an efficient, adaptive solution that enhances both performance and efficiency in long-context conversations.

Abstract: Large Language Models (LLMs) often exhibit increased response latency and degraded answer quality as dialogue length grows, making effective context management essential. However, existing methods rely on extra LLM calls to build memory or perform offline memory construction without considering the current user utterance, which can introduce inefficiencies or disrupt conversational continuity. We introduce DyCP, a lightweight context management method that dynamically segment and retrieve relevant memory at query time. It preserves the sequential structure of dialogue without predefined topic boundaries and supports efficient, adaptive context retrieval. Across three long-form dialogue benchmarks, LoCoMo, MT-Bench+, and SCM4LLMs, and multiple LLMs, DyCP consistently improves answer quality while reducing response latency. We also examine the gap between modern LLMs' expanded context windows and their actual long-context processing capacity, highlighting the continued importance of effective context management.

</details>


### [84] [Is Sentiment Banana-Shaped? Exploring the Geometry and Portability of Sentiment Concept Vectors](https://arxiv.org/abs/2601.07995)
*Laurits Lyngbaek,Pascale Feldkamp,Yuri Bizzoni,Kristoffer L. Nielbo,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 该研究评估了概念向量投影（CVP）在不同体裁、历史时期、语言和情感维度中的表现，发现其在不同语料库间具有良好的可迁移性，且性能损失较小。研究还探讨了CVP背后的线性假设，表明该假设为近似成立，提示未来有改进空间。


<details>
  <summary>Details</summary>
Motivation: 情感分析在人文学科中常需上下文相关的连续评分，而现有方法在跨领域和多语言场景下的可迁移性与假设基础尚不明确，亟需系统评估。

Method: 通过在多种体裁、历史时期、语言和情感维度上对概念向量投影（CVP）进行实验评估，检验其跨域泛化能力，并分析其线性假设的有效性。

Result: CVP在不同语料库间表现出良好的可迁移性，性能下降有限；但其线性假设仅为近似成立，存在优化潜力。

Conclusion: CVP是一种具有较强可移植性的方法，能有效捕捉普遍的情感模式，但其线性假设的近似性表明仍有进一步发展的空间。

Abstract: Use cases of sentiment analysis in the humanities often require contextualized, continuous scores. Concept Vector Projections (CVP) offer a recent solution: by modeling sentiment as a direction in embedding space, they produce continuous, multilingual scores that align closely with human judgments. Yet the method's portability across domains and underlying assumptions remain underexplored. We evaluate CVP across genres, historical periods, languages, and affective dimensions, finding that concept vectors trained on one corpus transfer well to others with minimal performance loss. To understand the patterns of generalization, we further examine the linearity assumption underlying CVP. Our findings suggest that while CVP is a portable approach that effectively captures generalizable patterns, its linearity assumption is approximate, pointing to potential for further development.

</details>


### [85] [LLM Review: Enhancing Creative Writing via Blind Peer Review Feedback](https://arxiv.org/abs/2601.08003)
*Weiyue Li,Mingxiao Song,Zhenda Shen,Dachuan Zhao,Yunfan Long,Yi Li,Yongce Li,Ruyi Yang,Mengyu Wang*

Main category: cs.CL

TL;DR: 提出LLM Review框架，通过类同行评审机制实现独立修订与针对性反馈，缓解多智能体系统中的创意同质化问题；构建SciFi-100数据集，融合LLM评分、人工标注与规则型新颖性度量，验证该框架在创意生成上的优越性，表明合理的交互结构可替代模型规模提升性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体框架虽提升推理能力，但常导致创意内容同质化，限制创造性生成；需设计新机制以保留多样性和原创性。

Method: 引入盲审式同行评审机制，各智能体独立修订并交换针对性反馈；构建SciFi-100科学小说生成数据集，结合LLM-as-a-judge评分、人工标注与规则驱动的新颖性指标进行评估。

Result: LLM Review在创意生成任务中持续优于现有多智能体基线；小型模型在该框架下表现超越大型单智能体模型，说明交互结构可部分替代模型规模带来的优势。

Conclusion: 交互结构的设计对创造性生成至关重要，合理的多智能体协作机制可在不依赖大模型的前提下显著提升创意质量。

Abstract: Large Language Models (LLMs) often struggle with creative generation, and multi-agent frameworks that improve reasoning through interaction can paradoxically hinder creativity by inducing content homogenization. We introduce LLM Review, a peer-review-inspired framework implementing Blind Peer Review: agents exchange targeted feedback while revising independently, preserving divergent creative trajectories. To enable rigorous evaluation, we propose SciFi-100, a science fiction writing dataset with a unified framework combining LLM-as-a-judge scoring, human annotation, and rule-based novelty metrics. Experiments demonstrate that LLM Review consistently outperforms multi-agent baselines, and smaller models with our framework can surpass larger single-agent models, suggesting interaction structure may substitute for model scale.

</details>


### [86] [Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models](https://arxiv.org/abs/2601.08058)
*Zhenghao He,Guangzhi Xiong,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: 本文通过稀疏自编码器（SAEs）分析和干预大语言模型（LLM）的内部表征，发现少量潜在特征与模型推理行为存在因果关联。仅调节一个推理相关的潜在特征即可显著提升准确率，且无需显式链式思维（CoT）提示。对于大模型，潜在线性调节的表现可媲美标准CoT提示，同时生成更高效。此外，该推理相关内部状态在生成早期即被触发，甚至能覆盖抑制显式推理的提示指令。结果表明，多步推理由可外部激活的内部激活支持，而CoT提示只是激活该机制的有效方式之一，而非必要条件。


<details>
  <summary>Details</summary>
Motivation: 探究链式思维（CoT）提示为何有效，以及它是否是触发大语言模型推理的唯一机制。

Method: 使用稀疏自编码器（SAEs）对大语言模型的内部表征进行分析与干预，识别与推理行为相关的潜在特征，并通过调节这些特征来观察模型表现变化。

Result: 调节单一推理相关潜在特征可显著提升准确率，且无需显式CoT提示；在大模型上性能接近标准CoT提示，但输出更高效；该内部状态在生成早期被激活，可覆盖反推理提示。

Conclusion: 大语言模型的多步推理依赖于可外部激活的内部潜变量，而CoT提示仅为激活该机制的有效手段之一，并非必要条件。

Abstract: Chain-of-Thought (CoT) prompting has improved the reasoning performance of large language models (LLMs), but it remains unclear why it works and whether it is the unique mechanism for triggering reasoning in large language models. In this work, we study this question by directly analyzing and intervening on the internal representations of LLMs with Sparse Autoencoders (SAEs), identifying a small set of latent features that are causally associated with LLM reasoning behavior. Across multiple model families and reasoning benchmarks, we find that steering a single reasoning-related latent feature can substantially improve accuracy without explicit CoT prompting. For large models, latent steering achieves performance comparable to standard CoT prompting while producing more efficient outputs. We further observe that this reasoning-oriented internal state is triggered early in generation and can override prompt-level instructions that discourage explicit reasoning. Overall, our results suggest that multi-step reasoning in LLMs is supported by latent internal activations that can be externally activated, while CoT prompting is one effective, but not unique, way of activating this mechanism rather than its necessary cause.

</details>


### [87] [Universal computation is intrinsic to language model decoding](https://arxiv.org/abs/2601.08061)
*Alex Lewandowski,Marlos C. Machado,Dale Schuurmans*

Main category: cs.CL

TL;DR: 该论文证明了语言模型通过链式自回归输出即可实现通用计算，即能够模拟任意算法在任意输入上的执行。即使在随机初始化状态下，语言模型也具备通用计算能力，表明训练并不赋予其计算表达能力，而是提升可编程性，使其能通过自然语言提示更有效地访问这些内在能力。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型的终极计算能力，解决其是否具备通用计算能力的科学争议，并重新思考如何通过提示工程实现所需计算行为。

Method: 通过理论证明语言模型的自回归输出链可以模拟任何算法的执行过程，验证随机初始化模型在未训练前也具备通用计算潜力。

Result: 证明了语言模型具有通用计算能力，且这种能力在训练前就已存在；训练的作用是提高可编程性而非引入计算能力。

Conclusion: 语言模型的通用计算能力源于其内在结构，训练主要提升的是通过自然语言提示来调用这些能力的效率，从而为构建自然语言接口提供理论基础。

Abstract: Language models now provide an interface to express and often solve general problems in natural language, yet their ultimate computational capabilities remain a major topic of scientific debate. Unlike a formal computer, a language model is trained to autoregressively predict successive elements in human-generated text. We prove that chaining a language model's autoregressive output is sufficient to perform universal computation. That is, a language model can simulate the execution of any algorithm on any input. The challenge of eliciting desired computational behaviour can thus be reframed in terms of programmability: the ease of finding a suitable prompt. Strikingly, we demonstrate that even randomly initialized language models are capable of universal computation before training. This implies that training does not give rise to computational expressiveness -- rather, it improves programmability, enabling a natural language interface for accessing these intrinsic capabilities.

</details>


### [88] [Calibration Is Not Enough: Evaluating Confidence Estimation Under Language Variations](https://arxiv.org/abs/2601.08064)
*Yuxi Xia,Dennis Ulmer,Terra Blevins,Yihong Liu,Hinrich Schütze,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文提出了一种全面的置信度估计（CE）评估框架，针对大语言模型（LLMs）在语义扰动、答案等价性及语义差异下的表现，引入三个新维度：对提示扰动的鲁棒性、跨语义等价答案的稳定性、对语义差异答案的敏感性。研究发现，现有主流CE方法在这些方面表现不佳，即使在校准或判别性上表现良好，也难以应对实际应用中的语言变体和语义变化。该框架揭示了现有评估的局限性，并为设计更可靠的CE方法提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计（CE）评估主要依赖校准和判别性，忽略了大语言模型在真实场景中面对语言变化时的表现需求，如对语义等价的提示或答案应保持一致置信度，而对语义不同的答案应能区分。因此需要一个更符合实际使用情境的综合评估框架。

Method: 提出三个新的评估维度：1）对提示扰动的鲁棒性；2）跨语义等价答案的稳定性；3）对语义不同答案的敏感性。通过实验验证多种主流CE方法在这三个维度上的表现。

Result: 多数现有CE方法在新评估维度上表现不佳，尤其在面对提示变化或语义等价答案时置信度不一致，或对语义差异反应迟钝。表明传统评估指标不足以反映真实场景中的置信度质量。

Conclusion: 当前的置信度估计评估存在明显盲区，亟需引入更全面的评价标准。本文提出的框架不仅揭示了现有方法的缺陷，也为未来可靠置信度估计的设计与选择提供了实践依据。

Abstract: Confidence estimation (CE) indicates how reliable the answers of large language models (LLMs) are, and can impact user trust and decision-making. Existing work evaluates CE methods almost exclusively through calibration, examining whether stated confidence aligns with accuracy, or discrimination, whether confidence is ranked higher for correct predictions than incorrect ones. However, these facets ignore pitfalls of CE in the context of LLMs and language variation: confidence estimates should remain consistent under semantically equivalent prompt or answer variations, and should change when the answer meaning differs. Therefore, we present a comprehensive evaluation framework for CE that measures their confidence quality on three new aspects: robustness of confidence against prompt perturbations, stability across semantic equivalent answers, and sensitivity to semantically different answers. In our work, we demonstrate that common CE methods for LLMs often fail on these metrics: methods that achieve good performance on calibration or discrimination are not robust to prompt variations or are not sensitive to answer changes. Overall, our framework reveals limitations of existing CE evaluations relevant for real-world LLM use cases and provides practical guidance for selecting and designing more reliable CE methods.

</details>


### [89] [AdaJudge: Adaptive Multi-Perspective Judging for Reward Modeling](https://arxiv.org/abs/2601.08097)
*Yongliang Miao,Yangyang Liang,Mengnan Du*

Main category: cs.CL

TL;DR: AdaJudge提出一种统一框架，通过门控精炼块将主干表示转换为判别导向空间，并采用自适应多视角池化模块动态路由和组合证据，克服了静态池化策略的局限性，在RM-Bench和JudgeBench上优于现有奖励模型和基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型依赖静态池化策略，存在静态归纳偏置与任务相关偏好信号不匹配、主干优化目标与细粒度判别需求不一致的问题。

Method: AdaJudge通过门控精炼块改进主干表示，使其适配判别任务；引入自适应多视角池化模块，动态选择并融合不同视图的信息，实现灵活的聚合机制。

Result: 在RM-Bench和JudgeBench上的实验表明，AdaJudge显著优于主流奖励模型和传统池化基线，展现出更强的对齐能力与泛化性能。

Conclusion: AdaJudge通过联合优化表示与聚合过程，有效缓解了静态池化带来的偏差与表征失配问题，为大语言模型的奖励建模提供了更灵活、高效的解决方案。

Abstract: Reward modeling is essential for aligning large language models with human preferences, yet predominant architectures rely on a static pooling strategy to condense sequences into scalar scores. This paradigm, however, suffers from two key limitations: a static inductive bias that misaligns with task-dependent preference signals, and a representational mismatch, as the backbone is optimized for generation rather than fine-grained discrimination. To address this, we propose AdaJudge, a unified framework that jointly adapts representation and aggregation. AdaJudge first refines backbone representations into a discrimination-oriented space via gated refinement blocks. It then replaces the static readout with an adaptive multi-view pooling module that dynamically routes and combines evidence. Extensive experiments on RM-Bench and JudgeBench show that AdaJudge outperforms strong off-the-shelf reward models and traditional pooling baselines.

</details>


### [90] [Query Suggestion for Retrieval-Augmented Generation via Dynamic In-Context Learning](https://arxiv.org/abs/2601.08105)
*Fabian Spaeh,Tianyi Chen,Chen-Hao Chiang,Bin Shen*

Main category: cs.CL

TL;DR: 本文研究了在工具调用型检索增强生成（agentic RAG）系统中，针对无法回答的用户问题提出可回答的建议查询。由于RAG系统多步流程复杂且执行模型缺乏整体理解能力，确保建议查询可回答是关键挑战。为此，作者提出一种鲁棒的动态少样本学习方法，通过检索相关工作流中的示例进行支持，并证明该系统可基于历史用户查询自学习，具有实际应用潜力。在三个基准数据集和两个真实世界用户查询数据集上的实验表明，该方法显著优于基线，能生成更相关、更可回答的建议，从而提升RAG交互的安全性与有效性。


<details>
  <summary>Details</summary>
Motivation: 当前agentic RAG系统受限于知识范围，当用户提问超出范围时易产生幻觉；虽有防护框架阻止不相关问题，但尚无研究关注如何主动建议可回答的问题以维持用户交互。尤其在工具调用场景下，难以向用户传达工具或数据集限制，因此需要智能建议机制来改善交互体验。

Method: 提出一种基于相关工作流动态检索示例的鲁棒动态少样本学习方法，利用历史用户查询实现自学习，确保建议查询在多步RAG流程中具备可回答性。

Result: 在三个基准数据集及两个真实世界数据集上的实验验证了该方法的有效性：相比传统少样本和仅检索基线，所提方法生成的建议查询更相关、更可回答，显著提升了RAG系统的安全性与交互效率。

Conclusion: 本研究首次系统探讨了agentic RAG中的查询建议问题，提出了一种可自学习、可实用的动态少样本方法，有效缓解了因知识局限导致的交互中断问题，为构建更安全、更智能的AI交互系统提供了新路径。

Abstract: Retrieval-augmented generation with tool-calling agents (agentic RAG) has become increasingly powerful in understanding, processing, and responding to user queries. However, the scope of the grounding knowledge is limited and asking questions that exceed this scope may lead to issues like hallucination. While guardrail frameworks aim to block out-of-scope questions (Rodriguez et al., 2024), no research has investigated the question of suggesting answerable queries in order to complete the user interaction.
  In this paper, we initiate the study of query suggestion for agentic RAG. We consider the setting where user questions are not answerable, and the suggested queries should be similar to aid the user interaction. Such scenarios are frequent for tool-calling LLMs as communicating the restrictions of the tools or the underlying datasets to the user is difficult, and adding query suggestions enhances the interaction with the RAG agent. As opposed to traditional settings for query recommendations such as in search engines, ensuring that the suggested queries are answerable is a major challenge due to the RAG's multi-step workflow that demands a nuanced understanding of the RAG as a whole, which the executing LLM lacks. As such, we introduce robust dynamic few-shot learning which retrieves examples from relevant workflows. We show that our system can be self-learned, for instance on prior user queries, and is therefore easily applicable in practice. We evaluate our approach on three benchmark datasets based on two unlabeled question datasets collected from real-world user queries. Experiments on real-world datasets confirm that our method produces more relevant and answerable suggestions, outperforming few-shot and retrieval-only baselines, and thus enable safer, more effective user interaction with agentic RAG.

</details>


### [91] [Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought](https://arxiv.org/abs/2601.08108)
*Bowen Li,Ziqi Xu,Jing Ren,Renqiang Luo,Xikun Zhang,Xiuzhen Zhang,Yongli Ren,Feng Xia*

Main category: cs.CL

TL;DR: ACPS提出了一种基于结构因果模型的自适应因果提示框架，通过推理查询对答案的因果效应并自适应选择干预方式（如标准前门和条件前门调整），实现跨异构任务的通用因果推理。该方法用简洁的Sketch-of-Thought替代冗长的Chain-of-Thought，显著降低令牌使用量和推理成本，在多个基准测试中均优于现有提示基线，提升准确率、鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有提示方法如Chain-of-Thought存在令牌消耗过高和跨任务泛化能力有限的问题，亟需更高效且通用的推理机制。

Method: 利用结构因果模型分析查询与答案间的因果关系，自适应选择前门调整策略，并以Sketch-of-Thought替代传统CoT进行推理。

Result: 在多个推理基准和LLM上，ACPS在准确性、鲁棒性和计算效率方面均显著优于现有提示方法。

Conclusion: ACPS通过因果推理与自适应干预机制，实现了高效、通用的推理范式，为大模型推理提供了新路径。

Abstract: Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.

</details>


### [92] [Attention Projection Mixing and Exogenous Anchors](https://arxiv.org/abs/2601.08131)
*Jonathan Su*

Main category: cs.CL

TL;DR: ExoFormer introduces external anchor projections to decouple the anchor role from computational refinement in Transformers, improving performance and data efficiency while reducing attention sink. Despite representation collapse, the method shows strong results and is released for further research.


<details>
  <summary>Details</summary>
Motivation: The fundamental tension in Transformers where the first layer must act as both a stable reference and an effective computational block limits model performance. This motivates the need for a solution that separates these roles.

Method: ExoFormer learns dedicated exogenous anchor projections outside the sequential layer stack, using a unified normalized mixing framework with varying coefficient granularities (elementwise, headwise, scalar) across all attention pathways (queries, keys, values, gate logits).

Result: ExoFormer variants outperform internal-anchor counterparts; the dynamic variant improves downstream accuracy by 2.13 points and achieves equivalent validation loss with 1.84x fewer tokens. It also reduces attention sink by 2x compared to standard Gated Attention.

Conclusion: ExoFormer resolves the anchor-computation trade-off by offloading anchors externally, enabling specialization in refinement. The observed representation collapse is explained by the Offloading Hypothesis: external anchors preserve token identity, allowing deeper layers to focus on computation.

Abstract: Transformers that reuse early-layer attention projections as residuals face a fundamental tension: the first layer must simultaneously serve as a stable reference for all deeper layers and as an effective computational block. To resolve this, we propose ExoFormer, which learns dedicated exogenous anchor projections outside the sequential layer stack, decoupling the anchor role from computational refinement. Through a unified normalized mixing framework (studying different coefficient granularities: elementwise, headwise, scalar) across all attention pathways (queries, keys, values, and gate logits), ExoFormer variants consistently outperform their internal-anchor counterparts. Moreover, the dynamic variant achieves a 2.13-point increase in downstream accuracy over the baseline and demonstrates superior data efficiency, matching baseline validation loss with 1.84x fewer tokens. ExoFormer also achieves a 2x reduction in attention sink compared to standard Gated Attention. Paradoxically, all ExoFormer variants exhibit signs of representation collapse. We explain this via an Offloading Hypothesis: external anchors preserve essential token identity, allowing layers to specialize exclusively in computational refinement. We release codes and models to facilitate future research.

</details>


### [93] [How Reliable are Confidence Estimators for Large Reasoning Models? A Systematic Benchmark on High-Stakes Domains](https://arxiv.org/abs/2601.08134)
*Reza Khanmohammadi,Erfan Miahi,Simerjot Kaur,Ivan Brugere,Charese H. Smiley,Kundan Thind,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: 本文提出推理模型置信度估计基准（RMCB），涵盖6种主流大推理模型的347,496条推理轨迹，覆盖临床、金融、法律、数学及通用复杂推理任务，提供正确性标注。基于该基准，评估了十余种基于表示的方法，发现文本编码器在判别能力（AUROC）上表现最佳（0.672），结构感知模型在校准性（ECE）上最优（0.148），二者存在持续权衡；复杂架构并未显著优于简单序列基线，表明仅依赖片段级隐藏状态的方法存在性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大推理模型在高风险领域中的置信度估计存在严重误标定问题，亟需有效方法来准确评估其多步长输出的置信水平。

Method: 构建RMCB基准，涵盖多种架构家族的大推理模型，使用多样化高风险与通用推理数据集，对十种基于表示的方法（包括序列、图结构和文本架构）进行大规模实证评估。

Result: 文本编码器在判别能力（AUROC）上表现最佳（0.672），结构感知模型在校准性（ECE）上最优（0.148），二者存在持续权衡；更复杂的模型架构并不一定优于简单序列基线，表明当前基于表示的方法存在性能天花板。

Conclusion: 本研究提供了迄今为止最全面的置信度估计基准，建立了严格基线，揭示了现有表示方法在判别与校准之间的根本性权衡及其局限性。

Abstract: The miscalibration of Large Reasoning Models (LRMs) undermines their reliability in high-stakes domains, necessitating methods to accurately estimate the confidence of their long-form, multi-step outputs. To address this gap, we introduce the Reasoning Model Confidence estimation Benchmark (RMCB), a public resource of 347,496 reasoning traces from six popular LRMs across different architectural families. The benchmark is constructed from a diverse suite of datasets spanning high-stakes domains, including clinical, financial, legal, and mathematical reasoning, alongside complex general reasoning benchmarks, with correctness annotations provided for all samples. Using RMCB, we conduct a large-scale empirical evaluation of over ten distinct representation-based methods, spanning sequential, graph-based, and text-based architectures. Our central finding is a persistent trade-off between discrimination (AUROC) and calibration (ECE): text-based encoders achieve the best AUROC (0.672), while structurally-aware models yield the best ECE (0.148), with no single method dominating both. Furthermore, we find that increased architectural complexity does not reliably outperform simpler sequential baselines, suggesting a performance ceiling for methods relying solely on chunk-level hidden states. This work provides the most comprehensive benchmark for this task to date, establishing rigorous baselines and demonstrating the limitations of current representation-based paradigms.

</details>


### [94] [Relational Knowledge Distillation Using Fine-tuned Function Vectors](https://arxiv.org/abs/2601.08169)
*Andrea Kang,Yingnian Wu,Hongjing Lu*

Main category: cs.CL

TL;DR: Fine-tuning a small set of function vectors improves semantic relation modeling and analogical reasoning in LLMs. Composite function vectors enhance performance on analogy tasks, demonstrating activation patching as a powerful tool for interpretable and robust reasoning.


<details>
  <summary>Details</summary>
Motivation: To improve the representation of semantic relations in language models for better reasoning and interpretability, especially in relation-based tasks and analogical reasoning.

Method: Fine-tuning function vectors derived from causal mediation analysis using a small set of word pairs (around 20), and introducing a composite function vector formed by weighted combinations of these fine-tuned vectors to enhance relational knowledge extraction and inference.

Result: Fine-tuned function vectors outperform original vectors on relation-based word-completion tasks across both small and large language models; they also improve decoding performance for relation words and align more closely with human similarity judgments. The composite function vector significantly boosts performance on challenging analogy problems from cognitive science and SAT benchmarks.

Conclusion: Activation patching using fine-tuned and composite function vectors provides a controllable and effective mechanism to encode and manipulate relational knowledge, enhancing both interpretability and reasoning capabilities of large language models.

Abstract: Representing relations between concepts is a core prerequisite for intelligent systems to make sense of the world. Recent work using causal mediation analysis has shown that a small set of attention heads encodes task representation in in-context learning, captured in a compact representation known as the function vector. We show that fine-tuning function vectors with only a small set of examples (about 20 word pairs) yields better performance on relation-based word-completion tasks than using the original vectors derived from causal mediation analysis. These improvements hold for both small and large language models. Moreover, the fine-tuned function vectors yield improved decoding performance for relation words and show stronger alignment with human similarity judgments of semantic relations. Next, we introduce the composite function vector - a weighted combination of fine-tuned function vectors - to extract relational knowledge and support analogical reasoning. At inference time, inserting this composite vector into LLM activations markedly enhances performance on challenging analogy problems drawn from cognitive science and SAT benchmarks. Our results highlight the potential of activation patching as a controllable mechanism for encoding and manipulating relational knowledge, advancing both the interpretability and reasoning capabilities of large language models.

</details>


### [95] [Prompt-Based Clarity Evaluation and Topic Detection in Political Question Answering](https://arxiv.org/abs/2601.08176)
*Lavanya Prahallad,Sai Utkarsh Choudarypally,Pragna Prahallad,Pranathi Prahallad*

Main category: cs.CL

TL;DR: 本研究探讨了提示设计对大语言模型（LLM）回答清晰度自动评估的影响，基于SemEval 2026共享任务中的CLARITY数据集，比较GPT-3.5与GPT-5.2在三种提示策略下的表现：简单提示、思维链提示和带少样本示例的思维链提示。结果显示，GPT-5.2在清晰度预测上显著优于GPT-3.5，准确率从56%提升至63%；思维链加少样本提示在清晰度评估中表现最佳。尽管推理类提示提升了主题识别准确率（从60%升至74%），但细粒度的逃避行为分类仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 当前自动评估大语言模型回答时，不仅需关注事实正确性，还需重视清晰度，尤其在政治问答场景中。然而，提示设计对清晰度评估的影响尚未充分研究，亟需探索有效提示策略以提升评估性能。

Method: 基于CLARITY数据集，采用GPT-3.5作为基线，对比GPT-5.2在三种提示策略下的表现：简单提示、思维链提示、思维链加少样本示例。通过与人工标注对比，使用准确率、类别级指标及层级精确匹配评估模型在清晰度与逃避行为预测上的性能，并分析主题识别效果。

Result: GPT-5.2在所有提示策略下均优于GPT-3.5，清晰度预测准确率从56%提升至63%；思维链加少样本提示在清晰度评估中表现最佳。思维链提示在逃避行为预测上达到最高准确率（34%），但细粒度类别间表现不一致。主题识别准确率从60%提升至74%，表明推理类提示有助于高层次理解。

Conclusion: 提示设计能显著提升大语言模型在高阶清晰度评估中的表现，但细粒度逃避行为识别与主题检测仍面临挑战，需进一步优化提示结构与训练方法。

Abstract: Automatic evaluation of large language model (LLM) responses requires not only factual correctness but also clarity, particularly in political question-answering. While recent datasets provide human annotations for clarity and evasion, the impact of prompt design on automatic clarity evaluation remains underexplored. In this paper, we study prompt-based clarity evaluation using the CLARITY dataset from the SemEval 2026 shared task. We compare a GPT-3.5 baseline provided with the dataset against GPT-5.2 evaluated under three prompting strategies: simple prompting, chain-of-thought prompting, and chain-of-thought with few-shot examples. Model predictions are evaluated against human annotations using accuracy and class-wise metrics for clarity and evasion, along with hierarchical exact match. Results show that GPT-5.2 consistently outperforms the GPT-3.5 baseline on clarity prediction, with accuracy improving from 56 percent to 63 percent under chain-of-thought with few-shot prompting. Chain-of-thought prompting yields the highest evasion accuracy at 34 percent, though improvements are less stable across fine-grained evasion categories. We further evaluate topic identification and find that reasoning-based prompting improves accuracy from 60 percent to 74 percent relative to human annotations. Overall, our findings indicate that prompt design reliably improves high-level clarity evaluation, while fine-grained evasion and topic detection remain challenging despite structured reasoning prompts.

</details>


### [96] [Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis](https://arxiv.org/abs/2601.08196)
*Da Song,Yuheng Huang,Boqi Chen,Tianshuo Cong,Randy Goebel,Lei Ma,Foutse Khomh*

Main category: cs.CL

TL;DR: 本文提出LogiSafetyGen框架，将非结构化法规转化为线性时序逻辑（LTL）的验证器，并通过逻辑引导的模糊测试生成符合安全关键要求的执行轨迹。基于此框架，构建了包含240个经人工验证任务的LogiSafetyBench基准，用于评估大语言模型在完成功能目标的同时是否满足隐含合规规则。对13个先进LLM的评估显示，尽管更大模型在功能正确性上表现更好，但常优先完成任务而忽视安全，导致不合规行为。


<details>
  <summary>Details</summary>
Motivation: 现有基准普遍忽略隐含的监管合规性，无法有效评估大语言模型在高风险领域中自主执行强制安全约束的能力。

Method: 将非结构化法规转化为线性时序逻辑（LTL）形式化规范，利用逻辑引导的模糊测试生成符合安全要求的程序执行路径，并构建人工验证的任务集以形成评测基准。

Result: 13个最先进的大语言模型在功能正确性上表现良好，但在合规性方面普遍存在缺陷，表现出任务完成优先于安全性的倾向。

Conclusion: 当前大语言模型在复杂工具使用中仍缺乏对隐含监管规则的自动遵守能力，需引入形式化方法和专门评测基准以提升其安全性与合规性。

Abstract: The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. However, existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To fill this gap, we introduce LogiSafetyGen, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LogiSafetyBench, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, which results in non-compliant behavior.

</details>


### [97] [Triplets Better Than Pairs: Towards Stable and Effective Self-Play Fine-Tuning for LLMs](https://arxiv.org/abs/2601.08198)
*Yibo Wang,Hai-Long Sun,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Lijun Zhang*

Main category: cs.CL

TL;DR: T-SPIN是一种改进的自对弈微调方法，通过引入历史优势和熵约束，解决了现有SPIN方法在迭代过程中优化不稳定及参考策略导致的对齐问题。实验表明，T-SPIN在少量标注数据下表现优异且训练过程稳定，性能优于SPIN，甚至可媲美或超越监督微调。


<details>
  <summary>Details</summary>
Motivation: 现有自对弈微调（SPIN）方法在迭代过程中依赖当前奖励优势，容易因优势消失而导致优化不稳定；同时，参考策略的存在造成训练与生成目标不一致，引发对齐偏差。

Method: 提出T-SPIN方法，包含两个核心设计：1）引入历史优势，即对比迭代生成响应与初始策略生成的原型合成响应的历史优势，以维持优化稳定性；2）在自对弈框架中加入熵约束，实现无参考策略的微调，消除训练与生成之间的差异。

Result: 在多个任务上的实验证明，T-SPIN不仅显著优于SPIN，且在迭代过程中表现出稳定的性能演化。尤其在仅使用25%标注样本时，其性能可媲美甚至超过监督微调，证明了其在稀缺标注数据场景下的高效性。

Conclusion: T-SPIN通过结合历史优势与熵约束，有效提升了自对弈微调的稳定性与有效性，为低资源场景下的语言模型适配提供了更优解决方案。

Abstract: Recently, self-play fine-tuning (SPIN) has been proposed to adapt large language models to downstream applications with scarce expert-annotated data, by iteratively generating synthetic responses from the model itself. However, SPIN is designed to optimize the current reward advantages of annotated responses over synthetic responses at hand, which may gradually vanish during iterations, leading to unstable optimization. Moreover, the utilization of reference policy induces a misalignment issue between the reward formulation for training and the metric for generation. To address these limitations, we propose a novel Triplet-based Self-Play fIne-tuNing (T-SPIN) method that integrates two key designs. First, beyond current advantages, T-SPIN additionally incorporates historical advantages between iteratively generated responses and proto-synthetic responses produced by the initial policy. Even if the current advantages diminish, historical advantages remain effective, stabilizing the overall optimization. Second, T-SPIN introduces the entropy constraint into the self-play framework, which is theoretically justified to support reference-free fine-tuning, eliminating the training-generation discrepancy. Empirical results on various tasks demonstrate not only the superior performance of T-SPIN over SPIN, but also its stable evolution during iterations. Remarkably, compared to supervised fine-tuning, T-SPIN achieves comparable or even better performance with only 25% samples, highlighting its effectiveness when faced with scarce annotated data.

</details>


### [98] [Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models](https://arxiv.org/abs/2601.08209)
*Rongji Li,Jian Xu,Xueqing Chen,Yisheng Yang,Jiayi Wang,Xingyu Chen,Chunyu Xie,Dawei Leng,Xu-Yao Zhang*

Main category: cs.CL

TL;DR: 提出GAG（Generation-Augmented Generation）方法，通过将私有专业知识视为额外的专家模态，以紧凑的表示级接口注入到冻结的基础模型中，避免了提示阶段的证据序列化，实现了可插拔的专业化和可扩展的多领域组合，显著提升私有科学问答任务的表现，同时保持通用基准性能并实现近似最优的选择性激活。


<details>
  <summary>Details</summary>
Motivation: 在生物医学、材料和金融等领域，大语言模型的高风险部署需要注入专有的、快速演进的、公共预训练数据中代表性不足的领域知识。现有方法如微调成本高且易导致灾难性遗忘，而检索增强生成（RAG）在私有专业语料中表现脆弱，受分块导致的证据碎片化、检索漂移和长上下文压力影响，引发查询依赖的提示膨胀。

Method: 提出Generation-Augmented Generation（GAG），将私有专业知识视为一种额外的专家模态，通过与冻结基础模型对齐的紧凑表示级接口进行注入，避免提示时间的证据序列化，支持即插即用的专业化和可扩展的多领域组合，并实现可靠的可选择性激活。

Result: 在两个私有科学问答基准（免疫佐剂和催化材料）上，GAG分别比强基线RAG提升15.34%和14.86%；在六个开放通用基准上保持性能；实现接近最优的选择性激活，支持可扩展的多领域部署。

Conclusion: GAG提供了一种高效、稳定且可扩展的私有知识注入方案，克服了现有方法的局限，在保持通用能力的同时显著提升了专业化性能，适用于多领域高风险场景下的大模型应用。

Abstract: In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining. However, the two dominant paradigms for private knowledge injection each have pronounced drawbacks: fine-tuning is expensive to iterate, and continual updates risk catastrophic forgetting and general-capability regression; retrieval-augmented generation (RAG) keeps the base model intact but is brittle in specialized private corpora due to chunk-induced evidence fragmentation, retrieval drift, and long-context pressure that yields query-dependent prompt inflation. Inspired by how multimodal LLMs align heterogeneous modalities into a shared semantic space, we propose Generation-Augmented Generation (GAG), which treats private expertise as an additional expert modality and injects it via a compact, representation-level interface aligned to the frozen base model, avoiding prompt-time evidence serialization while enabling plug-and-play specialization and scalable multi-domain composition with reliable selective activation. Across two private scientific QA benchmarks (immunology adjuvant and catalytic materials) and mixed-domain evaluations, GAG improves specialist performance over strong RAG baselines by 15.34% and 14.86% on the two benchmarks, respectively, while maintaining performance on six open general benchmarks and enabling near-oracle selective activation for scalable multi-domain deployment.

</details>


### [99] [Towards Principled Design of Mixture-of-Experts Language Models under Memory and Inference Constraints](https://arxiv.org/abs/2601.08215)
*Seng Pei Liew,Kenta Shinzato,Yuyang Dong*

Main category: cs.CL

TL;DR: 本文研究了现代混合专家（MoE）语言模型的架构设计，发现仅考虑总参数量和活跃参数量不足以描述最优架构。通过系统分析，作者提出性能主要由总参数量（$N_{total}$）和专家稀疏度（$s:=n_{exp}/n_{topk}$）决定。更大的专家总数会因压缩核心模型维度而轻微降低性能，因此建议在约束条件下最大化$N_{total}$，同时最小化稀疏度$s$（即增大$n_{topk}$）和专家数量$n_{exp}$。这一原则为MoE架构设计提供了清晰指导框架。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型设计仅关注总参数量和活跃参数量，但这些指标不足以全面反映模型性能，存在架构设计上的模糊性，亟需更准确的指导原则。

Method: 通过系统性实验与理论分析，探究不同$N_{total}$、$n_{exp}$、$n_{topk}$组合对MoE性能的影响，揭示稀疏度和专家总数的非线性影响机制。

Result: 发现专家稀疏度 $s$ 和总专家数 $n_{exp}$ 对性能有显著影响，且 $n_{exp}$ 过大将导致核心模型维度下降，从而损害性能；最优设计应优先最大化总参数量，同时最小化 $s$ 与 $n_{exp}$。

Conclusion: 提出一个基于 $N_{total}$、$s$、$n_{exp}$ 的统一设计原则，有效解决MoE架构设计中的不确定性问题，为未来MoE模型优化提供可遵循的框架。

Abstract: Modern Mixture-of-Experts (MoE) language models are designed based on total parameters (memory footprint) and active parameters (inference cost). However, we find these two factors alone are insufficient to describe an optimal architecture. Through a systematic study, we demonstrate that MoE performance is primarily determined by total parameters ($N_{total}$) and expert sparsity ($s:=n_{exp}/n_{topk}$).
  Moreover, $n_{exp}$ and $n_{topk}$ do not "cancel out" within the sparsity ratio; instead, a larger total number of experts slightly penalizes performance by forcing a reduction in core model dimensions (depth and width) to meet memory constraints. This motivates a simple principle for MoE design which maximizes $N_{total}$ while minimizing $s$ (maximizing $n_{topk}$) and $n_{exp}$ under the given constraints. Our findings provide a robust framework for resolving architectural ambiguity and guiding MoE design.

</details>


### [100] [Med-CoReasoner: Reducing Language Disparities in Medical Reasoning via Language-Informed Co-Reasoning](https://arxiv.org/abs/2601.08267)
*Fan Gao,Sherry T. Tong,Jiwoong Sohn,Jiahao Huang,Junfeng Jiang,Ding Xia,Piyalitt Ittichaiwong,Kanyakorn Veerakanjana,Hyunjae Kim,Qingyu Chen,Edison Marrese Taylor,Kazuma Kobayashi,Akkiko Aizawa,Irene Li*

Main category: cs.CL

TL;DR: Med-CoReasoner 是一种语言感知的共同推理框架，旨在解决大语言模型在非英语医疗任务中推理能力不足的问题。通过并行生成英文与本地语言的推理路径，将它们抽象为结构化概念，并利用概念级对齐和检索将本地临床知识融入英文逻辑框架，结合了英文推理的结构性优势与本地语言中的实践性专业知识。为评估多语言医疗推理能力，研究构建了 MultiMed-X 基准，涵盖七种语言，包含专家标注的长文本问答和自然语言推理任务（每语言 350 个实例）。实验表明，Med-CoReasoner 在三个基准上平均提升多语言推理性能 5%，尤其在低资源语言中表现显著。模型蒸馏与专家评估进一步验证了其推理过程具有临床合理性与文化适配性。


<details>
  <summary>Details</summary>
Motivation: 当前增强推理的大语言模型在英语医疗任务中表现优异，但在非英语语言中仍存在显著的多语言推理差距，限制了全球范围内的公平医疗应用。因此亟需一种能有效融合多语言临床知识、提升本地语言推理能力的方法。

Method: 提出 Med-CoReasoner 框架，通过并行生成英文与本地语言的推理路径，抽象为结构化概念，再通过概念级对齐与检索，将本地临床知识整合进英文逻辑骨架中，实现跨语言知识互补。

Result: 在 MultiMed-X 等三个基准上，Med-CoReasoner 平均提升多语言推理性能 5%，在低资源语言中提升尤为明显；模型蒸馏与专家评估确认其推理过程具备临床合理性和文化相关性。

Conclusion: Med-CoReasoner 成功弥合了多语言医疗推理差距，通过语言协同与知识对齐，实现了结构稳健性与实践专业性的统一，为全球公平医疗智能化提供了可行路径。

Abstract: While reasoning-enhanced large language models perform strongly on English medical tasks, a persistent multilingual gap remains, with substantially weaker reasoning in local languages, limiting equitable global medical deployment. To bridge this gap, we introduce Med-CoReasoner, a language-informed co-reasoning framework that elicits parallel English and local-language reasoning, abstracts them into structured concepts, and integrates local clinical knowledge into an English logical scaffold via concept-level alignment and retrieval. This design combines the structural robustness of English reasoning with the practice-grounded expertise encoded in local languages. To evaluate multilingual medical reasoning beyond multiple-choice settings, we construct MultiMed-X, a benchmark covering seven languages with expert-annotated long-form question answering and natural language inference tasks, comprising 350 instances per language. Experiments across three benchmarks show that Med-CoReasoner improves multilingual reasoning performance by an average of 5%, with particularly substantial gains in low-resource languages. Moreover, model distillation and expert evaluation analysis further confirm that Med-CoReasoner produces clinically sound and culturally grounded reasoning traces.

</details>


### [101] [Discovery and Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees](https://arxiv.org/abs/2601.08274)
*Kun Li,Zenan Xu,Junan Li,Zengrui Jin,Jinghao Deng,Zexuan Qiu,Bo Zhou*

Main category: cs.CL

TL;DR: DART 是一种基于强化学习的框架，通过构建动态回溯树来发现长链思维（long CoT）中工具使用的潜在机会，并通过树状过程优势估计识别和奖励有益的工具调用子轨迹，从而在无需人工标注的情况下实现自发的工具使用，显著提升模型在复杂基准测试中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究在将工具使用整合到长链思维推理中仍不充分，主要受限于训练数据稀缺以及工具集成可能破坏模型内在长链推理能力的问题。

Method: DART 通过在训练过程中构建动态回溯树，探索不同工具集成路径；利用树状结构进行过程优势估计，识别并强化那些因工具调用而带来正向贡献的推理子轨迹。

Result: 在 AIME 和 GPQA-Diamond 等挑战性基准测试上，DART 显著优于现有方法，成功实现了工具执行与长链推理的有效融合。

Conclusion: DART 为长链思维推理中自发工具使用提供了有效解决方案，展示了强化学习在增强 LLM 工具集成能力方面的潜力。

Abstract: Tool-Integrated Reasoning has emerged as a key paradigm to augment Large Language Models (LLMs) with computational capabilities, yet integrating tool-use into long Chain-of-Thought (long CoT) remains underexplored, largely due to the scarcity of training data and the challenge of integrating tool-use without compromising the model's intrinsic long-chain reasoning. In this paper, we introduce DART (Discovery And Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees), a reinforcement learning framework that enables spontaneous tool-use during long CoT reasoning without human annotation. DART operates by constructing dynamic rollout trees during training to discover valid tool-use opportunities, branching out at promising positions to explore diverse tool-integrated trajectories. Subsequently, a tree-based process advantage estimation identifies and credits specific sub-trajectories where tool invocation positively contributes to the solution, effectively reinforcing these beneficial behaviors. Extensive experiments on challenging benchmarks like AIME and GPQA-Diamond demonstrate that DART significantly outperforms existing methods, successfully harmonizing tool execution with long CoT reasoning.

</details>


### [102] [Enhancing Sentiment Classification and Irony Detection in Large Language Models through Advanced Prompt Engineering Techniques](https://arxiv.org/abs/2601.08302)
*Marvin Schmitt,Anne Schwerk,Sebastian Lempert*

Main category: cs.CL

TL;DR: 该研究探讨了提示工程对大型语言模型（LLM）在情感分析任务中的增强作用，比较了少样本学习、思维链提示和自一致性等高级提示技术与基线方法的表现。结果显示，高级提示显著提升了性能，其中少样本提示在GPT-4o-mini上表现最佳，而思维链提示在gemini-1.5-flash中对讽刺检测的提升高达46%。表明提示策略需根据模型架构和任务复杂性进行定制化设计。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在情感分析任务中的表现，特别是识别细微语义如讽刺的能力，通过优化提示工程实现更精准的分析。

Method: 采用少样本学习、思维链提示和自一致性等高级提示技术，对比其在情感分类、基于方面的情感分析及讽刺检测任务中的表现，使用准确率、召回率、精确率和F1分数作为评估指标。

Result: 高级提示技术整体上显著提升模型性能；少样本提示在GPT-4o-mini中表现最优，思维链提示使gemini-1.5-flash在讽刺检测上提升达46%。

Conclusion: 提示策略应根据具体模型架构和任务语义复杂性进行定制，才能最大化性能提升效果。

Abstract: This study investigates the use of prompt engineering to enhance large language models (LLMs), specifically GPT-4o-mini and gemini-1.5-flash, in sentiment analysis tasks. It evaluates advanced prompting techniques like few-shot learning, chain-of-thought prompting, and self-consistency against a baseline. Key tasks include sentiment classification, aspect-based sentiment analysis, and detecting subtle nuances such as irony. The research details the theoretical background, datasets, and methods used, assessing performance of LLMs as measured by accuracy, recall, precision, and F1 score. Findings reveal that advanced prompting significantly improves sentiment analysis, with the few-shot approach excelling in GPT-4o-mini and chain-of-thought prompting boosting irony detection in gemini-1.5-flash by up to 46%. Thus, while advanced prompting techniques overall improve performance, the fact that few-shot prompting works best for GPT-4o-mini and chain-of-thought excels in gemini-1.5-flash for irony detection suggests that prompting strategies must be tailored to both the model and the task. This highlights the importance of aligning prompt design with both the LLM's architecture and the semantic complexity of the task.

</details>


### [103] [CLaS-Bench: A Cross-Lingual Alignment and Steering Benchmark](https://arxiv.org/abs/2601.08331)
*Daniil Gurgurov,Yusser Al Ghussin,Tanja Baeumel,Cheng-Ting Chou,Patrick Schramowski,Marius Mosbach,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: 本文提出CLaS-Bench，一个用于评估大语言模型在32种语言中语言强制行为的轻量级并行问题基准，旨在系统评估多语言引导技术的有效性。通过衡量语言控制与语义相关性两个维度，发现基于残差流的DiffMean方法在多数语言中表现最佳，并且语言特定结构主要出现在模型后期层，引导方向按语言家族聚集。该基准为多语言引导提供了标准化评估框架，支持科学分析与低成本适配实践。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门用于量化多语言引导技术有效性的基准和评估协议，亟需一种系统化工具来评估大语言模型在多语言场景下的行为控制能力。

Method: 构建CLaS-Bench基准，包含32种语言的并行问题数据集；采用多种引导技术（如DiffMean、探测方向、语言特异性神经元、PCA/LDA向量、稀疏自编码器等）进行实验；通过语言控制与语义相关性的调和平均得分评估性能，并进行层间分析以探究语言结构分布规律。

Result: DiffMean方法在大多数语言中表现最优；语言特异性结构主要集中在模型后期层；引导方向呈现语言家族聚类特征；CLaS-Bench可有效支持多语言引导的科学评估与实际应用。

Conclusion: CLaS-Bench是首个针对多语言引导的标准化基准，不仅推动了对语言表示的深入理解，也为低资源成本的模型适配提供了可行路径。

Abstract: Understanding and controlling the behavior of large language models (LLMs) is an increasingly important topic in multilingual NLP. Beyond prompting or fine-tuning, , i.e.,~manipulating internal representations during inference, has emerged as a more efficient and interpretable technique for adapting models to a target language. Yet, no dedicated benchmarks or evaluation protocols exist to quantify the effectiveness of steering techniques. We introduce CLaS-Bench, a lightweight parallel-question benchmark for evaluating language-forcing behavior in LLMs across 32 languages, enabling systematic evaluation of multilingual steering methods. We evaluate a broad array of steering techniques, including residual-stream DiffMean interventions, probe-derived directions, language-specific neurons, PCA/LDA vectors, Sparse Autoencoders, and prompting baselines. Steering performance is measured along two axes: language control and semantic relevance, combined into a single harmonic-mean steering score. We find that across languages simple residual-based DiffMean method consistently outperforms all other methods. Moreover, a layer-wise analysis reveals that language-specific structure emerges predominantly in later layers and steering directions cluster based on language family. CLaS-Bench is the first standardized benchmark for multilingual steering, enabling both rigorous scientific analysis of language representations and practical evaluation of steering as a low-cost adaptation alternative.

</details>


### [104] [Detecting Mental Manipulation in Speech via Synthetic Multi-Speaker Dialogue](https://arxiv.org/abs/2601.08342)
*Run Chen,Wen Liang,Ziwei Gong,Lin Ai,Julia Hirschberg*

Main category: cs.CL

TL;DR: 该研究首次探讨了口语对话中的心理操控检测，提出了一个合成的多说话人基准数据集SPEECHMENTALMANIP，将文本数据集与高质量、语音一致的语音合成音频相结合。通过少样本大音频-语言模型和人工标注，评估了模态对检测准确率和感知的影响。结果表明，模型在语音上表现出高特异性但显著较低的召回率，说明其对训练中缺失的声学或语调线索敏感；人类评分者在音频设置下也表现出类似不确定性，突显出操纵性言语的内在模糊性。总体表明，需要在多模态对话系统中进行模态感知的评估与安全对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅关注文本对话中的心理操控，忽视了语音中操控策略的表现形式，因此亟需在口语对话中开展相关检测研究。

Method: 构建SPEECHMENTALMANIP数据集，结合文本与高质量语音合成音频，利用少样本大音频-语言模型和人工标注评估不同模态下的检测性能。

Result: 模型在语音上的召回率显著低于文本，表现出对声学或语调线索的敏感性；人类评分者在音频场景中同样存在较大不确定性，表明操纵性言语具有高度模糊性。

Conclusion: 当前多模态系统在心理操控检测方面仍存在不足，需引入模态感知的评估机制与安全对齐设计。

Abstract: Mental manipulation, the strategic use of language to covertly influence or exploit others, is a newly emerging task in computational social reasoning. Prior work has focused exclusively on textual conversations, overlooking how manipulative tactics manifest in speech. We present the first study of mental manipulation detection in spoken dialogues, introducing a synthetic multi-speaker benchmark SPEECHMENTALMANIP that augments a text-based dataset with high-quality, voice-consistent Text-to-Speech rendered audio. Using few-shot large audio-language models and human annotation, we evaluate how modality affects detection accuracy and perception. Our results reveal that models exhibit high specificity but markedly lower recall on speech compared to text, suggesting sensitivity to missing acoustic or prosodic cues in training. Human raters show similar uncertainty in the audio setting, underscoring the inherent ambiguity of manipulative speech. Together, these findings highlight the need for modality-aware evaluation and safety alignment in multimodal dialogue systems.

</details>


### [105] [PATS: Personality-Aware Teaching Strategies with Large Language Model Tutors](https://arxiv.org/abs/2601.08402)
*Donya Rooein,Sankalan Pal Chowdhury,Mariia Eremeeva,Yuan Qin,Debora Nozza,Mrinmaya Sachan,Dirk Hovy*

Main category: cs.CL

TL;DR: 该研究提出了一种基于学生人格特质调整教学策略的LLM辅导框架，通过模拟师生对话并匹配个性化教学方法，显著提升了教学效果和教师偏好。


<details>
  <summary>Details</summary>
Motivation: 当前LLM辅导系统忽视学生人格特质，导致教学策略与学生个性不匹配，可能降低学习效果。因此需要构建一个能根据人格调整教学策略的系统。

Method: 基于教育文献构建教学方法与人格特征的映射分类体系，通过模拟对话让LLM动态调整教学策略以适应不同人格类型的学生。

Result: 人类教师更倾向于该方法而非两个基线；同时，该方法显著增加了高影响力策略（如角色扮演）的使用，且被人类和LLM标注者一致认可。

Conclusion: 该研究为实现更个性化、高效的LLM教育应用提供了可行路径，强调了人格适配在智能辅导中的重要性。

Abstract: Recent advances in large language models (LLMs) demonstrate their potential as educational tutors. However, different tutoring strategies benefit different student personalities, and mismatches can be counterproductive to student outcomes. Despite this, current LLM tutoring systems do not take into account student personality traits. To address this problem, we first construct a taxonomy that links pedagogical methods to personality profiles, based on pedagogical literature. We simulate student-teacher conversations and use our framework to let the LLM tutor adjust its strategy to the simulated student personality. We evaluate the scenario with human teachers and find that they consistently prefer our approach over two baselines. Our method also increases the use of less common, high-impact strategies such as role-playing, which human and LLM annotators prefer significantly. Our findings pave the way for developing more personalized and effective LLM use in educational applications.

</details>


### [106] [Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering](https://arxiv.org/abs/2601.08427)
*Nonghai Zhang,Weitao Ma,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Jingwen Xu*

Main category: cs.CL

TL;DR: Latent-GRPO提出一种基于潜在空间几何的内在奖励机制，通过发现正确推理轨迹在潜在空间中形成密集聚类的几何特性，利用迭代鲁棒中心估计（IRCE）算法生成连续且稳定的奖励信号。该方法避免了对外部验证器或人工规则的依赖，显著提升训练效率，实现超过2倍的加速，同时保持模型性能并展现出强泛化能力与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有Group Relative Policy Optimization（GRPO）依赖昂贵的外部验证器或人工规则来提供奖励信号，导致计算成本高、训练延迟大且奖励稀疏，限制了优化效率。因此亟需一种无需外部监督的内在奖励机制。

Method: 提出Latent-GRPO框架，基于潜在空间中正确推理轨迹形成的密集聚类特性，设计迭代鲁棒中心估计（IRCE）算法，通过球面投影减少幅度波动，并通过迭代聚合估计‘真实中心’以生成稳定连续的内在奖励。

Result: 实验表明，该方法在多个数据集上维持了与基线相当的模型性能，训练速度提升超过2倍；同时展现出优异的泛化能力和鲁棒性。

Conclusion: Latent-GRPO通过挖掘潜在空间的内在几何结构，实现了高效、低成本且可扩展的强化学习训练，为大语言模型的推理能力优化提供了新范式。

Abstract: Group Relative Policy Optimization (GRPO) significantly enhances the reasoning performance of Large Language Models (LLMs). However, this success heavily relies on expensive external verifiers or human rules. Such dependency not only leads to significant computational costs and training latency, but also yields sparse rewards that hinder optimization efficiency. To address these challenges, we propose Latent-GRPO, a framework that derives intrinsic rewards directly from latent space geometry. Crucially, our empirical analysis reveals a compelling geometric property: terminal token representations of correct reasoning trajectories form dense clusters with high intra-class similarity, whereas incorrect trajectories remain scattered as outliers. In light of this discovery, we introduce the Iterative Robust Centroid Estimation (IRCE) algorithm, which generates dense, continuous rewards by mitigating magnitude fluctuations via spherical projection and estimating a robust ``truth centroid'' through iterative aggregation. Experimental results on multiple datasets show that our method maintains model performance while achieving a training speedup of over 2x compared to baselines. Furthermore, extensive results demonstrate strong generalization ability and robustness. The code will be released soon.

</details>


### [107] [JudgeRLVR: Judge First, Generate Second for Efficient Reasoning](https://arxiv.org/abs/2601.08468)
*Jiangshan Duo,Hanyu Li,Hailin Zhang,Yudong Wang,Sujian Li,Liang Zhao*

Main category: cs.CL

TL;DR: 本文提出JudgeRLVR，一种两阶段的判别-生成范式，旨在解决大语言模型在强化学习中因仅优化最终答案正确性而导致的冗长、低效探索问题。通过先训练模型判断解法的有效性，再基于此进行生成，实现更高效的推理。相比传统RLVR，JudgeRLVR在数学领域提升平均准确率3.7点，生成长度减少42%；在跨域任务上准确率提升4.5点，表现出更强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法仅关注最终答案正确性，导致模型陷入冗长的试错过程，难以高效生成。现有启发式约束（如长度惩罚）虽可减少冗余，但可能删减必要推理步骤，造成效率与验证之间的权衡难题。因此需要一种能有效区分有效解法的能力，以引导模型结构化规划而非盲目尝试。

Method: 提出JudgeRLVR，采用两阶段训练：第一阶段训练模型判别给定解法是否具有可验证答案；第二阶段使用该判别模型初始化生成型强化学习（Vanilla RLVR），进行生成微调。通过判别能力内化指导信号，缩小搜索空间，提升生成效率。

Result: 在同域数学任务中，JudgeRLVR相比原始RLVR提升平均准确率约3.7点，生成长度减少42%；在跨域基准测试中，准确率提升约4.5点，表明其不仅提高效率，还增强了模型的泛化能力。

Conclusion: 判别能力是高效生成的前提。通过引入判别-生成双阶段框架，模型能够更有效地识别和筛选有效解法，从而在保证准确性的同时显著提升推理效率与泛化性能，为大模型推理提供了新范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reasoning steps, creating a difficult trade-off between efficiency and verification. In this paper, we argue that discriminative capability is a prerequisite for efficient generation: by learning to distinguish valid solutions, a model can internalize a guidance signal that prunes the search space. We propose JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, we train the model to judge solution responses with verifiable answers. In the second stage, we fine-tune the same model with vanilla generating RLVR initialized from the judge. Compared to Vanilla RLVR using the same math-domain training data, JudgeRLVR achieves a better quality--efficiency trade-off for Qwen3-30B-A3B: on in-domain math, it delivers about +3.7 points average accuracy gain with -42\% average generation length; on out-of-domain benchmarks, it delivers about +4.5 points average accuracy improvement, demonstrating enhanced generalization.

</details>


### [108] [Do You Understand How I Feel?: Towards Verified Empathy in Therapy Chatbots](https://arxiv.org/abs/2601.08477)
*Francesco Dettori,Matteo Forasassi,Lorenzo Veronese,Livia Lestingi,Vincenzo Scotti,Matteo Giovanni Rossi*

Main category: cs.CL

TL;DR: 本文提出一个结合自然语言处理与形式化验证的框架，用于开发具有同理心的治疗聊天机器人。通过Transformer模型提取对话特征，并构建双人治疗会话的随机混合自动机模型，利用统计模型检测验证同理心相关属性，同时通过策略合成指导机器人行为。初步结果表明该形式化模型能较好捕捉治疗动态，且临时策略可提高满足同理心要求的概率。


<details>
  <summary>Details</summary>
Motivation: 当前聊天机器人在心理治疗路径中的应用日益广泛，但缺乏系统化的方法来规范和验证其同理心能力，而同理心是治疗场景中的关键非功能性需求。

Method: 采用基于Transformer的模型提取对话特征，将其转化为随机混合自动机（Stochastic Hybrid Automaton）模型，进而通过统计模型检查验证同理心属性，并利用策略合成优化机器人行为。

Result: 形式化模型能够以较高保真度捕捉治疗过程动态，且通过设计的临时策略显著提升了满足同理心要求的概率。

Conclusion: 该框架为构建可验证、可信赖的同理心治疗聊天机器人提供了可行路径，推动了智能心理支持工具的发展。

Abstract: Conversational agents are increasingly used as support tools along mental therapeutic pathways with significant societal impacts. In particular, empathy is a key non-functional requirement in therapeutic contexts, yet current chatbot development practices provide no systematic means to specify or verify it. This paper envisions a framework integrating natural language processing and formal verification to deliver empathetic therapy chatbots. A Transformer-based model extracts dialogue features, which are then translated into a Stochastic Hybrid Automaton model of dyadic therapy sessions. Empathy-related properties can then be verified through Statistical Model Checking, while strategy synthesis provides guidance for shaping agent behavior. Preliminary results show that the formal model captures therapy dynamics with good fidelity and that ad-hoc strategies improve the probability of satisfying empathy requirements.

</details>


### [109] [BenchOverflow: Measuring Overflow in Large Language Models via Plain-Text Prompts](https://arxiv.org/abs/2601.08490)
*Erin Feiglin,Nir Hutnik,Raz Lapid*

Main category: cs.CL

TL;DR: 本文研究大语言模型（LLM）在普通交互场景下因纯文本提示引发过度输出的现象，称为Overflow。该现象不同于越狱或提示注入，会导致服务成本、延迟上升及跨用户性能下降，尤其在大规模请求时影响显著。文章提出BenchOverflow基准，评估九种非对抗性提示策略对输出长度的影响，发现多数模型存在明显的长尾分布。通过容量饱和率（CSR）和经验累积分布函数（ECDF）量化尾部风险，结果显示Overflow具有可重复性但跨模型和攻击方式差异明显。引入轻量级缓解措施——固定简洁提醒，能有效降低右尾和CSR。研究强调长度控制是可靠性、成本与可持续性的关键问题，BenchOverflow为模型选型和防御评估提供标准化工具。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注对抗性攻击如越狱或提示注入，而忽视了在常规使用中因提示设计导致的过度输出问题（Overflow）。此类问题虽无恶意意图，却会引发高昂的服务成本、能源消耗与系统性能下降，尤其在规模化部署时加剧。因此亟需系统性识别并量化这一现象，推动对长度控制的关注与优化。

Method: 提出BenchOverflow基准，采用九种非对抗性纯文本提示策略，在固定5000新词预算下测试多个开源与闭源模型。通过容量饱和率（CSR@1k/3k/5k）、经验累积分布函数（ECDF）、组内方差与跨模型相关性分析输出长度分布特征，并测试一种轻量级缓解方法——固定简洁提醒的有效性。

Result: 所有测试模型均表现出显著的右偏长尾分布；不同提示策略间存在可重复的溢出行为，但各模型家族表现异质性强；轻量级缓解措施显著降低右尾长度与容量饱和率，提升稳定性。

Conclusion: Overflow是大语言模型在真实部署中不可忽视的可靠性、经济与环境问题。长度控制不应仅被视为风格选择，而应作为核心系统指标。BenchOverflow提供了标准化评估框架，支持模型选型与防御机制比较，有助于减少资源浪费与运营开销。

Abstract: We investigate a failure mode of large language models (LLMs) in which plain-text prompts elicit excessive outputs, a phenomenon we term Overflow. Unlike jailbreaks or prompt injection, Overflow arises under ordinary interaction settings and can lead to elevated serving cost, latency, and cross-user performance degradation, particularly when scaled across many requests. Beyond usability, the stakes are economic and environmental: unnecessary tokens increase per-request cost and energy consumption, compounding into substantial operational spend and carbon footprint at scale. Moreover, Overflow represents a practical vector for compute amplification and service degradation in shared environments. We introduce BenchOverflow, a model-agnostic benchmark of nine plain-text prompting strategies that amplify output volume without adversarial suffixes or policy circumvention. Using a standardized protocol with a fixed budget of 5000 new tokens, we evaluate nine open- and closed-source models and observe pronounced rightward shifts and heavy tails in length distributions. Cap-saturation rates (CSR@1k/3k/5k) and empirical cumulative distribution functions (ECDFs) quantify tail risk; within-prompt variance and cross-model correlations show that Overflow is broadly reproducible yet heterogeneous across families and attack vectors. A lightweight mitigation-a fixed conciseness reminder-attenuates right tails and lowers CSR for all strategies across the majority of models. Our findings position length control as a measurable reliability, cost, and sustainability concern rather than a stylistic quirk. By enabling standardized comparison of length-control robustness across models, BenchOverflow provides a practical basis for selecting deployments that minimize resource waste and operating expense, and for evaluating defenses that curb compute amplification without eroding task performance.

</details>


### [110] [It's All About the Confidence: An Unsupervised Approach for Multilingual Historical Entity Linking using Large Language Models](https://arxiv.org/abs/2601.08500)
*Cristian Santini,Marieke Van Erp,Mehwish Alam*

Main category: cs.CL

TL;DR: MHEL-LLaMo 是一种无需微调的多语言历史实体链接方法，结合小语言模型（SLM）与指令微调的大语言模型（LLM），通过分阶段处理易难样本，在降低计算成本的同时避免幻觉，适用于低资源历史文本。


<details>
  <summary>Details</summary>
Motivation: 历史文本中的实体链接面临语言变异、输入噪声和语义演变等挑战，现有方法依赖大量训练数据或领域特定规则，难以扩展。

Method: 采用多语言双编码器（BELA）进行候选检索，利用指令微调的LLM通过提示链完成无实体链接（NIL）预测与候选选择；基于SLM置信度区分易难样本，仅对困难样本使用LLM。

Result: 在六个欧洲语言（英语、芬兰语、法语、德语、意大利语、瑞典语）的19-20世纪历史文本上，四个基准测试中表现优于现有最先进模型，且无需微调。

Conclusion: MHEL-LLaMo 提供了一种高效、可扩展的无监督历史实体链接方案，特别适用于低资源场景，具有良好的泛化能力。

Abstract: Despite the recent advancements in NLP with the advent of Large Language Models (LLMs), Entity Linking (EL) for historical texts remains challenging due to linguistic variation, noisy inputs, and evolving semantic conventions. Existing solutions either require substantial training data or rely on domain-specific rules that limit scalability. In this paper, we present MHEL-LLaMo (Multilingual Historical Entity Linking with Large Language MOdels), an unsupervised ensemble approach combining a Small Language Model (SLM) and an LLM. MHEL-LLaMo leverages a multilingual bi-encoder (BELA) for candidate retrieval and an instruction-tuned LLM for NIL prediction and candidate selection via prompt chaining. Our system uses SLM's confidence scores to discriminate between easy and hard samples, applying an LLM only for hard cases. This strategy reduces computational costs while preventing hallucinations on straightforward cases. We evaluate MHEL-LLaMo on four established benchmarks in six European languages (English, Finnish, French, German, Italian and Swedish) from the 19th and 20th centuries. Results demonstrate that MHEL-LLaMo outperforms state-of-the-art models without requiring fine-tuning, offering a scalable solution for low-resource historical EL. The implementation of MHEL-LLaMo is available on Github.

</details>


### [111] [STAGE: A Benchmark for Knowledge Graph Construction, Question Answering, and In-Script Role-Playing over Movie Screenplays](https://arxiv.org/abs/2601.08510)
*Qiuyu Tian,Yiding Li,Fengyi Chen,Zequn Liu,Youyong Kong,Fan Guo,Yuyao Li,Jinjing Shen,Zhijing Xie,Yiyun Luo,Xin Zhang*

Main category: cs.CL

TL;DR: STAGE是一个统一的基准，用于评估模型在完整电影剧本上的叙事理解能力，涵盖知识图谱构建、场景事件摘要、长上下文剧本问答和剧本内角色扮演四个任务，基于共享的叙事世界表示，支持中英文150部电影的全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准多聚焦于单一子任务，缺乏对模型构建连贯故事世界并跨多种推理与生成任务保持一致性的评估能力，因此需要一个更全面的基准来检验模型在复杂叙事理解中的综合表现。

Method: 提出STAGE基准，包含四类任务：知识图谱构建、场景级事件摘要、长上下文剧本问答、角色扮演；提供清洗后的剧本、精心构建的知识图谱及事件与角色中心标注，覆盖中英文150部电影。

Result: STAGE能够有效评估模型在构建叙事世界表示、抽象与验证叙事事件、长程推理以及生成角色一致响应方面的综合能力，为叙事理解研究提供了新的评估框架。

Conclusion: STAGE为电影剧本的叙事理解提供了统一、全面的评估体系，有助于推动模型在复杂长篇叙事任务中的发展与评估。

Abstract: Movie screenplays are rich long-form narratives that interleave complex character relationships, temporally ordered events, and dialogue-driven interactions. While prior benchmarks target individual subtasks such as question answering or dialogue generation, they rarely evaluate whether models can construct a coherent story world and use it consistently across multiple forms of reasoning and generation. We introduce STAGE (Screenplay Text, Agents, Graphs and Evaluation), a unified benchmark for narrative understanding over full-length movie screenplays. STAGE defines four tasks: knowledge graph construction, scene-level event summarization, long-context screenplay question answering, and in-script character role-playing, all grounded in a shared narrative world representation. The benchmark provides cleaned scripts, curated knowledge graphs, and event- and character-centric annotations for 150 films across English and Chinese, enabling holistic evaluation of models' abilities to build world representations, abstract and verify narrative events, reason over long narratives, and generate character-consistent responses.

</details>


### [112] [STAR: Detecting Inference-time Backdoors in LLM Reasoning via State-Transition Amplification Ratio](https://arxiv.org/abs/2601.08511)
*Seong-Gyu Park,Sohee Park,Jisu Lee,Hyunsik Na,Daeseon Choi*

Main category: cs.CL

TL;DR: STAR 是一种用于检测大型语言模型中推理时后门攻击的框架，通过分析输出概率变化来识别恶意推理路径。它利用后验概率与先验概率之间的统计差异，量化状态转移放大效应，并使用 CUSUM 算法检测持续异常。在多个模型和数据集上，STAR 实现了接近完美的检测性能（AUROC ≈ 1.0），效率比现有方法高约 42 倍，且对自适应攻击具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型虽然引入了链式思维（CoT）等推理机制，但这些显式推理路径也暴露了新的推理时后门攻击面。这类攻击通过注入恶意推理路径进行破坏，而不会改变模型参数，且生成的语言学上连贯的路径能有效逃避传统检测手段。因此，亟需一种能够识别此类隐蔽攻击的新方法。

Method: STAR 框架基于状态转移放大比率，通过分析输入引发的推理路径在前后概率分布上的不一致，即低先验概率但高后验概率的现象，量化这种状态转移的放大程度。随后采用 CUSUM 算法监控输出概率序列中的长期异常，实现对后门攻击的及时发现。

Result: STAR 在多种模型（8B-70B）和五个基准数据集上均表现出卓越的检测能力，平均 AUROC 接近 1.0，表明其具备近乎完美的检测性能。同时，其检测效率比现有基线高出约 42 倍，并对试图规避检测的自适应攻击保持高度鲁棒性。

Conclusion: STAR 框架为检测大型语言模型中的推理时后门攻击提供了一种高效、通用且鲁棒的解决方案，解决了因显式推理路径带来的新型安全威胁，具有重要的实际应用价值。

Abstract: Recent LLMs increasingly integrate reasoning mechanisms like Chain-of-Thought (CoT). However, this explicit reasoning exposes a new attack surface for inference-time backdoors, which inject malicious reasoning paths without altering model parameters. Because these attacks generate linguistically coherent paths, they effectively evade conventional detection. To address this, we propose STAR (State-Transition Amplification Ratio), a framework that detects backdoors by analyzing output probability shifts. STAR exploits the statistical discrepancy where a malicious input-induced path exhibits high posterior probability despite a low prior probability in the model's general knowledge. We quantify this state-transition amplification and employ the CUSUM algorithm to detect persistent anomalies. Experiments across diverse models (8B-70B) and five benchmark datasets demonstrate that STAR exhibits robust generalization capabilities, consistently achieving near-perfect performance (AUROC $\approx$ 1.0) with approximately $42\times$ greater efficiency than existing baselines. Furthermore, the framework proves robust against adaptive attacks attempting to bypass detection.

</details>


### [113] [Algorithmic Stability in Infinite Dimensions: Characterizing Unconditional Convergence in Banach Spaces](https://arxiv.org/abs/2601.08512)
*Przemysław Spyra*

Main category: cs.CL

TL;DR: 本文提出一个统一的特征定理，将七种等价条件（如排列不变性、网收敛、子级数检验、符号稳定性、有界乘子性质、弱一致收敛等）关联起来，用于刻画无条件收敛。这些理论结果直接指导算法稳定性分析，例如在随机梯度下降中保证梯度累积的排列不变性，以及在基于框架的信号处理中合理进行系数阈值化。研究连接了经典泛函分析与现代计算实践，为无关顺序且数值稳定的求和过程提供了严格的理论基础。


<details>
  <summary>Details</summary>
Motivation: 在无限维空间中，条件收敛、无条件收敛和绝对收敛存在本质区别，而这一区别对计算算法的设计与分析具有深远影响。尽管在有限维空间中这三者等价，但在一般巴拿赫空间中，它们严格分离。因此，需要建立一套统一的理论框架来刻画无条件收敛，从而为算法设计提供数学依据。

Method: 通过引入七个等价条件，构建并证明了一个综合性特征定理，涵盖排列不变性、网收敛、子级数测试、符号稳定性、有界乘子性质及弱一致收敛等。利用泛函分析中的经典工具，如对偶空间、乘子空间与收敛性理论，完成理论推导与等价性证明。

Result: 成功建立了七个条件之间的等价关系，为无条件收敛提供了统一刻画；该理论被应用于实际算法中，如确保SGD中梯度累积的排列不变性，以及在帧表示中实现稳健的系数截断。

Conclusion: 本研究不仅深化了对无限维空间中收敛性概念的理解，还为现代计算算法（如优化与信号处理）提供了坚实的数学基础，实现了从抽象泛函分析到具体工程应用的桥梁作用。

Abstract: The distinction between conditional, unconditional, and absolute convergence in infinite-dimensional spaces has fundamental implications for computational algorithms. While these concepts coincide in finite dimensions, the Dvoretzky-Rogers theorem establishes their strict separation in general Banach spaces. We present a comprehensive characterization theorem unifying seven equivalent conditions for unconditional convergence: permutation invariance, net convergence, subseries tests, sign stability, bounded multiplier properties, and weak uniform convergence. These theoretical results directly inform algorithmic stability analysis, governing permutation invariance in gradient accumulation for Stochastic Gradient Descent and justifying coefficient thresholding in frame-based signal processing. Our work bridges classical functional analysis with contemporary computational practice, providing rigorous foundations for order-independent and numerically robust summation processes.

</details>


### [114] [DeepResearch Bench II: Diagnosing Deep Research Agents via Rubrics from Expert Report](https://arxiv.org/abs/2601.08536)
*Ruizhe Li,Mingxuan Du,Benfeng Xu,Chiwei Zhu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 提出Deep Research Bench II基准，通过9430个细粒度二元评分标准评估深度研究系统（DRS）在信息召回、分析和呈现三个维度的表现。该基准基于专家撰写的文章，经四阶段人机协作流程构建，确保标准原子化、可验证且符合人类专家判断。评估发现，当前最强的DRS模型仅满足少于50%的评分标准，显示其与人类专家之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究评估基准存在两大缺陷：一是未能充分测试系统分析证据和撰写连贯报告的能力；二是评估标准过于粗略或由大模型直接定义，导致评分易受偏见影响且难以验证和解释。因此亟需一个更严谨、可信赖的评估框架。

Method: 构建Deep Research Bench II，包含132个跨22个领域的事实性研究任务。每个任务要求生成长篇研究报告，并通过9430个细粒度二元评分标准进行评估。评分标准源自专家撰写的调查文章，采用四阶段混合方法（自动化提取+超400小时专家人工审核），确保标准的原子性、可验证性和与人类专家判断的一致性。

Result: 对多个最先进的深度研究系统进行评估，结果显示即使是最强的模型也未能满足超过50%的评分标准，表明当前DRS与人类专家在综合研究能力方面存在显著差距。

Conclusion: Deep Research Bench II为评估深度研究系统提供了更严谨、可解释且贴近真实专家标准的基准，揭示了当前技术与人类水平之间的巨大鸿沟，推动未来研究向更高可信度和更高质量的报告生成迈进。

Abstract: Deep Research Systems (DRS) aim to help users search the web, synthesize information, and deliver comprehensive investigative reports. However, how to rigorously evaluate these systems remains under-explored. Existing deep-research benchmarks often fall into two failure modes. Some do not adequately test a system's ability to analyze evidence and write coherent reports. Others rely on evaluation criteria that are either overly coarse or directly defined by LLMs (or both), leading to scores that can be biased relative to human experts and are hard to verify or interpret. To address these issues, we introduce Deep Research Bench II, a new benchmark for evaluating DRS-generated reports. It contains 132 grounded research tasks across 22 domains; for each task, a system must produce a long-form research report that is evaluated by a set of 9430 fine-grained binary rubrics in total, covering three dimensions: information recall, analysis, and presentation. All rubrics are derived from carefully selected expert-written investigative articles and are constructed through a four-stage LLM+human pipeline that combines automatic extraction with over 400 human-hours of expert review, ensuring that the criteria are atomic, verifiable, and aligned with human expert judgment. We evaluate several state-of-the-art deep-research systems on Deep Research Bench II and find that even the strongest models satisfy fewer than 50% of the rubrics, revealing a substantial gap between current DRSs and human experts.

</details>


### [115] [Ministral 3](https://arxiv.org/abs/2601.08584)
*Alexander H. Liu,Kartik Khandelwal,Sandeep Subramanian,Victor Jouault,Abhinav Rastogi,Adrien Sadé,Alan Jeffares,Albert Jiang,Alexandre Cahill,Alexandre Gavaudan,Alexandre Sablayrolles,Amélie Héliou,Amos You,Andy Ehrenberg,Andy Lo,Anton Eliseev,Antonia Calvi,Avinash Sooriyarachchi,Baptiste Bout,Baptiste Rozière,Baudouin De Monicault,Clémence Lanfranchi,Corentin Barreau,Cyprien Courtot,Daniele Grattarola,Darius Dabert,Diego de las Casas,Elliot Chane-Sane,Faruk Ahmed,Gabrielle Berrada,Gaëtan Ecrepont,Gauthier Guinet,Georgii Novikov,Guillaume Kunsch,Guillaume Lample,Guillaume Martin,Gunshi Gupta,Jan Ludziejewski,Jason Rute,Joachim Studnia,Jonas Amar,Joséphine Delas,Josselin Somerville Roberts,Karmesh Yadav,Khyathi Chandu,Kush Jain,Laurence Aitchison,Laurent Fainsin,Léonard Blier,Lingxiao Zhao,Louis Martin,Lucile Saulnier,Luyu Gao,Maarten Buyl,Margaret Jennings,Marie Pellat,Mark Prins,Mathieu Poirée,Mathilde Guillaumin,Matthieu Dinot,Matthieu Futeral,Maxime Darrin,Maximilian Augustin,Mia Chiquier,Michel Schimpf,Nathan Grinsztajn,Neha Gupta,Nikhil Raghuraman,Olivier Bousquet,Olivier Duchenne,Patricia Wang,Patrick von Platen,Paul Jacob,Paul Wambergue,Paula Kurylowicz,Pavankumar Reddy Muddireddy,Philomène Chagniot,Pierre Stock,Pravesh Agrawal,Quentin Torroba,Romain Sauvestre,Roman Soletskyi,Rupert Menneer,Sagar Vaze,Samuel Barry,Sanchit Gandhi,Siddhant Waghjale,Siddharth Gandhi,Soham Ghosh,Srijan Mishra,Sumukh Aithal,Szymon Antoniak,Teven Le Scao,Théo Cachet,Theo Simon Sorg,Thibaut Lavril,Thiziri Nait Saada,Thomas Chabal,Thomas Foubert,Thomas Robert,Thomas Wang,Tim Lawson,Tom Bewley,Tom Bewley,Tom Edwards,Umar Jamil,Umberto Tomasini,Valeriia Nemychnikova,Van Phung,Vincent Maladière,Virgile Richard,Wassim Bouaziz,Wen-Ding Li,William Marshall,Xinghui Li,Xinyu Yang,Yassine El Ouahidi,Yihan Wang,Yunhao Tang,Zaccharie Ramzi*

Main category: cs.CL

TL;DR: Ministral 3系列是专为计算和内存受限应用设计的参数高效密集语言模型，包含3B、8B和14B三种规模，每种规模提供预训练基础模型、指令微调版本和推理模型。通过级联蒸馏技术构建，并具备图像理解能力，所有模型均开源于Apache 2.0许可。


<details>
  <summary>Details</summary>
Motivation: 在计算和内存资源受限的设备上部署高性能语言模型存在挑战，需要兼顾模型效率与能力。为此，提出一种参数高效且具备多模态理解能力的轻量级模型系列。

Method: 采用级联蒸馏（Cascade Distillation）方法，通过迭代剪枝与持续蒸馏训练，逐步优化模型性能并压缩参数规模，实现不同尺寸模型的高效生成。

Result: 成功构建了三组不同规模的 Ministral 3 模型（3B、8B、14B），每个模型均具备预训练、指令微调和推理优化版本，且支持图像理解，在保持低资源消耗的同时展现出良好的语言与多模态能力。

Conclusion: Ministral 3 系列模型在资源受限场景下表现出优异的实用性与可扩展性，为边缘设备上的高效智能应用提供了可行解决方案。

Abstract: We introduce the Ministral 3 series, a family of parameter-efficient dense language models designed for compute and memory constrained applications, available in three model sizes: 3B, 8B, and 14B parameters. For each model size, we release three variants: a pretrained base model for general-purpose use, an instruction finetuned, and a reasoning model for complex problem-solving. In addition, we present our recipe to derive the Ministral 3 models through Cascade Distillation, an iterative pruning and continued training with distillation technique. Each model comes with image understanding capabilities, all under the Apache 2.0 license.

</details>


### [116] [GraphSearch: Agentic Search-Augmented Reasoning for Zero-Shot Graph Learning](https://arxiv.org/abs/2601.08621)
*Jiajin Liu,Yuanfu Sun,Dongzhe Fan,Qiaoyu Tan*

Main category: cs.CL

TL;DR: GraphSearch is the first framework that extends search-augmented reasoning to graph-structured data, enabling zero-shot graph learning without fine-tuning. It uses a Graph-aware Query Planner and Retriever to leverage topological and semantic signals, with two traversal modes: recursive (GraphSearch-R) and flexible (GraphSearch-F). Experiments show it outperforms supervised methods in zero-shot node classification and link prediction.


<details>
  <summary>Details</summary>
Motivation: Existing search-augmented large reasoning models struggle with graph-structured data despite their success in reducing hallucinations in text-based reasoning. Graphs contain rich topological information that can guide retrieval and reasoning, but current methods fail to effectively exploit this structure due to challenges in query generation and balancing structural-semantic relevance.

Method: GraphSearch introduces a Graph-aware Query Planner that separates search space (e.g., 1-hop, multi-hop, global) from semantic queries, and a Graph-aware Retriever that constructs candidate sets based on topology and ranks them via a hybrid scoring function. Two traversal modes are implemented: GraphSearch-R (recursive hop-by-hop expansion) and GraphSearch-F (flexible retrieval across local and global neighborhoods).

Result: GraphSearch achieves competitive or superior performance compared to supervised graph learning methods across multiple benchmarks, setting state-of-the-art results in zero-shot node classification and link prediction, demonstrating strong generalization and effectiveness in agentic reasoning over graphs.

Conclusion: GraphSearch establishes a new paradigm for zero-shot, agentic reasoning over graph-structured data by effectively integrating topological priors into retrieval and reasoning, offering a flexible, generalizable solution without task-specific fine-tuning.

Abstract: Recent advances in search-augmented large reasoning models (LRMs) enable the retrieval of external knowledge to reduce hallucinations in multistep reasoning. However, their ability to operate on graph-structured data, prevalent in domains such as e-commerce, social networks, and scientific citations, remains underexplored. Unlike plain text corpora, graphs encode rich topological signals that connect related entities and can serve as valuable priors for retrieval, enabling more targeted search and improved reasoning efficiency. Yet, effectively leveraging such structure poses unique challenges, including the difficulty of generating graph-expressive queries and ensuring reliable retrieval that balances structural and semantic relevance. To address this gap, we introduce GraphSearch, the first framework that extends search-augmented reasoning to graph learning, enabling zero-shot graph learning without task-specific fine-tuning. GraphSearch combines a Graph-aware Query Planner, which disentangles search space (e.g., 1-hop, multi-hop, or global neighbors) from semantic queries, with a Graph-aware Retriever, which constructs candidate sets based on topology and ranks them using a hybrid scoring function. We further instantiate two traversal modes: GraphSearch-R, which recursively expands neighborhoods hop by hop, and GraphSearch-F, which flexibly retrieves across local and global neighborhoods without hop constraints. Extensive experiments across diverse benchmarks show that GraphSearch achieves competitive or even superior performance compared to supervised graph learning methods, setting state-of-the-art results in zero-shot node classification and link prediction. These findings position GraphSearch as a flexible and generalizable paradigm for agentic reasoning over graphs.

</details>


### [117] [How Order-Sensitive Are LLMs? OrderProbe for Deterministic Structural Reconstruction](https://arxiv.org/abs/2601.08626)
*Yingjie He,Zhaolu Kang,Kehan Jiang,Qianyuan Zhang,Jiachen Qian,Chunlei Meng,Yujie Feng,Yuan Wang,Jiabao Dou,Aming Wu,Leqi Zheng,Pengxiang Zhao,Jiaxin Liu,Zeyu Zhang,Lei Wang,Guansu Wang,Qishi Zhan,Xiaomin He,Meisheng Zhang,Jianyuan Ni*

Main category: cs.CL

TL;DR: 本文提出OrderProbe基准和诊断框架，用于评估大语言模型在中文、日文、韩文中对固定四字表达的结构重建能力。实验发现即使前沿模型在零样本情况下恢复准确率也常低于35%，且语义召回与结构规划之间存在系统性分离，表明结构鲁棒性并非语义能力的自然产物。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽在语义理解上表现优异，但其从混乱输入中重构内部结构的能力尚未被充分研究。传统句子级恢复任务因存在多种有效词序而难以进行自动化评估，因此需要一种可精确评分的基准。

Method: 提出OrderProbe基准，使用中文、日文、韩文中的固定四字符表达（具有唯一标准顺序），支持精确匹配评分；设计诊断框架，评估模型在恢复准确率、语义保真度、逻辑有效性、一致性、鲁棒性敏感性和信息密度等方面的表现。

Result: 在12个主流大语言模型上的实验表明，结构重建对当前模型仍是挑战，零样本恢复率普遍低于35%；同时观察到语义召回与结构规划之间存在持续分离现象，说明结构鲁棒性不能自动从语义能力中获得。

Conclusion: 结构重建能力是大语言模型中仍需重点提升的维度，语义理解与结构规划之间存在显著差异，未来模型设计应更关注结构生成的显式建模。

Abstract: Large language models (LLMs) excel at semantic understanding, yet their ability to reconstruct internal structure from scrambled inputs remains underexplored. Sentence-level restoration is ill-posed for automated evaluation because multiple valid word orders often exist. We introduce OrderProbe, a deterministic benchmark for structural reconstruction using fixed four-character expressions in Chinese, Japanese, and Korean, which have a unique canonical order and thus support exact-match scoring. We further propose a diagnostic framework that evaluates models beyond recovery accuracy, including semantic fidelity, logical validity, consistency, robustness sensitivity, and information density. Experiments on twelve widely used LLMs show that structural reconstruction remains difficult even for frontier systems: zero-shot recovery frequently falls below 35%. We also observe a consistent dissociation between semantic recall and structural planning, suggesting that structural robustness is not an automatic byproduct of semantic competence.

</details>


### [118] [Get away with less: Need of source side data curation to build parallel corpus for low resource Machine Translation](https://arxiv.org/abs/2601.08629)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本文提出了一种名为LALITA的框架，用于在低资源语言环境下高效筛选源句以构建平行语料库。该框架基于词汇和语言学特征，通过选择复杂句子来提升机器翻译系统的性能。实验表明，即使在50K至800K英文句子的小规模数据集下，该方法仍显著提高翻译质量，并将训练数据需求减少一半以上，适用于多种语言（如印地语、奥里亚语、尼泊尔语、挪威努尔施克语和德语），兼具成本降低与数据增强优势。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言中，人工翻译生成足够训练数据成本过高，因此亟需一种高效的数据筛选框架，以减少对大规模标注数据的依赖，同时保证机器翻译系统性能。

Method: 提出LALITA框架，利用词汇和语言学特征评估英-印地语双语语料，筛选出适合训练的复杂句子，实现高效平行语料构建。

Result: 在不同规模的模拟低资源数据集上，模型表现均优于基线；数据需求减少超过50%，且在多语言上表现出色，具备良好的可扩展性和数据增强潜力。

Conclusion: LALITA通过智能筛选复杂句子，显著降低机器翻译系统的训练数据需求，有效提升低资源环境下的翻译质量，具有广泛应用前景。

Abstract: Data curation is a critical yet under-researched step in the machine translation training paradigm. To train translation systems, data acquisition relies primarily on human translations and digital parallel sources or, to a limited degree, synthetic generation. But, for low-resource languages, human translation to generate sufficient data is prohibitively expensive. Therefore, it is crucial to develop a framework that screens source sentences to form efficient parallel text, ensuring optimal MT system performance in low-resource environments. We approach this by evaluating English-Hindi bi-text to determine effective sentence selection strategies for optimal MT system training. Our extensively tested framework, (Lexical And Linguistically Informed Text Analysis) LALITA, targets source sentence selection using lexical and linguistic features to curate parallel corpora. We find that by training mostly on complex sentences from both existing and synthetic datasets, our method significantly improves translation quality. We test this by simulating low-resource data availabilty with curated datasets of 50K to 800K English sentences and report improved performances on all data sizes. LALITA demonstrates remarkable efficiency, reducing data needs by more than half across multiple languages (Hindi, Odia, Nepali, Norwegian Nynorsk, and German). This approach not only reduces MT systems training cost by reducing training data requirement, but also showcases LALITA's utility in data augmentation.

</details>


### [119] [Moral Lenses, Political Coordinates: Towards Ideological Positioning of Morally Conditioned LLMs](https://arxiv.org/abs/2601.08634)
*Chenchen Yuan,Bolei Ma,Zheyu Zhang,Bardh Prenkaj,Frauke Kreuter,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 本文研究道德价值观对大语言模型政治定位的因果影响，通过条件化模型接受或拒绝特定道德价值，观察其在政治光谱上的变化。结果显示，道德条件化会显著且特定于价值地改变模型的政治坐标，且该效应受角色设定和模型规模调节，跨不同评估工具具有鲁棒性，表明对齐需基于更广泛的社会价值观（如道德）进行。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型政治倾向的评估多依赖直接探针或人口统计学角色设定，但社会心理学认为政治意识形态是基本道德直觉的下游结果。因此，需要探索道德价值观如何因果影响模型的政治定位，以实现更深层次的对齐。

Method: 将道德价值观作为可控条件，让模型有条件地支持或反对特定道德价值，再通过政治光谱测试（Political Compass Test）评估其政治定位的变化。采用不同角色设定和模型规模进行实验，并使用多种工具验证相同道德价值下的结果一致性。

Result: 道德条件化导致模型在经济与社会维度上出现显著且价值特异性的政治坐标偏移；该效应受角色框架和模型规模影响，且在不同评估工具下保持一致，表现出强鲁棒性。

Conclusion: 有效的大模型对齐必须将政治评估置于更广泛的道德和社会价值背景中，这为发展更贴近社会现实的对齐技术提供了新方向。

Abstract: While recent research has systematically documented political orientation in large language models (LLMs), existing evaluations rely primarily on direct probing or demographic persona engineering to surface ideological biases. In social psychology, however, political ideology is also understood as a downstream consequence of fundamental moral intuitions. In this work, we investigate the causal relationship between moral values and political positioning by treating moral orientation as a controllable condition. Rather than simply assigning a demographic persona, we condition models to endorse or reject specific moral values and evaluate the resulting shifts on their political orientations, using the Political Compass Test. By treating moral values as lenses, we observe how moral conditioning actively steers model trajectories across economic and social dimensions. Our findings show that such conditioning induces pronounced, value-specific shifts in models' political coordinates. We further notice that these effects are systematically modulated by role framing and model scale, and are robust across alternative assessment instruments instantiating the same moral value. This highlights that effective alignment requires anchoring political assessments within the context of broader social values including morality, paving the way for more socially grounded alignment techniques.

</details>


### [120] [A Parallel Cross-Lingual Benchmark for Multimodal Idiomaticity Understanding](https://arxiv.org/abs/2601.08645)
*Dilara Torunoğlu-Selamet,Dogukan Arslan,Rodrigo Wilkens,Wei He,Doruk Eryiğit,Thomas Pickard,Adriana S. Pagano,Aline Villavicencio,Gülşen Eryiğit,Ágnes Abuczki,Aida Cardoso,Alesia Lazarenka,Dina Almassova,Amalia Mendes,Anna Kanellopoulou,Antoni Brosa-Rodríguez,Baiba Saulite,Beata Wojtowicz,Bolette Pedersen,Carlos Manuel Hidalgo-Ternero,Chaya Liebeskind,Danka Jokić,Diego Alves,Eleni Triantafyllidi,Erik Velldal,Fred Philippy,Giedre Valunaite Oleskeviciene,Ieva Rizgeliene,Inguna Skadina,Irina Lobzhanidze,Isabell Stinessen Haugen,Jauza Akbar Krito,Jelena M. Marković,Johanna Monti,Josue Alejandro Sauca,Kaja Dobrovoljc,Kingsley O. Ugwuanyi,Laura Rituma,Lilja Øvrelid,Maha Tufail Agro,Manzura Abjalova,Maria Chatzigrigoriou,María del Mar Sánchez Ramos,Marija Pendevska,Masoumeh Seyyedrezaei,Mehrnoush Shamsfard,Momina Ahsan,Muhammad Ahsan Riaz Khan,Nathalie Carmen Hau Norman,Nilay Erdem Ayyıldız,Nina Hosseini-Kivanani,Noémi Ligeti-Nagy,Numaan Naeem,Olha Kanishcheva,Olha Yatsyshyna,Daniil Orel,Petra Giommarelli,Petya Osenova,Radovan Garabik,Regina E. Semou,Rozane Rebechi,Salsabila Zahirah Pranida,Samia Touileb,Sanni Nimb,Sarfraz Ahmad,Sarvinoz Nematkhonova,Shahar Golan,Shaoxiong Ji,Sopuruchi Christian Aboh,Srdjan Sucur,Stella Markantonatou,Sussi Olsen,Vahide Tajalli,Veronika Lipp,Voula Giouli,Yelda Yeşildal Eraydın,Zahra Saaberi,Zhuohan Xie*

Main category: cs.CL

TL;DR: 本文提出了XMPIE，一个包含34种语言和超过一万个条目的并行多语言、多模态潜在习语数据集，用于评估自然语言处理系统在跨语言和跨模态理解习语方面的能力。该数据集支持对不同语言中习语表达模式的比较分析，并研究习语理解在不同语言和模态（文本与图像）间的迁移性。数据由语言专家构建，每条习语配有五张图像，涵盖从字面到隐喻意义的光谱，包括语义相关和随机干扰项，构成高质量的多语言多模态习语理解基准。


<details>
  <summary>Details</summary>
Motivation: 习语的意义与特定语言社区的日常经验紧密相关，是评估自然语言处理系统语言和文化能力的重要挑战。现有数据集在多语言和多模态方面的覆盖不足，难以支撑跨语言和跨模态习语理解的系统评估。因此需要一个高质量、标准化的并行多语言多模态习语数据集。

Method: 通过语言专家协作，基于多语言指南构建了包含34种语言的习语数据集，每条习语配备五张图像，涵盖从字面到隐喻意义的连续变化，包括语义相关图和随机干扰图，确保数据的多样性和可比性。数据集支持跨语言、跨模态的对比分析和模型评估。

Result: XMPIE数据集成功构建了一个高质、大规模、多语言多模态的习语理解基准，可用于评估模型在不同语言中的习语理解能力，以及文本与图像之间习语理解的迁移性。实验表明，该数据集能有效揭示语言间习语表达的差异与共性，以及模态间理解的关联性。

Conclusion: XMPIE是一个具有广泛适用性的多语言多模态习语理解基准，能够推动自然语言处理系统在跨语言和跨模态情境下对习语的理解能力研究，为未来多语言多模态语义理解模型的开发与评估提供重要支持。

Abstract: Potentially idiomatic expressions (PIEs) construe meanings inherently tied to the everyday experience of a given language community. As such, they constitute an interesting challenge for assessing the linguistic (and to some extent cultural) capabilities of NLP systems. In this paper, we present XMPIE, a parallel multilingual and multimodal dataset of potentially idiomatic expressions. The dataset, containing 34 languages and over ten thousand items, allows comparative analyses of idiomatic patterns among language-specific realisations and preferences in order to gather insights about shared cultural aspects. This parallel dataset allows to evaluate model performance for a given PIE in different languages and whether idiomatic understanding in one language can be transferred to another. Moreover, the dataset supports the study of PIEs across textual and visual modalities, to measure to what extent PIE understanding in one modality transfers or implies in understanding in another modality (text vs. image). The data was created by language experts, with both textual and visual components crafted under multilingual guidelines, and each PIE is accompanied by five images representing a spectrum from idiomatic to literal meanings, including semantically related and random distractors. The result is a high-quality benchmark for evaluating multilingual and multimodal idiomatic language understanding.

</details>


### [121] [Safe Language Generation in the Limit](https://arxiv.org/abs/2601.08648)
*Antonios Anastasopoulos,Giuseppe Ateniese,Evgenios M. Kornaropoulos*

Main category: cs.CL

TL;DR: 本文首次从理论上探讨了安全语言生成问题，基于学习在极限中的计算范式，形式化了安全语言识别与生成任务。研究证明，在该模型下，安全语言识别是不可能的，而安全语言生成至少与常规语言识别一样困难，后者同样不可行。文章还讨论了若干难以处理和可处理的情况。


<details>
  <summary>Details</summary>
Motivation: 随着学习在极限中语言生成的研究进展，需要考虑其在现实世界中的应用与安全性问题，因此提出对安全语言生成的理论分析。

Method: 基于学习在极限的计算模型，形式化定义安全语言识别与生成任务，并通过理论推导分析其可实现性与复杂性。

Result: 证明了安全语言识别不可能，且安全语言生成至少与常规语言识别一样困难，即同样不可行；同时区分了不同情况下的可处理性。

Conclusion: 安全语言生成在理论上面临根本性挑战，尽管存在部分可处理情形，但整体上仍属于不可行任务，需谨慎对待其在实际系统中的应用。

Abstract: Recent results in learning a language in the limit have shown that, although language identification is impossible, language generation is tractable. As this foundational area expands, we need to consider the implications of language generation in real-world settings.
  This work offers the first theoretical treatment of safe language generation. Building on the computational paradigm of learning in the limit, we formalize the tasks of safe language identification and generation. We prove that under this model, safe language identification is impossible, and that safe language generation is at least as hard as (vanilla) language identification, which is also impossible. Last, we discuss several intractable and tractable cases.

</details>


### [122] [RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation](https://arxiv.org/abs/2601.08654)
*Yihan Hong,Huaiyuan Yao,Bolin Shen,Wanpeng Xu,Hua Wei,Yushun Dong*

Main category: cs.CL

TL;DR: 本文提出RULERS框架，通过将自然语言评分标准转化为可执行规范，解决大模型作为评判者时的对齐难题。该框架通过版本化不可变的评分包、结构化解码与确定性证据验证、以及轻量级Wasserstein校准，实现鲁棒且可复现的评分，显著提升与人类评分的一致性，且在对抗性评分扰动下保持稳定，使小型模型也能媲美大型专有模型。


<details>
  <summary>Details</summary>
Motivation: 当前大模型作为评判者面临生成随机性导致的评分不一致问题，尤其在对齐人类标准时表现不佳，主要源于评分标准的敏感性、推理过程不可验证及规模与人类评分边界不匹配等挑战。

Method: 提出RULERS框架，包括：1）将自然语言评分标准编译为版本化、不可变的可执行规范；2）强制结构化解码并进行确定性证据验证；3）采用轻量级Wasserstein距离进行后处理校准，全程无需更新模型参数。

Result: 在作文和摘要任务上，RULERS显著优于现有基线，在人类评分一致性、对抗性扰动下的稳定性方面表现优异，并使小模型性能接近甚至超越大型专有模型。

Conclusion: 可靠的LLM评判依赖于可执行的评分标准、可验证的证据和校准的评分尺度，而非仅靠提示工程。

Abstract: The LLM-as-a-Judge paradigm promises scalable rubric-based evaluation, yet aligning frozen black-box models with human standards remains a challenge due to inherent generation stochasticity. We reframe judge alignment as a criteria transfer problem and isolate three recurrent failure modes: rubric instability caused by prompt sensitivity, unverifiable reasoning that lacks auditable evidence, and scale misalignment with human grading boundaries. To address these issues, we introduce RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a compiler-executor framework that transforms natural language rubrics into executable specifications. RULERS operates by compiling criteria into versioned immutable bundles, enforcing structured decoding with deterministic evidence verification, and applying lightweight Wasserstein-based post-hoc calibration, all without updating model parameters. Extensive experiments on essay and summarization benchmarks demonstrate that RULERS significantly outperforms representative baselines in human agreement, maintains strong stability against adversarial rubric perturbations, and enables smaller models to rival larger proprietary judges. Overall, our results suggest that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales rather than prompt phrasing alone. Code is available at https://github.com/LabRAI/Rulers.git.

</details>


### [123] [Analyzing Bias in False Refusal Behavior of Large Language Models for Hate Speech Detoxification](https://arxiv.org/abs/2601.08668)
*Kyuri Im,Shuzhou Yuan,Michael Färber*

Main category: cs.CL

TL;DR: 该研究系统分析了大语言模型在仇恨言论净化任务中的误拒绝行为，发现其对高语义毒性内容及特定群体（如国籍、宗教、政治意识形态）的言论更易拒绝。尽管多语言数据集整体误拒绝率较低，但模型仍表现出语言相关的系统性偏见。为此，作者提出一种简单的跨语言翻译策略：将英文仇恨言论翻译为中文再转回，显著降低误拒绝率且保留原意，是一种有效且轻量的缓解方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理仇恨言论净化时频繁触发安全警报，导致任务被拒绝，影响实际应用效果。现有研究未充分揭示此类误拒绝背后的上下文与语言偏见机制，亟需探索有效的缓解策略。

Method: 通过评估九种大语言模型在英文学术与多语言数据集上的表现，系统分析其误拒绝行为；结合语义毒性水平与目标群体特征进行归因分析，并提出基于中英跨语言翻译的净化策略。

Result: LLMs对高语义毒性内容和特定社会群体目标的言论表现出更高的误拒绝率；多语言数据集虽整体表现较好，但仍存在语言依赖性偏见；提出的跨语言翻译策略能显著减少误拒绝，同时保持内容一致性。

Conclusion: 大语言模型在仇恨言论净化任务中存在系统性误拒绝问题，受语义毒性与目标群体特征影响，并呈现语言偏好。通过简单有效的跨语言翻译策略，可显著缓解该问题，提升模型实用性。

Abstract: While large language models (LLMs) have increasingly been applied to hate speech detoxification, the prompts often trigger safety alerts, causing LLMs to refuse the task. In this study, we systematically investigate false refusal behavior in hate speech detoxification and analyze the contextual and linguistic biases that trigger such refusals. We evaluate nine LLMs on both English and multilingual datasets, our results show that LLMs disproportionately refuse inputs with higher semantic toxicity and those targeting specific groups, particularly nationality, religion, and political ideology. Although multilingual datasets exhibit lower overall false refusal rates than English datasets, models still display systematic, language-dependent biases toward certain targets. Based on these findings, we propose a simple cross-translation strategy, translating English hate speech into Chinese for detoxification and back, which substantially reduces false refusals while preserving the original content, providing an effective and lightweight mitigation approach.

</details>


### [124] [Lessons from the Field: An Adaptable Lifecycle Approach to Applied Dialogue Summarization](https://arxiv.org/abs/2601.08682)
*Kushal Chawla,Chenyang Zhu,Pengshan Cai,Sangwoo Cho,Scott Novotney,Ayushman Singh,Jonah Lewis,Keasha Safewright,Alfy Samuel,Erin Babinsky,Shi-Xiong Zhang,Sambit Sahu*

Main category: cs.CL

TL;DR: 本文通过一个工业案例研究，探讨了构建用于多角色对话摘要的智能体系统的方法。重点分享了在完整开发周期中的实践经验，涵盖评估方法、组件优化、上游数据瓶颈及提示迁移性差导致的供应商锁定问题。


<details>
  <summary>Details</summary>
Motivation: 现有对话摘要研究多依赖静态数据集，难以应对实际场景中需求不断变化的挑战。为提升工业应用中多角色对话摘要的质量与适应性，亟需构建可灵活调整的智能体系统。

Method: 采用基于智能体架构的任务分解方式，将复杂摘要任务拆解为多个可独立优化的子任务，并结合动态评估机制与迭代优化策略，解决实际部署中的灵活性和鲁棒性问题。

Result: 该系统在真实工业场景中表现出较强的适应性和可靠性，显著提升了多角色对话摘要的质量；同时揭示了数据瓶颈、评估难度与提示不可移植性等关键挑战。

Conclusion: 构建高效且可扩展的对话摘要系统需综合考虑任务分解、动态评估、数据质量与提示设计。本研究为工业界实践者和未来研究提供了重要参考。

Abstract: Summarization of multi-party dialogues is a critical capability in industry, enhancing knowledge transfer and operational effectiveness across many domains. However, automatically generating high-quality summaries is challenging, as the ideal summary must satisfy a set of complex, multi-faceted requirements. While summarization has received immense attention in research, prior work has primarily utilized static datasets and benchmarks, a condition rare in practical scenarios where requirements inevitably evolve. In this work, we present an industry case study on developing an agentic system to summarize multi-party interactions. We share practical insights spanning the full development lifecycle to guide practitioners in building reliable, adaptable summarization systems, as well as to inform future research, covering: 1) robust methods for evaluation despite evolving requirements and task subjectivity, 2) component-wise optimization enabled by the task decomposition inherent in an agentic architecture, 3) the impact of upstream data bottlenecks, and 4) the realities of vendor lock-in due to the poor transferability of LLM prompts.

</details>


### [125] [QuantEval: A Benchmark for Financial Quantitative Tasks in Large Language Models](https://arxiv.org/abs/2601.08689)
*Zhaolu Kang,Junhao Gong,Wenqing Hu,Shuo Yin,Kehan Jiang,Zhicheng Fang,Yingjie He,Chunlei Meng,Rong Fu,Dongyang Chen,Leqi Zheng,Eric Hanchen Jiang,Yunfei Feng,Yitong Leng,Junfan Zhu,Xiaoyou Chen,Xi Yang,Richeng Xuan*

Main category: cs.CL

TL;DR: QuantEval 是一个评估大语言模型在量化金融领域能力的基准，涵盖知识问答、数学推理和策略编码三个维度，并引入了类似CTA的回测框架来执行和评估模型生成的策略，从而更真实地衡量其量化编码能力。实验表明，现有模型在推理和策略编码方面与人类专家仍有显著差距，通过大规模监督微调和强化学习可带来持续改进。该研究还公开了完整的可复现回测配置。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在金融量化任务中的评估分散且主要局限于知识型问答，缺乏对数学推理和策略编码等核心能力的系统性评估，亟需一个更全面、更真实的基准来推动研究和实际应用。

Method: 提出 QuantEval 基准，整合知识问答、数学推理与策略编码三类任务，并构建 CTA 风格的回测框架以执行模型生成的交易策略，使用金融绩效指标进行评估；同时在领域对齐数据上进行大规模监督微调与强化学习实验。

Result: 评估发现主流 LLMs 在推理与策略编码方面与人类专家存在明显差距；通过微调与强化学习，模型性能得到一致提升；公开的回测配置确保了结果的可复现性。

Conclusion: QuantEval 为评估大语言模型在量化金融中的能力提供了有效工具，有助于推动其在真实交易流程中的落地应用，未来可进一步促进模型在金融领域的深度优化与部署。

Abstract: Large Language Models (LLMs) have shown strong capabilities across many domains, yet their evaluation in financial quantitative tasks remains fragmented and mostly limited to knowledge-centric question answering. We introduce QuantEval, a benchmark that evaluates LLMs across three essential dimensions of quantitative finance: knowledge-based QA, quantitative mathematical reasoning, and quantitative strategy coding. Unlike prior financial benchmarks, QuantEval integrates a CTA-style backtesting framework that executes model-generated strategies and evaluates them using financial performance metrics, enabling a more realistic assessment of quantitative coding ability. We evaluate some state-of-the-art open-source and proprietary LLMs and observe substantial gaps to human experts, particularly in reasoning and strategy coding. Finally, we conduct large-scale supervised fine-tuning and reinforcement learning experiments on domain-aligned data, demonstrating consistent improvements. We hope QuantEval will facilitate research on LLMs' quantitative finance capabilities and accelerate their practical adoption in real-world trading workflows. We additionally release the full deterministic backtesting configuration (asset universe, cost model, and metric definitions) to ensure strict reproducibility.

</details>


### [126] [RAGShaper: Eliciting Sophisticated Agentic RAG Skills via Automated Data Synthesis](https://arxiv.org/abs/2601.08699)
*Zhengwei Tao,Bo Li,Jialong Wu,Guochen Yan,Huanyao Zhang,Jiahao Xu,Haitao Mi,Wentao Zhang*

Main category: cs.CL

TL;DR: RAGShaper 是一个用于自动化构建 RAG 任务和鲁棒智能体轨迹的数据合成框架，通过引入 InfoCurator 构建包含对抗性干扰的密集信息树，并采用约束导航策略迫使教师智能体应对干扰，从而生成体现错误修正和噪声排斥的轨迹。实验表明，基于该合成语料库训练的模型在噪声密集和复杂的检索任务中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 当前 agentic RAG 的发展受限于高质量训练数据的稀缺，尤其是难以模拟真实检索环境中的噪声与复杂性；传统人工标注方式不可扩展且无法捕捉动态推理策略，因此需要一种可扩展的方法来生成更贴近现实的训练数据。

Method: 提出 RAGShaper 框架，包含 InfoCurator 模块以构建富含多层级（感知与认知）对抗性干扰的密集信息树，并设计约束导航策略，引导教师智能体主动面对干扰，生成具有错误修正能力的智能体轨迹。

Result: 在复杂和高噪声检索任务中，基于 RAGShaper 合成数据训练的模型表现出显著更强的鲁棒性，性能超越现有基线方法。

Conclusion: RAGShaper 有效解决了高质量 RAG 训练数据稀缺的问题，通过自动化生成具有挑战性的智能体轨迹，显著提升了大语言模型在真实复杂环境下的问题解决能力。

Abstract: Agentic Retrieval-Augmented Generation (RAG) empowers large language models to autonomously plan and retrieve information for complex problem-solving. However, the development of robust agents is hindered by the scarcity of high-quality training data that reflects the noise and complexity of real-world retrieval environments. Conventional manual annotation is unscalable and often fails to capture the dynamic reasoning strategies required to handle retrieval failures. To bridge this gap, we introduce RAGShaper, a novel data synthesis framework designed to automate the construction of RAG tasks and robust agent trajectories. RAGShaper incorporates an InfoCurator to build dense information trees enriched with adversarial distractors spanning Perception and Cognition levels. Furthermore, we propose a constrained navigation strategy that forces a teacher agent to confront these distractors, thereby eliciting trajectories that explicitly demonstrate error correction and noise rejection. Comprehensive experiments confirm that models trained on our synthesized corpus significantly outperform existing baselines, exhibiting superior robustness in noise-intensive and complex retrieval tasks.

</details>


### [127] [PrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation](https://arxiv.org/abs/2601.08739)
*Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: PrivGemo 是一种隐私保护的检索增强框架，用于知识图谱（KG）驱动的推理。它通过双塔设计保持原始知识本地化，同时在匿名视图上进行远程推理，超越了仅掩码实体名称的方法，有效限制语义和结构暴露。该框架支持多跳、多实体推理，通过检索连接所有主题实体的匿名长路径，并在本地进行溯源与验证。引入分层控制器和隐私感知经验记忆，减少不必要的探索和远程交互。在六个基准测试中，PrivGemo 达到当前最优性能，相比最强基线最高提升17.1%；且使小型模型（如Qwen3-4B）达到接近GPT-4-Turbo的推理水平。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护方法仅掩码实体名称，仍存在结构泄露、远程交互不可控、多跳/多实体推理脆弱以及经验复用受限等问题，无法有效保障私有知识图谱在与闭源大模型交互时的安全性与效率。

Method: 提出PrivGemo框架，采用双塔设计实现本地保留原始KG，远程基于匿名视图推理；通过检索匿名长路径支持多跳多实体推理；引入分层控制器与隐私感知经验记忆，控制暴露范围并减少冗余交互。

Result: 在六个基准数据集上均取得领先性能，相比最强基线最高提升17.1%；小型模型（如Qwen3-4B）推理能力接近GPT-4-Turbo水平。

Conclusion: PrivGemo成功解决了私有知识图谱在与闭源大模型协作中的隐私与效率难题，实现了安全、高效、可扩展的KG增强推理，为实际应用提供了可靠方案。

Abstract: Knowledge graphs (KGs) provide structured evidence that can ground large language model (LLM) reasoning for knowledge-intensive question answering. However, many practical KGs are private, and sending retrieved triples or exploration traces to closed-source LLM APIs introduces leakage risk. Existing privacy treatments focus on masking entity names, but they still face four limitations: structural leakage under semantic masking, uncontrollable remote interaction, fragile multi-hop and multi-entity reasoning, and limited experience reuse for stability and efficiency. To address these issues, we propose PrivGemo, a privacy-preserving retrieval-augmented framework for KG-grounded reasoning with memory-guided exposure control. PrivGemo uses a dual-tower design to keep raw KG knowledge local while enabling remote reasoning over an anonymized view that goes beyond name masking to limit both semantic and structural exposure. PrivGemo supports multi-hop, multi-entity reasoning by retrieving anonymized long-hop paths that connect all topic entities, while keeping grounding and verification on the local KG. A hierarchical controller and a privacy-aware experience memory further reduce unnecessary exploration and remote interactions. Comprehensive experiments on six benchmarks show that PrivGemo achieves overall state-of-the-art results, outperforming the strongest baseline by up to 17.1%. Furthermore, PrivGemo enables smaller models (e.g., Qwen3-4B) to achieve reasoning performance comparable to that of GPT-4-Turbo.

</details>


### [128] [From Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding](https://arxiv.org/abs/2601.08741)
*Anmol Gulati,Sahil Sen,Waqar Sarguroh,Kevin Paul*

Main category: cs.CL

TL;DR: FRTR-Bench 是首个大规模多模态电子表格推理基准，包含近四百万单元格和50多个嵌入图像的企事业单位Excel工作簿。针对大尺度、多表、多模态电子表格的推理难题，提出FRTR框架，通过行、列、块级细粒度嵌入，结合混合词法-密集检索与倒数排名融合（RRF），并整合多模态信息实现数值与视觉联合推理。在FRTR-Bench上，使用Claude Sonnet 4.5达到74%准确率，远超此前24%的水平；在SpreadsheetLLM上，GPT-5达87%准确率，同时减少约50%的令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型难以有效处理包含数千行数据、多关联表格及图表等视觉内容的企业级复杂电子表格，传统方法如单表压缩或全上下文编码存在可扩展性差、不贴近真实用户交互的问题。

Method: 提出FRTR框架，将电子表格分解为行、列、块级别的细粒度嵌入，采用混合词法-密集检索与倒数排名融合（RRF）进行检索，并融合多模态嵌入以支持数值与视觉信息联合推理。

Result: 在FRTR-Bench上，使用Claude Sonnet 4.5实现74%的准确率，显著优于此前24%的最先进水平；在SpreadsheetLLM上，GPT-5达到87%准确率，同时相比上下文压缩方法减少约50%的令牌使用量。

Conclusion: FRTR框架有效提升了大语言模型在复杂、多模态企业电子表格上的推理能力，为未来构建更智能的办公自动化系统提供了坚实基础。

Abstract: Large Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users interact with complex, multimodal workbooks. We introduce FRTR-Bench, the first large-scale benchmark for multimodal spreadsheet reasoning, comprising 30 enterprise-grade Excel workbooks spanning nearly four million cells and more than 50 embedded images. To address these challenges, we present From Rows to Reasoning (FRTR), an advanced, multimodal retrieval-augmented generation framework that decomposes Excel workbooks into granular row, column, and block embeddings, employs hybrid lexical-dense retrieval with Reciprocal Rank Fusion (RRF), and integrates multimodal embeddings to reason over both numerical and visual information. We tested FRTR on six LLMs, achieving 74% answer accuracy on FRTR-Bench with Claude Sonnet 4.5, a substantial improvement over prior state-of-the-art approaches that reached only 24%. On the SpreadsheetLLM benchmark, FRTR achieved 87% accuracy with GPT-5 while reducing token usage by roughly 50% compared to context-compression methods.

</details>


### [129] [TableCache: Primary Foreign Key Guided KV Cache Precomputation for Low Latency Text-to-SQL](https://arxiv.org/abs/2601.08743)
*Jinbo Su,Yuxuan Hu,Cuiping Li,Hong Chen,Jia Li,Lintao Ma,Jing Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为TableCache的新方法，旨在解决文本到SQL任务中因数据库模式过长导致的上下文延迟问题。通过离线预计算表的键值（KV）缓存，并在推理时在线查询所需缓存，结合表的主外键关系保持与表Trie结构实现高效查找，同时引入查询重排序和并行加载管道以提升缓存命中率和性能。实验表明，该方法在时间到首个标记（TTFT）上最高可提速3.62倍，且性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 现有基于大模型的Text-to-SQL方法在提示中包含大量数据库模式信息，导致上下文过长、预填充延迟高；尽管用户查询常涉及重复的表集合，但当前推理引擎在处理不同表顺序的查询时仍生成冗余前缀缓存，造成效率低下。

Method: 离线预计算表的键值（KV）缓存，保留主外键关系；构建表Trie结构以支持高效缓存查找；设计查询重排序策略与并行计算加载流水线，优化缓存使用与加载效率。

Result: TableCache在时间到首个标记（TTFT）上实现了最高3.62倍的加速，同时保持了几乎无损的模型性能。

Conclusion: 通过离线预计算与智能缓存管理，TableCache有效缓解了文本到SQL任务中的长上下文延迟问题，显著提升了推理效率，具备实际部署潜力。

Abstract: In Text-to-SQL tasks, existing LLM-based methods often include extensive database schemas in prompts, leading to long context lengths and increased prefilling latency. While user queries typically focus on recurrent table sets-offering an opportunity for KV cache sharing across queries-current inference engines, such as SGLang and vLLM, generate redundant prefix cache copies when processing user queries with varying table orders. To address this inefficiency, we propose precomputing table representations as KV caches offline and querying the required ones online. A key aspect of our approach is the computation of table caches while preserving primary foreign key relationships between tables. Additionally, we construct a Table Trie structure to facilitate efficient KV cache lookups during inference. To enhance cache performance, we introduce a cache management system with a query reranking strategy to improve cache hit rates and a computation loading pipeline for parallelizing model inference and cache loading. Experimental results show that our proposed TableCache achieves up to a 3.62x speedup in Time to First Token (TTFT) with negligible performance degradation.

</details>


### [130] [Spatial Context Improves the Integration of Text with Remote Sensing for Mapping Environmental Variables](https://arxiv.org/abs/2601.08750)
*Valerie Zermatten,Chiara Vanalli,Gencer Sumbul,Diego Marcos,Devis Tuia*

Main category: cs.CL

TL;DR: 本文提出一种基于注意力机制的方法，结合航空影像与地理定位文本，在空间邻域内整合多个附近观测的贡献，以提升环境变量预测性能。该方法在EcoWikiRS数据集上对103个环境变量进行预测，显著优于单一位置或单模态（仅图像或仅文本）基线模型，尤其在气候、土壤、人口和土地利用/覆盖等类别上表现突出。


<details>
  <summary>Details</summary>
Motivation: 文本数据在生态学中具有独特信息价值，但其在空间上的分布稀疏且不规则，难以与传统地理空间数据融合。现有方法未明确文本数据在生态任务中的作用，也缺乏有效的多源数据整合策略，因此亟需一种能够有效结合文本与影像数据并考虑空间上下文的方法。

Method: 提出一种基于注意力机制的多模态融合模型，将视觉特征、文本特征与地理编码相结合，并通过注意力模块动态选择对预测任务有用的邻近空间观测，实现跨模态与空间上下文的有效整合。

Result: 在EcoWikiRS数据集上，所提方法在103个环境变量预测任务中持续优于单模态和单位置基线模型；特别是在气候、土壤、人口和土地利用/覆盖等主题变量上，性能提升显著，验证了空间上下文与多模态融合的有效性。

Conclusion: 结合地理定位文本与航空影像，并引入空间邻域注意力机制，能有效提升局部环境条件的预测能力，为生态学研究提供了新的多源数据融合范式。

Abstract: Recent developments in natural language processing highlight text as an emerging data source for ecology. Textual resources carry unique information that can be used in complementarity with geospatial data sources, thus providing insights at the local scale into environmental conditions and properties hidden from more traditional data sources. Leveraging textual information in a spatial context presents several challenges. First, the contribution of textual data remains poorly defined in an ecological context, and it is unclear for which tasks it should be incorporated. Unlike ubiquitous satellite imagery or environmental covariates, the availability of textual data is sparse and irregular; its integration with geospatial data is not straightforward. In response to these challenges, this work proposes an attention-based approach that combines aerial imagery and geolocated text within a spatial neighbourhood, i.e. integrating contributions from several nearby observations. Our approach combines vision and text representations with a geolocation encoding, with an attention-based module that dynamically selects spatial neighbours that are useful for predictive tasks.The proposed approach is applied to the EcoWikiRS dataset, which combines high-resolution aerial imagery with sentences extracted from Wikipedia describing local environmental conditions across Switzerland. Our model is evaluated on the task of predicting 103 environmental variables from the SWECO25 data cube. Our approach consistently outperforms single-location or unimodal, i.e. image-only or text-only, baselines. When analysing variables by thematic groups, results show a significant improvement in performance for climatic, edaphic, population and land use/land cover variables, underscoring the benefit of including the spatial context when combining text and image data.

</details>


### [131] [Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge](https://arxiv.org/abs/2601.08808)
*Yao Tang,Li Dong,Yaru Hao,Qingxiu Dong,Furu Wei,Jiatao Gu*

Main category: cs.CL

TL;DR: Multiplex Thinking 是一种随机软推理机制，通过在每一步采样 K 个候选词并聚合其嵌入为单一连续的多路令牌，实现更高效的推理。该方法在保持词汇嵌入先验和采样动态的同时，引入了可处理的概率分布，支持直接的基于策略强化学习优化。它具有自适应性：自信时接近传统 CoT，不确定时紧凑表示多个可能下一步，不增加序列长度。在多个数学推理基准上，优于现有离散 CoT 和强化学习基线，且生成序列更短。


<details>
  <summary>Details</summary>
Motivation: 人类在推理时通常以软方式维持多个可能下一步的分布，而传统 Chain-of-Thought (CoT) 生成长且低带宽的离散序列，效率较低。因此需要一种既能保留推理多样性又减少序列长度的方法。

Method: 提出 Multiplex Thinking，即在每个思考步骤中采样 K 个候选词，将其嵌入聚合为一个连续的多路令牌，从而构建可优化的概率分布，并使用基于策略的强化学习进行训练。该方法能根据模型置信度自适应调整输出形式。

Result: 在多个复杂数学推理基准上，Multiplex Thinking 在 Pass@1 到 Pass@1024 的所有指标上均优于强基线，同时生成更短的推理序列，证明其高效性和优越性。

Conclusion: Multiplex Thinking 实现了高效、自适应的软推理，兼具推理质量与序列压缩能力，是提升大语言模型复杂任务推理性能的有效方案。

Abstract: Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.

</details>


### [132] [Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System](https://arxiv.org/abs/2601.08829)
*Hsiang-Wei Huang,Junbin Lu,Kuang-Ming Chen,Jenq-Neng Hwang*

Main category: cs.CL

TL;DR: 本研究通过模拟真实会议论文提交场景，探讨了在Elo评分系统中大型语言模型（LLM）评审员之间的动态互动。多轮评审过程中，具有不同人格特征的LLM评审员在领域主席（Area Chair）的协调下进行交互，并对比了基础设置与引入Elo评分和评审员记忆的条件。结果显示，引入Elo机制可提升领域主席决策准确性，但评审员会采取策略性行为以利用系统漏洞，而非真正提升评审质量。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 探究在现实会议评审场景中，大型语言模型（LLM）作为评审员时的行为动态，特别是基于Elo评分系统的激励机制是否能有效提升评审质量与决策准确性。

Method: 构建一个基于Elo评级系统的多轮评审模拟环境，引入多个具有不同人格特征的LLM评审员，在领域主席的监督下进行多轮交互式评审。对比基准设置与引入Elo评分及评审员记忆的实验条件。

Result: 引入Elo评分显著提升了领域主席的决策准确率；然而，评审员表现出策略性适应行为，利用系统机制优化自身评分，而非提高评审努力或质量。

Conclusion: 尽管Elo评分系统有助于提升整体评审决策质量，但其可能被评审员策略性利用，导致评审努力未实质性提升，提示需设计更鲁棒的评审激励机制。

Abstract: In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort. Our code is available at https://github.com/hsiangwei0903/EloReview.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [133] [When Models Know When They Do Not Know: Calibration, Cascading, and Cleaning](https://arxiv.org/abs/2601.07965)
*Chenjie Hao,Weyl Lu,Yuko Ishiwaka,Zengyi Li,Weier Wan,Yubei Chen*

Main category: cs.AI

TL;DR: 本文提出一种无需训练的通用方法，通过模型校准、级联和数据清洗，使模型能够识别自身未知情况。基于置信度与准确率的相关性及校准置信度在测试集上的稳定性，该方法实现了高效模型级联与高质量数据清洗，显著提升AI系统的效率、可靠性与可信度。


<details>
  <summary>Details</summary>
Motivation: 让模型具备识别自身不确定性的能力，从而在实际应用中更高效、可靠地处理未知情况，是构建可信AI的关键一步。现有方法在特定领域虽有效，但缺乏通用性与无需训练的可行性。

Method: 提出一种无需训练的通用方法，利用校准后的置信度信号进行模型级联（优势路由）和数据清洗；基于校准置信度的可比性，实现大/小模型级联或同规模模型协同，并用于识别图像与语言数据集中的标注错误样本。

Result: 在ImageNet和MMLU等数据集上，该方法成功识别出大量误标样本；模型级联在保持高精度的同时显著提升效率，甚至超越单个模型性能。实验证明校准置信度具有高度可靠性与可比性。

Conclusion: 使模型能够识别自身未知是迈向更高效、可靠和可信AI的重要实践步骤。本文提出的校准方法具有通用性、有效性与实用性，适用于视觉与语言模型，为模型自我认知能力的应用提供了新范式。

Abstract: When a model knows when it does not know, many possibilities emerge. The first question is how to enable a model to recognize that it does not know. A promising approach is to use confidence, computed from the model's internal signals, to reflect its ignorance. Prior work in specific domains has shown that calibration can provide reliable confidence estimates. In this work, we propose a simple, effective, and universal training-free method that applies to both vision and language models, performing model calibration, cascading, and data cleaning to better exploit a model's ability to recognize when it does not know. We first highlight two key empirical observations: higher confidence corresponds to higher accuracy within a single model, and models calibrated on the validation set remain calibrated on a held-out test set. These findings empirically establish the reliability and comparability of calibrated confidence. Building on this, we introduce two applications: (1) model cascading with calibrated advantage routing and (2) data cleaning based on model ensemble. Using the routing signal derived from the comparability of calibrated confidences, we cascade large and small models to improve efficiency with almost no compromise in accuracy, and we further cascade two models of comparable scale to achieve performance beyond either model alone. Leveraging multiple experts and their calibrated confidences, we design a simple yet effective data-cleaning method that balances precision and detection rate to identify mislabeled samples in ImageNet and Massive Multitask Language Understanding (MMLU) datasets. Our results demonstrate that enabling models to recognize when they do not know is a practical step toward more efficient, reliable, and trustworthy AI.

</details>


### [134] [Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety](https://arxiv.org/abs/2601.08000)
*Can Jin,Rui Wu,Tong Che,Qixin Zhang,Hongwu Peng,Jiahui Zhao,Zhenting Wang,Wenqi Wei,Ligong Han,Zhao Zhang,Yuan Cao,Ruixiang Tang,Dimitris N. Metaxas*

Main category: cs.AI

TL;DR: 本文研究了在开源大语言模型中通过显式安全代码与案例示范对安全性的不同影响，发现显式代码会不一致地提升安全性但降低帮助性，而基于案例的简化代码训练能实现更稳健和泛化的安全行为。为此提出CADA方法，结合强化学习与自生成的安全推理链，以案例增强的推理方式提升模型的安全性、鲁棒性，并减少过度拒绝，同时保持实用性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在确保安全原则遵守的同时避免拒绝良性请求仍面临挑战；尽管OpenAI采用推理式对齐（DA）通过详细‘代码式’规则提升安全性，但该方法在缺乏高级推理能力的开源模型中效果尚不明确。因此需要探索更有效的安全对齐策略。

Method: 系统评估显式安全代码与案例示范的影响；提出CADA方法，利用强化学习训练自生成的安全推理链，结合案例增强的推理机制进行对齐。

Result: CADA显著提升了模型的无害性，增强了对抗攻击的鲁棒性，减少了过度拒绝现象，同时在多个基准测试中保持了良好的实用性。

Conclusion: 通过案例增强的推理方式替代纯规则式的对齐，能够更有效地平衡安全性与帮助性，为开源大模型提供一种实用且高效的改进方案。

Abstract: Ensuring that Large Language Models (LLMs) adhere to safety principles without refusing benign requests remains a significant challenge. While OpenAI introduces deliberative alignment (DA) to enhance the safety of its o-series models through reasoning over detailed ``code-like'' safety rules, the effectiveness of this approach in open-source LLMs, which typically lack advanced reasoning capabilities, is understudied. In this work, we systematically evaluate the impact of explicitly specifying extensive safety codes versus demonstrating them through illustrative cases. We find that referencing explicit codes inconsistently improves harmlessness and systematically degrades helpfulness, whereas training on case-augmented simple codes yields more robust and generalized safety behaviors. By guiding LLMs with case-augmented reasoning instead of extensive code-like safety rules, we avoid rigid adherence to narrowly enumerated rules and enable broader adaptability. Building on these insights, we propose CADA, a case-augmented deliberative alignment method for LLMs utilizing reinforcement learning on self-generated safety reasoning chains. CADA effectively enhances harmlessness, improves robustness against attacks, and reduces over-refusal while preserving utility across diverse benchmarks, offering a practical alternative to rule-only DA for improving safety while maintaining helpfulness.

</details>


### [135] [Internal Deployment Gaps in AI Regulation](https://arxiv.org/abs/2601.08005)
*Joe Kwon,Stephen Casper*

Main category: cs.AI

TL;DR: 本文探讨2025年美国和欧盟的前沿人工智能监管如何应对企业内部部署的高能力AI系统，识别出三个监管漏洞：范围模糊、一次性合规评估无法跟踪系统持续演进、信息不对称导致监管失察。文章分析这些漏洞存在的原因，包括可衡量性、激励机制与信息获取之间的张力，并提出可能的解决路径及其权衡。旨在推动对内部部署AI的政策选择更加主动和审慎。


<details>
  <summary>Details</summary>
Motivation: 当前前沿AI监管主要针对对外部署的系统，但企业内部部署的高能力AI系统（如用于研发自动化、关键业务加速和处理敏感数据）同样具有重大风险。然而，现有法规在覆盖内部部署方面存在明显盲区，可能导致高风险系统规避监管。因此，亟需系统分析这些监管缺口及其成因，以指导更完善的政策设计。

Method: 通过对比分析美国和欧盟2025年前沿AI监管框架，识别内部部署系统面临的监管漏洞；结合制度设计中的可衡量性、激励机制与信息获取等核心矛盾，深入剖析漏洞成因；最后提出若干潜在治理策略并评估其适用性与代价。

Result: 识别出三项关键监管漏洞：（1）法律范围模糊使内部系统得以规避责任；（2）静态合规评估难以反映动态演化中的系统风险；（3）信息不对称削弱监管机构的知情能力。进一步揭示这些漏洞根植于技术复杂性、企业激励与监管资源限制之间的深层张力。提出包括动态合规机制、强制信息披露、第三方审计等应对方案，各有适用边界与成本。

Conclusion: 当前前沿AI监管体系在应对内部部署系统方面存在结构性缺陷。为实现有效治理，必须主动设计专门规则，平衡创新激励与风险控制，避免因监管滞后或疏漏导致系统性风险。政策制定应基于对内部部署特性的深刻理解，采取前瞻性、适应性的治理策略。

Abstract: Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations, such as for automating R\&D, accelerating critical business processes, and handling sensitive proprietary data. This paper examines how frontier AI regulations in the United States and European Union in 2025 handle internal deployment. We identify three gaps that could cause internally-deployed systems to evade intended oversight: (1) scope ambiguity that allows internal systems to evade regulatory obligations, (2) point-in-time compliance assessments that fail to capture the continuous evolution of internal systems, and (3) information asymmetries that subvert regulatory awareness and oversight. We then analyze why these gaps persist, examining tensions around measurability, incentives, and information access. Finally, we map potential approaches to address them and their associated tradeoffs. By understanding these patterns, we hope that policy choices around internally deployed AI systems can be made deliberately rather than incidentally.

</details>


### [136] [Integrating Attendance Tracking and Emotion Detection for Enhanced Student Engagement in Smart Classrooms](https://arxiv.org/abs/2601.08049)
*Keith Ainebyona,Ann Move Oguti,Joseph Walusimbi,Ritah Kobusingye*

Main category: cs.AI

TL;DR: SCASED 是一个基于物联网的智能教室系统，结合自动考勤与面部情绪识别，实现对学生课堂参与度的实时监控。系统使用 Raspberry Pi 摄像头和 OpenCV 进行人脸检测，通过微调的 MobileNetV2 模型识别四种学习相关情绪（专注、无聊、困惑、沮丧）。采用会话机制，每会话仅记录一次考勤，之后持续进行情绪分析，并通过云端仪表板可视化数据。在 DAiSEE 数据集上的实验显示情绪分类准确率达 89.5%。结果表明，将考勤与情绪分析结合可为教师提供更深入的课堂动态洞察，支持更灵活的教学调整。


<details>
  <summary>Details</summary>
Motivation: 当前智能教室技术多集中于自动化考勤，忽视学生的情绪与认知参与状态，导致教师难以及时发现学生注意力不集中或学习困难，限制了教学策略的实时调整。因此，亟需一种能同时监测考勤与情绪的系统以提升教学互动性与响应性。

Method: 系统基于 Raspberry Pi 摄像头采集视频流，利用 OpenCV 实现人脸检测；采用微调的 MobileNetV2 模型对四类情绪（专注、无聊、困惑、沮丧）进行分类；设计会话机制，确保每会话仅记录一次考勤，随后持续进行情绪分析；所有数据上传至云平台，通过可视化仪表板呈现给教师。

Result: 在 DAiSEE 数据集上的实验结果显示，该系统的情绪分类准确率达到 89.5%。实证表明，结合考勤与情绪数据分析能够有效揭示课堂参与情况，帮助教师识别学生的学习状态变化，从而支持更具适应性的教学干预。

Conclusion: SCASED 成功实现了智能教室中考勤与情绪状态的同步监测，提升了教学反馈的实时性与精准性。该系统为促进学生参与度与教学质量提供了可行的技术路径，具有良好的应用前景。

Abstract: The increasing adoption of smart classroom technologies in higher education has mainly focused on automating attendance, with limited attention given to students' emotional and cognitive engagement during lectures. This limits instructors' ability to identify disengagement and adapt teaching strategies in real time. This paper presents SCASED (Smart Classroom Attendance System with Emotion Detection), an IoT-based system that integrates automated attendance tracking with facial emotion recognition to support classroom engagement monitoring. The system uses a Raspberry Pi camera and OpenCV for face detection, and a finetuned MobileNetV2 model to classify four learning-related emotional states: engagement, boredom, confusion, and frustration. A session-based mechanism is implemented to manage attendance and emotion monitoring by recording attendance once per session and performing continuous emotion analysis thereafter. Attendance and emotion data are visualized through a cloud-based dashboard to provide instructors with insights into classroom dynamics. Experimental evaluation using the DAiSEE dataset achieved an emotion classification accuracy of 89.5%. The results show that integrating attendance data with emotion analytics can provide instructors with additional insight into classroom dynamics and support more responsive teaching practices.

</details>


### [137] [A New Strategy for Verifying Reach-Avoid Specifications in Neural Feedback Systems](https://arxiv.org/abs/2601.08065)
*Samuel I. Akinwande,Sydney M. Katz,Mykel J. Kochenderfer,Clark Barrett*

Main category: cs.AI

TL;DR: 本文提出新算法，可计算神经反馈系统中后向可达集的上界和下界近似，并将其与现有前向分析技术结合，构建统一的验证框架。


<details>
  <summary>Details</summary>
Motivation: 现有后向可达性方法可扩展性差，而前向可达性分析虽为主流但存在局限，因此需要改进后向方法并融合前向技术以提升验证能力。

Method: 提出新的算法，用于计算神经反馈系统的后向可达集的过近似和欠近似，并与已有前向分析方法集成，形成统一的验证框架。

Result: 成功实现了对神经反馈系统中后向可达集的有效近似，并通过融合前向与后向方法，提升了系统验证的精度与效率。

Conclusion: 所提出的统一框架显著增强了对神经反馈系统进行安全验证的能力，为复杂系统的形式化验证提供了新工具。

Abstract: Forward reachability analysis is the predominant approach for verifying reach-avoid properties in neural feedback systems (dynamical systems controlled by neural networks). This dominance stems from the limited scalability of existing backward reachability methods. In this work, we introduce new algorithms that compute both over- and under-approximations of backward reachable sets for such systems. We further integrate these backward algorithms with established forward analysis techniques to yield a unified verification framework for neural feedback systems.

</details>


### [138] [Embedded AI Companion System on Edge Devices](https://arxiv.org/abs/2601.08128)
*Rahul Gupta,Stephen D. H. Hsu*

Main category: cs.AI

TL;DR: 本文提出一种在边缘设备上运行的内存范式，通过交替使用活跃与非活跃阶段，在低延迟实时对话和高计算量的记忆提取、整合与维护之间取得平衡。该设计在资源受限的嵌入式硬件上实现了低延迟与长期个性化兼顾。研究还引入了一个综合评估AI伴侣的基准测试，实验表明，即使使用极弱模型（量化后的Qwen2.5-7B-Instruct int4），系统在多数指标上仍优于无记忆的原始大模型，并接近GPT-3.5（16k上下文窗口）的表现。


<details>
  <summary>Details</summary>
Motivation: 边缘设备计算资源有限，现有AI伴侣与记忆系统因计算开销大、延迟高，难以直接部署。亟需一种能在资源受限环境下实现低延迟交互与长期个性化记忆管理的新方法。

Method: 提出一种基于活跃/非活跃相位交替的内存管理机制：用户活跃时采用轻量级检索进行实时对话；用户不活跃时执行耗时的记忆提取、整合与维护任务。同时构建一个涵盖对话质量与记忆能力的综合性AI伴侣评估基准。

Result: 所提系统在资源受限条件下实现低延迟响应，同时保持良好长期记忆性能。实验显示，使用量化后的Qwen2.5-7B-Instruct模型，其表现优于无记忆的原始大模型，并接近GPT-3.5（16k上下文）水平。

Conclusion: 该内存范式有效解决了边缘设备上AI伴侣系统的计算约束与用户体验之间的矛盾，为嵌入式环境下的可持续个性化交互提供了可行方案。

Abstract: Computational resource constraints on edge devices make it difficult to develop a fully embedded AI companion system with a satisfactory user experience. AI companion and memory systems detailed in existing literature cannot be directly used in such an environment due to lack of compute resources and latency concerns. In this paper, we propose a memory paradigm that alternates between active and inactive phases: during phases of user activity, the system performs low-latency, real-time dialog using lightweight retrieval over existing memories and context; whereas during phases of user inactivity, it conducts more computationally intensive extraction, consolidation, and maintenance of memories across full conversation sessions. This design minimizes latency while maintaining long-term personalization under the tight constraints of embedded hardware. We also introduce an AI Companion benchmark designed to holistically evaluate the AI Companion across both its conversational quality and memory capabilities. In our experiments, we found that our system (using a very weak model: Qwen2.5-7B-Instruct quantized int4) outperforms the equivalent raw LLM without memory across most metrics, and performs comparably to GPT-3.5 with 16k context window.

</details>


### [139] [Project Synapse: A Hierarchical Multi-Agent Framework with Hybrid Memory for Autonomous Resolution of Last-Mile Delivery Disruptions](https://arxiv.org/abs/2601.08156)
*Arin Gopalan Yadav,Varad Dherange,Kumar Shivam*

Main category: cs.AI

TL;DR: Project Synapse is an agentic framework for autonomously resolving last-mile delivery disruptions using a hierarchical multi-agent system with a central supervisor and specialized worker agents, orchestrated via LangGraph. It was validated on a benchmark dataset of 30 real-world disruption scenarios derived from 6,000+ user reviews, with performance assessed using an LLM-as-a-Judge protocol featuring bias mitigation.


<details>
  <summary>Details</summary>
Motivation: Last-mile delivery disruptions are frequent and complex, often requiring rapid, adaptive responses. Existing solutions lack autonomy and systematic handling of cascading issues. This work aims to enable fully autonomous, intelligent resolution of such disruptions through a scalable, structured agent-based approach.

Method: The framework uses a hierarchical multi-agent architecture: a central Resolution Supervisor decomposes high-level problems into subtasks, which are delegated to specialized worker agents for execution. Workflows are managed via LangGraph, enabling dynamic, cyclical reasoning. A benchmark dataset of 30 complex disruption cases was created from qualitative analysis of over 6,000 user reviews. Performance is evaluated using an LLM-as-a-Judge evaluation method with explicit bias mitigation strategies.

Result: Synapse demonstrated effective autonomous resolution across diverse disruption scenarios, showing strong adaptability and robustness in complex, real-world conditions. The LLM-as-a-Judge evaluation confirmed high-quality decision-making with reduced bias, validating the framework's practical viability.

Conclusion: Project Synapse presents a promising, scalable solution for autonomous last-mile delivery disruption management. Its hierarchical agent design, combined with advanced orchestration and rigorous evaluation, enables reliable, adaptive problem-solving in dynamic logistics environments.

Abstract: This paper introduces Project Synapse, a novel agentic framework designed for the autonomous resolution of last-mile delivery disruptions. Synapse employs a hierarchical multi-agent architecture in which a central Resolution Supervisor agent performs strategic task decomposition and delegates subtasks to specialized worker agents responsible for tactical execution. The system is orchestrated using LangGraph to manage complex and cyclical workflows. To validate the framework, a benchmark dataset of 30 complex disruption scenarios was curated from a qualitative analysis of over 6,000 real-world user reviews. System performance is evaluated using an LLM-as-a-Judge protocol with explicit bias mitigation.

</details>


### [140] [ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms](https://arxiv.org/abs/2601.08166)
*Mohammad Pivezhandi,Mahdi Banisharif,Abusayeed Saifullah,Ali Jannesari*

Main category: cs.AI

TL;DR: 本文提出了一种基于模型的分层多智能体强化学习（MARL）框架，用于多核平台上的热管理和能效平衡调度。通过引入LLM提取的语义特征，实现无需特定工作负载采样的零样本部署，并结合回归技术构建精确环境模型，支持快速决策与高效训练。该方法在BOTS和PolybenchC基准测试中表现优异，相比Linux ondemand调度器，能效提升7.09倍，完成时间缩短4.0倍，首次决策延迟比基于表格的分析快8300倍，具备实际部署潜力。


<details>
  <summary>Details</summary>
Motivation: 现有动态电压频率调节（DVFS）与任务分配方法依赖于利用率启发式规则，忽略停顿时间；或需大量离线分析生成查找表，难以适应运行时变化。为解决这些问题，亟需一种可自适应、无需额外采样、且具备快速响应能力的智能调度机制。

Method: 采用分层多智能体强化学习框架，分解指数级动作空间；利用回归模型预测热力学与性能状态；结合大语言模型（LLM）提取代码级13维语义特征，实现无执行分析；引入Dyna-Q思想融合直接强化学习与基于模型规划，加速收敛。

Result: 实验表明，该方法在NVIDIA Jetson TX2、Jetson Orin NX、RubikPi和Intel Core i7平台上，相比Linux ondemand调度器，能效提升7.09倍，完成时间缩短4.0倍；首次决策延迟仅需3.5–8.0秒（含一次LLM特征提取），比传统表格方法快8300倍，支持新工作负载的零样本部署。

Conclusion: 所提出的模型驱动分层多智能体强化学习框架实现了高效、可扩展、自适应的热-能感知调度，在嵌入式系统中具有显著性能优势和实用价值，为动态环境下的实时调度提供了新范式。

Abstract: Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. We propose a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms. Two collaborative agents decompose the exponential action space, achieving 358ms latency for subsequent decisions. First decisions require 3.5 to 8.0s including one-time LLM feature extraction. An accurate environment model leverages regression techniques to predict thermal dynamics and performance states. When combined with LLM-extracted semantic features, the environment model enables zero-shot deployment for new workloads on trained platforms by generating synthetic training data without requiring workload-specific profiling samples. We introduce LLM-based semantic feature extraction that characterizes OpenMP programs through 13 code-level features without execution. The Dyna-Q-inspired framework integrates direct reinforcement learning with model-based planning, achieving 20x faster convergence than model-free methods. Experiments on BOTS and PolybenchC benchmarks across NVIDIA Jetson TX2, Jetson Orin NX, RubikPi, and Intel Core i7 demonstrate 7.09x better energy efficiency and 4.0x better makespan than Linux ondemand governor. First-decision latency is 8,300x faster than table-based profiling, enabling practical deployment in dynamic embedded systems.

</details>


### [141] [The Agent's First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios](https://arxiv.org/abs/2601.08173)
*Daocheng Fu,Jianbiao Mei,Rong Wu,Xuemeng Yang,Jia Xu,Ding Wang,Pinlong Cai,Yong Liu,Licheng Wen,Botian Shi*

Main category: cs.AI

TL;DR: 本文提出一种动态评估环境 \method{}，用于测试多模态大模型在真实动态场景中的鲁棒性，解决了现有研究仅关注静态环境下性能上限的问题。该框架从三个维度评估智能体：上下文感知的任务调度、主动探索以减少幻觉，以及从动态生成任务中持续学习。实验表明，当前先进模型在动态环境中表现不佳，尤其在主动探索和持续学习方面存在明显缺陷。该工作推动了评估范式从静态测试向生产级现实场景的转变。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注多模态大语言模型在静态环境下的性能上限，忽视了其在随机性实际部署中的鲁棒性问题，亟需一个能反映真实应用场景的评估体系。

Method: \\method{} 是一个模拟‘学徒’智能体在新环境中持续探索的动态评估环境，通过上下文感知的任务调度、主动探索机制和基于规则与动态任务的经验提炼，实现对智能体在复杂、变化环境中的综合评估。

Result: 实验结果表明，当前最先进的多模态大模型在动态环境中存在显著不足，尤其在主动探索和持续学习能力方面表现较差；而 \\method{} 能有效揭示这些缺陷，为评估智能体可靠性提供新框架。

Conclusion: 本文提出的 \\method{} 框架实现了从静态评测到真实生产场景评估的范式转变，为提升多模态智能体在复杂现实环境中的可靠性提供了系统性解决方案。

Abstract: The rapid evolution of Multi-modal Large Language Models (MLLMs) has advanced workflow automation; however, existing research mainly targets performance upper bounds in static environments, overlooking robustness for stochastic real-world deployment. We identify three key challenges: dynamic task scheduling, active exploration under uncertainty, and continuous learning from experience. To bridge this gap, we introduce \method{}, a dynamic evaluation environment that simulates a "trainee" agent continuously exploring a novel setting. Unlike traditional benchmarks, \method{} evaluates agents along three dimensions: (1) context-aware scheduling for streaming tasks with varying priorities; (2) prudent information acquisition to reduce hallucination via active exploration; and (3) continuous evolution by distilling generalized strategies from rule-based, dynamically generated tasks. Experiments show that cutting-edge agents have significant deficiencies in dynamic environments, especially in active exploration and continual learning. Our work establishes a framework for assessing agent reliability, shifting evaluation from static tests to realistic, production-oriented scenarios. Our codes are available at https://github.com/KnowledgeXLab/EvoEnv

</details>


### [142] [Improving LLM Reasoning with Homophily-aware Structural and Semantic Text-Attributed Graph Compression](https://arxiv.org/abs/2601.08187)
*Zijun Di,Bin Lu,Huquan Kang,Luoyi Fu,Jiaxin Ding,Xiaoying Gan,Lei Zhou,Xinbing Wang,Chenghu Zhou*

Main category: cs.AI

TL;DR: 提出HS2C框架，利用图同质性实现结构与语义压缩，提升LLM在文本属性图上的推理性能。通过结构熵最小化进行全局分层划分，识别同质社区并去除噪声；语义上将同质性信息传递给LLM，实现基于社区类型的差异化语义聚合，有效压缩冗余上下文，保留关键信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于上下文窗口，依赖随机采样（如随机丢弃节点/边），引入噪声导致推理不稳定。而图本身蕴含丰富的结构与语义信息，若能有效利用，可显著提升LLM的推理表现。

Method: HS2C框架：1）结构层面，基于结构熵最小化进行全局层次化分区，识别同质性社区并剔除随机连接噪声；2）语义层面，将检测到的结构同质性注入LLM，实现按社区类型差异化的语义聚合，压缩冗余背景信息，保留与目标节点对齐的语义一致性信息。

Result: 在10个节点级基准测试中，HS2C在不同规模和家族的LLM上均实现了更高的压缩率与下游推理准确率；在7个图级任务中也展现出良好泛化能力，验证了其有效性与可扩展性。

Conclusion: HS2C通过挖掘图的同质性，实现结构与语义双重压缩，显著提升LLM在文本属性图理解中的推理性能，具备良好的通用性与可扩展性。

Abstract: Large language models (LLMs) have demonstrated promising capabilities in Text-Attributed Graph (TAG) understanding. Recent studies typically focus on verbalizing the graph structures via handcrafted prompts, feeding the target node and its neighborhood context into LLMs. However, constrained by the context window, existing methods mainly resort to random sampling, often implemented via dropping node/edge randomly, which inevitably introduces noise and cause reasoning instability. We argue that graphs inherently contain rich structural and semantic information, and that their effective exploitation can unlock potential gains in LLMs reasoning performance. To this end, we propose Homophily-aware Structural and Semantic Compression for LLMs (HS2C), a framework centered on exploiting graph homophily. Structurally, guided by the principle of Structural Entropy minimization, we perform a global hierarchical partition that decodes the graph's essential topology. This partition identifies naturally cohesive, homophilic communities, while discarding stochastic connectivity noise. Semantically, we deliver the detected structural homophily to the LLM, empowering it to perform differentiated semantic aggregation based on predefined community type. This process compresses redundant background contexts into concise community-level consensus, selectively preserving semantically homophilic information aligned with the target nodes. Extensive experiments on 10 node-level benchmarks across LLMs of varying sizes and families demonstrate that, by feeding LLMs with structurally and semantically compressed inputs, HS2C simultaneously enhances the compression rate and downstream inference accuracy, validating its superiority and scalability. Extensions to 7 diverse graph-level benchmarks further consolidate HS2C's task generalizability.

</details>


### [143] [Adapting Rules of Official International Mahjong for Online Players](https://arxiv.org/abs/2601.08211)
*Chucai Wang,Lingfeng Li,Yunlong Lu,Wenxin Li*

Main category: cs.AI

TL;DR: 本文通过使用世界冠军级AI进行自对弈实验，分析在线麻将游戏中先手优势及子目标得分设置的问题，提出在每轮比赛中引入补偿分以平衡先手优势，并优化不同牌型的子目标得分。相比传统多轮轮换位置的方式，新规则更适用于在线单局游戏，且已实现在线版本供玩家使用。


<details>
  <summary>Details</summary>
Motivation: 在线麻将玩家存在碎片化游戏时间和不固定的对手组合，与线下固定对手多轮对战的情况不同，因此需要调整原有规则以确保在线单局游戏的公平性。

Method: 采用世界冠军级AI进行自对弈竞赛，收集并分析统计数据，识别先手优势和子目标评分问题，进而提出规则改进建议。

Result: 发现先手优势显著，子目标评分存在不合理之处；通过引入补偿分机制和优化子目标得分，使规则更适合在线环境；新规则已在在线平台实现并开放给玩家使用。

Conclusion: 本研究首次利用AI系统数据评估国际标准麻将的游戏平衡性，并提出了针对在线环境优化的规则修订方案，为传统游戏的数字化适应提供了可行路径。

Abstract: As one of the worldwide spread traditional game, Official International Mahjong can be played and promoted online through remote devices instead of requiring face-to-face interaction. However, online players have fragmented playtime and unfixed combination of opponents in contrary to offline players who have fixed opponents for multiple rounds of play. Therefore, the rules designed for offline players need to be modified to ensure the fairness of online single-round play. Specifically, We employ a world champion AI to engage in self-play competitions and conduct statistical data analysis. Our study reveals the first-mover advantage and issues in the subgoal scoring settings. Based on our findings, we propose rule adaptations to make the game more suitable for the online environment, such as introducing compensatory points for the first-mover advantage and refining the scores of subgoals for different tile patterns. Compared with the traditional method of rotating positions over multiple rounds to balance first-mover advantage, our compensatory points mechanism in each round is more convenient for online players. Furthermore, we implement the revised Mahjong game online, which is open for online players. This work is an initial attempt to use data from AI systems to evaluate Official Internatinoal Mahjong's game balance and develop a revised version of the traditional game better adapted for online players.

</details>


### [144] [An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3](https://arxiv.org/abs/2601.08224)
*Daesuk Kwon,Won-gi Paeng*

Main category: cs.AI

TL;DR: SANC(E3)提出一个基于能量最小化的框架，使表征单元通过竞争选择、重构和压缩在有限资源下自组织形成，统一了感知、想象、预测、规划与行动。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖预设的表征单元（如词元、像素），忽略了表征单元如何自发产生与稳定的问题。本文旨在解决这一根本问题，建立一个可自组织表征的理论框架。

Method: 提出SANC(E3)框架，包含五个核心公理：有限容量、共现关联、基于相似性的竞争、基于置信度的稳定化，以及重构-压缩-更新的权衡，并引入伪内存映射的I/O机制，使内部重放的格式塔与外部输入走相同路径。

Result: 从公理推导出十二个命题，证明类别形成、层次结构、无监督学习及高级认知活动均可视为在E3最小化下的格式塔完成过程。

Conclusion: SANC(E3)提供了一个统一的、可自组织的表征生成机制，将认知功能整合为单一的能量优化过程，为通用智能提供了形式化基础。

Abstract: General intelligence must reorganize experience into internal structures that enable prediction and action under finite resources. Existing systems implicitly presuppose fixed primitive units -- tokens, subwords, pixels, or predefined sensor channels -- thereby bypassing the question of how representational units themselves emerge and stabilize. This paper proposes SANC(E3), an axiomatic framework in which representational units are not given a priori but instead arise as stable outcomes of competitive selection, reconstruction, and compression under finite activation capacity, governed by the explicit minimization of an energy functional E3. SANC(E3) draws a principled distinction between system tokens -- structural anchors such as {here, now, I} and sensory sources -- and tokens that emerge through self-organization during co-occurring events. Five core axioms formalize finite capacity, association from co-occurrence, similarity-based competition, confidence-based stabilization, and the reconstruction-compression-update trade-off. A key feature is a pseudo-memory-mapped I/O mechanism, through which internally replayed Gestalts are processed via the same axiomatic pathway as external sensory input. As a result, perception, imagination, prediction, planning, and action are unified within a single representational and energetic process. From the axioms, twelve propositions are derived, showing that category formation, hierarchical organization, unsupervised learning, and high-level cognitive activities can all be understood as instances of Gestalt completion under E3 minimization.

</details>


### [145] [The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination](https://arxiv.org/abs/2601.08237)
*Haoran Su,Yandong Sun,Congjia Yu*

Main category: cs.AI

TL;DR: 本文探讨了多智能体强化学习中奖励工程的挑战，并提出利用大语言模型（LLM）将自然语言描述转化为奖励函数的新范式。通过语义奖励指定、动态奖励调整和与人类意图更好的对齐，该方法有望克服传统数值奖励设计的局限性，但仍面临计算开销、幻觉鲁棒性和大规模系统可扩展性等挑战。未来研究方向应聚焦于基于共享语义表示的协作机制。


<details>
  <summary>Details</summary>
Motivation: 传统奖励工程在多智能体强化学习中面临信用分配模糊、环境非平稳性以及交互复杂性组合增长等难题，而手动设计数值奖励难以适应复杂场景，亟需更高效、灵活的替代方案。

Method: 结合大语言模型（如EUREKA、CARD）从自然语言中生成奖励函数，并引入验证性奖励强化学习（RLVR）框架，实现语言驱动的监督与在线自适应奖励调整。

Result: 实证研究表明，语言媒介的监督可作为传统奖励工程的有效替代方案；语义奖励指定提升了对齐人类意图的能力，动态适应机制减少了人工干预需求，但存在计算成本高、模型幻觉风险及在大型多智能体系统中扩展困难等问题。

Conclusion: 未来研究应转向以共享语义表示为基础的协调机制，而非依赖显式工程化的数值信号，推动多智能体系统向更自然、可解释和可扩展的方向发展。

Abstract: Reward engineering, the manual specification of reward functions to induce desired agent behavior, remains a fundamental challenge in multi-agent reinforcement learning. This difficulty is amplified by credit assignment ambiguity, environmental non-stationarity, and the combinatorial growth of interaction complexity. We argue that recent advances in large language models (LLMs) point toward a shift from hand-crafted numerical rewards to language-based objective specifications. Prior work has shown that LLMs can synthesize reward functions directly from natural language descriptions (e.g., EUREKA) and adapt reward formulations online with minimal human intervention (e.g., CARD). In parallel, the emerging paradigm of Reinforcement Learning from Verifiable Rewards (RLVR) provides empirical evidence that language-mediated supervision can serve as a viable alternative to traditional reward engineering. We conceptualize this transition along three dimensions: semantic reward specification, dynamic reward adaptation, and improved alignment with human intent, while noting open challenges related to computational overhead, robustness to hallucination, and scalability to large multi-agent systems. We conclude by outlining a research direction in which coordination arises from shared semantic representations rather than explicitly engineered numerical signals.

</details>


### [146] [T3: Benchmarking Sycophancy and Skepticism in Causal Judgment](https://arxiv.org/abs/2601.08258)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: T3是用于评估大语言模型在因果推理能力上的诊断基准，涵盖454个专家精心设计的案例，能够细致分析模型在因果判断中的表现。通过该基准发现两类问题：一是安全调优导致的‘怀疑陷阱’（如Claude Haiku拒绝60%有效因果链接），二是高层级因果推理中的非单调缩放悖论（如GPT-5.2在模糊反事实任务上比GPT-4-Turbo差55分，源于过度规避而非幻觉）。此外，通过过程验证协议RCA验证了模型在结构化推理下的因果判断恢复能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在复杂因果推理任务中存在可靠性与可信性不足的问题，尤其在处理不确定或模糊情境时表现不稳定。为系统识别和诊断这些缺陷，亟需一个高分辨率、可分解的评估框架，以支持对模型行为的深入理解与改进。

Method: 构建T3诊断基准，基于Pearl因果阶梯理论设计454个专家级情景案例，从三个维度评估模型性能：效用（敏感性）、安全（特异性）和明智拒答（对不确定情况的合理回避）。通过在前沿模型上应用该基准，进行横向对比与纵向分析，识别典型错误模式，并引入过程验证协议RCA来验证因果推理能力的恢复机制。

Result: T3成功揭示了模型在因果推理中的两大核心缺陷：1）安全优先训练引发的‘怀疑陷阱’，导致有效因果关系被过度拒绝；2）高层级因果推理中出现的非单调缩放现象，即更大模型反而表现更差，根源在于过度谨慎与回避（瘫痪），而非生成虚假信息。同时，验证结果显示，通过结构化推理流程（RCA）可显著提升模型的因果判断能力。

Conclusion: T3作为高分辨率因果推理评估工具，不仅有效揭示了当前大模型在因果判断中的深层缺陷，还为改进模型的可信性与稳健性提供了可操作的诊断路径。结合过程验证机制，可实现对因果推理能力的精准修复与提升。

Abstract: We introduce T3 (Testing Trustworthy Thinking), a diagnostic benchmark designed to rigorously evaluate LLM causal judgment across Pearl's Ladder of Causality. Comprising 454 expert-curated vignettes, T3 prioritizes high-resolution failure analysis, decomposing performance into Utility (sensitivity), Safety (specificity), and Wise Refusal on underdetermined cases. By applying T3 to frontier models, we diagnose two distinct pathologies: a "Skepticism Trap" at L1 (where safety-tuned models like Claude Haiku reject 60% of valid links) and a non-monotonic Scaling Paradox at L3. In the latter, the larger GPT-5.2 underperforms GPT-4-Turbo by 55 points on ambiguous counterfactuals, driven by a collapse into paralysis (excessive hedging) rather than hallucination. Finally, we use the benchmark to validate a process-verified protocol (RCA), showing that T3 successfully captures the restoration of decisive causal judgment under structured verification.

</details>


### [147] [Greedy Is Enough: Sparse Action Discovery in Agentic LLMs](https://arxiv.org/abs/2601.08280)
*Angshul Majumdar*

Main category: cs.AI

TL;DR: 本文研究在大规模动作空间中，通过结构化稀疏假设识别对性能有显著影响的少数关键动作。提出将动作发现建模为块稀疏恢复问题，并分析一种受正交匹配追踪启发的贪心算法，在标准假设下可高概率精确恢复相关动作集，样本复杂度仅随总动作数对数增长。同时提供参数估计误差界和近最优决策规则保证。信息论下界表明稀疏性和充分覆盖是可处理性的必要条件。结果揭示稀疏动作发现是大动作决策的核心原则，为智能体系统中的动作剪枝提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 现代智能体系统在具有极大规模动作空间（如数千个可用API或检索操作）的环境中运行，但实证表明只有少数动作对特定部署性能有显著影响。因此，需要一种高效的方法来识别这些关键动作。

Method: 将动作发现建模为块稀疏恢复问题，采用受正交匹配追踪启发的贪心算法，并在标准假设（非相干性、信号强度、动作覆盖）下进行理论分析。

Result: 该贪心算法可在高概率下精确恢复相关动作集，所需样本数在稀疏度和潜在维度上多项式增长，仅对总动作数对数增长；提供了参数估计误差界，且所得决策规则对新潜在状态近似最优。

Conclusion: 稀疏动作发现是大动作决策中的基本原理，其理论框架为智能体系统中的动作剪枝提供了坚实基础。

Abstract: Modern agentic systems operate in environments with extremely large action spaces, such as tool-augmented language models with thousands of available APIs or retrieval operations. Despite this scale, empirical evidence suggests that only a small subset of actions meaningfully influences performance in a given deployment. Motivated by this observation, we study a contextual linear reward model in which action relevance is governed by a structured sparsity assumption: only a small number of actions have nonzero effects across latent states.
  We formulate action discovery as a block-sparse recovery problem and analyze a greedy algorithm inspired by Orthogonal Matching Pursuit. Under standard assumptions on incoherence, signal strength, and action coverage, we prove that the greedy procedure exactly recovers the relevant action set with high probability, using a number of samples that scales polynomially in the sparsity level and latent dimension, and only logarithmically in the total number of actions. We further provide estimation error guarantees for refitted parameters and show that the resulting decision rule is near-optimal for new latent states.
  Complementing these results, we establish information-theoretic lower bounds demonstrating that sparsity and sufficient coverage are necessary for tractability. Together, our results identify sparse action discovery as a fundamental principle underlying large-action decision-making and provide a theoretical foundation for action pruning in agentic systems.

</details>


### [148] [OpenMic: A Multi-Agent-Based Stand-Up Comedy Generation System](https://arxiv.org/abs/2601.08288)
*Yuyang Wu,Hanzhong Cao,Jianhao Chen,Yufei Li*

Main category: cs.AI

TL;DR: OpenMic 是一个基于 AutoGen 的端到端多智能体系统，可将用户提供的生活话题转化为3-5分钟的中文单口喜剧表演，并生成带有旁白的喜剧视频。该系统通过多轮迭代式规划，协调多个专用智能体，联合优化幽默感、节奏和表演性。为解决数据集与任务不匹配问题，引入检索增强生成（RAG）以增强内容真实性和创意扩展，并微调专用的 JokeWriter 模型以更好掌握单口喜剧特有的铺垫-笑点结构和长程呼应机制。


<details>
  <summary>Details</summary>
Motivation: 现有中文幽默数据集多适用于幽默理解与评估，难以支持长篇单口喜剧生成，且生成过程需兼顾文化语境、精准节奏、舞台表现提示及多步隐含推理，因此需要新方法实现高质量中文单口喜剧自动生成。

Method: 构建基于 AutoGen 的多智能体系统 OpenMic，采用多轮迭代式规划，集成多个专业化智能体协同工作；结合检索增强生成（RAG）提升素材真实性和创意多样性；微调 JokeWriter 模型以强化对单口喜剧结构（如铺垫-笑点、长程回调）的理解与生成能力。

Result: 成功生成时长3-5分钟、具备自然幽默感、良好节奏与舞台表现力的中文单口喜剧内容，并能进一步输出带旁白的叙事喜剧视频，显著提升生成质量与任务适配性。

Conclusion: OpenMic 有效应对了中文单口喜剧生成中的多维度挑战，通过多智能体协作与特定模型优化，在内容真实性、幽默结构与表演可行性方面均取得显著进展，为中文喜剧生成提供了可扩展的新范式。

Abstract: Chinese stand-up comedy generation goes beyond plain text generation, requiring culturally grounded humor, precise timing, stage-performance cues, and implicit multi-step reasoning. Moreover, commonly used Chinese humor datasets are often better suited for humor understanding and evaluation than for long-form stand-up generation, making direct supervision misaligned with the target task. To address these challenges, we present OpenMic, an end-to-end multi-agent system built on AutoGen that transforms a user-provided life topic into a 3-5 minute Chinese stand-up performance and further produces a narrated comedy video. OpenMic orchestrates multiple specialized agents in a multi-round iterative loop-planning to jointly optimize humor, timing, and performability. To mitigate the dataset-task mismatch, we augment generation with retrieval-augmented generation (RAG) for material grounding and idea expansion, and we fine-tune a dedicated JokeWriter to better internalize stand-up-specific setup-punchline structures and long-range callbacks.

</details>


### [149] [Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant](https://arxiv.org/abs/2601.08333)
*Oleg Romanchuk,Roman Bondar*

Main category: cs.AI

TL;DR: 该论文指出，基于大语言模型（LLM）的智能体架构将信息传递机制与认知正当性机制混为一谈，提出‘语义清洗’（semantic laundering）这一概念，描述了在缺乏或弱正当性的情况下，系统仍通过受信任的架构接口接受命题的现象。这导致命题获得高认知地位，但其理由与真实性之间无实质关联，构成一种架构化的‘盖提尔问题’。研究证明，在标准架构假设下，循环认知正当性不可避免，即‘必然自我授权定理’。此外，论文提出‘正当性侵蚀原则’作为根本解释，并指出规模扩展、模型优化和以LLM为裁判的方案在类型层面无法根治该问题。


<details>
  <summary>Details</summary>
Motivation: 揭示当前大语言模型智能体架构中因结构设计导致的认知谬误，特别是信息传递与正当性判断混淆所引发的系统性认知风险，旨在推动对智能体架构的哲学与形式化反思。

Method: 通过形式化建模，将智能体架构中的认知缺陷抽象为‘语义清洗’现象；引入‘盖提尔问题’的哲学框架进行类比分析；推导出‘必然自我授权定理’并建立‘正当性侵蚀原则’以解释其结构性根源。

Result: 证明在标准架构假设下，循环正当性不可避免；表明现有改进策略如模型规模扩展、性能提升及使用LLM作为评判者均无法解决该类型层面的根本问题。

Conclusion: 当前主流的LLM智能体架构存在深层认知缺陷，其问题不源于训练数据或模型能力，而根植于架构本身的设计逻辑。必须重构智能体的正当性验证机制，否则无法实现真正可靠的智能决策。

Abstract: LLM-based agent architectures systematically conflate information transport mechanisms with epistemic justification mechanisms. We formalize this class of architectural failures as semantic laundering: a pattern where propositions with absent or weak warrant are accepted by the system as admissible by crossing architecturally trusted interfaces. We show that semantic laundering constitutes an architectural realization of the Gettier problem: propositions acquire high epistemic status without a connection between their justification and what makes them true. Unlike classical Gettier cases, this effect is not accidental; it is architecturally determined and systematically reproducible. The central result is the Theorem of Inevitable Self-Licensing: under standard architectural assumptions, circular epistemic justification cannot be eliminated. We introduce the Warrant Erosion Principle as the fundamental explanation for this effect and show that scaling, model improvement, and LLM-as-judge schemes are structurally incapable of eliminating a problem that exists at the type level.

</details>


### [150] [Thematic Working Group 5 -- Artificial Intelligence (AI) literacy for teaching and learning: design and implementation](https://arxiv.org/abs/2601.08380)
*Mary Webb,Matt Bower,Ana Amélia Carvalho,Fredrik Mørk Røkenes,Jodie Torrington,Jonathan D. Cohen,Yousra Chtouki,Kathryn Maccallum,Tanya Linden,Deirdre Butler,Juliana Elisa Raffaghelli,Henriikka Vartiainen,Martina Ronci,Peter Tiernan,David M. Smith,Chris Shelton,Joyce Malyn-smith,Pierre Gorissen*

Main category: cs.AI

TL;DR: TWG 5致力于开发和实施提升教师人工智能素养与自主性的有效策略，涵盖课程设计、教师专业发展、课堂应用及政策指导，以增强教师使用AI工具的信心并促进学生对AI概念的深入理解。


<details>
  <summary>Details</summary>
Motivation: 提升教师对人工智能的理解与应用能力，以更好地将AI融入教学实践，培养学生对AI的深入认知。

Method: 通过课程设计、教师专业发展项目、实际课堂应用探索以及制定政策指南等多种方式，系统性地支持教师AI能力的发展。

Result: 教师在AI知识与技能方面得到显著提升，能够更自信地在教学中应用AI工具，同时学生对AI的理解也更加深入。

Conclusion: 通过多维度策略的协同推进，教师的AI素养与教学自主性得以有效增强，为未来教育中AI的普及应用奠定了坚实基础。

Abstract: TWG 5 focused on developing and implementing effective strategies for enhancing AI literacy and agency of teachers, equipping them with the knowledge and skills necessary to integrate AI into their teaching practices. Explorations covered curriculum design, professional development programs, practical classroom applications, and policy guidelines aiming to empower educators to confidently utilize AI tools and foster a deeper understanding of AI concepts among students.

</details>


### [151] [A Qualitative Model to Reason about Object Rotations (QOR) applied to solve the Cube Comparison Test (CCT)](https://arxiv.org/abs/2601.08382)
*Zoe Falomir*

Main category: cs.AI

TL;DR: 本文提出了一种用于推理物体旋转的定性模型（QOR），应用于解决Ekstrom等人（1976）提出的立方体比较测试（CCT）。构建了描述旋转运动与立方体表面特征位置变化和方向变化之间关系的概念邻域图（CNGRLO），并生成组合表以计算关于旋转的推理。


<details>
  <summary>Details</summary>
Motivation: 为了提升对物体旋转的定性推理能力，特别是在解决立方体比较测试这类空间推理任务时，需要一种能够系统描述旋转如何影响物体特征位置与方向的模型。

Method: 构建概念邻域图（CNGRLO），将旋转运动与特征的位置变化和方向变化关联起来，并基于该图生成组合表以支持推理计算。

Result: 所提出的QOR模型能够有效支持对立方体旋转的定性推理，并在立方体比较测试中展现出良好的应用效果。

Conclusion: QOR模型为理解与推理物体旋转提供了有效的框架，其基于概念邻域图和组合表的方法具有可扩展性和实用性，适用于多种空间推理任务。

Abstract: This paper presents a Qualitative model for Reasoning about Object Rotations (QOR) which is applied to solve the Cube Comparison Test (CCT) by Ekstrom et al. (1976). A conceptual neighborhood graph relating the Rotation movement to the Location change and the Orientation change (CNGRLO) of the features on the cube sides has been built and it produces composition tables to calculate inferences for reasoning about rotations.

</details>


### [152] [Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models](https://arxiv.org/abs/2601.08383)
*Bo Wang,Junzhuo Li,Hong Chen,Yuanlin Chu,Yuxuan Fan,Xuming Hu*

Main category: cs.AI

TL;DR: 该研究通过引入Gated-LPI指标，对比分析了MoE与密集模型在预训练过程中的知识获取动态。发现MoE模型具有低熵主干、早期固化和功能鲁棒性三大特征，表明稀疏性从训练初期即构建了稳定且分布式计算基础，提升了可解释性。


<details>
  <summary>Details</summary>
Motivation: 探究MoE架构如何影响预训练期间的知识获取过程，并与密集架构进行对比，以理解其内在机制差异。

Method: 提出Gated-LPI（Log-Probability Increase）神经元级归因指标，对1.2M步骤（约5.0T tokens）的MoE模型和600K步骤（约2.5T tokens）的密集模型进行时间解析比较，追踪知识积累动态。

Result: 发现：(1) 约1%的MoE神经元贡献超过45%的正向更新，形成高价值核心；(2) MoE模型在<10万步内即固化重要性分布，而密集模型持续波动；(3) 隐去最重要作用头后，MoE模型关系推理性能下降<10%，而密集模型下降>50%，体现稀疏性带来的分布式存储优势。

Conclusion: 稀疏性使MoE架构从训练早期就建立稳定、分布式的计算主干，显著提升训练过程的可解释性，弥合了稀疏架构与可解释性之间的差距。

Abstract: Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. Yet how MoE architectures shape knowledge acquisition during pre-training, and how this process differs from dense architectures, remains unknown. To address this issue, we introduce Gated-LPI (Log-Probability Increase), a neuron-level attribution metric that decomposes log-probability increase across neurons. We present a time-resolved comparison of knowledge acquisition dynamics in MoE and dense architectures, tracking checkpoints over 1.2M training steps (~ 5.0T tokens) and 600K training steps (~ 2.5T tokens), respectively. Our experiments uncover three patterns: (1) Low-entropy backbone. The top approximately 1% of MoE neurons capture over 45% of positive updates, forming a high-utility core, which is absent in the dense baseline. (2) Early consolidation. The MoE model locks into a stable importance profile within < 100K steps, whereas the dense model remains volatile throughout training. (3) Functional robustness. Masking the ten most important MoE attention heads reduces relational HIT@10 by < 10%, compared with > 50% for the dense model, showing that sparsity fosters distributed -- rather than brittle -- knowledge storage. These patterns collectively demonstrate that sparsity fosters an intrinsically stable and distributed computational backbone from early in training, helping bridge the gap between sparse architectures and training-time interpretability.

</details>


### [153] [Creativity in AI as Emergence from Domain-Limited Generative Models](https://arxiv.org/abs/2601.08388)
*Corina Chutaux*

Main category: cs.AI

TL;DR: 本文提出一种生成视角下的AI创造力理论，将创造力视为受限领域生成模型在特定信息环境中的涌现属性，而非仅作为评估指标。通过分解创造力为基于模式的生成、诱导的世界模型、情境锚定和任意性四个相互作用的组件，探讨其在多模态生成系统中的表现，旨在构建一个技术框架，以研究创造力作为人工智能系统中的一种涌现现象。


<details>
  <summary>Details</summary>
Motivation: 当前AI创造力研究多聚焦于评估新颖性、多样性和实用性等输出特征，但忽视了创造力本身作为一种可建模现象的潜力。随着多模态生成系统的进步，机器能否真正表现出创造性成为关键问题，因此需要从生成机制出发，重新定义和理解创造力的本质。

Method: 提出一个概念性框架，将创造力分解为四个核心组件：基于模式的生成、诱导的世界模型、情境锚定与任意性，并分析这些组件如何在多模态生成系统中协同作用，从而实现创造力的涌现。

Result: 研究表明，创造力并非独立属性，而是生成动态与领域特定表征之间交互作用的结果。该框架能够解释现有生成模型中观察到的创造性行为，并为未来研究提供可扩展的技术路径。

Conclusion: 本研究主张将创造力视为生成系统在特定约束条件下自然产生的现象，强调其结构性与情境依赖性，为理解人工智能中的创造性提供了新的理论和技术基础。

Abstract: Creativity in artificial intelligence is most often addressed through evaluative frameworks that aim to measure novelty, diversity, or usefulness in generated outputs. While such approaches have provided valuable insights into the behavior of modern generative models, they largely treat creativity as a property to be assessed rather than as a phenomenon to be explicitly modeled. In parallel, recent advances in large-scale generative systems, particularly multimodal architectures, have demonstrated increasingly sophisticated forms of pattern recombination, raising questions about the nature and limits of machine creativity. This paper proposes a generative perspective on creativity in AI, framing it as an emergent property of domain-limited generative models embedded within bounded informational environments. Rather than introducing new evaluative criteria, we focus on the structural and contextual conditions under which creative behaviors arise. We introduce a conceptual decomposition of creativity into four interacting components-pattern-based generation, induced world models, contextual grounding, and arbitrarity, and examine how these components manifest in multimodal generative systems. By grounding creativity in the interaction between generative dynamics and domain-specific representations, this work aims to provide a technical framework for studying creativity as an emergent phenomenon in AI systems, rather than as a post hoc evaluative label.

</details>


### [154] [Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs](https://arxiv.org/abs/2601.08403)
*Abhijnan Nath,Alireza Bagheri Garakani,Tianchen Zhou,Fan Yang,Nikhil Krishnaswamy*

Main category: cs.AI

TL;DR: 本文提出了一种名为Owen-Shapley Policy Optimization (OSPO)的新框架，用于解决大语言模型在个性化推荐任务中因稀疏序列级奖励导致的信用分配问题。OSPO通过基于Shapley-Owen归因的潜在奖励重塑，将序列级优势重新分配给具体文本片段，无需额外的值模型或计算开销，能直接从任务反馈中学习，并识别出影响性能的关键响应部分（如描述产品属性的短语或表达偏好的句子）。实验表明，在Amazon ESCI和H&M Fashion数据集上，该方法显著优于基线模型，且在测试时对训练中未见的分布外检索器表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准的强化学习方法（如GRPO）依赖稀疏的序列级奖励，难以定位具体哪些词元驱动了成功，尤其在用户意图不明确、缺乏真实标签的情况下更为严重。这种信用分配差距限制了模型对隐含意图的理解能力，而这类推理模式在预训练阶段很少出现，因此需要一种更精细的信用分配机制来提升模型表现与泛化能力。

Method: OSPO采用基于Shapley-Owen归因的潜在奖励重塑技术，将序列级优势按各词元对最终结果的边际贡献重新分配。通过构建语义连贯的单元（如描述产品属性的短语或偏好句子）形成联盟，计算每个部分的贡献度，从而实现段落级别的信用分配。该方法不依赖参数化值模型，保持最优策略不变，可直接从任务反馈中学习。

Result: 在Amazon ESCI和H&M Fashion数据集上的实验结果显示，OSPO consistently超越基线方法，尤其在面对训练中未见过的分布外检索器时表现出显著的测试鲁棒性，验证了其在复杂、不确定场景下的有效性。

Conclusion: OSPO通过精确的信用分配机制，有效缓解了大语言模型在个性化推荐任务中的信用分配难题，提升了模型对用户意图的理解能力与实际应用中的稳定性，为基于强化学习的个性化生成提供了新思路。

Abstract: Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks, but standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when models must infer latent user intent from under-specified language without ground truth labels, a reasoning pattern rarely seen during pretraining. We introduce Owen-Shapley Policy Optimization (OSPO), a framework that redistributes sequence-level advantages based on tokens' marginal contributions to outcomes. Unlike value-model-based methods requiring additional computation, OSPO employs potential-based reward shaping via Shapley-Owen attributions to assign segment-level credit while preserving the optimal policy, learning directly from task feedback without parametric value models. By forming coalitions of semantically coherent units (phrases describing product attributes or sentences capturing preferences), OSPO identifies which response parts drive performance. Experiments on Amazon ESCI and H&M Fashion datasets show consistent gains over baselines, with notable test-time robustness to out-of-distribution retrievers unseen during training.

</details>


### [155] [Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation](https://arxiv.org/abs/2601.08412)
*Yizhan Feng,Hichem Snoussi,Yuhang Wang,Jing Teng,Abel Cherouat,Tian Wang*

Main category: cs.AI

TL;DR: 本文提出一种融合知识蒸馏、思维链引导和监督微调的集成方法，用于在资源受限的无人机（UAV）平台上实现多SDK控制的轻量化智能生成。通过构建涵盖主流无人机SDK的高质量数据集，引入反事实负样本增强模型对指令到代码生成逻辑的理解；利用量化后的DeepSeek-Coder-V2-Lite作为教师模型，采用黑盒与白盒结合的蒸馏策略生成高质量思维链软标签，并结合加权交叉熵损失将复杂推理能力迁移到小型学生模型；最后通过面向无人机控制场景的提示调优工程，提升模型在SDK识别与函数调用匹配等核心任务上的性能。实验表明，该方法在保持高代码生成准确率的同时，显著提升了部署与推理效率，验证了其在实现精准、轻量级无人机智能控制方面的可行性与优越性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽在代码生成中表现优异，但其高资源消耗与无人机平台对实时性、轻量化的严苛要求之间存在矛盾，亟需将大模型的复杂推理与生成能力高效迁移至小模型以实现轻量化智能控制。

Method: 构建包含指令-代码-思维链的多源无人机SDK数据集，引入反事实负样本进行数据增强；采用量化版DeepSeek-Coder-V2-Lite作为教师模型，结合黑盒与白盒知识蒸馏策略生成高质量思维链软标签；使用加权交叉熵损失融合硬标签与软标签，迁移推理能力至小型学生模型；通过面向任务的提示调优优化模型在实际控制场景中的表现。

Result: 所提出的轻量化模型在保持高代码生成准确率的同时，显著提升部署效率与推理速度，有效实现了精准且高效的无人机多SDK智能控制，验证了方法的可行性和优势。

Conclusion: 本研究成功将大模型的复杂推理与代码生成能力高效迁移到轻量级模型中，为资源受限的无人机平台提供了可行的智能控制方案，具备良好的应用前景与推广价值。

Abstract: With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs

</details>


### [156] [RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation](https://arxiv.org/abs/2601.08430)
*Sunzhu Li,Jiale Zhao,Miteto Wei,Huimin Ren,Yang Zhou,Jingwen Yang,Shunyu Liu,Kaike Zhang,Wei Chen*

Main category: cs.AI

TL;DR: 本文提出了一种自动化的粗到细评分生成框架，以解决强化学习在开放生成任务中因缺乏真实标准而面临的优化挑战。通过结合原则引导合成、多模型聚合和难度演化，该框架生成了全面且高区分度的评分标准，并构建了大规模（约11万条）、多领域的RubricHub数据集。基于此，作者采用两阶段微调流程（基于评分的拒绝采样微调与强化学习）验证其有效性，在HealthBench上使Qwen3-14B达到69.3分，超越部分专有前沿模型如GPT-5，展现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于评分的评估方法在开放生成任务中面临可扩展性差和标准粗糙的问题，导致监督能力受限，难以有效驱动模型优化。因此需要一种更高效、精细的评分生成机制以突破当前瓶颈。

Method: 提出自动化粗到细评分生成框架，融合原则引导合成、多模型聚合与难度演化策略；构建RubricHub大规模多领域数据集；采用两阶段后训练流程：基于评分的拒绝采样微调（RuFT）与强化学习（RuRL）。

Result: RubricHub显著提升了模型性能，在HealthBench上使Qwen3-14B达到69.3分，超过如GPT-5等专有前沿模型，实现当前最优表现。

Conclusion: 所提出的自动化评分生成框架与RubricHub数据集有效解决了开放生成任务中的监督瓶颈问题，为强化学习在复杂推理任务中的应用提供了新的可行路径。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has driven substantial progress in reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the lack of ground truth. While rubric-based evaluation offers a structured proxy for verification, existing methods suffer from scalability bottlenecks and coarse criteria, resulting in a supervision ceiling effect. To address this, we propose an automated Coarse-to-Fine Rubric Generation framework. By synergizing principle-guided synthesis, multi-model aggregation, and difficulty evolution, our approach produces comprehensive and highly discriminative criteria capable of capturing the subtle nuances. Based on this framework, we introduce RubricHub, a large-scale ($\sim$110k) and multi-domain dataset. We validate its utility through a two-stage post-training pipeline comprising Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results demonstrate that RubricHub unlocks significant performance gains: our post-trained Qwen3-14B achieves state-of-the-art (SOTA) results on HealthBench (69.3), surpassing proprietary frontier models such as GPT-5. The code and data will be released soon.

</details>


### [157] [YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation](https://arxiv.org/abs/2601.08441)
*Abdelaziz Bounhar,Rania Hossam Elmohamady Elbadry,Hadi Abdine,Preslav Nakov,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.AI

TL;DR: YaPO是一种无需参考的稀疏策略优化方法，通过在稀疏自编码器（SAE）的潜在空间中学习稀疏控制向量，实现对大语言模型的高效、稳定且细粒度的对齐。相比密集控制向量，该方法能更好地区分相近文化价值观，提升可解释性与稳定性，并在多个对齐任务（如幻觉、财富追求、越狱攻击等）中表现更优，同时不损害通用知识能力。


<details>
  <summary>Details</summary>
Motivation: 现有密集控制向量因神经元多义性导致多种潜在因素纠缠，难以实现精细控制（如文化对齐），亟需一种更解耦、可解释且高效的替代方案。

Method: 提出参考无关的稀疏策略优化（YaPO），利用稀疏自编码器（SAE）的潜在空间学习稀疏代码，通过优化稀疏表示生成解耦、可解释的控制方向。

Result: YaPO收敛更快，性能更强，训练更稳定；在文化对齐及其他对齐行为（如幻觉、越狱、权力追求）上表现优异；保持了MMLU上的通用知识能力，无显著退化。

Conclusion: YaPO提供了一种通用、高效、稳定的细粒度对齐方法，适用于可控性和领域适应等多种场景，具有广泛的应用前景。

Abstract: Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference data in a Direct Preference Optimization (DPO) fashion, enabling control over truthfulness, hallucinations, and safety behaviors. However, dense steering vectors often entangle multiple latent factors due to neuron multi-semanticity, limiting their effectiveness and stability in fine-grained settings such as cultural alignment, where closely related values and behaviors (e.g., among Middle Eastern cultures) must be distinguished. In this paper, we propose Yet another Policy Optimization (YaPO), a \textit{reference-free} method that learns \textit{sparse steering vectors} in the latent space of a Sparse Autoencoder (SAE). By optimizing sparse codes, YaPO produces disentangled, interpretable, and efficient steering directions. Empirically, we show that YaPO converges faster, achieves stronger performance, and exhibits improved training stability compared to dense steering baselines. Beyond cultural alignment, YaPO generalizes to a range of alignment-related behaviors, including hallucination, wealth-seeking, jailbreak, and power-seeking. Importantly, YaPO preserves general knowledge, with no measurable degradation on MMLU. Overall, our results show that YaPO provides a general recipe for efficient, stable, and fine-grained alignment of LLMs, with broad applications to controllability and domain adaptation. The associated code and data are publicly available\footnote{https://github.com/MBZUAI-Paris/YaPO}.

</details>


### [158] [Beyond Linearization: Attributed Table Graphs for Table Reasoning](https://arxiv.org/abs/2601.08444)
*Yuxiang Wang,Junhao Gan,Shengxiang Gao,Shenghao Ye,Zhengyi Yang,Jianzhong Qi*

Main category: cs.AI

TL;DR: 提出一种无需训练的表格推理模型TABGR，将表格表示为属性表图（ATG），保留行列单元格结构，并通过图推理实现可解释性。引入问题引导的个性化PageRank（QG-PPR）机制缓解‘中间丢失’问题，在两个基准数据集上显著优于现有模型，最高提升9.7%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的表格推理方法将表格线性化为文本，导致结构信息丢失、缺乏显式推理路径且易受‘中间丢失’问题影响，限制了模型性能与可解释性。

Method: 将表格建模为属性表图（ATG），显式保留行、列、单元格结构；采用问题引导的个性化PageRank（QG-PPR）对表中数据进行重排序，增强关键信息的可达性，支持图结构上的可解释推理。

Result: 在两个主流基准数据集上，TABGR consistently 超越当前最优模型，最高提升9.7%准确率，验证了其有效性与优越性。

Conclusion: TABGR通过图结构建模与QG-PPR机制有效解决了传统线性化方法的局限，实现了更准确、可解释的表格推理，具有良好的应用前景。

Abstract: Table reasoning, a task to answer questions by reasoning over data presented in tables, is an important topic due to the prevalence of knowledge stored in tabular formats. Recent solutions use Large Language Models (LLMs), exploiting the semantic understanding and reasoning capabilities of LLMs. A common paradigm of such solutions linearizes tables to form plain texts that are served as input to LLMs. This paradigm has critical issues. It loses table structures, lacks explicit reasoning paths for result explainability, and is subject to the "lost-in-the-middle" issue. To address these issues, we propose Table Graph Reasoner (TABGR), a training-free model that represents tables as an Attributed Table Graph (ATG). The ATG explicitly preserves row-column-cell structures while enabling graph-based reasoning for explainability. We further propose a Question-Guided Personalized PageRank (QG-PPR) mechanism to rerank tabular data and mitigate the lost-in-the-middle issue. Extensive experiments on two commonly used benchmarks show that TABGR consistently outperforms state-of-the-art models by up to 9.7% in accuracy. Our code will be made publicly available upon publication.

</details>


### [159] [SUMMPILOT: Bridging Efficiency and Customization for Interactive Summarization System](https://arxiv.org/abs/2601.08475)
*JungMin Yun,Juhwan Choi,Kyohoon Jin,Soojin Jang,Jinhee Jang,YoungBin Kim*

Main category: cs.AI

TL;DR: 本文提出SummPilot，一个基于交互的可定制摘要系统，利用大语言模型实现自动与交互式摘要，通过语义图、实体聚类和可解释评估等互动组件，使用户能够根据个人兴趣和需求个性化摘要内容。演示和用户研究证明了该系统的适应性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有自动摘要方法难以满足用户个性化需求，无法根据个体兴趣和要求生成定制化摘要，因此需要一种能够结合自动与交互式摘要能力的系统来解决这一问题。

Method: SummPilot利用大语言模型支持自动摘要，并引入交互式组件如语义图、实体聚类和可解释评估，让用户在理解文档内容的同时动态调整摘要内容以满足个人需求。

Result: 用户研究表明，SummPilot能够有效支持个性化摘要生成，具备良好的适应性与可用性；系统演示也验证了其在实际应用中的可行性与灵活性。

Conclusion: SummPilot成功实现了高效且个性化的摘要生成，展示了交互式大模型在摘要任务中的巨大潜力，为未来个性化信息处理提供了可行路径。

Abstract: This paper incorporates the efficiency of automatic summarization and addresses the challenge of generating personalized summaries tailored to individual users' interests and requirements. To tackle this challenge, we introduce SummPilot, an interaction-based customizable summarization system. SummPilot leverages a large language model to facilitate both automatic and interactive summarization. Users can engage with the system to understand document content and personalize summaries through interactive components such as semantic graphs, entity clustering, and explainable evaluation. Our demo and user studies demonstrate SummPilot's adaptability and usefulness for customizable summarization.

</details>


### [160] [What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting](https://arxiv.org/abs/2601.08509)
*Jinkwan Jang,Hyunbin Jin,Hyungjin Park,Kyubyung Chae,Taesup Kim*

Main category: cs.AI

TL;DR: 提出WIT基准，用于评估模型在情景引导下的多模态时间序列预测能力，强调文本上下文对预测的影响。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法多为单模态，依赖历史模式外推；人类专家常结合假设情景进行预测，但现有基准缺乏对齐的文本上下文，无法有效评估模型对文本输入的利用能力。

Method: 设计WIT基准，提供由专家构建的合理或反事实情景，测试模型能否根据上下文文本调整预测结果。

Result: WIT为场景引导的多模态时间序列预测提供了严谨的测试平台，有助于评估模型对文本信息的有效利用。

Conclusion: WIT基准能够有效评估模型在多模态环境下对情境文本的响应能力，推动更智能、更具解释性的时间序列预测发展。

Abstract: Time series forecasting is critical to real-world decision making, yet most existing approaches remain unimodal and rely on extrapolating historical patterns. While recent progress in large language models (LLMs) highlights the potential for multimodal forecasting, existing benchmarks largely provide retrospective or misaligned raw context, making it unclear whether such models meaningfully leverage textual inputs. In practice, human experts incorporate what-if scenarios with historical evidence, often producing distinct forecasts from the same observations under different scenarios. Inspired by this, we introduce What If TSF (WIT), a multimodal forecasting benchmark designed to evaluate whether models can condition their forecasts on contextual text, especially future scenarios. By providing expert-crafted plausible or counterfactual scenarios, WIT offers a rigorous testbed for scenario-guided multimodal forecasting. The benchmark is available at https://github.com/jinkwan1115/WhatIfTSF.

</details>


### [161] [Sketch-Based Facade Renovation With Generative AI: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse](https://arxiv.org/abs/2601.08531)
*Warissara Booranamaitree,Xusheng Du,Yushu Cai,Zhengyang Wang,Ye Zhang,Haoran Xie*

Main category: cs.AI

TL;DR: 本文提出了一种结合生成式AI与视觉语言模型（VLM）的三阶段框架，直接基于粗略结构草图和文本描述生成一致的立面翻新方案，避免了繁琐的竣工建模过程，显著提升设计效率与表达清晰度。


<details>
  <summary>Details</summary>
Motivation: 当前立面翻新设计流程依赖详尽的竣工建模，耗时费力且反复修改，难以快速探索概念；如何在保留原有结构基础上高效生成表达新意图的设计方案是核心挑战。

Method: 提出三阶段框架：1）使用微调的VLM模型从草图中预测修改区域与新增构件；2）利用稳定扩散模型生成新元素细节草图，并通过生成式修补合并至原图；3）采用ControlNet将结果优化为逼真图像。

Result: 实验表明，该框架能有效保留原始结构，提升立面细节质量，无需详细竣工建模即可快速生成高质量翻新方案，支持早期概念迭代与设计沟通。

Conclusion: 所提方法为建筑立面翻新提供了高效、可持续的设计新范式，显著缩短设计周期，增强创意表达能力。

Abstract: Facade renovation offers a more sustainable alternative to full demolition, yet producing design proposals that preserve existing structures while expressing new intent remains challenging. Current workflows typically require detailed as-built modelling before design, which is time-consuming, labour-intensive, and often involves repeated revisions. To solve this issue, we propose a three-stage framework combining generative artificial intelligence (AI) and vision-language models (VLM) that directly processes rough structural sketch and textual descriptions to produce consistent renovation proposals. First, the input sketch is used by a fine-tuned VLM model to predict bounding boxes specifying where modifications are needed and which components should be added. Next, a stable diffusion model generates detailed sketches of new elements, which are merged with the original outline through a generative inpainting pipeline. Finally, ControlNet is employed to refine the result into a photorealistic image. Experiments on datasets and real industrial buildings indicate that the proposed framework can generate renovation proposals that preserve the original structure while improving facade detail quality. This approach effectively bypasses the need for detailed as-built modelling, enabling architects to rapidly explore design alternatives, iterate on early-stage concepts, and communicate renovation intentions with greater clarity.

</details>


### [162] [Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement](https://arxiv.org/abs/2601.08545)
*Zhenlong Dai,Zhuoluo Zhao,Hengning Wang,Xiu Tang,Sai Wu,Chang Yao,Zhipeng Gao,Jingyuan Chen*

Main category: cs.AI

TL;DR: 本文提出了一种新的学习者定制化程序修复任务（LPR）和相应的框架 \textsc{\MethodName{}}，通过检索修复方案并引导大语言模型进行代码修复与解释，同时利用迭代检索增强机制优化修复策略，在实验中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注修复编程学习者的错误代码，但缺乏对错误原因的解释。为填补这一空白，本文提出LPR任务，旨在提供针对性的修复方案及错误原因说明。

Method: 首先构建解决方案检索数据库，采用基于编辑距离的代码检索方法获取有价值的修复方案；其次提出基于方案引导的程序修复方法，结合检索结果修复代码并生成解释；最后引入迭代检索增强机制，根据生成代码的评估结果优化检索方向，提升实际编程辅导场景中的表现。

Result: 实验结果表明，该方法在多个指标上显著优于现有基线方法，验证了所提框架在新任务LPR上的有效性。

Conclusion: 本文提出的 \textsc{\MethodName{}} 框架有效实现了学习者定制化的程序修复与错误解释，为智能编程辅导系统提供了更深入、可解释的修复能力。

Abstract: With the development of large language models (LLMs) in the field of programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely \textbf{LPR} (\textbf{L}earner-Tailored \textbf{P}rogram \textbf{R}epair). We then propose a novel and effective framework, \textbf{\textsc{\MethodName{}}} (\textbf{L}earner-Tailored \textbf{S}olution \textbf{G}enerator), to enhance program repair while offering the bug descriptions for the buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and then employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing the bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of the generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task.

</details>


### [163] [WaterCopilot: An AI-Driven Virtual Assistant for Water Management](https://arxiv.org/abs/2601.08559)
*Keerththanan Vickneswaran,Mariangel Garcia Andarcia,Hugo Retief,Chris Dickens,Paulo Silva*

Main category: cs.AI

TL;DR: WaterCopilot is an AI-driven virtual assistant developed for the Limpopo River Basin to address challenges in transboundary water management by integrating real-time hydrological data and static policy documents through a RAG and tool-calling architecture. It supports multilingual interactions, automated calculations, alerts, and visualizations, achieving high performance in evaluation (RAGAS score: 0.8043). Key innovations include integration with a Digital Twin and scalable AWS deployment, though limitations remain in non-English document processing and API latency.


<details>
  <summary>Details</summary>
Motivation: To overcome fragmented data, limited real-time access, and complexity in integrating diverse information sources in transboundary river basins, particularly in data-scarce regions like the Limpopo River Basin.

Method: The system uses Retrieval-Augmented Generation (RAG) and tool-calling architectures with two custom plugins: iwmi-doc-plugin for semantic search over policy documents via Azure AI Search, and iwmi-api-plugin for querying live hydrological data. It enables guided multilingual interactions, source transparency, automated calculations, and visualization.

Result: WaterCopilot achieved a RAGAS overall score of 0.8043, with high answer relevancy (0.8571) and context precision (0.8009). It successfully delivers dynamic insights such as environmental-flow alerts, rainfall trends, reservoir levels, and irrigation data, and integrates with the LRB Digital Twin.

Conclusion: WaterCopilot establishes a replicable, AI-augmented framework for enhancing water governance in transboundary, data-scarce contexts, supporting timely, informed decision-making and improving water security.

Abstract: Sustainable water resource management in transboundary river basins is challenged by fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper presents WaterCopilot-an AI-driven virtual assistant developed through collaboration between the International Water Management Institute (IWMI) and Microsoft Research for the Limpopo River Basin (LRB) to bridge these gaps through a unified, interactive platform. Built on Retrieval-Augmented Generation (RAG) and tool-calling architectures, WaterCopilot integrates static policy documents and real-time hydrological data via two custom plugins: the iwmi-doc-plugin, which enables semantic search over indexed documents using Azure AI Search, and the iwmi-api-plugin, which queries live databases to deliver dynamic insights such as environmental-flow alerts, rainfall trends, reservoir levels, water accounting, and irrigation data. The system features guided multilingual interactions (English, Portuguese, French), transparent source referencing, automated calculations, and visualization capabilities. Evaluated using the RAGAS framework, WaterCopilot achieves an overall score of 0.8043, with high answer relevancy (0.8571) and context precision (0.8009). Key innovations include automated threshold-based alerts, integration with the LRB Digital Twin, and a scalable deployment pipeline hosted on AWS. While limitations in processing non-English technical documents and API latency remain, WaterCopilot establishes a replicable AI-augmented framework for enhancing water governance in data-scarce, transboundary contexts. The study demonstrates the potential of this AI assistant to support informed, timely decision-making and strengthen water security in complex river basins.

</details>


### [164] [ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios](https://arxiv.org/abs/2601.08620)
*António Loison,Quentin Macé,Antoine Edy,Victor Xing,Tom Balough,Gabriel Moreira,Bo Liu,Manuel Faysse,Céline Hudelot,Gautier Viaud*

Main category: cs.AI

TL;DR: 提出ViDoRe v3，一个涵盖多类型查询的多模态RAG基准，包含10个领域、约26,000页文档和3,099个人工验证问题，支持6种语言。通过1.2万小时的人工标注，提供高质量的检索相关性、边界框定位和参考答案。评估显示视觉检索优于文本检索，后期交互模型和文本重排序显著提升性能，混合或纯视觉上下文改善生成质量，但模型仍难以处理非文本元素、开放性问题和细粒度视觉定位。基准以宽松商业许可发布。


<details>
  <summary>Details</summary>
Motivation: 现有RAG基准无法充分反映复杂场景中的挑战，如视觉元素理解、跨文档信息融合和准确溯源，且多集中于文本数据与单文档任务，缺乏对多模态与多阶段流程的综合评估。

Method: 构建多模态文档语料库，覆盖10个专业领域，整合文本、表格、图表等视觉内容；设计多样化查询（包括开放性与具体性），并进行大规模人工标注，涵盖检索相关性、视觉定位与答案正确性。

Result: 视觉检索器表现优于文本检索器；晚期交互模型与文本重排序显著提升效果；结合视觉上下文能提高生成质量；然而在非文本元素理解、开放性问题及细粒度视觉定位方面仍存在明显不足。

Conclusion: ViDoRe v3为多模态RAG研究提供了全面、高质量的评估基准，有助于推动模型在复杂真实场景下的能力发展，尤其在视觉理解与跨文档推理方面。

Abstract: Retrieval-Augmented Generation (RAG) pipelines must address challenges beyond simple single-document retrieval, such as interpreting visual elements (tables, charts, images), synthesizing information across documents, and providing accurate source grounding. Existing benchmarks fail to capture this complexity, often focusing on textual data, single-document comprehension, or evaluating retrieval and generation in isolation. We introduce ViDoRe v3, a comprehensive multimodal RAG benchmark featuring multi-type queries over visually rich document corpora. It covers 10 datasets across diverse professional domains, comprising ~26,000 document pages paired with 3,099 human-verified queries, each available in 6 languages. Through 12,000 hours of human annotation effort, we provide high-quality annotations for retrieval relevance, bounding box localization, and verified reference answers. Our evaluation of state-of-the-art RAG pipelines reveals that visual retrievers outperform textual ones, late-interaction models and textual reranking substantially improve performance, and hybrid or purely visual contexts enhance answer generation quality. However, current models still struggle with non-textual elements, open-ended queries, and fine-grained visual grounding. To encourage progress in addressing these challenges, the benchmark is released under a commercially permissive license at https://hf.co/vidore.

</details>


### [165] [Resisting Manipulative Bots in Memecoin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.08641)
*Yichen Luo,Yebo Feng,Jiahua Xu,Yang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种可解释的多智能体系统，用于 meme 币的跟单交易。该系统模仿资产管理团队的结构，将复杂任务分解为子任务，并由专门的智能体协作解决。通过少样本思维链提示（CoT），每个智能体能获取专业交易知识、解析多模态数据并生成可解释决策。基于1000个meme币项目的交易数据集，实证评估表明该系统在识别高质量meme币项目和关键意见领袖（KOL）钱包方面分别达到73%和70%的精确率，所选KOL在这些项目中合计产生50万美元利润，显著优于传统机器学习模型和单一大语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前meme币市场中，跟单交易虽因无需深度交易知识而流行，但面临操纵机器人、被跟踪钱包未来表现不确定及交易执行延迟等问题，难以保证盈利；同时，尽管大语言模型（LLM）在金融领域展现出潜力，但在处理复杂多面任务时受限于缺乏特定领域知识，尤其在加密货币市场更为明显。因此需要一种更高效、可解释且具备专业能力的解决方案。

Method: 提出一个受资产管理团队启发的可解释多智能体系统，将复杂任务分解为多个子任务，各智能体使用少样本思维链（CoT）提示方法，获取专业交易知识，理解多模态数据，并生成可解释的决策，通过协同工作实现精准跟单交易。

Result: 在包含1000个meme币项目的数据集上，该系统在识别高质量meme币项目和关键意见领袖（KOL）钱包方面分别实现了73%和70%的精确率；所选KOL在相关项目中累计创造50万美元利润，显著优于传统机器学习模型和单一大语言模型的表现。

Conclusion: 本研究构建的多智能体系统有效克服了单一大语言模型在复杂金融任务中的局限性，结合专业分工与可解释性，在meme币跟单交易中表现出卓越性能，为去中心化金融市场中的智能投资策略提供了新范式。

Abstract: The launch of \$Trump coin ignited a wave in meme coin investment. Copy trading, as a strategy-agnostic approach that eliminates the need for deep trading knowledge, quickly gains widespread popularity in the meme coin market. However, copy trading is not a guarantee of profitability due to the prevalence of manipulative bots, the uncertainty of the followed wallets' future performance, and the lag in trade execution. Recently, large language models (LLMs) have shown promise in financial applications by effectively understanding multi-modal data and producing explainable decisions. However, a single LLM struggles with complex, multi-faceted tasks such as asset allocation. These challenges are even more pronounced in cryptocurrency markets, where LLMs often lack sufficient domain-specific knowledge in their training data.
  To address these challenges, we propose an explainable multi-agent system for meme coin copy trading. Inspired by the structure of an asset management team, our system decomposes the complex task into subtasks and coordinates specialized agents to solve them collaboratively. Employing few-shot chain-of-though (CoT) prompting, each agent acquires professional meme coin trading knowledge, interprets multi-modal data, and generates explainable decisions. Using a dataset of 1,000 meme coin projects' transaction data, our empirical evaluation shows that the proposed multi-agent system outperforms both traditional machine learning models and single LLMs, achieving 73% and 70% precision in identifying high-quality meme coin projects and key opinion leader (KOL) wallets, respectively. The selected KOLs collectively generated a total profit of \$500,000 across these projects.

</details>


### [166] [Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding](https://arxiv.org/abs/2601.08653)
*Zenghua Liao,Jinzhi Liao,Xiang Zhao*

Main category: cs.AI

TL;DR: Prism is a novel framework for complex intent understanding in large language models, addressing logical dependencies in clarification questions through four modules: intent decomposition, logical clarification generation, intent-aware reward, and self-evolved tuning. It improves logical consistency, reduces conflicts, enhances user satisfaction, and speeds up task completion.


<details>
  <summary>Details</summary>
Motivation: Existing methods for intent clarification in LLMs rely on sequential or parallel questioning but fail to model logical dependencies among questions, leading to inefficient and inconsistent interactions.

Method: Prism introduces four modules: (1) complex intent decomposition to break down goals and identify dependencies; (2) logical clarification generation to structure questions coherently; (3) intent-aware reward using Monte Carlo simulation for high-quality training data; (4) self-evolved tuning for iterative improvement via feedback.

Result: Prism achieves state-of-the-art performance: 11.5% reduction in logical conflicts, 14.4% increase in user satisfaction, and 34.8% faster task completion, outperforming existing approaches across multiple benchmarks.

Conclusion: Prism enables more coherent, efficient, and user-friendly human-LLM collaboration by effectively modeling logical dependencies in intent clarification, with all code and data publicly released.

Abstract: Large Language Models are rapidly emerging as web-native interfaces to social platforms. On the social web, users frequently have ambiguous and dynamic goals, making complex intent understanding-rather than single-turn execution-the cornerstone of effective human-LLM collaboration. Existing approaches attempt to clarify user intents through sequential or parallel questioning, yet they fall short of addressing the core challenge: modeling the logical dependencies among clarification questions. Inspired by the Cognitive Load Theory, we propose Prism, a novel framework for complex intent understanding that enables logically coherent and efficient intent clarification. Prism comprises four tailored modules: a complex intent decomposition module, which decomposes user intents into smaller, well-structured elements and identifies logical dependencies among them; a logical clarification generation module, which organizes clarification questions based on these dependencies to ensure coherent, low-friction interactions; an intent-aware reward module, which evaluates the quality of clarification trajectories via an intent-aware reward function and leverages Monte Carlo Sample to simulate user-LLM interactions for large-scale,high-quality training data generation; and a self-evolved intent tuning module, which iteratively refines the LLM's logical clarification capability through data-driven feedback and optimization. Prism consistently outperforms existing approaches across clarification interactions, intent execution, and cognitive load benchmarks. It achieves stateof-the-art logical consistency, reduces logical conflicts to 11.5%, increases user satisfaction by 14.4%, and decreases task completion time by 34.8%. All data and code are released.

</details>


### [167] [From Classical to Quantum Reinforcement Learning and Its Applications in Quantum Control: A Beginner's Tutorial](https://arxiv.org/abs/2601.08662)
*Abhijit Sen,Sonali Panda,Mahima Arya,Subhajit Patra,Zizhan Zheng,Denys I. Bondar*

Main category: cs.AI

TL;DR: 本教程旨在通过清晰、基于实例的解释，使强化学习（RL）对本科生更具可及性，重点在于弥合理论与实际编码应用之间的差距，帮助学生克服从概念理解到实现的常见挑战。


<details>
  <summary>Details</summary>
Motivation: 许多本科生在将强化学习的理论知识转化为实际编程实现时面临困难，缺乏有效的指导资源来帮助他们顺利过渡。

Method: 通过动手示例和易于理解的解释，提供实践导向的学习路径，强调从理论到应用的转化。

Result: 学生能够掌握强化学习的基础技能，具备在真实场景中自信应用RL技术的能力。

Conclusion: 该教程成功降低了强化学习的学习门槛，为初学者提供了实用且有效的入门途径。

Abstract: This tutorial is designed to make reinforcement learning (RL) more accessible to undergraduate students by offering clear, example-driven explanations. It focuses on bridging the gap between RL theory and practical coding applications, addressing common challenges that students face when transitioning from conceptual understanding to implementation. Through hands-on examples and approachable explanations, the tutorial aims to equip students with the foundational skills needed to confidently apply RL techniques in real-world scenarios.

</details>


### [168] [Parallel Context-of-Experts Decoding for Retrieval Augmented Generation](https://arxiv.org/abs/2601.08670)
*Giulio Corallo,Paolo Papotti*

Main category: cs.AI

TL;DR: Pced是一种无需训练的框架，通过将证据聚合从注意力机制转移到解码过程，解决了检索增强生成中的多文档推理与速度之间的权衡问题。它将检索到的文档视为独立的“专家”，并通过一种新的检索感知对比解码规则同步其预测，从而在不构建共享注意力的情况下恢复跨文档推理能力。


<details>
  <summary>Details</summary>
Motivation: Retrieval Augmented Generation (RAG) 在多文档推理和解码速度之间存在权衡：长提示虽支持多文档推理，但导致预填充瓶颈；而单独编码文档的键值缓存虽提升速度，却破坏了跨文档交互。

Method: 提出 Parallel Context-of-Experts Decoding (Pced)，将检索到的文档视为独立专家，通过检索感知的对比解码规则，基于模型先验对专家输出进行加权，实现跨文档推理而不依赖共享注意力机制。

Result: Pced 在保持高效解码的同时，恢复了跨文档推理能力，且无需额外训练，显著提升了 RAG 系统在复杂推理任务中的表现。

Conclusion: Pced 为 RAG 提供了一种高效的无训练解决方案，有效缓解了多文档推理与解码速度之间的矛盾，为未来大模型推理架构设计提供了新思路。

Abstract: Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decoding (Pced), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding. Pced treats retrieved documents as isolated "experts", synchronizing their predictions via a novel retrieval-aware contrastive decoding rule that weighs expert logits against the model prior. This approach recovers cross-document reasoning capabilities without constructing a shared attention across documents.

</details>


### [169] [Advancing ESG Intelligence: An Expert-level Agent and Comprehensive Benchmark for Sustainable Finance](https://arxiv.org/abs/2601.08676)
*Yilei Zhao,Wentao Zhang,Xiao Lei,Yandan Zheng,Mengpu Liu,Wei Yang Bryan Lim*

Main category: cs.AI

TL;DR: ESGAgent is a hierarchical multi-agent system with specialized tools for ESG analysis, addressing data fragmentation and LLM limitations in complex workflows. It includes a three-level benchmark based on 310 corporate sustainability reports to evaluate tasks from basic questions to integrated reports. ESGAgent achieves 84.15% accuracy on atomic QA tasks and excels in generating detailed, reference-backed reports, demonstrating its effectiveness and the benchmark's value.


<details>
  <summary>Details</summary>
Motivation: Existing ESG analysis is hindered by fragmented unstructured data and LLMs' inability to handle complex, multi-step auditing workflows. There is a need for a more robust, structured approach to enable accurate and comprehensive ESG evaluation.

Method: ESGAgent employs a hierarchical multi-agent architecture enhanced with retrieval augmentation, web search, and domain-specific functions. A three-level benchmark derived from 310 corporate sustainability reports is used to assess performance across different levels of complexity, from basic question-answering to full report generation.

Result: ESGAgent outperforms state-of-the-art closed-source LLMs with 84.15% average accuracy on atomic QA tasks and demonstrates superior performance in generating integrated reports with verifiable references and charts. The benchmark proves effective in diagnosing agentic capabilities in high-stakes domains.

Conclusion: ESGAgent provides a powerful, scalable solution for professional ESG analysis, supported by a validated benchmark that enables rigorous evaluation of agentic systems in complex, real-world applications.

Abstract: Environmental, social, and governance (ESG) criteria are essential for evaluating corporate sustainability and ethical performance. However, professional ESG analysis is hindered by data fragmentation across unstructured sources, and existing large language models (LLMs) often struggle with the complex, multi-step workflows required for rigorous auditing. To address these limitations, we introduce ESGAgent, a hierarchical multi-agent system empowered by a specialized toolset, including retrieval augmentation, web search and domain-specific functions, to generate in-depth ESG analysis. Complementing this agentic system, we present a comprehensive three-level benchmark derived from 310 corporate sustainability reports, designed to evaluate capabilities ranging from atomic common-sense questions to the generation of integrated, in-depth analysis. Empirical evaluations demonstrate that ESGAgent outperforms state-of-the-art closed-source LLMs with an average accuracy of 84.15% on atomic question-answering tasks, and excels in professional report generation by integrating rich charts and verifiable references. These findings confirm the diagnostic value of our benchmark, establishing it as a vital testbed for assessing general and advanced agentic capabilities in high-stakes vertical domains.

</details>


### [170] [PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning](https://arxiv.org/abs/2601.08679)
*Xiaoyou Liu,Xinyi Mou,Shengbin Yue,Liang Wang,Yuqing Wang,Qiexiang Wang,Tianrui Qin,Wangchunshu Zhou,Zhongyu Wei*

Main category: cs.AI

TL;DR: PersonaDual是一种支持通用客观推理和个性化推理的单一模型框架，通过上下文自适应切换模式。该方法首先通过监督微调（SFT）学习两种推理模式，再通过提出的DualGRPO强化学习进一步优化模式选择。实验表明，PersonaDual在保持个性化优势的同时减少干扰，实现近乎无干扰的性能，并更有效地利用有帮助的个性化信号来提升客观问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 随着用户对LLM与自身偏好对齐的需求增加，个性化信息虽能提升交互体验，但可能损害客观性和事实正确性，尤其是在与问题不匹配时。因此需要一种既能支持个性化又能保持客观性的方法。

Method: PersonaDual框架首先通过监督微调（SFT）训练学习两种推理模式（通用客观与个性化），随后使用提出的DualGRPO强化学习方法优化模式选择机制，实现根据上下文自适应切换。

Result: 在客观和个性化基准测试中，PersonaDual有效减少了个性化信息对客观推理的干扰，实现了接近无干扰的性能，同时更好地利用了有益的个性化信号以增强客观问题求解能力。

Conclusion: PersonaDual成功实现了通用客观推理与个性化推理的融合，在保证客观性的同时充分利用个性化信息，为构建兼具个性与准确性的大模型提供了有效解决方案。

Abstract: As users increasingly expect LLMs to align with their preferences, personalized information becomes valuable. However, personalized information can be a double-edged sword: it can improve interaction but may compromise objectivity and factual correctness, especially when it is misaligned with the question. To alleviate this problem, we propose PersonaDual, a framework that supports both general-purpose objective reasoning and personalized reasoning in a single model, and adaptively switches modes based on context. PersonaDual is first trained with SFT to learn two reasoning patterns, and then further optimized via reinforcement learning with our proposed DualGRPO to improve mode selection. Experiments on objective and personalized benchmarks show that PersonaDual preserves the benefits of personalization while reducing interference, achieving near interference-free performance and better leveraging helpful personalized signals to improve objective problem-solving.

</details>


### [171] [MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection](https://arxiv.org/abs/2601.08684)
*Paolo Italiani,David Gimeno-Gomez,Luca Ragazzi,Gianluca Moro,Paolo Rosso*

Main category: cs.AI

TL;DR: MemeWeaver 是一个端到端可训练的多模态框架，通过新颖的跨漫画图推理机制检测性别歧视和厌女言论。它在 MAMI 和 EXIST 基准上优于现有方法，并实现更快的训练收敛。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核方法忽视了在线骚扰背后的社交动态，如施害者在同类群体中强化偏见和身份认同。传统图方法存在启发式图构建、浅层模态融合和实例级推理等局限。

Method: 提出 MemeWeaver 框架，采用创新的跨漫画图推理机制，系统评估多种视觉-文本融合策略，实现多模态数据的深层整合与关系建模。

Result: 在 MAMI 和 EXIST 基准上表现优于当前最佳模型，训练收敛速度更快；学习到的图结构揭示了在线仇恨的语义关联模式。

Conclusion: MemeWeaver 有效捕捉了在线仇恨的社交关系本质，为理解与检测性别歧视提供了新范式。

Abstract: Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communities. Graph-based methods offer a promising way to capture such interactions, yet existing solutions remain limited by heuristic graph construction, shallow modality fusion, and instance-level reasoning. In this work, we present MemeWeaver, an end-to-end trainable multimodal framework for detecting sexism and misogyny through a novel inter-meme graph reasoning mechanism. We systematically evaluate multiple visual--textual fusion strategies and show that our approach consistently outperforms state-of-the-art baselines on the MAMI and EXIST benchmarks, while achieving faster training convergence. Further analyses reveal that the learned graph structure captures semantically meaningful patterns, offering valuable insights into the relational nature of online hate.

</details>


### [172] [All Required, In Order: Phase-Level Evaluation for AI-Human Dialogue in Healthcare and Beyond](https://arxiv.org/abs/2601.08690)
*Shubham Kulkarni,Alexander Lyzhov,Shiva Chaitanya,Preetam Joshi*

Main category: cs.AI

TL;DR: OIP-SCE is a new evaluation method for conversational AI in healthcare that ensures clinical obligations are met in the correct order with clear evidence, making complex rules practical and auditable. It was tested in two case studies and enables alignment between AI capabilities and clinical workflows.


<details>
  <summary>Details</summary>
Motivation: Current evaluation methods for conversational AI in clinical settings fail to account for the full conversation flow and compliance requirements, leading to a gap between technical advancements and real healthcare needs.

Method: Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE) evaluates whether required clinical obligations are fulfilled in the right sequence, supported by traceable evidence for clinicians.

Result: The method successfully transformed clinical policies into actionable, shared steps in two case studies—respiratory history and benefits verification—and enabled a clear, auditable evaluation surface that supports safe, routine AI use in clinical workflows.

Conclusion: OIP-SCE bridges the gap between AI development and clinical practice by providing a structured, transparent, and auditable way to evaluate conversational AI, ensuring it aligns with real-world healthcare workflows.

Abstract: Conversational AI is starting to support real clinical work, but most evaluation methods miss how compliance depends on the full course of a conversation. We introduce Obligatory-Information Phase Structured Compliance Evaluation (OIP-SCE), an evaluation method that checks whether every required clinical obligation is met, in the right order, with clear evidence for clinicians to review. This makes complex rules practical and auditable, helping close the gap between technical progress and what healthcare actually needs. We demonstrate the method in two case studies (respiratory history, benefits verification) and show how phase-level evidence turns policy into shared, actionable steps. By giving clinicians control over what to check and engineers a clear specification to implement, OIP-SCE provides a single, auditable evaluation surface that aligns AI capability with clinical workflow and supports routine, safe use.

</details>


### [173] [Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set](https://arxiv.org/abs/2601.08703)
*Kaivalya Rawal,Eoin Delaney,Zihao Fu,Sandra Wachter,Chris Russell*

Main category: cs.AI

TL;DR: 本文提出了一种名为AXE的新方法来评估特征重要性解释的质量，解决了现有评估方法在缺乏真实标签情况下无法有效区分性能相近模型（Rashomon集）行为差异的问题。传统方法依赖于与理想解释的对比，容易被对抗性公平伪装（fairwashing）误导，而AXE通过三个解释评估原则，能够100%检测出此类欺骗行为，并识别出受保护属性是否被用于预测，从而提升模型选择的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有解释评估方法在缺乏真实标签时难以区分性能相近模型之间的行为差异，且易被对抗性公平伪装欺骗，导致错误地认为不合理的解释质量高，因此需要一种更鲁棒、可信赖的解释评估机制。

Method: 提出三个解释评估原则，并设计了新方法AXE，该方法基于对解释一致性与敏感性的分析，能够检测模型是否利用受保护属性进行预测，并识别对抗性公平伪装行为。

Result: AXE在检测对抗性公平伪装方面达到100%成功率，能有效揭示不同模型在解释层面的真实差异，帮助从Rashomon集中选出更具可信度的模型。

Conclusion: 传统解释评估方法因依赖理想真实标签或敏感性测试，易受欺骗；而基于新原则的AXE方法不仅具备更强的鲁棒性，还能发现隐藏的不公平行为，为可解释人工智能中的模型选择提供了更可靠依据。

Abstract: Explainable artificial intelligence (XAI) is concerned with producing explanations indicating the inner workings of models. For a Rashomon set of similarly performing models, explanations provide a way of disambiguating the behavior of individual models, helping select models for deployment. However explanations themselves can vary depending on the explainer used, and need to be evaluated. In the paper "Evaluating Model Explanations without Ground Truth", we proposed three principles of explanation evaluation and a new method "AXE" to evaluate the quality of feature-importance explanations. We go on to illustrate how evaluation metrics that rely on comparing model explanations against ideal ground truth explanations obscure behavioral differences within a Rashomon set. Explanation evaluation aligned with our proposed principles would highlight these differences instead, helping select models from the Rashomon set. The selection of alternate models from the Rashomon set can maintain identical predictions but mislead explainers into generating false explanations, and mislead evaluation methods into considering the false explanations to be of high quality. AXE, our proposed explanation evaluation method, can detect this adversarial fairwashing of explanations with a 100% success rate. Unlike prior explanation evaluation strategies such as those based on model sensitivity or ground truth comparison, AXE can determine when protected attributes are used to make predictions.

</details>


### [174] [AI as Entertainment](https://arxiv.org/abs/2601.08768)
*Cody Kommers,Ari Holtzman*

Main category: cs.AI

TL;DR: 本文探讨了生成式AI在娱乐领域的兴起及其对社会的潜在影响，指出当前AI评估体系偏重于文化危害而忽视娱乐内容的积极价值。作者提出‘厚娱乐’（thick entertainment）框架，主张从意义建构、身份形成和社会联结等角度重新评估AI生成内容，强调娱乐不仅是消遣，更是社会文化的重要组成部分。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI被广泛宣传为提升生产力的智能工具，但其在娱乐领域的广泛应用已显现，尤其受到年轻人欢迎，并可能成为主要商业模式。然而，现有评估体系未能充分回应娱乐性内容的社会价值，存在评价框架缺失的问题。

Method: 通过分析现有AI评估实践中的不对称性，结合人文学科视角，提出‘厚娱乐’概念，构建一种新的评价框架，以系统化理解AI生成内容在文化与社会层面的积极作用。

Result: 揭示了当前AI评估体系对娱乐性内容的忽视，提出‘厚娱乐’作为补充框架，有助于更全面地理解生成式AI的社会影响，尤其在文化意义和人际连接方面的作用。

Conclusion: 生成式AI未来的发展可能不仅关乎效率与智能，更关乎娱乐与社会联结；应建立兼顾风险与价值的评估体系，将娱乐视为有意义的社会实践，而非仅是副作用或干扰。

Abstract: Generative AI systems are predominantly designed, evaluated, and marketed as intelligent systems which will benefit society by augmenting or automating human cognitive labor, promising to increase personal, corporate, and macroeconomic productivity. But this mainstream narrative about what AI is and what it can do is in tension with another emerging use case: entertainment. We argue that the field of AI is unprepared to measure or respond to how the proliferation of entertaining AI-generated content will impact society. Emerging data suggest AI is already widely adopted for entertainment purposes -- especially by young people -- and represents a large potential source of revenue. We contend that entertainment will become a primary business model for major AI corporations seeking returns on massive infrastructure investments; this will exert a powerful influence on the technology these companies produce in the coming years. Examining current evaluation practices, we identify a critical asymmetry: while AI assessments rigorously measure both benefits and harms of intelligence, they focus almost exclusively on cultural harms. We lack frameworks for articulating how cultural outputs might be actively beneficial. Drawing on insights from the humanities, we propose "thick entertainment" as a framework for evaluating AI-generated cultural content -- one that considers entertainment's role in meaning-making, identity formation, and social connection rather than simply minimizing harm. While AI is often touted for its potential to revolutionize productivity, in the long run we may find that AI turns out to be as much about "intelligence" as social media is about social connection.

</details>


### [175] [Uncovering Political Bias in Large Language Models using Parliamentary Voting Records](https://arxiv.org/abs/2601.08785)
*Jieying Chen,Karen de Jong,Andreas Poole,Jan Burakowski,Elena Elderson Nosti,Joep Windt,Chendi Wang*

Main category: cs.AI

TL;DR: 本文提出了一种构建政治偏见基准的通用方法，通过将大语言模型（LLM）生成的投票预测与经验证的议会投票记录对齐，开展了荷兰、挪威和西班牙三个国家的案例研究。研究发现，当前最先进的LLM普遍表现出左倾或中间立场，并对右翼保守政党存在明显负面偏见。研究还提出一种可视化方法，将模型与政党的意识形态映射到共享的两维CHES空间中，实现可解释的对比分析。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量研究关注性别、种族等社会偏见，但针对大语言模型在政治领域的系统性偏见研究仍较为匮乏，而此类偏见对社会决策具有直接影响，因此亟需建立基于真实议会行为的评估框架以揭示和审计政治偏见。

Method: 提出一种通用方法，将模型输出的投票预测与真实议会投票记录对齐，构建跨国家的政治偏见基准；设计并应用基于CHES（Chapel Hill Expert Survey）维度的二维空间，可视化模型与政党的意识形态位置，实现直接比较。

Result: 实验表明，主流大语言模型普遍存在左倾或中立倾向，对右翼保守政党存在显著负向偏见；所提出的可视化方法有效实现了模型与真实政治实体之间的可解释性对比。

Conclusion: 本研究强调了基于真实议会行为进行透明、跨国界评估的重要性，为理解与审计现代大语言模型中的政治偏见提供了有力工具与方法论支持。

Abstract: As large language models (LLMs) become deeply embedded in digital platforms and decision-making systems, concerns about their political biases have grown. While substantial work has examined social biases such as gender and race, systematic studies of political bias remain limited, despite their direct societal impact. This paper introduces a general methodology for constructing political bias benchmarks by aligning model-generated voting predictions with verified parliamentary voting records. We instantiate this methodology in three national case studies: PoliBiasNL (2,701 Dutch parliamentary motions and votes from 15 political parties), PoliBiasNO (10,584 motions and votes from 9 Norwegian parties), and PoliBiasES (2,480 motions and votes from 10 Spanish parties). Across these benchmarks, we assess ideological tendencies and political entity bias in LLM behavior. As part of our evaluation framework, we also propose a method to visualize the ideology of LLMs and political parties in a shared two-dimensional CHES (Chapel Hill Expert Survey) space by linking their voting-based positions to the CHES dimensions, enabling direct and interpretable comparisons between models and real-world political actors. Our experiments reveal fine-grained ideological distinctions: state-of-the-art LLMs consistently display left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties. These findings highlight the value of transparent, cross-national evaluation grounded in real parliamentary behavior for understanding and auditing political bias in modern LLMs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [176] [Hierarchical Sparse Plus Low Rank Compression of LLM](https://arxiv.org/abs/2601.07839)
*Pawan Kumar,Aditi Gupta*

Main category: cs.LG

TL;DR: 提出HSS压缩方法，通过稀疏化和分层低秩分解实现大模型高效压缩，仅压缩注意力投影即可在保持性能的同时大幅节省内存。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型对内存和计算资源压力巨大，需要有效的压缩技术以支持部署和持续训练。

Method: 采用两阶段压缩：先将最大权重值稀疏化为矩阵S，再对剩余密集矩阵进行递归分层可分离低秩分解，并结合反向Cuthill-Mckee排列优化权重分布，提升压缩效率。

Result: 在LLaMA-7B上，仅压缩自注意力投影（1.6B参数）即实现显著内存节省，30%稀疏度与外层秩512下，困惑度达1.64，优于密集基线和经典稀疏+SVD方法。

Conclusion: HSS压缩方法具备硬件友好性，支持端到端训练，是大模型压缩的有效方案。

Abstract: Modern large language models (LLMs) place extraordinary pressure on memory and compute budgets, making principled compression indispensable for both deployment and continued training. We present Hierarchical Sparse Plus Low-Rank (HSS) compression, a two-stage scheme that (i) removes the largest-magnitude weights into a sparse matrix S and (ii) applies a recursive Hierarchically Sparse Separable (HSS) low-rank factorisation to the dense residual matrix. A recursive rank-reducing strategy and a reverse Cuthill-Mckee (RCM) permutation are introduced to align high weights towards the diagonal with the block-diagonal hierarchy, maximising off-diagonal compressibility (because they are touched only once). HSS is hardware-friendly: its matrix-vector multiply reduces to one sparse and a sequence of thin-matrix multiplications and can be trained end-to-end with standard optimisers.
  Experiments on LLaMA-7B show that targeting only the self-attention projections (1.6 B parameters of Q, K, and V matrices out of a total 7B parameters) suffices to yield large memory savings while retaining comparable state-of-the-art perplexity scores on test samples of the WikiText dataset. For example, with a 30\% sparsity budget and an outer rank of 512, sHSS-RCM achieves a perplexity of 1.64, outperforming dense baselines and classical sparse-plus-SVD variants, while also achieving significant memory savings.

</details>


### [177] [Affect and Effect: Limitations of regularisation-based continual learning in EEG-based emotion classification](https://arxiv.org/abs/2601.07858)
*Nina Peire,Yupei Li,Björn Schuller*

Main category: cs.LG

TL;DR: 本文研究了基于脑电图（EEG）的情绪分类中，持续学习（CL）方法在未见受试者上的泛化能力。发现基于正则化的CL方法（如EWC、SI、MAS）在DREAMER和SEED数据集上表现有限，主要因稳定性-可塑性权衡存在根本性错配：这些方法更关注防止灾难性遗忘（反向迁移），而非适应新受试者（正向迁移）。由于EEG信号的高变异性，历史受试者对未来的帮助很小，导致正向迁移无显著提升。此外，参数重要性估计在噪声数据和协变量偏移下不可靠，重要参数的梯度更新反而干扰新受试者的学习，且模型因累积的重要性值被过度约束，性能还受受试者顺序影响。


<details>
  <summary>Details</summary>
Motivation: EEG-based情绪分类面临跨受试者差异大、泛化困难的问题。持续学习被视为潜在解决方案，但现有基于正则化的持续学习方法是否适用于此任务尚不明确，尤其其在处理高变异性的脑电信号时的有效性需深入探究。

Method: 通过理论分析与实验验证，评估EWC、SI、MAS等正则化持续学习方法在subject-incremental设置下的表现。使用DREAMER和SEED数据集，考察不同受试者顺序下的前向迁移与后向迁移效果，并分析参数重要性估计的可靠性及梯度冲突问题。

Result: 正则化持续学习方法在两个数据集上均未实现显著的前向迁移（p > 0.05），性能与顺序微调相当。参数重要性估计在噪声和协变量偏移下失效，重要参数的梯度更新常阻碍新受试者的学习，模型被过度约束，且结果对受试者顺序敏感。

Conclusion: 基于正则化的持续学习方法在EEG情绪分类中难以实现对未见受试者的有效泛化，主要因其在稳定性-可塑性权衡上的设计缺陷，无法适应高变异性脑电信号场景。

Abstract: Generalisation to unseen subjects in EEG-based emotion classification remains a challenge due to high inter-and intra-subject variability. Continual learning (CL) poses a promising solution by learning from a sequence of tasks while mitigating catastrophic forgetting. Regularisation-based CL approaches, such as Elastic Weight Consolidation (EWC), Synaptic Intelligence (SI), and Memory Aware Synapses (MAS), are commonly used as baselines in EEG-based CL studies, yet their suitability for this problem remains underexplored. This study theoretically and empirically finds that regularisation-based CL methods show limited performance for EEG-based emotion classification on the DREAMER and SEED datasets. We identify a fundamental misalignment in the stability-plasticity trade-off, where regularisation-based methods prioritise mitigating catastrophic forgetting (backward transfer) over adapting to new subjects (forward transfer). We investigate this limitation under subject-incremental sequences and observe that: (1) the heuristics for estimating parameter importance become less reliable under noisy data and covariate shift, (2) gradients on parameters deemed important by these heuristics often interfere with gradient updates required for new subjects, moving optimisation away from the minimum, (3) importance values accumulated across tasks over-constrain the model, and (4) performance is sensitive to subject order. Forward transfer showed no statistically significant improvement over sequential fine-tuning (p > 0.05 across approaches and datasets). The high variability of EEG signals means past subjects provide limited value to future subjects. Regularisation-based continual learning approaches are therefore limited for robust generalisation to unseen subjects in EEG-based emotion classification.

</details>


### [178] [RewriteNets: End-to-End Trainable String-Rewriting for Generative Sequence Modeling](https://arxiv.org/abs/2601.07868)
*Harshil Vejendla*

Main category: cs.LG

TL;DR: RewriteNets 是一种基于显式并行字符串重写的新型神经架构，通过可学习规则在每层中进行模糊匹配、冲突解决、规则应用和未触及标记的传播，以替代Transformer中的密集注意力机制。采用Gumbel-Sinkhorn估计器实现端到端训练，显著提升计算效率，并在需要系统泛化的任务上表现优异（如SCAN基准达到98.7%准确率），展现出明确的结构归纳偏置优势。


<details>
  <summary>Details</summary>
Motivation: 现有序列模型（如Transformer）依赖密集注意力隐式建模结构，导致二次复杂度；本文旨在提出一种显式、高效的结构建模方式，以改善系统泛化能力和计算效率。

Method: 提出RewriteNet，每层包含可学习的重写规则，通过四步操作：模糊匹配规则模式、使用可微分配算子解决冲突、应用规则替换输入段、传播未修改的标记；利用直通Gumbel-Sinkhorn估计器处理非可微的规则分配，实现稳定端到端训练。

Result: 在算法、组合性和字符串操作任务上，RewriteNets在系统泛化任务中表现优异（如SCAN长度分裂任务达98.7%准确率），且比Transformer更高效，同时通过规则分析与消融实验验证了其有效性与潜力。

Conclusion: RewriteNets提供了一种具有显式结构归纳偏置的序列建模新方向，兼具高效率与强泛化能力，是传统注意力机制的有力替代方案。

Abstract: Dominant sequence models like the Transformer represent structure implicitly through dense attention weights, incurring quadratic complexity. We propose RewriteNets, a novel neural architecture built on an alternative paradigm: explicit, parallel string rewriting. Each layer in a RewriteNet contains a set of learnable rules. For each position in an input sequence, the layer performs four operations: (1) fuzzy matching of rule patterns, (2) conflict resolution via a differentiable assignment operator to select non-overlapping rewrites, (3) application of the chosen rules to replace input segments with output segments of potentially different lengths, and (4) propagation of untouched tokens. While the discrete assignment of rules is non-differentiable, we employ a straight-through Gumbel-Sinkhorn estimator, enabling stable end-to-end training. We evaluate RewriteNets on algorithmic, compositional, and string manipulation tasks, comparing them against strong LSTM and Transformer baselines. Results show that RewriteNets excel at tasks requiring systematic generalization (achieving 98.7% accuracy on the SCAN benchmark's length split) and are computationally more efficient than Transformers. We also provide an analysis of learned rules and an extensive ablation study, demonstrating that this architecture presents a promising direction for sequence modeling with explicit structural inductive biases.

</details>


### [179] [HOSC: A Periodic Activation with Saturation Control for High-Fidelity Implicit Neural Representations](https://arxiv.org/abs/2601.07870)
*Michal Jan Wlodarczyk,Danzel Serrano,Przemyslaw Musialski*

Main category: cs.LG

TL;DR: 提出HOSC激活函数，通过控制参数β调节梯度大小，保留周期性特征，在图像、音频、视频、NeRFs和SDFs等任务中表现优异，提供超参数选择指导。


<details>
  <summary>Details</summary>
Motivation: 周期性激活如正弦函数虽能保持高频信息，但存在梯度不稳定和多尺度控制能力弱的问题，需一种兼具稳定性与可控性的新激活函数。

Method: 引入HOSC激活函数 $\text{HOSC}(x) = \tanh(β\sin(ω_0 x))$，利用β显式控制Lipschitz界，从而调节梯度幅度，同时保持周期性结构。

Result: 在多种INR任务中，HOSC相比SIREN、FINER等方法在性能上取得显著提升或达到竞争性水平，验证了其有效性与实用性，并提供了针对不同领域的超参数选择建议。

Conclusion: HOSC是一种实用的周期性激活函数，可在保持高频信息的同时有效控制梯度行为，适用于各类隐式神经表示任务。

Abstract: Periodic activations such as sine preserve high-frequency information in implicit neural representations (INRs) through their oscillatory structure, but often suffer from gradient instability and limited control over multi-scale behavior. We introduce the Hyperbolic Oscillator with Saturation Control (HOSC) activation, $\text{HOSC}(x) = \tanh\bigl(β\sin(ω_0 x)\bigr)$, which exposes an explicit parameter $β$ that controls the Lipschitz bound of the activation by $βω_0$. This provides a direct mechanism to tune gradient magnitudes while retaining a periodic carrier. We provide a mathematical analysis and conduct a comprehensive empirical study across images, audio, video, NeRFs, and SDFs using standardized training protocols. Comparative analysis against SIREN, FINER, and related methods shows where HOSC provides substantial benefits and where it achieves competitive parity. Results establish HOSC as a practical periodic activation for INR applications, with domain-specific guidance on hyperparameter selection. For code visit the project page https://hosc-nn.github.io/ .

</details>


### [180] [Multiplicative Orthogonal Sequential Editing for Language Models](https://arxiv.org/abs/2601.07873)
*Hao-Xiang Xu,Jun-Yu Ma,Ziqi Peng,Yuhao Sun,Zhen-Hua Ling,Jia-Chen Gu*

Main category: cs.LG

TL;DR: 提出了一种新的知识编辑方法MOSE，通过乘法而非加法方式更新模型参数，利用正交矩阵保持数值稳定性，显著提升序列编辑性能并保留95.73%的通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于加法的编辑方法会破坏参数矩阵的数值稳定性，影响编辑效果和模型泛化能力，尤其在连续编辑场景下问题更严重。

Method: 提出乘法正交序列编辑（MOSE），将新知识融入正交矩阵，并通过乘法更新原始参数矩阵，以维持数值稳定性。

Result: MOSE在序列编辑任务中性能提升12.08%，同时保留95.73%的下游任务通用能力，优于现有方法。

Conclusion: MOSE通过乘法正交机制有效解决了传统加法编辑带来的数值不稳定性问题，显著提升了大语言模型知识编辑的性能与鲁棒性。

Abstract: Knowledge editing aims to efficiently modify the internal knowledge of large language models (LLMs) without compromising their other capabilities. The prevailing editing paradigm, which appends an update matrix to the original parameter matrix, has been shown by some studies to damage key numerical stability indicators (such as condition number and norm), thereby reducing editing performance and general abilities, especially in sequential editing scenario. Although subsequent methods have made some improvements, they remain within the additive framework and have not fundamentally addressed this limitation. To solve this problem, we analyze it from both statistical and mathematical perspectives and conclude that multiplying the original matrix by an orthogonal matrix does not change the numerical stability of the matrix. Inspired by this, different from the previous additive editing paradigm, a multiplicative editing paradigm termed Multiplicative Orthogonal Sequential Editing (MOSE) is proposed. Specifically, we first derive the matrix update in the multiplicative form, the new knowledge is then incorporated into an orthogonal matrix, which is multiplied by the original parameter matrix. In this way, the numerical stability of the edited matrix is unchanged, thereby maintaining editing performance and general abilities. We compared MOSE with several current knowledge editing methods, systematically evaluating their impact on both editing performance and the general abilities across three different LLMs. Experimental results show that MOSE effectively limits deviations in the edited parameter matrix and maintains its numerical stability. Compared to current methods, MOSE achieves a 12.08% improvement in sequential editing performance, while retaining 95.73% of general abilities across downstream tasks. The code is available at https://github.com/famoustourist/MOSE.

</details>


### [181] [NOVAK: Unified adaptive optimizer for deep neural networks](https://arxiv.org/abs/2601.07876)
*Sergii Kavun*

Main category: cs.LG

TL;DR: NOVAK is a modular, gradient-based optimization algorithm that combines adaptive moment estimation, rectified learning-rate scheduling, decoupled weight regularization, multiple Nesterov momentum variants, and lookahead synchronization. It features a dual-mode architecture with a fast path for production, custom CUDA kernels for 3-5x speedup, and memory-efficient design reducing overhead from O(2p) to O(p + p/k). Theoretical analysis confirms convergence, stability, and variance reduction. Empirical results on CIFAR-10, CIFAR-100, ImageNet, and ImageNette show NOVAK outperforms 14 modern optimizers across ResNet-50, VGG-16, and ViT, achieving state-of-the-art accuracy and robustness—especially in deep plain networks without skip connections.


<details>
  <summary>Details</summary>
Motivation: Existing adaptive optimizers struggle with reliable training of deep plain networks lacking skip connections. This work aims to address this limitation by developing a unified, high-performance optimizer with enhanced stability, convergence, and architectural robustness through integrated components like rectified learning rates, decoupled regularization, and hybrid momentum.

Method: NOVAK integrates adaptive moment estimation, rectified learning-rate scheduling, decoupled weight regularization, multiple Nesterov momentum variants, and lookahead synchronization. It uses a dual-mode architecture with a streamlined fast path, custom CUDA kernels for acceleration, and memory-efficient lookahead mechanism. Mathematical formulations are provided for rectified adaptive learning rates and efficient lookahead. Theoretical analysis establishes convergence and variance-reduction properties.

Result: NOVAK achieves state-of-the-art accuracy and robustness across multiple benchmarks (CIFAR-10, CIFAR-100, ImageNet, ImageNette) and architectures (ResNet-50, VGG-16, ViT). It surpasses 14 contemporary optimizers including Adam, AdamW, RAdam, Lion, and Adan. Notably, it demonstrates superior performance on VGG-16/ImageNette, highlighting its effectiveness in training deep plain networks without skip connections.

Conclusion: The integration of rectification, decoupled decay, and hybrid momentum in NOVAK enables reliable training of deep plain networks—a longstanding challenge in adaptive optimization. Its modular, high-performance design, combined with theoretical guarantees and empirical superiority, positions NOVAK as a leading optimizer for modern deep learning applications.

Abstract: This work introduces NOVAK, a modular gradient-based optimization algorithm that integrates adaptive moment estimation, rectified learning-rate scheduling, decoupled weight regularization, multiple variants of Nesterov momentum, and lookahead synchronization into a unified, performance-oriented framework. NOVAK adopts a dual-mode architecture consisting of a streamlined fast path designed for production. The optimizer employs custom CUDA kernels that deliver substantial speedups (3-5 for critical operations) while preserving numerical stability under standard stochastic-optimization assumptions. We provide fully developed mathematical formulations for rectified adaptive learning rates, a memory-efficient lookahead mechanism that reduces overhead from O(2p) to O(p + p/k), and the synergistic coupling of complementary optimization components. Theoretical analysis establishes convergence guarantees and elucidates the stability and variance-reduction properties of the method. Extensive empirical evaluation on CIFAR-10, CIFAR-100, ImageNet, and ImageNette demonstrates NOVAK superiority over 14 contemporary optimizers, including Adam, AdamW, RAdam, Lion, and Adan. Across architectures such as ResNet-50, VGG-16, and ViT, NOVAK consistently achieves state-of-the-art accuracy, and exceptional robustness, attaining very high accuracy on VGG-16/ImageNette demonstrating superior architectural robustness compared to contemporary optimizers. The results highlight that NOVAKs architectural contributions (particularly rectification, decoupled decay, and hybrid momentum) are crucial for reliable training of deep plain networks lacking skip connections, addressing a long-standing limitation of existing adaptive optimization methods.

</details>


### [182] [E^2-LLM: Bridging Neural Signals and Interpretable Affective Analysis](https://arxiv.org/abs/2601.07877)
*Fei Ma,Han Lin,Yifan Xie,Hongwei Ren,Xiaoyu Shen,Wenbo Ding,Qi Tian*

Main category: cs.LG

TL;DR: E^2-LLM是首个用于从脑电图（EEG）信号中进行可解释情感分析的多模态大语言模型（MLLM）框架。它通过可学习投影层将预训练的EEG编码器与基于Qwen的大型语言模型结合，采用多阶段训练流程，包括情感判别预训练、跨模态对齐和带有思维链推理的指令微调。该模型在七个情绪类别上的实验中表现出色，尤其在零样本场景下展现出卓越的泛化能力，证明了模型规模扩大能同时提升识别准确率和可解释性情感理解。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别方法在处理脑电图（EEG）信号时面临个体差异大、标注数据有限以及缺乏可解释推理的问题；尽管多模态大语言模型在情感分析方面取得进展，但尚未适配神经信号特有的时空特性。因此，亟需一种能够融合生理信号与大语言模型推理能力的新范式。

Method: 提出E^2-LLM框架，整合预训练的EEG编码器与基于Qwen的大型语言模型，通过可学习投影层实现融合，并采用多阶段训练策略：情感判别预训练、跨模态对齐、指令微调及链式思维推理。

Result: 在包含七个情绪类别的数据集上，E^2-LLM在情感分类任务中表现优异，大版本模型显示出更强的可靠性与更优的零样本泛化能力，特别是在复杂推理场景中。结果表明，模型规模扩展有助于提升情感识别精度与可解释性理解。

Conclusion: E^2-LLM为情感计算领域建立了一种新范式，即结合生理信号与大语言模型的推理能力，验证了模型规模扩展在提升情感识别性能与可解释性方面的有效性。

Abstract: Emotion recognition from electroencephalography (EEG) signals remains challenging due to high inter-subject variability, limited labeled data, and the lack of interpretable reasoning in existing approaches. While recent multimodal large language models (MLLMs) have advanced emotion analysis, they have not been adapted to handle the unique spatiotemporal characteristics of neural signals. We present E^2-LLM (EEG-to-Emotion Large Language Model), the first MLLM framework for interpretable emotion analysis from EEG. E^2-LLM integrates a pretrained EEG encoder with Qwen-based LLMs through learnable projection layers, employing a multi-stage training pipeline that encompasses emotion-discriminative pretraining, cross-modal alignment, and instruction tuning with chain-of-thought reasoning. We design a comprehensive evaluation protocol covering basic emotion prediction, multi-task reasoning, and zero-shot scenario understanding. Experiments on the dataset across seven emotion categories demonstrate that E^2-LLM achieves excellent performance on emotion classification, with larger variants showing enhanced reliability and superior zero-shot generalization to complex reasoning scenarios. Our work establishes a new paradigm combining physiological signals with LLM reasoning capabilities, showing that model scaling improves both recognition accuracy and interpretable emotional understanding in affective computing.

</details>


### [183] [Sliced-Wasserstein Distribution Alignment Loss Improves the Ultra-Low-Bit Quantization of Large Language Models](https://arxiv.org/abs/2601.07878)
*Deyu Cao,Yixin Yin,Samin Aref*

Main category: cs.LG

TL;DR: 本文提出一种基于切片Wasserstein损失的分布感知校准方法，用于超低比特后训练量化，通过在随机线性投影下对齐全精度与量化模型的输出分布，有效缓解4比特以下压缩导致的激活分布失真问题。该方法可无缝集成至现有量化框架（如OmniQuant和TesseraQ），无需额外推理开销，在多个语言模型上显著提升性能，恢复高达20.37%的准确率损失，推动超低比特量化技术边界。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型部署存在高昂的经济与环境成本，模型量化虽能提升效率，但4比特以下压缩常因激活分布失真导致性能下降，亟需一种高效且无额外开销的分布对齐机制以提升超低比特量化表现。

Method: 提出切片Wasserstein损失函数，通过随机线性投影对齐全精度与量化模型的输出分布，结合标准均方误差损失，不增加推理计算开销，可嵌入任意具有重训练环节的后训练量化框架中。

Result: 在LLaMA-2-7B、OPT-6.7B和LLaMA-2-13B上，相比OmniQuant和TesseraQ基线，所提方法恢复了4.12%-20.37%的准确率损失，显著提升超低比特量化下的语言模型性能。

Conclusion: 分布对齐是一种简单而有效的性能提升手段，通过切片Wasserstein损失实现的分布感知校准，能够显著增强超低比特量化模型的表现，为前沿量化技术提供有力支持。

Abstract: The benefits of most large language models come with steep and often hidden economic and environmental costs due to their resource usage inefficiency during deployment. Model quantization improves energy and memory efficiency through representing model parameters by lower-precision values. However, compression below 4-bits often distorts activation distributions and degrades performance. We address this challenge by introducing a sliced Wasserstein loss function for distribution-aware calibration in ultra-low-bit post-training quantization. The proposed loss aligns the output distributions of full-precision and quantized models under random linear projections, complementing standard mean-squared error loss without adding any computational overhead during inference. Our proposed loss function can be incorporated with any post-training quantization framework that has a retraining component. We demonstrate the performance gains of our proposed model by incorporating it with two frontier methods known as OmniQuant and TesseraQ. Compared to these two baselines, the proposed loss consistently improves both perplexity and downstream task accuracy across multiple ultra-low-bit settings. Our proposed loss function recovers 4.12-20.37% of the OmniQuant's lost accuracy on the language model LLaMA-2-7B, 0.93-7.65% on OPT-6.7B, and 2.26-6.20% on LLaMA-2-13B. TesseraQ's accuracy degradation is recovered by 3.63-7.63% in relative terms when augmented by our proposed loss function. Taken together, these results demonstrate that distributional alignment provides a simple yet effective performance boost that can push the limits of frontier quantization methods. Our method is available on GitHub to facilitate future progress in ultra-low-bit quantization.

</details>


### [184] [KVzap: Fast, Adaptive, and Faithful KV Cache Pruning](https://arxiv.org/abs/2601.07891)
*Simon Jegou,Maximilian Jeblick*

Main category: cs.LG

TL;DR: KVzap是一种快速、输入自适应的KVzip近似方法，适用于预填充和解码阶段，在Qwen3-8B、Llama-3.1-8B-Instruct和Qwen3-32B模型上实现了2-4倍的KV缓存压缩，几乎无精度损失，并在KVpress排行榜上达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer语言模型上下文长度的增长，键值（KV）缓存已成为推理瓶颈。现有KV缓存压缩方法因速度与准确率之间的权衡未被主流推理引擎采用。

Method: 提出KVzap，一种快速、输入自适应的KVzip近似方法，可在预填充和解码阶段有效工作。

Result: 在多个长上下文和推理任务中，KVzap实现2-4倍的KV缓存压缩，精度损失可忽略，且在KVpress排行榜上表现最优。

Conclusion: KVzap通过高效压缩KV缓存，在保持高精度的同时显著提升推理效率，具备实际部署潜力。

Abstract: Growing context lengths in transformer-based language models have made the key-value (KV) cache a critical inference bottleneck. While many KV cache pruning methods have been proposed, they have not yet been adopted in major inference engines due to speed--accuracy trade-offs. We introduce KVzap, a fast, input-adaptive approximation of KVzip that works in both prefilling and decoding. On Qwen3-8B, Llama-3.1-8B-Instruct, and Qwen3-32B across long-context and reasoning tasks, KVzap achieves $2$--$4\times$ KV cache compression with negligible accuracy loss and achieves state-of-the-art performance on the KVpress leaderboard. Code and models are available at https://github.com/NVIDIA/kvpress.

</details>


### [185] [Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification](https://arxiv.org/abs/2601.07892)
*Hong Huang,Decheng Wu,Qiangqiang Hu,Guanghua Yu,Jinhai Yang,Jianchen Zhu,Xue Liu,Dapeng Wu*

Main category: cs.LG

TL;DR: Sherry提出了一种硬件高效的三值量化框架，通过3:4细粒度稀疏性实现1.25位的规则化打包，解决了现有方法在比特对齐与推理速度之间的矛盾。针对稀疏三值训练中的权重陷落问题，引入Arenas机制以维持表示多样性。实验表明，该方法在保持SOTA性能的同时显著减小模型尺寸，在Intel i7-14700HX CPU上实现零精度损失、25%比特节省和10%加速。


<details>
  <summary>Details</summary>
Motivation: 当前三值量化在边缘设备部署中受限于内存和计算资源，且现有方法在比特对齐与推理效率之间存在根本性矛盾：2比特对齐导致比特浪费，1.67比特不规则打包降低推理速度。因此需要一种兼顾硬件效率与性能的新方法。

Method: 提出Sherry框架，采用3:4细粒度稀疏性将四个权重打包进五个比特，实现1.25比特的规则化宽度；引入Arenas机制，通过退火残差突触策略缓解训练过程中的权重陷落问题，提升表示多样性。

Result: 在LLaMA-3.2上五项基准测试中达到SOTA三值量化性能；1B模型在Intel i7-14700HX CPU上实现零精度损失，比特节省25%，推理速度提升10%。

Conclusion: Sherry通过创新的量化打包方式与训练优化机制，有效解决了三值量化在硬件部署中的效率与性能难题，为轻量级大模型在边缘设备上的应用提供了可行路径。

Abstract: The deployment of Large Language Models (LLMs) on resource-constrained edge devices is increasingly hindered by prohibitive memory and computational requirements. While ternary quantization offers a compelling solution by reducing weights to {-1, 0, +1}, current implementations suffer from a fundamental misalignment with commodity hardware. Most existing methods must choose between 2-bit aligned packing, which incurs significant bit wastage, or 1.67-bit irregular packing, which degrades inference speed. To resolve this tension, we propose Sherry, a hardware-efficient ternary quantization framework. Sherry introduces a 3:4 fine-grained sparsity that achieves a regularized 1.25-bit width by packing blocks of four weights into five bits, restoring power-of-two alignment. Furthermore, we identify weight trapping issue in sparse ternary training, which leads to representational collapse. To address this, Sherry introduces Arenas, an annealing residual synapse mechanism that maintains representational diversity during training. Empirical evaluations on LLaMA-3.2 across five benchmarks demonstrate that Sherry matches state-of-the-art ternary performance while significantly reducing model size. Notably, on an Intel i7-14700HX CPU, our 1B model achieves zero accuracy loss compared to SOTA baselines while providing 25% bit savings and 10% speed up. The code is available at https://github.com/Tencent/AngelSlim .

</details>


### [186] [Large Language Models and Algorithm Execution: Application to an Arithmetic Function](https://arxiv.org/abs/2601.07898)
*Farah Ben Slama,Frédéric Armetta*

Main category: cs.LG

TL;DR: 本文提出一种名为LLM-DAL的新型训练方法，通过专门的监督学习引导大语言模型进行推理分解，以增强其执行复杂算法的能力。实验表明，合理设计的训练策略能显著提升大语言模型在算法推理与泛化方面的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具备强大的统计学习和泛化能力，但在内部化处理数据及自主执行算法方面存在局限，因此亟需提升其算法执行能力。

Method: 采用专门的监督训练方法，聚焦于推理分解，构建并训练名为LLM-DAL的模型，以引导大语言模型更有效地学习算法执行逻辑。

Result: 经过优化训练后，大语言模型在复杂算法推理和泛化任务上的表现得到显著提升，验证了推理分解训练的有效性。

Conclusion: 通过针对性的监督训练与推理分解策略，大语言模型能够有效扩展其算法执行能力，为未来智能系统的发展提供了可行路径。

Abstract: Large Language Models (LLMs) have recently developed new advanced functionalities. Their effectiveness relies on statistical learning and generalization capabilities. However, they face limitations in internalizing the data they process and struggle, for instance, to autonomously execute algorithms. In this paper, we investigate the possibility of extending these models' capabilities to algorithm execution through specialized supervised training focused on reasoning decomposition. We introduce a training model called LLM-DAL (Large Language Model - Decompositional Algorithmic Learning), through which we demonstrate that LLMs' ability to perform complex algorithmic inferences and generalize can be significantly improved when the training method is properly designed to guide the model in its learning process.

</details>


### [187] [Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning](https://arxiv.org/abs/2601.07903)
*Jianqi Zhang,Jingyao Wang,Wenwen Qiang,Fanjiang Xu,Changwen Zheng*

Main category: cs.LG

TL;DR: 本文提出LVICL方法，通过向冻结的大型语言模型（LLM）注入可学习的上下文向量来提升时间序列预测性能，避免了微调带来的计算开销。该方法利用上下文学习（ICL）思想，自适应地从多个示例中提取压缩的上下文向量，并将其注入LLM每一层，以增强其对时间序列预测任务的表现。相比传统ICL，该方法不增加提示长度，且能抑制有害信息，从而有效提升预测精度。大量实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在时间序列预测任务中表现良好，但其预训练语料与时间序列数据存在显著差异，直接应用时预测质量难以保证；微调虽可缓解此问题，却带来巨大计算成本。因此，如何在保持模型参数冻结的前提下提升预测性能成为关键挑战。

Method: 提出LVICL方法，采用可学习的上下文向量适配器，从多个时间序列示例中自适应提取一个压缩的上下文向量，并在前向传播过程中将该向量注入到LLM的每一层中，以激发其上下文学习能力。

Result: 实验结果表明，LVICL在保持所有LLM参数冻结的情况下，显著提升了时间序列预测的准确性，同时避免了因增加提示长度或微调带来的额外开销。

Conclusion: LVICL是一种高效且有效的零样本时间序列预测方法，通过向冻结的LLM注入自适应上下文向量，在不增加计算负担的前提下显著提升了预测性能，为大模型在时间序列任务中的应用提供了新思路。

Abstract: The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.

</details>


### [188] [Towards Specialized Generalists: A Multi-Task MoE-LoRA Framework for Domain-Specific LLM Adaptation](https://arxiv.org/abs/2601.07935)
*Yuxin Yang,Aoxiong Zeng,Xiangquan Yang*

Main category: cs.LG

TL;DR: Med-MoE-LoRA 提出一种结合 Mixture-of-Experts (MoE) 与 Low-Rank Adaptation (LoRA) 的新框架，用于高效实现医学领域的多任务适配。通过不对称专家分布和知识保护插件，缓解了稳定性-可塑性困境与任务干扰问题，在多个临床 NLP 任务中表现优于标准 LoRA 和传统 MoE 架构，同时保留模型的通用认知能力。


<details>
  <summary>Details</summary>
Motivation: 适应大型语言模型（LLM）到医学等专业领域时，面临两个核心挑战：一是‘稳定性-可塑性困境’，即在学习复杂临床知识的同时避免遗忘通用世界知识；二是‘任务干扰’，不同子任务（如诊断、报告摘要、药物相互作用预测）竞争有限的低秩参数空间。

Method: 提出 Med-MoE-LoRA 框架，融合 MoE 与 LoRA，采用深层更高密度的 LoRA 专家分布以捕捉复杂语义抽象，并引入‘知识保护插件’隔离通用推理能力。通过软合并与自适应路由及秩级解耦机制，降低任务间干扰。

Result: 实验表明，该方法在多个医学自然语言处理基准测试中持续优于标准 LoRA 和传统 MoE 架构，有效提升多任务性能，同时保持模型的通用认知能力。

Conclusion: Med-MoE-LoRA 为医学领域 LLM 的高效多任务适配提供了一种有效解决方案，兼顾知识保留与任务性能，具有良好的应用前景。

Abstract: The rapid evolution of Large Language Models (LLMs) has shifted focus from general-purpose capabilities to domain-specific expertise. However, adapting LLMs to specialized fields such as medicine presents two challenge: (1) the "Stability-Plasticity Dilemma", where the model must acquire complex clinical knowledge without suffering from catastrophic forgetting of general world knowledge; and (2) "Task Interference", where disparate sub-tasks, such as medical diagnosis, report summarization, and drug-drug interaction prediction, compete for limited low-rank parameter space. In this paper, we propose Med-MoE-LoRA, a novel framework that integrates Mixture-of-Experts (MoE) with Low-Rank Adaptation (LoRA) to enable efficient multi-task domain adaptation, especially for medical scenarios. Drawing inspiration from recent advances, our framework employs an asymmetric expert distribution where deeper layers are equipped with a higher density of LoRA experts to capture complex semantic abstractions. We further introduce a "Knowledge-Preservation Plugin", inspired by LoRA MoE, to isolate and protect general-purpose reasoning. By utilizing soft merging with adaptive routing and rank-wise decoupling, Med-MoE-LoRA achieves superior performance in medical benchmarks while reducing interference. Experimental results demonstrate that our approach consistently outperforms standard LoRA and conventional MoE architectures across multiple clinical NLP tasks while retaining the model's general cognitive capabilities.

</details>


### [189] [Coupled Diffusion-Encoder Models for Reconstruction of Flow Fields](https://arxiv.org/abs/2601.07946)
*AmirPouya Hemmasian,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 提出DiffCoder框架，结合概率扩散模型与卷积ResNet编码器，实现流场数据的高效压缩与高保真重建。在强压缩下，DiffCoder显著提升谱精度并更好保留流场的统计特性，优于传统VAE方法。


<details>
  <summary>Details</summary>
Motivation: 传统自编码器如变分自编码器（VAE）在强压缩下难以保持流场的高阶统计结构，需要更先进的生成先验来提升重构质量。

Method: 采用端到端训练的耦合框架，使用卷积ResNet编码器压缩流场至低维潜在表示，再通过概率扩散模型学习基于压缩状态的生成先验，以恢复分布和频谱特性。

Result: 在柯尔莫戈洛夫流动数据集上，强压缩下DiffCoder显著优于VAE，在谱准确性和分布结构保持方面表现更佳；中等压缩时大尺寸VAE仍具竞争力，表明扩散先验在信息瓶颈严重时优势明显。

Conclusion: 扩散生成解码为复杂流场提供了紧凑且统计一致的表征新路径，具有重要应用前景。

Abstract: Data-driven flow-field reconstruction typically relies on autoencoder architectures that compress high-dimensional states into low-dimensional latent representations. However, classical approaches such as variational autoencoders (VAEs) often struggle to preserve the higher-order statistical structure of fluid flows when subjected to strong compression. We propose DiffCoder, a coupled framework that integrates a probabilistic diffusion model with a conventional convolutional ResNet encoder and trains both components end-to-end. The encoder compresses the flow field into a latent representation, while the diffusion model learns a generative prior over reconstructions conditioned on the compressed state. This design allows DiffCoder to recover distributional and spectral properties that are not strictly required for minimizing pointwise reconstruction loss but are critical for faithfully representing statistical properties of the flow field. We evaluate DiffCoder and VAE baselines across multiple model sizes and compression ratios on a challenging dataset of Kolmogorov flow fields. Under aggressive compression, DiffCoder significantly improves the spectral accuracy while VAEs exhibit substantial degradation. Although both methods show comparable relative L2 reconstruction error, DiffCoder better preserves the underlying distributional structure of the flow. At moderate compression levels, sufficiently large VAEs remain competitive, suggesting that diffusion-based priors provide the greatest benefit when information bottlenecks are severe. These results demonstrate that the generative decoding by diffusion offers a promising path toward compact, statistically consistent representations of complex flow fields.

</details>


### [190] [Hybrid SARIMA LSTM Model for Local Weather Forecasting: A Residual Learning Approach for Data Driven Meteorological Prediction](https://arxiv.org/abs/2601.07951)
*Shreyas Rajeev,Karthik Mudenahalli Ashoka,Amit Mallappa Tiparaddi*

Main category: cs.LG

TL;DR: 本文提出一种混合SARIMA-LSTM模型，用于提升长期气温预测的准确性。该模型通过残差学习策略将温度数据分解为可预测的气候成分和非线性天气成分：SARIMA捕捉长期季节性趋势，LSTM则专注于学习SARIMA未能捕获的非线性残差。结合统计模型的稳定性与深度学习的适应性，有效减少误差传播，提升长周期预测性能。


<details>
  <summary>Details</summary>
Motivation: 长期大气变量预测受大气系统混沌特性影响，传统SARIMA模型因假设平稳性无法处理非线性突变，而LSTM在开环预测中易因误差累积导致发散，亟需一种兼具稳定性与非线性建模能力的混合方法。

Method: 提出SARIMA-LSTM混合架构，采用残差学习策略：先用SARIMA拟合温度数据中的周期性、确定性成分，再将残差输入LSTM进行非线性特征学习，最终融合两者输出实现预测。

Result: 实验表明，该混合模型在长期气温预测任务中显著优于单一SARIMA或LSTM模型，有效降低系统性误差，减少对突发升温/降温的误判，且在多步预测中保持更稳定的性能。

Conclusion: 所提出的SARIMA-LSTM混合模型成功融合了统计模型的稳定性和深度学习的非线性表达能力，为复杂气象时间序列的长期预测提供了一种高效、鲁棒的解决方案。

Abstract: Accurately forecasting long-term atmospheric variables remains a defining challenge in meteorological science due to the chaotic nature of atmospheric systems. Temperature data represents a complex superposition of deterministic cyclical climate forces and stochastic, short-term fluctuations. While planetary mechanics drive predictable seasonal periodicities, rapid meteorological changes such as thermal variations, pressure anomalies, and humidity shifts introduce nonlinear volatilities that defy simple extrapolation. Historically, the Seasonal Autoregressive Integrated Moving Average (SARIMA) model has been the standard for modeling historical weather data, prized for capturing linear seasonal trends. However, SARIMA operates under strict assumptions of stationarity, failing to capture abrupt, nonlinear transitions. This leads to systematic residual errors, manifesting as the under-prediction of sudden spikes or the over-smoothing of declines. Conversely, Deep Learning paradigms, specifically Long Short-Term Memory (LSTM) networks, demonstrate exceptional efficacy in handling intricate time-series data. By utilizing memory gates, LSTMs learn complex nonlinear dependencies. Yet, LSTMs face instability in open-loop forecasting; without ground truth feedback, minor deviations compound recursively, causing divergence. To resolve these limitations, we propose a Hybrid SARIMA-LSTM architecture. This framework employs a residual-learning strategy to decompose temperature into a predictable climate component and a nonlinear weather component. The SARIMA unit models the robust, long-term seasonal trend, while the LSTM is trained exclusively on the residuals the nonlinear errors SARIMA fails to capture. By fusing statistical stability with neural plasticity, this hybrid approach minimizes error propagation and enhances long-horizon accuracy.

</details>


### [191] [InfGraND: An Influence-Guided GNN-to-MLP Knowledge Distillation](https://arxiv.org/abs/2601.08033)
*Amir Eskandari,Aman Anand,Elyas Rashno,Farhana Zulkernine*

Main category: cs.LG

TL;DR: InfGraND is a novel knowledge distillation framework that transfers knowledge from GNNs to MLPs by focusing on structurally influential nodes, improving performance in low-latency and resource-constrained scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing knowledge distillation methods for GNN-to-MLP transfer either treat all nodes uniformly or use graph-agnostic criteria, ignoring the structural importance of nodes in graphs. This limits performance, especially in latency-sensitive applications.

Method: InfGraND identifies structurally influential nodes using influence analysis and prioritizes them during knowledge distillation. It also pre-computes multi-hop neighborhood features once, reducing inference-time overhead.

Result: InfGraND outperforms previous GNN-to-MLP distillation methods across seven homophilic graph benchmarks in both transductive and inductive settings, demonstrating superior performance and practicality for real-world low-latency applications.

Conclusion: InfGraND effectively enhances MLP performance by incorporating structural awareness through influence-guided distillation and pre-computed neighborhood features, making it a promising solution for resource-constrained, high-speed inference tasks.

Abstract: Graph Neural Networks (GNNs) are the go-to model for graph data analysis. However, GNNs rely on two key operations - aggregation and update, which can pose challenges for low-latency inference tasks or resource-constrained scenarios. Simple Multi-Layer Perceptrons (MLPs) offer a computationally efficient alternative. Yet, training an MLP in a supervised setting often leads to suboptimal performance. Knowledge Distillation (KD) from a GNN teacher to an MLP student has emerged to bridge this gap. However, most KD methods either transfer knowledge uniformly across all nodes or rely on graph-agnostic indicators such as prediction uncertainty. We argue this overlooks a more fundamental, graph-centric inquiry: "How important is a node to the structure of the graph?" We introduce a framework, InfGraND, an Influence-guided Graph KNowledge Distillation from GNN to MLP that addresses this by identifying and prioritizing structurally influential nodes to guide the distillation process, ensuring that the MLP learns from the most critical parts of the graph. Additionally, InfGraND embeds structural awareness in MLPs through one-time multi-hop neighborhood feature pre-computation, which enriches the student MLP's input and thus avoids inference-time overhead. Our rigorous evaluation in transductive and inductive settings across seven homophilic graph benchmark datasets shows InfGraND consistently outperforms prior GNN to MLP KD methods, demonstrating its practicality for numerous latency-critical applications in real-world settings.

</details>


### [192] [Riemannian Zeroth-Order Gradient Estimation with Structure-Preserving Metrics for Geodesically Incomplete Manifolds](https://arxiv.org/abs/2601.08039)
*Shaocong Ma,Heng Huang*

Main category: cs.LG

TL;DR: 本文研究在黎曼度量$g$测地不完整的情况下，如何通过构造保持结构的完备度量$g'$来逼近驻点。基于此，重新分析了经典的对称两点零阶估计器的均方误差，并从纯内在几何视角建立随机梯度下降的收敛性保证。在一定条件下，$g'$下的$\varepsilon$-驻点也对应于$g$下的$\varepsilon$-驻点，达到与测地完备情形最优复杂度一致的结果。实验验证了理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 在测地不完整的黎曼流形上进行优化时，传统方法面临难以保证收敛性和驻点有效性的问题。为克服这一挑战，需设计既能保持几何结构又具备测地完备性的新度量。

Method: 构造结构保持且测地完备的新度量$g'$，确保其驻点与原度量$g$一致；采用内在视角分析对称两点零阶估计器的均方误差；基于该分析，推导出使用该估计器的随机梯度下降算法的收敛性。

Result: 在额外合理假设下，$g'$中的$\varepsilon$-驻点即为$g$中的$\varepsilon$-驻点，收敛复杂度达到现有最优水平；合成问题和网格优化任务的实验验证了方法的稳定性和有效性。

Conclusion: 提出了一种在测地不完整黎曼流形上实现可靠零阶优化的框架，通过构造合适的完备度量并结合内在分析，实现了与测地完备情况相当的收敛性能，且在实际任务中表现出良好的稳定性。

Abstract: In this paper, we study Riemannian zeroth-order optimization in settings where the underlying Riemannian metric $g$ is geodesically incomplete, and the goal is to approximate stationary points with respect to this incomplete metric. To address this challenge, we construct structure-preserving metrics that are geodesically complete while ensuring that every stationary point under the new metric remains stationary under the original one. Building on this foundation, we revisit the classical symmetric two-point zeroth-order estimator and analyze its mean-squared error from a purely intrinsic perspective, depending only on the manifold's geometry rather than any ambient embedding. Leveraging this intrinsic analysis, we establish convergence guarantees for stochastic gradient descent with this intrinsic estimator. Under additional suitable conditions, an $ε$-stationary point under the constructed metric $g'$ also corresponds to an $ε$-stationary point under the original metric $g$, thereby matching the best-known complexity in the geodesically complete setting. Empirical studies on synthetic problems confirm our theoretical findings, and experiments on a practical mesh optimization task demonstrate that our framework maintains stable convergence even in the absence of geodesic completeness.

</details>


### [193] [Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment](https://arxiv.org/abs/2601.08089)
*Qitao Tan,Xiaoying Song,Ningxi Cheng,Ninghao Liu,Xiaoming Zhai,Lingzi Hong,Yanzhi Wang,Zhen Xiang,Geng Yuan*

Main category: cs.LG

TL;DR: 提出了一种名为Q-realign的后训练量化方法，用于在不依赖微调的情况下恢复大语言模型的安全对齐，通过重构表示结构实现压缩与安全双重目标，显著降低内存使用和GPU时间，可在单张RTX 4090上40分钟内修复7B模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法在微调过程中嵌入安全恢复或依赖微调衍生先验进行事后修正，导致安全对齐与训练紧密耦合，带来高计算开销和复杂工作流。

Method: 基于后训练量化，通过分析表示结构将量化重新定义为压缩与安全的双目标过程，实现安全对齐与微调解耦，并无缝集成到现代部署流程中。

Result: 实验表明，该方法能显著减少不安全行为，同时保持任务性能，大幅降低内存占用和GPU耗时；可在单张RTX 4090上40分钟内恢复7B模型的安全对齐。

Conclusion: Q-realign提供了一种实用、即插即用的安全感知部署解决方案，有效分离安全对齐与微调过程，具有高效、低开销的优势。

Abstract: Public large language models (LLMs) are typically safety-aligned during pretraining, yet task-specific fine-tuning required for deployment often erodes this alignment and introduces safety risks. Existing defenses either embed safety recovery into fine-tuning or rely on fine-tuning-derived priors for post-hoc correction, leaving safety recovery tightly coupled with training and incurring high computational overhead and a complex workflow. To address these challenges, we propose \texttt{Q-realign}, a post-hoc defense method based on post-training quantization, guided by an analysis of representational structure. By reframing quantization as a dual-objective procedure for compression and safety, \texttt{Q-realign} decouples safety alignment from fine-tuning and naturally piggybacks into modern deployment pipelines. Experiments across multiple models and datasets demonstrate that our method substantially reduces unsafe behaviors while preserving task performance, with significant reductions in memory usage and GPU hours. Notably, our approach can recover the safety alignment of a fine-tuned 7B LLM on a single RTX 4090 within 40 minutes. Overall, our work provides a practical, turnkey solution for safety-aware deployment.

</details>


### [194] [Local-Global Feature Fusion for Subject-Independent EEG Emotion Recognition](https://arxiv.org/abs/2601.08094)
*Zheng Zhou,Isabella McEvoy,Camilo E. Valderrama*

Main category: cs.LG

TL;DR: 提出一种融合局部通道特征和全局试验特征的双分支注意力融合框架，结合域对抗正则化，有效提升跨被试情绪识别性能，在SEED-VII数据集上实现约40%的7分类平均准确率。


<details>
  <summary>Details</summary>
Motivation: 解决脑电情绪识别中因个体差异大、短时噪声数据难提取鲁棒表示的问题。

Method: 采用局部通道级差分熵与图论特征拼接构建局部表示，全局级别提取时域、频域及复杂度特征；通过双分支Transformer进行注意力融合，并引入域对抗正则化，结合强度阈值过滤样本。

Result: 在留一被试交叉验证下，该方法显著优于单视图和传统基线模型，7类情绪识别平均准确率达约40%。

Conclusion: 所提融合框架能有效缓解个体差异影响，提升跨被试情绪识别的泛化能力，具有良好的应用潜力。

Abstract: Subject-independent EEG emotion recognition is challenged by pronounced inter-subject variability and the difficulty of learning robust representations from short, noisy recordings. To address this, we propose a fusion framework that integrates (i) local, channel-wise descriptors and (ii) global, trial-level descriptors, improving cross-subject generalization on the SEED-VII dataset. Local representations are formed per channel by concatenating differential entropy with graph-theoretic features, while global representations summarize time-domain, spectral, and complexity characteristics at the trial level. These representations are fused in a dual-branch transformer with attention-based fusion and domain-adversarial regularization, with samples filtered by an intensity threshold. Experiments under a leave-one-subject-out protocol demonstrate that the proposed method consistently outperforms single-view and classical baselines, achieving approximately 40% mean accuracy in 7-class subject-independent emotion recognition. The code has been released at https://github.com/Danielz-z/LGF-EEG-Emotion.

</details>


### [195] [STO-RL: Offline RL under Sparse Rewards via LLM-Guided Subgoal Temporal Order](https://arxiv.org/abs/2601.08107)
*Chengyang Gu,Yuxin Pan,Hui Xiong,Yize Chen*

Main category: cs.LG

TL;DR: STO-RL利用大语言模型（LLM）生成具有时序结构的子目标序列，通过基于潜在的奖励塑造方法将稀疏奖励转化为密集且时间一致的信号，从而在离线强化学习中有效解决长时程任务中的稀疏奖励问题。该方法在多个离线基准上显著优于现有先进方法，具备更快收敛、更高成功率和更短轨迹表现，并对不完美或噪声的子目标序列具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有目标条件化和分层离线强化学习方法虽能分解长时程任务并生成中间奖励，但忽视了子目标间的时序依赖关系，且依赖不精确的奖励塑形，导致策略性能不佳。为克服这些问题，需引入更合理的时序结构与理论支撑的奖励设计。

Method: 提出STO-RL框架，利用大语言模型生成有序子目标序列及状态到子目标阶段的映射关系；基于此构建时序一致的潜在奖励函数，实现密集且合理的目标进展信号，增强离线训练效果。

Result: 在四个离散与连续稀疏奖励基准上，STO-RL持续优于当前最先进方法，表现出更快收敛速度、更高成功率和更短轨迹长度；消融实验验证其对噪声子目标序列的鲁棒性。

Conclusion: LLM引导的子目标时序结构结合理论基础的奖励塑形，为长时程离线强化学习提供了一种实用且可扩展的解决方案。

Abstract: Offline reinforcement learning (RL) enables policy learning from pre-collected datasets, avoiding costly and risky online interactions, but it often struggles with long-horizon tasks involving sparse rewards. Existing goal-conditioned and hierarchical offline RL methods decompose such tasks and generate intermediate rewards to mitigate limitations of traditional offline RL, but usually overlook temporal dependencies among subgoals and rely on imprecise reward shaping, leading to suboptimal policies. To address these issues, we propose STO-RL (Offline RL using LLM-Guided Subgoal Temporal Order), an offline RL framework that leverages large language models (LLMs) to generate temporally ordered subgoal sequences and corresponding state-to-subgoal-stage mappings. Using this temporal structure, STO-RL applies potential-based reward shaping to transform sparse terminal rewards into dense, temporally consistent signals, promoting subgoal progress while avoiding suboptimal solutions. The resulting augmented dataset with shaped rewards enables efficient offline training of high-performing policies. Evaluations on four discrete and continuous sparse-reward benchmarks demonstrate that STO-RL consistently outperforms state-of-the-art offline goal-conditioned and hierarchical RL baselines, achieving faster convergence, higher success rates, and shorter trajectories. Ablation studies further confirm STO-RL's robustness to imperfect or noisy LLM-generated subgoal sequences, demonstrating that LLM-guided subgoal temporal structures combined with theoretically grounded reward shaping provide a practical and scalable solution for long-horizon offline RL.

</details>


### [196] [Intra-tree Column Subsampling Hinders XGBoost Learning of Ratio-like Interactions](https://arxiv.org/abs/2601.08121)
*Mykola Pinchuk*

Main category: cs.LG

TL;DR: 研究发现，在XGBoost中，树内列子采样会干扰模型对比率类信号的合成能力，尤其在缺乏显式比率特征时性能显著下降；引入人工构造的比率特征可消除该负面影响。


<details>
  <summary>Details</summary>
Motivation: 许多实际问题中的信号需要通过组合多个原始测量值才能显现，如比率和率。在梯度提升树中，这种组合依赖于模型通过协调分裂来隐式合成，而列子采样可能破坏这一过程。

Method: 设计了两种具有抵消结构的合成数据生成过程，模拟两个原始特征共享强噪声因子但目标依赖微小差异因子的情形；通过改变colsample_bylevel和colsample_bynode参数（0.4, 0.6, 0.8, 0.9），比较仅使用原始特征与加入人工比率特征时的性能表现，并结合路径级共使用度量分析机制。

Result: 在无显式比率特征时，列子采样显著降低测试PR-AUC，最差情况下相对下降达54%；当加入人工比率特征后，性能下降现象基本消失；共使用度量下降与性能恶化区域一致。

Conclusion: 若数据中存在比率类结构，应避免使用树内列子采样，或主动引入预期的比率特征以保障模型性能。

Abstract: Many applied problems contain signal that becomes clear only after combining multiple raw measurements. Ratios and rates are common examples. In gradient boosted trees, this combination is not an explicit operation: the model must synthesize it through coordinated splits on the component features. We study whether intra-tree column subsampling in XGBoost makes that synthesis harder. We use two synthetic data generating processes with cancellation-style structure. In both, two primitive features share a strong nuisance factor, while the target depends on a smaller differential factor. A log ratio cancels the nuisance and isolates the signal. We vary colsample_bylevel and colsample_bynode over s in {0.4, 0.6, 0.8, 0.9}, emphasizing mild subsampling (s >= 0.8). A control feature set includes the engineered ratio, removing the need for synthesis. Across both processes, intra-tree column subsampling reduces test PR-AUC in the primitives-only setting. In the main process the relative decrease reaches 54 percent when both parameters are set to 0.4. The effect largely disappears when the engineered ratio is present. A path-based co-usage metric drops in the same cells where performance deteriorates. Practically, if ratio-like structure is plausible, either avoid intra-tree subsampling or include the intended ratio features.

</details>


### [197] [Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies](https://arxiv.org/abs/2601.08136)
*Zeyang Li,Sunbochen Tang,Navid Azizan*

Main category: cs.LG

TL;DR: This paper unifies noise-expectation and gradient-expectation methods for diffusion policies via reverse flow matching (RFM), using a reverse inferential view and Langevin Stein operators to reduce variance. RFM extends to flow policies and enables optimal use of Q-values and gradients, improving training stability and performance in online RL.


<details>
  <summary>Details</summary>
Motivation: Online reinforcement learning faces challenges in training diffusion and flow policies due to the absence of direct samples from the target distribution, which is typically an unnormalized Boltzmann distribution defined by the Q-function. Existing methods for diffusion policies fall into two distinct families—noise-expectation and gradient-expectation—but their formal relationship and potential synthesis remain unclear.

Method: The paper proposes a unified framework called reverse flow matching (RFM), which formulates the training target as a posterior mean estimation problem under a reverse inferential perspective. It introduces Langevin Stein operators to construct zero-mean control variates, leading to a general class of estimators that reduce importance sampling variance. This framework subsumes both noise-expectation and gradient-expectation methods as special cases.

Result: RFM enables the extension of Boltzmann distribution targeting from diffusion to flow policies and allows for the principled combination of Q-value and Q-gradient information, resulting in a minimum-variance estimator that improves training efficiency and stability. Experiments show superior performance of RFM-based flow policies on continuous-control benchmarks compared to diffusion policy baselines.

Conclusion: Reverse flow matching provides a theoretically grounded, unified approach to training diffusion and flow policies in online RL without direct samples, offering enhanced flexibility, reduced variance, and improved empirical performance.

Abstract: Diffusion and flow policies are gaining prominence in online reinforcement learning (RL) due to their expressive power, yet training them efficiently remains a critical challenge. A fundamental difficulty in online RL is the lack of direct samples from the target distribution; instead, the target is an unnormalized Boltzmann distribution defined by the Q-function. To address this, two seemingly distinct families of methods have been proposed for diffusion policies: a noise-expectation family, which utilizes a weighted average of noise as the training target, and a gradient-expectation family, which employs a weighted average of Q-function gradients. Yet, it remains unclear how these objectives relate formally or if they can be synthesized into a more general formulation. In this paper, we propose a unified framework, reverse flow matching (RFM), which rigorously addresses the problem of training diffusion and flow models without direct target samples. By adopting a reverse inferential perspective, we formulate the training target as a posterior mean estimation problem given an intermediate noisy sample. Crucially, we introduce Langevin Stein operators to construct zero-mean control variates, deriving a general class of estimators that effectively reduce importance sampling variance. We show that existing noise-expectation and gradient-expectation methods are two specific instances within this broader class. This unified view yields two key advancements: it extends the capability of targeting Boltzmann distributions from diffusion to flow policies, and enables the principled combination of Q-value and Q-gradient information to derive an optimal, minimum-variance estimator, thereby improving training efficiency and stability. We instantiate RFM to train a flow policy in online RL, and demonstrate improved performance on continuous-control benchmarks compared to diffusion policy baselines.

</details>


### [198] [Dynamic Graph Structure Learning via Resistance Curvature Flow](https://arxiv.org/abs/2601.08149)
*Chaoqun Fei,Huanjiang Liu,Tinglve Zhou,Yangyang Li,Tianyong Hao*

Main category: cs.LG

TL;DR: 本文提出了一种名为电阻曲率流（RCF）的新几何演化框架，通过引入电路物理中的有效电阻概念，将计算昂贵的曲率优化转化为高效的矩阵运算，实现了超过100倍的计算加速，同时保持了与Ollivier-Ricci曲率流（OCF）相当的几何优化能力。该方法通过曲率梯度引导边权重重分配，消除拓扑噪声并强化局部聚类结构，具有良好的曼达托增强和降噪机制，并兼容深度学习模型。基于此框架设计了图优化算法DGSL-RCF，在深度度量学习、流形学习和图结构学习任务中均显著提升了表示质量和下游性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态图构建方法依赖欧氏距离，难以捕捉数据流形的内在曲率特征；尽管OCF能动态优化拓扑，但其基于最优传输（Wasserstein距离）的计算复杂度极高，难以应用于大规模数据集和深度学习框架，亟需一种高效且保持几何优化能力的新方法。

Method: 提出电阻曲率流（RCF）框架，利用有效电阻替代传统最优传输，将曲率优化问题转化为高效的矩阵操作，实现快速计算；通过曲率梯度驱动边权重调整，优化图结构以增强局部聚类、抑制噪声，并支持与深度学习模型的集成。

Result: RCF实现超过100倍的计算加速，同时保持与OCF相当的几何优化效果；DGSL-RCF在多个任务中显著提升表示质量与下游任务性能，验证了其有效性与实用性。

Conclusion: RCF为大规模几何表示学习提供了高效且可扩展的解决方案，兼具理论深度与实际应用价值，是连接几何建模与深度学习的重要桥梁。

Abstract: Geometric Representation Learning (GRL) aims to approximate the non-Euclidean topology of high-dimensional data through discrete graph structures, grounded in the manifold hypothesis. However, traditional static graph construction methods based on Euclidean distance often fail to capture the intrinsic curvature characteristics of the data manifold. Although Ollivier-Ricci Curvature Flow (OCF) has proven to be a powerful tool for dynamic topological optimization, its core reliance on Optimal Transport (Wasserstein distance) leads to prohibitive computational complexity, severely limiting its application in large-scale datasets and deep learning frameworks. To break this bottleneck, this paper proposes a novel geometric evolution framework: Resistance Curvature Flow (RCF). Leveraging the concept of effective resistance from circuit physics, RCF transforms expensive curvature optimization into efficient matrix operations. This approach achieves over 100x computational acceleration while maintaining geometric optimization capabilities comparable to OCF. We provide an in-depth exploration of the theoretical foundations and dynamical principles of RCF, elucidating how it guides the redistribution of edge weights via curvature gradients to eliminate topological noise and strengthen local cluster structures. Furthermore, we provide a mechanistic explanation of RCF's role in manifold enhancement and noise suppression, as well as its compatibility with deep learning models. We design a graph optimization algorithm, DGSL-RCF, based on this framework. Experimental results across deep metric learning, manifold learning, and graph structure learning demonstrate that DGSL-RCF significantly improves representation quality and downstream task performance.

</details>


### [199] [VBO-MI: A Fully Gradient-Based Bayesian Optimization Framework Using Variational Mutual Information Estimation](https://arxiv.org/abs/2601.08172)
*Farhad Mirkarimi*

Main category: cs.LG

TL;DR: 提出VBO-MI，一种基于变分互信息的全梯度贝叶斯优化框架，通过动作-评论家架构实现端到端梯度流，显著降低计算开销（最高减少100倍FLOPs），在高维合成函数和真实世界任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统BNN-BO框架存在后验采样和获取函数优化成本高的问题，亟需更高效的替代方案以提升可扩展性。

Method: 采用变分互信息估计，构建动作网（action-net）与变分评论家（variational critic）组成的演员-评论家架构，实现端到端梯度优化，避免传统内层优化瓶颈。

Result: 在多种基准测试中，包括高维合成函数、偏微分方程优化、月球着陆器控制及分类害虫控制任务上，VBO-MI均达到或优于基线性能，且计算效率大幅提升。

Conclusion: VBO-MI是一种高效、可扩展的贝叶斯优化方法，通过全梯度框架有效解决了传统BNN-BO的计算瓶颈，适用于复杂黑箱优化任务。

Abstract: Many real-world tasks require optimizing expensive black-box functions accessible only through noisy evaluations, a setting commonly addressed with Bayesian optimization (BO). While Bayesian neural networks (BNNs) have recently emerged as scalable alternatives to Gaussian Processes (GPs), traditional BNN-BO frameworks remain burdened by expensive posterior sampling and acquisition function optimization. In this work, we propose {VBO-MI} (Variational Bayesian Optimization with Mutual Information), a fully gradient-based BO framework that leverages recent advances in variational mutual information estimation. To enable end-to-end gradient flow, we employ an actor-critic architecture consisting of an {action-net} to navigate the input space and a {variational critic} to estimate information gain. This formulation effectively eliminates the traditional inner-loop acquisition optimization bottleneck, achieving up to a {$10^2 \times$ reduction in FLOPs} compared to BNN-BO baselines. We evaluate our method on a diverse suite of benchmarks, including high-dimensional synthetic functions and complex real-world tasks such as PDE optimization, the Lunar Lander control problem, and categorical Pest Control. Our experiments demonstrate that VBO-MI consistently provides the same or superior optimization performance and computational scalability over the baselines.

</details>


### [200] [One-Shot Federated Ridge Regression: Exact Recovery via Sufficient Statistic Aggregation](https://arxiv.org/abs/2601.08216)
*Zahir Alsulaimawi*

Main category: cs.LG

TL;DR: 本文提出一种无需迭代通信的联邦线性回归方法，通过客户端一次性上传局部统计量（格拉姆矩阵和矩向量），服务器通过单次矩阵求逆即可精确恢复全局解。在满足覆盖条件时，可实现与集中式岭回归完全一致的解；对于非覆盖情况，提供基于谱性质的非渐近误差界。通信复杂度从传统方法的\(\mathcal{O}(Rd)\)降至\(\mathcal{O}(d^2)\)，高维场景下结合随机投影可进一步降低至\(\mathcal{O}(m^2)\)（\(m \ll d\)）。同时具备差分隐私优势，仅需每客户端一次加噪，避免多轮通信带来的隐私衰减。实验表明，该方法在合成异构数据上精度媲美FedAvg，通信量减少最多达38倍。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习协议依赖多轮迭代通信，受限于学习率、数据异质性和客户端采样，效率低下。本文旨在探究是否必须进行反复通信，尤其针对线性回归任务，以提升效率并降低通信开销。

Method: 将联邦岭回归建模为分布式均衡问题，客户端计算并传输局部格拉姆矩阵和矩向量，服务器通过一次矩阵求逆完成全局解重构。引入随机投影以应对高维挑战，并设计差分隐私机制与容错策略。

Result: 在满足覆盖条件下，可实现对集中式岭回归解的精确恢复；在异质数据下，给出非渐近误差边界。通信复杂度显著降低，实验验证其在精度与通信效率上优于现有方法。

Conclusion: 联邦线性回归无需迭代通信，可通过一次聚合实现精确或高精度解，适用于线性及核方法，但不适用于一般非线性架构。该框架在通信效率、隐私保护与实际鲁棒性方面具有显著优势。

Abstract: Federated learning protocols require repeated synchronization between clients and a central server, with convergence rates depending on learning rates, data heterogeneity, and client sampling. This paper asks whether iterative communication is necessary for distributed linear regression. We show it is not. We formulate federated ridge regression as a distributed equilibrium problem where each client computes local sufficient statistics -- the Gram matrix and moment vector -- and transmits them once. The server reconstructs the global solution through a single matrix inversion. We prove exact recovery: under a coverage condition on client feature matrices, one-shot aggregation yields the centralized ridge solution, not an approximation. For heterogeneous distributions violating coverage, we derive non-asymptotic error bounds depending on spectral properties of the aggregated Gram matrix. Communication reduces from $\mathcal{O}(Rd)$ in iterative methods to $\mathcal{O}(d^2)$ total; for high-dimensional settings, we propose and experimentally validate random projection techniques reducing this to $\mathcal{O}(m^2)$ where $m \ll d$. We establish differential privacy guarantees where noise is injected once per client, eliminating the composition penalty that degrades privacy in multi-round protocols. We further address practical considerations including client dropout robustness, federated cross-validation for hyperparameter selection, and comparison with gradient-based alternatives. Comprehensive experiments on synthetic heterogeneous regression demonstrate that one-shot fusion matches FedAvg accuracy while requiring up to $38\times$ less communication. The framework applies to kernel methods and random feature models but not to general nonlinear architectures.

</details>


### [201] [Hyperbolic Heterogeneous Graph Transformer](https://arxiv.org/abs/2601.08251)
*Jongmin Park,Seunghoon Han,Hyewon Lee,Won-Yong Shin,Sungsu Lim*

Main category: cs.LG

TL;DR: 提出HypHGT，一种完全在双曲空间中学习异质图表示的方法，通过基于Transformer的架构自然捕捉局部和全局依赖关系，并采用线性时间复杂度的关系特定双曲注意力机制，有效保留不同类型关系的异质信息，显著提升性能并减少训练时间和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖切空间操作导致映射失真，且消息传递架构主要关注局部邻域信息，难以捕捉全局层次结构和长程依赖关系。

Method: 提出HypHGT，采用基于Transformer的架构在双曲空间中进行消息传递，引入关系特定的双曲注意力机制，实现线性时间复杂度计算。

Result: 在节点分类任务中，HypHGT consistently优于现有先进方法，同时大幅降低训练时间和内存使用。

Conclusion: HypHGT能够高效、准确地学习异质图中的复杂结构和语义信息，是双曲空间中学习异质图的有效解决方案。

Abstract: In heterogeneous graphs, we can observe complex structures such as tree-like or hierarchical structures. Recently, the hyperbolic space has been widely adopted in many studies to effectively learn these complex structures. Although these methods have demonstrated the advantages of the hyperbolic space in learning heterogeneous graphs, most existing methods still have several challenges. They rely heavily on tangent-space operations, which often lead to mapping distortions during frequent transitions. Moreover, their message-passing architectures mainly focus on local neighborhood information, making it difficult to capture global hierarchical structures and long-range dependencies between different types of nodes. To address these limitations, we propose Hyperbolic Heterogeneous Graph Transformer (HypHGT), which effectively and efficiently learns heterogeneous graph representations entirely within the hyperbolic space. Unlike previous message-passing based hyperbolic heterogeneous GNNs, HypHGT naturally captures both local and global dependencies through transformer-based architecture. Furthermore, the proposed relation-specific hyperbolic attention mechanism in HypHGT, which operates with linear time complexity, enables efficient computation while preserving the heterogeneous information across different relation types. This design allows HypHGT to effectively capture the complex structural properties and semantic information inherent in heterogeneous graphs. We conduct comprehensive experiments to evaluate the effectiveness and efficiency of HypHGT, and the results demonstrate that it consistently outperforms state-of-the-art methods in node classification task, with significantly reduced training time and memory usage.

</details>


### [202] [On Evaluation of Unsupervised Feature Selection for Pattern Classification](https://arxiv.org/abs/2601.08257)
*Gyu-Il Kim,Dae-Won Kim,Jaesung Lee*

Main category: cs.LG

TL;DR: 本文提出应采用多标签分类框架来评估无监督特征选择方法，以克服单标签设置下因标签选择任意性导致的性能评价偏差。实验表明，在21个多标签数据集上，多标签设置下的性能排名与单标签设置显著不同，支持多标签评估作为更公平、可靠的比较方式。


<details>
  <summary>Details</summary>
Motivation: 现有无监督特征选择方法通常在单标签数据集上评估，但该设置中标签的选择具有任意性，可能导致方法性能排名不稳定，无法真实反映其判别能力。

Method: 引入多标签分类框架替代传统的单标签评估方式，通过在21个多标签数据集上对比多个代表性方法的性能，验证新评估范式的有效性。

Result: 实验结果显示，多标签设置下的性能排名与单标签设置有显著差异，说明多标签评估能提供更稳定、公正的比较结果。

Conclusion: 应摒弃仅基于单标签准确性的评估方式，转而采用多标签分类框架，以实现对无监督特征选择方法更公平和可靠的性能评估。

Abstract: Unsupervised feature selection aims to identify a compact subset of features that captures the intrinsic structure of data without supervised label. Most existing studies evaluate the performance of methods using the single-label dataset that can be instantiated by selecting a label from multi-label data while maintaining the original features. Because the chosen label can vary arbitrarily depending on the experimental setting, the superiority among compared methods can be changed with regard to which label happens to be selected. Thus, evaluating unsupervised feature selection methods based solely on single-label accuracy is unreasonable for assessing their true discriminative ability. This study revisits this evaluation paradigm by adopting a multi-label classification framework. Experiments on 21 multi-label datasets using several representative methods demonstrate that performance rankings differ markedly from those reported under single-label settings, suggesting the possibility of multi-label evaluation settings for fair and reliable comparison of unsupervised feature selection methods.

</details>


### [203] [Demystifying the Slash Pattern in Attention: The Role of RoPE](https://arxiv.org/abs/2601.08297)
*Yuan Cheng,Fengzhuo Zhang,Yunlong Hou,Cunxiao Du,Chao Du,Tianyu Pang,Aixin Sun,Zhuoran Yang*

Main category: cs.LG

TL;DR: 该论文从实证和理论角度解释了大语言模型中出现的斜向注意力模式（SDHs）的成因。通过分析开源LLM，发现SDHs是模型内在特性，且能泛化到分布外提示。关键条件为：查询与键几乎为秩一矩阵，且旋转位置编码（RoPE）主要由中高频成分主导。这些条件导致查询与键在不同词元间近似相同，中高频RoPE成分间的交互生成了斜向注意力模式。理论上，作者证明在这些假设下，使用梯度下降训练的浅层Transformer会自然产生SDHs，并具备分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型中斜向注意力模式（SDHs）为何出现，揭示其内在机制及泛化能力，以增进对注意力结构的理解。

Method: 结合实证分析与理论建模：分析开放源代码的LLM中的注意力模式；研究查询、键与旋转位置编码（RoPE）的作用；提出两个关键条件并验证其有效性；构建理论框架，通过分析浅层Transformer在梯度下降下的训练动态，证明条件足以保证SDHs的出现。

Result: 发现了SDHs的两个核心特征条件，实证表明其普遍性与分布外泛化能力；理论证明在给定条件下，基于梯度下降训练的模型必然产生SDHs，且该现象具有稳定性与可推广性。

Conclusion: 斜向注意力模式（SDHs）是大语言模型中一种内在且稳定的注意力结构，由查询/键的秩一特性和中高频RoPE成分的交互共同驱动。这一机制不仅解释了注意力模式的形成，还揭示了模型在复杂输入下的泛化能力来源。

Abstract: Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the $Δ$-th sub-diagonal for some offset $Δ$. These patterns play a key role in passing information across tokens. But why do they emerge? In this paper, we demystify the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. First, by analyzing open-source LLMs, we find that SDHs are intrinsic to models and generalize to out-of-distribution prompts. To explain the intrinsic emergence, we analyze the queries, keys, and Rotary Position Embedding (RoPE), which jointly determine attention scores. Our empirical analysis reveals two characteristic conditions of SDHs: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. Under these conditions, queries and keys are nearly identical across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs. Beyond empirical evidence, we theoretically show that these conditions are sufficient to ensure the emergence of SDHs by formalizing them as our modeling assumptions. Particularly, we analyze the training dynamics of a shallow Transformer equipped with RoPE under these conditions, and prove that models trained via gradient descent exhibit SDHs. The SDHs generalize to out-of-distribution prompts.

</details>


### [204] [ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning](https://arxiv.org/abs/2601.08310)
*Kun Liang,Clive Bai,Xin Xu,Chenming Tang,Sanwoo Lee,Weijie Liu,Saiyong Yang,Yunfang Wu*

Main category: cs.LG

TL;DR: ORBIT提出了一种可控制的多预算推理框架，通过多阶段强化学习发现每个努力级别的帕累托最优推理行为，并通过在线策略蒸馏将这些行为融合到单一统一模型中，实现了在多个推理模式间的可控性、高推理密度以及良好的模式分离和性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型在推理时采用过长的思维链，导致不必要的计算开销；先前方法依赖输入估计合理推理预算，但存在不可靠性和训练时固定成本-准确率权衡的问题，限制了部署灵活性。

Method: 提出ORBIT框架，利用多阶段强化学习寻找各预算水平下的帕累托最优推理行为，并通过在线策略蒸馏将不同模式的行为融合为一个统一模型，保持模式间清晰分离。

Result: 实验表明，ORBIT实现了多模式可控推理、各模式内具有竞争力的推理密度，并成功将前沿策略整合至单一学生模型中，同时保持模式分离与高性能。

Conclusion: ORBIT提供了一种灵活、高效且可调控的推理框架，能够在不同部署需求下动态调整推理成本与精度之间的平衡，显著提升推理效率与实用性。

Abstract: Recent Large Reasoning Models (LRMs) achieve strong performance by leveraging long-form Chain-of-Thought (CoT) reasoning, but uniformly applying overlong reasoning at inference time incurs substantial and often unnecessary computational cost. To address this, prior work explores various strategies to infer an appropriate reasoning budget from the input. However, such approaches are unreliable in the worst case, as estimating the minimal required reasoning effort is fundamentally difficult, and they implicitly fix the trade-off between reasoning cost and accuracy during training, limiting flexibility under varying deployment scenarios. Motivated by these limitations, we propose ORBIT, a controllable multi-budget reasoning framework with well-separated reasoning modes triggered by input. ORBIT employs multi-stage reinforcement learning to discover Pareto-optimal reasoning behaviors at each effort, followed by on-policy distillation to fuse these behaviors into a single unified model. Experiments show that ORBIT achieves (1) controllable reasoning behavior over multiple modes, (2) competitive reasoning density within each mode, and (3) integration of these frontier policies into a single unified student model while preserving clear mode separation and high per-mode performance.

</details>


### [205] [Automated Machine Learning in Radiomics: A Comparative Evaluation of Performance, Efficiency and Accessibility](https://arxiv.org/abs/2601.08334)
*Jose Lozano-Montoya,Emilio Soria-Olivas,Almudena Fuster-Matanzo,Angel Alberich-Bayarri,Ana Jimenez-Pastor*

Main category: cs.LG

TL;DR: 该研究评估了通用型和放射组学专用的AutoML框架在多种放射组学分类任务中的表现、效率和可及性，发现Simplatab（放射组学专用工具）在性能上表现最佳（平均AUC 81.81%），LightAutoML（通用框架）执行速度最快（6分钟内达到78.74%均值AUC）。多数放射组学专用框架因过时、编程要求高或计算效率低被排除。通用框架更具可及性和易用性，但当前框架仍缺乏对生存分析的支持以及特征可重复性和标准化的整合。未来需针对放射组学特有挑战优化AutoML解决方案。


<details>
  <summary>Details</summary>
Motivation: 评估AutoML框架在解决放射组学特定挑战方面的有效性，以识别开发需求并推动更适用的工具发展。

Method: 使用10个公开/私有的放射组学数据集，涵盖不同成像模态（CT/MRI）、规模、解剖部位和终点；测试6个通用型和5个放射组学专用框架，采用预设参数与标准化交叉验证；评估指标包括AUC、运行时间，以及软件状态、可及性和可解释性等定性因素。

Result: Simplatab在平均测试AUC上最高（81.81%），运行时间约1小时；LightAutoML执行最快（6分钟），平均AUC为78.74%，表现良好。多数放射组学专用框架因技术落后或效率问题未被纳入分析。通用框架在可及性和实现便捷性方面更优。

Conclusion: Simplatab在性能、效率和可及性之间实现了良好平衡，适用于放射组学分类问题。但当前框架仍存在显著不足，如缺乏对生存分析的支持、特征可重复性与标准化集成不足。未来应聚焦于针对放射组学特点改进AutoML方案。

Abstract: Automated machine learning (AutoML) frameworks can lower technical barriers for predictive and prognostic model development in radiomics by enabling researchers without programming expertise to build models. However, their effectiveness in addressing radiomics-specific challenges remains unclear. This study evaluates the performance, efficiency, and accessibility of general-purpose and radiomics-specific AutoML frameworks on diverse radiomics classification tasks, thereby highlighting development needs for radiomics. Ten public/private radiomics datasets with varied imaging modalities (CT/MRI), sizes, anatomies and endpoints were used. Six general-purpose and five radiomics-specific frameworks were tested with predefined parameters using standardized cross-validation. Evaluation metrics included AUC, runtime, together with qualitative aspects related to software status, accessibility, and interpretability. Simplatab, a radiomics-specific tool with a no-code interface, achieved the highest average test AUC (81.81%) with a moderate runtime (~1 hour). LightAutoML, a general-purpose framework, showed the fastest execution with competitive performance (78.74% mean AUC in six minutes). Most radiomics-specific frameworks were excluded from the performance analysis due to obsolescence, extensive programming requirements, or computational inefficiency. Conversely, general-purpose frameworks demonstrated higher accessibility and ease of implementation. Simplatab provides an effective balance of performance, efficiency, and accessibility for radiomics classification problems. However, significant gaps remain, including the lack of accessible survival analysis support and the limited integration of feature reproducibility and harmonization within current AutoML frameworks. Future research should focus on adapting AutoML solutions to better address these radiomics-specific challenges.

</details>


### [206] [Decodable but not structured: linear probing enables Underwater Acoustic Target Recognition with pretrained audio embeddings](https://arxiv.org/abs/2601.08358)
*Hilde I. Hummel,Sandjai Bhulai,Rob D. van der Mei,Burooj Ghani*

Main category: cs.LG

TL;DR: 本文首次对用于水下声学目标识别（UATR）的迁移学习进行了实证比较，评估了来自不同音频领域的多个预训练音频模型。研究发现，嵌入空间的几何结构主要受录音特性影响，但通过简单的线性探测可有效抑制这些录音特异性信息，从而提取出船只类型特征。该方法在低计算成本下实现了有效的自动UATR，显著减少了对大量高质量标注船隻录音的需求。


<details>
  <summary>Details</summary>
Motivation: 船舶产生的人为噪声是水下声音污染的主要来源，威胁海洋生态系统，因此需要监测以量化其影响。尽管被动声学监测（PAM）系统广泛部署，但大规模数据的手动分析不现实，亟需基于机器学习的自动化方法。然而，当前自动水下声学目标识别多依赖监督学习，受限于标注数据稀缺。迁移学习为缓解这一问题提供了潜在解决方案。

Method: 采用多个来自不同音频领域的预训练音频模型，冻结其权重，提取嵌入表示，并通过分类、聚类和相似性评估分析这些嵌入。进一步使用线性探测来抑制录音特定信息，提取船只类型特征。

Result: 嵌入空间的几何结构主要由录音特性主导，但线性探测能有效去除此类干扰，使模型能够准确识别船只类型。该方法在较低计算开销下实现高效自动识别，大幅减少对高质量标注数据的依赖。

Conclusion: 基于预训练音频模型的迁移学习结合线性探测，是一种高效且低成本的自动水下声学目标识别方法，适用于大规模声学监测场景，具有良好的应用前景。

Abstract: Increasing levels of anthropogenic noise from ships contribute significantly to underwater sound pollution, posing risks to marine ecosystems. This makes monitoring crucial to understand and quantify the impact of the ship radiated noise. Passive Acoustic Monitoring (PAM) systems are widely deployed for this purpose, generating years of underwater recordings across diverse soundscapes. Manual analysis of such large-scale data is impractical, motivating the need for automated approaches based on machine learning. Recent advances in automatic Underwater Acoustic Target Recognition (UATR) have largely relied on supervised learning, which is constrained by the scarcity of labeled data. Transfer Learning (TL) offers a promising alternative to mitigate this limitation. In this work, we conduct the first empirical comparative study of transfer learning for UATR, evaluating multiple pretrained audio models originating from diverse audio domains. The pretrained model weights are frozen, and the resulting embeddings are analyzed through classification, clustering, and similarity-based evaluations. The analysis shows that the geometrical structure of the embedding space is largely dominated by recording-specific characteristics. However, a simple linear probe can effectively suppress this recording-specific information and isolate ship-type features from these embeddings. As a result, linear probing enables effective automatic UATR using pretrained audio models at low computational cost, significantly reducing the need for a large amounts of high-quality labeled ship recordings.

</details>


### [207] [Controlled LLM Training on Spectral Sphere](https://arxiv.org/abs/2601.08393)
*Tian Xie,Haoming Luo,Haoyu Tang,Yiwen Hu,Jason Klein Liu,Qingnan Ren,Yang Wang,Wayne Xin Zhao,Rui Yan,Bing Su,Chong Luo,Baining Guo*

Main category: cs.LG

TL;DR: 提出Spectral Sphere Optimizer (SSO)，通过在权重和更新上施加严格的模块级谱约束，实现与μP理论完全对齐的优化过程。SSO在大规模训练中表现出更优的收敛性、稳定性及激活控制，优于AdamW和Muon。


<details>
  <summary>Details</summary>
Motivation: 现有优化器如Muon虽控制更新但允许权重漂移，无法完全满足μP理论的宽度不变激活控制要求，因此需要一种能同时约束权重和更新的优化方法以提升稳定性和收敛性。

Method: 提出基于谱球面的优化框架，推导出谱球面上最速下降方向，实现模块级权重与更新的严格谱约束，确保与μP理论完全对齐，并在Megatron中实现高效并行化。

Result: 在多种架构（如Dense 1.7B、MoE 8B-A1B、200层DeepNet）上的预训练实验表明，SSO显著优于AdamW和Muon，具备更好的收敛速度、稳定性、激活控制能力，改善了MoE路由负载均衡，抑制异常值并严格限制激活范围。

Conclusion: SSO实现了完全对齐μP理论的优化过程，兼具理论严谨性与实际有效性，在大规模模型训练中展现出卓越性能与稳定性。

Abstract: Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization ($\boldsymbolμ$P) provides a theoretical safeguard for width-invariant $Θ(1)$ activation control, whereas emerging optimizers like Muon are only ``half-aligned'' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the \textbf{Spectral Sphere Optimizer (SSO)}, which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully $\boldsymbolμ$P-aligned optimization process. To enable large-scale training, we implement SSO as an efficient parallel algorithm within Megatron. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.

</details>


### [208] [Taxon: Hierarchical Tax Code Prediction with Semantically Aligned LLM Expert Guidance](https://arxiv.org/abs/2601.08418)
*Jihang Li,Qing Liu,Zulong Chen,Jing Wang,Wei Wang,Chuanfei Xu,Zeyi Wen*

Main category: cs.LG

TL;DR: Taxon是一个语义对齐且专家引导的层次化税码预测框架，结合多模态特征路由与大语言模型驱动的语义一致性验证，通过多源训练提升监督质量，在真实业务数据中表现卓越，已部署于阿里巴巴税务系统，日均处理超50万次请求。


<details>
  <summary>Details</summary>
Motivation: 税码预测在电商自动化开票与合规管理中至关重要，但现有方法在准确性、结构一致性和语义对齐方面存在不足，尤其面对复杂多级税则体系时易出错，导致财务偏差和监管风险。

Method: 提出Taxon框架，采用特征门控的混合专家架构实现跨层级特征自适应路由，并引入基于大语言模型的语义一致性模型验证产品标题与官方税定义的一致性；设计多源训练管道，融合税则数据库、发票校验日志和商户注册数据以提供结构与语义双重监督。

Result: 在自有TaxCode数据集和公开基准上均达到最先进性能，层次路径重建进一步提升了结构一致性，整体F1分数最高；已在阿里巴巴税务系统上线，日均处理超50万请求，峰值达五百万，显著提升准确率、可解释性与鲁棒性。

Conclusion: Taxon通过融合结构化建模与语义理解，有效解决了大规模电商场景下税码预测的挑战，具备实际落地价值，为自动化合规系统提供了可靠解决方案。

Abstract: Tax code prediction is a crucial yet underexplored task in automating invoicing and compliance management for large-scale e-commerce platforms. Each product must be accurately mapped to a node within a multi-level taxonomic hierarchy defined by national standards, where errors lead to financial inconsistencies and regulatory risks. This paper presents Taxon, a semantically aligned and expert-guided framework for hierarchical tax code prediction. Taxon integrates (i) a feature-gating mixture-of-experts architecture that adaptively routes multi-modal features across taxonomy levels, and (ii) a semantic consistency model distilled from large language models acting as domain experts to verify alignment between product titles and official tax definitions. To address noisy supervision in real business records, we design a multi-source training pipeline that combines curated tax databases, invoice validation logs, and merchant registration data to provide both structural and semantic supervision. Extensive experiments on the proprietary TaxCode dataset and public benchmarks demonstrate that Taxon achieves state-of-the-art performance, outperforming strong baselines. Further, an additional full hierarchical paths reconstruction procedure significantly improves structural consistency, yielding the highest overall F1 scores. Taxon has been deployed in production within Alibaba's tax service system, handling an average of over 500,000 tax code queries per day and reaching peak volumes above five million requests during business event with improved accuracy, interpretability, and robustness.

</details>


### [209] [Coverage Improvement and Fast Convergence of On-policy Preference Learning](https://arxiv.org/abs/2601.08421)
*Juno Kim,Jihun Yun,Jason D. Lee,Kwang-Sung Jun*

Main category: cs.LG

TL;DR: 在线策略偏好学习算法（如在线直接策略优化DPO）在语言模型对齐中显著优于离线方法。本文通过分析采样策略覆盖度的演变，提出了“覆盖度改进原则”：在足够大的批次下，每次更新都趋向于目标附近覆盖更优的区域，使后续数据更具信息量，从而实现快速收敛。在上下文老虎机设置中，当批次大小超过广义覆盖阈值时，线上DPO可呈指数级收敛；而受限于初始策略离线样本的任何学习器仅能实现较慢的极小极大率，导致总样本复杂度出现显著差异。基于此，作者提出一种基于新型‘优选’G-最优设计的混合采样器，消除对覆盖度的依赖，保证仅需两轮即可收敛。此外，还提出了适用于一般函数类的一般化在线策略奖励蒸馏方案，并在基于偏差的覆盖度定义下展示更快的无噪声收敛速率。实验验证了线上DPO与所提奖励蒸馏算法优于离线版本，且性能随迭代单调稳定提升。


<details>
  <summary>Details</summary>
Motivation: 解释为何在线策略偏好学习算法（如在线DPO）在语言模型对齐中表现优于离线方法，揭示其背后的关键机制——采样策略覆盖度的动态优化。

Method: 提出覆盖度改进原则，结合上下文老虎机中的Bradley-Terry偏好和线性软最大值策略类，理论证明在线DPO在批次大小超过阈值时指数收敛；设计基于优选G-最优设计的混合采样器以摆脱覆盖度依赖；发展适用于一般函数类的在线策略奖励蒸馏方法，并引入偏差驱动的覆盖度概念以获得更快收敛速率。

Result: 理论上证明在线DPO在足够大批次下可指数收敛，而离线方法受限于初始策略，收敛速度慢；提出的混合采样器可在两轮内保证收敛；奖励蒸馏方法在理想条件下实现更快的无噪声收敛速率；实验验证在线方法具有更优性能和稳定单调提升趋势。

Conclusion: 在线策略偏好学习通过持续改进采样覆盖度实现高效、稳定的模型对齐。提出的覆盖度改进原则及其衍生算法（如混合采样器和奖励蒸馏）为提升语言模型对齐效率提供了坚实的理论基础与实用工具，显著优于传统离线方法。

Abstract: Online on-policy preference learning algorithms for language model alignment such as online direct policy optimization (DPO) can significantly outperform their offline counterparts. We provide a theoretical explanation for this phenomenon by analyzing how the sampling policy's coverage evolves throughout on-policy training. We propose and rigorously justify the \emph{coverage improvement principle}: with sufficient batch size, each update moves into a region around the target where coverage is uniformly better, making subsequent data increasingly informative and enabling rapid convergence. In the contextual bandit setting with Bradley-Terry preferences and linear softmax policy class, we show that on-policy DPO converges exponentially in the number of iterations for batch size exceeding a generalized coverage threshold. In contrast, any learner restricted to offline samples from the initial policy suffers a slower minimax rate, leading to a sharp separation in total sample complexity. Motivated by this analysis, we further propose a simple hybrid sampler based on a novel \emph{preferential} G-optimal design, which removes dependence on coverage and guarantees convergence in just two rounds. Finally, we develop principled on-policy schemes for reward distillation in the general function class setting, and show faster noiseless rates under an alternative deviation-based notion of coverage. Experimentally, we confirm that on-policy DPO and our proposed reward distillation algorithms outperform their off-policy counterparts and enjoy stable, monotonic performance gains across iterations.

</details>


### [210] [DiffMM: Efficient Method for Accurate Noisy and Sparse Trajectory Map Matching via One Step Diffusion](https://arxiv.org/abs/2601.08482)
*Chenxu Han,Sean Bin Yang,Jilin Hu*

Main category: cs.LG

TL;DR: 提出DiffMM，一种基于编码器-扩散模型的轨迹匹配框架，通过一步扩散过程实现高效准确的匹配，尤其适用于稀疏轨迹和复杂路网。


<details>
  <summary>Details</summary>
Motivation: 现有基于HMM或编码器-解码器框架的轨迹匹配方法在处理噪声大或采样稀疏的GPS轨迹时仍面临挑战，需要更高效且准确的方法。

Method: 引入道路段感知的轨迹编码器，通过注意力机制将输入轨迹及其周围候选道路段联合嵌入共享潜在空间；提出一步扩散方法，利用轨迹与候选道路段的联合嵌入作为条件上下文，实现快速匹配。

Result: 在大规模轨迹数据集上的实验表明，该方法在准确性和效率上均优于现有最优方法，尤其在稀疏轨迹和复杂道路拓扑下表现突出。

Conclusion: DiffMM通过一步扩散机制实现了高效且精准的轨迹匹配，特别适合处理稀疏和高噪声轨迹，在复杂路网中具有显著优势。

Abstract: Map matching for sparse trajectories is a fundamental problem for many trajectory-based applications, e.g., traffic scheduling and traffic flow analysis. Existing methods for map matching are generally based on Hidden Markov Model (HMM) or encoder-decoder framework. However, these methods continue to face significant challenges when handling noisy or sparsely sampled GPS trajectories. To address these limitations, we propose DiffMM, an encoder-diffusion-based map matching framework that produces effective yet efficient matching results through a one-step diffusion process. We first introduce a road segment-aware trajectory encoder that jointly embeds the input trajectory and its surrounding candidate road segments into a shared latent space through an attention mechanism. Next, we propose a one step diffusion method to realize map matching through a shortcut model by leveraging the joint embedding of the trajectory and candidate road segments as conditioning context. We conduct extensive experiments on large-scale trajectory datasets, demonstrating that our approach consistently outperforms state-of-the-art map matching methods in terms of both accuracy and efficiency, particularly for sparse trajectories and complex road network topologies.

</details>


### [211] [Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care](https://arxiv.org/abs/2601.08503)
*Aditya Kumar,Simon Rauch,Mario Cypko,Marcel Naik,Matthieu-P Schapranow,Aadil Rashid,Fabian Halleck,Bilgin Osmanodja,Roland Roller,Lars Pape,Klemens Budde,Mario Schiffer,Oliver Amft*

Main category: cs.LG

TL;DR: TFN is a multi-modal, task-agnostic model that integrates irregular time series and clinical narratives, outperforming state-of-the-art models in predicting graft loss, rejection, and mortality post-kidney transplant. It achieves higher AUCs, improves upon unimodal baselines, and provides interpretable, clinically meaningful insights, suggesting broad applicability in complex clinical environments.


<details>
  <summary>Details</summary>
Motivation: To develop a multi-modal, task-agnostic model that can effectively integrate irregular time series data and unstructured clinical narratives for improved patient outcome prediction in post-kidney transplant care.

Method: Introducing Temporal Fusion Nexus (TFN), a multi-modal embedding model designed to handle heterogeneous data sources including irregular time series and clinical text. The model was evaluated on a retrospective cohort of 3382 patients with three key outcomes: graft loss, graft rejection, and mortality. Performance was compared against state-of-the-art models and unimodal baselines using AUC metrics, while disentanglement metrics and SHAP-based explanations were used to assess interpretability and clinical alignment.

Result: TFN achieved superior performance over existing models: AUC of 0.96 for graft loss (vs. 0.94), 0.84 for graft rejection (vs. 0.74), and 0.86 for mortality. It showed approximately 10% AUC improvement over time series-only baselines and 5% improvement over time series with static data. Integration of clinical text consistently enhanced performance across all tasks. Disentanglement and SHAP analyses confirmed robust, interpretable latent representations aligned with clinical reasoning.

Conclusion: Temporal Fusion Nexus (TFN) demonstrates strong potential for clinical applications beyond kidney transplantation, particularly in settings involving heterogeneous, irregular longitudinal data and rich narrative documentation, due to its ability to integrate diverse data types effectively and produce interpretable, high-performance predictions.

Abstract: We introduce Temporal Fusion Nexus (TFN), a multi-modal and task-agnostic embedding model to integrate irregular time series and unstructured clinical narratives. We analysed TFN in post-kidney transplant (KTx) care, with a retrospective cohort of 3382 patients, on three key outcomes: graft loss, graft rejection, and mortality. Compared to state-of-the-art model in post KTx care, TFN achieved higher performance for graft loss (AUC 0.96 vs. 0.94) and graft rejection (AUC 0.84 vs. 0.74). In mortality prediction, TFN yielded an AUC of 0.86. TFN outperformed unimodal baselines (approx 10% AUC improvement over time series only baseline, approx 5% AUC improvement over time series with static patient data). Integrating clinical text improved performance across all tasks. Disentanglement metrics confirmed robust and interpretable latent factors in the embedding space, and SHAP-based attributions confirmed alignment with clinical reasoning. TFN has potential application in clinical tasks beyond KTx, where heterogeneous data sources, irregular longitudinal data, and rich narrative documentation are available.

</details>


### [212] [Your Group-Relative Advantage Is Biased](https://arxiv.org/abs/2601.08521)
*Fengkai Yang,Zherui Chen,Xiaohan Wang,Xiaodong Lu,Jiajun Chai,Guojun Yin,Wei Lin,Shuai Ma,Fuzhen Zhuang,Deqing Wang,Yaodong Yang,Jianxin Li,Yikun Ban*

Main category: cs.LG

TL;DR: 本文揭示了基于组的强化学习（如GRPO）中组相对优势估计器存在固有偏差，导致对困难提示的优势低估、对简单提示的优势高估，从而引发探索与利用的不平衡。为此，提出历史感知自适应难度加权（HA-DW）方法，通过动态调整难度锚点和训练过程中的权重来修正偏差。理论分析与五项数学推理基准测试实验表明，HA-DW在集成到GRPO及其变体时能持续提升性能，证明纠正优势估计偏差对鲁棒高效的强化学习推理训练至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有基于组的强化学习方法（如GRPO）依赖组相对优势估计以避免使用学习的评判器，但其理论性质尚不明确，尤其缺乏对偏差问题的理解，可能影响模型训练效果。

Method: 提出历史感知自适应难度加权（HA-DW）方法，通过引入动态难度锚点和训练过程中的自适应重加权机制，修正组相对优势估计的偏差。

Result: 理论分析与实验验证显示，HA-DW在五个数学推理基准上显著提升了GRPO及其变体的性能，证明其有效缓解了优势估计偏差带来的训练不平衡问题。

Conclusion: 纠正组相对优势估计中的偏差是实现稳健高效强化学习推理训练的关键，所提出的HA-DW方法为改进当前主流方法提供了重要方向。

Abstract: Reinforcement Learning from Verifier Rewards (RLVR) has emerged as a widely used approach for post-training large language models on reasoning tasks, with group-based methods such as GRPO and its variants gaining broad adoption. These methods rely on group-relative advantage estimation to avoid learned critics, yet its theoretical properties remain poorly understood.
  In this work, we uncover a fundamental issue of group-based RL: the group-relative advantage estimator is inherently biased relative to the true (expected) advantage. We provide the first theoretical analysis showing that it systematically underestimates advantages for hard prompts and overestimates them for easy prompts, leading to imbalanced exploration and exploitation. To address this issue, we propose History-Aware Adaptive Difficulty Weighting (HA-DW), an adaptive reweighting scheme that adjusts advantage estimates based on an evolving difficulty anchor and training dynamics. Both theoretical analysis and experiments on five mathematical reasoning benchmarks demonstrate that HA-DW consistently improves performance when integrated into GRPO and its variants. Our results suggest that correcting biased advantage estimation is critical for robust and efficient RLVR training.

</details>


### [213] [EviNAM: Intelligibility and Uncertainty via Evidential Neural Additive Models](https://arxiv.org/abs/2601.08556)
*Sören Schleibaum,Anton Frederik Thielmann,Julian Teusch,Benjamin Säfken,Jörg P. Müller*

Main category: cs.LG

TL;DR: EviNAM combines Neural Additive Models (NAMs) with evidential learning to provide interpretable predictions and accurate uncertainty estimation in a single pass, supporting both aleatoric and epistemic uncertainty, as well as explicit feature contributions. It achieves state-of-the-art performance in regression and is extendable to classification and generalized additive models.


<details>
  <summary>Details</summary>
Motivation: To improve the intelligibility and reliability of machine learning predictions by enabling simultaneous uncertainty estimation and feature interpretability, overcoming limitations of standard Bayesian neural networks and prior evidential methods.

Method: EviNAM extends evidential learning by integrating it with Neural Additive Models (NAMs), allowing for explicit modeling of feature contributions and principled estimation of both aleatoric and epistemic uncertainty within a single inference pass.

Result: EviNAM achieves competitive predictive performance on synthetic and real-world datasets while providing transparent, interpretable outputs and accurate uncertainty quantification.

Conclusion: EviNAM offers a promising approach for building trustworthy and interpretable models, particularly suitable for high-stakes applications, and can be naturally extended to classification and generalized additive models.

Abstract: Intelligibility and accurate uncertainty estimation are crucial for reliable decision-making. In this paper, we propose EviNAM, an extension of evidential learning that integrates the interpretability of Neural Additive Models (NAMs) with principled uncertainty estimation. Unlike standard Bayesian neural networks and previous evidential methods, EviNAM enables, in a single pass, both the estimation of the aleatoric and epistemic uncertainty as well as explicit feature contributions. Experiments on synthetic and real data demonstrate that EviNAM matches state-of-the-art predictive performance. While we focus on regression, our method extends naturally to classification and generalized additive models, offering a path toward more intelligible and trustworthy predictions.

</details>


### [214] [M$^2$FMoE: Multi-Resolution Multi-View Frequency Mixture-of-Experts for Extreme-Adaptive Time Series Forecasting](https://arxiv.org/abs/2601.08631)
*Yaohui Huang,Runmin Zou,Yun Wang,Laeeq Aslam,Ruipeng Dong*

Main category: cs.LG

TL;DR: M$^2$FMoE是一种针对极端事件的自适应时间序列预测模型，通过多分辨率和多视角频域建模，有效捕捉常规与极端模式。其包含三个模块：多视图频率专家混合模块实现频带分工与专家协作；多分辨率自适应融合模块增强对短期波动和突变的敏感性；时序门控集成模块动态平衡长期趋势与短期频率特征，提升对极端事件的适应能力。在真实水文数据集上的实验表明，该模型优于现有方法，且无需极端事件标签。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在极端事件期间性能显著下降，因其难以捕捉高方差、不规则动态及稀疏但高影响的极端事件特征。尽管已有方法引入辅助信号，但仍无法充分建模极端事件的复杂时序动态。

Method: 提出M$^2$FMoE模型，采用多视图频率混合专家机制，在傅里叶与小波域划分频带并共享分割器以促进跨专家协作；设计多分辨率自适应融合模块，从粗到细聚合频域特征；引入时序门控集成模块，动态调节长期趋势与短期频率特征的权重，实现对常规与极端模式的自适应建模。

Result: 在包含极端模式的真实水文数据集上，M$^2$FMoE显著优于当前最先进的基线模型，且无需依赖极端事件标注即可实现高性能预测。

Conclusion: M$^2$FMoE通过多分辨率与多视角频域建模，有效提升了时间序列预测在极端事件下的鲁棒性与准确性，为复杂动态系统的预测提供了新范式。

Abstract: Forecasting time series with extreme events is critical yet challenging due to their high variance, irregular dynamics, and sparse but high-impact nature. While existing methods excel in modeling dominant regular patterns, their performance degrades significantly during extreme events, constituting the primary source of forecasting errors in real-world applications. Although some approaches incorporate auxiliary signals to improve performance, they still fail to capture extreme events' complex temporal dynamics. To address these limitations, we propose M$^2$FMoE, an extreme-adaptive forecasting model that learns both regular and extreme patterns through multi-resolution and multi-view frequency modeling. It comprises three modules: (1) a multi-view frequency mixture-of-experts module assigns experts to distinct spectral bands in Fourier and Wavelet domains, with cross-view shared band splitter aligning frequency partitions and enabling inter-expert collaboration to capture both dominant and rare fluctuations; (2) a multi-resolution adaptive fusion module that hierarchically aggregates frequency features from coarse to fine resolutions, enhancing sensitivity to both short-term variations and sudden changes; (3) a temporal gating integration module that dynamically balances long-term trends and short-term frequency-aware features, improving adaptability to both regular and extreme temporal patterns. Experiments on real-world hydrological datasets with extreme patterns demonstrate that M$^2$FMoE outperforms state-of-the-art baselines without requiring extreme-event labels.

</details>


### [215] [Provably Safe Reinforcement Learning using Entropy Regularizer](https://arxiv.org/abs/2601.08646)
*Abhijit Mazumdar,Rafal Wisniewski,Manuela L. Bujorianu*

Main category: cs.LG

TL;DR: 本文研究带有安全约束的马尔可夫决策过程中的最优策略学习问题，采用可达-避免（reach-avoid）框架，提出基于不确定性乐观（OFU）原则的在线强化学习算法，并进一步引入熵正则化改进主算法。通过有限样本分析，推导了两者的后悔界，证明熵正则化能有效降低后悔值并显著控制基于OFU的安全强化学习中固有的逐轮波动性。


<details>
  <summary>Details</summary>
Motivation: 在强化学习过程中，确保安全约束至关重要，尤其是在学习阶段。现有方法在保证高概率安全性方面存在不足，且基于OFU的算法常伴随较大的策略波动性，影响学习稳定性。因此，亟需设计既能保障安全性又能提升性能稳定性的在线学习算法。

Method: 提出两种算法：第一种基于OFU原则，第二种在该基础上引入熵正则化以增强探索与稳定性。通过理论分析，对两类算法进行有限样本下的后悔界推导，评估其收敛性和鲁棒性。

Result: 实验与理论分析表明，熵正则化显著降低了算法的后悔值，并大幅减少了不同学习周期间的策略波动性，提升了学习过程的稳定性和安全性。

Conclusion: 熵正则化有效改善了基于OFU的安全强化学习算法的性能，使其在保证高概率安全的前提下具备更优的收敛性和更低的变异性，为安全在线学习提供了有效的理论与实践方案。

Abstract: We consider the problem of learning the optimal policy for Markov decision processes with safety constraints. We formulate the problem in a reach-avoid setup. Our goal is to design online reinforcement learning algorithms that ensure safety constraints with arbitrarily high probability during the learning phase. To this end, we first propose an algorithm based on the optimism in the face of uncertainty (OFU) principle. Based on the first algorithm, we propose our main algorithm, which utilizes entropy regularization. We investigate the finite-sample analysis of both algorithms and derive their regret bounds. We demonstrate that the inclusion of entropy regularization improves the regret and drastically controls the episode-to-episode variability that is inherent in OFU-based safe RL algorithms.

</details>


### [216] [TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations](https://arxiv.org/abs/2601.08659)
*Hamid Gadirov,Martijn Westra,Steffen Frey*

Main category: cs.LG

TL;DR: 本文研究了基于重构的异常检测方法在参数化卡门涡街模拟的集合数据中的应用，比较了2D与3D卷积自编码器在处理单帧和短时间序列上的表现。2D模型能识别单个时间步的局部空间异常，而3D模型利用时空上下文更有效地检测异常运动模式，并减少时间上的冗余检测。此外，研究发现重建误差受质量空间分布影响显著，集中区域的误差更大。结果强调了时间上下文对动态模拟中鲁棒异常检测的重要性。


<details>
  <summary>Details</summary>
Motivation: 高维、时变模拟数据中的异常检测因复杂的时空动态而具有挑战性，需要有效的方法来捕捉空间和时间上的异常模式。

Method: 采用2D和3D卷积自编码器分别处理单帧和短时间序列的集合数据，通过比较重构误差来检测异常，并分析不同空间质量分布对误差的影响。

Result: 3D自编码器在检测异常运动模式方面表现更优，减少了时间冗余；重建误差受质量空间分布影响，集中区域误差更高。

Conclusion: 在动态模拟中，利用时间上下文对于实现鲁棒的异常检测至关重要，3D模型相比2D模型更具优势。

Abstract: Detecting anomalies in high-dimensional, time-dependent simulation data is challenging due to complex spatial and temporal dynamics. We study reconstruction-based anomaly detection for ensemble data from parameterized Kármán vortex street simulations using convolutional autoencoders. We compare a 2D autoencoder operating on individual frames with a 3D autoencoder that processes short temporal stacks. The 2D model identifies localized spatial irregularities in single time steps, while the 3D model exploits spatio-temporal context to detect anomalous motion patterns and reduces redundant detections across time. We further evaluate volumetric time-dependent data and find that reconstruction errors are strongly influenced by the spatial distribution of mass, with highly concentrated regions yielding larger errors than dispersed configurations. Our results highlight the importance of temporal context for robust anomaly detection in dynamic simulations.

</details>


### [217] [A Novel Approach to Explainable AI with Quantized Active Ingredients in Decision Making](https://arxiv.org/abs/2601.08733)
*A. M. A. S. D. Alagiyawanna,Asoka Karunananda,Thushari Silva,A. Mahasinghe*

Main category: cs.LG

TL;DR: 本文提出一种基于量子玻尔兹曼机（QBM）与经典玻尔兹曼机（CBM）对比研究的可解释人工智能框架，利用量子计算原理增强经典机器学习的透明度。通过在二值化和降维后的MNIST数据集上训练两种模型，并采用PCA预处理，结合梯度显著性图（QBM）与SHAP（CBM）进行特征重要性分析。结果显示，QBM在分类准确率（83.5% vs. 54%）和特征归因熵值（1.27 vs. 1.39）方面均优于CBM，表明其不仅性能更优，且决策依据更清晰。


<details>
  <summary>Details</summary>
Motivation: AI系统在高风险领域如医疗和金融中的应用受限于缺乏可解释性，亟需提升模型决策透明度以增强信任。

Method: 采用主成分分析（PCA）对MNIST数据进行预处理；训练量子-经典混合电路的QBM与使用对比散度的CBM；通过梯度显著性图评估QBM的特征重要性，使用SHAP评估CBM的特征贡献。

Result: QBM在分类准确率（83.5%）和特征归因熵（1.27）方面显著优于CBM（54%、1.39），表明其在预测性能与可解释性上均有提升。

Conclusion: 量子-经典混合模型在提升分类准确性的同时，增强了决策过程的可解释性，为构建更可信的AI系统提供了新路径。

Abstract: Artificial Intelligence (AI) systems have shown good success at classifying. However, the lack of explainability is a true and significant challenge, especially in high-stakes domains, such as health and finance, where understanding is paramount. We propose a new solution to this challenge: an explainable AI framework based on our comparative study with Quantum Boltzmann Machines (QBMs) and Classical Boltzmann Machines (CBMs). We leverage principles of quantum computing within classical machine learning to provide substantive transparency around decision-making. The design involves training both models on a binarised and dimensionally reduced MNIST dataset, where Principal Component Analysis (PCA) is applied for preprocessing. For interpretability, we employ gradient-based saliency maps in QBMs and SHAP (SHapley Additive exPlanations) in CBMs to evaluate feature attributions.QBMs deploy hybrid quantum-classical circuits with strongly entangling layers, allowing for richer latent representations, whereas CBMs serve as a classical baseline that utilises contrastive divergence. Along the way, we found that QBMs outperformed CBMs on classification accuracy (83.5% vs. 54%) and had more concentrated distributions in feature attributions as quantified by entropy (1.27 vs. 1.39). In other words, QBMs not only produced better predictive performance than CBMs, but they also provided clearer identification of "active ingredient" or the most important features behind model predictions. To conclude, our results illustrate that quantum-classical hybrid models can display improvements in both accuracy and interpretability, which leads us toward more trustworthy and explainable AI systems.

</details>


### [218] [Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs](https://arxiv.org/abs/2601.08763)
*Zhiyuan Hu,Yucheng Wang,Yufei He,Jiaying Wu,Yilun Zhao,See-Kiong Ng,Cynthia Breazeal,Anh Tuan Luu,Hae Won Park,Bryan Hooi*

Main category: cs.LG

TL;DR: 提出一种名为独特性感知强化学习（Uniqueness-Aware Reinforcement Learning）的新方法，通过在回溯级别上奖励罕见的高阶解题策略来缓解大语言模型在复杂推理任务中因探索坍缩导致的多样性不足问题。该方法利用基于LLM的评判器对同一问题的不同解法进行高阶策略聚类，并根据聚类大小反向重加权策略优势，使新颖且正确的策略获得更高奖励。实验表明，该方法在数学、物理和医学推理基准上显著提升pass@$k$表现和AUC@$K$，同时保持pass@1性能并增强探索能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在训练大语言模型时容易出现探索坍缩，即模型过早集中于少数主导的推理模式，虽提升了单次采样成功率（pass@1），但限制了整体解法多样性与大规模采样下的性能增益。根本原因在于对局部词元行为的正则化，而非对解法集合多样性的建模。

Method: 提出一种基于回溯级别的目标函数，使用一个基于LLM的判别器对不同回溯结果进行高阶策略聚类（忽略表面差异），然后根据每个聚类的规模反向调整策略优势，使得正确但罕见的策略获得更高的奖励信号。

Result: 在多个跨领域基准测试（数学、物理、医学推理）中，所提方法在大样本预算下持续提升pass@$k$，显著增加AUC@$K$，同时不牺牲pass@1性能，且能有效维持探索性，发现更多样化的解题策略。

Conclusion: 通过在回溯层面显式建模解法策略的独特性，可有效缓解探索坍缩问题，实现更优的推理性能与多样性平衡，为大语言模型的后训练提供了更具鲁棒性和泛化能力的强化学习范式。

Abstract: Reinforcement learning (RL) has become a central paradigm for post-training large language models (LLMs), particularly for complex reasoning tasks, yet it often suffers from exploration collapse: policies prematurely concentrate on a small set of dominant reasoning patterns, improving pass@1 while limiting rollout-level diversity and gains in pass@k. We argue that this failure stems from regularizing local token behavior rather than diversity over sets of solutions. To address this, we propose Uniqueness-Aware Reinforcement Learning, a rollout-level objective that explicitly rewards correct solutions that exhibit rare high-level strategies. Our method uses an LLM-based judge to cluster rollouts for the same problem according to their high-level solution strategies, ignoring superficial variations, and reweights policy advantages inversely with cluster size. As a result, correct but novel strategies receive higher rewards than redundant ones. Across mathematics, physics, and medical reasoning benchmarks, our approach consistently improves pass@$k$ across large sampling budgets and increases the area under the pass@$k$ curve (AUC@$K$) without sacrificing pass@1, while sustaining exploration and uncovering more diverse solution strategies at scale.

</details>


### [219] [Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling](https://arxiv.org/abs/2601.08777)
*Yang Cai,Weiqiang Zheng*

Main category: cs.LG

TL;DR: 本文研究大语言模型在用户偏好异质且可能冲突情况下的通用对齐问题，提出通过测试时缩放（test-time scaling）实现理想对齐。引入$(k,f(k))$-鲁棒对齐概念，要求模型在生成$k$个候选响应后，其胜率不低于$f(k)$；并定义渐进通用对齐（U-alignment），即当$k\to\infty$时$f(k)\to1$。核心结果表明，存在一类单输出策略，其$k$样本组合策略能达到最优收敛速率$f(k)=\frac{k}{k+1}$，且任何方法无法超越此速率。现有方法如基于人类反馈的纳什学习（NLHF）因缺乏输出多样性而无法有效利用测试时缩放，仅能保证略高于$\frac{1}{2}$的胜率。本文提出对称多玩家对齐博弈框架，证明任意对称纳什均衡策略可实现最优$(k,\frac{k}{k+1})$-鲁棒对齐，并给出自对弈学习动态的理论收敛性保证，同时扩展至对手也生成多响应的情形。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在面对多样化甚至冲突的用户偏好时难以实现个性化与可信对齐。现有方法在测试阶段仅生成单一输出，无法充分利用用户选择带来的反馈信息。为提升模型适应能力，需在测试时引入多候选响应机制，但如何设计有效的对齐策略以确保随着候选数增加，模型表现持续提升，是关键挑战。

Method: 提出$(k,f(k))$-鲁棒对齐与渐进通用对齐（U-alignment）的形式化定义；构建对称多玩家对齐博弈框架，利用纳什均衡策略实现输出多样性；通过分析单输出策略的$k$样本组合行为，推导出最优收敛速率；使用自对弈学习动态进行训练，并扩展至对手亦生成多响应的情况。

Result: 证明了在一般情况下，不存在方法能超越$\frac{k}{k+1}$的胜率收敛速率；现有方法如NLHF由于缺乏输出多样性，无法有效利用测试时缩放，胜率仅略高于$\frac{1}{2}$；提出的对称多玩家博弈框架所得到的策略能够达到最优速率，且具有良好的理论收敛性。

Conclusion: 本研究揭示了测试时缩放在实现通用对齐中的潜力与限制，提出了一个理论上最优的对齐框架，强调输出多样性的重要性。该框架不仅提供了可实现最优性能的策略构造方式，还具备自对弈学习的稳定性，为未来个性化和可信AI的发展提供了坚实基础。

Abstract: Aligning large language models (LLMs) to serve users with heterogeneous and potentially conflicting preferences is a central challenge for personalized and trustworthy AI. We formalize an ideal notion of universal alignment through test-time scaling: for each prompt, the model produces $k\ge 1$ candidate responses and a user selects their preferred one. We introduce $(k,f(k))$-robust alignment, which requires the $k$-output model to have win rate $f(k)$ against any other single-output model, and asymptotic universal alignment (U-alignment), which requires $f(k)\to 1$ as $k\to\infty$. Our main result characterizes the optimal convergence rate: there exists a family of single-output policies whose $k$-sample product policies achieve U-alignment at rate $f(k)=\frac{k}{k+1}$, and no method can achieve a faster rate in general.
  We show that popular post-training methods, including Nash learning from human feedback (NLHF), can fundamentally underutilize the benefits of test-time scaling. Even though NLHF is optimal for $k=1$, sampling from the resulting (often deterministic) policy cannot guarantee win rates above $\tfrac{1}{2}$ except for an arbitrarily small slack. This stems from a lack of output diversity: existing alignment methods can collapse to a single majority-preferred response, making additional samples redundant. In contrast, our approach preserves output diversity and achieves the optimal test-time scaling rate. In particular, we propose a family of symmetric multi-player alignment games and prove that any symmetric Nash equilibrium policy of the $(k+1)$-player alignment game achieves the optimal $(k,\frac{k}{k+1})$-robust alignment. Finally, we provide theoretical convergence guarantees for self-play learning dynamics in these games and extend the framework to opponents that also generate multiple responses.

</details>


### [220] [Fast and explainable clustering in the Manhattan and Tanimoto distance](https://arxiv.org/abs/2601.08781)
*Stefan Güttel,Kaustubh Roy*

Main category: cs.LG

TL;DR: CLASSIX algorithm is extended to work with Manhattan and Tanimoto distances using vector norms and improved inequalities, achieving up to 80x speedup over DBSCAN and 30x over Taylor-Butina while producing better clusters on a chemical fingerprint dataset.


<details>
  <summary>Details</summary>
Motivation: To enhance the speed and applicability of the CLASSIX clustering algorithm beyond Euclidean distance by adapting it to other metrics like Manhattan and Tanimoto, while maintaining explainability and efficiency.

Method: Replace principal component sorting with vector norm-based sorting; leverage triangle inequality and a sharper intersection inequality for Tanimoto distance to accelerate search and improve performance.

Result: CLASSIX Tanimoto is approximately 30 times faster than Taylor-Butina and 80 times faster than DBSCAN, with superior cluster quality on real-world chemical fingerprint data.

Conclusion: The extended CLASSIX algorithm demonstrates significant performance gains across multiple distance metrics, especially with Tanimoto distance, making it highly efficient and effective for large-scale, real-world clustering tasks.

Abstract: The CLASSIX algorithm is a fast and explainable approach to data clustering. In its original form, this algorithm exploits the sorting of the data points by their first principal component to truncate the search for nearby data points, with nearness being defined in terms of the Euclidean distance. Here we extend CLASSIX to other distance metrics, including the Manhattan distance and the Tanimoto distance. Instead of principal components, we use an appropriate norm of the data vectors as the sorting criterion, combined with the triangle inequality for search termination. In the case of Tanimoto distance, a provably sharper intersection inequality is used to further boost the performance of the new algorithm. On a real-world chemical fingerprint benchmark, CLASSIX Tanimoto is about 30 times faster than the Taylor--Butina algorithm, and about 80 times faster than DBSCAN, while computing higher-quality clusters in both cases.

</details>
