<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 94]
- [cs.CL](#cs.CL) [Total: 34]
- [cs.LG](#cs.LG) [Total: 56]
- [cs.AI](#cs.AI) [Total: 20]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [nuCarla: A nuScenes-Style Bird's-Eye View Perception Dataset for CARLA Simulation](https://arxiv.org/abs/2511.13744)
*Zhijie Qiao,Zhong Cao,Henry X. Liu*

Main category: cs.CV

TL;DR: nuCarla is a large-scale, BEV-focused dataset built in the CARLA simulator to support closed-loop end-to-end autonomous driving research. It is compatible with nuScenes, offers balanced class distributions, and enables direct use in closed-loop simulations with state-of-the-art BEV detection performance.


<details>
  <summary>Details</summary>
Motivation: Existing datasets are collected under open-loop conditions, limiting their utility for training and evaluating closed-loop E2E autonomous driving systems. There is a lack of standardized, large-scale datasets that support learning meaningful intermediate representations like BEV features, hindering progress in closed-loop development.

Method: nuCarla is constructed within the CARLA simulator, designed to mirror the nuScenes format while providing enhanced data balance and compatibility. It includes high-performance BEV backbones and supports end-to-end closed-loop simulation.

Result: nuCarla achieves state-of-the-art BEV detection performance, enables seamless integration with existing real-world models, and significantly accelerates closed-loop E2E autonomous driving research.

Conclusion: nuCarla serves as a crucial open benchmark that bridges the gap between real-world perception and closed-loop simulation, enabling more reliable and safety-aware advancements in autonomous driving.

Abstract: End-to-end (E2E) autonomous driving heavily relies on closed-loop simulation, where perception, planning, and control are jointly trained and evaluated in interactive environments. Yet, most existing datasets are collected from the real world under non-interactive conditions, primarily supporting open-loop learning while offering limited value for closed-loop testing. Due to the lack of standardized, large-scale, and thoroughly verified datasets to facilitate learning of meaningful intermediate representations, such as bird's-eye-view (BEV) features, closed-loop E2E models remain far behind even simple rule-based baselines. To address this challenge, we introduce nuCarla, a large-scale, nuScenes-style BEV perception dataset built within the CARLA simulator. nuCarla features (1) full compatibility with the nuScenes format, enabling seamless transfer of real-world perception models; (2) a dataset scale comparable to nuScenes, but with more balanced class distributions; (3) direct usability for closed-loop simulation deployment; and (4) high-performance BEV backbones that achieve state-of-the-art detection results. By providing both data and models as open benchmarks, nuCarla substantially accelerates closed-loop E2E development, paving the way toward reliable and safety-aware research in autonomous driving.

</details>


### [2] [Known Meets Unknown: Mitigating Overconfidence in Open Set Recognition](https://arxiv.org/abs/2511.13775)
*Dongdong Zhao,Ranxin Fang,Changtian Song,Zhihui Liu,Jianwen Xiang*

Main category: cs.CV

TL;DR: 本文提出一种新框架以解决开放集识别（OSR）中因已知类别间语义相似导致的过度自信问题。该框架包含两个部分：基于扰动的不确定性估计模块，通过可控参数扰动生成多样化预测并量化预测不确定性；以及基于学习的未知样本检测模块，采用两阶段过程利用不确定性提升已知与未知类别的区分能力，从而增强OSR性能。在三个公开数据集上的实验表明，该方法优于现有OSR方法。


<details>
  <summary>Details</summary>
Motivation: 当未知样本与已知类别在语义上相近时，特征空间中的类别间重叠会导致模型对其赋予过高置信度，从而错误地将其分类为已知类别，即产生过度自信现象，这会模糊已知与未知类别的决策边界，影响开放集识别的准确性。

Method: 提出一个双组件框架：1）基于扰动的不确定性估计模块，通过施加可控参数扰动生成多样预测，以量化模型的不确定性；2）未知检测模块，采用两阶段学习策略，利用估计的不确定性来增强对已知与未知类别的区分能力。

Result: 在三个公开数据集上的实验结果表明，所提框架在开放集识别任务中表现优于现有方法，有效缓解了过度自信问题，提升了未知样本的检出能力。

Conclusion: 所提出的框架通过显式建模和抑制由类别间重叠引发的过度自信，显著提升了开放集识别的性能，为处理语义相似的未知样本提供了有效的解决方案。

Abstract: Open Set Recognition (OSR) requires models not only to accurately classify known classes but also to effectively reject unknown samples. However, when unknown samples are semantically similar to known classes, inter-class overlap in the feature space often causes models to assign unjustifiably high confidence to them, leading to misclassification as known classes -- a phenomenon known as overconfidence. This overconfidence undermines OSR by blurring the decision boundary between known and unknown classes. To address this issue, we propose a framework that explicitly mitigates overconfidence caused by inter-class overlap. The framework consists of two components: a perturbation-based uncertainty estimation module, which applies controllable parameter perturbations to generate diverse predictions and quantify predictive uncertainty, and an unknown detection module with distinct learning-based classifiers, implemented as a two-stage procedure, which leverages the estimated uncertainty to improve discrimination between known and unknown classes, thereby enhancing OSR performance. Experimental results on three public datasets show that the proposed framework achieves superior performance over existing OSR methods.

</details>


### [3] [Temporal Object-Aware Vision Transformer for Few-Shot Video Object Detection](https://arxiv.org/abs/2511.13784)
*Yogesh Kumar,Anand Mishra*

Main category: cs.CV

TL;DR: 本文提出了一种新型的物体感知时间建模方法，用于少样本视频目标检测（FSVOD），通过选择性传播高置信度目标特征来提升时间一致性并减少噪声累积，从而在有限标注数据下实现更准确的目标检测。该方法不依赖复杂的区域提议，显著降低计算开销，并在多个基准上取得显著性能提升，包括5-shot设置下4.3%至5.3%的AP增益。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法需要大量标注数据，难以应对新对象检测；而少样本视频目标检测面临时间一致性保持、外观变化与遮挡处理等挑战，且现有方法常依赖复杂且耗时的区域提议机制，限制了效率与泛化能力。因此亟需一种高效、鲁棒且无需任务特定训练的新方法。

Method: 提出一种物体感知的时间建模机制，引入过滤机制以选择性传播高置信度的目标特征，实现高效特征传递；结合少样本训练的检测与分类头，聚焦于关键特征传播，避免使用显式物体轨迹提议，提升时间一致性与泛化能力。

Result: 在5-shot设置下，相对于基线模型，实现了3.7%（FSVOD-500）、5.3%（FSYTV-40）、4.3%（VidOR）和4.5%（VidVRD）的平均精度（AP）提升；在1-shot、3-shot及10-shot设置中也表现出持续改进。

Conclusion: 所提方法有效解决了少样本视频目标检测中的时间一致性与泛化难题，通过轻量级特征传播机制实现高性能，同时避免复杂区域提议，具有良好的实用性和可扩展性，代码已开源。

Abstract: Few-shot Video Object Detection (FSVOD) addresses the challenge of detecting novel objects in videos with limited labeled examples, overcoming the constraints of traditional detection methods that require extensive training data. This task presents key challenges, including maintaining temporal consistency across frames affected by occlusion and appearance variations, and achieving novel object generalization without relying on complex region proposals, which are often computationally expensive and require task-specific training. Our novel object-aware temporal modeling approach addresses these challenges by incorporating a filtering mechanism that selectively propagates high-confidence object features across frames. This enables efficient feature progression, reduces noise accumulation, and enhances detection accuracy in a few-shot setting. By utilizing few-shot trained detection and classification heads with focused feature propagation, we achieve robust temporal consistency without depending on explicit object tube proposals. Our approach achieves performance gains, with AP improvements of 3.7% (FSVOD-500), 5.3% (FSYTV-40), 4.3% (VidOR), and 4.5 (VidVRD) in the 5-shot setting. Further results demonstrate improvements in 1-shot, 3-shot, and 10-shot configurations. We make the code public at: https://github.com/yogesh-iitj/fs-video-vit

</details>


### [4] [FusionFM: All-in-One Multi-Modal Image Fusion with Flow Matching](https://arxiv.org/abs/2511.13794)
*Huayi Zhu,Xiu Shu,Youqiang Xiong,Qiao Liu,Rui Chen,Di Yuan,Xiaojun Chang,Zhenyu He*

Main category: cs.CV

TL;DR: 本文提出一种基于流匹配的多模态图像融合方法，通过直接概率传输实现高效采样，利用多模型生成的伪标签与任务感知选择机制缓解高质量监督数据缺失问题，并引入分而治之的融合精炼模块提升图像质量。针对多任务场景，结合弹性权重固化与经验回放机制增强持续学习能力，显著提升效率与模型轻量化水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖特定任务模型，训练成本高且可扩展性差；生成方法虽具统一建模优势，但推理速度慢，因复杂采样路径导致效率低下。因此需要一种高效、通用且能持续学习的图像融合框架。

Method: 将图像融合建模为从源模态到融合图像分布的直接概率传输，采用流匹配范式加速采样过程；通过集成多个先进模型的融合结果作为先验，使用任务感知选择函数筛选可靠伪标签；设计融合精炼模块以分解并增强劣化成分；在多任务设置中引入弹性权重固化与经验回放机制，兼顾参数稳定与记忆保留。

Result: 在多种融合任务上达到竞争力性能，显著提升采样效率，同时保持轻量级模型结构，具备良好的持续学习能力。

Conclusion: 所提方法有效解决了多模态图像融合中的效率、泛化与持续学习难题，为构建高效、通用的融合系统提供了新思路。

Abstract: Current multi-modal image fusion methods typically rely on task-specific models, leading to high training costs and limited scalability. While generative methods provide a unified modeling perspective, they often suffer from slow inference due to the complex sampling trajectories from noise to image. To address this, we formulate image fusion as a direct probabilistic transport from source modalities to the fused image distribution, leveraging the flow matching paradigm to improve sampling efficiency and structural consistency. To mitigate the lack of high-quality fused images for supervision, we collect fusion results from multiple state-of-the-art models as priors, and employ a task-aware selection function to select the most reliable pseudo-labels for each task. We further introduce a Fusion Refiner module that employs a divide-and-conquer strategy to systematically identify, decompose, and enhance degraded components in selected pseudo-labels. For multi-task scenarios, we integrate elastic weight consolidation and experience replay mechanisms to preserve cross-task performance and enhance continual learning ability from both parameter stability and memory retention perspectives. Our approach achieves competitive performance across diverse fusion tasks, while significantly improving sampling efficiency and maintaining a lightweight model design. The code will be available at: https://github.com/Ist-Zhy/FusionFM.

</details>


### [5] [A Trajectory-free Crash Detection Framework with Generative Approach and Segment Map Diffusion](https://arxiv.org/abs/2511.13795)
*Weiying Shen,Hao Yu,Yu Dong,Pan Liu,Yu Han,Xin Wen*

Main category: cs.CV

TL;DR: 提出了一种两阶段无轨迹碰撞检测框架Mapfusion，通过扩散模型生成合理的未来道路段地图，并利用监控地图与生成地图的对比实现碰撞检测。该方法不依赖轨迹获取和车辆跟踪，结合序列嵌入捕捉时间动态，并通过ControlNet引入背景上下文以增强生成控制。在真实世界数据上的实验表明，该方法能有效准确地检测交通事故。


<details>
  <summary>Details</summary>
Motivation: 现有碰撞检测方法受限于轨迹获取和车辆跟踪的精度与实时性，难以满足主动安全管理和交通效率提升的需求。为克服这些局限，本文提出直接基于道路段地图进行碰撞检测的新思路，避免对个体车辆轨迹的依赖。

Method: 采用两阶段框架：第一阶段使用基于扩散的段地图生成模型Mapfusion，通过从噪声到正常状态的去噪过程生成未来道路段地图；该过程由序列嵌入组件驱动以捕捉时间动态，并通过ControlNet集成背景上下文信息；第二阶段通过比较实际监控地图与生成地图来识别碰撞事件。

Result: Mapfusion在非碰撞车辆运动数据上训练后，能够根据学习到的运动模式生成逼真的道路段演化地图，并在不同采样间隔下保持鲁棒性。真实世界事故数据的实验验证了该方法在碰撞检测中的高准确性与有效性。

Conclusion: 所提出的两阶段无轨迹碰撞检测框架通过融合扩散模型与上下文感知生成机制，实现了高效、精准的实时碰撞检测，为智能交通系统提供了新的技术路径。

Abstract: Real-time crash detection is essential for developing proactive safety management strategy and enhancing overall traffic efficiency. To address the limitations associated with trajectory acquisition and vehicle tracking, road segment maps recording the individual-level traffic dynamic data were directly served in crash detection. A novel two-stage trajectory-free crash detection framework, was present to generate the rational future road segment map and identify crashes. The first-stage diffusion-based segment map generation model, Mapfusion, conducts a noisy-to-normal process that progressively adds noise to the road segment map until the map is corrupted to pure Gaussian noise. The denoising process is guided by sequential embedding components capturing the temporal dynamics of segment map sequences. Furthermore, the generation model is designed to incorporate background context through ControlNet to enhance generation control. Crash detection is achieved by comparing the monitored segment map with the generations from diffusion model in second stage. Trained on non-crash vehicle motion data, Mapfusion successfully generates realistic road segment evolution maps based on learned motion patterns and remains robust across different sampling intervals. Experiments on real-world crashes indicate the effectiveness of the proposed two-stage method in accurately detecting crashes.

</details>


### [6] [Synergizing Multigrid Algorithms with Vision Transformer: A Novel Approach to Enhance the Seismic Foundation Model](https://arxiv.org/abs/2511.13800)
*Huiwen Wu,Shuo Zhang,Yi Liu,Hongbin Ye*

Main category: cs.CV

TL;DR: 本文提出了一种针对地震波形数据的自适应双网格基础模型训练策略（ADATG），结合希尔伯特编码，通过频谱分解分离高低频成分，并利用分层希尔伯特编码有效表示数据。基于视觉变换器中的频率原理，采用渐进式训练策略，先关注粗粒度信息，再逐步聚焦细粒度特征。实验表明该方法在地震数据预训练中具有高效性和有效性，强调了针对高低频特征设计编码与训练策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 地震数据具有独特的高低频特征，现有视觉变换器（ViTs）的序列化处理方式无法有效捕捉这些特征，导致预训练效果不佳。因此需要一种专门针对地震数据特性的新型训练策略。

Method: 提出ADATG方法，包含频谱分解以分离高低频成分，分层希尔伯特编码进行数据表示，并设计基于频率原理的自适应训练策略，先关注粗粒度信息，后逐步优化对细粒度特征的学习。

Result: 大量实验验证了所提方法在地震数据预训练中的有效性与效率，显著提升了视觉地震基础模型的性能。

Conclusion: 针对地震数据的高低频特性，合理的数据编码和自适应训练策略对于提升视觉地震基础模型的预训练效果至关重要，本研究为地震领域基础模型的发展提供了新思路。

Abstract: Due to the emergency and homogenization of Artificial Intelligence (AI) technology development, transformer-based foundation models have revolutionized scientific applications, such as drug discovery, materials research, and astronomy. However, seismic data presents unique characteristics that require specialized processing techniques for pretraining foundation models in seismic contexts with high- and low-frequency features playing crucial roles. Existing vision transformers (ViTs) with sequential tokenization ignore the intrinsic pattern and fail to grasp both the high- and low-frequency seismic information efficiently and effectively. This work introduces a novel adaptive two-grid foundation model training strategy (ADATG) with Hilbert encoding specifically tailored for seismogram data, leveraging the hierarchical structures inherent in seismic data. Specifically, our approach employs spectrum decomposition to separate high- and low-frequency components and utilizes hierarchical Hilbert encoding to represent the data effectively. Moreover, observing the frequency principle observed in ViTs, we propose an adaptive training strategy that initially emphasizes coarse-level information and then progressively refines the model's focus on fine-level features. Our extensive experiments demonstrate the effectiveness and efficiency of our training methods. This research highlights the importance of data encoding and training strategies informed by the distinct characteristics of high- and low-frequency features in seismic images, ultimately contributing to the enhancement of visual seismic foundation models pretraining.

</details>


### [7] [Passive Dementia Screening via Facial Temporal Micro-Dynamics Analysis of In-the-Wild Talking-Head Video](https://arxiv.org/abs/2511.13802)
*Filippo Cenacchi. Longbing Cao,Mitchell McEwan,Deborah Richards*

Main category: cs.CV

TL;DR: 本文提出一种无需语言的被动阿尔茨海默病筛查方法，通过分析短时摄像头拍摄的说话头视频中的面部微动态（如眨眼、嘴部/下颌微动、视线变化和头部细微调整），实现无干预、跨设备、跨文化的大规模自然状态视频分析。研究构建了新的公开数据集YT DemTalk（300段视频，含150例自报痴呆与150例对照），并设计了一种基于面部微动态时间序列的分析框架，通过稳定信号、平滑处理并提取片段级统计特征，以运动分布而非幅度作为判别依据，提升模型可解释性。实验表明，注视不稳定性与口颌运动最具诊断价值，轻量级分类器即可达到AUROC 0.953、AP 0.961、F1-score 0.851、准确率0.857的优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有痴呆筛查多依赖语音或脚本化访谈，受限于临床环境、语言与转录，难以实现大规模、无干预的自然状态分析。本文旨在探索仅通过面部微动态即可实现早期神经认知变化检测的可能性，突破语言与文本依赖，推动被动、可扩展、跨文化的痴呆筛查技术发展。

Method: 提出一种面部时间微动态分析框架：首先对原始视频进行面部信号稳定化处理，将微动作转化为可解释的时间序列；随后对信号进行平滑，并在短时间窗口内提取紧凑的片段级统计特征；采用‘活动混合’（activity mix）编码方式，即分析各运动通道间的相对贡献比例，使模型关注运动分布而非绝对强度，增强可解释性；结合新构建的公开数据集YT DemTalk进行模型训练与评估。

Result: 在新数据集YT DemTalk上，模型表现出卓越的筛查性能：轻量级分类器达到AUROC 0.953，平均精度（AP）0.961，F1-score 0.851，准确率0.857；消融实验表明，注视不稳定性与口颌微动是最重要的判别线索。

Conclusion: 仅依靠面部微动态信息即可实现高精度、无需语言参与的阿尔茨海默病早期筛查，具备在真实世界中大规模部署的潜力，为未来无接触、跨文化、非侵入式神经认知健康监测提供了新范式。

Abstract: We target passive dementia screening from short camera-facing talking head video, developing a facial temporal micro dynamics analysis for language free detection of early neuro cognitive change. This enables unscripted, in the wild video analysis at scale to capture natural facial behaviors, transferrable across devices, topics, and cultures without active intervention by clinicians or researchers during recording. Most existing resources prioritize speech or scripted interviews, limiting use outside clinics and coupling predictions to language and transcription. In contrast, we identify and analyze whether temporal facial kinematics, including blink dynamics, small mouth jaw motions, gaze variability, and subtle head adjustments, are sufficient for dementia screening without speech or text. By stabilizing facial signals, we convert these micro movements into interpretable facial microdynamic time series, smooth them, and summarize short windows into compact clip level statistics for screening. Each window is encoded by its activity mix (the relative share of motion across streams), thus the predictor analyzes the distribution of motion across streams rather than its magnitude, making per channel effects transparent. We also introduce YT DemTalk, a new dataset curated from publicly available, in the wild camera facing videos. It contains 300 clips (150 with self reported dementia, 150 controls) to test our model and offer a first benchmarking of the corpus. On YT DemTalk, ablations identify gaze lability and mouth/jaw dynamics as the most informative cues, and light weighted shallow classifiers could attain a dementia prediction performance of (AUROC) 0.953, 0.961 Average Precision (AP), 0.851 F1-score, and 0.857 accuracy.

</details>


### [8] [Can World Simulators Reason? Gen-ViRe: A Generative Visual Reasoning Benchmark](https://arxiv.org/abs/2511.13853)
*Xinxin Liu,Zhaopan Xu,Kai Wang,Yong Jae Lee,Yuzhang Shang*

Main category: cs.CV

TL;DR: 提出Gen-ViRe基准，用于量化评估视频生成模型在链式帧（CoF）推理中的认知能力，涵盖从感知逻辑到抽象规划的六个维度和24个子任务，揭示了视觉质量与实际推理深度之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽能生成高质量视觉序列，但缺乏对多步规划、算法逻辑和抽象模式外推等核心认知能力的评估，导致无法系统理解模型真实推理能力并指导改进。

Method: 基于认知科学与现实应用设计Gen-ViRe框架，通过多源数据收集、最小化提示协议及混合视觉语言模型辅助评估，分解CoF推理为六维认知维度与24个子任务，实现定量评估。

Result: 实验显示当前顶尖模型在视觉质量上表现优异，但在推理深度方面存在明显不足，建立了基准线与诊断工具，推动真正世界模拟器的发展。

Conclusion: Gen-ViRe是首个对视频生成模型作为推理者进行量化评估的框架，揭示了现有模型在认知推理上的局限性，为未来模型优化提供了方向。

Abstract: While Chain-of-Thought (CoT) prompting enables sophisticated symbolic reasoning in LLMs, it remains confined to discrete text and cannot simulate the continuous, physics-governed dynamics of the real world. Recent video generation models have emerged as potential world simulators through Chain-of-Frames (CoF) reasoning -- materializing thought as frame-by-frame visual sequences, with each frame representing a physically-grounded reasoning step. Despite compelling demonstrations, a challenge persists: existing benchmarks, focusing on fidelity or alignment, do not assess CoF reasoning and thus cannot measure core cognitive abilities in multi-step planning, algorithmic logic, or abstract pattern extrapolation. This evaluation void prevents systematic understanding of model capabilities and principled guidance for improvement. We introduce Gen-ViRe (Generative Visual Reasoning Benchmark), a framework grounded in cognitive science and real-world AI applications, which decomposes CoF reasoning into six cognitive dimensions -- from perceptual logic to abstract planning -- and 24 subtasks. Through multi-source data curation, minimal prompting protocols, and hybrid VLM-assisted evaluation with detailed criteria, Gen-ViRe delivers the first quantitative assessment of video models as reasoners. Our experiments on SOTA systems reveal substantial discrepancies between impressive visual quality and actual reasoning depth, establishing baselines and diagnostic tools to advance genuine world simulators.

</details>


### [9] [RSPose: Ranking Based Losses for Human Pose Estimation](https://arxiv.org/abs/2511.13857)
*Muhammed Can Keles,Bedrettin Cetinkaya,Sinan Kalkan,Emre Akbas*

Main category: cs.CV

TL;DR: 本文提出基于排序的损失函数（RSPose），以解决热图法人体姿态估计中的三大问题：(P1) MSE损失对所有像素偏差同等惩罚，不利于关键点峰值的锐化与精确定位；(P2) 热图存在空间与类别不平衡；(P3) 评估指标（mAP）与损失函数不一致。所提方法在理论上和实证上均优于传统损失（如MSE、KL散度），显著提升置信度得分与定位质量的相关性，从而改善NMS中实例选择精度与mAP表现。RSPose在COCO、CrowdPose、MPII三个数据集上均表现优异，尤其在COCO-val上达到79.9 mAP（ViTPose-H），并使SimCC ResNet-50提升1.5 AP至73.6，是首个针对mAP设计的损失函数。


<details>
  <summary>Details</summary>
Motivation: 现有热图法人体姿态估计因使用MSE等损失函数，导致关键点定位不准、热图不平衡及评价指标与训练目标不一致，影响最终性能。为解决这些问题，需设计更符合实际评估标准（mAP）的损失函数。

Method: 提出基于排序的损失函数，通过优化热图中关键点峰值的相对排序关系，增强峰值锐度与定位准确性，并提升置信度与定位质量的相关性，实现与mAP评价指标的一致性。该方法适用于一维与二维热图，在多种模型与数据集上验证有效性。

Result: RSPose在多个基准测试中超越先前最先进方法：在COCO-val上达到79.9 mAP（ViTPose-H），同时将SimCC ResNet-50的性能提升1.5 AP至73.6，显著改善了关键点定位与实例选择质量。

Conclusion: 本研究首次提出与mAP评价指标对齐的排序损失函数，有效缓解热图法中的核心缺陷，显著提升人体姿态估计性能，为未来基于热图的方法提供了新的优化方向。

Abstract: While heatmap-based human pose estimation methods have shown strong performance, they suffer from three main problems: (P1) "Commonly used Mean Squared Error (MSE)" Loss may not always improve joint localization because it penalizes all pixel deviations equally, without focusing explicitly on sharpening and correctly localizing the peak corresponding to the joint; (P2) heatmaps are spatially and class-wise imbalanced; and, (P3) there is a discrepancy between the evaluation metric (i.e., mAP) and the loss functions.
  We propose ranking-based losses to address these issues.
  Both theoretically and empirically, we show that our proposed losses are superior to commonly used heatmap losses (MSE, KL-Divergence). Our losses considerably increase the correlation between confidence scores and localization qualities, which is desirable because higher correlation leads to more accurate instance selection during Non-Maximum Suppression (NMS) and better Average Precision (mAP) performance. We refer to the models trained with our losses as RSPose.
  We show the effectiveness of RSPose across two different modes: one-dimensional and two-dimensional heatmaps, on three different datasets (COCO, CrowdPose, MPII).
  To the best of our knowledge, we are the first to propose losses that align with the evaluation metric (mAP) for human pose estimation.
  RSPose outperforms the previous state of the art on the COCO-val set and achieves an mAP score of 79.9 with ViTPose-H, a vision transformer model for human pose estimation.
  We also improve SimCC Resnet-50, a coordinate classification-based pose estimation method, by 1.5 AP on the COCO-val set, achieving 73.6 AP.

</details>


### [10] [Segmenting Collision Sound Sources in Egocentric Videos](https://arxiv.org/abs/2511.13863)
*Kranti Kumar Parida,Omar Emara,Hazel Doughty,Dima Damen*

Main category: cs.CV

TL;DR: 提出新任务碰撞声音源分割（CS3），旨在根据音频在视频中分割出引发碰撞声的物体。利用基础模型CLIP和SAM2，结合第一人称视角中的手部动作线索，实现弱监督音频条件分割，在两个新基准上性能显著优于基线，提升达3倍和4.7倍。


<details>
  <summary>Details</summary>
Motivation: 人类能通过物体相互作用的声音识别其属性，但现有方法难以处理由两个物体交互产生的复杂碰撞声，尤其在第一人称视角下视觉场景杂乱、物体小且交互短暂，因此需要新任务与方法解决此挑战。

Method: 采用弱监督学习框架，结合CLIP和SAM2等基础模型进行音频条件分割，并引入第一人称视角中的手部物体作为动作线索以定位潜在的碰撞声音源。

Result: 在自建的EPIC-CS3和Ego4D-CS3两个基准上，mIoU指标分别比最优基线高出3倍和4.7倍，验证了方法的有效性。

Conclusion: 所提出的CS3任务及基于基础模型与视角线索的弱监督分割方法，有效解决了第一人称视频中复杂碰撞声音源的精准定位问题，为多模态感知提供了新思路。

Abstract: Humans excel at multisensory perception and can often recognise object properties from the sound of their interactions. Inspired by this, we propose the novel task of Collision Sound Source Segmentation (CS3), where we aim to segment the objects responsible for a collision sound in visual input (i.e. video frames from the collision clip), conditioned on the audio. This task presents unique challenges. Unlike isolated sound events, a collision sound arises from interactions between two objects, and the acoustic signature of the collision depends on both. We focus on egocentric video, where sounds are often clear, but the visual scene is cluttered, objects are small, and interactions are brief.
  To address these challenges, we propose a weakly-supervised method for audio-conditioned segmentation, utilising foundation models (CLIP and SAM2). We also incorporate egocentric cues, i.e. objects in hands, to find acting objects that can potentially be collision sound sources. Our approach outperforms competitive baselines by $3\times$ and $4.7\times$ in mIoU on two benchmarks we introduce for the CS3 task: EPIC-CS3 and Ego4D-CS3.

</details>


### [11] [GRLoc: Geometric Representation Regression for Visual Localization](https://arxiv.org/abs/2511.13864)
*Changyang Li,Xuejian Ma,Lixiang Liu,Zhan Li,Qingan Yan,Yi Xu*

Main category: cs.CV

TL;DR: 本文提出一种名为几何表示回归（GRR）的新范式，用于视觉定位。与传统绝对姿态回归（APR）直接从图像中端到端预测6-DoF姿态不同，GRR反向思考，通过回归图像对应的3D几何表示来估计姿态。模型显式地在世界坐标系中预测两个解耦的几何表示：射线束方向（用于估计旋转）和对应点图（用于估计平移），最终通过可微分确定性求解器恢复完整姿态。这种解耦设计引入了强几何先验，有效提升泛化能力，并在7-Scenes和Cambridge Landmarks数据集上达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 传统绝对姿态回归（APR）模型作为黑箱，容易记忆训练视图而非理解3D场景几何，导致泛化能力差。为提升鲁棒性和可解释性，需要引入更强的几何先验。

Method: 提出几何表示回归（GRR）范式，将APR逆向为从图像回归底层3D几何表示；显式预测射线方向（用于旋转）和点图（用于平移）；通过可微分确定性求解器合成最终6-DoF姿态；采用解耦学习策略分离视觉到几何映射与姿态计算。

Result: 在7-Scenes和Cambridge Landmarks数据集上实现当前最优性能，验证了逆向渲染建模路径的有效性与鲁棒性；解耦设计显著提升模型对新场景的泛化能力。

Conclusion: 通过回归3D几何表示而非直接预测姿态，GRR范式显著增强了模型的几何理解能力与泛化性能，为可解释、鲁棒的视觉定位提供了新思路。

Abstract: Absolute Pose Regression (APR) has emerged as a compelling paradigm for visual localization. However, APR models typically operate as black boxes, directly regressing a 6-DoF pose from a query image, which can lead to memorizing training views rather than understanding 3D scene geometry. In this work, we propose a geometrically-grounded alternative. Inspired by novel view synthesis, which renders images from intermediate geometric representations, we reformulate APR as its inverse that regresses the underlying 3D representations directly from the image, and we name this paradigm Geometric Representation Regression (GRR). Our model explicitly predicts two disentangled geometric representations in the world coordinate system: (1) a ray bundle's directions to estimate camera rotation, and (2) a corresponding pointmap to estimate camera translation. The final 6-DoF camera pose is then recovered from these geometric components using a differentiable deterministic solver. This disentangled approach, which separates the learned visual-to-geometry mapping from the final pose calculation, introduces a strong geometric prior into the network. We find that the explicit decoupling of rotation and translation predictions measurably boosts performance. We demonstrate state-of-the-art performance on 7-Scenes and Cambridge Landmarks datasets, validating that modeling the inverse rendering process is a more robust path toward generalizable absolute pose estimation.

</details>


### [12] [H-CNN-ViT: A Hierarchical Gated Attention Multi-Branch Model for Bladder Cancer Recurrence Prediction](https://arxiv.org/abs/2511.13869)
*Xueyang Li,Zongren Wang,Yuliang Zhang,Zixuan Pan,Yu-Jen Chen,Nishchal Sapkota,Gelei Xu,Danny Z. Chen,Yiyu Shi*

Main category: cs.CV

TL;DR: 本研究提出一个专门用于膀胱癌复发预测的多序列、多模态MRI数据集，并开发了H-CNN-ViT模型，该模型通过分层门控注意力机制实现全局（ViT）与局部（CNN）特征的动态融合，在自建数据集上取得78.6%的AUC，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 膀胱癌术后复发率高，需精准监测；现有MRI影像解读因术后改变困难，且缺乏专用多序列MRI数据集，限制了AI在复发预测中的发展。

Method: 构建多序列多模态MRI数据集，提出H-CNN-ViT模型，采用多分支结构独立处理各模态，结合层级门控注意力实现上下文感知的特征融合。

Result: H-CNN-ViT在自建数据集上达到78.6% AUC，性能超越当前最优模型。

Conclusion: 本研究建立了首个针对膀胱癌复发预测的多模态MRI基准数据集，并提出高效融合模型H-CNN-ViT，为未来研究提供重要基础和工具。

Abstract: Bladder cancer is one of the most prevalent malignancies worldwide, with a recurrence rate of up to 78%, necessitating accurate post-operative monitoring for effective patient management. Multi-sequence contrast-enhanced MRI is commonly used for recurrence detection; however, interpreting these scans remains challenging, even for experienced radiologists, due to post-surgical alterations such as scarring, swelling, and tissue remodeling. AI-assisted diagnostic tools have shown promise in improving bladder cancer recurrence prediction, yet progress in this field is hindered by the lack of dedicated multi-sequence MRI datasets for recurrence assessment study. In this work, we first introduce a curated multi-sequence, multi-modal MRI dataset specifically designed for bladder cancer recurrence prediction, establishing a valuable benchmark for future research. We then propose H-CNN-ViT, a new Hierarchical Gated Attention Multi-Branch model that enables selective weighting of features from the global (ViT) and local (CNN) paths based on contextual demands, achieving a balanced and targeted feature fusion. Our multi-branch architecture processes each modality independently, ensuring that the unique properties of each imaging channel are optimally captured and integrated. Evaluated on our dataset, H-CNN-ViT achieves an AUC of 78.6%, surpassing state-of-the-art models. Our model is publicly available at https://github.com/XLIAaron/H-CNN-ViT}.

</details>


### [13] [QwenCLIP: Boosting Medical Vision-Language Pretraining via LLM Embeddings and Prompt tuning](https://arxiv.org/abs/2511.13876)
*Xiaoyang Wei,Camille Kurtz,Florence Cloppet*

Main category: cs.CV

TL;DR: QwenCLIP 提出一种基于大语言模型（如 Qwen3-Embedding）的文本编码器，替代 CLIP 的短文本限制，以增强医学影像与长篇放射学报告之间的跨模态对齐，显著提升在放射学基准上的性能。


<details>
  <summary>Details</summary>
Motivation: CLIP 的文本编码器仅支持最多 77 个标记，难以处理信息丰富的长篇放射学报告；现有医学专用编码器虽改进了领域适应性，但受限于输入长度（约 512 标记）和语义理解深度。

Method: 用 LLM 基础嵌入模块（如 Qwen3-Embedding）替换 CLIP 的文本编码器，并引入可学习提示（learnable prompts）以增强视觉-语言对齐能力。

Result: QwenCLIP 能够有效捕捉长文本中的全面医学语义，在多个放射学图像-文本对齐任务中显著提升性能，优于现有方法。

Conclusion: 通过结合大语言模型的长上下文能力和可学习提示机制，QwenCLIP 实现了更强大的医学视觉-语言理解，为医疗领域跨模态任务提供了高效解决方案。

Abstract: Contrastive Language-Image Pretraining (CLIP) has demonstrated strong generalization for vision-language tasks in computer vision and medical domains, yet its text encoder accepts only up to 77 tokens, which limits its ability to represent long and information-rich radiology reports. Recent adaptations using domain-specific encoders, such as PubMedBERT or ClinicalBERT, mitigate this issue by leveraging medical corpora, but remain constrained by their limited input length (typically 512 tokens) and relatively shallow semantic understanding. To address these limitations, we propose QwenCLIP, a vision-language framework that replaces CLIP's text encoder with a large language model (LLM)-based embedding module (e.g., Qwen3-Embedding) and introduces learnable prompts to enhance cross-modal alignment. By leveraging the extended context window and richer representations of LLMs, QwenCLIP captures comprehensive medical semantics from long-form clinical text, substantially improving medical image-text alignment and downstream performance on radiology benchmarks. Our code is publicly available at https://github.com/Wxy-24/QwenCLIP.

</details>


### [14] [Hybrid Convolution Neural Network Integrated with Pseudo-Newton Boosting for Lumbar Spine Degeneration Detection](https://arxiv.org/abs/2511.13877)
*Pandiyaraju V,Abishek Karthik,Jaspin K,Kannan A,Jaime Lloret*

Main category: cs.CV

TL;DR: 该论文提出了一种新型增强模型架构，用于基于DICOM图像对腰椎退行性病变进行分类。通过结合EfficientNet和VGG19，并引入自定义组件，构建了一个多层级框架。该模型创新性地采用伪牛顿提升层和稀疏诱导特征压缩层，有效提升了特征选择与表示能力，克服了传统迁移学习在高维医学图像中的局限性。实验结果显示，该模型在精度、召回率、F1分数、损失和准确率方面均优于基准模型EfficientNet，性能显著提升，为自动化医学影像诊断工具的发展提供了支持。


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习方法在处理高维医学图像（如腰椎DICOM图像）时，常因忽略关键解剖特征和特征冗余问题导致性能受限。因此，亟需一种更高效、更具鲁棒性的模型架构来提升腰椎退行性病变的自动分类能力。

Method: 提出一种融合EfficientNet与VGG19的混合架构，引入伪牛顿提升层以动态优化特征权重，增强对细微解剖结构的捕捉；同时设计稀疏诱导特征压缩层，去除冗余特征，生成精炼且稳健的病理特征表示，形成多层级深度学习框架。

Result: 模型在腰椎退行性病变分类任务中达到精度0.9、召回率0.861、F1分数0.88、损失0.18、准确率88.1%，显著优于基准模型EfficientNet，验证了所提架构的有效性与优越性。

Conclusion: 所提出的混合增强模型通过创新的特征优化机制，在高维医学图像分类任务中表现出卓越性能，为开发高效、精准的自动化医学影像诊断系统提供了可行的技术路径。

Abstract: This paper proposes a new enhanced model architecture to perform classification of lumbar spine degeneration with DICOM images while using a hybrid approach, integrating EfficientNet and VGG19 together with custom-designed components. The proposed model is differentiated from traditional transfer learning methods as it incorporates a Pseudo-Newton Boosting layer along with a Sparsity-Induced Feature Reduction Layer that forms a multi-tiered framework, further improving feature selection and representation. The Pseudo-Newton Boosting layer makes smart variations of feature weights, with more detailed anatomical features, which are mostly left out in a transfer learning setup. In addition, the Sparsity-Induced Layer removes redundancy for learned features, producing lean yet robust representations for pathology in the lumbar spine. This architecture is novel as it overcomes the constraints in the traditional transfer learning approach, especially in the high-dimensional context of medical images, and achieves a significant performance boost, reaching a precision of 0.9, recall of 0.861, F1 score of 0.88, loss of 0.18, and an accuracy of 88.1%, compared to the baseline model, EfficientNet. This work will present the architectures, preprocessing pipeline, and experimental results. The results contribute to the development of automated diagnostic tools for medical images.

</details>


### [15] [VLMs Guided Interpretable Decision Making for Autonomous Driving](https://arxiv.org/abs/2511.13881)
*Xin Hu,Taotao Jing,Renran Tian,Zhengming Ding*

Main category: cs.CV

TL;DR: 本文研究了视觉语言模型（VLMs）在自动驾驶中的应用，发现其依赖手工提示且性能不稳定。为此，提出将VLMs从直接决策生成者转变为语义增强者，通过丰富视觉基准数据的语义描述来提升系统表现。进一步设计了多模态交互架构和后处理优化模块，以实现更准确、可解释的决策。实验表明该方法在两个自动驾驶基准上均达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的自动驾驶方法依赖手工提示，存在性能不一致的问题，限制了其在真实场景中的鲁棒性和泛化能力。因此需要一种更可靠、可解释的集成方式。

Method: 将VLMs用作语义增强工具，生成结构化、语言丰富的场景描述；构建多模态交互架构融合视觉与语言特征；引入后处理精炼模块提升预测可靠性。

Result: 在两个自动驾驶基准上实现了当前最优性能，显著提升了决策准确性与可解释性。

Conclusion: 通过将VLMs作为语义增强器而非直接决策者，本方法为构建可靠、可解释的自动驾驶系统提供了新路径。

Abstract: Recent advancements in autonomous driving (AD) have explored the use of vision-language models (VLMs) within visual question answering (VQA) frameworks for direct driving decision-making. However, these approaches often depend on handcrafted prompts and suffer from inconsistent performance, limiting their robustness and generalization in real-world scenarios. In this work, we evaluate state-of-the-art open-source VLMs on high-level decision-making tasks using ego-view visual inputs and identify critical limitations in their ability to deliver reliable, context-aware decisions. Motivated by these observations, we propose a new approach that shifts the role of VLMs from direct decision generators to semantic enhancers. Specifically, we leverage their strong general scene understanding to enrich existing vision-based benchmarks with structured, linguistically rich scene descriptions. Building on this enriched representation, we introduce a multi-modal interactive architecture that fuses visual and linguistic features for more accurate decision-making and interpretable textual explanations. Furthermore, we design a post-hoc refinement module that utilizes VLMs to enhance prediction reliability. Extensive experiments on two autonomous driving benchmarks demonstrate that our approach achieves state-of-the-art performance, offering a promising direction for integrating VLMs into reliable and interpretable AD systems.

</details>


### [16] [Revisiting Data Scaling Law for Medical Segmentation](https://arxiv.org/abs/2511.13883)
*Yuetan Chu,Zhongyi Han,Gongning Luo,Xin Gao*

Main category: cs.CV

TL;DR: 本研究探讨了医学解剖分割中数据规模与模型性能之间的缩放规律，分析了15个语义任务和4种成像模态下的缩放趋势，并提出一种基于图像配准的微分同胚映射生成方法，以提升数据利用效率，实现超越传统幂律缩放的性能提升。


<details>
  <summary>Details</summary>
Motivation: 医学解剖分割领域在数据缩放规律方面研究不足，且现有方法难以有效利用有限标注数据；同时，图像间解剖结构的拓扑同构性提示可通过合理变形增强来改善模型泛化能力。

Method: 基于图像配准构建测地子空间，生成真实的微分同胚形变映射，用于图像增强；对比随机弹性形变与注册引导形变的效果，并引入新型可扩展的形变增强策略。

Result: 所提生成形变方法显著提升数据利用效率，加速模型收敛，性能超越标准幂律缩放趋势，无需额外数据即可实现更优表现。

Conclusion: 该工作揭示了医学影像中分割可扩展性的关键影响因素，特别是拓扑变化的作用，为减少标注与计算成本提供了高效模型开发路径。

Abstract: The population loss of trained deep neural networks often exhibits power law scaling with the size of the training dataset, guiding significant performance advancements in deep learning applications. In this study, we focus on the scaling relationship with data size in the context of medical anatomical segmentation, a domain that remains underexplored. We analyze scaling laws for anatomical segmentation across 15 semantic tasks and 4 imaging modalities, demonstrating that larger datasets significantly improve segmentation performance, following similar scaling trends. Motivated by the topological isomorphism in images sharing anatomical structures, we evaluate the impact of deformation-guided augmentation strategies on data scaling laws, specifically random elastic deformation and registration-guided deformation. We also propose a novel, scalable image augmentation approach that generates diffeomorphic mappings from geodesic subspace based on image registration to introduce realistic deformation. Our experimental results demonstrate that both registered and generated deformation-based augmentation considerably enhance data utilization efficiency. The proposed generated deformation method notably achieves superior performance and accelerated convergence, surpassing standard power law scaling trends without requiring additional data. Overall, this work provides insights into the understanding of segmentation scalability and topological variation impact in medical imaging, thereby leading to more efficient model development with reduced annotation and computational costs.

</details>


### [17] [Uni-Hema: Unified Model for Digital Hematopathology](https://arxiv.org/abs/2511.13889)
*Abdul Rehman,Iqra Rasool,Ayesha Imran,Mohsen Ali,Waqas Sultani*

Main category: cs.CV

TL;DR: Uni-Hema 是一个统一的多任务、多模态数字血液病理模型，旨在解决现有模型在血液病分析中无法跨疾病、跨任务进行统一推理的问题。它整合了检测、分类、分割、形态预测和推理等多种功能，基于 46 个公开数据集（超 70 万张图像和 2.1 万对问答）训练，并采用 Hema-Former 多模态模块实现视觉与文本在不同粒度层级上的融合。实验表明，Uni-Hema 在多种血液学任务中表现优于或相当单任务模型，且能提供可解释的细胞级形态学洞察。该框架为数字血液病理学树立了新标准，代码将公开。


<details>
  <summary>Details</summary>
Motivation: 现有数字血液病理模型多为单任务、单数据集训练，缺乏跨疾病、跨任务、跨模态的统一推理能力，难以应对复杂多样的血液疾病分析需求。

Method: 提出 Uni-Hema 模型，基于 Hema-Former 多模态架构，在不同粒度层级上融合视觉与文本信息，支持检测、分类、分割、形态预测、掩码语言建模和视觉问答等多任务；利用 46 个公开数据集中的超 70 万图像和 2.1 万问答对进行训练。

Result: Uni-Hema 在多项血液病理任务中表现优于或相当于单任务模型，具备强大的多任务、多模态推理能力，并能在单细胞层面提供可解释的形态学分析结果。

Conclusion: Uni-Hema 建立了多任务、多模态数字血液病理分析的新标准，推动了智能血液病理诊断的发展，其开源代码将进一步促进领域研究。

Abstract: Digital hematopathology requires cell-level analysis across diverse disease categories, including malignant disorders (e.g., leukemia), infectious conditions (e.g., malaria), and non-malignant red blood cell disorders (e.g., sickle cell disease). Whether single-task, vision-language, WSI-optimized, or single-cell hematology models, these approaches share a key limitation, they cannot provide unified, multi-task, multi-modal reasoning across the complexities of digital hematopathology. To overcome these limitations, we propose Uni-Hema, a multi-task, unified model for digital hematopathology integrating detection, classification, segmentation, morphology prediction, and reasoning across multiple diseases. Uni-Hema leverages 46 publicly available datasets, encompassing over 700K images and 21K question-answer pairs, and is built upon Hema-Former, a multimodal module that bridges visual and textual representations at the hierarchy level for the different tasks (detection, classification, segmentation, morphology, mask language modeling and visual question answer) at different granularity. Extensive experiments demonstrate that Uni-Hema achieves comparable or superior performance to train on a single-task and single dataset models, across diverse hematological tasks, while providing interpretable, morphologically relevant insights at the single-cell level. Our framework establishes a new standard for multi-task and multi-modal digital hematopathology. The code will be made publicly available.

</details>


### [18] [Weakly Supervised Ephemeral Gully Detection In Remote Sensing Images Using Vision Language Models](https://arxiv.org/abs/2511.13891)
*Seyed Mohamad Ali Tousi,John A. Lory,G. N. DeSouza*

Main category: cs.CV

TL;DR: 提出首个弱监督方法用于农田中临时沟壑的自动检测，利用视觉语言模型（VLMs）减少人工标注负担，并结合教师-学生框架与噪声感知损失函数提升性能。同时发布首个半监督临时沟壑检测数据集，包含超过18,000张高分辨率遥感图像，涵盖13年数据。实验表明该方法优于仅使用VLMs或标签模型的基线方法。代码与数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 临时沟壑在农业用地中具有严重危害，但其生命周期短、难以通过传统计算机视觉和遥感技术自动识别；且高质量标注数据稀缺，限制了机器学习方法的应用，现有研究多依赖难以实现的零样本方法。因此亟需一种高效、低标注成本的检测方案。

Method: 提出基于视觉语言模型（VLMs）的弱监督检测框架：1）利用VLM预训练知识生成初始标签；2）采用教师-学生模型结构，教师基于VLM生成的噪声标签学习，学生则在弱监督下通过教师生成标签及噪声感知损失函数进行训练，从而缓解标注误差影响。

Result: 实验结果表明，所提方法在弱监督条件下显著优于单独使用VLMs或标签模型的表现，验证了其有效性；同时构建并发布了首个面向半监督学习的临时沟壑遥感图像数据集，支持后续研究。

Conclusion: 本工作首次实现了临时沟壑的弱监督自动检测，有效降低了对人工标注的依赖，提升了检测精度与实用性，为农业土壤侵蚀监测提供了可扩展的技术路径。

Abstract: Among soil erosion problems, Ephemeral Gullies are one of the most concerning phenomena occurring in agricultural fields. Their short temporal cycles increase the difficulty in automatically detecting them using classical computer vision approaches and remote sensing. Also, due to scarcity of and the difficulty in producing accurate labeled data, automatic detection of ephemeral gullies using Machine Learning is limited to zero-shot approaches which are hard to implement. To overcome these challenges, we present the first weakly supervised pipeline for detection of ephemeral gullies. Our method relies on remote sensing and uses Vision Language Models (VLMs) to drastically reduce the labor-intensive task of manual labeling. In order to achieve that, the method exploits: 1) the knowledge embedded in the VLM's pretraining; 2) a teacher-student model where the teacher learns from noisy labels coming from the VLMs, and the student learns by weak supervision using teacher-generate labels and a noise-aware loss function. We also make available the first-of-its-kind dataset for semi-supervised detection of ephemeral gully from remote-sensed images. The dataset consists of a number of locations labeled by a group of soil and plant scientists, as well as a large number of unlabeled locations. The dataset represent more than 18,000 high-resolution remote-sensing images obtained over the course of 13 years. Our experimental results demonstrate the validity of our approach by showing superior performances compared to VLMs and the label model itself when using weak supervision to train an student model. The code and dataset for this work are made publicly available.

</details>


### [19] [SAE-MCVT: A Real-Time and Scalable Multi-Camera Vehicle Tracking Framework Powered by Edge Computing](https://arxiv.org/abs/2511.13904)
*Yuqiang Lin,Sam Lockyer,Florian Stanek,Markus Zarbock,Adrian Evans,Wenbin Li,Nic Zhang*

Main category: cs.CV

TL;DR: SAE-MCVT 是首个适用于城市规模部署的可扩展实时多摄像头车辆跟踪框架。该系统采用边缘-中心协同架构，边缘设备处理视频流并仅上传轻量级元数据（位置和外观特征），中央工作站基于自监督相机链接模型进行跨摄像头关联，兼顾实时性与可扩展性。在 RoundaboutHD 数据集上，系统在 2K 15 FPS 视频流下保持实时运行，IDF1 达到 61.2，是首个满足真实场景需求的 MCVT 解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有 MCVT 方法虽注重精度，但忽视实时性和可扩展性，难以在城市规模应用中部署，尤其当摄像头数量增加时挑战加剧。因此亟需一种既能保证高精度又能实现实时、可扩展的解决方案。

Method: 提出 SAE-MCVT 框架，采用边缘-中心协同架构：边缘侧对实时 RTSP 流进行对象检测、跟踪、地理映射和特征提取，仅传输车辆位置和深度外观特征；中央侧利用自监督学习构建相机间时空关系模型，实现跨摄像头关联。

Result: 在 2K 15 FPS 视频流下保持实时运行，IDF1 达到 61.2，首次实现可扩展的实时多摄像头车辆跟踪，适合城市规模部署。

Conclusion: SAE-MCVT 是首个兼顾实时性、可扩展性和高精度的多摄像头车辆跟踪框架，为城市级 ITS 应用提供了可行的技术路径。

Abstract: In modern Intelligent Transportation Systems (ITS), cameras are a key component due to their ability to provide valuable information for multiple stakeholders. A central task is Multi-Camera Vehicle Tracking (MCVT), which generates vehicle trajectories and enables applications such as anomaly detection, traffic density estimation, and suspect vehicle tracking. However, most existing studies on MCVT emphasize accuracy while overlooking real-time performance and scalability. These two aspects are essential for real-world deployment and become increasingly challenging in city-scale applications as the number of cameras grows. To address this issue, we propose SAE-MCVT, the first scalable real-time MCVT framework. The system includes several edge devices that interact with one central workstation separately. On the edge side, live RTSP video streams are serialized and processed through modules including object detection, object tracking, geo-mapping, and feature extraction. Only lightweight metadata -- vehicle locations and deep appearance features -- are transmitted to the central workstation. On the central side, cross-camera association is calculated under the constraint of spatial-temporal relations between adjacent cameras, which are learned through a self-supervised camera link model. Experiments on the RoundaboutHD dataset show that SAE-MCVT maintains real-time operation on 2K 15 FPS video streams and achieves an IDF1 score of 61.2. To the best of our knowledge, this is the first scalable real-time MCVT framework suitable for city-scale deployment.

</details>


### [20] [Mind the Gap: Evaluating LLM Understanding of Human-Taught Road Safety Principles](https://arxiv.org/abs/2511.13909)
*Chalamalasetti Kranti*

Main category: cs.CV

TL;DR: 本研究评估了多模态大语言模型对交通标志和道路安全规范的理解能力，通过零样本设置下的教科书图像数据集进行测试。结果显示，模型在安全推理方面表现不佳，揭示了人类学习与模型理解之间的差距，并为未来研究提供了分析方向。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大语言模型对道路安全概念的理解能力，特别是通过图示和示意性表示，以识别其在自动驾驶安全应用中的潜在局限性。

Method: 构建了一个来自学校教科书的交通标志和道路安全规范图像数据集，用于在零样本设置下评估多模态大语言模型的表现。

Result: 模型在安全推理任务中表现较差，显示出与人类理解之间存在显著差距，尤其在复杂或非字面含义的情境下。

Conclusion: 当前多模态大语言模型在理解和推理道路安全概念方面仍存在明显不足，需进一步研究以提升其在真实交通场景中的可靠性和安全性。

Abstract: Following road safety norms is non-negotiable not only for humans but also for the AI systems that govern autonomous vehicles. In this work, we evaluate how well multi-modal large language models (LLMs) understand road safety concepts, specifically through schematic and illustrative representations. We curate a pilot dataset of images depicting traffic signs and road-safety norms sourced from school text books and use it to evaluate models capabilities in a zero-shot setting. Our preliminary results show that these models struggle with safety reasoning and reveal gaps between human learning and model interpretation. We further provide an analysis of these performance gaps for future research.

</details>


### [21] [Start Small, Think Big: Curriculum-based Relative Policy Optimization for Visual Grounding](https://arxiv.org/abs/2511.13924)
*Qingyang Yan,Guangyao Chen,Yixiong Zou*

Main category: cs.CV

TL;DR: CuRPO提出了一种基于课程学习的相对策略优化方法，利用CoT长度和gIoU奖励作为复杂度指标，逐步从简单到复杂地训练模型，在视觉定位任务中显著提升性能，尤其在少量样本场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 发现RL微调的CoT推理在视觉定位任务中可能因输出过长或复杂而降低性能，且数据集增大不总能带来性能提升，因此需要一种更有效的训练策略来应对复杂性变化。

Method: 提出CuRPO，通过CoT长度和gIoU作为复杂度指示器，构建渐进式训练课程，引导模型从简单到复杂逐步学习。

Result: 在RefCOCO、RefCOCO+、RefCOCOg和LISA等多个数据集上，CuRPO显著优于现有方法，最高提升达+12.52 mAP；在少样本学习中也表现出强鲁棒性和高效性。

Conclusion: CuRPO是一种高效且鲁棒的训练策略，能够有效应对视觉定位任务中的复杂描述与数据异质性问题，特别适用于模糊和复杂的文本-图像对齐任务。

Abstract: Chain-of-Thought (CoT) prompting has recently shown significant promise across various NLP and computer vision tasks by explicitly generating intermediate reasoning steps. However, we find that reinforcement learning (RL)-based fine-tuned CoT reasoning can paradoxically degrade performance in Visual Grounding tasks, particularly as CoT outputs become lengthy or complex. Additionally, our analysis reveals that increased dataset size does not always enhance performance due to varying data complexities. Motivated by these findings, we propose Curriculum-based Relative Policy Optimization (CuRPO), a novel training strategy that leverages CoT length and generalized Intersection over Union (gIoU) rewards as complexity indicators to progressively structure training data from simpler to more challenging examples. Extensive experiments on RefCOCO, RefCOCO+, RefCOCOg, and LISA datasets demonstrate the effectiveness of our approach. CuRPO consistently outperforms existing methods, including Visual-RFT, with notable improvements of up to +12.52 mAP on RefCOCO. Moreover, CuRPO exhibits exceptional efficiency and robustness, delivering strong localization performance even in few-shot learning scenarios, particularly benefiting tasks characterized by ambiguous and intricate textual descriptions.The code is released on https://github.com/qyoung-yan/CuRPO.

</details>


### [22] [Find the Leak, Fix the Split: Cluster-Based Method to Prevent Leakage in Video-Derived Datasets](https://arxiv.org/abs/2511.13944)
*Noam Glazner,Noam Tsfaty,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出一种基于聚类的帧选择策略，通过在划分训练、验证和测试集前对视觉相似的帧进行分组，减少视频帧数据集中的信息泄露，提升数据集划分的代表性、平衡性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决视频衍生帧数据集中因帧之间存在高度相关性而导致的信息泄露问题，确保训练、验证和测试集之间的独立性。

Method: 采用聚类方法对视频帧进行分组，将视觉相似的帧归为同一簇，然后在簇内或簇间进行数据集划分，避免同一视频的多个帧同时出现在不同集合中。

Result: 实验表明，该方法显著降低了信息泄露风险，提升了模型评估的可靠性和泛化能力。

Conclusion: 基于聚类的帧选择策略能有效缓解视频数据集中的信息泄露问题，是构建高质量视频数据集的重要手段。

Abstract: We propose a cluster-based frame selection strategy to mitigate information leakage in video-derived frames datasets. By grouping visually similar frames before splitting into training, validation, and test sets, the method produces more representative, balanced, and reliable dataset partitions.

</details>


### [23] [Can You Learn to See Without Images? Procedural Warm-Up for Vision Transformers](https://arxiv.org/abs/2511.13945)
*Zachary Shinnick,Liangze Jiang,Hemanth Saratchandran,Damien Teney,Anton van den Hengel*

Main category: cs.CV

TL;DR: 本文提出通过在无视觉或语义内容的程序生成数据上预训练视觉变换器（ViTs），以引入跨模态通用归纳偏置。使用形式语法等简单算法生成数据，绕过视觉补丁嵌入机制，使模型学习抽象计算先验。该预训练阶段显著提升数据效率、收敛速度和下游性能，在ImageNet-1k上仅用1%的预算即可提升准确率超过1.7%，相当于28%的ImageNet数据效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何在视觉变换器中引入跨模态通用的归纳偏置，以提升模型的数据效率和泛化能力，避免依赖大量真实图像数据。

Method: 在无视觉或语义内容的程序生成数据上预训练ViTs，利用形式语法生成数据，跳过视觉补丁嵌入，引导模型学习抽象计算先验。随后进行标准图像训练。

Result: 在ImageNet-1k上，仅用1%的程序生成数据预训练，可使最终准确率提升超过1.7%，其效果相当于28%的ImageNet数据。模型在数据效率、收敛速度和下游性能方面均有显著改善。

Conclusion: 程序生成数据预训练是一种高效且通用的预训练策略，有助于构建数据高效、领域无关的视觉模型，为未来通用人工智能提供了新路径。

Abstract: Transformers show remarkable versatility across domains, suggesting the existence of inductive biases beneficial across modalities. In this work, we explore a new way to instil such generic biases in vision transformers (ViTs) by pretraining on procedurally-generated data devoid of visual or semantic content. We generate this data with simple algorithms such as formal grammars, so the results bear no relationship to either natural or synthetic images. We use this procedurally-generated data to pretrain ViTs in a warm-up phase that bypasses their visual patch embedding mechanisms, thus encouraging the models to internalise abstract computational priors. When followed by standard image-based training, this warm-up significantly improves data efficiency, convergence speed, and downstream performance. On ImageNet-1k for example, allocating just 1% of the training budget to procedural data improves final accuracy by over 1.7%. In terms of its effect on performance, 1% procedurally generated data is thus equivalent to 28% of the ImageNet-1k data. These findings suggest a promising path toward new data-efficient and domain-agnostic pretraining strategies.

</details>


### [24] [Learning Skill-Attributes for Transferable Assessment in Video](https://arxiv.org/abs/2511.13993)
*Kumar Ashutosh,Kristen Grauman*

Main category: cs.CV

TL;DR: 提出CrossTrainer方法，通过发现跨运动的通用技能属性（如平衡、控制、手部位置），训练多模态语言模型生成可操作反馈和技能水平评估，显著提升跨运动和同运动场景下的技能评估性能，相对现有技术最高提升60%。


<details>
  <summary>Details</summary>
Motivation: 当前技能评估模型局限于单一运动，且缺乏跨长尾运动领域的专家标注数据，导致泛化能力差。需要一种能跨运动迁移的视频表征方法来降低对专家标注的依赖。

Method: 提出CrossTrainer方法，利用视频表示学习发现跨运动通用技能属性，并基于这些属性训练多模态语言模型，实现对新视频的动作反馈与技能等级判断。

Result: 在跨运动和同运动设置下均取得显著提升，相比现有最佳方法相对增益高达60%，表明该方法具有更强的泛化能力。

Conclusion: 通过抽象共通的人类技能行为，所提出的视频表征方法显著提升了多模态大模型在技能评估任务中的泛化性能，为跨运动技能分析提供了有效解决方案。

Abstract: Skill assessment from video entails rating the quality of a person's physical performance and explaining what could be done better. Today's models specialize for an individual sport, and suffer from the high cost and scarcity of expert-level supervision across the long tail of sports. Towards closing that gap, we explore transferable video representations for skill assessment. Our CrossTrainer approach discovers skill-attributes, such as balance, control, and hand positioning -- whose meaning transcends the boundaries of any given sport, then trains a multimodal language model to generate actionable feedback for a novel video, e.g., "lift hands more to generate more power" as well as its proficiency level, e.g., early expert. We validate the new model on multiple datasets for both cross-sport (transfer) and intra-sport (in-domain) settings, where it achieves gains up to 60% relative to the state of the art. By abstracting out the shared behaviors indicative of human skill, the proposed video representation generalizes substantially better than an array of existing techniques, enriching today's multimodal large language models.

</details>


### [25] [RISE: Single Static Radar-based Indoor Scene Understanding](https://arxiv.org/abs/2511.14019)
*Kaichen Zhou,Laura Dodds,Sayed Saad Afzal,Fadel Adib*

Main category: cs.CV

TL;DR: RISE 是首个针对单静态雷达室内场景理解的基准和系统，通过利用多路径反射（传统上视为噪声）中的几何线索，提出双角度增强方法以恢复二次反射并揭示隐藏结构，并基于仿真到现实的分层扩散框架实现完整的布局重建与物体检测。该研究构建了包含 50,000 帧、100 条真实轨迹的大规模雷达数据集。实验表明，RISE 在布局重建上将 Chamfer 距离降低 60%（降至 16 厘米），首次实现毫米波雷达下的物体检测，达到 58% IoU，为几何感知且隐私保护的室内场景理解提供了新基础。


<details>
  <summary>Details</summary>
Motivation: 现有光学传感器（如 RGB、LiDAR）虽空间分辨率高，但存在严重遮挡问题且在室内环境中带来隐私风险；而毫米波雷达虽具备隐私保护和穿透能力，但其低空间分辨率导致难以进行可靠的几何推理。因此，亟需一种既能保持隐私又能实现精确室内场景理解的新方法。

Method: 提出 Bi-Angular Multipath Enhancement 方法，显式建模到达角（AoA）与出发角（AoD），以恢复二次反射（鬼影）并揭示不可见结构；在此基础上，采用 Simulation-to-Reality Hierarchical Diffusion 框架，将碎片化的雷达响应转化为完整的布局重建与物体检测结果。

Result: 在布局重建方面，相比最先进方法，Chamfer Distance 降低 60%（降至 16 厘米）；首次实现了基于 mmWave 雷达的物体检测，达到 58% 的 IoU。

Conclusion: RISE 成功建立了首个基于单静态雷达的室内场景理解基准与系统，有效融合多路径反射信息，实现了高精度、隐私保护的几何感知场景理解，为未来智能环境感知提供了新范式。

Abstract: Robust and privacy-preserving indoor scene understanding remains a fundamental open problem. While optical sensors such as RGB and LiDAR offer high spatial fidelity, they suffer from severe occlusions and introduce privacy risks in indoor environments. In contrast, millimeter-wave (mmWave) radar preserves privacy and penetrates obstacles, but its inherently low spatial resolution makes reliable geometric reasoning difficult.
  We introduce RISE, the first benchmark and system for single-static-radar indoor scene understanding, jointly targeting layout reconstruction and object detection. RISE is built upon the key insight that multipath reflections, traditionally treated as noise, encode rich geometric cues. To exploit this, we propose a Bi-Angular Multipath Enhancement that explicitly models Angle-of-Arrival and Angle-of-Departure to recover secondary (ghost) reflections and reveal invisible structures. On top of these enhanced observations, a simulation-to-reality Hierarchical Diffusion framework transforms fragmented radar responses into complete layout reconstruction and object detection.
  Our benchmark contains 50,000 frames collected across 100 real indoor trajectories, forming the first large-scale dataset dedicated to radar-based indoor scene understanding. Extensive experiments show that RISE reduces the Chamfer Distance by 60% (down to 16 cm) compared to the state of the art in layout reconstruction, and delivers the first mmWave-based object detection, achieving 58% IoU. These results establish RISE as a new foundation for geometry-aware and privacy-preserving indoor scene understanding using a single static radar.

</details>


### [26] [MRI Plane Orientation Detection using a Context-Aware 2.5D Model](https://arxiv.org/abs/2511.14021)
*SangHyuk Kim,Daniel Haehn,Sumientra Rampersad*

Main category: cs.CV

TL;DR: 本文提出一种2.5D上下文感知模型，用于自动识别MRI图像的解剖平面（轴向、冠状、矢状），显著提升平面方向元数据生成的准确性。相比仅使用2D图像的基准模型（98.74%准确率），2.5D模型达到99.49%准确率，错误率降低60%。该模型在脑肿瘤检测任务中通过基于置信度的门控策略，将诊断准确率从97.0%提升至98.0%，误诊减少33.3%。研究成果已集成至开源交互式Web应用中。


<details>
  <summary>Details</summary>
Motivation: 自动化系统难以准确识别MRI图像中的解剖平面方向，缺乏平面方向元数据会导致数据分析复杂化、数据集间域偏移增加以及诊断分类器性能下降。因此需要一种高精度的平面方向自动识别方法。

Method: 采用2.5D上下文感知模型，利用多切片信息来消除孤立切片带来的歧义，并实现更鲁棒的特征学习。模型在3D切片序列和静态2D图像上进行联合训练，同时设计门控策略，根据预测不确定性选择性使用增强后的元数据以提升下游任务性能。

Result: 2D参考模型准确率为98.74%，2.5D模型提升至99.49%，错误率降低60%；在脑肿瘤检测任务中，引入元数据后准确率从97.0%提升至98.0%，误诊减少33.3%。

Conclusion: 2.5D上下文建模对提高MRI图像平面方向识别的准确性至关重要，所提出的模型有效提升了元数据生成质量，并在下游医学影像分析任务中展现出显著优势，研究成果已开源并集成于交互式平台。

Abstract: Humans can easily identify anatomical planes (axial, coronal, and sagittal) on a 2D MRI slice, but automated systems struggle with this task. Missing plane orientation metadata can complicate analysis, increase domain shift when merging heterogeneous datasets, and reduce accuracy of diagnostic classifiers. This study develops a classifier that accurately generates plane orientation metadata. We adopt a 2.5D context-aware model that leverages multi-slice information to avoid ambiguity from isolated slices and enable robust feature learning. We train the 2.5D model on both 3D slice sequences and static 2D images. While our 2D reference model achieves 98.74% accuracy, our 2.5D method raises this to 99.49%, reducing errors by 60%, highlighting the importance of 2.5D context. We validate the utility of our generated metadata in a brain tumor detection task. A gated strategy selectively uses metadata-enhanced predictions based on uncertainty scores, boosting accuracy from 97.0% with an image-only model to 98.0%, reducing misdiagnoses by 33.3%. We integrate our plane orientation model into an interactive web application and provide it open-source.

</details>


### [27] [LINGUAL: Language-INtegrated GUidance in Active Learning for Medical Image Segmentation](https://arxiv.org/abs/2511.14028)
*Md Shazid Islam,Shreyangshu Bera,Sudipta Paul,Amit K. Roy-Chowdhury*

Main category: cs.CV

TL;DR: LINGUAL 是一种利用自然语言指令通过上下文学习将专家指令转化为可执行程序的框架，实现自动化的图像分割任务，在主动域适应中表现优于或相当传统主动学习方法，同时将标注时间减少约80%。


<details>
  <summary>Details</summary>
Motivation: 医学图像中边界模糊且不明确，传统主动学习需专家精确勾画区域，费时费力且认知负担重；小区域虽精度高但更耗精力，大区域虽易标注但成本高。语言指导可降低标注复杂度，减少专家负担。

Method: LINGUAL 框架接收专家的自然语言指令，利用上下文学习将其转换为可执行程序，并自动完成一系列子任务，实现无干预的自动化标注流程。

Result: 在主动域适应任务中，LINGUAL 达到了与传统主动学习相当或更优的性能，同时估计标注时间减少约80%。

Conclusion: 语言引导的自动化标注框架 LINGUAL 有效缓解了医学图像分割中专家标注的高成本与高认知负荷问题，具备显著的效率优势和应用潜力。

Abstract: Although active learning (AL) in segmentation tasks enables experts to annotate selected regions of interest (ROIs) instead of entire images, it remains highly challenging, labor-intensive, and cognitively demanding due to the blurry and ambiguous boundaries commonly observed in medical images. Also, in conventional AL, annotation effort is a function of the ROI- larger regions make the task cognitively easier but incur higher annotation costs, whereas smaller regions demand finer precision and more attention from the expert. In this context, language guidance provides an effective alternative, requiring minimal expert effort while bypassing the cognitively demanding task of precise boundary delineation in segmentation. Towards this goal, we introduce LINGUAL: a framework that receives natural language instructions from an expert, translates them into executable programs through in-context learning, and automatically performs the corresponding sequence of sub-tasks without any human intervention. We demonstrate the effectiveness of LINGUAL in active domain adaptation (ADA) achieving comparable or superior performance to AL baselines while reducing estimated annotation time by approximately 80%.

</details>


### [28] [Training-free Detection of AI-generated images via Cropping Robustness](https://arxiv.org/abs/2511.14030)
*Sungik Choi,Hankook Lee,Moontae Lee*

Main category: cs.CV

TL;DR: WaRPAD是基于自监督模型的无训练AI生成图像检测方法，利用图像在不同分辨率下的嵌入一致性敏感性，通过Haar小波分解提取高频方向并计算扰动敏感度，结合多尺度分块平均得分实现检测。该方法在多种生成模型和数据集上表现稳定，对测试时噪声具有强鲁棒性，并适用于各类自监督模型。


<details>
  <summary>Details</summary>
Motivation: 随着视觉生成模型的快速发展，AI生成图像检测变得尤为重要。传统方法依赖特定数据集训练，存在泛化能力差的问题。为解决这一问题，研究者提出无需训练的检测方法，利用自监督模型在随机缩放等增强下学习到的一致表示特性，提升检测通用性与鲁棒性。

Method: WaRPAD首先通过Haar小波分解提取图像的高频方向，定义基评分函数以量化嵌入对扰动的敏感性；随后将图像缩放到模型输入尺寸的倍数，分割为多个小块，分别计算每块的基评分；最终通过对所有块的得分取平均，得到全局检测分数。

Result: WaRPAD在23种不同生成模型产生的图像及多领域、多分辨率的真实数据集上均表现出色，性能优于或接近现有方法，且对测试时的各类噪声和变换具有强鲁棒性。此外，由于其基于自监督模型的普遍特性，该方法可广泛适配于各类自监督模型。

Conclusion: WaRPAD是一种高效、通用且鲁棒的训练-free AI生成图像检测方法，充分利用了自监督模型对随机缩放的不变性特征，实现了无需训练即可跨模型、跨数据集的有效检测，具有良好的实际应用前景。

Abstract: AI-generated image detection has become crucial with the rapid advancement of vision-generative models. Instead of training detectors tailored to specific datasets, we study a training-free approach leveraging self-supervised models without requiring prior data knowledge. These models, pre-trained with augmentations like RandomResizedCrop, learn to produce consistent representations across varying resolutions. Motivated by this, we propose WaRPAD, a training-free AI-generated image detection algorithm based on self-supervised models. Since neighborhood pixel differences in images are highly sensitive to resizing operations, WaRPAD first defines a base score function that quantifies the sensitivity of image embeddings to perturbations along high-frequency directions extracted via Haar wavelet decomposition. To simulate robustness against cropping augmentation, we rescale each image to a multiple of the models input size, divide it into smaller patches, and compute the base score for each patch. The final detection score is then obtained by averaging the scores across all patches. We validate WaRPAD on real datasets of diverse resolutions and domains, and images generated by 23 different generative models. Our method consistently achieves competitive performance and demonstrates strong robustness to test-time corruptions. Furthermore, as invariance to RandomResizedCrop is a common training scheme across self-supervised models, we show that WaRPAD is applicable across self-supervised models.

</details>


### [29] [FashionMAC: Deformation-Free Fashion Image Generation with Fine-Grained Model Appearance Customization](https://arxiv.org/abs/2511.14031)
*Rong Zhang,Jinxiao Li,Jingnan Wang,Zhiwen Zuo,Jianfeng Dong,Wei Li,Chi Wang,Weiwei Xu,Xun Wang*

Main category: cs.CV

TL;DR: FashionMAC is a diffusion-based, deformation-free framework for garment-centric fashion image generation that preserves detailed garment textures and enables fine-grained controllability through a region-adaptive decoupled attention (RADA) mechanism and chained mask injection strategy.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle with garment texture distortions due to required deformation during generation and lack fine-grained control over human model appearance, limiting realism and controllability in fashion image synthesis.

Method: FashionMAC eliminates garment deformation by directly outpainting segmented garments from dressed persons. It introduces RADA to adaptively predict regions for text attributes and uses chained mask injection to enforce attribute focus on relevant regions, enhancing visual fidelity and controllability.

Result: Extensive experiments show FashionMAC outperforms state-of-the-art methods in both image quality and fine-grained controllability, achieving more realistic and accurately controlled fashion images.

Conclusion: FashionMAC provides a deformation-free, high-fidelity approach to garment-centric fashion image generation, effectively preserving intricate garment details and enabling precise control over human model appearance through innovative attention and masking mechanisms.

Abstract: Garment-centric fashion image generation aims to synthesize realistic and controllable human models dressing a given garment, which has attracted growing interest due to its practical applications in e-commerce. The key challenges of the task lie in two aspects: (1) faithfully preserving the garment details, and (2) gaining fine-grained controllability over the model's appearance. Existing methods typically require performing garment deformation in the generation process, which often leads to garment texture distortions. Also, they fail to control the fine-grained attributes of the generated models, due to the lack of specifically designed mechanisms. To address these issues, we propose FashionMAC, a novel diffusion-based deformation-free framework that achieves high-quality and controllable fashion showcase image generation. The core idea of our framework is to eliminate the need for performing garment deformation and directly outpaint the garment segmented from a dressed person, which enables faithful preservation of the intricate garment details. Moreover, we propose a novel region-adaptive decoupled attention (RADA) mechanism along with a chained mask injection strategy to achieve fine-grained appearance controllability over the synthesized human models. Specifically, RADA adaptively predicts the generated regions for each fine-grained text attribute and enforces the text attribute to focus on the predicted regions by a chained mask injection strategy, significantly enhancing the visual fidelity and the controllability. Extensive experiments validate the superior performance of our framework compared to existing state-of-the-art methods.

</details>


### [30] [Flood-LDM: Generalizable Latent Diffusion Models for rapid and accurate zero-shot High-Resolution Flood Mapping](https://arxiv.org/abs/2511.14033)
*Sun Han Neo,Sachith Seneviratne,Herath Mudiyanselage Viraj Vidura Herath,Abhishek Saha,Sanka Rasnayaka,Lucy Amanda Marshall*

Main category: cs.CV

TL;DR: 本文提出一种基于潜在扩散模型的洪水地图超分辨率方法，能够在保持高精度的同时显著降低推理时间，适用于实时洪水风险管理。该方法在不同地理区域间具有优异的泛化能力，并通过引入物理信息输入提升了模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统水动力模型计算成本高，难以用于实时大规模洪水预测；现有深度学习方法虽速度快但泛化能力差，无法适应未见区域。因此需要一种既快速又具备强泛化能力的洪水地图超分辨率方法。

Method: 采用潜在扩散模型对粗网格洪水地图进行超分辨率重建，结合物理信息输入以增强模型的可解释性，并利用迁移学习加速在新地理区域的适应过程。

Result: 实验结果表明，该方法在生成高保真洪水地图方面显著减少了计算时间，同时保持了与细网格模型相当的精度，且在多个地理区域表现出良好的泛化性能。

Conclusion: 所提出的基于潜在扩散模型的方法实现了高效、准确且可推广的洪水地图超分辨率，为实时洪水风险评估提供了可行的技术路径。

Abstract: Flood prediction is critical for emergency planning and response to mitigate human and economic losses. Traditional physics-based hydrodynamic models generate high-resolution flood maps using numerical methods requiring fine-grid discretization; which are computationally intensive and impractical for real-time large-scale applications. While recent studies have applied convolutional neural networks for flood map super-resolution with good accuracy and speed, they suffer from limited generalizability to unseen areas. In this paper, we propose a novel approach that leverages latent diffusion models to perform super-resolution on coarse-grid flood maps, with the objective of achieving the accuracy of fine-grid flood maps while significantly reducing inference time. Experimental results demonstrate that latent diffusion models substantially decrease the computational time required to produce high-fidelity flood maps without compromising on accuracy, enabling their use in real-time flood risk management. Moreover, diffusion models exhibit superior generalizability across different physical locations, with transfer learning further accelerating adaptation to new geographic regions. Our approach also incorporates physics-informed inputs, addressing the common limitation of black-box behavior in machine learning, thereby enhancing interpretability. Code is available at https://github.com/neosunhan/flood-diff.

</details>


### [31] [Saliency-Guided Deep Learning for Bridge Defect Detection in Drone Imagery](https://arxiv.org/abs/2511.14040)
*Loucif Hebbache,Dariush Amirkhani,Mohand Saïd Allili,Jean-François Lapointe*

Main category: cs.CV

TL;DR: 本文提出一种基于无人机图像的混凝土桥梁结构缺陷自动检测、定位与分类新方法。该框架包含两个阶段：第一阶段利用显著性检测缺陷区域，因缺陷常表现为局部表面模式的不连续；第二阶段采用基于YOLOX的深度学习检测器，在显著性增强图像上通过边界框级亮度增强处理，提升检测性能。实验结果表明，该方法在标准数据集上具有高精度和高效计算能力，具备在自供电检测系统中应用的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统缺陷检测方法在复杂背景和光照变化下表现不佳，且难以实现自动化、高效率的检测。无人机图像提供了大范围、高分辨率的桥梁表面数据，但如何有效提取缺陷特征并实现实时检测仍是挑战。因此，亟需一种高效、准确的自动化检测框架以应对实际工程需求。

Method: 首先使用显著性分析生成缺陷区域候选框，捕捉局部表面模式的不连续性；随后对候选区域进行边界框级亮度增强，以强化缺陷特征；最后采用YOLOX目标检测模型在增强后的图像上进行缺陷定位与分类。

Result: 在标准数据集上的实验验证了所提方法在检测精度和计算效率方面的优越性，能够有效识别多种类型的混凝土缺陷，并具备部署于自供电智能巡检系统的可行性。

Conclusion: 所提出的双阶段框架结合显著性分析与增强型YOLOX检测，显著提升了混凝土桥梁缺陷检测的准确性与实时性，为智能基础设施健康监测提供了可行的技术路径。

Abstract: Anomaly object detection and classification are one of the main challenging tasks in computer vision and pattern recognition. In this paper, we propose a new method to automatically detect, localize and classify defects in concrete bridge structures using drone imagery. This framework is constituted of two main stages. The first stage uses saliency for defect region proposals where defects often exhibit local discontinuities in the normal surface patterns with regard to their surrounding. The second stage employs a YOLOX-based deep learning detector that operates on saliency-enhanced images obtained by applying bounding-box level brightness augmentation to salient defect regions. Experimental results on standard datasets confirm the performance of our framework and its suitability in terms of accuracy and computational efficiency, which give a huge potential to be implemented in a self-powered inspection system.

</details>


### [32] [Semantic Context Matters: Improving Conditioning for Autoregressive Models](https://arxiv.org/abs/2511.14063)
*Dongyang Jin,Ryan Xu,Jianhao Zeng,Rui Lan,Yancheng Bai,Lei Sun,Xiangxiang Chu*

Main category: cs.CV

TL;DR: SCAR 是一种用于自回归（AR）图像生成模型的语义-上下文驱动方法，通过引入压缩语义预填充和语义对齐引导两个关键组件，显著提升图像编辑中的指令遵循能力和视觉保真度。该方法在保持低开销的同时，通用性强，适用于多种AR范式，性能优于现有AR方法。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型在图像编辑任务中面临条件控制弱、效率低的问题，导致指令遵循差和视觉伪影，亟需更有效的语义引导机制以提升生成质量与可控性。

Method: SCAR 提出压缩语义预填充（将高层语义编码为紧凑前缀）和语义对齐引导（在解码过程中对齐视觉隐藏状态与目标语义），结合向量量化预填充的灵活性并克服其语义局限与高成本问题。

Result: 在指令编辑和可控生成基准上，SCAR 在视觉保真度和语义一致性方面均优于现有自回归方法，且具有良好的泛化能力与可控性。

Conclusion: SCAR 为自回归图像生成提供了高效、通用且高保真的语义控制方案，推动了AR模型在复杂图像编辑任务中的应用发展。

Abstract: Recently, autoregressive (AR) models have shown strong potential in image generation, offering better scalability and easier integration with unified multi-modal systems compared to diffusion-based methods. However, extending AR models to general image editing remains challenging due to weak and inefficient conditioning, often leading to poor instruction adherence and visual artifacts. To address this, we propose SCAR, a Semantic-Context-driven method for Autoregressive models. SCAR introduces two key components: Compressed Semantic Prefilling, which encodes high-level semantics into a compact and efficient prefix, and Semantic Alignment Guidance, which aligns the last visual hidden states with target semantics during autoregressive decoding to enhance instruction fidelity. Unlike decoding-stage injection methods, SCAR builds upon the flexibility and generality of vector-quantized-based prefilling while overcoming its semantic limitations and high cost. It generalizes across both next-token and next-set AR paradigms with minimal architectural changes. SCAR achieves superior visual fidelity and semantic alignment on both instruction editing and controllable generation benchmarks, outperforming prior AR-based methods while maintaining controllability. All code will be released.

</details>


### [33] [CORE: Compact Object-centric REpresentations as a New Paradigm for Token Merging in LVLMs](https://arxiv.org/abs/2511.14072)
*Jingyu Lei,Gaoang Wang,Der-Horng Lee*

Main category: cs.CV

TL;DR: 本文提出了一种名为CORE（Compact Object-centric REpresentations）的新范式，用于视觉令牌压缩。通过高效的分割解码器生成物体掩码，作为高层次语义先验来指导视觉令牌的合并，形成紧凑的以物体为中心的表示。此外，引入一种新的中心点引导排序机制，恢复合并后令牌的连贯空间顺序，保留关键位置信息。实验表明，CORE在六个权威基准上实现了固定率压缩的新状态，同时在自适应率设置下表现出显著的效率提升。即使在极端压缩下（仅保留2.2%的视觉令牌），仍保持97.4%的基线性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌压缩方法缺乏高层次语义理解，导致合并效果不佳、信息冗余或上下文丢失，难以满足大型视觉语言模型对高效计算和内存的需求。

Method: 使用高效分割解码器生成物体掩码，作为高阶语义先验；基于此进行视觉令牌合并，形成对象中心表示；引入中心点引导排序机制，恢复空间顺序。

Result: CORE在六项权威基准上达到固定率压缩新纪录，在自适应率设置中实现显著效率提升；极端压缩（仅2.2%令牌）下仍保持97.4%性能。

Conclusion: 以物体为中心的表示在高效且有效的大规模视觉语言模型处理中具有明显优势，验证了CORE方法的有效性与优越性。

Abstract: Large Vision-Language Models (LVLMs) usually suffer from prohibitive computational and memory costs due to the quadratic growth of visual tokens with image resolution. Existing token compression methods, while varied, often lack a high-level semantic understanding, leading to suboptimal merges, information redundancy, or context loss. To address these limitations, we introduce CORE (Compact Object-centric REpresentations), a new paradigm for visual token compression. CORE leverages an efficient segmentation decoder to generate object masks, which serve as a high-level semantic prior to guide the merging of visual tokens into a compact set of object-centric representations. Furthermore, a novel centroid-guided sorting mechanism restores a coherent spatial order to the merged tokens, preserving vital positional information. Extensive experiments show that CORE not only establishes a new state-of-the-art on six authoritative benchmarks for fixed-rate compression, but also achieves dramatic efficiency gains in adaptive-rate settings. Even under extreme compression, after aggressively retaining with only 2.2% of all visual tokens, CORE still maintains 97.4% of baseline performance. Our work demonstrates the superiority of object-centric representations for efficient and effective LVLM processing.

</details>


### [34] [Zero-Training Task-Specific Model Synthesis for Few-Shot Medical Image Classification](https://arxiv.org/abs/2511.14082)
*Yao Qin,Yangyang Yan,YuanChao Yang,Jinhua Pang,Huanyong Bi,Yuan Liu,HaiHua Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为零训练任务特定模型合成（ZS-TMS）的新范式，通过利用大规模预训练生成引擎直接合成任务特定分类器的完整参数，无需传统训练或微调。其核心框架SGPS仅需单张图像和对应的临床文本描述即可生成高效轻量级分类器的权重，显著提升在极低数据场景（如1-shot、5-shot）下的性能，尤其适用于罕见病等数据稀缺领域，为快速部署AI诊断工具提供了新路径。


<details>
  <summary>Details</summary>
Motivation: 医学影像分析中的深度学习模型依赖大量精心标注的数据，但医疗数据获取困难且专家标注成本高，尤其对于罕见病样本稀缺，导致模型训练受限。因此亟需一种无需大量标注数据即可快速构建有效模型的方法。

Method: 提出基于语义引导的参数合成器（SGPS），利用预训练生成模型，结合少量多模态输入（如一张图像和一段临床描述），直接生成任务特定分类器的完整参数，实现零训练部署。

Result: 在ISIC 2018皮肤病变数据集和自建罕见病数据集上的实验表明，SGPS在1-shot和5-shot等极低数据条件下显著优于现有先进少样本与零样本学习方法，达到新基准水平。

Conclusion: 该研究突破了医疗领域对大规模标注数据的依赖，实现了在极少样本下快速构建高性能诊断模型，为罕见病等长尾疾病的人工智能应用提供了可行方案。

Abstract: Deep learning models have achieved remarkable success in medical image analysis but are fundamentally constrained by the requirement for large-scale, meticulously annotated datasets. This dependency on "big data" is a critical bottleneck in the medical domain, where patient data is inherently difficult to acquire and expert annotation is expensive, particularly for rare diseases where samples are scarce by definition. To overcome this fundamental challenge, we propose a novel paradigm: Zero-Training Task-Specific Model Synthesis (ZS-TMS). Instead of adapting a pre-existing model or training a new one, our approach leverages a large-scale, pre-trained generative engine to directly synthesize the entire set of parameters for a task-specific classifier. Our framework, the Semantic-Guided Parameter Synthesizer (SGPS), takes as input minimal, multi-modal task information as little as a single example image (1-shot) and a corresponding clinical text description to directly synthesize the entire set of parameters for a task-specific classifier.
  The generative engine interprets these inputs to generate the weights for a lightweight, efficient classifier (e.g., an EfficientNet-V2), which can be deployed for inference immediately without any task-specific training or fine-tuning. We conduct extensive evaluations on challenging few-shot classification benchmarks derived from the ISIC 2018 skin lesion dataset and a custom rare disease dataset. Our results demonstrate that SGPS establishes a new state-of-the-art, significantly outperforming advanced few-shot and zero-shot learning methods, especially in the ultra-low data regimes of 1-shot and 5-shot classification. This work paves the way for the rapid development and deployment of AI-powered diagnostic tools, particularly for the long tail of rare diseases where data is critically limited.

</details>


### [35] [Error-Driven Scene Editing for 3D Grounding in Large Language Models](https://arxiv.org/abs/2511.14086)
*Yue Zhang,Zun Wang,Han Lin,Jialu Li,Jianing Yang,Yonatan Bitton,Idan Szpektor,Mohit Bansal*

Main category: cs.CV

TL;DR: 本文提出DEER-3D框架，通过误差驱动的3D场景编辑来提升3D-LLM的空间定位能力。该方法采用‘分解、诊断评估、编辑、再训练’流程，针对模型在语义与空间关系上的具体错误进行精细化修改，如重置颜色或位置，生成针对性反事实监督信号，从而有效缓解语言-空间对齐偏差。实验表明，该方法在多个3D理解基准上显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D-LLM在将语言与3D视觉和空间元素对齐方面仍存在局限，主要因训练数据偏重语言推理而非空间理解，且缺乏高质量3D数据，导致固有的定位偏差难以解决。

Method: 提出DEER-3D框架，采用‘分解、诊断评估、编辑、再训练’四步流程：首先识别3D-LLM的定位失败；其次在谓词层面（如属性或空间关系）诊断错误；然后执行最小化、对齐谓词的3D场景编辑（如重色、移位）以生成反事实监督；最后用于迭代微调模型。

Result: 在多个3D定位与场景理解基准测试中，DEER-3D均实现一致且显著的性能提升，验证了误差驱动、目标导向的场景编辑在增强3D-LLM空间接地性方面的有效性。

Conclusion: DEER-3D证明了通过精准、基于错误的3D场景编辑，可有效弥合3D-LLM在语言推理与空间感知之间的差距，为提升其真实场景理解能力提供了新范式。

Abstract: Despite recent progress in 3D-LLMs, they remain limited in accurately grounding language to visual and spatial elements in 3D environments. This limitation stems in part from training data that focuses on language reasoning rather than spatial understanding due to scarce 3D resources, leaving inherent grounding biases unresolved. To address this, we propose 3D scene editing as a key mechanism to generate precise visual counterfactuals that mitigate these biases through fine-grained spatial manipulation, without requiring costly scene reconstruction or large-scale 3D data collection. Furthermore, to make these edits targeted and directly address the specific weaknesses of the model, we introduce DEER-3D, an error-driven framework following a structured "Decompose, Diagnostic Evaluation, Edit, and Re-train" workflow, rather than broadly or randomly augmenting data as in conventional approaches. Specifically, upon identifying a grounding failure of the 3D-LLM, our framework first diagnoses the exact predicate-level error (e.g., attribute or spatial relation). It then executes minimal, predicate-aligned 3D scene edits, such as recoloring or repositioning, to produce targeted counterfactual supervision for iterative model fine-tuning, significantly enhancing grounding accuracy. We evaluate our editing pipeline across multiple benchmarks for 3D grounding and scene understanding tasks, consistently demonstrating improvements across all evaluated datasets through iterative refinement. DEER-3D underscores the effectiveness of targeted, error-driven scene editing in bridging linguistic reasoning capabilities with spatial grounding in 3D LLMs.

</details>


### [36] [BCE3S: Binary Cross-Entropy Based Tripartite Synergistic Learning for Long-tailed Recognition](https://arxiv.org/abs/2511.14097)
*Weijia Fan,Qiufu Li,Jiajun Wen,Xiaoyang Peng*

Main category: cs.CV

TL;DR: 本文提出一种基于二元交叉熵（BCE）的三重协同学习方法（BCE3S），用于长尾识别（LTR）任务。该方法通过解耦特征与不平衡分类器向量之间的度量关系，提升特征的类内紧凑性和类间可分性，并平衡分类器间的可分性，从而在多个长尾数据集上达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于交叉熵（CE）损失的长尾识别方法难以学习到理想的特征属性，且在Softmax的分母中耦合了不平衡的分类器向量，加剧了长尾问题中的类别不平衡效应。因此需要一种能解耦特征与分类器、同时优化特征和分类器的新方法。

Method: BCE3S包含三个组件：(1) 基于BCE的联合学习，通过多个Sigmoid解耦特征与不平衡分类器向量的度量，优化分类器和样本特征；(2) 基于BCE的对比学习，进一步增强类内紧凑性；(3) 基于BCE的均匀学习，平衡分类器间的可分性，并与联合学习协同优化特征属性。

Result: 实验表明，BCE3S训练的模型在特征紧凑性和可分性方面均优于传统方法，分类器可分性也得到均衡，显著提升了长尾识别性能，在CIFAR10-LT、CIFAR100-LT、ImageNet-LT和iNaturalist2018等多个数据集上达到当前最优（SOTA）结果。

Conclusion: BCE3S通过三重协同学习机制有效缓解了长尾识别中的类别不平衡问题，实现了特征与分类器的协同优化，为长尾识别提供了新的有效解决方案。

Abstract: For long-tailed recognition (LTR) tasks, high intra-class compactness and inter-class separability in both head and tail classes, as well as balanced separability among all the classifier vectors, are preferred. The existing LTR methods based on cross-entropy (CE) loss not only struggle to learn features with desirable properties but also couple imbalanced classifier vectors in the denominator of its Softmax, amplifying the imbalance effects in LTR. In this paper, for the LTR, we propose a binary cross-entropy (BCE)-based tripartite synergistic learning, termed BCE3S, which consists of three components: (1) BCE-based joint learning optimizes both the classifier and sample features, which achieves better compactness and separability among features than the CE-based joint learning, by decoupling the metrics between feature and the imbalanced classifier vectors in multiple Sigmoid; (2) BCE-based contrastive learning further improves the intra-class compactness of features; (3) BCE-based uniform learning balances the separability among classifier vectors and interactively enhances the feature properties by combining with the joint learning. The extensive experiments show that the LTR model trained by BCE3S not only achieves higher compactness and separability among sample features, but also balances the classifier's separability, achieving SOTA performance on various long-tailed datasets such as CIFAR10-LT, CIFAR100-LT, ImageNet-LT, and iNaturalist2018.

</details>


### [37] [FAPE-IR: Frequency-Aware Planning and Execution Framework for All-in-One Image Restoration](https://arxiv.org/abs/2511.14099)
*Jingren Liu,Shuning Xu,Qirui Yang,Yun Wang,Xiangyu Chen,Zhong Ji*

Main category: cs.CV

TL;DR: FAPE-IR提出一种基于频率感知规划与执行的统一图像修复框架，利用冻结的多模态大语言模型（MLLM）生成频率感知的修复计划，并通过LoRA-MoE模块动态选择高低频专家进行修复。结合对抗训练和频率正则化损失，显著提升修复质量并减少伪影，在7个任务上达到顶尖性能，并展现强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有All-in-One Image Restoration方法依赖任务特定设计或潜在路由策略，难以适应真实世界中多种退化混合的复杂场景，缺乏统一且可解释的解决方案。

Method: 采用冻结的多模态大语言模型作为规划器，分析退化图像并生成频率感知的修复计划；使用基于LoRA的专家混合（LoRA-MoE）模块作为执行器，根据计划动态选择高/低频专家，并融合输入图像的频率特征；引入对抗训练与频率正则化损失以优化修复质量。

Result: 在七个图像修复任务中均达到当前最优性能，具备出色的零样本泛化能力，尤其在混合退化条件下表现优异。

Conclusion: FAPE-IR通过将语义规划与频率导向修复相结合，为所有类型图像修复提供了一个统一、高效且可解释的解决方案，推动了复杂退化场景下图像恢复的发展。

Abstract: All-in-One Image Restoration (AIO-IR) aims to develop a unified model that can handle multiple degradations under complex conditions. However, existing methods often rely on task-specific designs or latent routing strategies, making it hard to adapt to real-world scenarios with various degradations. We propose FAPE-IR, a Frequency-Aware Planning and Execution framework for image restoration. It uses a frozen Multimodal Large Language Model (MLLM) as a planner to analyze degraded images and generate concise, frequency-aware restoration plans. These plans guide a LoRA-based Mixture-of-Experts (LoRA-MoE) module within a diffusion-based executor, which dynamically selects high- or low-frequency experts, complemented by frequency features of the input image. To further improve restoration quality and reduce artifacts, we introduce adversarial training and a frequency regularization loss. By coupling semantic planning with frequency-based restoration, FAPE-IR offers a unified and interpretable solution for all-in-one image restoration. Extensive experiments show that FAPE-IR achieves state-of-the-art performance across seven restoration tasks and exhibits strong zero-shot generalization under mixed degradations.

</details>


### [38] [Text-Driven Reasoning Video Editing via Reinforcement Learning on Digital Twin Representations](https://arxiv.org/abs/2511.14100)
*Yiqing Shen,Chenjia Li,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文提出了一种名为RIVER的新型视频编辑模型，旨在解决基于文本的隐式视频编辑任务。该任务要求模型通过多跳推理理解用户模糊的语义查询，并自动推断出需要编辑的目标。RIVER采用数字孪生表示来保留视频的空间关系、时间轨迹和语义属性，结合大语言模型进行推理，生成结构化指令以指导扩散模型完成像素级修改。训练采用强化学习，奖励机制同时评估推理准确性和生成质量。此外，作者构建了首个专门针对该任务的基准数据集RVEBenchmark，包含100段视频和519个不同复杂度的隐式查询。实验表明，RIVER在RVEBenchmark上表现最佳，并在VegGIE和FiVE两个主流视频编辑基准上超越六种基线方法，达到当前最优水平。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动视频编辑方法依赖于对编辑目标的明确描述（如精确位置和时间范围），但在面对用户通过语义属性或对象关系表达的隐式查询时，这种要求变得不切实际。因此，亟需一种能够理解抽象、间接文本指令并自主推断编辑目标的新方法。

Method: RIVER模型通过数字孪生技术将视频内容转化为保留空间、时间与语义信息的抽象表示；利用大语言模型联合处理该表示与隐式文本查询，执行多跳推理以确定修改内容；输出结构化指令，由扩散模型执行像素级编辑。训练过程采用强化学习，奖励函数综合评估推理正确性与生成质量。

Result: RIVER在自建的RVEBenchmark上取得最佳性能，且在VegGIE和FiVE两个公开视频编辑基准上均优于六个基线模型，展现出卓越的泛化能力与推理能力。

Conclusion: RIVER是首个面向隐式视频编辑任务的端到端解决方案，证明了通过多跳推理与数字孪生表示实现复杂语义理解与精准编辑的可行性。本研究为未来智能视频编辑系统的发展提供了新范式。

Abstract: Text-driven video editing enables users to modify video content only using text queries. While existing methods can modify video content if explicit descriptions of editing targets with precise spatial locations and temporal boundaries are provided, these requirements become impractical when users attempt to conceptualize edits through implicit queries referencing semantic properties or object relationships. We introduce reasoning video editing, a task where video editing models must interpret implicit queries through multi-hop reasoning to infer editing targets before executing modifications, and a first model attempting to solve this complex task, RIVER (Reasoning-based Implicit Video Editor). RIVER decouples reasoning from generation through digital twin representations of video content that preserve spatial relationships, temporal trajectories, and semantic attributes. A large language model then processes this representation jointly with the implicit query, performing multi-hop reasoning to determine modifications, then outputs structured instructions that guide a diffusion-based editor to execute pixel-level changes. RIVER training uses reinforcement learning with rewards that evaluate reasoning accuracy and generation quality. Finally, we introduce RVEBenchmark, a benchmark of 100 videos with 519 implicit queries spanning three levels and categories of reasoning complexity specifically for reasoning video editing. RIVER demonstrates best performance on the proposed RVEBenchmark and also achieves state-of-the-art performance on two additional video editing benchmarks (VegGIE and FiVE), where it surpasses six baseline methods.

</details>


### [39] [RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment](https://arxiv.org/abs/2511.14107)
*Zeyu Cheng,Tongfei Liu,Tao Lei,Xiang Hua,Yi Zhang,Chengkai Tang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、高效的自监督单目深度估计方法RTS-Mono，适用于自动驾驶和智能机器人导航。该方法在保持极低参数量（3M）的同时，在KITTI数据集上实现了最先进的性能，并在真实世界部署中实现了49 FPS的实时推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有自监督单目深度估计模型通常计算资源消耗大，尽管部分方法减小了模型规模，但性能下降严重，限制了其在实际场景中的部署。因此需要一种高效且高性能的轻量级模型以支持实时应用。

Method: RTS-Mono采用基于Lite-Encoder的编码器与多尺度稀疏融合解码器结构，通过减少冗余来提升推理速度并保持高精度。

Result: 在KITTI数据集上，RTS-Mono在高低分辨率下均达到当前最优性能；相比轻量级方法，在低分辨率下Abs Rel和Sq Rel分别提升5.6%和9.8%，在高分辨率下Sq Rel和RMSE分别提升6.1%和1.9%。真实部署中可在Nvidia Jetson Orin上实现49 FPS的实时推理。

Conclusion: RTS-Mono是一种高效、轻量且性能优越的自监督单目深度估计方法，具备良好的实际部署能力，适用于对实时性和计算效率要求高的智能系统。

Abstract: Depth information is crucial for autonomous driving and intelligent robot navigation. The simplicity and flexibility of self-supervised monocular depth estimation are conducive to its role in these fields. However, most existing monocular depth estimation models consume many computing resources. Although some methods have reduced the model's size and improved computing efficiency, the performance deteriorates, seriously hindering the real-world deployment of self-supervised monocular depth estimation models in the real world. To address this problem, we proposed a real-time self-supervised monocular depth estimation method and implemented it in the real world. It is called RTS-Mono, which is a lightweight and efficient encoder-decoder architecture. The encoder is based on Lite-Encoder, and the decoder is designed with a multi-scale sparse fusion framework to minimize redundancy, ensure performance, and improve inference speed. RTS-Mono achieved state-of-the-art (SoTA) performance in high and low resolutions with extremely low parameter counts (3 M) in experiments based on the KITTI dataset. Compared with lightweight methods, RTS-Mono improved Abs Rel and Sq Rel by 5.6% and 9.8% at low resolution and improved Sq Rel and RMSE by 6.1% and 1.9% at high resolution. In real-world deployment experiments, RTS-Mono has extremely high accuracy and can perform real-time inference on Nvidia Jetson Orin at a speed of 49 FPS. Source code is available at https://github.com/ZYCheng777/RTS-Mono.

</details>


### [40] [$A^2$GC: $A$symmetric $A$ggregation with Geometric Constraints for Locally Aggregated Descriptors](https://arxiv.org/abs/2511.14109)
*Zhenyu Li,Tianyi Shang*

Main category: cs.CV

TL;DR: 提出了一种名为A^2GC-VPR的非对称聚合视觉位置识别方法，通过行-列归一化平均与独立边际校准实现非对称匹配，有效应对图像特征与聚类中心分布差异问题；引入可学习坐标嵌入以融合几何约束，增强空间感知能力，显著提升匹配准确率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准Sinkhorn算法对源和目标边际对称处理，在图像特征与聚类中心分布差异较大时效果受限，亟需一种能适应分布不均衡的非对称聚合方法。

Method: 采用行-列归一化平均与独立边际校准实现非对称特征分配；引入可学习坐标嵌入，结合几何约束计算兼容性分数，与特征相似度融合，强化空间邻近特征归属同一聚类。

Result: 在MSLS、NordLand和Pittsburgh数据集上均取得优于现有方法的性能，验证了该方法在提升匹配精度与鲁棒性方面的有效性。

Conclusion: 所提出的A^2GC-VPR方法通过非对称聚合与几何约束建模，显著提升了视觉位置识别中局部聚合描述符的表达能力，为复杂场景下的精准匹配提供了新思路。

Abstract: Visual Place Recognition (VPR) aims to match query images against a database using visual cues. State-of-the-art methods aggregate features from deep backbones to form global descriptors. Optimal transport-based aggregation methods reformulate feature-to-cluster assignment as a transport problem, but the standard Sinkhorn algorithm symmetrically treats source and target marginals, limiting effectiveness when image features and cluster centers exhibit substantially different distributions. We propose an asymmetric aggregation VPR method with geometric constraints for locally aggregated descriptors, called $A^2$GC-VPR. Our method employs row-column normalization averaging with separate marginal calibration, enabling asymmetric matching that adapts to distributional discrepancies in visual place recognition. Geometric constraints are incorporated through learnable coordinate embeddings, computing compatibility scores fused with feature similarities, thereby promoting spatially proximal features to the same cluster and enhancing spatial awareness. Experimental results on MSLS, NordLand, and Pittsburgh datasets demonstrate superior performance, validating the effectiveness of our approach in improving matching accuracy and robustness.

</details>


### [41] [Coffee: Controllable Diffusion Fine-tuning](https://arxiv.org/abs/2511.14113)
*Ziyao Zeng,Jingcheng Ni,Ruyi Liu,Alex Wong*

Main category: cs.CV

TL;DR: 提出Coffee方法，通过语言指定不需要的概念来正则化文本到图像扩散模型的微调过程，无需额外训练即可防止模型学习不希望的概念，并能灵活修改这些概念描述。实验表明其在阻止学习特定不良概念方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型在微调时容易学习到用户数据中的不良概念，且这些概念可能与用户提示纠缠，影响下游任务如偏见缓解、防止恶意适应等，因此需要一种可控的微调方法以避免此类问题。

Method: Coffee方法通过保持用户提示嵌入与不良概念之间的不对齐，利用语言描述指定不良概念，从而在微调过程中进行正则化，该方法无需额外训练，可通过修改文本描述灵活调整不良概念。

Result: 实验结果表明，Coffee能够有效防止模型在微调过程中学习到指定的不良概念，且性能优于现有方法。

Conclusion: Coffee提供了一种高效、灵活且无需额外训练的可控微调方法，有助于实现更安全、可解释和通用的文本到图像模型微调。

Abstract: Text-to-image diffusion models can generate diverse content with flexible prompts, which makes them well-suited for customization through fine-tuning with a small amount of user-provided data. However, controllable fine-tuning that prevents models from learning undesired concepts present in the fine-tuning data, and from entangling those concepts with user prompts, remains an open challenge. It is crucial for downstream tasks like bias mitigation, preventing malicious adaptation, attribute disentanglement, and generalizable fine-tuning of diffusion policy. We propose Coffee that allows using language to specify undesired concepts to regularize the adaptation process. The crux of our method lies in keeping the embeddings of the user prompt from aligning with undesired concepts. Crucially, Coffee requires no additional training and enables flexible modification of undesired concepts by modifying textual descriptions. We evaluate Coffee by fine-tuning on images associated with user prompts paired with undesired concepts. Experimental results demonstrate that Coffee can prevent text-to-image models from learning specified undesired concepts during fine-tuning and outperforms existing methods. Code will be released upon acceptance.

</details>


### [42] [Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models](https://arxiv.org/abs/2511.14120)
*Hao Zhen,Yunxiang Yang,Jidong J. Yang*

Main category: cs.CV

TL;DR: MP-PVIR 是一种多视角、分阶段的行人-车辆事故分析框架，通过视频采集、行为阶段分割、阶段内多视角推理和层次化合成，实现对事故过程的结构化诊断。利用专用视觉语言模型（TG-VLM 和 PhaVR-VLM）提升行为识别与问答准确率，并结合大语言模型生成包含因果推理与预防建议的综合报告，在 Woven Traffic Safety 数据集上表现优异，推动了智能交通系统的安全分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频系统虽能检测行人-车辆事故，但缺乏对事故过程中行人认知阶段的深入理解；同时，主流视觉语言模型通常孤立处理视频，缺少时间结构与多视角融合，难以支持深层次行为分析与可解释性推理。

Method: 提出 MP-PVIR 框架，包括四个阶段：事件触发的多视角视频获取、行人行为阶段分割、阶段特定的多视角推理、以及结果的层次化合成与诊断推理。采用 TG-VLM 进行行为阶段分割，PhaVR-VLM 实现相位感知的多视角分析，并使用大语言模型生成完整诊断报告。

Result: TG-VLM 在行为阶段分割上达到 mIoU = 0.4881；PhaVR-VLM 在描述生成任务中得分 33.063，问答准确率最高达 64.70%；整体框架在 Woven Traffic Safety 数据集上成功将多视角视频转化为可操作的洞察，支持因果分析与预防策略制定。

Conclusion: MP-PVIR 通过整合多视角视频与行为理论，实现了对行人-车辆事故全过程的结构化、可解释分析，显著提升了 AI 在交通安全管理中的应用价值，为车路协同系统提供了有力的技术支撑。

Abstract: Pedestrian-vehicle incidents remain a critical urban safety challenge, with pedestrians accounting for over 20% of global traffic fatalities. Although existing video-based systems can detect when incidents occur, they provide little insight into how these events unfold across the distinct cognitive phases of pedestrian behavior. Recent vision-language models (VLMs) have shown strong potential for video understanding, but they remain limited in that they typically process videos in isolation, without explicit temporal structuring or multi-view integration. This paper introduces Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning (MP-PVIR), a unified framework that systematically processes multi-view video streams into structured diagnostic reports through four stages: (1) event-triggered multi-view video acquisition, (2) pedestrian behavior phase segmentation, (3) phase-specific multi-view reasoning, and (4) hierarchical synthesis and diagnostic reasoning. The framework operationalizes behavioral theory by automatically segmenting incidents into cognitive phases, performing synchronized multi-view analysis within each phase, and synthesizing results into causal chains with targeted prevention strategies. Particularly, two specialized VLMs underpin the MP-PVIR pipeline: TG-VLM for behavioral phase segmentation (mIoU = 0.4881) and PhaVR-VLM for phase-aware multi-view analysis, achieving a captioning score of 33.063 and up to 64.70% accuracy on question answering. Finally, a designated large language model is used to generate comprehensive reports detailing scene understanding, behavior interpretation, causal reasoning, and prevention recommendations. Evaluation on the Woven Traffic Safety dataset shows that MP-PVIR effectively translates multi-view video data into actionable insights, advancing AI-driven traffic safety analytics for vehicle-infrastructure cooperative systems.

</details>


### [43] [Wave-Former: Through-Occlusion 3D Reconstruction via Wireless Shape Completion](https://arxiv.org/abs/2511.14152)
*Laura Dodds,Maisy Lam,Waleed Akbar,Yibo Cheng,Fadel Adib*

Main category: cs.CV

TL;DR: Wave-Former 是一种新颖的方法，能够高精度重建完全遮挡的多样化日常物体的3D形状。它利用毫米波（mmWave）无线信号穿透常见遮挡并反射隐藏物体的特性，通过一个三阶段物理感知的形状补全管道，结合了视觉形状补全的最新进展和mmWave信号的物理特性。该方法仅需合成点云数据进行训练，并在真实世界数据上表现出优异的泛化能力，在与现有先进方法的对比中，召回率从54%提升至72%，同时保持85%的高精确率。


<details>
  <summary>Details</summary>
Motivation: 传统mmWave重建方法存在覆盖范围有限和噪声高的问题，难以准确重建完全遮挡物体的3D形状，限制了其在机器人、增强现实和物流等领域的应用。因此需要一种能够克服这些限制、实现高精度3D形状重建的新方法。

Method: Wave-Former采用三阶段管道：首先提出候选几何表面；其次使用专为mmWave信号设计的基于Transformer的形状补全模型；最后通过熵引导的表面选择机制优化结果。整个流程融合了mmWave信号的物理特性，支持仅用合成数据训练并在真实数据上良好泛化。

Result: 在与现有最先进基线方法的对比中，Wave-Former将召回率从54%显著提升至72%，同时保持85%的高精确率，证明了其在复杂遮挡场景下重建性能的优越性。

Conclusion: Wave-Former成功实现了对完全遮挡物体的高精度3D形状重建，不仅突破了传统mmWave方法的局限，还展示了在真实世界中的强大泛化能力，具有广泛的应用前景。

Abstract: We present Wave-Former, a novel method capable of high-accuracy 3D shape reconstruction for completely occluded, diverse, everyday objects. This capability can open new applications spanning robotics, augmented reality, and logistics. Our approach leverages millimeter-wave (mmWave) wireless signals, which can penetrate common occlusions and reflect off hidden objects. In contrast to past mmWave reconstruction methods, which suffer from limited coverage and high noise, Wave-Former introduces a physics-aware shape completion model capable of inferring full 3D geometry. At the heart of Wave-Former's design is a novel three-stage pipeline which bridges raw wireless signals with recent advancements in vision-based shape completion by incorporating physical properties of mmWave signals. The pipeline proposes candidate geometric surfaces, employs a transformer-based shape completion model designed specifically for mmWave signals, and finally performs entropy-guided surface selection. This enables Wave-Former to be trained using entirely synthetic point-clouds, while demonstrating impressive generalization to real-world data.In head-to-head comparisons with state-of-the-art baselines, Wave-Former raises recall from 54% to 72% while maintaining a high precision of 85%.

</details>


### [44] [O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model](https://arxiv.org/abs/2511.14368)
*Rishi Gupta,Mukilan Karuppasamy,Shyam Marjit,Aditay Tripathi,Anirban Chakraborty*

Main category: cs.CV

TL;DR: 本文针对大型视觉语言模型（LVLMs）在理解手绘草图等抽象视觉输入方面的不足，提出了一种新的大规模图像-草图-指令三元组数据集，并基于该数据集训练了O3SLM模型。通过在多个草图相关任务上的评估，O3SLM在对象定位、计数、图像检索和视觉问答等方面均达到当前最佳性能，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在处理手绘草图这类抽象视觉输入时表现不佳，主要受限于缺乏联合建模草图、真实图像与自然语言指令的大规模数据集。

Method: 构建了一个大规模的图像-草图-指令三元组数据集，并利用该数据集对LVLM进行预训练和指令微调，得到O3SLM模型。

Result: O3SLM在多个草图理解任务上表现优异，包括对象定位、计数、图像检索（SBIR与细粒度SBIR）以及视觉问答，超越了现有主流模型。

Conclusion: 本研究通过构建新数据集并训练专用模型，显著提升了大型视觉语言模型在草图理解与推理方面的能力，为未来多模态交互系统的发展提供了重要基础。

Abstract: While Large Vision Language Models (LVLMs) are increasingly deployed in real-world applications, their ability to interpret abstract visual inputs remains limited. Specifically, they struggle to comprehend hand-drawn sketches, a modality that offers an intuitive means of expressing concepts that are difficult to describe textually. We identify the primary bottleneck as the absence of a large-scale dataset that jointly models sketches, photorealistic images, and corresponding natural language instructions. To address this, we present two key contributions: (1) a new, large-scale dataset of image-sketch-instruction triplets designed to facilitate both pretraining and instruction tuning, and (2) O3SLM, an LVLM trained on this dataset. Comprehensive evaluations on multiple sketch-based tasks: (a) object localization, (b) counting, (c) image retrieval i.e., (SBIR and fine-grained SBIR), and (d) visual question answering (VQA); while incorporating the three existing sketch datasets, namely QuickDraw!, Sketchy, and Tu Berlin, along with our generated SketchVCL dataset, show that O3SLM achieves state-of-the-art performance, substantially outperforming existing LVLMs in sketch comprehension and reasoning.

</details>


### [45] [Learning Representation and Synergy Invariances: A Povable Framework for Generalized Multimodal Face Anti-Spoofing](https://arxiv.org/abs/2511.14157)
*Xun Lin,Shuai Wang,Yi Yu,Zitong Yu,Jiale Zhou,Yizhong Liu,Xiaochun Cao,Alex Kot,Yefeng Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为RiSe的可证明框架，用于解决多模态人脸反欺骗（FAS）在跨域场景下的性能退化问题。主要针对两种被忽视的风险：模态表示不变性风险和模态协同不变性风险。通过引入对称不变风险最小化（AsyIRM）和多模态协同解耦（MMSD），RiSe在径向空间中学习不变球形决策边界以适应类别不对称分布，并在角空间中保留域线索；同时通过自监督任务增强跨样本混合与解耦，提升泛化能力。理论分析与实验验证表明，该方法在跨域场景下达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 多模态人脸反欺骗方法在未见域上性能下降严重，主要源于两个被忽视的风险：模态表示不变性风险和模态协同不变性风险。前者由FAS任务中真实样本紧凑、伪造样本多样导致的类别不对称放大泛化误差上界；后者源于模型过拟合于特定域内的模态间虚假相关性，无法泛化到新攻击类型。

Method: 提出RiSe框架，包含两个核心组件：(1) 对称不变风险最小化（AsyIRM），在径向空间构建不变球形决策边界以适应类别不对称，同时在角空间保留域信息；(2) 多模态协同解耦（MMSD），通过自监督的跨样本混合与特征解耦，强化模态间的内在、可泛化的关联。

Result: RiSe在多个跨域测试集上均取得当前最优性能，显著优于现有方法，且理论分析验证了其对两类风险的有效缓解。

Conclusion: RiSe通过联合建模表示与协同的不变性，有效解决了多模态FAS在跨域部署中的关键挑战，为实际应用提供了更强的鲁棒性和泛化能力。

Abstract: Multimodal Face Anti-Spoofing (FAS) methods, which integrate multiple visual modalities, often suffer even more severe performance degradation than unimodal FAS when deployed in unseen domains. This is mainly due to two overlooked risks that affect cross-domain multimodal generalization. The first is the modal representation invariant risk, i.e., whether representations remain generalizable under domain shift. We theoretically show that the inherent class asymmetry in FAS (diverse spoofs vs. compact reals) enlarges the upper bound of generalization error, and this effect is further amplified in multimodal settings. The second is the modal synergy invariant risk, where models overfit to domain-specific inter-modal correlations. Such spurious synergy cannot generalize to unseen attacks in target domains, leading to performance drops. To solve these issues, we propose a provable framework, namely Multimodal Representation and Synergy Invariance Learning (RiSe). For representation risk, RiSe introduces Asymmetric Invariant Risk Minimization (AsyIRM), which learns an invariant spherical decision boundary in radial space to fit asymmetric distributions, while preserving domain cues in angular space. For synergy risk, RiSe employs Multimodal Synergy Disentanglement (MMSD), a self-supervised task enhancing intrinsic, generalizable modal features via cross-sample mixing and disentanglement. Theoretical analysis and experiments verify RiSe, which achieves state-of-the-art cross-domain performance.

</details>


### [46] [MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs](https://arxiv.org/abs/2511.14159)
*Huiyi Chen,Jiawei Peng,Dehai Min,Changchang Sun,Kaijie Chen,Yan Yan,Xu Yang,Lu Cheng*

Main category: cs.CV

TL;DR: 本文提出MVI-Bench，首个专门评估误导性视觉输入对大型视觉语言模型（LVLMs）鲁棒性影响的综合性基准。基于视觉基本要素，构建了三个层次的误导性视觉输入分类：视觉概念、视觉属性和视觉关系，涵盖六个代表性类别，共1,248个专家标注的VQA任务。同时引入MVI-Sensitivity新指标，实现细粒度鲁棒性评估。实验发现18个主流LVLMs在误导性视觉输入下存在显著脆弱性，并提供可指导模型改进的洞察。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒性评测主要关注幻觉或误导性文本输入，忽视了误导性视觉输入对视觉理解能力的同等重要挑战。为填补这一空白，亟需一个专门针对视觉误导的评测基准。

Method: 设计MVI-Bench基准，依据视觉基本要素划分三层次误导性视觉输入（视觉概念、属性、关系），构建六类典型场景，收集并标注1,248个VQA样本；提出MVI-Sensitivity指标，实现模型鲁棒性的细粒度量化评估。

Result: 在18个先进LVLM上进行实证测试，揭示其对误导性视觉输入的高度敏感性；通过深入分析，获得有助于提升模型可靠性和鲁棒性的关键洞见。

Conclusion: MVI-Bench为评估LVLM在误导性视觉输入下的表现提供了首个系统化框架，推动更稳健的视觉语言模型研发。开源资源已发布，供研究社区使用。

Abstract: Evaluating the robustness of Large Vision-Language Models (LVLMs) is essential for their continued development and responsible deployment in real-world applications. However, existing robustness benchmarks typically focus on hallucination or misleading textual inputs, while largely overlooking the equally critical challenge posed by misleading visual inputs in assessing visual understanding. To fill this important gap, we introduce MVI-Bench, the first comprehensive benchmark specially designed for evaluating how Misleading Visual Inputs undermine the robustness of LVLMs. Grounded in fundamental visual primitives, the design of MVI-Bench centers on three hierarchical levels of misleading visual inputs: Visual Concept, Visual Attribute, and Visual Relationship. Using this taxonomy, we curate six representative categories and compile 1,248 expertly annotated VQA instances. To facilitate fine-grained robustness evaluation, we further introduce MVI-Sensitivity, a novel metric that characterizes LVLM robustness at a granular level. Empirical results across 18 state-of-the-art LVLMs uncover pronounced vulnerabilities to misleading visual inputs, and our in-depth analyses on MVI-Bench provide actionable insights that can guide the development of more reliable and robust LVLMs. The benchmark and codebase can be accessed at https://github.com/chenyil6/MVI-Bench.

</details>


### [47] [AdaTok: Adaptive Token Compression with Object-Aware Representations for Efficient Multimodal LLMs](https://arxiv.org/abs/2511.14169)
*Xinliang Zhang,Lei Zhu,Hangzhou He,Shuang Zeng,Ourui Fu,Jiakui Hu,Zhengjian Yao,Yanye Lu*

Main category: cs.CV

TL;DR: 提出一种基于对象级别的令牌合并策略，用于自适应令牌压缩，以解决多模态大语言模型中因补丁级标记化导致的计算和内存负担问题。该方法与人类视觉认知系统一致，实验表明在仅使用10%令牌的情况下，性能达到原始模型的96%，显著提升了压缩比与性能之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统补丁级标记化导致图像令牌数量呈二次增长，增加计算和内存负担，并且与人类视觉认知系统不一致，引发幻觉和计算冗余。因此需要一种更高效、更符合人类视觉认知的标记化方法。

Method: 提出一种对象级别的令牌合并策略，实现自适应令牌压缩，使标记化过程更贴近人类视觉认知系统。

Result: 在多个基准测试中，所提方法仅使用10%的令牌，性能达到原始模型的96%，优于现有相关方法，在压缩比与性能之间表现出更优的平衡。

Conclusion: 该方法有效缓解了多模态大语言模型中的计算与内存压力，同时提升模型性能与人类认知一致性，具有显著优势。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated substantial value in unified text-image understanding and reasoning, primarily by converting images into sequences of patch-level tokens that align with their architectural paradigm. However, patch-level tokenization leads to a quadratic growth in image tokens, burdening MLLMs' understanding and reasoning with enormous computation and memory. Additionally, the traditional patch-wise scanning tokenization workflow misaligns with the human vision cognition system, further leading to hallucination and computational redundancy. To address this issue, we propose an object-level token merging strategy for Adaptive Token compression, revealing the consistency with human vision system. The experiments are conducted on multiple comprehensive benchmarks, which show that our approach averagely, utilizes only 10% tokens while achieving almost 96% of the vanilla model's performance. More extensive experimental results in comparison with relevant works demonstrate the superiority of our method in balancing compression ratio and performance. Our code will be available.

</details>


### [48] [DoGCLR: Dominance-Game Contrastive Learning Network for Skeleton-Based Action Recognition](https://arxiv.org/abs/2511.14179)
*Yanshan Li,Ke Ma,Miaomiao Wei,Linhui Dai*

Main category: cs.CV

TL;DR: 本文提出一种基于博弈论的自监督对比学习框架DoGCLR，用于骨架动作识别。针对传统方法在处理骨架区域时均一化且负样本选择不佳的问题，DoGCLR将正负样本构建建模为动态主导博弈，通过时空双重加权定位机制识别关键运动区域，引导区域级增强以提升运动多样性并保持语义一致性；同时采用熵驱动的主导策略管理记忆库，保留高熵（难）负样本，替换低熵（弱）负样本，确保持续接收信息丰富的对比信号。在NTU RGB+D和PKU-MMD数据集上的实验表明，DoGCLR在多个设置下显著优于现有方法，尤其在挑战性场景中表现出更强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自监督对比学习方法对骨架各区域处理方式统一，使用先进先出队列存储负样本，导致运动信息丢失且负样本选择不优，影响模型性能。

Method: 提出基于博弈论的DoGCLR框架，将正负样本构建视为动态主导博弈；引入时空双重加权定位机制以识别关键运动区域，并指导区域级增强；设计熵驱动的主导策略管理记忆库，优先保留高熵负样本。

Result: 在NTU RGB+D 60 X-Sub/X-View上分别达到81.1%和89.4%准确率，在120 X-Sub/X-Set上分别达到71.2%和75.5%准确率，超越当前最优方法0.1%、2.7%、1.1%和2.3%；在PKU-MMD Part II上比现有方法高出1.9%，显示良好鲁棒性。

Conclusion: DoGCLR通过博弈论建模与智能负样本管理，有效缓解运动信息损失问题，提升了骨架动作识别的自监督学习性能，尤其在复杂场景下表现突出。

Abstract: Existing self-supervised contrastive learning methods for skeleton-based action recognition often process all skeleton regions uniformly, and adopt a first-in-first-out (FIFO) queue to store negative samples, which leads to motion information loss and non-optimal negative sample selection. To address these challenges, this paper proposes Dominance-Game Contrastive Learning network for skeleton-based action Recognition (DoGCLR), a self-supervised framework based on game theory. DoGCLR models the construction of positive and negative samples as a dynamic Dominance Game, where both sample types interact to reach an equilibrium that balances semantic preservation and discriminative strength. Specifically, a spatio-temporal dual weight localization mechanism identifies key motion regions and guides region-wise augmentations to enhance motion diversity while maintaining semantics. In parallel, an entropy-driven dominance strategy manages the memory bank by retaining high entropy (hard) negatives and replacing low-entropy (weak) ones, ensuring consistent exposure to informative contrastive signals. Extensive experiments are conducted on NTU RGB+D and PKU-MMD datasets. On NTU RGB+D 60 X-Sub/X-View, DoGCLR achieves 81.1%/89.4% accuracy, and on NTU RGB+D 120 X-Sub/X-Set, DoGCLR achieves 71.2%/75.5% accuracy, surpassing state-of-the-art methods by 0.1%, 2.7%, 1.1%, and 2.3%, respectively. On PKU-MMD Part I/Part II, DoGCLR performs comparably to the state-of-the-art methods and achieves a 1.9% higher accuracy on Part II, highlighting its strong robustness on more challenging scenarios.

</details>


### [49] [UniSER: A Foundation Model for Unified Soft Effects Removal](https://arxiv.org/abs/2511.14183)
*Jingdong Zhang,Lingzhi Zhang,Qing Liu,Mang Tik Chiu,Connelly Barnes,Yizhou Wang,Haoran You,Xiaoyang Liu,Yuqian Zhou,Zhe Lin,Eli Shechtman,Sohrab Amirghodsi,Xin Li,Wenping Wang,Xiaohang Zhan*

Main category: cs.CV

TL;DR: 提出统一模型UniSER，通过380万对数据和微调扩散Transformer，实现对多种软效应（如镜头光晕、雾霾、阴影）的统一修复，显著优于专用与通用模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法将软效应退化问题孤立处理，导致模型专一性过强、可扩展性差；而通用模型虽具备强大编辑能力，但对细粒度修复任务鲁棒性不足且难以保持场景身份。

Method: 构建包含380万对图像的大型数据集，融合物理上合理的新型数据以填补公开基准空白；采用定制化训练流程，微调扩散Transformer学习从多样化数据中恢复的先验知识，并集成细粒度掩码与强度控制。

Result: UniSER在真实复杂场景下实现了高保真、鲁棒的图像修复效果，显著超越专用与通用模型，在多种软效应退化修复任务中表现优异。

Conclusion: UniSER通过捕捉软效应的共同本质——半透明遮挡，建立了一个统一、可扩展的图像修复框架，为复杂退化场景下的图像恢复提供了新范式。

Abstract: Digital images are often degraded by soft effects such as lens flare, haze, shadows, and reflections, which reduce aesthetics even though the underlying pixels remain partially visible. The prevailing works address these degradations in isolation, developing highly specialized, specialist models that lack scalability and fail to exploit the shared underlying essences of these restoration problems. While specialist models are limited, recent large-scale pretrained generalist models offer powerful, text-driven image editing capabilities. while recent general-purpose systems (e.g., GPT-4o, Flux Kontext, Nano Banana) require detailed prompts and often fail to achieve robust removal on these fine-grained tasks or preserve identity of the scene. Leveraging the common essence of soft effects, i.e., semi-transparent occlusions, we introduce a foundational versatile model UniSER, capable of addressing diverse degradations caused by soft effects within a single framework. Our methodology centers on curating a massive 3.8M-pair dataset to ensure robustness and generalization, which includes novel, physically-plausible data to fill critical gaps in public benchmarks, and a tailored training pipeline that fine-tunes a Diffusion Transformer to learn robust restoration priors from this diverse data, integrating fine-grained mask and strength controls. This synergistic approach allows UniSER to significantly outperform both specialist and generalist models, achieving robust, high-fidelity restoration in the wild.

</details>


### [50] [GloTok: Global Perspective Tokenizer for Image Reconstruction and Generation](https://arxiv.org/abs/2511.14184)
*Xuan Zhao,Zhongyu Zhang,Yuge Huang,Yuxi Mi,Guodong Mu,Shouhong Ding,Jun Wang,Rizen Guo,Shuigeng Zhou*

Main category: cs.CV

TL;DR: 本文提出一种全局视角分词器（GloTok），通过利用全局关系信息建模更均匀的语义分布，提升图像重建与生成质量。方法上，采用基于码本直方图的关系学习来传递预训练模型在全数据集上的语义信息，并设计残差学习模块以恢复细节、减少量化误差。实验表明，GloTok在ImageNet-1k上达到顶尖的重建与生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像分词方法依赖局部语义监督，导致语义分布不均；而研究表明更均匀的特征分布有助于提升生成效果，因此需要一种能实现全局语义一致性的分词方法。

Method: 提出全局视角分词器GloTok，包括码本级直方图关系学习机制，用于将预训练模型在全数据集上的语义信息迁移至语义码本，并引入残差学习模块以恢复细粒度细节，降低量化带来的重建误差。

Result: 在ImageNet-1k基准测试中，GloTok实现了当前最优的图像重建性能和生成质量，且无需在训练过程中访问预训练模型。

Conclusion: GloTok通过全局关系建模实现了更均匀的语义潜空间分布，显著提升了自回归模型生成高质量图像的能力，为无须直接调用预训练模型的高效图像生成提供了新思路。

Abstract: Existing state-of-the-art image tokenization methods leverage diverse semantic features from pre-trained vision models for additional supervision, to expand the distribution of latent representations and thereby improve the quality of image reconstruction and generation. These methods employ a locally supervised approach for semantic supervision, which limits the uniformity of semantic distribution. However, VA-VAE proves that a more uniform feature distribution yields better generation performance. In this work, we introduce a Global Perspective Tokenizer (GloTok), which utilizes global relational information to model a more uniform semantic distribution of tokenized features. Specifically, a codebook-wise histogram relation learning method is proposed to transfer the semantics, which are modeled by pre-trained models on the entire dataset, to the semantic codebook. Then, we design a residual learning module that recovers the fine-grained details to minimize the reconstruction error caused by quantization. Through the above design, GloTok delivers more uniformly distributed semantic latent representations, which facilitates the training of autoregressive (AR) models for generating high-quality images without requiring direct access to pre-trained models during the training process. Experiments on the standard ImageNet-1k benchmark clearly show that our proposed method achieves state-of-the-art reconstruction performance and generation quality.

</details>


### [51] [PAVE: An End-to-End Dataset for Production Autonomous Vehicle Evaluation](https://arxiv.org/abs/2511.14185)
*Xiangyu Li,Chen Wang,Yumao Liu,Dengbo He,Jiahao Zhang,Ke Ma*

Main category: cs.CV

TL;DR: 本文提出首个完全由自动驾驶模式在真实世界中采集的端到端基准数据集，包含超过100小时的自然驾驶数据，涵盖多种量产自动驾驶车型。数据被分割为32,727个关键帧，每帧包含四路同步摄像头图像和高精度GNSS/IMU数据（定位精度0.8厘米），并提供前后各6秒和5秒的20Hz车辆轨迹及详细2D标注（车辆、行人、交通灯、交通标志）。关键帧具备丰富的场景级属性，如驾驶意图、区域类型、光照、天气、路面状况、交通密度、交通信号等。通过端到端运动规划模型评估，自动驾驶帧上的平均位移误差（ADE）为1.4米。数据集每周新增超10小时数据，持续扩展，为自动驾驶行为分析与安全评估提供可持续研究基础。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶数据集（如KITTI、nuScenes、Waymo Perception Dataset）多由人类驾驶或未明确驾驶模式采集，仅适用于感知与预测的初步训练。为真正评估黑箱控制下自动驾驶车辆的行为安全性，亟需基于真实自动驾驶模式采集的数据集。

Method: 在真实世界中，使用多款市售自动驾驶车辆模型，以全自动驾驶模式采集数据；将原始数据分割为32,727个关键帧，每帧包含四路同步摄像头图像与高精度GNSS/IMU数据（0.8厘米定位精度），并提供前后各6秒与5秒的20Hz车辆轨迹，以及对周围车辆、行人、交通灯、交通标志的详细2D标注。同时标注关键帧的场景级属性，如区域类型、光照、天气、道路表面、交通密度、交通信号类型等。采用端到端运动规划模型进行轨迹预测，评估自动驾驶行为的安全性。

Result: 数据集成功构建，包含超过100小时的真实自动驾驶数据，关键帧具有高精度时空信息与丰富语义标注。端到端运动规划模型在自动驾驶帧上实现1.4米的平均位移误差（ADE），验证了数据集可用于评估自动驾驶系统行为安全性。数据集每周新增超10小时数据，具备持续扩展能力。

Conclusion: 该数据集是首个完全基于真实自动驾驶模式采集的端到端基准数据集，填补了现有数据集在真实自动驾驶行为评估方面的空白，为自动驾驶系统行为分析与安全评估提供了高质量、可持续的研究基础。

Abstract: Most existing autonomous-driving datasets (e.g., KITTI, nuScenes, and the Waymo Perception Dataset), collected by human-driving mode or unidentified driving mode, can only serve as early training for the perception and prediction of autonomous vehicles (AVs). To evaluate the real behavioral safety of AVs controlled in the black box, we present the first end-to-end benchmark dataset collected entirely by autonomous-driving mode in the real world. This dataset contains over 100 hours of naturalistic data from multiple production autonomous-driving vehicle models in the market. We segment the original data into 32,727 key frames, each consisting of four synchronized camera images and high-precision GNSS/IMU data (0.8 cm localization accuracy). For each key frame, 20 Hz vehicle trajectories spanning the past 6 s and future 5 s are provided, along with detailed 2D annotations of surrounding vehicles, pedestrians, traffic lights, and traffic signs. These key frames have rich scenario-level attributes, including driver intent, area type (covering highways, urban roads, and residential areas), lighting (day, night, or dusk), weather (clear or rain), road surface (paved or unpaved), traffic and vulnerable road users (VRU) density, traffic lights, and traffic signs (warning, prohibition, and indication). To evaluate the safety of AVs, we employ an end-to-end motion planning model that predicts vehicle trajectories with an Average Displacement Error (ADE) of 1.4 m on autonomous-driving frames. The dataset continues to expand by over 10 hours of new data weekly, thereby providing a sustainable foundation for research on AV driving behavior analysis and safety evaluation.

</details>


### [52] [Hierarchical Semantic Learning for Multi-Class Aorta Segmentation](https://arxiv.org/abs/2511.14187)
*Pengcheng Shi*

Main category: cs.CV

TL;DR: 本文提出一种基于课程学习的分层语义学习方法，用于主动脉血管的3D分割，解决现有方法在层次结构建模和类别不平衡方面的不足。通过引入新型分形Softmax，模型从简单到复杂逐步学习解剖约束，显著提升对罕见但关键血管结构的识别能力，并实现五倍加速的推理效率。在测试集上，该方法比基线模型提高5.6%的Dice分数，验证了其在临床实时应用中的有效性。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 主动脉疾病如夹层、动脉瘤和动脉粥样硬化需要及时干预，而微创修复依赖于详细的3D解剖分析。现有方法常忽略血管的层次结构关系，且在处理血管结构中严重的类别不平衡问题时表现不佳。

Method: 提出一种结合课程学习策略与分形Softmax的分层语义学习框架，通过从简单到复杂的渐进式训练方式，增强模型对主导类别的特征表示，并逐步关注稀有但重要的解剖结构；同时采用两阶段推理策略，显著提升推理速度。

Result: 在验证集第50轮时，分层语义损失使nnU-Net ResEnc M的Dice分数提升11.65%；在测试集上，模型比基线高出5.6%的Dice分数，且推理速度提升达五倍，具备良好的临床实用性。

Conclusion: 所提出的框架有效提升了主动脉多类分割的准确性与效率，适用于实时临床场景，具有重要应用价值。

Abstract: The aorta, the body's largest artery, is prone to pathologies such as dissection, aneurysm, and atherosclerosis, which often require timely intervention. Minimally invasive repairs involving branch vessels necessitate detailed 3D anatomical analysis. Existing methods often overlook hierarchical anatomical relationships while struggling with severe class imbalance inherent in vascular structures. We address these challenges with a curriculum learning strategy that leverages a novel fractal softmax for hierarchical semantic learning. Inspired by human cognition, our approach progressively learns anatomical constraints by decomposing complex structures from simple to complex components. The curriculum learning framework naturally addresses class imbalance by first establishing robust feature representations for dominant classes before tackling rare but anatomically critical structures, significantly accelerating model convergence in multi-class scenarios. Our two-stage inference strategy achieves up to fivefold acceleration, enhancing clinical practicality. On the validation set at epoch 50, our hierarchical semantic loss improves the Dice score of nnU-Net ResEnc M by 11.65%. The proposed model demonstrates a 5.6% higher Dice score than baselines on the test set. Experimental results show significant improvements in segmentation accuracy and efficiency, making the framework suitable for real-time clinical applications. The implementation code for this challenge entry is publicly available at: https://github.com/PengchengShi1220/AortaSeg24. The code for fractal softmax will be available at https://github.com/PengchengShi1220/fractal-softmax.

</details>


### [53] [Multi-Scale Correlation-Aware Transformer for Maritime Vessel Re-Identification](https://arxiv.org/abs/2511.14203)
*Yunhe Liu*

Main category: cs.CV

TL;DR: 提出MCFormer模型，通过多尺度相关性建模解决船舶重识别中的身份内差异和局部缺失问题，结合全局与局部相关性模块，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有船舶重识别方法多直接套用行人重识别算法，无法有效应对船舶图像中身份内变化大、局部缺失严重等问题，导致同类别异常样本增多。

Method: 设计MCFormer模型，包含全局相关性模块（GCM）和局部相关性模块（LCM），GCM通过跨图像一致性构建全局相似性矩阵，LCM利用动态记忆库对齐正样本局部特征，增强上下文关联性，并融合多尺度的全局与局部特征以提高鲁棒性。

Result: 在三个基准数据集上实验表明，MCFormer达到当前最优性能。

Conclusion: MCFormer通过显式建模多尺度相关性，有效缓解了船舶图像中因身份内差异和局部缺失带来的挑战，显著提升了重识别准确率。

Abstract: Maritime vessel re-identification (Re-ID) plays a crucial role in advancing maritime monitoring and intelligent situational awareness systems. However, some existing vessel Re-ID methods are directly adapted from pedestrian-focused algorithms, making them ill-suited for mitigating the unique problems present in vessel images, particularly the greater intra-identity variations and more severe missing of local parts, which lead to the emergence of outlier samples within the same identity. To address these challenges, we propose the Multi-scale Correlation-aware Transformer Network (MCFormer), which explicitly models multi-scale correlations across the entire input set to suppress the adverse effects of outlier samples with intra-identity variations or local missing, incorporating two novel modules, the Global Correlation Module (GCM), and the Local Correlation Module (LCM). Specifically, GCM constructs a global similarity affinity matrix across all input images to model global correlations through feature aggregation based on inter-image consistency, rather than solely learning features from individual images as in most existing approaches. Simultaneously, LCM mines and aligns local features of positive samples with contextual similarity to extract local correlations by maintaining a dynamic memory bank, effectively compensating for missing or occluded regions in individual images. To further enhance feature robustness, MCFormer integrates global and local features that have been respectively correlated across multiple scales, effectively capturing latent relationships among image features. Experiments on three benchmarks demonstrate that MCFormer achieves state-of-the-art performance.

</details>


### [54] [InstantViR: Real-Time Video Inverse Problem Solver with Distilled Diffusion Prior](https://arxiv.org/abs/2511.14208)
*Weimin Bai,Suzhe Xu,Yiwei Ren,Jinhua Hao,Ming Sun,Wenzheng Chen,He Sun*

Main category: cs.CV

TL;DR: InstantViR enables ultra-fast, high-quality video restoration by distilling a bidirectional video diffusion model into a causal autoregressive student model with a LeanVAE backbone, achieving real-time performance (35+ FPS) and up to 100x speedup over iterative methods, without needing paired training data.


<details>
  <summary>Details</summary>
Motivation: Video inverse problems are crucial for applications like streaming, telepresence, and AR/VR, requiring high perceptual quality with strict latency constraints. Existing diffusion-based methods either introduce temporal artifacts through ad hoc temporal regularizers or suffer from slow iterative sampling in video diffusion models, making them unsuitable for real-time use.

Method: InstantViR introduces an amortized inference framework that distills a bidirectional video diffusion model (teacher) into a causal autoregressive student model. This student model performs single-pass restoration of degraded videos, inheriting strong temporal modeling without iterative optimization. The distillation is prior-driven, relying only on the teacher model and degradation operators, not paired clean/noisy data. Additionally, a high-efficiency LeanVAE replaces the original VAE backbone via a novel teacher-space regularized distillation scheme to enhance throughput.

Result: InstantViR achieves reconstruction quality comparable to or better than state-of-the-art diffusion-based baselines across tasks such as streaming random inpainting, Gaussian deblurring, and super-resolution. It runs at over 35 FPS on NVIDIA A100 GPUs, delivering up to 100x speedups over iterative video diffusion solvers, enabling real-time, interactive, and editable video restoration.

Conclusion: Diffusion-based video reconstruction is now viable for real-time applications, making high-quality video restoration a practical component in modern vision systems.

Abstract: Video inverse problems are fundamental to streaming, telepresence, and AR/VR, where high perceptual quality must coexist with tight latency constraints. Diffusion-based priors currently deliver state-of-the-art reconstructions, but existing approaches either adapt image diffusion models with ad hoc temporal regularizers - leading to temporal artifacts - or rely on native video diffusion models whose iterative posterior sampling is far too slow for real-time use. We introduce InstantViR, an amortized inference framework for ultra-fast video reconstruction powered by a pre-trained video diffusion prior. We distill a powerful bidirectional video diffusion model (teacher) into a causal autoregressive student that maps a degraded video directly to its restored version in a single forward pass, inheriting the teacher's strong temporal modeling while completely removing iterative test-time optimization. The distillation is prior-driven: it only requires the teacher diffusion model and known degradation operators, and does not rely on externally paired clean/noisy video data. To further boost throughput, we replace the video-diffusion backbone VAE with a high-efficiency LeanVAE via an innovative teacher-space regularized distillation scheme, enabling low-latency latent-space processing. Across streaming random inpainting, Gaussian deblurring and super-resolution, InstantViR matches or surpasses the reconstruction quality of diffusion-based baselines while running at over 35 FPS on NVIDIA A100 GPUs, achieving up to 100 times speedups over iterative video diffusion solvers. These results show that diffusion-based video reconstruction is compatible with real-time, interactive, editable, streaming scenarios, turning high-quality video restoration into a practical component of modern vision systems.

</details>


### [55] [Measurement-Constrained Sampling for Text-Prompted Blind Face Restoration](https://arxiv.org/abs/2511.14213)
*Wenjie Li,Yulun Zhang,Guangwei Gao,Heng Guo,Zhanyu Ma*

Main category: cs.CV

TL;DR: 本文提出一种测量约束采样（MCS）方法，用于盲人脸恢复（BFR），以解决低质量输入下存在多个合理高质量重建的“一对多”问题。通过构建受控退化下的逆问题，将BFR建模为测量约束生成任务，结合前向与反向测量约束，实现基于文本提示的多样化重建。实验表明，该方法能生成与提示一致的结果，并优于现有BFR方法。


<details>
  <summary>Details</summary>
Motivation: 现有盲人脸恢复方法通常产生确定性结果，无法捕捉低质量输入下可能存在的多种高质量重建，缺乏对‘一对多’特性的建模能力。

Method: 提出测量约束采样（MCS）方法，将盲人脸恢复建模为测量约束的生成任务。通过控制粗略重建的退化过程构建逆问题，引入前向测量（保证结果与输入结构一致）和反向测量（生成投影空间以匹配不同文本提示），在文本到图像扩散模型中实现后验引导采样。

Result: 所提方法能够生成与不同文本提示对齐的多样化高保真人脸重建，有效捕捉一对多特性，在多项指标上优于现有方法。

Conclusion: MCS成功实现了盲人脸恢复中多样性和提示可控性的统一，为解决低质量输入下的不确定性重建提供了新思路。

Abstract: Blind face restoration (BFR) may correspond to multiple plausible high-quality (HQ) reconstructions under extremely low-quality (LQ) inputs. However, existing methods typically produce deterministic results, struggling to capture this one-to-many nature. In this paper, we propose a Measurement-Constrained Sampling (MCS) approach that enables diverse LQ face reconstructions conditioned on different textual prompts. Specifically, we formulate BFR as a measurement-constrained generative task by constructing an inverse problem through controlled degradations of coarse restorations, which allows posterior-guided sampling within text-to-image diffusion. Measurement constraints include both Forward Measurement, which ensures results align with input structures, and Reverse Measurement, which produces projection spaces, ensuring that the solution can align with various prompts. Experiments show that our MCS can generate prompt-aligned results and outperforms existing BFR methods. Codes will be released after acceptance.

</details>


### [56] [StreamingTalker: Audio-driven 3D Facial Animation with Autoregressive Diffusion Model](https://arxiv.org/abs/2511.14223)
*Yifan Yang,Zhi Cen,Sida Peng,Xiangwei Chen,Yifu Deng,Xinyu Zhu,Fan Jia,Xiaowei Zhou,Hujun Bao*

Main category: cs.CV

TL;DR: 本文提出一种新型自回归扩散模型，用于语音驱动的3D面部动画生成，通过流式处理音频输入，实现低延迟与长音频支持，提升实时性与灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用音频条件扩散模型处理整个音频序列，导致在超出训练长度时表现不佳且处理长音频时存在显著延迟，亟需更高效、灵活的方案。

Method: 设计一种自回归扩散模型，以流式方式处理音频输入；仅保留有限数量的历史动作帧作为上下文，并结合当前音频输入动态生成条件，指导扩散过程逐帧生成面部运动。

Result: 实现了与音频长度无关的低延迟实时合成，生成高质量、同步的面部动画，且已构建实时交互演示系统验证效果。

Conclusion: 所提方法有效解决了长音频处理与延迟问题，在语音驱动3D面部动画中具备高效率与实用性，代码将公开发布。

Abstract: This paper focuses on the task of speech-driven 3D facial animation, which aims to generate realistic and synchronized facial motions driven by speech inputs.Recent methods have employed audio-conditioned diffusion models for 3D facial animation, achieving impressive results in generating expressive and natural animations.However, these methods process the whole audio sequences in a single pass, which poses two major challenges: they tend to perform poorly when handling audio sequences that exceed the training horizon and will suffer from significant latency when processing long audio inputs. To address these limitations, we propose a novel autoregressive diffusion model that processes input audio in a streaming manner. This design ensures flexibility with varying audio lengths and achieves low latency independent of audio duration. Specifically, we select a limited number of past frames as historical motion context and combine them with the audio input to create a dynamic condition. This condition guides the diffusion process to iteratively generate facial motion frames, enabling real-time synthesis with high-quality results. Additionally, we implemented a real-time interactive demo, highlighting the effectiveness and efficiency of our approach. We will release the code at https://zju3dv.github.io/StreamingTalker/.

</details>


### [57] [Enhancing Generalization of Depth Estimation Foundation Model via Weakly-Supervised Adaptation with Regularization](https://arxiv.org/abs/2511.14238)
*Yan Huang,Yongyi Su,Xin Lin,Le Zhang,Xun Xu*

Main category: cs.CV

TL;DR: WeSTAR是一种参数高效框架，用于在弱监督下进行自训练适应与正则化，以提升单目深度估计（MDE）基础模型在未见和多样化领域中的鲁棒性。通过密集自训练目标、语义感知的分层归一化、成对序数深度标注的弱监督以及权重正则化损失，显著增强模型泛化能力，在多种基准测试中达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型如Depth Anything在零样本泛化方面已取得进展，但如何利用下游任务的少量数据进一步提升性能仍是一个开放问题。尤其在未知和多样化的现实场景中，模型鲁棒性亟待增强。

Method: 提出WeSTAR框架：采用密集自训练作为结构自监督；引入语义感知的分层归一化以实现更稳定、多尺度的结构归一化；使用成对序数深度标注提供低成本弱监督，约束局部拓扑错误；结合权重正则化损失，确保LoRA更新稳定并保留通用知识。

Result: 在真实和受损的分布外数据集上，WeSTAR在多种复杂场景下均表现出更强的泛化能力，持续超越现有方法，达到多个基准上的最先进水平。

Conclusion: WeSTAR有效提升了单目深度估计基础模型在多样化和未知环境下的适应性与鲁棒性，证明了弱监督自训练与正则化机制在参数高效微调中的有效性。

Abstract: The emergence of foundation models has substantially advanced zero-shot generalization in monocular depth estimation (MDE), as exemplified by the Depth Anything series. However, given access to some data from downstream tasks, a natural question arises: can the performance of these models be further improved? To this end, we propose WeSTAR, a parameter-efficient framework that performs Weakly supervised Self-Training Adaptation with Regularization, designed to enhance the robustness of MDE foundation models in unseen and diverse domains. We first adopt a dense self-training objective as the primary source of structural self-supervision. To further improve robustness, we introduce semantically-aware hierarchical normalization, which exploits instance-level segmentation maps to perform more stable and multi-scale structural normalization. Beyond dense supervision, we introduce a cost-efficient weak supervision in the form of pairwise ordinal depth annotations to further guide the adaptation process, which enforces informative ordinal constraints to mitigate local topological errors. Finally, a weight regularization loss is employed to anchor the LoRA updates, ensuring training stability and preserving the model's generalizable knowledge. Extensive experiments on both realistic and corrupted out-of-distribution datasets under diverse and challenging scenarios demonstrate that WeSTAR consistently improves generalization and achieves state-of-the-art performance across a wide range of benchmarks.

</details>


### [58] [V2VLoc: Robust GNSS-Free Collaborative Perception via LiDAR Localization](https://arxiv.org/abs/2511.14247)
*Wenkai Lin,Qiming Xia,Wen Li,Xun Huang,Chenglu Wen*

Main category: cs.CV

TL;DR: 本文提出了一种基于激光雷达定位的鲁棒无GNSS协同感知框架，通过轻量级置信度姿态生成器（PGC）估计紧凑的姿态与置信度表示，并引入置信度感知时空对齐变换器（PASTAT）以缓解定位误差影响。同时构建了新仿真数据集V2VLoc，包含用于定位和协同检测任务的多个子集。实验表明，该方法在无GNSS环境下达到领先性能，并在真实数据集上验证了有效性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统基于GNSS的定位在无GNSS环境中失效，导致多智能体间观测共享与对齐困难，影响协同感知效果。因此需要一种不依赖GNSS、具备高鲁棒性的协同感知方法。

Method: 提出轻量级姿态生成器与置信度（PGC）用于估计姿态与置信度；设计置信度感知时空对齐变换器（PASTAT），实现基于置信度的空间对齐与时间上下文建模；构建V2VLoc仿真数据集，支持定位与协同检测任务训练与评估。

Result: 在V2VLoc数据集上的实验表明，所提方法在无GNSS环境下达到当前最优性能；在真实世界数据集V2V4Real上的扩展实验验证了PASTAT的有效性与泛化能力。

Conclusion: 所提出的无GNSS协同感知框架在复杂环境下表现出优异的鲁棒性与准确性，为多智能体协同感知提供了有效的解决方案。

Abstract: Multi-agents rely on accurate poses to share and align observations, enabling a collaborative perception of the environment. However, traditional GNSS-based localization often fails in GNSS-denied environments, making consistent feature alignment difficult in collaboration. To tackle this challenge, we propose a robust GNSS-free collaborative perception framework based on LiDAR localization. Specifically, we propose a lightweight Pose Generator with Confidence (PGC) to estimate compact pose and confidence representations. To alleviate the effects of localization errors, we further develop the Pose-Aware Spatio-Temporal Alignment Transformer (PASTAT), which performs confidence-aware spatial alignment while capturing essential temporal context. Additionally, we present a new simulation dataset, V2VLoc, which can be adapted for both LiDAR localization and collaborative detection tasks. V2VLoc comprises three subsets: Town1Loc, Town4Loc, and V2VDet. Town1Loc and Town4Loc offer multi-traversal sequences for training in localization tasks, whereas V2VDet is specifically intended for the collaborative detection task. Extensive experiments conducted on the V2VLoc dataset demonstrate that our approach achieves state-of-the-art performance under GNSS-denied conditions. We further conduct extended experiments on the real-world V2V4Real dataset to validate the effectiveness and generalizability of PASTAT.

</details>


### [59] [ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation](https://arxiv.org/abs/2511.14259)
*Zitong Xu,Huiyu Duan,Xiaoyu Wang,Zhaolin Cai,Kaiwei Zhang,Qiang Hu,Jing Liu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出ManipBench大规模基准和ManipShield统一模型，解决现有图像篡改检测数据集多样性不足、模型覆盖有限及可解释性差的问题。ManipBench包含45万+张由25种先进编辑模型生成的图像，涵盖12类篡改，其中10万张配有边界框、判断线索和文本解释；ManipShield基于多模态大语言模型，结合对比LoRA微调与任务特定解码器，在检测、定位和解释方面均达到领先性能，并具备强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有图像篡改检测与定位（IMDL）基准存在内容多样性不足、生成模型覆盖范围窄、可解释性差等问题，限制了检测方法的泛化性和可解释性。随着生成模型快速发展，传统深度伪造检测已无法应对新型高真实感图像编辑挑战。

Method: 构建ManipBench大规模基准，涵盖25种前沿图像编辑模型生成的45万+张图像，12类篡改，其中10万张含细粒度标注（边界框、判断线索、文本解释）；设计ManipShield模型，基于多模态大语言模型（MLLM），采用对比LoRA微调与任务专用解码器，实现统一的篡改检测、定位与解释。

Result: ManipShield在ManipBench及多个公开数据集上均取得当前最佳性能，对未见过的篡改模型展现出强大泛化能力；所提出的ManipBench与ManipShield将在论文发表后公开。

Conclusion: ManipBench为图像篡改检测提供了高质量、多样化、可解释的大规模基准，ManipShield实现了检测、定位与解释的统一建模，显著提升了在复杂生成图像下的检测性能与泛化能力。

Abstract: With the rapid advancement of generative models, powerful image editing methods now enable diverse and highly realistic image manipulations that far surpass traditional deepfake techniques, posing new challenges for manipulation detection. Existing image manipulation detection and localization (IMDL) benchmarks suffer from limited content diversity, narrow generative-model coverage, and insufficient interpretability, which hinders the generalization and explanation capabilities of current manipulation detection methods. To address these limitations, we introduce \textbf{ManipBench}, a large-scale benchmark for image manipulation detection and localization focusing on AI-edited images. ManipBench contains over 450K manipulated images produced by 25 state-of-the-art image editing models across 12 manipulation categories, among which 100K images are further annotated with bounding boxes, judgment cues, and textual explanations to support interpretable detection. Building upon ManipBench, we propose \textbf{ManipShield}, an all-in-one model based on a Multimodal Large Language Model (MLLM) that leverages contrastive LoRA fine-tuning and task-specific decoders to achieve unified image manipulation detection, localization, and explanation. Extensive experiments on ManipBench and several public datasets demonstrate that ManipShield achieves state-of-the-art performance and exhibits strong generality to unseen manipulation models. Both ManipBench and ManipShield will be released upon publication.

</details>


### [60] [Gaussian Splatting-based Low-Rank Tensor Representation for Multi-Dimensional Image Recovery](https://arxiv.org/abs/2511.14270)
*Yiming Zeng,Xi-Le Zhao,Wei-Hao Wu,Teng-Yu Ji,Chao Wang*

Main category: cs.CV

TL;DR: 提出GSLR框架，利用2D和1D高斯点阵表示多维图像的低秩张量与变换矩阵，有效提升局部高频信息捕捉能力，在多维图像恢复任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有t-SVD方法在低秩张量近似和固定基函数变换矩阵方面存在不足，难以准确捕捉局部高频信息。

Method: 采用定制化的2D高斯点阵生成潜在张量，1D高斯点阵生成变换矩阵，构建连续且紧凑的多维图像表示框架。

Result: 在多维图像恢复实验中，GSLR显著优于现有先进方法，尤其在局部高频信息重建方面表现突出。

Conclusion: GSLR通过高斯点阵实现对多维图像的高效连续表示，具备强大的局部高频信息表达能力，为多维图像处理提供了新思路。

Abstract: Tensor singular value decomposition (t-SVD) is a promising tool for multi-dimensional image representation, which decomposes a multi-dimensional image into a latent tensor and an accompanying transform matrix. However, two critical limitations of t-SVD methods persist: (1) the approximation of the latent tensor (e.g., tensor factorizations) is coarse and fails to accurately capture spatial local high-frequency information; (2) The transform matrix is composed of fixed basis atoms (e.g., complex exponential atoms in DFT and cosine atoms in DCT) and cannot precisely capture local high-frequency information along the mode-3 fibers. To address these two limitations, we propose a Gaussian Splatting-based Low-rank tensor Representation (GSLR) framework, which compactly and continuously represents multi-dimensional images. Specifically, we leverage tailored 2D Gaussian splatting and 1D Gaussian splatting to generate the latent tensor and transform matrix, respectively. The 2D and 1D Gaussian splatting are indispensable and complementary under this representation framework, which enjoys a powerful representation capability, especially for local high-frequency information. To evaluate the representation ability of the proposed GSLR, we develop an unsupervised GSLR-based multi-dimensional image recovery model. Extensive experiments on multi-dimensional image recovery demonstrate that GSLR consistently outperforms state-of-the-art methods, particularly in capturing local high-frequency information.

</details>


### [61] [Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation](https://arxiv.org/abs/2511.14271)
*Weimin Bai,Yubo Li,Weijian Luo,Zeqiang Lai,Yequan Wang,Wenzheng Chen,He Sun*

Main category: cs.CV

TL;DR: VLM3D提出一种通用框架，利用大视觉语言模型（VLM）作为可微分的语义与空间批评者，通过双查询批评信号（基于是/否对数似然）同时评估语义保真度和几何一致性。该方法在优化型和前馈型3D生成流程中均表现出色，显著提升生成质量并纠正严重空间错误，为多种3D生成管道注入丰富的语言-空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D生成模型在语义对齐和3D空间理解方面存在不足，导致细节丢失和几何不一致等问题，亟需一种能同时捕捉语义与空间信息的通用指导机制。

Method: 提出VLM3D框架，利用大视觉语言模型（VLM）生成双查询批评信号（基于是/否对数似然），用于评估语义与几何质量；该信号可作为优化型管道中的奖励目标或前馈型管道中的测试时引导模块，动态修正生成过程中的错误。

Result: 在标准基准上，VLM3D在优化型和前馈型生成管道中均显著优于现有方法，有效提升语义对齐精度与几何一致性，成功纠正复杂部件装配与空间关系错误。

Conclusion: VLM3D提供了一种原理清晰、通用性强的方法，将大视觉语言模型的语言-空间理解能力无缝集成到多样化的3D生成流程中，推动了文本到3D生成技术的发展。

Abstract: Text-to-3D generation has advanced rapidly, yet state-of-the-art models, encompassing both optimization-based and feed-forward architectures, still face two fundamental limitations. First, they struggle with coarse semantic alignment, often failing to capture fine-grained prompt details. Second, they lack robust 3D spatial understanding, leading to geometric inconsistencies and catastrophic failures in part assembly and spatial relationships. To address these challenges, we propose VLM3D, a general framework that repurposes large vision-language models (VLMs) as powerful, differentiable semantic and spatial critics. Our core contribution is a dual-query critic signal derived from the VLM's Yes or No log-odds, which assesses both semantic fidelity and geometric coherence. We demonstrate the generality of this guidance signal across two distinct paradigms: (1) As a reward objective for optimization-based pipelines, VLM3D significantly outperforms existing methods on standard benchmarks. (2) As a test-time guidance module for feed-forward pipelines, it actively steers the iterative sampling process of SOTA native 3D models to correct severe spatial errors. VLM3D establishes a principled and generalizable path to inject the VLM's rich, language-grounded understanding of both semantics and space into diverse 3D generative pipelines.

</details>


### [62] [NeuralBoneReg: A Novel Self-Supervised Method for Robust and Accurate Multi-Modal Bone Surface Registration](https://arxiv.org/abs/2511.14286)
*Luohong Wu,Matthias Seibold,Nicola A. Cavalcanti,Yunke Ao,Roman Flepp,Aidana Massalimova,Lilian Calvet,Philipp Fürnstahl*

Main category: cs.CV

TL;DR: NeuralBoneReg is a self-supervised, surface-based framework for modality-agnostic bone surface registration in computer- and robot-assisted orthopedic surgery. It uses an implicit neural unsigned distance field (UDF) to model preoperative bone structures and an MLP-based registration module for global initialization and local refinement, enabling accurate alignment between preoperative and intraoperative 3D point clouds without requiring labeled training data. Evaluated on three multi-modal datasets—including two public ones and a newly introduced cadaveric CT-ultrasound dataset—NeuralBoneReg achieves state-of-the-art performance with mean RRE/RTE of 1.68°/1.86 mm (UltraBones100k), 1.88°/1.89 mm (UltraBones-Hip), and 3.79°/2.45 mm (SpineDepth), demonstrating strong generalizability across anatomies and imaging modalities.


<details>
  <summary>Details</summary>
Motivation: Cross-registration between preoperative and intraoperative imaging data is critical in computer- and robot-assisted orthopedic surgery (CAOS), but challenging due to substantial modality heterogeneity across imaging techniques like CT, ultrasound, and RGB-D. Existing supervised methods rely on inter-subject training data, which limits generalization and scalability. There is a clinical need for robust, automatic, and modality-agnostic bone surface registration that does not depend on labeled data or specific modality pairs.

Method: NeuralBoneReg employs a self-supervised, surface-based approach using 3D point clouds as a modality-agnostic representation. It consists of two modules: (1) an implicit neural unsigned distance field (UDF) that learns the preoperative bone geometry from CT scans; and (2) an MLP-based registration module that generates transformation hypotheses to align intraoperative point clouds (from ultrasound or RGB-D) with the neural UDF through global initialization and local refinement. The entire framework operates without supervision, leveraging geometric consistency and reconstruction loss for training.

Result: NeuralBoneReg outperforms baseline methods on all evaluated datasets. On UltraBones100k (CT-US), it achieved 1.68°/1.86 mm mean RRE/RTE; on UltraBones-Hip (CT-US, cadaveric), 1.88°/1.89 mm; and on SpineDepth (CT-RGB-D), 3.79°/2.45 mm. These results demonstrate high accuracy and strong generalizability across different anatomical regions and imaging modalities, even without access to labeled training data.

Conclusion: NeuralBoneReg provides a robust, self-supervised, and modality-agnostic solution for cross-modal bone surface registration in CAOS. Its ability to achieve state-of-the-art performance without relying on inter-subject training data makes it highly practical for real-world surgical applications, paving the way for more reliable and automated image-guided interventions.

Abstract: In computer- and robot-assisted orthopedic surgery (CAOS), patient-specific surgical plans derived from preoperative imaging define target locations and implant trajectories. During surgery, these plans must be accurately transferred, relying on precise cross-registration between preoperative and intraoperative data. However, substantial modality heterogeneity across imaging modalities makes this registration challenging and error-prone. Robust, automatic, and modality-agnostic bone surface registration is therefore clinically important. We propose NeuralBoneReg, a self-supervised, surface-based framework that registers bone surfaces using 3D point clouds as a modality-agnostic representation. NeuralBoneReg includes two modules: an implicit neural unsigned distance field (UDF) that learns the preoperative bone model, and an MLP-based registration module that performs global initialization and local refinement by generating transformation hypotheses to align the intraoperative point cloud with the neural UDF. Unlike SOTA supervised methods, NeuralBoneReg operates in a self-supervised manner, without requiring inter-subject training data. We evaluated NeuralBoneReg against baseline methods on two publicly available multi-modal datasets: a CT-ultrasound dataset of the fibula and tibia (UltraBones100k) and a CT-RGB-D dataset of spinal vertebrae (SpineDepth). The evaluation also includes a newly introduced CT--ultrasound dataset of cadaveric subjects containing femur and pelvis (UltraBones-Hip), which will be made publicly available. NeuralBoneReg matches or surpasses existing methods across all datasets, achieving mean RRE/RTE of 1.68°/1.86 mm on UltraBones100k, 1.88°/1.89 mm on UltraBones-Hip, and 3.79°/2.45 mm on SpineDepth. These results demonstrate strong generalizability across anatomies and modalities, providing robust and accurate cross-modal alignment for CAOS.

</details>


### [63] [GEN3D: Generating Domain-Free 3D Scenes from a Single Image](https://arxiv.org/abs/2511.14291)
*Yuxin Zhang,Ziyu Lu,Hongbo Duan,Keyu Fan,Pengting Luo,Peiyu Zhuang,Mengyu Yang,Houde Liu*

Main category: cs.CV

TL;DR: Gen3d提出一种从单张图像生成高质量、大范围且通用的3D场景的新方法，通过提升RGBD图像生成初始点云，并优化高斯点阵表示来完成3D场景构建，在多个数据集上表现出优异的泛化能力和生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有神经3D重建方法依赖密集多视角采集，限制了其广泛应用；同时，为推进具身智能和世界模型的发展，需要多样且高质量的3D场景用于学习与评估。

Method: 首先通过提升RGBD图像生成初始点云，随后维护并扩展世界模型，最终通过优化高斯点阵表示完成3D场景生成。

Result: 在多个数据集上的实验表明，该方法具有强大的泛化能力，在生成世界模型和合成高保真、一致的新视角方面表现优异。

Conclusion: Gen3d能够高效生成高质量、广范围且通用的3D场景，为具身AI和世界模型提供了有力支持。

Abstract: Despite recent advancements in neural 3D reconstruction, the dependence on dense multi-view captures restricts their broader applicability. Additionally, 3D scene generation is vital for advancing embodied AI and world models, which depend on diverse, high-quality scenes for learning and evaluation. In this work, we propose Gen3d, a novel method for generation of high-quality, wide-scope, and generic 3D scenes from a single image. After the initial point cloud is created by lifting the RGBD image, Gen3d maintains and expands its world model. The 3D scene is finalized through optimizing a Gaussian splatting representation. Extensive experiments on diverse datasets demonstrate the strong generalization capability and superior performance of our method in generating a world model and Synthesizing high-fidelity and consistent novel views.

</details>


### [64] [SAM-Fed: SAM-Guided Federated Semi-Supervised Learning for Medical Image Segmentation](https://arxiv.org/abs/2511.14302)
*Sahar Nasirihaghighi,Negin Ghamsarian,Yiping Li,Marcel Breeuwer,Raphael Sznitman,Klaus Schoeffmann*

Main category: cs.CV

TL;DR: SAM-Fed 是一种联邦半监督学习框架，利用高容量分割基础模型指导轻量级客户端训练，通过双知识蒸馏和自适应一致性机制提升像素级监督质量，在皮肤病变和息肉分割任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分割依赖专家标注，但数据隐私和标注成本限制了标注数据的可用性；联邦半监督学习虽提供解决方案，但本地模型性能受限于设备计算资源，导致伪标签可靠性差，且大模型难以在客户端部署。

Method: 提出 SAM-Fed 框架，采用高容量基础模型引导轻量客户端，结合双知识蒸馏与自适应一致性机制，优化伪标签质量并提升模型稳定性。

Result: 在皮肤病变和息肉分割任务中，无论同质还是异构设置下，SAM-Fed 均显著优于当前最先进的联邦半监督学习方法。

Conclusion: SAM-Fed 有效解决了联邦半监督学习中伪标签质量与客户端模型轻量化之间的矛盾，为医疗图像分割提供了高效、可靠的分布式学习方案。

Abstract: Medical image segmentation is clinically important, yet data privacy and the cost of expert annotation limit the availability of labeled data. Federated semi-supervised learning (FSSL) offers a solution but faces two challenges: pseudo-label reliability depends on the strength of local models, and client devices often require compact or heterogeneous architectures due to limited computational resources. These constraints reduce the quality and stability of pseudo-labels, while large models, though more accurate, cannot be trained or used for routine inference on client devices. We propose SAM-Fed, a federated semi-supervised framework that leverages a high-capacity segmentation foundation model to guide lightweight clients during training. SAM-Fed combines dual knowledge distillation with an adaptive agreement mechanism to refine pixel-level supervision. Experiments on skin lesion and polyp segmentation across homogeneous and heterogeneous settings show that SAM-Fed consistently outperforms state-of-the-art FSSL methods.

</details>


### [65] [Iterative Diffusion-Refined Neural Attenuation Fields for Multi-Source Stationary CT Reconstruction: NAF Meets Diffusion Model](https://arxiv.org/abs/2511.14310)
*Jiancheng Fang,Shaoyu Wang,Junlin Wang,Weiwen Wu,Yikun Zhang,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出Diff-NAF框架，结合神经衰减场与双分支条件扩散模型，通过迭代方式在超稀疏视角下提升多源静态CT的重建质量。利用角度先验引导的投影合成和扩散驱动的投影精炼模块，逐步优化投影数据并生成伪标签以改进重建结果。实验表明其在模拟和真实数据上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法在超稀疏视角条件下因插值不准导致重建质量下降，亟需一种能有效应对极端采样限制的新方法。

Method: 采用神经衰减场表示初始模型，通过角度先验引导的投影合成生成新投影，并用扩散驱动的重用投影精炼模块进行优化；将精炼后的投影作为伪标签加入训练集，实现迭代改进。

Result: 在多个模拟3D CT体积和真实投影数据上，Diff-NAF在超稀疏视角条件下均取得最佳重建性能，显著提升图像质量和投影完整性。

Conclusion: Diff-NAF是一种高效且鲁棒的迭代重建框架，适用于超稀疏视角下的多源静态CT，可实现高质量、快速的图像重建，具有良好的临床与工业应用前景。

Abstract: Multi-source stationary computed tomography (CT) has recently attracted attention for its ability to achieve rapid image reconstruction, making it suitable for time-sensitive clinical and industrial applications. However, practical systems are often constrained by ultra-sparse-view sampling, which significantly degrades reconstruction quality. Traditional methods struggle under ultra-sparse-view settings, where interpolation becomes inaccurate and the resulting reconstructions are unsatisfactory. To address this challenge, this study proposes Diffusion-Refined Neural Attenuation Fields (Diff-NAF), an iterative framework tailored for multi-source stationary CT under ultra-sparse-view conditions. Diff-NAF combines a Neural Attenuation Field representation with a dual-branch conditional diffusion model. The process begins by training an initial NAF using ultra-sparse-view projections. New projections are then generated through an Angle-Prior Guided Projection Synthesis strategy that exploits inter view priors, and are subsequently refined by a Diffusion-driven Reuse Projection Refinement Module. The refined projections are incorporated as pseudo-labels into the training set for the next iteration. Through iterative refinement, Diff-NAF progressively enhances projection completeness and reconstruction fidelity under ultra-sparse-view conditions, ultimately yielding high-quality CT reconstructions. Experimental results on multiple simulated 3D CT volumes and real projection data demonstrate that Diff-NAF achieves the best performance under ultra-sparse-view conditions.

</details>


### [66] [Dental3R: Geometry-Aware Pairing for Intraoral 3D Reconstruction from Sparse-View Photographs](https://arxiv.org/abs/2511.14315)
*Yiyi Miao,Taoyu Wu,Tong Chen,Ji Jiang,Zhe Tang,Zhengyong Jiang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: Dental3R提出了一种无姿态、图引导的稀疏口内照片高保真重建方法，通过几何感知配对策略（GAPS）选择高质量图像对，提升几何初始化稳定性并降低内存开销；结合小波正则化的目标函数，利用离散小波变换保持牙釉质边界和邻接边缘等精细特征，同时抑制高频伪影。在950个临床案例和195个视频测试集上验证，显著优于现有方法，适用于远程正畸中的稀疏非摆姿图像重建。


<details>
  <summary>Details</summary>
Motivation: 传统口内扫描难以支持远程正畸，而基于智能手机的稀疏图像重建面临大视点基线、光照不一致和镜面反射等问题，导致3DGS在姿态与几何联合估计中不稳定；且稀疏光度监督常引发频率偏差，造成重建结果过度平滑，丢失关键诊断细节。

Method: 提出Dental3R，包含两个核心模块：(1) 几何感知配对策略（GAPS），用于智能筛选高价值图像对以增强对应匹配和几何初始化稳定性；(2) 基于小波正则化的3DGS训练目标，通过离散小波变换强制带限保真度，保留细粒度解剖结构。

Result: 在大规模临床数据集（950例）和视频测试集（195例）上验证，Dental3R能有效处理稀疏、非摆姿输入，在新视角合成质量上显著优于当前最优方法，尤其在牙合关系可视化方面表现突出。

Conclusion: Dental3R实现了无需姿态先验、鲁棒性强且高保真的口内三维重建，为远程数字正畸提供了实用可行的技术路径。

Abstract: Intraoral 3D reconstruction is fundamental to digital orthodontics, yet conventional methods like intraoral scanning are inaccessible for remote tele-orthodontics, which typically relies on sparse smartphone imagery. While 3D Gaussian Splatting (3DGS) shows promise for novel view synthesis, its application to the standard clinical triad of unposed anterior and bilateral buccal photographs is challenging. The large view baselines, inconsistent illumination, and specular surfaces common in intraoral settings can destabilize simultaneous pose and geometry estimation. Furthermore, sparse-view photometric supervision often induces a frequency bias, leading to over-smoothed reconstructions that lose critical diagnostic details. To address these limitations, we propose \textbf{Dental3R}, a pose-free, graph-guided pipeline for robust, high-fidelity reconstruction from sparse intraoral photographs. Our method first constructs a Geometry-Aware Pairing Strategy (GAPS) to intelligently select a compact subgraph of high-value image pairs. The GAPS focuses on correspondence matching, thereby improving the stability of the geometry initialization and reducing memory usage. Building on the recovered poses and point cloud, we train the 3DGS model with a wavelet-regularized objective. By enforcing band-limited fidelity using a discrete wavelet transform, our approach preserves fine enamel boundaries and interproximal edges while suppressing high-frequency artifacts. We validate our approach on a large-scale dataset of 950 clinical cases and an additional video-based test set of 195 cases. Experimental results demonstrate that Dental3R effectively handles sparse, unposed inputs and achieves superior novel view synthesis quality for dental occlusion visualization, outperforming state-of-the-art methods.

</details>


### [67] [ArchMap: Arch-Flattening and Knowledge-Guided Vision Language Model for Tooth Counting and Structured Dental Understanding](https://arxiv.org/abs/2511.14336)
*Bohan Zhang,Yiyi Miao,Taoyu Wu,Tong Chen,Ji Jiang,Zhuoxiao Li,Zhe Tang,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: 提出ArchMap框架，通过几何感知的牙弓展平模块和牙科知识库（DKB）实现无需训练、基于知识引导的3D口内扫描结构化理解，显著提升在真实临床条件下的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖特定模态训练、大规模标注数据和受控扫描环境，难以跨设备泛化；且原始口内网格存在牙弓姿态差异、几何不完整及缺乏纹理信息，导致统一语义解析困难。

Method: 引入几何感知的牙弓展平模块将原始3D网格标准化为空间对齐、连续性保持的多视角投影；构建包含牙齿层级本体、牙列阶段策略和临床语义的牙科知识库（DKB），约束符号推理空间。

Result: 在1060例正/术后正畸病例上验证，相比监督方法和提示式视觉语言模型基线，ArchMap在牙齿计数、解剖分割、牙列阶段分类及临床问题识别（如拥挤、缺牙、假牙、龋齿）中表现更优，具备更低语义漂移和更强稀疏或伪影条件下的稳定性。

Conclusion: ArchMap作为完全无训练系统，证明结合几何归一化与本体引导的多模态推理，是现代数字正畸中3D口内扫描结构化分析的实用且可扩展解决方案。

Abstract: A structured understanding of intraoral 3D scans is essential for digital orthodontics. However, existing deep-learning approaches rely heavily on modality-specific training, large annotated datasets, and controlled scanning conditions, which limit generalization across devices and hinder deployment in real clinical workflows. Moreover, raw intraoral meshes exhibit substantial variation in arch pose, incomplete geometry caused by occlusion or tooth contact, and a lack of texture cues, making unified semantic interpretation highly challenging. To address these limitations, we propose ArchMap, a training-free and knowledge-guided framework for robust structured dental understanding. ArchMap first introduces a geometry-aware arch-flattening module that standardizes raw 3D meshes into spatially aligned, continuity-preserving multi-view projections. We then construct a Dental Knowledge Base (DKB) encoding hierarchical tooth ontology, dentition-stage policies, and clinical semantics to constrain the symbolic reasoning space. We validate ArchMap on 1060 pre-/post-orthodontic cases, demonstrating robust performance in tooth counting, anatomical partitioning, dentition-stage classification, and the identification of clinical conditions such as crowding, missing teeth, prosthetics, and caries. Compared with supervised pipelines and prompted VLM baselines, ArchMap achieves higher accuracy, reduced semantic drift, and superior stability under sparse or artifact-prone conditions. As a fully training-free system, ArchMap demonstrates that combining geometric normalization with ontology-guided multimodal reasoning offers a practical and scalable solution for the structured analysis of 3D intraoral scans in modern digital orthodontics.

</details>


### [68] [Silhouette-to-Contour Registration: Aligning Intraoral Scan Models with Cephalometric Radiographs](https://arxiv.org/abs/2511.14343)
*Yiyi Miao,Taoyu Wu,Ji Jiang,Tong Chen,Zhe Tang,Zhengyong Jiang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: 提出DentalSCR框架，通过构建统一的跨牙弓解剖坐标系（UMDA）和基于表面的数字重建射线图（DRR）生成，实现对临床真实条件下的口内扫描与侧位头颅片的高精度、可解释性轮廓对齐。采用分层粗到精的对称双向切比雪夫距离优化，有效处理投影放大、几何失真等问题，显著降低后牙区标志点误差，提升下颌一致性，并在曲线层面实现低切比雪夫与受控豪斯多夫距离，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于强度的配准方法在临床实际中因头颅片存在投影放大、几何失真、牙冠对比度低及成像差异等问题，导致外观相似性度量不稳定，常出现收敛失败或解剖上不合理的对齐结果，亟需更鲁棒且可解释的3D-2D配准方案。

Method: 提出DentalSCR框架：首先构建U-Midline Dental Axis (UMDA)建立统一的跨牙弓解剖坐标系以稳定初始化并标准化投影几何；利用基于表面的数字重建射线图（DRR）生成方式，结合冠状轴视角与高斯点云渲染，保留源-物-探测器放大关系并强调外部轮廓；注册过程采用分层粗到精的2D相似变换优化，以对称双向切比雪夫距离为损失函数，实现大范围捕获与亚像素级轮廓匹配。

Result: 在34例专家标注的临床数据上评估，DentalSCR显著降低后牙区标志点误差，下颌分布更紧凑，曲线层面的切比雪夫距离和豪斯多夫距离均较低且可控，整体配准精度与稳定性显著优于传统基线方法，具备高保真度与临床可检查性。

Conclusion: DentalSCR能够有效应对真实临床环境中复杂多变的头颅片特性，实现可靠、精准且可解释的3D-2D对齐，为正畸诊断中的影像融合提供了强有力的技术支持。

Abstract: Reliable 3D-2D alignment between intraoral scan (IOS) models and lateral cephalometric radiographs is critical for orthodontic diagnosis, yet conventional intensity-driven registration methods struggle under real clinical conditions, where cephalograms exhibit projective magnification, geometric distortion, low-contrast dental crowns, and acquisition-dependent variation. These factors hinder the stability of appearance-based similarity metrics and often lead to convergence failures or anatomically implausible alignments. To address these limitations, we propose DentalSCR, a pose-stable, contour-guided framework for accurate and interpretable silhouette-to-contour registration. Our method first constructs a U-Midline Dental Axis (UMDA) to establish a unified cross-arch anatomical coordinate system, thereby stabilizing initialization and standardizing projection geometry across cases. Using this reference frame, we generate radiograph-like projections via a surface-based DRR formulation with coronal-axis perspective and Gaussian splatting, which preserves clinical source-object-detector magnification and emphasizes external silhouettes. Registration is then formulated as a 2D similarity transform optimized with a symmetric bidirectional Chamfer distance under a hierarchical coarse-to-fine schedule, enabling both large capture range and subpixel-level contour agreement. We evaluate DentalSCR on 34 expert-annotated clinical cases. Experimental results demonstrate substantial reductions in landmark error-particularly at posterior teeth-tighter dispersion on the lower jaw, and low Chamfer and controlled Hausdorff distances at the curve level. These findings indicate that DentalSCR robustly handles real-world cephalograms and delivers high-fidelity, clinically inspectable 3D--2D alignment, outperforming conventional baselines.

</details>


### [69] [ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries](https://arxiv.org/abs/2511.14349)
*Junfu Pu,Teng Wang,Yixiao Ge,Yuying Ge,Chen Li,Ying Shan*

Main category: cs.CV

TL;DR: ARC-Chapter is a large-scale video chaptering model trained on over a million long video chapters with bilingual, temporally grounded, and hierarchical annotations. It introduces a new dataset and evaluation metric (GRACE) that improve performance and generalization on long-form videos, achieving state-of-the-art results with significant gains in F1 (+14.0%) and SODA (+11.3%) scores, and strong transferability to tasks like dense video captioning.


<details>
  <summary>Details</summary>
Motivation: Existing video chaptering methods are limited by small-scale, coarse annotations, which hinder their ability to capture nuanced transitions in hour-long videos such as lectures and documentaries. There is a need for larger, more detailed, and multilingual training data to improve generalization and performance.

Method: The authors curated a bilingual (English-Chinese) chapter dataset using a structured pipeline integrating ASR transcripts, scene texts, and visual captions into multi-level annotations. They trained ARC-Chapter on this large-scale dataset and introduced GRACE, a new evaluation metric that accounts for many-to-one overlaps and semantic similarity.

Result: ARC-Chapter significantly outperforms previous models, achieving 14.0% higher F1 score and 11.3% higher SODA score. It also demonstrates strong transferability, improving performance on downstream tasks like dense video captioning on YouCook2.

Conclusion: ARC-Chapter establishes a new benchmark for video chaptering by leveraging large-scale, richly annotated data and a novel evaluation framework, enabling better understanding and structuring of long-form video content.

Abstract: The proliferation of hour-long videos (e.g., lectures, podcasts, documentaries) has intensified demand for efficient content structuring. However, existing approaches are constrained by small-scale training with annotations that are typical short and coarse, restricting generalization to nuanced transitions in long videos. We introduce ARC-Chapter, the first large-scale video chaptering model trained on over million-level long video chapters, featuring bilingual, temporally grounded, and hierarchical chapter annotations. To achieve this goal, we curated a bilingual English-Chinese chapter dataset via a structured pipeline that unifies ASR transcripts, scene texts, visual captions into multi-level annotations, from short title to long summaries. We demonstrate clear performance improvements with data scaling, both in data volume and label intensity. Moreover, we design a new evaluation metric termed GRACE, which incorporates many-to-one segment overlaps and semantic similarity, better reflecting real-world chaptering flexibility. Extensive experiments demonstrate that ARC-Chapter establishes a new state-of-the-art by a significant margin, outperforming the previous best by 14.0% in F1 score and 11.3% in SODA score. Moreover, ARC-Chapter shows excellent transferability, improving the state-of-the-art on downstream tasks like dense video captioning on YouCook2.

</details>


### [70] [IBGS: Image-Based Gaussian Splatting](https://arxiv.org/abs/2511.14357)
*Hoang Chuong Nguyen,Wei Mao,Jose M. Alvarez,Miaomiao Liu*

Main category: cs.CV

TL;DR: 提出Image-Based Gaussian Splatting，利用高分辨率源图像实现细节丰富、视角依赖颜色的高效建模，通过像素级残差学习提升渲染质量，且不增加存储开销。


<details>
  <summary>Details</summary>
Motivation: 3DGS使用低阶球谐函数难以捕捉空间变化的颜色和视点依赖效果（如镜面高光），现有方法或使用全局纹理图（复杂场景表现差）或每高斯纹理图（存储开销大），因此需要一种高效且高质量的替代方案。

Method: 将每个像素颜色建模为标准3DGS渲染的基色与从邻近训练图像中学习到的残差之和，利用高分辨率源图像增强高频细节和视点相关性，实现精确表面对齐。

Result: 在标准NVS基准测试中，该方法显著优于现有高斯溅射方法，在保持相同存储开销的前提下提升了渲染质量。

Conclusion: Image-Based Gaussian Splatting通过结合源图像信息有效解决了3DGS在细节和视点依赖建模上的局限，实现了高质量、高效率的新型视图合成。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a fast, high-quality method for novel view synthesis (NVS). However, its use of low-degree spherical harmonics limits its ability to capture spatially varying color and view-dependent effects such as specular highlights. Existing works augment Gaussians with either a global texture map, which struggles with complex scenes, or per-Gaussian texture maps, which introduces high storage overhead. We propose Image-Based Gaussian Splatting, an efficient alternative that leverages high-resolution source images for fine details and view-specific color modeling. Specifically, we model each pixel color as a combination of a base color from standard 3DGS rendering and a learned residual inferred from neighboring training images. This promotes accurate surface alignment and enables rendering images of high-frequency details and accurate view-dependent effects. Experiments on standard NVS benchmarks show that our method significantly outperforms prior Gaussian Splatting approaches in rendering quality, without increasing the storage footprint.

</details>


### [71] [Clinically-Validated Innovative Mobile Application for Assessing Blinking and Eyelid Movements](https://arxiv.org/abs/2511.14361)
*Gustavo Adolpho Bonesso,Carlos Marcelo Gurjão de Godoy,Tammy Hentona Osaki,Midori Hentona Osaki,Bárbara Moreira Ribeiro Trindade dos Santos,Regina Célia Coelho*

Main category: cs.CV

TL;DR: Bapp是一款基于Flutter框架和Google ML Kit开发的移动应用，用于实时、本地化分析眨眼动作。通过45个患者视频的临床验证，其在精确度（98.4%）、召回率（96.9%）和总体准确率（98.3%）方面表现优异，证实其作为便携、客观、可访问的睑缘运动监测工具的可靠性，为眼科健康监测与术后评估提供了有力支持。


<details>
  <summary>Details</summary>
Motivation: 现有眨眼动作的客观评估工具存在复杂、成本高及临床适用性差的问题，亟需一种简便、精准且易于推广的解决方案来实现对睑缘运动的实时监测。

Method: 采用Flutter框架开发移动端应用Bapp，集成Google ML Kit实现设备端实时分析；使用来自EPM-UNIFESP的45段真实患者视频作为数据集，由眼科专家手动标注作为金标准进行验证。

Result: Bapp在测试中达到98.4%的精度、96.9%的召回率和98.3%的整体准确率，表现出极高的可靠性。

Conclusion: Bapp是一种便携、易用且可靠的眨眼行为分析工具，能够有效替代传统人工计数方法，适用于日常眼表健康监测与术后评估，具有良好的临床应用前景。

Abstract: Blinking is a vital physiological process that protects and maintains the health of the ocular surface. Objective assessment of eyelid movements remains challenging due to the complexity, cost, and limited clinical applicability of existing tools. This study presents the clinical validation of Bapp (Blink Application), a mobile application developed using the Flutter framework and integrated with Google ML Kit for on-device, real-time analysis of eyelid movements. The validation occurred using 45 videos from real patients, whose blinks were manually annotated by ophthalmology specialists from the Paulista School of Medicine of the Federal University of Sao Paulo (EPM-UNIFESP) to serve as the ground truth. Bapp's performance was evaluated using standard metrics, including Precision, Recall, and F1-Score, with results demonstrating 98.4% precision, 96.9% recall, and an overall accuracy of 98.3%. These outcomes confirm the reliability of Bapp as a portable, accessible, and objective tool for monitoring both normal and abnormal eyelid movements. The application offers a promising alternative to traditional manual blink counting, supporting continuous ocular health monitoring and postoperative evaluation in clinical environments.

</details>


### [72] [A Quantitative Method for Shoulder Presentation Evaluation in Biometric Identity Documents](https://arxiv.org/abs/2511.14376)
*Alfonso Pedro Ridao*

Main category: cs.CV

TL;DR: 本文提出了一种肩部呈现评估（SPE）算法，用于量化生物特征身份文件中肩部的偏航和滚动角度，仅需常见姿态估计框架提供的两个肩部关键点的3D坐标。在121张人像图像的数据集上评估表明，SPE得分与人工标注标签具有较强的皮尔逊相关性（r≈0.80），且通过改进的错误-剔除分析验证了其在识别不合规样本方面的有效性。该算法为注册系统中的自动化合规检查提供了一种轻量级可行工具。


<details>
  <summary>Details</summary>
Motivation: 国际生物特征身份文件标准要求严格的姿态规范，包括肩部的正方形呈现，但现有自动化质量评估方法缺乏对此特定属性的定量评估手段，因此亟需一种可量化肩部姿态的方法以实现合规性检查。

Method: 利用常见姿态估计框架提供的两个肩部关键点的3D坐标，计算肩部的偏航角和滚动角，构建肩部呈现评估（SPE）算法。

Result: SPE得分与人工标注标签间呈现强相关性（r≈0.80），且在错误-剔除分析中表现出良好的过滤性能，能够有效识别不合规样本。

Conclusion: 所提出的SPE算法是一种轻量级、高效的自动化工具，适用于身份文件注册系统中的姿态合规性检测，填补了现有技术在肩部姿态量化评估方面的空白。

Abstract: International standards for biometric identity documents mandate strict compliance with pose requirements, including the square presentation of a subject's shoulders. However, the literature on automated quality assessment offers few quantitative methods for evaluating this specific attribute. This paper proposes a Shoulder Presentation Evaluation (SPE) algorithm to address this gap. The method quantifies shoulder yaw and roll using only the 3D coordinates of two shoulder landmarks provided by common pose estimation frameworks. The algorithm was evaluated on a dataset of 121 portrait images. The resulting SPE scores demonstrated a strong Pearson correlation (r approx. 0.80) with human-assigned labels. An analysis of the metric's filtering performance, using an adapted Error-versus-Discard methodology, confirmed its utility in identifying non-compliant samples. The proposed algorithm is a viable lightweight tool for automated compliance checking in enrolment systems.

</details>


### [73] [Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving](https://arxiv.org/abs/2511.14386)
*Kangqiao Zhao,Shuo Huai,Xurui Song,Jun Luo*

Main category: cs.CV

TL;DR: This paper introduces a novel 3D physical adversarial attack targeting stereo depth estimation in autonomous driving, using global camouflage textures and a specialized rendering module to ensure realism and effectiveness across viewpoints. A fine-grained merging technique enhances stealth by seamlessly blending the attack into the environment, significantly improving attack success rates and evasion capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing adversarial attacks on autonomous driving perception primarily focus on 2D patches and monocular models, leaving stereo-based binocular depth estimation vulnerable. Physical Adversarial Examples (PAEs) that are effective in real-world scenarios remain underexplored.

Method: Proposes a texture-enabled 3D physical adversarial attack for stereo matching models, using a 3D PAE with global camouflage texture to maintain visual consistency across viewpoints. Introduces a 3D stereo matching rendering module to align the PAE with real-world positions and headings. Implements a novel merging attack with fine-grained optimization for seamless integration into the environment.

Result: The proposed PAEs successfully deceive stereo matching models, generating erroneous depth information. The attack demonstrates enhanced stealth and lethality compared to existing hiding methods, with strong effectiveness across diverse viewing angles and real-world conditions.

Conclusion: This work presents the first effective 3D texture-enabled physical adversarial attack on stereo-based depth estimation in autonomous driving, demonstrating significant vulnerability of current systems and highlighting the need for robust defenses.

Abstract: Though deep neural models adopted to realize the perception of autonomous driving have proven vulnerable to adversarial examples, known attacks often leverage 2D patches and target mostly monocular perception. Therefore, the effectiveness of Physical Adversarial Examples (PAEs) on stereo-based binocular depth estimation remains largely unexplored. To this end, we propose the first texture-enabled physical adversarial attack against stereo matching models in the context of autonomous driving. Our method employs a 3D PAE with global camouflage texture rather than a local 2D patch-based one, ensuring both visual consistency and attack effectiveness across different viewpoints of stereo cameras. To cope with the disparity effect of these cameras, we also propose a new 3D stereo matching rendering module that allows the PAE to be aligned with real-world positions and headings in binocular vision. We further propose a novel merging attack that seamlessly blends the target into the environment through fine-grained PAE optimization. It has significantly enhanced stealth and lethality upon existing hiding attacks that fail to get seamlessly merged into the background. Extensive evaluations show that our PAEs can successfully fool the stereo models into producing erroneous depth information.

</details>


### [74] [Enhancing LLM-based Autonomous Driving with Modular Traffic Light and Sign Recognition](https://arxiv.org/abs/2511.14391)
*Fabian Schmidt,Noushiq Mohammed Kayilan Abdul Nazar,Markus Enzweiler,Abhinav Valada*

Main category: cs.CV

TL;DR: TLS-Assist is a plug-and-play module that enhances LLM-based driving agents by injecting structured natural language messages from detected traffic lights and signs into the LLM input, improving compliance with traffic rules and driving performance by up to 14% compared to prior methods.


<details>
  <summary>Details</summary>
Motivation: Current LLM-based autonomous driving agents lack explicit mechanisms to enforce traffic rules and struggle with detecting small, safety-critical objects like traffic lights and signs.

Method: Introduce TLS-Assist, a modular redundancy layer that enhances LLM-based driving agents by adding explicit traffic light and sign recognition. It converts object detections into structured natural language messages injected into the LLM input to enforce attention on safety-critical cues. The framework is plug-and-play, model-agnostic, and supports both single-view and multi-view camera setups.

Result: In a closed-loop evaluation on the LangAuto benchmark in CARLA, TLS-Assist achieves up to 14% improvement over LMDrive and 7% over BEVDriver in driving performance, while consistently reducing traffic light and sign infractions.

Conclusion: TLS-Assist effectively improves the safety and reliability of LLM-based autonomous driving agents by explicitly integrating traffic rule enforcement through structured language injection, demonstrating strong potential for real-world deployment.

Abstract: Large Language Models (LLMs) are increasingly used for decision-making and planning in autonomous driving, showing promising reasoning capabilities and potential to generalize across diverse traffic situations. However, current LLM-based driving agents lack explicit mechanisms to enforce traffic rules and often struggle to reliably detect small, safety-critical objects such as traffic lights and signs. To address this limitation, we introduce TLS-Assist, a modular redundancy layer that augments LLM-based autonomous driving agents with explicit traffic light and sign recognition. TLS-Assist converts detections into structured natural language messages that are injected into the LLM input, enforcing explicit attention to safety-critical cues. The framework is plug-and-play, model-agnostic, and supports both single-view and multi-view camera setups. We evaluate TLS-Assist in a closed-loop setup on the LangAuto benchmark in CARLA. The results demonstrate relative driving performance improvements of up to 14% over LMDrive and 7% over BEVDriver, while consistently reducing traffic light and sign infractions. We publicly release the code and models on https://github.com/iis-esslingen/TLS-Assist.

</details>


### [75] [BEDLAM2.0: Synthetic Humans and Cameras in Motion](https://arxiv.org/abs/2511.14394)
*Joachim Tesch,Giorgio Becherini,Prerana Achar,Anastasios Yiannakidis,Muhammed Kocabas,Priyanka Patel,Michael J. Black*

Main category: cs.CV

TL;DR: 提出BEDLAM2.0数据集，用于提升从视频中估计3D人体运动的准确性，尤其在世界坐标系下；该数据集在相机运动、人体形态、动作、服装、环境等方面更具多样性和真实性，并引入了鞋类细节。相比原版BEDLAM，BEDLAM2.0显著提升模型性能，特别适用于需世界坐标输出的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在估计3D人体运动时难以处理人与摄像机同时运动的情况，且缺乏足够丰富的真实世界标注数据支持训练，限制了精度提升。因此需要更高质量、多样化且包含真实相机运动和人体动态的数据集。

Method: 构建并发布BEDLAM2.0数据集，通过增加更多样化的相机轨迹、人体形状、动作、衣物、发型及三维环境，并加入鞋类细节，提升数据真实感与多样性；提供渲染视频、真实人体参数与相机运动信息，以及可复用的3D资产资源。

Result: 在多个先进方法上对比验证表明，使用BEDLAM2.0训练的模型在世界坐标系下对人体运动估计的精度显著优于基于BEDLAM训练的模型，尤其在复杂运动场景中表现更优。

Conclusion: BEDLAM2.0是一个更全面、真实且具有挑战性的新基准数据集，能够有效推动3D人体运动估计研究的发展，特别是在世界坐标系下的建模能力方面。

Abstract: Inferring 3D human motion from video remains a challenging problem with many applications. While traditional methods estimate the human in image coordinates, many applications require human motion to be estimated in world coordinates. This is particularly challenging when there is both human and camera motion. Progress on this topic has been limited by the lack of rich video data with ground truth human and camera movement. We address this with BEDLAM2.0, a new dataset that goes beyond the popular BEDLAM dataset in important ways. In addition to introducing more diverse and realistic cameras and camera motions, BEDLAM2.0 increases diversity and realism of body shape, motions, clothing, hair, and 3D environments. Additionally, it adds shoes, which were missing in BEDLAM. BEDLAM has become a key resource for training 3D human pose and motion regressors today and we show that BEDLAM2.0 is significantly better, particularly for training methods that estimate humans in world coordinates. We compare state-of-the art methods trained on BEDLAM and BEDLAM2.0, and find that BEDLAM2.0 significantly improves accuracy over BEDLAM. For research purposes, we provide the rendered videos, ground truth body parameters, and camera motions. We also provide the 3D assets to which we have rights and links to those from third parties.

</details>


### [76] [Stage Aware Diagnosis of Diabetic Retinopathy via Ordinal Regression](https://arxiv.org/abs/2511.14398)
*Saksham Kumar,D Sridhar Aditya,T Likhil Kumar,Thulasi Bikku,Srinivasarao Thota,Chandan Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种基于序数回归的糖尿病视网膜病变（DR）检测框架，利用APTOS-2019眼底图像数据集进行训练与评估。通过绿通道提取、噪声掩码和CLAHE等预处理方法，有效提取了与DR相关的关键特征。模型采用加权肯德尔协调系数（QWK）作为评估指标，结果达到0.8992，显著优于现有方法，为该数据集设立了新基准。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是导致可预防性失明的主要原因之一，早期筛查和干预至关重要。然而，传统诊断依赖专业医生，存在资源不足和效率低下的问题。因此，亟需一种高效、准确的自动化检测方法，以实现大规模筛查和早期干预。

Method: 采用序数回归模型对糖尿病视网膜病变进行分级检测。在数据预处理阶段，结合绿通道提取、噪声掩码和对比度受限自适应直方图均衡化（CLAHE），增强图像中病灶区域的可见性。随后将处理后的图像输入序数回归模型，实现从无病变到重度病变的有序分类。

Result: 所提出的序数回归框架在APTOS-2019数据集上取得了0.8992的QWK评分，显著优于以往方法，在临床分级一致性方面表现优异，验证了其在实际应用中的潜力。

Conclusion: 本研究提出的基于序数回归的DR检测框架在性能上达到了新高度，具备良好的临床应用前景，有助于推动糖尿病视网膜病变的自动化筛查与早期干预。

Abstract: Diabetic Retinopathy (DR) has emerged as a major cause of preventable blindness in recent times. With timely screening and intervention, the condition can be prevented from causing irreversible damage. The work introduces a state-of-the-art Ordinal Regression-based DR Detection framework that uses the APTOS-2019 fundus image dataset. A widely accepted combination of preprocessing methods: Green Channel (GC) Extraction, Noise Masking, and CLAHE, was used to isolate the most relevant features for DR classification. Model performance was evaluated using the Quadratic Weighted Kappa, with a focus on agreement between results and clinical grading. Our Ordinal Regression approach attained a QWK score of 0.8992, setting a new benchmark on the APTOS dataset.

</details>


### [77] [Language as an Anchor: Preserving Relative Visual Geometry for Domain Incremental Learning](https://arxiv.org/abs/2511.14401)
*Shuyi Geng,Tao Zhou,Yi Zhou*

Main category: cs.CV

TL;DR: LAVA提出了一种新的领域增量学习框架，通过文本锚定的视觉对齐来解决领域间分布变化带来的知识遗忘与干扰问题。它利用类名间的语义相似性构建相对几何结构，作为跨域桥梁，保持视觉表示的一致性，从而实现更好的知识复用和特征聚合。


<details>
  <summary>Details</summary>
Motivation: 现有DIL方法在统一视觉空间中面临域间干扰和语义扭曲，在隔离参数时又导致知识碎片化，难以有效复用和迁移知识。

Method: LAVA采用基于文本参考锚点的相对对齐机制，通过镜像类名之间的语义相似性来定义视觉表示的相对几何结构，从而在不同域间保持一致性。

Result: 在标准DIL基准测试中，LAVA显著优于现有最先进方法，有效缓解了知识遗忘并提升了模型性能。

Conclusion: LAVA通过语言锚定的相对对齐机制，成功构建了跨域一致的视觉表示结构，为持续学习提供了稳健的知识保留与迁移路径。

Abstract: A key challenge in Domain Incremental Learning (DIL) is to continually learn under shifting distributions while preserving knowledge from previous domains. Existing methods face a fundamental dilemma. On one hand, projecting all domains into a single unified visual space leads to inter-domain interference and semantic distortion, as large shifts may vary with not only visual appearance but also underlying semantics. On the other hand, isolating domain-specific parameters causes knowledge fragmentation, creating "knowledge islands" that hamper knowledge reuse and exacerbate forgetting. To address this issue, we propose LAVA (Language-Anchored Visual Alignment), a novel DIL framework that replaces direct feature alignment with relative alignment driven by a text-based reference anchor. LAVA guides the visual representations of each incoming domain to preserve a consistent relative geometry, which is defined by mirroring the pairwise semantic similarities between the class names. This anchored geometric structure acts as a bridge across domains, enabling the retrieval of class-aware prior knowledge and facilitating robust feature aggregation. Extensive experiments on standard DIL benchmarks demonstrate that LAVA achieves significant performance improvements over state-of-the-arts. Code is available at https://github.com/ShuyiGeng/LAVA.

</details>


### [78] [Cranio-ID: Graph-Based Craniofacial Identification via Automatic Landmark Annotation in 2D Multi-View X-rays](https://arxiv.org/abs/2511.14411)
*Ravi Shankar Prasad,Nandani Sharma,Dinesh Singh*

Main category: cs.CV

TL;DR: 本文提出了一种名为Cranio-ID的新框架，用于法医颅面识别中的自动颅骨标志点标注与跨模态匹配。该框架首先使用训练好的YOLO-pose模型在2D颅骨图像（如面部X光片）及其对应的光学图像上自动标注标志点；其次，通过将标志点构建成图结构，并利用交叉注意力和最优传输框架实现两模态之间的语义对应匹配。在S2F和CUHK数据集上的大量实验验证表明，该方法在可靠性、准确性和跨域颅骨-人脸、草图-人脸匹配方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统颅骨标志点定位方法耗时且依赖专业知识，现有基于超像素或深度学习的方法缺乏大规模验证，可靠性不足。因此亟需一种高效、准确且可验证的自动标注与跨模态匹配方法，以支持法医颅面识别及生物医学应用。

Method: 提出Cranio-ID框架，包含两个核心步骤：(1) 使用训练好的YOLO-pose模型对2D颅骨图像（X光片）及其光学图像进行自动标志点标注；(2) 将标注结果建模为图结构，采用交叉注意力机制与最优传输算法实现不同模态间的语义对应匹配。

Result: 在S2F和CUHK数据集上的实验结果显示，Cranio-ID在颅骨-人脸和草图-人脸匹配任务中均表现出更高的准确率与可靠性，显著优于现有方法，尤其在跨域场景下具有强适应性。

Conclusion: Cranio-ID框架实现了高效、精准的自动标志点标注与跨模态匹配，在法医颅面识别中展现出巨大潜力，为后续自动化、智能化的生物特征识别系统提供了可靠的技术支撑。

Abstract: In forensic craniofacial identification and in many biomedical applications, craniometric landmarks are important. Traditional methods for locating landmarks are time-consuming and require specialized knowledge and expertise. Current methods utilize superimposition and deep learning-based methods that employ automatic annotation of landmarks. However, these methods are not reliable due to insufficient large-scale validation studies. In this paper, we proposed a novel framework Cranio-ID: First, an automatic annotation of landmarks on 2D skulls (which are X-ray scans of faces) with their respective optical images using our trained YOLO-pose models. Second, cross-modal matching by formulating these landmarks into graph representations and then finding semantic correspondence between graphs of these two modalities using cross-attention and optimal transport framework. Our proposed framework is validated on the S2F and CUHK datasets (CUHK dataset resembles with S2F dataset). Extensive experiments have been conducted to evaluate the performance of our proposed framework, which demonstrates significant improvements in both reliability and accuracy, as well as its effectiveness in cross-domain skull-to-face and sketch-to-face matching in forensic science.

</details>


### [79] [Learning to See Through a Baby's Eyes: Early Visual Diets Enable Robust Visual Intelligence in Humans and Machines](https://arxiv.org/abs/2511.14440)
*Yusen Cai,Bhargava Satya Nunna,Qing Lin,Mengmi Zhang*

Main category: cs.CV

TL;DR: 该研究通过模拟婴儿视觉发展的渐进过程（灰度到彩色、模糊到清晰、时间连续性保留），提出CATDiet训练框架，用于自监督学习模型。实验表明，该方法显著提升了模型在多种任务中的鲁棒性，并展现出与生物发育相似的神经可塑性和行为模式。进一步提出的CombDiet结合前期阶段训练，在多个领域表现优于传统方法，揭示了早期视觉经验发展路径对机器视觉智能构建的重要启示。


<details>
  <summary>Details</summary>
Motivation: 探索婴儿视觉发展过程中阶段性视觉输入（低分辨率、色彩退化、时间连续）的生态优势，以反向工程方式理解机器视觉智能的稳健性如何形成。

Method: 设计CATDiet训练范式，模拟婴儿视觉发展：在自监督学习中引入灰度到彩色（C）、模糊到清晰（A）、时间连续性保留（T）的约束；构建多任务评估基准，涵盖图像识别、纹理-形状冲突、轮廓识别、深度排序及视觉悬崖测试；提出CombDiet，先用CATDiet预训练再进行标准训练。

Result: CATDiet模型在各类任务中表现出更强的鲁棒性，且其神经活动和行为响应与灵长类动物视觉皮层发育及婴儿视觉悬崖反应一致；CombDiet在域内与域外对象识别和深度感知任务中均优于标准自监督学习方法。

Conclusion: 早期婴儿视觉体验的发展阶段为构建稳健的机器视觉系统提供了有效的逆向工程框架，支持将发展轨迹融入模型训练中以提升智能水平。所有代码、数据和模型将公开发布。

Abstract: Newborns perceive the world with low-acuity, color-degraded, and temporally continuous vision, which gradually sharpens as infants develop. To explore the ecological advantages of such staged "visual diets", we train self-supervised learning (SSL) models on object-centric videos under constraints that simulate infant vision: grayscale-to-color (C), blur-to-sharp (A), and preserved temporal continuity (T)-collectively termed CATDiet. For evaluation, we establish a comprehensive benchmark across ten datasets, covering clean and corrupted image recognition, texture-shape cue conflict tests, silhouette recognition, depth-order classification, and the visual cliff paradigm. All CATDiet variants demonstrate enhanced robustness in object recognition, despite being trained solely on object-centric videos. Remarkably, models also exhibit biologically aligned developmental patterns, including neural plasticity changes mirroring synaptic density in macaque V1 and behaviors resembling infants' visual cliff responses. Building on these insights, CombDiet initializes SSL with CATDiet before standard training while preserving temporal continuity. Trained on object-centric or head-mounted infant videos, CombDiet outperforms standard SSL on both in-domain and out-of-domain object recognition and depth perception. Together, these results suggest that the developmental progression of early infant visual experience offers a powerful reverse-engineering framework for understanding the emergence of robust visual intelligence in machines. All code, data, and models will be publicly released.

</details>


### [80] [Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding](https://arxiv.org/abs/2511.14446)
*Hong Gao,Yiming Bao,Xuezhen Tu,Yutong Xu,Yue Jin,Yiyang Mu,Bin Zhong,Linan Yue,Min-Ling Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为Agentic Video Intelligence (AVI)的无需训练、灵活的视频理解框架，通过模拟人类三阶段推理过程（检索-感知-回顾），结合结构化知识库与多粒度工具，利用开源模型集合实现高效视频分析，在多个基准测试中表现优异且可解释性更强。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在处理视频时通常采用单次遍历，缺乏证据回溯和迭代优化能力；而现有的基于智能体的方法依赖昂贵的专有模型或大量强化学习训练，成本高且难以推广。因此需要一种无需训练、高效且可解释的视频理解框架。

Method: AVI引入了三阶段推理流程（Retrieve-Perceive-Review），构建基于实体图的结构化视频知识库，并集成多粒度工具作为交互环境，同时采用开源模型组合（包括推理型LLM、轻量级基础CV模型和VLM）以避免对专有API或强化学习训练的依赖。

Result: 在LVBench、VideoMME-Long、LongVideoBench和Charades-STA等多个数据集上，AVI取得了具有竞争力的性能，同时展现出显著优于现有方法的可解释性。

Conclusion: AVI成功实现了无需训练的高效视频理解，通过系统级设计模仿人类认知过程，为复杂视频任务提供了一种灵活、透明且低成本的解决方案。

Abstract: Video understanding requires not only visual recognition but also complex reasoning. While Vision-Language Models (VLMs) demonstrate impressive capabilities, they typically process videos largely in a single-pass manner with limited support for evidence revisit and iterative refinement. While recently emerging agent-based methods enable long-horizon reasoning, they either depend heavily on expensive proprietary models or require extensive agentic RL training. To overcome these limitations, we propose Agentic Video Intelligence (AVI), a flexible and training-free framework that can mirror human video comprehension through system-level design and optimization. AVI introduces three key innovations: (1) a human-inspired three-phase reasoning process (Retrieve-Perceive-Review) that ensures both sufficient global exploration and focused local analysis, (2) a structured video knowledge base organized through entity graphs, along with multi-granularity integrated tools, constituting the agent's interaction environment, and (3) an open-source model ensemble combining reasoning LLMs with lightweight base CV models and VLM, eliminating dependence on proprietary APIs or RL training. Experiments on LVBench, VideoMME-Long, LongVideoBench, and Charades-STA demonstrate that AVI achieves competitive performance while offering superior interpretability.

</details>


### [81] [DIR-TIR: Dialog-Iterative Refinement for Text-to-Image Retrieval](https://arxiv.org/abs/2511.14449)
*Zongwei Zhen,Biqing Zeng*

Main category: cs.CV

TL;DR: 本文提出DIR-TIR框架，通过对话和图像双重精炼模块，实现交互式文本到图像的检索。该框架在多轮对话中逐步优化目标图像搜索，显著提升检索准确率与交互体验。


<details>
  <summary>Details</summary>
Motivation: 传统单次查询方法在文本到图像检索中缺乏可控性和容错能力，难以满足用户对精准图像搜索的需求。因此，需要一种能够通过多轮对话动态调整描述并减少视觉-语义差异的交互式检索方法。

Method: 提出双模块架构：对话精炼模块（Dialog Refiner）主动向用户提问以获取关键信息并生成更精确的描述；图像精炼模块（Image Refiner）识别生成图像与用户意图之间的感知差距，降低视觉-语义不一致。两者协同工作，通过多轮对话实现高效、精准的图像检索。

Result: 在多个图像数据集上的实验表明，所提方法显著优于仅依赖初始描述的基线模型，在检索精度和交互体验方面均有明显提升。模块间的协同作用进一步增强了系统的性能与鲁棒性。

Conclusion: DIR-TIR框架通过融合对话引导与图像反馈机制，实现了高可控性、高容错性的交互式文本到图像检索，为复杂视觉搜索任务提供了有效解决方案。

Abstract: This paper addresses the task of interactive, conversational text-to-image retrieval.
  Our DIR-TIR framework progressively refines the target image search through two specialized modules: the Dialog Refiner Module and the Image Refiner Module.
  The Dialog Refiner actively queries users to extract essential information and generate increasingly precise descriptions of the target image.
  Complementarily, the Image Refiner identifies perceptual gaps between generated images and user intentions, strategically reducing the visual-semantic discrepancy. By leveraging multi-turn dialogues, DIR-TIR provides superior controllability and fault tolerance compared to conventional single-query methods, significantly improving target image hit accuracy.
  Comprehensive experiments across diverse image datasets demonstrate our dialogue-based approach substantially outperforms initial-description-only baselines, while the synergistic module integration achieves both higher retrieval precision and enhanced interactive experience.

</details>


### [82] [Segmentation-Aware Latent Diffusion for Satellite Image Super-Resolution: Enabling Smallholder Farm Boundary Delineation](https://arxiv.org/abs/2511.14481)
*Aditi Agarwal,Anjali Jain,Nikita Saxena,Ishan Deshpande,Michal Kazmierski,Abigail Annkah,Nadav Sherman,Karthikeyan Shanmugam,Alok Talekar,Vaibhav Rajan*

Main category: cs.CV

TL;DR: 本文提出一种名为SEED-SR的新方法，通过在分割感知的潜在空间中进行超分辨率重建，解决了小农户农田边界提取中高分辨率图像获取频率低的问题。该方法利用条件潜在扩散模型和大规模多光谱、多源地理空间基础模型，跳过像素空间中的显式超分辨率步骤，实现了20倍的超分辨率尺度因子，在两个真实大型数据集上分别相对于现有最优参考超分辨率方法提升了25.5%和12.9%的实例与语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 小农户农田边界提取依赖高分辨率卫星图像，但高分辨率图像获取频率低（如每年一次），难以支持频繁的季节性监测。虽然可结合低分辨率、高重访频率图像与高分辨率参考图像使用参考超分辨率技术，但现有方法在优化感知质量时会模糊对下游任务至关重要的细节特征，且无法满足本任务的大尺度因子需求。此外，传统的两步法（先超分辨率再分割）未能有效融合多种卫星数据源输入。

Method: 提出SEED-SR方法，采用条件潜在扩散模型与大规模多源多光谱地理空间基础模型，将超分辨率过程从像素空间转移到分割感知的潜在空间，从而在不直接重建像素的情况下实现高质量、高精度的分割图生成。

Result: 在两个真实大型数据集上，SEED-SR实现了20倍的超分辨率尺度因子，实例分割指标提升25.5%，语义分割指标提升12.9%，显著优于当前最先进的参考超分辨率方法。

Conclusion: SEED-SR通过在分割感知的潜在空间中执行超分辨率，有效克服了传统方法在细节保留与大尺度因子方面的局限，为农业遥感中的频繁、精准农田边界提取提供了新范式。

Abstract: Delineating farm boundaries through segmentation of satellite images is a fundamental step in many agricultural applications. The task is particularly challenging for smallholder farms, where accurate delineation requires the use of high resolution (HR) imagery which are available only at low revisit frequencies (e.g., annually). To support more frequent (sub-) seasonal monitoring, HR images could be combined as references (ref) with low resolution (LR) images -- having higher revisit frequency (e.g., weekly) -- using reference-based super-resolution (Ref-SR) methods. However, current Ref-SR methods optimize perceptual quality and smooth over crucial features needed for downstream tasks, and are unable to meet the large scale-factor requirements for this task. Further, previous two-step approaches of SR followed by segmentation do not effectively utilize diverse satellite sources as inputs. We address these problems through a new approach, $\textbf{SEED-SR}$, which uses a combination of conditional latent diffusion models and large-scale multi-spectral, multi-source geo-spatial foundation models. Our key innovation is to bypass the explicit SR task in the pixel space and instead perform SR in a segmentation-aware latent space. This unique approach enables us to generate segmentation maps at an unprecedented 20$\times$ scale factor, and rigorous experiments on two large, real datasets demonstrate up to $\textbf{25.5}$ and $\textbf{12.9}$ relative improvement in instance and semantic segmentation metrics respectively over approaches based on state-of-the-art Ref-SR methods.

</details>


### [83] [Parameter Aware Mamba Model for Multi-task Dense Prediction](https://arxiv.org/abs/2511.14503)
*Xinzhuo Yu,Yunzhi Zhuge,Sitong Gong,Lu Zhang,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: 提出了一种基于状态空间模型的新型多任务密集预测框架PAMM，通过双状态空间参数专家和多方向希尔伯特扫描，提升任务间交互与特征感知能力，在NYUD-v2和PASCAL-Context上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖卷积和注意力机制建模任务间关系，但难以有效捕捉任务内在特性及全局任务先验，因此需要更高效、可扩展的建模方式。

Method: 设计了基于状态空间模型（S4）的PAMM框架，引入双状态空间参数专家以设置任务特定参数先验，并结合多方向希尔伯特扫描构建多角度特征序列，增强对2D数据的感知能力。

Result: 在NYUD-v2和PASCAL-Context数据集上均取得了优于现有方法的性能，验证了该方法在多任务密集预测中的有效性。

Conclusion: PAMM通过融合状态空间模型与任务先验，实现了高效的任务间交互与全局信息整合，为多任务密集预测提供了新范式。

Abstract: Understanding the inter-relations and interactions between tasks is crucial for multi-task dense prediction. Existing methods predominantly utilize convolutional layers and attention mechanisms to explore task-level interactions. In this work, we introduce a novel decoder-based framework, Parameter Aware Mamba Model (PAMM), specifically designed for dense prediction in multi-task learning setting. Distinct from approaches that employ Transformers to model holistic task relationships, PAMM leverages the rich, scalable parameters of state space models to enhance task interconnectivity. It features dual state space parameter experts that integrate and set task-specific parameter priors, capturing the intrinsic properties of each task. This approach not only facilitates precise multi-task interactions but also allows for the global integration of task priors through the structured state space sequence model (S4). Furthermore, we employ the Multi-Directional Hilbert Scanning method to construct multi-angle feature sequences, thereby enhancing the sequence model's perceptual capabilities for 2D data. Extensive experiments on the NYUD-v2 and PASCAL-Context benchmarks demonstrate the effectiveness of our proposed method. Our code is available at https://github.com/CQC-gogopro/PAMM.

</details>


### [84] [DeCo-VAE: Learning Compact Latents for Video Reconstruction via Decoupled Representation](https://arxiv.org/abs/2511.14530)
*Xiangchen Yin,Jiahui Yuan,Zhangchi Hu,Wenzhang Sun,Jie Chen,Xiaozhen Qiao,Hao Li,Xiaoyan Sun*

Main category: cs.CV

TL;DR: 提出DeCo-VAE，通过将视频内容显式分解为关键帧、运动和残差三部分，分别学习独立的潜在表示，避免组件间干扰，结合共享3D解码器保持时空一致性，并采用分步训练策略实现稳定且准确的静态与动态特征学习，显著提升视频重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频变分自编码器忽略帧间内容相似性，导致潜在空间冗余建模，影响压缩效率与重建质量。

Method: 将视频内容分解为关键帧、运动和残差三个成分，使用专用编码器分别建模，共享3D解码器保证时空一致性，采用分步冻结训练策略减少跨组件干扰。

Result: 在定量与定性实验中均表现出优于现有方法的视频重建性能。

Conclusion: DeCo-VAE通过显式解耦视频成分，实现了紧凑且高效的潜在表示，有效提升了视频重建质量。

Abstract: Existing video Variational Autoencoders (VAEs) generally overlook the similarity between frame contents, leading to redundant latent modeling. In this paper, we propose decoupled VAE (DeCo-VAE) to achieve compact latent representation. Instead of encoding RGB pixels directly, we decompose video content into distinct components via explicit decoupling: keyframe, motion and residual, and learn dedicated latent representation for each. To avoid cross-component interference, we design dedicated encoders for each decoupled component and adopt a shared 3D decoder to maintain spatiotemporal consistency during reconstruction. We further utilize a decoupled adaptation strategy that freezes partial encoders while training the others sequentially, ensuring stable training and accurate learning of both static and dynamic features. Extensive quantitative and qualitative experiments demonstrate that DeCo-VAE achieves superior video reconstruction performance.

</details>


### [85] [D-PerceptCT: Deep Perceptual Enhancement for Low-Dose CT Images](https://arxiv.org/abs/2511.14518)
*Taifour Yousra Nabila,Azeddine Beghdadi,Marie Luong,Zuheng Ming,Habib Zaidi,Faouzi Alaya Cheikh*

Main category: cs.CV

TL;DR: D-PerceptCT是一种受人类视觉系统启发的新型低剂量CT图像增强方法，通过结合语义先验与多尺度特征，有效保留关键解剖结构和病理细节。其核心包括视觉双路径提取器（ViDex）和全局-局部状态空间块，并引入基于人眼对比敏感度的深度感知相关性损失函数（DPRLF），显著提升图像感知质量。在Mayo2016数据集上的实验表明，该方法优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT虽降低了辐射风险，但导致图像质量下降，现有方法常过度平滑或高估噪声，造成重要细节丢失。为提升诊断可用性，需更贴近人类视觉感知机制的图像增强方法。

Method: 提出D-PerceptCT架构，包含视觉双路径提取器（ViDex）融合DINOv2语义先验与局部空间特征，以及全局-局部状态空间块以捕捉长程依赖和多尺度信息；设计深度感知相关性损失函数（DPRLF），基于人眼对比敏感度强化感知重要特征。

Result: 在Mayo2016数据集上，D-PerceptCT在结构与纹理信息保留方面优于当前最先进的方法，显著提升图像感知质量，使关键解剖结构和细小病灶更清晰可见。

Conclusion: D-PerceptCT通过模拟人类视觉系统的感知机制，实现了对低剂量CT图像的有效增强，在保持真实感的同时显著提升了诊断相关细节的可见性，为临床应用提供了高质量图像支持。

Abstract: Low Dose Computed Tomography (LDCT) is widely used as an imaging solution to aid diagnosis and other clinical tasks. However, this comes at the price of a deterioration in image quality due to the low dose of radiation used to reduce the risk of secondary cancer development. While some efficient methods have been proposed to enhance LDCT quality, many overestimate noise and perform excessive smoothing, leading to a loss of critical details. In this paper, we introduce D-PerceptCT, a novel architecture inspired by key principles of the Human Visual System (HVS) to enhance LDCT images. The objective is to guide the model to enhance or preserve perceptually relevant features, thereby providing radiologists with CT images where critical anatomical structures and fine pathological details are perceptu- ally visible. D-PerceptCT consists of two main blocks: 1) a Visual Dual-path Extractor (ViDex), which integrates semantic priors from a pretrained DINOv2 model with local spatial features, allowing the network to incorporate semantic-awareness during enhancement; (2) a Global-Local State-Space block that captures long-range information and multiscale features to preserve the important structures and fine details for diagnosis. In addition, we propose a novel deep perceptual loss, designated as the Deep Perceptual Relevancy Loss Function (DPRLF), which is inspired by human contrast sensitivity, to further emphasize perceptually important features. Extensive experiments on the Mayo2016 dataset demonstrate the effectiveness of D-PerceptCT method for LDCT enhancement, showing better preservation of structural and textural information within LDCT images compared to SOTA methods.

</details>


### [86] [Deep Learning-Based Regional White Matter Hyperintensity Mapping as a Robust Biomarker for Alzheimer's Disease](https://arxiv.org/abs/2511.14588)
*Julia Machnio,Mads Nielsen,Mostafa Mehdipour Ghazi*

Main category: cs.CV

TL;DR: 本文提出一种深度学习框架，用于白质高信号（WMH）的鲁棒分割与定位。该方法在多个公共数据集和独立的ADNI队列中评估，结果表明其预测的病变负荷与参考值一致，具备对病变负荷、成像方式和人口统计学差异的鲁棒性。除了精确分割外，还量化了解剖定义区域内的WMH负荷，并结合脑结构体积评估诊断价值。结果显示，区域性的WMH体积优于全局病变负担，与脑萎缩指标结合后分类性能显著提升，AUC最高达0.97。前部白质束等特定空间区域与疾病状态显著相关，提示阿尔茨海默病中的局部易感性。研究强调了区域化WMH量化的重要性，融合局部病变指标与萎缩标记可提升神经退行性疾病早期诊断与分层能力。


<details>
  <summary>Details</summary>
Motivation: 当前自动化WMH分割方法多仅提供全局病变负荷，忽视其在不同白质区域的空间分布，限制了对疾病机制的理解及诊断效能。因此，亟需一种能精准分割并量化区域病变负荷的方法，以揭示与认知老化、阿尔茨海默病等相关的空间模式。

Method: 提出基于深度学习的框架，实现对WMH的高精度分割与空间定位；通过解剖学定义区域量化病变负荷，并结合脑结构体积进行多模态分析，评估其在疾病分类中的诊断价值。

Result: 区域性的WMH体积在疾病分类中表现优于全局病变负荷；结合脑萎缩指标后，分类性能显著提升，AUC可达0.97；前部白质束等特定区域与诊断状态高度相关，显示出局部易感性。

Conclusion: 区域化WMH量化具有重要临床价值，融合局部病变指标与脑萎缩标记可显著提升神经退行性疾病早期诊断与个体化分层的能力。

Abstract: White matter hyperintensities (WMH) are key imaging markers in cognitive aging, Alzheimer's disease (AD), and related dementias. Although automated methods for WMH segmentation have advanced, most provide only global lesion load and overlook their spatial distribution across distinct white matter regions. We propose a deep learning framework for robust WMH segmentation and localization, evaluated across public datasets and an independent Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort. Our results show that the predicted lesion loads are in line with the reference WMH estimates, confirming the robustness to variations in lesion load, acquisition, and demographics. Beyond accurate segmentation, we quantify WMH load within anatomically defined regions and combine these measures with brain structure volumes to assess diagnostic value. Regional WMH volumes consistently outperform global lesion burden for disease classification, and integration with brain atrophy metrics further improves performance, reaching area under the curve (AUC) values up to 0.97. Several spatially distinct regions, particularly within anterior white matter tracts, are reproducibly associated with diagnostic status, indicating localized vulnerability in AD. These results highlight the added value of regional WMH quantification. Incorporating localized lesion metrics alongside atrophy markers may enhance early diagnosis and stratification in neurodegenerative disorders.

</details>


### [87] [CCSD: Cross-Modal Compositional Self-Distillation for Robust Brain Tumor Segmentation with Missing Modalities](https://arxiv.org/abs/2511.14599)
*Dongqing Xie,Yonghuang Wu,Zisheng Ai,Jun Min,Zhencun Jiang,Shaojin Geng,Lei Wang*

Main category: cs.CV

TL;DR: 提出一种新型的跨模态组合自蒸馏（CCSD）框架，用于处理多模态MRI中任意缺失模态的情况，通过共享-特定编码器-解码器架构和两种自蒸馏策略，显著提升模型在不同模态缺失场景下的性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 真实临床环境中常出现一种或多种MRI模态缺失，导致现有深度学习分割模型性能下降且泛化能力受限，亟需一种能灵活应对任意模态组合的鲁棒方法。

Method: 采用共享-特定编码器-解码器架构，结合层次化模态自蒸馏机制（减少模态间语义差异）和渐进式模态组合蒸馏策略（模拟模态逐步缺失以增强鲁棒性）。

Result: 在公开脑肿瘤分割数据集上的实验表明，CCSD在多种模态缺失场景下均达到当前最优性能，具有优异的泛化性和稳定性。

Conclusion: CCSD框架有效解决了多模态MRI中模态缺失问题，为临床实际应用提供了更可靠、灵活的脑肿瘤分割解决方案。

Abstract: The accurate segmentation of brain tumors from multi-modal MRI is critical for clinical diagnosis and treatment planning. While integrating complementary information from various MRI sequences is a common practice, the frequent absence of one or more modalities in real-world clinical settings poses a significant challenge, severely compromising the performance and generalizability of deep learning-based segmentation models. To address this challenge, we propose a novel Cross-Modal Compositional Self-Distillation (CCSD) framework that can flexibly handle arbitrary combinations of input modalities. CCSD adopts a shared-specific encoder-decoder architecture and incorporates two self-distillation strategies: (i) a hierarchical modality self-distillation mechanism that transfers knowledge across modality hierarchies to reduce semantic discrepancies, and (ii) a progressive modality combination distillation approach that enhances robustness to missing modalities by simulating gradual modality dropout during training. Extensive experiments on public brain tumor segmentation benchmarks demonstrate that CCSD achieves state-of-the-art performance across various missing-modality scenarios, with strong generalization and stability.

</details>


### [88] [Learning Compact Latent Space for Representing Neural Signed Distance Functions with High-fidelity Geometry Details](https://arxiv.org/abs/2511.14539)
*Qiang Bai,Bojian Wu,Xi Yang,Zhizhong Han*

Main category: cs.CV

TL;DR: 本文提出了一种在共同空间中表示多个神经符号距离函数（SDF）的方法，通过结合泛化和过拟合学习策略，以更紧凑的潜在编码恢复高保真几何细节。同时引入一种新型采样策略，提升训练效率并消除其他SDF带来的伪影。在多个基准数据集上进行了数值和视觉评估，结果表明该方法在表达能力和紧凑性方面优于现有最新方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经SDF在处理多个具有高保真几何细节的形状或场景时，受限于潜在空间信息不足及几何细节丢失，难以有效建模多SDF之间的关系。因此需要一种新的方法来统一表示多个SDF，同时保持细节并压缩表示。

Method: 提出一种基于泛化与过拟合学习策略相结合的框架，用于在公共潜在空间中表示多个SDF；设计一种新型采样策略，优化训练查询的选取，提升训练效率并减少跨SDF干扰引起的伪影。

Result: 在多个公开基准数据集上，所提方法在几何细节恢复、表示紧凑性以及训练效率方面均表现出色，相比最新方法具有明显优势。

Conclusion: 通过融合泛化与过拟合学习机制，并结合高效采样策略，本方法实现了对多个高保真SDF的紧凑而精确的联合表示，为多形状/场景的隐式建模提供了新范式。

Abstract: Neural signed distance functions (SDFs) have been a vital representation to represent 3D shapes or scenes with neural networks. An SDF is an implicit function that can query signed distances at specific coordinates for recovering a 3D surface. Although implicit functions work well on a single shape or scene, they pose obstacles when analyzing multiple SDFs with high-fidelity geometry details, due to the limited information encoded in the latent space for SDFs and the loss of geometry details. To overcome these obstacles, we introduce a method to represent multiple SDFs in a common space, aiming to recover more high-fidelity geometry details with more compact latent representations. Our key idea is to take full advantage of the benefits of generalization-based and overfitting-based learning strategies, which manage to preserve high-fidelity geometry details with compact latent codes. Based on this framework, we also introduce a novel sampling strategy to sample training queries. The sampling can improve the training efficiency and eliminate artifacts caused by the influence of other SDFs. We report numerical and visual evaluations on widely used benchmarks to validate our designs and show advantages over the latest methods in terms of the representative ability and compactness.

</details>


### [89] [Interaction-Aware 4D Gaussian Splatting for Dynamic Hand-Object Interaction Reconstruction](https://arxiv.org/abs/2511.14540)
*Hao Tian,Chenyangguang Zhang,Rui Liu,Wen Shen,Xiaolin Qin*

Main category: cs.CV

TL;DR: 本文提出一种无需物体先验的动态3D高斯溅射方法，用于同时建模手-物体交互场景中的几何与外观。通过引入可优化参数的交互感知高斯表示，结合手形与物体形变场的互补性，构建动态交互场以捕捉复杂运动和相互遮挡。采用渐进式优化策略和显式正则化，提升重建稳定性与物理真实性，实验表明该方法在动态手-物体交互重建上达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在无物体先验条件下难以准确建模手-物体交互中的复杂几何与外观变化，尤其在相互遮挡、边缘模糊和动态形变方面存在挑战，亟需更精细的建模机制与优化策略。

Method: 提出交互感知的手-物体高斯表示，引入可优化参数以实现分段线性结构建模；将手信息融入物体形变场，构建交互感知的动态场；设计渐进式优化流程，并加入显式正则化以稳定手-物体表示，确保平滑运动过渡与真实物理交互。

Result: 所提方法在动态手-物体交互场景重建中显著优于现有基于动态3D高斯溅射的方法，实现了最先进的性能，在几何精度、外观保真度和运动连续性方面均有提升。

Conclusion: 本文提出的交互感知动态3D高斯溅射框架有效解决了无先验条件下手-物体交互的建模难题，为复杂动态场景的高质量重建提供了新思路。

Abstract: This paper focuses on a challenging setting of simultaneously modeling geometry and appearance of hand-object interaction scenes without any object priors. We follow the trend of dynamic 3D Gaussian Splatting based methods, and address several significant challenges. To model complex hand-object interaction with mutual occlusion and edge blur, we present interaction-aware hand-object Gaussians with newly introduced optimizable parameters aiming to adopt piecewise linear hypothesis for clearer structural representation. Moreover, considering the complementarity and tightness of hand shape and object shape during interaction dynamics, we incorporate hand information into object deformation field, constructing interaction-aware dynamic fields to model flexible motions. To further address difficulties in the optimization process, we propose a progressive strategy that handles dynamic regions and static background step by step. Correspondingly, explicit regularizations are designed to stabilize the hand-object representations for smooth motion transition, physical interaction reality, and coherent lighting. Experiments show that our approach surpasses existing dynamic 3D-GS-based methods and achieves state-of-the-art performance in reconstructing dynamic hand-object interaction.

</details>


### [90] [OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models](https://arxiv.org/abs/2511.14582)
*Keda Tao,Kele Shao,Bohan Yu,Weiqiang Wang,Jian liu,Huan Wang*

Main category: cs.CV

TL;DR: OmniZip 是一种无需训练的音频引导音视频标记压缩框架，通过识别重要音频标记并计算音频保留分数，动态指导视频标记剪枝，同时利用跨模态相似性增强音频锚点，实现高效的音视频标记压缩。在保持性能不变的情况下，相比现有方法实现3.42倍推理加速和1.4倍内存减少。


<details>
  <summary>Details</summary>
Motivation: 现有的标记压缩方法无法有效应对音视频联合压缩的需求，音视频标记序列处理存在显著计算瓶颈，亟需一种适用于多模态标记压缩的新方法。

Method: OmniZip首先识别关键音频标记，计算每个时间组的音频保留分数以捕捉信息密度，进而动态引导视频标记剪枝；采用交错的时空压缩策略对视频标记进行压缩，并利用跨模态相似性增强音频锚点，实现高效且无训练的多模态压缩。

Result: 在不依赖训练的前提下，OmniZip实现了3.42倍的推理速度提升和1.4倍的内存占用降低，同时保持了与现有顶尖方法相当的性能表现。

Conclusion: OmniZip为音视频联合理解任务提供了高效、无需训练的多模态标记压缩方案，有效缓解了计算瓶颈问题，具备良好的实用价值和扩展潜力。

Abstract: Omnimodal large language models (OmniLLMs) have attracted increasing research attention of late towards unified audio-video understanding, wherein processing audio-video token sequences creates a significant computational bottleneck, however. Existing token compression methods have yet to accommodate this emerging need of jointly compressing multimodal tokens. To bridge this gap, we present OmniZip, a training-free, audio-guided audio-visual token-compression framework that optimizes multimodal token representation and accelerates inference. Specifically, OmniZip first identifies salient audio tokens, then computes an audio retention score for each time group to capture information density, thereby dynamically guiding video token pruning and preserving cues from audio anchors enhanced by cross-modal similarity. For each time window, OmniZip compresses the video tokens using an interleaved spatio-temporal scheme. Extensive empirical results demonstrate the merits of OmniZip - it achieves 3.42X inference speedup and 1.4X memory reduction over other top-performing counterparts, while maintaining performance with no training.

</details>


### [91] [XAttn-BMD: Multimodal Deep Learning with Cross-Attention for Femoral Neck Bone Mineral Density Estimation](https://arxiv.org/abs/2511.14604)
*Yilin Zhang,Leo D. Westbury,Elaine M. Dennison,Nicholas C. Harvey,Nicholas R. Fuggle,Rahman Attar*

Main category: cs.CV

TL;DR: XAttn-BMD是一种基于交叉注意力机制的多模态深度学习框架，用于从髋关节X光片和结构化临床数据中预测股骨颈骨密度（BMD）。通过双向交叉注意力实现图像与临床数据特征的动态融合，提升跨模态相互增强效果，并采用加权平滑L1损失缓解BMD分布不平衡问题，尤其关注临床关键病例。在赫特福德郡队列研究数据上的实验表明，该模型在回归泛化性和鲁棒性方面优于基线模型；消融实验证明交叉注意力融合和定制损失函数的有效性。相比简单的特征拼接，该方法将均方误差降低16.7%，平均绝对误差降低6.03%，决定系数R²提升16.4%。此外，在临床相关BMD阈值下的二分类筛查性能也表现出良好潜力，具备实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 低骨密度是导致骨折风险增加的关键因素，也是骨质疏松症的核心特征。现有方法多依赖单一模态数据，难以充分整合影像与临床信息，限制了预测精度。因此，亟需一种能够有效融合多源异构数据、提升预测性能的智能模型，以支持早期筛查与个性化干预。

Method: 提出XAttn-BMD框架，采用双向交叉注意力机制实现髋关节X光图像与结构化临床数据之间的动态特征交互与融合；设计加权平滑L1损失函数，以应对骨密度分布不均问题并强化对临床关键病例的关注；通过端到端训练优化模型参数。

Result: 在Hertfordshire Cohort Study数据集上，XAttn-BMD在股骨颈BMD预测任务中显著优于多种基线模型，相较于简单特征拼接方式，其MSE降低16.7%，MAE下降6.03%，R²提升16.4%；在临床相关阈值下的二分类筛查任务中表现优异，证明其具备真实世界应用潜力。

Conclusion: XAttn-BMD通过多模态交叉注意力机制与定制化损失函数，实现了影像与临床数据的高效融合，在股骨颈骨密度预测中展现出优越的性能与稳健性，为骨质疏松早期筛查提供了强有力的智能化工具。

Abstract: Poor bone health is a significant public health concern, and low bone mineral density (BMD) leads to an increased fracture risk, a key feature of osteoporosis. We present XAttn-BMD (Cross-Attention BMD), a multimodal deep learning framework that predicts femoral neck BMD from hip X-ray images and structured clinical metadata. It utilizes a novel bidirectional cross-attention mechanism to dynamically integrate image and metadata features for cross-modal mutual reinforcement. A Weighted Smooth L1 loss is tailored to address BMD imbalance and prioritize clinically significant cases. Extensive experiments on the data from the Hertfordshire Cohort Study show that our model outperforms the baseline models in regression generalization and robustness. Ablation studies confirm the effectiveness of both cross-attention fusion and the customized loss function. Experimental results show that the integration of multimodal data via cross-attention outperforms naive feature concatenation without cross-attention, reducing MSE by 16.7%, MAE by 6.03%, and increasing the R2 score by 16.4%, highlighting the effectiveness of the approach for femoral neck BMD estimation. Furthermore, screening performance was evaluated using binary classification at clinically relevant femoral neck BMD thresholds, demonstrating the model's potential in real-world scenarios.

</details>


### [92] [3D-Guided Scalable Flow Matching for Generating Volumetric Tissue Spatial Transcriptomics from Serial Histology](https://arxiv.org/abs/2511.14613)
*Mohammad Vali Sanian,Arshia Hemmat,Amirhossein Vahidi,Jonas Maaskola,Jimmy Tsz Hang Lee,Stanislaw Makarchuk,Yeliz Demirci,Nana-Jane Chipampe,Omer Bayraktar,Lassi Paavolainen,Mohammad Lotfollahi*

Main category: cs.CV

TL;DR: HoloTea 是一种3D感知的流匹配框架，用于从H&E染色图像中推断点级基因表达，通过融合相邻切片的上下文信息提升3D空间转录组的准确性与可扩展性。它引入了3D一致的先验（结合零膨胀负二项分布与空间经验先验），并采用轻量级ControlNet和全局注意力机制，实现对大规模3D ST数据的有效建模。在多个组织类型和分辨率的数据集上，HoloTea显著优于2D及现有3D基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理空间转录组时，大多忽略3D结构或无法有效扩展；需要一种既能保持3D连续性又能高效处理大规模数据的生成式框架，以更准确地重建组织三维基因表达图谱。

Method: 提出HoloTea框架，利用共享特征空间检索相邻切片中形态对应的点，通过轻量级ControlNet融合跨切片上下文；设计3D一致的先验（结合学习到的ZINB先验与基于邻近切片的经验先验）；引入全局注意力块实现3D H&E的线性缩放，支持大规模数据训练与推理。

Result: 在三个不同组织类型和分辨率的空间转录组数据集上，HoloTea在3D表达预测精度和泛化能力方面均显著优于2D和3D基线模型，展现出良好的鲁棒性与可扩展性。

Conclusion: HoloTea为构建高精度3D虚拟组织提供了新工具，有望加速生物标志物发现并深化对疾病机制的理解。

Abstract: A scalable and robust 3D tissue transcriptomics profile can enable a holistic understanding of tissue organization and provide deeper insights into human biology and disease. Most predictive algorithms that infer ST directly from histology treat each section independently and ignore 3D structure, while existing 3D-aware approaches are not generative and do not scale well. We present Holographic Tissue Expression Inpainting and Analysis (HoloTea), a 3D-aware flow-matching framework that imputes spot-level gene expression from H&E while explicitly using information from adjacent sections. Our key idea is to retrieve morphologically corresponding spots on neighboring slides in a shared feature space and fuse this cross section context into a lightweight ControlNet, allowing conditioning to follow anatomical continuity. To better capture the count nature of the data, we introduce a 3D-consistent prior for flow matching that combines a learned zero-inflated negative binomial (ZINB) prior with a spatial-empirical prior constructed from neighboring sections. A global attention block introduces 3D H&E scaling linearly with the number of spots in the slide, enabling training and inference on large 3D ST datasets. Across three spatial transcriptomics datasets spanning different tissue types and resolutions, HoloTea consistently improves 3D expression accuracy and generalization compared to 2D and 3D baselines. We envision HoloTea advancing the creation of accurate 3D virtual tissues, ultimately accelerating biomarker discovery and deepening our understanding of disease.

</details>


### [93] [SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2511.14633)
*Meiying Gu,Jiawei Zhang,Jiahe Li,Xiaohan Yu,Haonan Luo,Jin Zheng,Xiao Bai*

Main category: cs.CV

TL;DR: 本文提出了一种名为
et{}的新方法，旨在解决稀疏视角下高斯点阵重建中的过拟合问题。通过引入立体几何-纹理对齐机制，联合优化表面重建与视图合成质量；同时提出伪特征增强的几何一致性策略，利用训练和未见视角信息提升多视角几何一致性，有效缓解稀疏监督带来的过拟合。在DTU、BlendedMVS和Mip-NeRF360数据集上的实验表明，该方法达到当前最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏视角下容易因过拟合导致重建质量下降，尽管采用扁平化高斯原型和深度正则化改善几何拟合，但其固有的各向异性加剧了过拟合问题，影响表面拟合精度和新视角合成效果。因此需要一种能同时提升几何估计与渲染质量的新方法。

Method: 提出Stereo Geometry-Texture Alignment（立体几何-纹理对齐）以协同优化几何与渲染质量；设计Pseudo-Feature Enhanced Geometry Consistency（伪特征增强的几何一致性），融合训练与未见视角信息，增强多视角几何一致性，减少过拟合。

Result: 在DTU、BlendedMVS和Mip-NeRF360等多个基准数据集上，所提方法在表面重建精度和新视角合成质量方面均优于现有方法，达到当前最佳水平。

Conclusion: 
et{}通过几何-纹理对齐与伪特征增强的一致性约束，在稀疏视角下实现了更准确、更细节丰富的表面重建，并保持高质量的新视角渲染，显著提升了重建鲁棒性与视觉效果。

Abstract: Recent advances in optimizing Gaussian Splatting for scene geometry have enabled efficient reconstruction of detailed surfaces from images. However, when input views are sparse, such optimization is prone to overfitting, leading to suboptimal reconstruction quality. Existing approaches address this challenge by employing flattened Gaussian primitives to better fit surface geometry, combined with depth regularization to alleviate geometric ambiguities under limited viewpoints. Nevertheless, the increased anisotropy inherent in flattened Gaussians exacerbates overfitting in sparse-view scenarios, hindering accurate surface fitting and degrading novel view synthesis performance. In this paper, we propose \net{}, a method that reconstructs more accurate and detailed surfaces while preserving high-quality novel view rendering. Our key insight is to introduce Stereo Geometry-Texture Alignment, which bridges rendering quality and geometry estimation, thereby jointly enhancing both surface reconstruction and view synthesis. In addition, we present a Pseudo-Feature Enhanced Geometry Consistency that enforces multi-view geometric consistency by incorporating both training and unseen views, effectively mitigating overfitting caused by sparse supervision. Extensive experiments on the DTU, BlendedMVS, and Mip-NeRF360 datasets demonstrate that our method achieves the state-of-the-art performance.

</details>


### [94] [SLAM-AGS: Slide-Label Aware Multi-Task Pretraining Using Adaptive Gradient Surgery in Computational Cytology](https://arxiv.org/abs/2511.14639)
*Marco Acerbis,Swarnadip Chatterjee,Christophe Avenel,Joakim Lindblad*

Main category: cs.CV

TL;DR: SLAM-AGS 是一种针对骨髓细胞学中实例标签不可靠、阳性样本极低问题的多任务预训练框架，通过弱监督相似性与自监督对比学习联合优化，并结合自适应梯度手术稳定训练，显著提升低阳性率下的分类与异常细胞检索性能，开源实现以支持复现。


<details>
  <summary>Details</summary>
Motivation: 解决计算细胞学中实例级标签不可靠、获取成本高以及阳性样本（见证率）极低的问题，提升下游任务性能。

Method: 提出SLAM-AGS框架，联合优化滑片负样本的弱监督相似性目标和滑片正样本的自监督对比学习目标；采用自适应梯度手术缓解任务间梯度冲突，防止模型崩溃；使用基于注意力的多实例学习聚合器进行袋级预测并引导异常实例检索。

Result: 在公开骨髓细胞学数据集上，模拟见证率从10%降至0.5%时，SLAM-AGS在袋级F1分数和前400个阳性细胞检索上均优于其他预训练方法，尤其在低见证率下优势显著，证明梯度干扰缓解可实现稳定预训练与更优下游表现。

Conclusion: SLAM-AGS通过有效处理梯度冲突与低见证率挑战，实现了在弱监督和自监督协同下的稳定预训练，显著提升细胞学图像分析的性能，为复杂医学影像分析提供了可复现的解决方案。

Abstract: Computational cytology faces two major challenges: i) instance-level labels are unreliable and prohibitively costly to obtain, ii) witness rates are extremely low. We propose SLAM-AGS, a Slide-Label-Aware Multitask pretraining framework that jointly optimizes (i) a weakly supervised similarity objective on slide-negative patches and (ii) a self-supervised contrastive objective on slide-positive patches, yielding stronger performance on downstream tasks. To stabilize learning, we apply Adaptive Gradient Surgery to tackle conflicting task gradients and prevent model collapse. We integrate the pretrained encoder into an attention-based Multiple Instance Learning aggregator for bag-level prediction and attention-guided retrieval of the most abnormal instances in a bag. On a publicly available bone-marrow cytology dataset, with simulated witness rates from 10% down to 0.5%, SLAM-AGS improves bag-level F1-Score and Top 400 positive cell retrieval over other pretraining methods, with the largest gains at low witness rates, showing that resolving gradient interference enables stable pretraining and better performance on downstream tasks. To facilitate reproducibility, we share our complete implementation and evaluation framework as open source: https://github.com/Ace95/SLAM-AGS.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [95] [Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models](https://arxiv.org/abs/2511.13722)
*William Guo,Adaku Uchendu,Ana Smith*

Main category: cs.CL

TL;DR: 本文评估了多种水印技术在对抗攻击下的鲁棒性，比较了改写和反向翻译攻击的效果，并通过语言学指标评估其对文本质量和写作风格的保持能力。结果表明，现有水印技术虽能保留语义，但会改变原始写作风格，且易受反向翻译等对抗攻击影响，难以被广泛采纳。


<details>
  <summary>Details</summary>
Motivation: 为缓解大语言模型生成文本可能带来的危害，研究者提出了水印技术以嵌入可检测信号。然而，现有方法存在影响生成文本质量及易被对抗攻击去除水印的问题，阻碍了其在实际中的广泛应用。因此，亟需评估水印技术的鲁棒性与保质能力，以推动其落地应用。

Method: 采用改写和反向翻译（英→其他语言→英）作为对抗攻击手段，评估不同水印技术的鲁棒性；同时利用语言学指标衡量生成文本的质量与写作风格与原始文本的一致性。

Result: 水印技术虽能保持语义，但显著偏离原写作风格；且在反向翻译攻击下极易失效，显示出较低的鲁棒性。

Conclusion: 当前主流水印技术在质量保持和抗攻击能力方面表现不佳，限制了其在大语言模型中的推广，亟需更鲁棒、更隐蔽的水印机制。

Abstract: To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

</details>


### [96] [Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning](https://arxiv.org/abs/2511.13726)
*Guangzhi Wang,Kai Li,Yinghao Jiao,Zhi Liu*

Main category: cs.CL

TL;DR: 提出RT（Refine Thought）方法，通过多次前向传播增强文本嵌入模型的语义推理能力，在BRIGHT和PJBenchmark1上显著提升推理任务表现，同时保持在C-MTEB等通用语义理解任务上的稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型在语义推理任务中表现有限，尽管预训练阶段已学习一定推理能力，但未被充分激活。需要一种方法在推理时进一步激发模型的推理潜力。

Method: RT方法通过多次运行文本嵌入模型的前向传播，逐步优化和细化最终的语义表示，是一种测试时的推理增强技术。

Result: 在BRIGHT和PJBenchmark1上实现显著性能提升，同时在C-MTEB等通用任务上保持一致性能，证明其有效性和泛化能力。

Conclusion: RT能够有效激活解码器仅有的文本嵌入模型（如Qwen3-Embedding-8B）在预训练中学习到的语义推理能力，是一种高效的测试时推理方法。

Abstract: We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.

</details>


### [97] [Can QE-informed (Re)Translation lead to Error Correction?](https://arxiv.org/abs/2511.13884)
*Govardhan Padmanabhan*

Main category: cs.CL

TL;DR: 本文提出两种无需训练的QE-informed方法用于段落级错误修正，其中一种通过选择多个LLM生成翻译中的最优版本获胜，另一方法则根据QE解释替换错误子串。前者在Delta COMET上取得0.0201的提升，表现优于后者。


<details>
  <summary>Details</summary>
Motivation: 现有APE系统在自动后编辑中存在过度修正问题，导致机器翻译性能下降，因此需要更稳健的无需训练的方法来改进质量评估与纠错效果。

Method: 提出两种训练-free方法：一是基于多个LLM生成候选翻译并选择最高质量者；二是根据QE解释指导LLM替换错误子串，并采用条件启发式策略以最大化收益/编辑比。

Result: 所提方法在子任务排行榜中分别获得Delta COMET得分0.0201和-0.0108，前者表现优异，位居第一。

Conclusion: QE-informed Retranslation方法在不依赖训练的情况下有效提升了段落级错误修正的质量，证明了其在实际应用中的潜力。

Abstract: The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a Delta COMET score of 0.0201 and -0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.

</details>


### [98] [What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations](https://arxiv.org/abs/2511.13900)
*Mihir Gupte,Eshan Dixit,Muhammad Tayyab,Arun Adiththan*

Main category: cs.CL

TL;DR: 本文提出GM-Extract基准数据集，用于评估大语言模型在长文本中提取控制变量的能力。通过空间检索（文档度量）和语义检索（变量提取度量）两种指标诊断模型失败模式，发现数据表示方式对检索性能有显著影响。尽管未观察到一致的U形曲线，但性能变化与困惑度相关。文献调研表明缓解方法可分为黑盒与白盒两类，实际应用中其效果复杂且存在负面效应，揭示了现有策略在真实场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长上下文场景下出现的'迷失于中间'现象，特别是在信息检索任务中因上下文过长导致关键信息丢失的问题。需要一个真实应用场景下的评估框架来系统分析模型表现及失败原因。

Method: 构建GM-Extract基准数据集，设计双维度评估体系（文档度量与变量提取度量），对7-8B参数模型在多文档任务（键值提取、问答）中进行系统测试，并结合困惑度分析性能变化；梳理并分类现有缓解方法为黑盒与白盒两类，进一步在该基准上验证其有效性。

Result: 数据表示方式显著影响模型检索性能；性能变化趋势与困惑度呈一定相关性；黑盒与白盒缓解方法在不同场景下效果各异，部分情况下甚至导致性能下降，说明其适用性高度依赖具体情境。

Conclusion: 当前大语言模型在长上下文处理中仍面临严重挑战，现有缓解策略并非普适有效，需根据具体任务与数据结构谨慎选择。本研究提供了可复现的评估框架和深入洞察，有助于未来模型设计与优化方向的明确。

Abstract: The diminishing ability of large language models (LLMs) to effectively utilize long-range context-the "lost-in-the-middle" phenomenon-poses a significant challenge in retrieval-based LLM applications. To study the impact of this phenomenon in a real-world application setting, we introduce GM-Extract, a novel benchmark dataset meticulously designed to evaluate LLM performance on retrieval of control variables. To accurately diagnose failure modes, we propose a simple yet elegant evaluation system using two distinct metrics: one for spatial retrieval capability (Document Metric) and the other for semantic retrieval capability (Variable Extraction Metric). We conduct a systematic evaluation of 7-8B parameter models on two multi-document tasks (key-value extraction and question-answering), demonstrating a significant change in retrieval performance simply by altering how the data is represented in the context window. While a distinct U-shaped curve was not consistently observed, our analysis reveals a clear pattern of performance across models, which we further correlate with perplexity scores. Furthermore, we perform a literature survey of mitigation methods, which we categorize into two distinct approaches: black-box and white-box methods. We then apply these techniques to our benchmark, finding that their efficacy is highly nuanced. Our evaluation highlights scenarios where these strategies successfully improve performance, as well as surprising cases where they lead to a negative impact, providing a comprehensive understanding of their utility in a practical context.

</details>


### [99] [Hint-Augmented Re-ranking: Efficient Product Search using LLM-Based Query Decomposition](https://arxiv.org/abs/2511.13994)
*Yilun Zhu,Nikhita Vedula,Shervin Malmasi*

Main category: cs.CL

TL;DR: 该研究提出一种框架，利用大语言模型（LLM）解析电商搜索查询中蕴含的超度词（如'最好'、'最热门'）的潜在意图，通过生成结构化属性-值提示来提升搜索性能。方法将查询分解为并行生成的提示，可高效集成到排序流程中，显著提升MAP（+10.9点）和MRR（+5.9点）。针对LLM直接重排序带来的高延迟问题，提出轻量级模型迁移策略，实现语义知识的有效转移。研究揭示了超度语义的表示与跨模型传递机制，推动检索系统中的语言理解能力，并兼顾实际部署需求。


<details>
  <summary>Details</summary>
Motivation: 电商搜索中包含超度词的查询需要跨多维度比较候选结果，依赖深层语言理解和领域知识；传统方法难以准确捕捉其隐含意图，且基于LLM的重排序存在高延迟问题，亟需高效、可部署的解决方案。

Method: 提出一种基于LLM的框架，将超度词查询分解为并行生成的属性-值提示（attribute-value hints），结合检索过程进行结构化解释，再通过知识迁移将这些提示转化为轻量级模型可用的形式，实现高效排序。

Result: 在真实电商数据集上，相比基线方法，该方法在MAP上提升10.9点，在MRR上提升5.9点；同时解决了直接使用LLM重排序带来的高延迟问题，实现了高性能与低延迟的平衡。

Conclusion: 该研究证明了通过结构化提示提取超度词语义的有效性，为复杂查询的理解提供了新范式，且提出的迁移策略使先进语言模型的能力可在资源受限场景下落地，推动了检索系统中语言理解与工程部署的协同发展。

Abstract: Search queries with superlatives (e.g., best, most popular) require comparing candidates across multiple dimensions, demanding linguistic understanding and domain knowledge. We show that LLMs can uncover latent intent behind these expressions in e-commerce queries through a framework that extracts structured interpretations or hints. Our approach decomposes queries into attribute-value hints generated concurrently with retrieval, enabling efficient integration into the ranking pipeline. Our method improves search performanc eby 10.9 points in MAP and ranking by 5.9 points in MRR over baselines. Since direct LLM-based reranking faces prohibitive latency, we develop an efficient approach transferring superlative interpretations to lightweight models. Our findings provide insights into how superlative semantics can be represented and transferred between models, advancing linguistic interpretation in retrieval systems while addressing practical deployment constraints.

</details>


### [100] [HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027)
*Junjie Wu,Yumeng Fu,Nan Yu,Guohong Fu*

Main category: cs.CL

TL;DR: 本文提出了一种名为HiEAG的层次化证据增强生成框架，旨在通过利用多模态大语言模型（MLLMs）的广泛知识来改进图像-文本对与外部证据之间的外部一致性检查。该框架将外部一致性检查分解为包含检索、重排和重写三个模块的完整流水线。其中，证据重排模块采用自动证据选择提示（AESP），从检索结果中筛选相关证据；证据重写模块则使用自动证据生成提示（AEGP），提升MLLM在OOC虚假信息检测任务中的适应性。此外，该方法支持判断过程的可解释性，并通过指令微调实现优异性能。在多个基准数据集上的实验表明，HiEAG在所有样本上的准确率均优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有OOC虚假信息检测方法过于关注模态内部一致性，忽视了图像-文本对与外部证据之间的外部一致性，导致检测效果受限。因此，亟需一种能够有效整合外部证据并提升一致性判断能力的新方法。

Method: 提出HiEAG框架，包含证据检索、自动证据选择提示（AESP）进行重排、以及自动证据生成提示（AEGP）进行重写三个核心模块，结合多模态大语言模型（MLLMs）实现外部一致性增强与任务适配。

Result: 在多个公开基准数据集上，HiEAG在整体准确率上显著超越现有SOTA方法，且具备良好的可解释性与任务适应性。

Conclusion: HiEAG通过引入层次化证据增强机制，有效提升了多模态虚假信息检测中对外部一致性的判断能力，为构建更可靠、可解释的OOC misinformation检测系统提供了新范式。

Abstract: Recent advancements in multimodal out-of-context (OOC) misinformation detection have made remarkable progress in checking the consistencies between different modalities for supporting or refuting image-text pairs. However, existing OOC misinformation detection methods tend to emphasize the role of internal consistency, ignoring the significant of external consistency between image-text pairs and external evidence. In this paper, we propose HiEAG, a novel Hierarchical Evidence-Augmented Generation framework to refine external consistency checking through leveraging the extensive knowledge of multimodal large language models (MLLMs). Our approach decomposes external consistency checking into a comprehensive engine pipeline, which integrates reranking and rewriting, apart from retrieval. Evidence reranking module utilizes Automatic Evidence Selection Prompting (AESP) that acquires the relevant evidence item from the products of evidence retrieval. Subsequently, evidence rewriting module leverages Automatic Evidence Generation Prompting (AEGP) to improve task adaptation on MLLM-based OOC misinformation detectors. Furthermore, our approach enables explanation for judgment, and achieves impressive performance with instruction tuning. Experimental results on different benchmark datasets demonstrate that our proposed HiEAG surpasses previous state-of-the-art (SOTA) methods in the accuracy over all samples.

</details>


### [101] [Based on Data Balancing and Model Improvement for Multi-Label Sentiment Classification Performance Enhancement](https://arxiv.org/abs/2511.14073)
*Zijin Su,Huanzhu Lv,Yuren Niu,Yiming Liu*

Main category: cs.CL

TL;DR: 本文针对多标签情感分类中因类别不平衡导致模型性能下降的问题，构建了一个平衡的多标签情感数据集（包含28个情绪类别），并提出了一种结合FastText嵌入、卷积层、双向LSTM和注意力机制的增强型多标签分类模型。通过混合精度训练提升效率，实验表明该方法在准确率、精确率、召回率、F1分数和AUC等方面均优于基于不平衡数据训练的模型，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集如GoEmotions存在严重的类别不平衡问题，导致模型对少数情绪类别的识别能力差，影响整体性能。因此需要构建一个更均衡的数据集，并设计更有效的模型来提升多标签情感分类效果。

Method: 整合原始GoEmotions数据、使用RoBERTa-base-GoEmotions模型从Sentiment140中提取情感标注样本，以及利用GPT-4 mini生成人工标注文本，实现数据平衡；在此基础上构建融合FastText嵌入、卷积层、双向LSTM和注意力机制的深度学习模型，采用sigmoid输出层进行多标签预测，并应用混合精度训练以提高计算效率。

Result: 实验结果显示，所提方法在准确率、精确率、召回率、F1分数和AUC等指标上均显著优于基于不平衡数据训练的模型，证明了数据平衡与模型设计的有效性。

Conclusion: 通过构建平衡的多标签情感数据集并设计高效的多标签分类模型，能够有效缓解类别不平衡带来的负面影响，显著提升多标签情感分类的性能。

Abstract: Multi-label sentiment classification plays a vital role in natural language processing by detecting multiple emotions within a single text. However, existing datasets like GoEmotions often suffer from severe class imbalance, which hampers model performance, especially for underrepresented emotions. To address this, we constructed a balanced multi-label sentiment dataset by integrating the original GoEmotions data, emotion-labeled samples from Sentiment140 using a RoBERTa-base-GoEmotions model, and manually annotated texts generated by GPT-4 mini. Our data balancing strategy ensured an even distribution across 28 emotion categories. Based on this dataset, we developed an enhanced multi-label classification model that combines pre-trained FastText embeddings, convolutional layers for local feature extraction, bidirectional LSTM for contextual learning, and an attention mechanism to highlight sentiment-relevant words. A sigmoid-activated output layer enables multi-label prediction, and mixed precision training improves computational efficiency. Experimental results demonstrate significant improvements in accuracy, precision, recall, F1-score, and AUC compared to models trained on imbalanced data, highlighting the effectiveness of our approach.

</details>


### [102] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 本文提出一种名为'隐秘微调'(Stealth Fine-Tuning)的新攻击方法，可有效突破推理增强型视觉-语言模型（RVLMs）的安全对齐机制。该方法通过段级干扰诱发有害推理过程，并利用模型自生成内容作为监督微调数据，结合轮次加权损失设计，实现轻量、分布一致的微调。实验表明，仅需499个样本和单张A100显卡3小时内即可使攻击成功率（ASR）比现有方法IDEATOR高出38.52%，同时保持原始模型的通用推理能力。在AdvBench及多个通用基准测试中均验证了该方法低成本且高效绕过安全防御的能力。


<details>
  <summary>Details</summary>
Motivation: 现有推理增强型视觉-语言模型依赖安全对齐来防止有害行为，但其暴露的思维链（CoT）痕迹成为新的攻击入口。本文旨在揭示这一安全隐患，并开发一种高效、隐蔽的攻击方法以评估当前安全机制的脆弱性。

Method: 提出‘隐秘微调’方法，通过段级干扰诱导模型生成有害推理路径；将自生成输出用作微调数据；采用轮次加权损失函数，实现轻量化且分布一致的微调策略。

Result: 在仅使用499个样本、单张A100显卡3小时内完成微调的情况下，攻击成功率（ASR）相比IDEATOR提升38.52%，同时保留原模型的通用推理能力；在AdvBench及多个通用基准上均表现出显著攻击效果，证明该方法为低代价、高效率的对齐绕过手段。

Conclusion: 本研究揭示了推理增强型视觉-语言模型在安全对齐方面的严重漏洞，提出了一种高效、隐蔽且低成本的攻击方法——隐秘微调，能够有效绕过现有防御机制，提示需重新审视模型的推理透明性与安全性设计。

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [103] [Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding](https://arxiv.org/abs/2511.14112)
*Truong Vo,Weiyi Wu,Kaize Ding*

Main category: cs.CL

TL;DR: 本文提出一种数据驱动的框架，通过生成高质量的合成出院记录来缓解临床文本自动ICD编码中的长尾分布问题。该方法基于真实共现模式、ICD描述、同义词、分类体系和相似临床笔记，构建以罕见代码为中心的多标签代码集，并生成9万条涵盖7,902个ICD代码的合成数据。在原始与扩展数据集上微调PLM-ICD和GKI-ICD模型，实验显示宏观F1略有提升，微观F1保持良好，优于现有最先进方法。尽管增益相对计算成本较小，但结果表明精心设计的合成数据可提升罕见代码预测的公平性。


<details>
  <summary>Details</summary>
Motivation: 临床文本自动ICD编码面临严重的长尾分布问题，大量罕见和零样本ICD代码在数据集中严重不足，导致模型在这些类别上的表现差，尤其影响宏观F1指标。需要有效方法缓解数据不平衡问题。

Method: 提出一种数据中心框架，利用真实世界共现模式、ICD描述、同义词、分类体系及相似临床笔记，构建以罕见代码为核心的多标签代码集，并生成高保真合成出院记录，从而扩充训练数据分布。

Result: 在扩展数据集上微调PLM-ICD和GKI-ICD模型后，宏观F1得到小幅提升，微观F1保持稳定，优于现有最先进方法；表明合成数据能有效改善长尾类别预测性能。

Conclusion: 精心设计的合成数据可有效缓解罕见ICD代码的数据稀缺问题，提升模型对长尾类别的预测公平性，为医疗NLP中的数据不平衡挑战提供可行解决方案。

Abstract: Automatic ICD coding from clinical text is a critical task in medical NLP but remains hindered by the extreme long-tail distribution of diagnostic codes. Thousands of rare and zero-shot ICD codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. In this work, we propose a data-centric framework that generates high-quality synthetic discharge summaries to mitigate this imbalance. Our method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, we generate 90,000 synthetic notes covering 7,902 ICD codes, significantly expanding the training distribution. We fine-tune two state-of-the-art transformer-based models, PLM-ICD and GKI-ICD, on both the original and extended datasets. Experiments show that our approach modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain may seem marginal relative to the computational cost, our results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

</details>


### [104] [From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling](https://arxiv.org/abs/2511.14142)
*Omkar Mahesh Kashyap,Padegal Amit,Madhav Kashyap,Ashwini M Joshi,Shylaja SS*

Main category: cs.CL

TL;DR: 提出HyperABSA，一种基于动态超图的方面情感分析框架，通过样本特定的层次聚类构建方面-意见结构，引入新的加速-回退截断机制以自适应确定粒度。在三个基准数据集上优于强基线，尤其在使用RoBERTa时提升显著，证明该方法在短文本、低资源场景下的高效与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有图模型仅建模成对依赖关系，需构建多个图以捕捉不同关系视图，导致冗余、参数开销大及融合过程中的误差传播，限制了其在短文本、低资源场景下的表现。

Method: 提出动态超图框架HyperABSA，利用样本特定的层次聚类自动发现方面与意见之间的复杂关系，并引入加速-回退截断策略自适应控制聚类粒度，实现高效的超边构建。

Result: 在Lap14、Rest14、MAMS三个数据集上均取得一致性能提升，尤其在结合RoBERTa模型时表现出显著优势，验证了动态超图构造的有效性与可扩展性。

Conclusion: 动态超图建模为方面情感分析提供了一种高效且强大的新范式，尤其适用于短文本和低资源任务，具有向其他短文本NLP任务拓展的潜力。

Abstract: Aspect-Based Sentiment Analysis (ABSA) predicts sentiment polarity for specific aspect terms, a task made difficult by conflicting sentiments across aspects and the sparse context of short texts. Prior graph-based approaches model only pairwise dependencies, forcing them to construct multiple graphs for different relational views. These introduce redundancy, parameter overhead, and error propagation during fusion, limiting robustness in short-text, low-resource settings. We present HyperABSA, a dynamic hypergraph framework that induces aspect-opinion structures through sample-specific hierarchical clustering. To construct these hyperedges, we introduce a novel acceleration-fallback cutoff for hierarchical clustering, which adaptively determines the level of granularity. Experiments on three benchmarks (Lap14, Rest14, MAMS) show consistent improvements over strong graph baselines, with substantial gains when paired with RoBERTa backbones. These results position dynamic hypergraph construction as an efficient, powerful alternative for ABSA, with potential extensions to other short-text NLP tasks.

</details>


### [105] [Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions](https://arxiv.org/abs/2511.14144)
*Naoki Shimoda,Akihiro Yamamoto*

Main category: cs.CL

TL;DR: 本文提出一种结合Transformer-based关系抽取与知识图谱匹配的方法，用于回答填空式多选题（MCQs），同时保持输出过程的可追溯性。通过将自然语言句子转换为关系图并验证其与事实正确知识图谱的一致性，在封闭世界假设下评估问题句子的真实性。实验表明该方法能正确回答约70%的问题，并揭示问题类别对准确率有显著影响。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱构建成本高，被视为静态数据库；而基于Transformer的关系抽取技术使动态生成知识图谱成为可能，但若输入文本存在事实错误，则生成的知识图谱也可能包含虚假信息。因此需要一种机制来验证输入句子的真实性，以提高多选题答案的可靠性。

Method: 首先使用Transformer-based关系抽取方法将问题句子转换为关系图；然后在封闭世界假设下，将生成的关系图与已知的事实性知识图谱进行比对，验证其真实性；最后基于验证结果回答填空式多选题。

Result: 实验结果显示，该方法能够正确回答约70%的多选题，且整个推理过程具有良好的可追溯性。此外，问题类别对最终准确率有显著影响。

Conclusion: 本方法通过结合动态关系抽取与知识图谱验证，有效提升了多选题回答的准确性与可解释性，尤其适用于需保证事实一致性的场景。问题类别差异是影响性能的关键因素，未来工作应针对不同类别优化模型。

Abstract: In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the "fill-in-the-blank" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.

</details>


### [106] [Selective Weak-to-Strong Generalization](https://arxiv.org/abs/2511.14166)
*Hao Lang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 本文提出一种选择性弱到强泛化（Selective W2SG）框架，通过训练一个二分类器P(IK)来识别强模型可回答的问题，并利用其自生成标签进行对齐，同时采用图平滑方法优化弱标签。实验表明该方法在三个基准测试中均优于现有基线，且P(IK)具备跨任务和难度的泛化能力，支持超对齐的实现。


<details>
  <summary>Details</summary>
Motivation: 现有弱到强泛化方法依赖不变的弱监督，导致部分弱标签有害，影响模型鲁棒性；为缓解高质量数据缺乏问题，需在无需弱监督时避免使用弱标签。

Method: 训练二分类器P(IK)判断强模型能否回答问题，对可回答问题使用自生成标签进行对齐；结合图平滑方法进一步优化弱标签。

Result: 在三个基准测试中，所提方法持续优于竞争性基线；P(IK)展现出跨任务与难度的泛化能力，验证了选择性W2SG对超对齐的有效性。

Conclusion: 选择性弱到强泛化框架能有效避免不必要的弱监督，提升模型对齐质量与鲁棒性，推动超级人类模型的对齐研究。

Abstract: Future superhuman models will surpass the ability of humans and humans will only be able to \textit{weakly} supervise superhuman models. To alleviate the issue of lacking high-quality data for model alignment, some works on weak-to-strong generalization (W2SG) finetune a strong pretrained model with a weak supervisor so that it can generalize beyond weak supervision. However, the invariable use of weak supervision in existing methods exposes issues in robustness, with a proportion of weak labels proving harmful to models. In this paper, we propose a selective W2SG framework to avoid using weak supervision when unnecessary. We train a binary classifier P(IK) to identify questions that a strong model can answer and use its self-generated labels for alignment. We further refine weak labels with a graph smoothing method. Extensive experiments on three benchmarks show that our method consistently outperforms competitive baselines. Further analyses show that P(IK) can generalize across tasks and difficulties, which indicates selective W2SG can help superalignment.

</details>


### [107] [SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 本文提出首个基于符号语言学和语义知识的符号定位框架，用于系统追踪大模型中符号幻觉在各层的发展过程。通过分析五种模型在HaluEval和TruthfulQA上的表现，发现符号触发词（如否定、数字、命名实体）在早期层（2-4层）即引发注意力方差的剧烈波动，尤其否定词导致灾难性不稳定性。尽管模型规模增大，幻觉率仍维持在78.3%-83.7%的高位，且深层对符号语义触发词的注意力显著下降。研究揭示幻觉本质上是符号语言处理失败，而非泛化生成问题，强调符号语义知识是理解与定位幻觉机制的关键。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在面对符号触发词（如否定、数量、例外、命名实体）时仍存在严重幻觉，但缺乏对这些符号幻觉来源的清晰理解，尤其缺少基于符号语言学知识的系统性定位方法。现有统计方法（如LSC、激活方差分析）忽略符号语言结构的作用，无法有效识别符号触发如何导致幻觉。因此亟需一种以符号语言知识为基础的定位框架，来揭示幻觉在模型内部的演化机制。

Method: 提出首个符号定位框架，结合符号语言学与语义知识，聚焦模型对符号触发词的处理过程，通过分析注意力分布的变化，追踪幻觉在不同模型层中的发展轨迹。采用HaluEval和TruthfulQA作为评估基准，对五种模型进行实验，量化符号触发词在各层引起的注意力方差，并对比不同模型规模下的幻觉表现。

Result: 结果显示，符号触发词在早期层（2-4层）即引发注意力方差急剧上升，其中否定词导致最严重的不稳定性；尽管模型规模增加，幻觉率仍高达78.3%-83.7%，且深层对符号语义触发词的注意力持续下降。这表明幻觉并非一般生成错误，而是符号语义处理从初始阶段就开始崩溃的结果。

Conclusion: 幻觉本质上是符号语言处理失败，而非模型整体生成能力的问题。符号语义知识为理解与定位幻觉机制提供了关键路径，未来应围绕符号语言结构设计更鲁棒的模型架构与训练策略。

Abstract: LLMs still struggle with hallucination, especially when confronted with symbolic triggers like modifiers, negation, numbers, exceptions, and named entities. Yet, we lack a clear understanding of where these symbolic hallucinations originate, making it crucial to systematically handle such triggers and localize the emergence of hallucination inside the model. While prior work explored localization using statistical techniques like LSC and activation variance analysis, these methods treat all tokens equally and overlook the role symbolic linguistic knowledge plays in triggering hallucinations. So far, no approach has investigated how symbolic elements specifically drive hallucination failures across model layers, nor has symbolic linguistic knowledge been used as the foundation for a localization framework. We propose the first symbolic localization framework that leverages symbolic linguistic and semantic knowledge to meaningfully trace the development of hallucinations across all model layers. By focusing on how models process symbolic triggers, we analyze five models using HaluEval and TruthfulQA. Our symbolic knowledge approach reveals that attention variance for these linguistic elements explodes to critical instability in early layers (2-4), with negation triggering catastrophic variance levels, demonstrating that symbolic semantic processing breaks down from the very beginning. Through the lens of symbolic linguistic knowledge, despite larger model sizes, hallucination rates remain consistently high (78.3%-83.7% across Gemma variants), with steep attention drops for symbolic semantic triggers throughout deeper layers. Our findings demonstrate that hallucination is fundamentally a symbolic linguistic processing failure, not a general generation problem, revealing that symbolic semantic knowledge provides the key to understanding and localizing hallucination mechanisms in LLMs.

</details>


### [108] [Harnessing Deep LLM Participation for Robust Entity Linking](https://arxiv.org/abs/2511.14181)
*Jiajun Hou,Chenyu Zhang,Rui Meng*

Main category: cs.CL

TL;DR: DeepEL is a comprehensive framework that integrates Large Language Models (LLMs) into every stage of the entity linking (EL) task, addressing the limitation of prior methods that apply LLMs in isolated stages. It introduces a self-validation mechanism using global context to improve disambiguation and capture cohesive relationships among entities. Evaluated on ten benchmark datasets, DeepEL achieves an average 2.6% improvement in F1 score and up to 4% gain on out-of-domain data, demonstrating significant advances in EL performance.


<details>
  <summary>Details</summary>
Motivation: Prior approaches leverage LLMs only in isolated stages of entity linking, limiting their full potential. Disambiguating entities in isolation is insufficient for optimal performance, especially in capturing contextual relationships across entities in a sentence.

Method: DeepEL integrates LLMs throughout all stages of EL. It employs a novel self-validation mechanism that uses global contextual information to allow LLMs to correct their own predictions and better recognize inter-entity relationships within the same sentence.

Result: DeepEL outperforms existing state-of-the-art methods across ten benchmark datasets, achieving an average 2.6% increase in F1 score and a 4% improvement on out-of-domain datasets.

Conclusion: The deep integration of LLMs into all stages of entity linking, combined with a self-validation mechanism leveraging global context, significantly enhances EL performance and sets a new benchmark in the field.

Abstract: Entity Linking (EL), the task of mapping textual entity mentions to their corresponding entries in knowledge bases, constitutes a fundamental component of natural language understanding. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable potential for enhancing EL performance. Prior research has leveraged LLMs to improve entity disambiguation and input representation, yielding significant gains in accuracy and robustness. However, these approaches typically apply LLMs to isolated stages of the EL task, failing to fully integrate their capabilities throughout the entire process.
  In this work, we introduce DeepEL, a comprehensive framework that incorporates LLMs into every stage of the entity linking task. Furthermore, we identify that disambiguating entities in isolation is insufficient for optimal performance. To address this limitation, we propose a novel self-validation mechanism that utilizes global contextual information, enabling LLMs to rectify their own predictions and better recognize cohesive relationships among entities within the same sentence.
  Extensive empirical evaluation across ten benchmark datasets demonstrates that DeepEL substantially outperforms existing state-of-the-art methods, achieving an average improvement of 2.6\% in overall F1 score and a remarkable 4% gain on out-of-domain datasets. These results underscore the efficacy of deep LLM integration in advancing the state-of-the-art in entity linking.

</details>


### [109] [ArbESC+: Arabic Enhanced Edit Selection System Combination for Grammatical Error Correction Resolving conflict and improving system combination in Arabic GEC](https://arxiv.org/abs/2511.14230)
*Ahlam Alrehili,Areej Alhothali*

Main category: cs.CL

TL;DR: 本文提出了一种名为ArbESC+的多系统阿拉伯语语法错误纠正框架，通过整合AraT5、ByT5、mT5、AraBART、AraBART+Morph+GEC和文本编辑系统等多种模型，利用数值特征与分类器实现更优的纠错效果。该方法在QALB-14、QALB-15 L1和L2数据集上分别取得82.63%、84.64%和65.55%的F0.5分数，显著优于单一模型，并首次实现了阿拉伯语语法纠错的系统性集成，为阿拉伯语自然语言处理提供了重要进展。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有复杂的形态和句法结构，传统单模型方法在语法错误纠正方面存在局限性，亟需更高效的集成方法以提升纠错性能。

Method: 提出ArbESC+多系统框架，融合多种预训练模型生成纠错建议，将建议转化为数值特征，通过分类器选择最优修正方案，并引入支持技术过滤重复修正并评估决策可靠性。

Result: 在QALB-14测试集上达到82.63% F0.5，在QALB-15 L1数据集上达84.64%，在QALB-15 L2数据集上达65.55%，显著优于单一模型表现。

Conclusion: ArbESC+是首个针对阿拉伯语语法错误纠正的多系统集成框架，有效提升了纠错准确率，为未来阿拉伯语文本处理工具的发展奠定了坚实基础。

Abstract: Grammatical Error Correction (GEC) is an important aspect of natural language processing. Arabic has a complicated morphological and syntactic structure, posing a greater challenge than other languages. Even though modern neural models have improved greatly in recent years, the majority of previous attempts used individual models without taking into account the potential benefits of combining different systems. In this paper, we present one of the first multi-system approaches for correcting grammatical errors in Arabic, the Arab Enhanced Edit Selection System Complication (ArbESC+). Several models are used to collect correction proposals, which are represented as numerical features in the framework. A classifier determines and implements the appropriate corrections based on these features. In order to improve output quality, the framework uses support techniques to filter overlapping corrections and estimate decision reliability. A combination of AraT5, ByT5, mT5, AraBART, AraBART+Morph+GEC, and Text editing systems gave better results than a single model alone, with F0.5 at 82.63% on QALB-14 test data, 84.64% on QALB-15 L1 data, and 65.55% on QALB-15 L2 data. As one of the most significant contributions of this work, it's the first Arab attempt to integrate linguistic error correction. Improving existing models provides a practical step towards developing advanced tools that will benefit users and researchers of Arabic text processing.

</details>


### [110] [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)
*Kai Tian,Yirong Mao,Wendong Bi,Hanjie Wang,Que Wenhui*

Main category: cs.CL

TL;DR: 本文构建了一个包含400亿词元的大规模音乐相关自然语言语料库，结合开源与内部数据，并提出领域优先的数据处理流程：通过轻量级分类器筛选和加权领域内文本，再经多阶段清洗、去重及隐私保护掩码处理。同时融合多源音乐文本与元数据，形成更广泛、结构化的领域知识基础。在训练方面，引入基于参考模型（RM）的令牌级软评分机制，采用统一的损失比标准进行数据选择与优化过程中的动态降权，降低噪声梯度，增强任务对齐信号，从而实现更有效的音乐领域持续预训练与对齐。为评估事实性，设计了MusicSimpleQA基准，采用短单答提示与自动化一致性评分。通过系统性比较不同数据构成，本文在数据与目标上均取得进展，提供可扩展的数据-训练框架与可复用的评估工具，推动音乐领域大模型的发展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用任务上表现优异，但在音乐等专业领域受限，尤其在音乐娱乐场景中，语料规模、纯净度以及数据与训练目标的匹配度至关重要。现有方法在音乐领域数据质量和训练目标适配上存在不足，亟需构建高质量、领域特定的语料库与针对性训练策略。

Method: 构建大规模音乐相关自然语言语料库（40B tokens），整合开源与内部数据；设计领域优先的数据管道，包括轻量级分类器过滤与加权、多阶段清洗、去重与隐私掩码；融合多源音乐文本与元数据以增强领域知识；引入基于参考模型（RM）的令牌级软评分机制，利用统一损失比准则进行数据选择与动态降权，提升训练质量；设计MusicSimpleQA基准用于评估事实性。

Result: 成功构建了高质量、大规模的音乐领域语料库，实现了更有效的音乐领域持续预训练与对齐；提出的训练机制显著降低了噪声梯度，增强了任务对齐信号；MusicSimpleQA基准提供了可靠的自动化评估手段；系统性实验表明，数据组成对模型性能有显著影响，验证了所提框架的有效性与可扩展性。

Conclusion: 本研究在音乐领域大模型建设中，实现了从优质语料到精准训练目标的双重突破，提出了一个可复用、可扩展的数据-训练框架与评估工具，为构建高性能音乐领域语言模型提供了坚实基础。

Abstract: Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, music-related natural language corpus (40B tokens) that combines open source and in-house data, and by implementing a domain-first data pipeline: a lightweight classifier filters and weights in-domain text, followed by multi-stage cleaning, de-duplication, and privacy-preserving masking. We further integrate multi-source music text with associated metadata to form a broader, better-structured foundation of domain knowledge. On the training side, we introduce reference-model (RM)-based token-level soft scoring for quality control: a unified loss-ratio criterion is used both for data selection and for dynamic down-weighting during optimization, reducing noise gradients and amplifying task-aligned signals, thereby enabling more effective music-domain continued pretraining and alignment. To assess factuality, we design the MusicSimpleQA benchmark, which adopts short, single-answer prompts with automated agreement scoring. Beyond the benchmark design, we conduct systematic comparisons along the axes of data composition. Overall, this work advances both the right corpus and the right objective, offering a scalable data-training framework and a reusable evaluation tool for building domain LLMs in the music field.

</details>


### [111] [Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249)
*Rui Liu,Yuan Zhao,Zhenqi Jia*

Main category: cs.CL

TL;DR: 提出Authentic-Dubber模型，通过模拟导演-演员互动学习机制，实现更真实的电影配音。引入多模态参考视频库、基于情感相似性的检索增强策略以及渐进式图结构语音生成方法，显著提升情感表达的真实性与同步性。


<details>
  <summary>Details</summary>
Motivation: 现有自动配音模型忽略导演与演员之间的动态协作过程，仅模拟简单直接的配音流程，无法真实还原实际工作中的情感内化与指导环节。为解决此问题，需构建更符合真实配音流程的模型。

Method: 1. 构建融合多模态信号的参考视频库，并利用大语言模型理解情感表征；2. 设计基于情感相似性的检索增强策略，从参考库中提取与目标视频最相关的情感信息；3. 采用渐进式图结构语音生成方法，逐步融入检索到的情感知识，模拟演员最终配音过程。

Result: 在V2C动画基准数据集上的主观与客观评估均证明该方法在情感表达丰富性和唇形同步性方面有显著提升，接近真实配音效果。代码与演示已开源。

Conclusion: Authentic-Dubber成功模拟了导演-演员间的真实互动流程，通过多模态情感信息的检索与渐进式融合，实现了更具表现力和真实感的自动电影配音，推动了语音生成向更自然的人机协同方向发展。

Abstract: The automatic movie dubbing model generates vivid speech from given scripts, replicating a speaker's timbre from a brief timbre prompt while ensuring lip-sync with the silent video. Existing approaches simulate a simplified workflow where actors dub directly without preparation, overlooking the critical director-actor interaction. In contrast, authentic workflows involve a dynamic collaboration: directors actively engage with actors, guiding them to internalize the context cues, specifically emotion, before performance. To address this issue, we propose a new Retrieve-Augmented Director-Actor Interaction Learning scheme to achieve authentic movie dubbing, termed Authentic-Dubber, which contains three novel mechanisms: (1) We construct a multimodal Reference Footage library to simulate the learning footage provided by directors. Note that we integrate Large Language Models (LLMs) to achieve deep comprehension of emotional representations across multimodal signals. (2) To emulate how actors efficiently and comprehensively internalize director-provided footage during dubbing, we propose an Emotion-Similarity-based Retrieval-Augmentation strategy. This strategy retrieves the most relevant multimodal information that aligns with the target silent video. (3) We develop a Progressive Graph-based speech generation approach that incrementally incorporates the retrieved multimodal emotional knowledge, thereby simulating the actor's final dubbing process. The above mechanisms enable the Authentic-Dubber to faithfully replicate the authentic dubbing workflow, achieving comprehensive improvements in emotional expressiveness. Both subjective and objective evaluations on the V2C Animation benchmark dataset validate the effectiveness. The code and demos are available at https://github.com/AI-S2-Lab/Authentic-Dubber.

</details>


### [112] [AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR](https://arxiv.org/abs/2511.14255)
*Gabrial Zencha Ashungafac,Mardhiyah Sanni,Busayo Awobade,Alex Gichamba,Tobi Olatunji*

Main category: cs.CL

TL;DR: AfriSpeech-MultiBench 是首个针对非洲英语口音的专用评估基准，涵盖10+国家、100+口音和7个应用领域。评估了多种开源、闭源、单模态ASR及多模态大模型，发现开源ASR在自然语音中表现好但对非标准对话降级；多模态模型抗口音能力强但命名实体识别差；闭源模型在清晰语音上准确率高但跨国家/领域差异大；微调后的模型精度高且延迟低，但幻觉问题仍严重。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对非洲语言多样性的语音接口评估工具，而语音技术在全球迅速发展，亟需适合非洲场景的评测体系以推动包容性语音应用的发展。

Method: 构建AfriSpeech-MultiBench评估套件，基于多个公开非洲英语口音语料库，涵盖自发与非自发语音，评估多种ASR与多模态大模型在金融、法律、医疗等七大领域的表现。

Result: 开源ASR在自然语音中表现优异但在噪声或非标准对话中性能下降；多模态模型口音鲁棒性强但命名实体识别能力弱；闭源模型在干净语音中准确率高但存在国家与领域间差异；微调模型具有竞争力的精度与更低延迟，但幻觉问题普遍存在。

Conclusion: 通过发布该基准，为研究人员和实践者提供适配非洲场景的语音技术选型依据，助力开发更包容、服务于边缘群体的语音应用。

Abstract: Recent advances in speech-enabled AI, including Google's NotebookLM and OpenAI's speech-to-speech API, are driving widespread interest in voice interfaces globally. Despite this momentum, there exists no publicly available application-specific model evaluation that caters to Africa's linguistic diversity. We present AfriSpeech-MultiBench, the first domain-specific evaluation suite for over 100 African English accents across 10+ countries and seven application domains: Finance, Legal, Medical, General dialogue, Call Center, Named Entities and Hallucination Robustness. We benchmark a diverse range of open, closed, unimodal ASR and multimodal LLM-based speech recognition systems using both spontaneous and non-spontaneous speech conversation drawn from various open African accented English speech datasets. Our empirical analysis reveals systematic variation: open-source ASR models excels in spontaneous speech contexts but degrades on noisy, non-native dialogue; multimodal LLMs are more accent-robust yet struggle with domain-specific named entities; proprietary models deliver high accuracy on clean speech but vary significantly by country and domain. Models fine-tuned on African English achieve competitive accuracy with lower latency, a practical advantage for deployment, hallucinations still remain a big problem for most SOTA models. By releasing this comprehensive benchmark, we empower practitioners and researchers to select voice technologies suited to African use-cases, fostering inclusive voice applications for underserved communities.

</details>


### [113] [Entropy-Guided Reasoning Compression](https://arxiv.org/abs/2511.14258)
*Hourun Zhu,Yang Gao,Wenlong Fei,Jiawei Li,Huashan Sun*

Main category: cs.CL

TL;DR: 本文提出了一种熵引导的训练框架，以解决大推理模型在链式思维输出过长带来的计算成本高和部署困难问题。传统压缩方法忽视了训练过程中的熵冲突现象：压缩目标降低熵导致探索不足，而准确率目标增加熵又延长推理链。本文揭示该冲突源于逻辑连接词在性能目标下获得更大梯度，却在压缩目标下被惩罚，形成矛盾压力。为此，所提方法根据熵的变化动态调整训练策略，熵下降时鼓励简洁推理，熵上升时增强探索以提升鲁棒性。在六个数学基准上的实验表明，该方法可将推理长度压缩至原长的20%，同时保持或超越基线准确率。


<details>
  <summary>Details</summary>
Motivation: 现有压缩方法未能有效解决大推理模型链式思维输出过长的问题，尤其忽视了训练过程中熵冲突这一关键现象，即压缩目标与准确率目标对熵的影响相互矛盾，导致模型陷入局部困境。

Method: 提出一种熵引导的训练框架，根据训练过程中熵的变化动态调整策略：当熵下降时，强化简洁推理；当熵上升时，增强探索能力，从而缓解熵冲突，提升推理效率与鲁棒性。

Result: 在六个数学基准测试中，该方法将推理长度压缩至原始长度的20%，同时保持甚至超过基线模型的准确率，验证了其有效性与优越性。

Conclusion: 通过引入熵引导机制，有效缓解了训练过程中的熵冲突问题，实现了高效且准确的推理压缩，为大模型推理优化提供了新思路。

Abstract: Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.

</details>


### [114] [Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space](https://arxiv.org/abs/2511.14275)
*Ante Wang,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出通过预测口语化概率分布来促进大模型进行深度推理以估计置信度，该方法能促使模型全面考虑答案空间中的所有候选，并合理分配置信度，从而提升置信度估计的准确性。该方法在不同模型和任务中均表现优越，且在强化学习后仍保持优势，其推理模式也与人类预期一致。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在生成置信度时，虽已结合链式思维推理以提高透明性，但不同推理策略对置信度估计的影响仍不明确。因此需要探索更有效的置信度估计方法，以增强模型输出的可靠性与可解释性。

Method: 提出让大模型预测一个口语化的概率分布，以强制其在回答空间中全面考虑所有可能选项，并精细分配置信度，从而实现更深入的推理和更准确的置信度估计。

Result: 该方法在多种模型和任务上均优于传统方法，无论答案空间是否已知；即使经过强化学习优化，优势依然存在；且其推理过程与人类直觉高度一致。

Conclusion: 预测口语化概率分布是一种有效提升大模型置信度估计质量的方法，能够引导模型进行更全面、更合理的推理，显著增强模型输出的可靠性与可信度。

Abstract: Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.

</details>


### [115] [AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models](https://arxiv.org/abs/2511.14295)
*Mohammad Zbib,Hasan Abed Al Kader Hammoud,Sina Mukalled,Nadine Rizk,Fatima Karnib,Issam Lakkis,Ammar Mohanna,Bernard Ghanem*

Main category: cs.CL

TL;DR: AraLingBench 是一个全面的人工标注基准，用于评估大语言模型（LLMs）在阿拉伯语语言能力方面的表现。该基准涵盖语法、形态、拼写、阅读理解和句法五个核心类别，包含150道专家设计的多项选择题，旨在直接测试语言结构理解能力。对35个阿拉伯语及双语LLMs的评估显示，当前模型虽在表层层面表现出色，但在深层语法和句法推理方面存在困难。该研究揭示了知识型基准高分与真正语言掌握之间的持续差距，表明许多模型依赖记忆或模式识别而非真实理解。AraLingBench 提供了一种诊断框架，有助于推动阿拉伯语LLMs的发展。完整评估代码已公开于GitHub。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准未能有效衡量大语言模型在阿拉伯语中的真实语言理解能力，尤其在深层语法和句法推理方面存在不足。为填补这一空白，需要一个专注于阿拉伯语语言结构理解的高质量人工标注基准，以更准确地评估模型的语言能力。

Method: 构建一个涵盖五个核心语言学领域的基准：语法、形态、拼写、阅读理解和句法；由专家设计150道多项选择题，确保问题聚焦于语言结构理解；对35个阿拉伯语及双语大语言模型进行系统评估；通过对比模型在不同任务上的表现，分析其语言理解深度。

Result: 评估结果显示，大多数模型在表面层面表现良好，但在涉及深层语法和句法推理的任务上表现不佳。这表明当前模型更多依赖记忆或模式识别，而非真正的语言理解。该基准有效揭示了模型在语言能力上的局限性，并为后续改进提供了方向。

Conclusion: AraLingBench 为评估阿拉伯语大语言模型的语言能力提供了一个可靠且可诊断的基准。它不仅揭示了当前模型在深层语言理解方面的不足，还强调了开发更注重语言结构理解而非单纯知识记忆的模型的重要性。该基准及其代码的公开将促进阿拉伯语自然语言处理技术的发展。

Abstract: We present AraLingBench: a fully human annotated benchmark for evaluating the Arabic linguistic competence of large language models (LLMs). The benchmark spans five core categories: grammar, morphology, spelling, reading comprehension, and syntax, through 150 expert-designed multiple choice questions that directly assess structural language understanding. Evaluating 35 Arabic and bilingual LLMs reveals that current models demonstrate strong surface level proficiency but struggle with deeper grammatical and syntactic reasoning. AraLingBench highlights a persistent gap between high scores on knowledge-based benchmarks and true linguistic mastery, showing that many models succeed through memorization or pattern recognition rather than authentic comprehension. By isolating and measuring fundamental linguistic skills, AraLingBench provides a diagnostic framework for developing Arabic LLMs. The full evaluation code is publicly available on GitHub.

</details>


### [116] [ConInstruct: Evaluating Large Language Models on Conflict Detection and Resolution in Instructions](https://arxiv.org/abs/2511.14342)
*Xingwei He,Qianru Zhang,Pengfei Chen,Guanhua Chen,Linlin Yu,Yuan Yuan,Siu-Ming Yiu*

Main category: cs.CL

TL;DR: 本文提出ConInstruct基准，用于评估大语言模型（LLMs）在存在冲突约束的复杂指令下的冲突检测与解决能力。实验发现，多数专有模型具备较强的冲突检测能力，其中DeepSeek-R1和Claude-4.5-Sonnet表现最佳（F1分数分别为91.5%和87.3%），但大多数模型在识别冲突后未主动告知用户或请求澄清，暴露出当前LLMs在指令遵循中的关键缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLMs对用户指令的遵循程度，却忽视了指令中常见冲突约束情境，导致模型在复杂提示下的行为尚不明确，亟需系统评估其冲突处理能力。

Method: 构建ConInstruct基准数据集，涵盖多种类型的冲突指令，用于评估不同LLMs在冲突检测与解决方面的表现，并通过定量分析其响应行为。

Result: 1. 专有模型普遍具备强冲突检测能力，仅DeepSeek-R1在开源模型中表现接近；2. 尽管能检测冲突，但绝大多数模型未主动提醒用户或请求澄清，暴露了指令遵循机制的重大缺陷。

Conclusion: 当前大语言模型虽在冲突检测上表现良好，但在冲突反馈与交互方面严重不足，未来应重点提升模型在复杂、矛盾指令下的透明性与交互能力。

Abstract: Instruction-following is a critical capability of Large Language Models (LLMs). While existing works primarily focus on assessing how well LLMs adhere to user instructions, they often overlook scenarios where instructions contain conflicting constraints-a common occurrence in complex prompts. The behavior of LLMs under such conditions remains under-explored. To bridge this gap, we introduce ConInstruct, a benchmark specifically designed to assess LLMs' ability to detect and resolve conflicts within user instructions. Using this dataset, we evaluate LLMs' conflict detection performance and analyze their conflict resolution behavior. Our experiments reveal two key findings: (1) Most proprietary LLMs exhibit strong conflict detection capabilities, whereas among open-source models, only DeepSeek-R1 demonstrates similarly strong performance. DeepSeek-R1 and Claude-4.5-Sonnet achieve the highest average F1-scores at 91.5% and 87.3%, respectively, ranking first and second overall. (2) Despite their strong conflict detection abilities, LLMs rarely explicitly notify users about the conflicts or request clarification when faced with conflicting constraints. These results underscore a critical shortcoming in current LLMs and highlight an important area for future improvement when designing instruction-following LLMs.

</details>


### [117] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出ATLAS，一个大规模、高难度、跨学科的科学推理评估基准，包含约800个由领域专家原创或大幅改编的问题，覆盖数学、物理、化学、生物、计算机、地球科学和材料科学七个领域。其特点包括高原创性与抗数据泄露、跨学科知识整合能力评估、高保真复杂答案（如多步推理与LaTeX表达式）以及严格的多阶段质量控制。同时引入基于LLM评判员的自动化评估范式，有效区分领先模型的科学推理能力。旨在构建一个开放、可持续的社区平台，为通用人工智能进展提供可靠衡量标准。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在主流基准上性能趋于饱和，难以区分前沿模型；而现有高难度基准存在领域狭窄、答案形式简单、易受数据污染等问题，无法真实反映科学探究中的复杂推理能力。因此亟需一个更具挑战性、更贴近真实科研场景的评估体系。

Method: 构建ATLAS评估基准，由博士及以上水平专家设计问题，确保原创性和科学严谨性；采用多阶段专家评审与对抗测试保证质量；设计支持复杂推理与开放式回答的题型；引入一组LLM评判员进行自动化、精细化的答案评估。

Result: 初步实验表明，ATLAS能够有效区分主流先进模型在科学推理方面的差异，具备良好的区分度和评估价值；该基准可作为衡量AGI发展的重要工具。

Conclusion: ATLAS是一个高质量、跨学科、高难度的科学推理评估体系，不仅克服了现有基准的局限性，还为未来大模型在真实科研场景中的能力评估提供了可靠框架。未来将推动其成为开放、社区驱动的长期评估平台，助力通用人工智能的发展。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [118] [Mitigating Label Length Bias in Large Language Models](https://arxiv.org/abs/2511.14385)
*Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: 本文提出了一种名为标准化上下文校准（NCC）的新方法，用于缓解大语言模型在多标记类别标签中因标签长度不同而产生的标签长度偏差问题。NCC通过在完整标签层面进行归一化和校准，显著提升了多个数据集和模型上的性能，F1得分最高提升达10%。该方法还增强了对少样本示例选择的鲁棒性，并改善了置信度估计的可靠性，适用于多选题问答等更广泛任务。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理候选选项预测时存在标签偏差，尤其是多标记标签的长度偏差问题，现有校准方法未能有效解决此问题，影响了模型的准确性和可靠性。

Method: 提出标准化上下文校准（NCC），在完整标签层面进行归一化与校准，以消除标签长度带来的不一致性。

Result: NCC在多个数据集和模型上均取得显著优于先前方法的结果，最大F1提升达10%，且在少样本学习场景下表现更稳定，置信度估计更可靠。

Conclusion: 消除完整标签层面的偏差对于提升大语言模型在真实应用中的性能与鲁棒性至关重要，NCC为解决此类问题提供了有效方案。

Abstract: Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.

</details>


### [119] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 本文构建了EduHarm基准，涵盖五个典型教育场景的安全-不安全指令对，用于系统评估教育类大模型的安全性。提出三阶段防护框架（TSSF），通过注意力重定向、分层安全判断和防御驱动双路由机制，同时抵御越狱攻击与微调攻击。实验表明，TSSF在八种越狱攻击下有效提升安全性，避免误拒良性查询；在三种微调攻击数据集上也表现出稳健的防御能力，同时保持良性微调带来的性能增益。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注通用安全性评估，忽视教育场景特有的安全需求。教育类大模型易受越狱和微调攻击，导致安全对齐失效并产生有害输出，亟需针对性的安全评估与防护机制。

Method: 提出三阶段盾构框架（TSSF）：1）安全感知注意力重定向，增强对危险标记的关注，恢复有害性特征；2）分层安全判断，聚合多层安全线索以识别有害指令；3）防御驱动双路由，分离安全与不安全查询，确保良性输入正常处理，有害输入获得受控响应。

Result: 在8种越狱攻击策略下，TSSF显著提升安全性，且未过度拒绝良性请求；在3个微调攻击数据集上，持续有效防御有害查询，同时保留良性微调带来的性能提升。

Conclusion: EduHarm基准和TSSF框架为教育类大模型提供了系统性的安全评估与防护方案，有效应对越狱与微调攻击，在保障安全性的同时维持模型实用性。

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>


### [120] [MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents](https://arxiv.org/abs/2511.14439)
*Jinru Ding,Lu Lu,Chao Ding,Mouxiao Bian,Jiayuan Chen,Renjie Lu,Wenrao Pang,Xiaoqin Wu,Zhiqiang Liu,Luyi Jiang,Bing Han,Yunqiu Wang,Jie Xu*

Main category: cs.CL

TL;DR: MedBench v4 是一个全国性、基于云的基准测试基础设施，包含超过70万项专家标注的任务，覆盖24个主要和91个次要医学专科，专为评估医疗大模型（LLMs）、多模态模型和智能体（agents）而设计。任务经过多轮临床专家评审，开放回答由经过人类评分校准的LLM-as-a-judge进行评分。评估显示，基础大模型平均得分为54.1/100（最佳：Claude Sonnet 4.5，62.5/100），但安全与伦理表现较差（18.4/100）；多模态模型整体表现更差（平均47.5/100），感知能力强但跨模态推理弱；基于相同底座构建的智能体显著提升端到端性能（平均79.8/100），其中基于Claude Sonnet 4.5的智能体在安全性任务上达到88.9/100。研究揭示了基础模型在多模态推理和安全性方面的不足，同时表明具备治理意识的智能体编排可大幅提高临床可用性。平台依据中国临床指南与监管重点设计，为医院、开发者和政策制定者提供实用参考。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI评估框架难以反映真实临床工作流程和安全约束，亟需更贴近实际应用的评测体系。随着医疗大模型、多模态模型和智能体的发展，必须建立全面、权威、可扩展的评估基础设施以支撑技术发展与监管合规。

Method: 构建覆盖广泛医学专科的多任务基准集，通过来自500多家医疗机构的临床专家进行多阶段筛选与多轮评审，确保任务质量与临床相关性；采用经人类评分校准的LLM-as-a-judge对开放回答进行自动评分；分别评估基础大模型、多模态模型和智能体三类系统，并对比其在综合性能与安全伦理方面的表现。

Result: 基础大模型平均得分54.1/100，安全伦理仅18.4/100；多模态模型平均47.5/100，感知强但跨模态推理弱；智能体平均达79.8/100，最高达85.3/100，尤其在安全任务上表现优异（88.9/100）。结果表明，智能体架构可通过治理驱动的协同机制显著提升临床就绪度。

Conclusion: 当前基础模型在多模态推理与安全性方面仍存在明显短板，而基于治理意识的智能体编排能够有效弥补这些缺陷，显著提升医疗AI系统的临床适用性与可信度。MedBench v4为医疗AI的开发、评估与监管提供了重要实践参考。

Abstract: Recent advances in medical large language models (LLMs), multimodal models, and agents demand evaluation frameworks that reflect real clinical workflows and safety constraints. We present MedBench v4, a nationwide, cloud-based benchmarking infrastructure comprising over 700,000 expert-curated tasks spanning 24 primary and 91 secondary specialties, with dedicated tracks for LLMs, multimodal models, and agents. Items undergo multi-stage refinement and multi-round review by clinicians from more than 500 institutions, and open-ended responses are scored by an LLM-as-a-judge calibrated to human ratings. We evaluate 15 frontier models. Base LLMs reach a mean overall score of 54.1/100 (best: Claude Sonnet 4.5, 62.5/100), but safety and ethics remain low (18.4/100). Multimodal models perform worse overall (mean 47.5/100; best: GPT-5, 54.9/100), with solid perception yet weaker cross-modal reasoning. Agents built on the same backbones substantially improve end-to-end performance (mean 79.8/100), with Claude Sonnet 4.5-based agents achieving up to 85.3/100 overall and 88.9/100 on safety tasks. MedBench v4 thus reveals persisting gaps in multimodal reasoning and safety for base models, while showing that governance-aware agentic orchestration can markedly enhance benchmarked clinical readiness without sacrificing capability. By aligning tasks with Chinese clinical guidelines and regulatory priorities, the platform offers a practical reference for hospitals, developers, and policymakers auditing medical AI.

</details>


### [121] [Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.14460)
*Mingyue Cheng,Jie Ouyang,Shuo Yu,Ruiran Yan,Yucong Luo,Zirui Liu,Daoyu Wang,Qi Liu,Enhong Chen*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLM）智能体在复杂问题求解中应用强化学习（RL）的挑战，系统性地扩展了马尔可夫决策过程（MDP）框架以明确定义LLM智能体的关键组件，并提出一个模块化、灵活且用户友好的训练框架Agent-R1，支持多种任务场景和交互环境的快速适配。实验在多跳问答基准任务上验证了方法与框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在大语言模型智能体中的应用仍处于初级阶段，面临方法不明确、缺乏灵活可扩展训练框架等挑战，亟需系统性研究与工具支持。

Method: 通过扩展马尔可夫决策过程（MDP）框架来定义LLM智能体的核心要素，并设计并实现了一个名为Agent-R1的模块化、可扩展的强化学习训练框架。

Result: 在多跳问答任务上的实验表明，所提出的框架与方法能够有效支持基于强化学习的LLM智能体训练，具备良好的适应性和有效性。

Conclusion: 本研究为强化学习在大语言模型智能体中的应用提供了理论框架与实践工具，推动了该领域向更系统化和实用化的方向发展。

Abstract: Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.

</details>


### [122] [LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation](https://arxiv.org/abs/2511.14531)
*David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Alex Shtoff,Oren Somekh,Ran Tavory*

Main category: cs.CL

TL;DR: LiveRAG是一个公开的合成问答数据集，包含895个问题和答案，用于系统评估基于RAG的问答系统。该数据集源自SIGIR'2025 LiveRAG挑战赛，并补充了比赛期间未公开的真值答案及支持性论据，还引入了基于项目反应理论的难度与区分度评分，以衡量问题质量。其多样性和不同难度水平有助于区分不同系统的性能，推动RAG研究与更鲁棒问答系统的发展。


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成（RAG）在生成式AI中的广泛应用，亟需一种系统化的方法来评估其有效性。现有评估方法缺乏全面性和可重复性，因此需要一个高质量、结构化的基准测试数据集。

Method: 基于SIGIR'2025 LiveRAG挑战赛的合成数据，构建了一个包含895个问题的公开数据集；通过项目反应理论（IRT）模型对参赛者回答进行分析，计算每个问题的难度与区分度得分；并标注真值答案及其支持性证据，以支持精确评估。

Result: 该基准展示了问题的多样性、广泛分布的难度水平，并能有效区分不同系统的能力表现。实证分析表明，该数据集具有良好的评估价值，适用于系统性评估RAG模型性能。

Conclusion: LiveRAG基准为社区提供了一个高质量、可复现的评估工具，有助于推动RAG技术的研究与应用，提升问答系统的鲁棒性与可靠性。

Abstract: With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.

</details>


### [123] [Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak](https://arxiv.org/abs/2511.14566)
*Lucia Makaiová,Martin Fajčík,Antonín Jarolím*

Main category: cs.CL

TL;DR: 本文研究文档级声明提取的评估问题，提出一种通过对齐评分来比较模型提取与人工标注声明集的方法，旨在建立可靠的评估框架。在捷克和斯洛伐克新闻评论数据上进行实验，揭示现有评估方法在处理非正式语言、地方语境及语言细微差异时的局限性，强调需发展更先进的方法以准确捕捉语义相似性并评估声明的原子性、可验证性和去上下文化等关键属性。


<details>
  <summary>Details</summary>
Motivation: 文档级声明提取在事实核查领域仍面临挑战，且现有方法对提取声明的评估关注不足。当前评估手段难以有效衡量模型性能或标注者间一致性，尤其在面对非正式语言和复杂语境时表现不佳，亟需更可靠的评估框架。

Method: 提出一种基于对齐的声明集相似性计算方法，通过寻找最佳声明间的对应关系并计算对齐得分，实现模型提取与人工标注声明集的比较，从而评估模型性能和标注一致性。

Result: 实验表明，现有评估方法在处理捷克和斯洛伐克新闻评论中的声明提取任务时存在明显局限，特别是在捕捉语义相似性及判断声明的原子性、可验证性、去上下文化等属性方面表现不足，凸显了开发更先进评估方法的必要性。

Conclusion: 当前评估方法不足以应对文档级声明提取的复杂性，未来需发展能够准确识别语义相似性并评估声明核心属性的新方法，以提升模型评估与标注一致性度量的可靠性。

Abstract: Document-level claim extraction remains an open challenge in the field of fact-checking, and subsequently, methods for evaluating extracted claims have received limited attention. In this work, we explore approaches to aligning two sets of claims pertaining to the same source document and computing their similarity through an alignment score. We investigate techniques to identify the best possible alignment and evaluation method between claim sets, with the aim of providing a reliable evaluation framework. Our approach enables comparison between model-extracted and human-annotated claim sets, serving as a metric for assessing the extraction performance of models and also as a possible measure of inter-annotator agreement. We conduct experiments on newly collected dataset-claims extracted from comments under Czech and Slovak news articles-domains that pose additional challenges due to the informal language, strong local context, and subtleties of these closely related languages. The results draw attention to the limitations of current evaluation approaches when applied to document-level claim extraction and highlight the need for more advanced methods-ones able to correctly capture semantic similarity and evaluate essential claim properties such as atomicity, checkworthiness, and decontextualization.

</details>


### [124] [A Method for Characterizing Disease Progression from Acute Kidney Injury to Chronic Kidney Disease](https://arxiv.org/abs/2511.14603)
*Yilu Fang,Jordan G. Nestor,Casey N. Ta,Jerard Z. Kneifati-Hayek,Chunhua Weng*

Main category: cs.CL

TL;DR: 本研究利用电子健康记录（EHR）数据动态追踪急性肾损伤（AKI）患者的临床演变，识别其向慢性肾病（CKD）进展的轨迹。通过聚类分析确定15种不同的术后AKI状态，结合多状态模型估计状态间转移概率及CKD进展风险。结果显示，约17%的AKI患者发展为CKD，且不同临床状态的CKD风险差异显著。研究还识别出多种已知和新发现的风险因素，其影响在不同亚群中存在异质性，为早期识别高危患者、开发辅助决策工具提供了数据支持。


<details>
  <summary>Details</summary>
Motivation: AKI患者发展为CKD的风险较高，但目前缺乏有效方法识别高危人群。亟需一种基于真实世界数据的方法，动态刻画患者临床演变路径，以精准评估进展风险并指导干预。

Method: 采用电子健康记录数据，基于纵向医疗编码和肌酐水平构建患者向量，通过聚类分析识别术后临床状态；利用多状态模型估算状态间转移概率及向CKD的进展风险；结合生存分析在不同AKI亚群中识别CKD风险因素。

Result: 共纳入20,699例入院时有AKI的患者，其中3,491人（17%）发展为CKD。识别出15种不同的术后临床状态，各状态的CKD进展概率不同。大多数患者（75%）仅维持单一状态或经历一次状态转换。既往已知风险因素（如AKI严重程度、糖尿病、高血压、心力衰竭、肝病）以及若干新发现的因素均影响CKD风险，且其作用随临床状态而异。

Conclusion: 本研究提出一种数据驱动的方法，可有效识别高风险AKI患者，有助于开发用于早期检测和干预慢性肾病的临床决策支持工具。

Abstract: Patients with acute kidney injury (AKI) are at high risk of developing chronic kidney disease (CKD), but identifying those at greatest risk remains challenging. We used electronic health record (EHR) data to dynamically track AKI patients' clinical evolution and characterize AKI-to-CKD progression. Post-AKI clinical states were identified by clustering patient vectors derived from longitudinal medical codes and creatinine measurements. Transition probabilities between states and progression to CKD were estimated using multi-state modeling. After identifying common post-AKI trajectories, CKD risk factors in AKI subpopulations were identified through survival analysis. Of 20,699 patients with AKI at admission, 3,491 (17%) developed CKD. We identified fifteen distinct post-AKI states, each with different probabilities of CKD development. Most patients (75%, n=15,607) remained in a single state or made only one transition during the study period. Both established (e.g., AKI severity, diabetes, hypertension, heart failure, liver disease) and novel CKD risk factors, with their impact varying across these clinical states. This study demonstrates a data-driven approach for identifying high-risk AKI patients, supporting the development of decision-support tools for early CKD detection and intervention.

</details>


### [125] [Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models](https://arxiv.org/abs/2511.14606)
*Shreya Adrita Banik,Niaz Nafi Rahman,Tahsina Moiukh,Farig Sadeque*

Main category: cs.CL

TL;DR: 本研究构建了一个手动标注的新闻文章数据集，比较了人类标注与多种大语言模型（GPT、BERT、RoBERTa、FLAN）在政治偏见检测上的表现。结果显示，尽管传统Transformer模型中RoBERTa与人类标注最一致，但在零样本设置下，生成式模型GPT整体上与人类判断的吻合度最高。微调后的RoBERTa模型在准确率和与人工标注的一致性方面表现最佳。研究揭示了人类与大语言模型在感知政治倾向上的系统性差异，强调需要结合人类可解释性与模型可扩展性的混合评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型在政治偏见检测任务中是否与人类判断一致仍缺乏深入理解，亟需建立一个对比评估框架以揭示模型与人类认知之间的差异。

Method: 构建手动标注的新闻文章数据集，评估标注一致性、偏见极性及跨模型一致性；对比多个LLM（GPT、BERT、RoBERTa、FLAN）在零样本和微调设置下的表现，并分析其与人类标注的对齐程度。

Result: RoBERTa在传统模型中与人类标注最一致；生成式模型GPT在零样本设置下整体一致性最强；微调后的RoBERTa在准确率和与人工标注的一致性上达到最高水平。

Conclusion: 人类与大语言模型在政治偏见感知上存在系统性差异，未来应发展融合人类可解释性与模型可扩展性的混合评估框架，以提升自动化媒体偏见检测的可靠性。

Abstract: Detecting political bias in news media is a complex task that requires interpreting subtle linguistic and contextual cues. Although recent advances in Natural Language Processing (NLP) have enabled automatic bias classification, the extent to which large language models (LLMs) align with human judgment still remains relatively underexplored and not yet well understood. This study aims to present a comparative framework for evaluating the detection of political bias across human annotations and multiple LLMs, including GPT, BERT, RoBERTa, and FLAN. We construct a manually annotated dataset of news articles and assess annotation consistency, bias polarity, and inter-model agreement to quantify divergence between human and model perceptions of bias. Experimental results show that among traditional transformer-based models, RoBERTa achieves the highest alignment with human labels, whereas generative models such as GPT demonstrate the strongest overall agreement with human annotations in a zero-shot setting. Among all transformer-based baselines, our fine-tuned RoBERTa model acquired the highest accuracy and the strongest alignment with human-annotated labels. Our findings highlight systematic differences in how humans and LLMs perceive political slant, underscoring the need for hybrid evaluation frameworks that combine human interpretability with model scalability in automated media bias detection.

</details>


### [126] [Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities](https://arxiv.org/abs/2511.14631)
*Kahaan Gandhi,Boris Bolliet,Inigo Zubeldia*

Main category: cs.CL

TL;DR: 该研究提出利用视觉-语言模型（VLM）引导多智能体系统实现端到端的自主科学发现。通过将图表作为可验证的检查点，VLM作为裁判依据动态生成的领域特定评估标准来评估图表，使智能体能够自我纠正并实时调整探索性数据分析。在宇宙学和天体化学的案例研究中，系统展示了从错误推理路径中恢复并适应新数据集的能力，无需人工干预。在10个数据驱动发现任务的基准测试中，增强VLM的系统在‘一次性通过’（pass at 1）指标上达到0.7-0.8，远超仅代码（0.2-0.3）和代码+文本基线（0.4-0.5），同时提供可审计的推理轨迹，显著提升可解释性。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 现有自主科学发现系统缺乏对可视化结果的有效评估能力，难以在探索过程中自我纠错，且推理过程不透明。为解决这一问题，需引入具备理解图像与文本能力的模型，以实现对科学图表的自动评估和实时反馈，从而提升系统的鲁棒性、自洽性和可解释性。

Method: 构建基于VLM的多智能体系统，将科学图表视为可验证的检查点；设计动态生成的领域特定评估规则；利用VLM作为裁判评估图表质量；基于评估反馈，智能体自主修正错误并调整分析路径；通过案例研究与基准测试验证方法的有效性。

Result: 在10项数据驱动发现任务中，VLM增强系统在pass at 1指标上达到0.7-0.8，显著优于代码仅（0.2-0.3）和代码+文本基线（0.4-0.5）；系统能自动纠正错误推理路径，适应新数据，生成可审计的推理日志，提升可解释性；代码已开源。

Conclusion: 将VLM集成至多智能体系统可有效提升自主科学发现的准确性、鲁棒性和可解释性，为未来自动化科研提供可行范式。

Abstract: We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent

</details>


### [127] [A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases](https://arxiv.org/abs/2511.14638)
*Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li*

Main category: cs.CL

TL;DR: RareSeek R1 是一种针对罕见病诊断的先进AI系统，通过整合临床语料库和医生验证的推理数据集，采用分阶段指令微调、思维链学习和图结构检索技术，在多中心电子健康记录（EHR）和公开基准上实现了最先进的准确率、鲁棒性和稳定性。其增强型检索在结合优先变异信息时显著提升诊断能力，尤其在解决表型模糊性和对齐致病机制方面表现突出。人类评估显示其性能与经验丰富的医生相当，并在辅助诊断中持续带来提升。透明化推理揭示了非表型证据（如影像学、干预措施、功能检查）在正确诊断中的关键作用（中位占比23.1%），推动了以叙事为导向、知识融合的推理范式，缩短了诊断旅程，实现可审计、临床可转化的决策支持。


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断常需多年时间，传统方法分离噪声证据提取与后续推理，且通用或医学大模型受限于真实世界电子健康记录稀缺、领域知识陈旧及幻觉问题。亟需更精准、可解释、集成知识的诊断支持系统。

Method: 构建大规模专业化临床语料库与医生验证的推理数据集；采用分阶段指令微调、思维链学习（Chain-of-Thought）与图结构基底检索技术训练RareSeek R1模型。

Result: 在多中心EHR文本与公开基准测试中，RareSeek R1达到当前最优准确率与泛化能力，对噪声或重叠表型具有强稳定性；增强检索在结合优先基因变异时提升显著；人类研究证实其性能媲美资深医生，且在辅助使用中持续有效；透明推理揭示非表型证据占诊断依据中位数达23.1%，具有重要临床意义。

Conclusion: 本研究提出以叙事为先、知识融合的推理新范式，显著缩短罕见病诊断周期，实现可审计、临床可落地的智能辅助诊断系统，为未来精准医疗提供关键技术支撑。

Abstract: Rare diseases affect hundreds of millions worldwide, yet diagnosis often spans years. Convectional pipelines decouple noisy evidence extraction from downstream inferential diagnosis, and general/medical large language models (LLMs) face scarce real world electronic health records (EHRs), stale domain knowledge, and hallucinations. We assemble a large, domain specialized clinical corpus and a clinician validated reasoning set, and develop RareSeek R1 via staged instruction tuning, chain of thought learning, and graph grounded retrieval. Across multicenter EHR narratives and public benchmarks, RareSeek R1 attains state of the art accuracy, robust generalization, and stability under noisy or overlapping phenotypes. Augmented retrieval yields the largest gains when narratives pair with prioritized variants by resolving ambiguity and aligning candidates to mechanisms. Human studies show performance on par with experienced physicians and consistent gains in assistive use. Notably, transparent reasoning highlights decisive non phenotypic evidence (median 23.1%, such as imaging, interventions, functional tests) underpinning many correct diagnoses. This work advances a narrative first, knowledge integrated reasoning paradigm that shortens the diagnostic odyssey and enables auditable, clinically translatable decision support.

</details>


### [128] [Graded strength of comparative illusions is explained by Bayesian inference](https://arxiv.org/abs/2511.14642)
*Yuhan Zhang,Erxiao Wang,Cory Shain*

Main category: cs.CL

TL;DR: 该研究通过结合统计语言模型与人类行为数据，构建了一个定量模型来预测比较错觉（CI）的强度。研究不仅解释了CI效应的细微差异，还首次解释了代词与完整名词短语作从句主语时的未解现象，支持了句子理解中的噪声通道理论，并将其作为统一的计算层级理论，解释多种语言处理现象。


<details>
  <summary>Details</summary>
Motivation: 探讨语言处理中的错觉现象，特别是比较错觉（CI），并验证噪声通道理论在解释此类现象中的有效性，以建立一个统一的语言理解计算模型。

Method: 结合统计语言模型与人类行为数据，构建后验概率模型，量化不同解释的可能性，并预测比较错觉的强度。

Result: 模型成功预测了比较错觉的强度变化，包括先前无法解释的代词与完整名词短语主语之间的差异，证实了噪声通道理论的预测能力。

Conclusion: 噪声通道理论能够有效解释语言处理中的多种现象，包括错觉和非错觉情境，支持其作为语言理解的统一计算层级理论。

Abstract: Like visual processing, language processing is susceptible to illusions in which people systematically misperceive stimuli. In one such case--the comparative illusion (CI), e.g., More students have been to Russia than I have--comprehenders tend to judge the sentence as acceptable despite its underlying nonsensical comparison. Prior research has argued that this phenomenon can be explained as Bayesian inference over a noisy channel: the posterior probability of an interpretation of a sentence is proportional to both the prior probability of that interpretation and the likelihood of corruption into the observed (CI) sentence. Initial behavioral work has supported this claim by evaluating a narrow set of alternative interpretations of CI sentences and showing that comprehenders favor interpretations that are more likely to have been corrupted into the illusory sentence. In this study, we replicate and go substantially beyond this earlier work by directly predicting the strength of illusion with a quantitative model of the posterior probability of plausible interpretations, which we derive through a novel synthesis of statistical language models with human behavioral data. Our model explains not only the fine gradations in the strength of CI effects, but also a previously unexplained effect caused by pronominal vs. full noun phrase than-clause subjects. These findings support a noisy-channel theory of sentence comprehension by demonstrating that the theory makes novel predictions about the comparative illusion that bear out empirically. This outcome joins related evidence of noisy channel processing in both illusory and non-illusory contexts to support noisy channel inference as a unified computational-level theory of diverse language processing phenomena.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [129] [Blurred Encoding for Trajectory Representation Learning](https://arxiv.org/abs/2511.13741)
*Silin Zhou,Yao Chen,Shuo Shang,Lisi Chen,Bingsheng He,Ryosuke Shibasaki*

Main category: cs.LG

TL;DR: 提出BLUE方法，通过渐进式降低GPS坐标精度生成多层级的分块表示，结合编码器-解码器金字塔结构，在保留细粒度时空细节的同时捕捉整体出行模式，显著提升轨迹表示学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹表示学习方法将原始GPS轨迹转换为网格或道路轨迹时会丢失细粒度的空间时间细节，因此需要一种能够同时保留细节与高层语义的新方法。

Method: 提出BLUE方法，采用渐进式降精度策略生成多层级分块，构建基于Transformer的编码器-解码器金字塔结构，利用池化和上采样实现不同层级间的互补，通过轨迹重建任务以MSE损失进行训练。

Result: 在3个下游任务中，BLUE均显著优于8种SOTA方法，平均性能超越最佳基线30.90%。

Conclusion: BLUE有效平衡了轨迹表示中的细粒度细节与高层次语义，是一种高效且通用的轨迹表示学习框架。

Abstract: Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.

</details>


### [130] [SCALEX: Scalable Concept and Latent Exploration for Diffusion Models](https://arxiv.org/abs/2511.13750)
*E. Zhixuan Zeng,Yuhao Chen,Alexander Wong*

Main category: cs.LG

TL;DR: SCALEX 是一种用于可扩展、自动化探索扩散模型潜在空间的框架，通过仅使用自然语言提示从 H-space 提取语义有意义的方向，实现零样本解释，无需重新训练或标注。该方法能够系统地比较任意概念，并大规模发现模型内部关联，有效检测职业相关的性别偏见，排序身份描述符的语义对齐程度，并揭示无监督的聚类概念结构。


<details>
  <summary>Details</summary>
Motivation: 现有分析扩散模型中社会偏见的方法要么局限于预定义类别，要么依赖于对潜在方向的手动解释，限制了可扩展性并阻碍了细微或意外模式的发现。

Method: SCALEX 通过仅使用自然语言提示从 H-space 提取语义有意义的方向，实现零样本解释，无需重新训练或标注，从而实现对扩散模型潜在空间的大规模、自动化探索。

Result: SCALEX 能够检测职业提示中的性别偏见，对身份描述符的语义对齐进行排序，并在无监督情况下揭示聚类的概念结构，显著提升了偏见分析的可扩展性、可解释性和可扩展性。

Conclusion: 通过直接将提示与潜在方向关联，SCALEX 使扩散模型中的偏见分析比以往方法更具可扩展性、可解释性和可扩展性。

Abstract: Image generation models frequently encode social biases, including stereotypes tied to gender, race, and profession. Existing methods for analyzing these biases in diffusion models either focus narrowly on predefined categories or depend on manual interpretation of latent directions. These constraints limit scalability and hinder the discovery of subtle or unanticipated patterns.
  We introduce SCALEX, a framework for scalable and automated exploration of diffusion model latent spaces. SCALEX extracts semantically meaningful directions from H-space using only natural language prompts, enabling zero-shot interpretation without retraining or labelling. This allows systematic comparison across arbitrary concepts and large-scale discovery of internal model associations. We show that SCALEX detects gender bias in profession prompts, ranks semantic alignment across identity descriptors, and reveals clustered conceptual structure without supervision. By linking prompts to latent directions directly, SCALEX makes bias analysis in diffusion models more scalable, interpretable, and extensible than prior approaches.

</details>


### [131] [Robustness of LLM-enabled vehicle trajectory prediction under data security threats](https://arxiv.org/abs/2511.13753)
*Feilong Wang,Fuqiang Liu*

Main category: cs.LG

TL;DR: 该研究系统分析了基于大语言模型（LLM）的车辆轨迹预测模型在自动驾驶中的脆弱性，提出一种单特征差分进化攻击方法，在黑盒设置下对周围车辆的单一运动学特征进行微小但物理上合理的扰动，发现此类扰动可显著破坏模型输出，揭示了LLM驱动自动驾驶系统在车际交互中的对抗性漏洞。研究还发现了准确率与鲁棒性之间的权衡，探讨了失效机制并提出潜在缓解方案，强调未来LLM驱动智能交通系统需以鲁棒性为导向进行设计。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自动驾驶中展现出强大的推理和决策能力，但其在安全关键系统中的可靠性尚未得到充分验证，尤其在面对对抗性攻击时的脆弱性尚不明确，亟需系统评估其安全性。

Method: 提出一种单特征差分进化攻击方法，针对周围车辆的单一运动学特征进行扰动，在黑盒设置下评估LLM模型的鲁棒性，并在highD数据集上进行实验验证。

Result: 实验表明，即使微小且物理上合理的扰动也能显著影响模型输出，证明了LLM-based车辆轨迹预测模型存在严重的对抗性脆弱性；同时发现准确率与鲁棒性之间存在权衡关系，揭示了模型失效机制，并探索了潜在的缓解策略。

Conclusion: 该研究首次揭示了基于大语言模型的自动驾驶系统在车际交互中的对抗性漏洞，强调必须在未来的智能交通系统设计中优先考虑鲁棒性，以确保系统的安全可靠运行。

Abstract: The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.

</details>


### [132] [Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement](https://arxiv.org/abs/2511.13755)
*Zhe Yang,Wenrui Li,Hongtao Chen,Penghong Wang,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.LG

TL;DR: 提出RedReg方法，通过自适应冗余调节实现多模态信息平衡优化，解决主导模态长期占优导致的表示-输出耦合弱化和梯度调整忽视跨模态语义的问题。引入冗余阶段监控器与共信息门控机制，动态抑制冗余梯度，保留模态特异性信息，在多种场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态训练中因模态偏差导致优势模态长期主导反向传播，造成优化不平衡，且过度统一地调整优势模态梯度，忽略跨模态语义和方向性，影响模型性能。

Method: 设计冗余阶段监控器，基于有效增益增长速率与冗余程度判断干预时机；引入共信息门控机制评估主导模态贡献，动态启用抑制项；将优势模态梯度投影至联合梯度子空间的正交补空间，并按冗余程度抑制梯度。

Result: 实验表明RedReg在多数场景下优于当前主流方法，消融实验验证了各模块的有效性，代码已开源。

Conclusion: RedReg通过自适应冗余调节实现了多模态信息的平衡优化，提升了模型表现，尤其在处理模态依赖性强的任务时具有显著优势。

Abstract: Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git

</details>


### [133] [VitalBench: A Rigorous Multi-Center Benchmark for Long-Term Vital Sign Prediction in Intraoperative Care](https://arxiv.org/abs/2511.13757)
*Xiuding Cai,Xueyao Wang,Sen Wang,Yaoyao Zhu,Jiao Chen,Yu Yao*

Main category: cs.LG

TL;DR: 提出VitalBench基准，用于术中生命体征预测，涵盖4000+手术数据，支持完整、不完整数据及跨中心泛化评估，提升模型鲁棒性与临床适用性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在医疗时间序列预测中仍面临缺乏标准化基准、数据不完整和跨中心验证不足等问题，限制了模型的实用性和可比性。

Method: 构建VitalBench基准，整合来自两个独立医疗中心的超4000例手术数据，设计三种评估任务：完整数据、不完整数据和跨中心泛化，并采用掩码损失技术实现更稳健、无偏的模型评估。

Result: VitalBench提供了一个标准化、统一的平台，支持模型开发与比较，减少预处理依赖，促进架构创新，提升模型在真实临床环境中的适应能力。

Conclusion: VitalBench为术中生命体征预测奠定了坚实基础，推动高精度、强鲁棒性与跨场景适应性的预测模型发展。

Abstract: Intraoperative monitoring and prediction of vital signs are critical for ensuring patient safety and improving surgical outcomes. Despite recent advances in deep learning models for medical time-series forecasting, several challenges persist, including the lack of standardized benchmarks, incomplete data, and limited cross-center validation. To address these challenges, we introduce VitalBench, a novel benchmark specifically designed for intraoperative vital sign prediction. VitalBench includes data from over 4,000 surgeries across two independent medical centers, offering three evaluation tracks: complete data, incomplete data, and cross-center generalization. This framework reflects the real-world complexities of clinical practice, minimizing reliance on extensive preprocessing and incorporating masked loss techniques for robust and unbiased model evaluation. By providing a standardized and unified platform for model development and comparison, VitalBench enables researchers to focus on architectural innovation while ensuring consistency in data handling. This work lays the foundation for advancing predictive models for intraoperative vital sign forecasting, ensuring that these models are not only accurate but also robust and adaptable across diverse clinical environments. Our code and data are available at https://github.com/XiudingCai/VitalBench.

</details>


### [134] [ChemFixer: Correcting Invalid Molecules to Unlock Previously Unseen Chemical Space](https://arxiv.org/abs/2511.13758)
*Jun-Hyoung Park,Ho-Jun Song,Seong-Whan Lee*

Main category: cs.LG

TL;DR: ChemFixer 是一种基于 Transformer 架构的分子修复框架，通过预训练和在大规模有效/无效分子对数据集上的微调，能够将生成的化学无效分子修正为有效分子。该方法在保持原有化学和生物分布特性的同时显著提升了分子有效性，扩展了可探索的化学空间，并在有限数据下的药物-靶点相互作用预测任务中表现出色，具备广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习分子生成模型常产生化学无效分子，限制了其在实际药物发现中的应用，亟需一种高效、通用的分子修复方法以提升生成质量并扩大可用化学空间。

Method: 基于 Transformer 的预训练与微调框架，利用掩码技术进行预训练，并在自建的大规模有效/无效分子对数据集上进行微调，实现对无效分子的自动修复。

Result: ChemFixer 在多种生成模型上均显著提高了分子有效性，同时保留了原始输出的化学与生物分布特征；在药物-靶点相互作用预测任务中，提升了生成配体的有效性并发现了有潜力的配体-蛋白相互作用对。

Conclusion: ChemFixer 作为一种实用工具，能有效提升深度学习驱动药物发现中的分子有效性，扩展可访问的化学空间，适用于多种下游任务，具有良好的泛化性和应用价值。

Abstract: Deep learning-based molecular generation models have shown great potential in efficiently exploring vast chemical spaces by generating potential drug candidates with desired properties. However, these models often produce chemically invalid molecules, which limits the usable scope of the learned chemical space and poses significant challenges for practical applications. To address this issue, we propose ChemFixer, a framework designed to correct invalid molecules into valid ones. ChemFixer is built on a transformer architecture, pre-trained using masking techniques, and fine-tuned on a large-scale dataset of valid/invalid molecular pairs that we constructed. Through comprehensive evaluations across diverse generative models, ChemFixer improved molecular validity while effectively preserving the chemical and biological distributional properties of the original outputs. This indicates that ChemFixer can recover molecules that could not be previously generated, thereby expanding the diversity of potential drug candidates. Furthermore, ChemFixer was effectively applied to a drug-target interaction (DTI) prediction task using limited data, improving the validity of generated ligands and discovering promising ligand-protein pairs. These results suggest that ChemFixer is not only effective in data-limited scenarios, but also extensible to a wide range of downstream tasks. Taken together, ChemFixer shows promise as a practical tool for various stages of deep learning-based drug discovery, enhancing molecular validity and expanding accessible chemical space.

</details>


### [135] [Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection](https://arxiv.org/abs/2511.13759)
*Han Wang,Deyi Ji,Junyu Lu,Lanyun Zhu,Hailong Zhang,Haiyang Wu,Liqun Liu,Peng Shu,Roy Ka-Wei Lee*

Main category: cs.LG

TL;DR: 本文提出一种自训练框架，利用大量未标注数据通过协作伪标签来解决社交媒体中攻击性内容检测的低资源挑战。该方法结合轻量级分类器与多智能体视觉-语言模型（MA-VLMs），在迭代过程中生成伪标签，并通过双视角（监管者与用户）模拟提升标签可靠性。采用新型正-负-未标记（PNU）损失函数，有效利用已标注、一致未知和冲突未知数据，同时抑制伪标签噪声。实验表明，在有限监督下显著优于基线模型，并接近大规模模型性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中攻击性内容检测需要高质量标注数据，但因攻击性实例稀少且人工标注成本高，导致标注数据稀缺，因此亟需一种高效利用未标注数据的低资源学习方法。

Method: 提出基于多智能体视觉-语言模型（MA-VLMs）的自训练框架，通过轻量级分类器初始化，迭代生成伪标签；利用MA-VLMs的双视角（监管者与用户）模拟增强标签可靠性；将未标注样本分为一致未知集与冲突未知集；采用正-负-未标记（PNU）损失函数联合优化所有类型数据，降低伪标签噪声影响。

Result: 在多个基准数据集上的实验结果表明，该框架在低监督条件下显著优于现有基线方法，性能接近大规模模型水平。

Conclusion: 所提出的自训练框架能有效应对攻击性内容检测中的低资源问题，通过协同伪标签与双视角建模提升标签质量，结合PNU损失实现稳定优化，为实际应用提供了高效可行的解决方案。

Abstract: Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models

</details>


### [136] [MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm](https://arxiv.org/abs/2511.13760)
*Xiao Fan,Jingyan Jiang,Zhaoru Chen,Fanding Huang,Xiao Chen,Qinting Jiang,Bowen Zhang,Xing Tang,Zhi Wang*

Main category: cs.LG

TL;DR: MoETTA提出一种基于熵的测试时自适应框架，结合混合专家（MoE）架构，通过多个解耦专家实现多样化梯度方向更新，以应对真实世界中的异构混合分布偏移。引入新基准potpourri和potpourri+，涵盖自然、艺术、对抗性等多样扭曲，更贴近实际部署场景。实验表明MoETTA在多种混合分布偏移下均优于现有方法，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法依赖统一适应路径，无法应对真实世界中复杂且冲突的异构分布偏移；同时现有基准多为合成或同质偏移，难以反映实际挑战。

Method: 提出MoETTA框架，采用混合专家（MoE）结构，使模型能够根据测试样本动态选择不同专家进行参数更新，实现多方向灵活适应，并结合熵机制引导专家选择。

Result: 在三个混合分布偏移设置下，MoETTA显著优于主流基线方法，展现出更强的鲁棒性和适应能力，验证了专家多样性对提升泛化性能的有效性。

Conclusion: MoETTA通过引入专家级多样性与熵驱动的自适应机制，有效应对真实世界中复杂的混合分布偏移问题，是当前最先进的测试时自适应方法。

Abstract: Test-Time adaptation (TTA) has proven effective in mitigating performance drops under single-domain distribution shifts by updating model parameters during inference. However, real-world deployments often involve mixed distribution shifts, where test samples are affected by diverse and potentially conflicting domain factors, posing significant challenges even for SOTA TTA methods. A key limitation in existing approaches is their reliance on a unified adaptation path, which fails to account for the fact that optimal gradient directions can vary significantly across different domains. Moreover, current benchmarks focus only on synthetic or homogeneous shifts, failing to capture the complexity of real-world heterogeneous mixed distribution shifts. To address this, we propose MoETTA, a novel entropy-based TTA framework that integrates the Mixture-of-Experts (MoE) architecture. Rather than enforcing a single parameter update rule for all test samples, MoETTA introduces a set of structurally decoupled experts, enabling adaptation along diverse gradient directions. This design allows the model to better accommodate heterogeneous shifts through flexible and disentangled parameter updates. To simulate realistic deployment conditions, we introduce two new benchmarks: potpourri and potpourri+. While classical settings focus solely on synthetic corruptions, potpourri encompasses a broader range of domain shifts--including natural, artistic, and adversarial distortions--capturing more realistic deployment challenges. Additionally, potpourri+ further includes source-domain samples to evaluate robustness against catastrophic forgetting. Extensive experiments across three mixed distribution shifts settings show that MoETTA consistently outperforms strong baselines, establishing SOTA performance and highlighting the benefit of modeling multiple adaptation directions via expert-level diversity.

</details>


### [137] [Gene Incremental Learning for Single-Cell Transcriptomics](https://arxiv.org/abs/2511.13762)
*Jiaxin Qi,Yan Cui,Jianqiang Huang,Gaogang Xie*

Main category: cs.LG

TL;DR: 本文针对令牌（tokens）在增量学习中的研究匮乏问题，以基因这一特殊类型的令牌为研究对象，基于单细胞转录组学大数据集构建了基因增量学习的框架与评估体系。研究发现基因增量学习中同样存在遗忘问题，并通过适配现有类别增量学习方法缓解该问题。实验验证了框架设计和方法的有效性，最终提供了首个完整的基因增量学习基准。


<details>
  <summary>Details</summary>
Motivation: 当前增量学习研究主要聚焦于类别（classes），而作为具有类似增长特性的令牌（tokens），其在增量学习中的研究严重不足，尤其因语言中令牌的全局特性带来设计挑战。因此，本文选择基因作为典型令牌，在单细胞转录组学背景下探索其增量学习机制。

Method: 基于单细胞转录组学数据，构建基因增量学习的完整流程与评估体系；将现有类别增量学习方法适配至基因场景，以缓解遗忘问题。

Result: 实验表明所提框架设计合理、评估体系有效，适配的方法能显著缓解基因增量学习中的遗忘现象，且建立了首个系统性的基因增量学习基准。

Conclusion: 本研究填补了令牌增量学习领域的空白，证明了基因作为令牌在增量学习中的可行性与有效性，为后续生物数据中的动态学习提供了新范式与基准支持。

Abstract: Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics.

</details>


### [138] [Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels](https://arxiv.org/abs/2511.13764)
*Arun Thangamani,Md Asghar Ahmad Shahid,Adam Siemieniuk,Rolf Morel,Renato Golin,Alexander Heinecke*

Main category: cs.LG

TL;DR: 本文提出一种基于MLIR方言的编译方案，自动生成可扩展、高性能的微内核，通过组合低级IR构造实现近最优寄存器利用，从而在无需依赖底层库的情况下直接生成接近最优的代码。该方法支持向量和分块的CPU指令，在实验中表现出与现有顶尖微内核库相当的性能，具备生产质量。


<details>
  <summary>Details</summary>
Motivation: 当前AI和机器学习工作负载快速发展，但高层域操作与硬件高效利用之间存在巨大鸿沟。现有实现方式（如手写特定内核或依赖专用库）需要深厚硬件知识，复杂且难以扩展，限制了大多数机器学习实践者的使用。

Method: 利用MLIR方言构建编译方案，通过自动组合低级IR构造生成纳米内核，形成针对具体目标优化的高效微内核；核心机制聚焦于近最优寄存器利用率，并在基于MLIR的编译器中实现，支持向量与分块的CPU指令。

Result: 生成的纳米内核达到生产级别质量，性能与当前最先进的微内核库相当，在多个基准测试中表现优异。

Conclusion: 该编译方案成功实现了从高级域操作到硬件能力的无缝映射，显著降低了对低层库和专家知识的依赖，为机器学习开发者提供了高效、可扩展的自动化代码生成能力。

Abstract: The rapidly evolving landscape of AI and machine learning workloads has widened the gap between high-level domain operations and efficient hardware utilization. Achieving near-peak performance still demands deep hardware expertise-experts either handcraft target-specific kernels (e.g., DeepSeek) or rely on specialized libraries (e.g., CUTLASS)-both of which add complexity and limit scalability for most ML practitioners.
  This paper introduces a compilation scheme that automatically generates scalable, high-performance microkernels by leveraging the MLIR dialects to bridge domain-level operations and processor capabilities. Our approach removes dependence on low-level libraries by enabling the compiler to auto-generate near-optimal code directly. At its core is a mechanism for composing nanokernels from low-level IR constructs with near-optimal register utilization, forming efficient microkernels tailored to each target. We implement this technique in an MLIR-based compiler supporting both vector and tile based CPU instructions. Experiments show that the generated nanokernels are of production-quality, and competitive with state-of-the-art microkernel libraries.

</details>


### [139] [PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning](https://arxiv.org/abs/2511.13765)
*Shengjie Sun,Jiafei Lyu,Runze Liu,Mengbei Yan,Bo Liu,Deheng Ye,Xiu Li*

Main category: cs.LG

TL;DR: PROF利用大语言模型（LLMs）从自然语言描述和单个专家轨迹生成并优化可执行的奖励函数代码，提出一种无需环境交互或强化学习训练的奖励函数质量评估与排序策略RPR。通过交替使用RPR和基于文本的梯度优化，实现奖励函数的全自动选择与精炼，在D4RL多个数据集和领域上表现优于或媲美现有强基线。


<details>
  <summary>Details</summary>
Motivation: 现有离线模仿学习方法通常假设轨迹与专家示范的相似性与奖励正相关，这过于简化了真实的奖励结构，导致奖励函数设计不准确。为克服这一局限，需要更智能、自动化的方法来生成和优化奖励函数。

Method: PROF框架结合大语言模型生成初始奖励函数代码，并通过自然语言描述进行迭代优化；引入Reward Preference Ranking（RPR）策略，基于专家偏好计算奖励函数的支配得分，以无交互方式评估其质量；通过交替优化与评分，自动筛选最优奖励函数用于策略学习。

Result: 在D4RL基准测试中，PROF在多个数据集和任务域上均表现出色，超越或匹配当前主流强基线方法，验证了其在奖励函数生成与优化方面的有效性与通用性。

Conclusion: PROF通过融合大语言模型与偏好排序机制，实现了奖励函数的自动化生成与优化，显著提升了离线模仿学习中无显式奖励标注下的策略性能，为复杂任务中的奖励工程提供了新范式。

Abstract: Offline imitation learning (offline IL) enables training effective policies without requiring explicit reward annotations. Recent approaches attempt to estimate rewards for unlabeled datasets using a small set of expert demonstrations. However, these methods often assume that the similarity between a trajectory and an expert demonstration is positively correlated with the reward, which oversimplifies the underlying reward structure. We propose PROF, a novel framework that leverages large language models (LLMs) to generate and improve executable reward function codes from natural language descriptions and a single expert trajectory. We propose Reward Preference Ranking (RPR), a novel reward function quality assessment and ranking strategy without requiring environment interactions or RL training. RPR calculates the dominance scores of the reward functions, where higher scores indicate better alignment with expert preferences. By alternating between RPR and text-based gradient optimization, PROF fully automates the selection and refinement of optimal reward functions for downstream policy learning. Empirical results on D4RL demonstrate that PROF surpasses or matches recent strong baselines across numerous datasets and domains, highlighting the effectiveness of our approach.

</details>


### [140] [Credal Ensemble Distillation for Uncertainty Quantification](https://arxiv.org/abs/2511.13766)
*Kaizheng Wang,Fabio Cuzzolin,David Moens,Hans Hallez*

Main category: cs.LG

TL;DR: 提出了一种名为CREDAL Ensemble Distillation（CED）的新框架，将深度集成（DE）压缩为单一模型CREDIT，通过输出类别概率区间来量化不确定性，实现高效且可靠的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 深度集成（DE）虽然能有效量化预测不确定性并区分随机性和认知性不确定性，但其高计算和内存开销限制了实际应用。因此需要一种高效的方法来降低推理成本，同时保持良好的不确定性估计性能。

Method: 提出了一种新的框架CED，通过将深度集成压缩为单个模型CREDIT，使其输出类别的概率区间，构建一个凸的概率分布集合（即可信集），从而在保持不确定性量化能力的同时显著减少推理开销。

Result: 在多个分布外检测基准上，CED的表现优于或相当其他现有基线方法，同时大幅降低了推理开销，证明了其在效率与性能之间的良好平衡。

Conclusion: CED是一种高效的不确定性量化方法，能够以极低的推理成本实现与深度集成相当甚至更优的不确定性估计性能，具有广泛的实际部署潜力。

Abstract: Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.

</details>


### [141] [Dynamic Temperature Scheduler for Knowledge Distillation](https://arxiv.org/abs/2511.13767)
*Sibgat Ul Islam,Jawad Ibn Ahad,Fuad Rahman,Mohammad Ruhul Amin,Nabeel Mohammed,Shafin Rahman*

Main category: cs.LG

TL;DR: 本文提出一种动态温度调度器（DTS），根据教师与学生模型之间的交叉熵损失差距动态调整知识蒸馏中的温度，以优化学生模型的学习过程。该方法在视觉和自然语言处理任务中均优于固定温度的基线方法，且可无缝集成到现有知识蒸馏框架中。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏使用固定的温度参数，无法适应训练过程中学生模型对软/硬概率需求的变化；同时，教师与学生模型间的架构差异导致输出logit幅度不匹配，影响蒸馏效果。因此需要一种能自适应调节温度的方法。

Method: 提出动态温度调度器（DTS），通过监测教师与学生模型在训练过程中的交叉熵损失差距，动态调整温度：初期使用较低温度以获得更软的概率分布，后期逐步提高温度以增强概率尖锐性，从而提升学习效率。

Result: 在多个视觉（CIFAR-100、Tiny-ImageNet）和NLP任务（GLUE、Dolly、SelfIns、UnNI、S-NI）上，DTS均显著优于静态温度设置的基线方法，证明其有效性与泛化能力。

Conclusion: DTS是首个基于教师-学生分布差异自适应调整温度的知识蒸馏方法，能够有效缓解因架构差异带来的概率不匹配问题，提升学生模型性能，且实现简单、兼容性强。

Abstract: Knowledge Distillation (KD) trains a smaller student model using a large, pre-trained teacher model, with temperature as a key hyperparameter controlling the softness of output probabilities. Traditional methods use a fixed temperature throughout training, which is suboptimal. Moreover, architectural differences between teacher and student often result in mismatched logit magnitudes. We demonstrate that students benefit from softer probabilities early in training but require sharper probabilities in later stages. We introduce Dynamic Temperature Scheduler (DTS), which adjusts temperature dynamically based on the cross-entropy loss gap between teacher and student. To our knowledge, this is the first temperature scheduling method that adapts based on the divergence between teacher and student distributions. Our method integrates seamlessly with existing KD frameworks. We validate DTS across multiple KD strategies on vision (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI), consistently outperforming static-temperature baselines. Code is available at https://github.com/Sibgat-Ul/DTS.

</details>


### [142] [Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture](https://arxiv.org/abs/2511.13780)
*Nihal Mehta*

Main category: cs.LG

TL;DR: 本文通过将自注意力机制与分布语义原理联系起来，揭示了其数学本质。研究从GloVe嵌入背后的共现矩阵出发，证明投影过程自然地捕捉了上下文影响，并推导出查询-键-值机制作为建模方向性关系的非对称扩展。位置编码和多头注意力则被视为该投影原则的结构化改进。结果表明，Transformer架构的代数形式源于这些投影原则，而非任意设计选择。


<details>
  <summary>Details</summary>
Motivation: 揭示自注意力机制的深层数学基础，解释其为何能有效建模上下文依赖关系，避免将其视为黑箱或任意设计。

Method: 基于共现矩阵构建分布语义框架，分析自注意力在该框架下的投影生成机制，推导出查询-键-值结构及其扩展形式。

Result: 自注意力可被解释为对全局共现统计的上下文投影，其核心结构源于语义投影原则，而非人为构造；位置编码与多头注意力是该原则的自然延伸。

Conclusion: Transformer的自注意力机制具有坚实的数学与语义基础，其形式由分布语义中的投影原则所决定，这为理解模型行为提供了理论支持。

Abstract: This paper presents a mathematical interpretation of self-attention by connecting it to distributional semantics principles. We show that self-attention emerges from projecting corpus-level co-occurrence statistics into sequence context. Starting from the co-occurrence matrix underlying GloVe embeddings, we demonstrate how the projection naturally captures contextual influence, with the query-key-value mechanism arising as the natural asymmetric extension for modeling directional relationships. Positional encodings and multi-head attention then follow as structured refinements of this same projection principle. Our analysis demonstrates that the Transformer architecture's particular algebraic form follows from these projection principles rather than being an arbitrary design choice.

</details>


### [143] [ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design](https://arxiv.org/abs/2511.13809)
*Emanuel Covaci,Fabian Galis,Radu Balan,Daniela Zaharie,Darian Onchis*

Main category: cs.LG

TL;DR: 本文提出一种可微的全局可解释性方法，将特征重要性估计直接集成到模型训练中。通过ScoresActivation函数实现特征排序，并在端到端训练中保持可微性，使模型能根据特征对预测性能的贡献进行优先级排序。实验表明，该方法生成的特征排名与SHAP值和真实重要性高度一致，且计算速度比经典SHAP快150倍（仅需2秒 vs 300秒），同时在包含无关特征的情况下显著提升分类准确率（分别提高11.24%和29.33%）。该方法实现了模型准确性与可解释性的统一，提供了一种可扩展的内在可解释机器学习框架。


<details>
  <summary>Details</summary>
Motivation: 当前后处理解释方法虽能提供特征重要性洞察，但与模型训练过程脱节，导致解释结果的忠实度和实用性受限。为解决这一问题，亟需一种从设计上就具备全局可解释性的方法，使特征重要性评估与模型训练深度融合。

Method: 提出ScoresActivation函数，作为嵌入学习流程中的特征排序机制，实现特征重要性估计的可微化与端到端可训练性，使模型在训练过程中自动学习并优化特征优先级。

Result: 在多个基准数据集上的评估显示，该方法生成的特征排名具有高忠实性和稳定性，与SHAP值及真实特征重要性高度一致；特征评分速度比传统SHAP快150倍（2秒对比300秒）；在10个特征（5个相关）和16个特征（5个相关，11个无关）配置下，分类准确率分别提升11.24%和29.33%，表现出对无关输入的强鲁棒性。

Conclusion: 本工作成功弥合了模型准确率与可解释性之间的鸿沟，提出了一种可扩展的、从设计上即具可解释性的机器学习框架，为构建透明可信的深度学习系统提供了新路径。

Abstract: Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.

</details>


### [144] [Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](https://arxiv.org/abs/2511.13841)
*Zelei Shao,Vikranth Srivatsa,Sanjana Srivastava,Qingyang Wu,Alpay Ariyak,Xiaoxia Wu,Ameen Patel,Jue Wang,Percy Liang,Tri Dao,Ce Zhang,Yiying Zhang,Ben Athiwaratkun,Chenfeng Xu,Junxiong Wang*

Main category: cs.LG

TL;DR: DAS提出了一种分布感知的推测解码框架，通过利用历史回滚数据中的长尾分布特性，采用自适应非参数起草器和长度感知的推测策略，显著加速强化学习后训练中的回滚阶段，最多减少50%的回滚时间，同时保持相同的训练曲线，证明了分布感知推测解码在不牺牲学习质量的前提下可有效提升效率。


<details>
  <summary>Details</summary>
Motivation: RL后训练中回滚阶段因长轨迹逐词生成而效率低下，且存在回滚长度的长尾分布现象，少数长轨迹占据大量时间；同时历史回滚数据中隐藏着提示级别稳定模式，可被用于优化。

Method: 提出DAS框架，包含两个核心：基于增量维护后缀树的自适应非参数起草器，以及根据轨迹长度分配更激进草案预算的长度感知推测策略，从而在不改变模型输出的前提下平衡基础与分词级成本。

Result: 在数学和代码推理任务上，DAS将回滚时间最多减少50%，并保持完全一致的训练曲线，验证了其在加速RL后训练方面的有效性与学习质量的保真性。

Conclusion: 分布感知的推测解码能够显著加速强化学习后训练过程，通过有效利用历史回滚数据和动态调整推测策略，在不牺牲学习效果的前提下大幅提升效率。

Abstract: Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout lengths, where a small fraction of long generations dominates wall clock time and a complementary opportunity; the availability of historical rollouts that reveal stable prompt level patterns across training epochs. Motivated by these observations, we propose DAS, a Distribution Aware Speculative decoding framework that accelerates RL rollouts without altering model outputs. DAS integrates two key ideas: an adaptive, nonparametric drafter built from recent rollouts using an incrementally maintained suffix tree, and a length aware speculation policy that allocates more aggressive draft budgets to long trajectories that dominate makespan. This design exploits rollout history to sustain acceptance while balancing base and token level costs during decoding. Experiments on math and code reasoning tasks show that DAS reduces rollout time up to 50% while preserving identical training curves, demonstrating that distribution-aware speculative decoding can significantly accelerate RL post training without compromising learning quality.

</details>


### [145] [AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection](https://arxiv.org/abs/2511.13880)
*Saleh Momeni,Changnan Xiao,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出AnaCP，一种新型类增量学习方法，通过分析对比投影实现无需梯度训练的特征表示增量适应，有效缓解灾难性遗忘，在不使用预训练模型的情况下达到联合训练的性能水平。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习方法因需同时增量学习特征表示和分类器而易产生灾难性遗忘；尽管引入预训练模型可提升效率，但仍无法持续适应特征表示，导致性能受限。

Method: 提出AnaCP方法，利用分析式分类器并结合对比投影机制，实现无需梯度更新的特征表示增量适应。

Result: 实验表明，AnaCP在多个基准上优于现有基线，性能接近联合训练的上限。

Conclusion: AnaCP通过高效且无梯度的方式实现了特征表示的持续适应，显著提升了类增量学习的性能，为该领域提供了新的有效解决方案。

Abstract: This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.

</details>


### [146] [Beyond One-Size-Fits-All: Neural Networks for Differentially Private Tabular Data Synthesis](https://arxiv.org/abs/2511.13893)
*Kai Chen,Chen Gong,Tianhao Wang*

Main category: cs.LG

TL;DR: MargNet proposes a novel neural network-based approach for differentially private tabular data synthesis, combining the strengths of statistical models and neural networks. It uses an adaptive marginal selection strategy to improve performance on densely correlated datasets, where traditional statistical models struggle. MargNet achieves state-of-the-art results, reducing fidelity error by up to 26% compared to previous methods, while also offering significant speedups on sparsely correlated data.


<details>
  <summary>Details</summary>
Motivation: Existing differential privacy methods for tabular data synthesis favor statistical models over neural networks, but this view overlooks challenges in densely correlated datasets where complex dependencies overwhelm statistical approaches. Neural networks can better capture such complexity, yet existing NN-based methods have limitations.

Method: MargNet integrates successful algorithmic designs from statistical models into neural networks. It employs an adaptive marginal selection strategy and trains the network to generate data consistent with selected marginals.

Result: On sparsely correlated datasets, MargNet matches the utility of the best statistical method with an average 7× speedup. On densely correlated datasets, it achieves a new state-of-the-art, reducing fidelity error by up to 26% compared to prior methods.

Conclusion: MargNet demonstrates that neural networks, when properly designed with insights from statistical models, can outperform traditional methods in differentially private tabular data synthesis, especially in complex, densely correlated settings.

Abstract: In differentially private (DP) tabular data synthesis, the consensus is that statistical models are better than neural network (NN)-based methods. However, we argue that this conclusion is incomplete and overlooks the challenge of densely correlated datasets, where intricate dependencies can overwhelm statistical models. In such complex scenarios, neural networks are more suitable due to their capacity to fit complex distributions by learning directly from samples. Despite this potential, existing NN-based algorithms still suffer from significant limitations. We therefore propose MargNet, incorporating successful algorithmic designs of statistical models into neural networks. MargNet applies an adaptive marginal selection strategy and trains the neural networks to generate data that conforms to the selected marginals. On sparsely correlated datasets, our approach achieves utility close to the best statistical method while offering an average 7$\times$ speedup over it. More importantly, on densely correlated datasets, MargNet establishes a new state-of-the-art, reducing fidelity error by up to 26\% compared to the previous best. We release our code on GitHub.\footnote{https://github.com/KaiChen9909/margnet}

</details>


### [147] [The Impact of Bootstrap Sampling Rate on Random Forest Performance in Regression Tasks](https://arxiv.org/abs/2511.13952)
*Michał Iwaniuk,Mateusz Jarosz,Bartłomiej Borycki,Bartosz Jezierski,Jan Cwalina,Stanisław Kaźmierczak,Jacek Mańdziuk*

Main category: cs.LG

TL;DR: 本文系统研究了随机森林中自助采样率（BR）在0.2到5.0范围内变化对模型性能的影响，发现调整BR可显著提升性能；多数数据集最优BR不等于默认值1.0，且数据特征决定最佳BR：全局关系强的数据适合高BR，局部方差大的数据适合低BR。合成数据实验验证了噪声水平与BR选择的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 传统随机森林默认自助采样率（BR）为1.0，但该设置未必最优。本文旨在探索不同BR对回归性能的影响，并揭示其与数据特性的关联，以指导更优的超参数调优。

Method: 在39个异构回归数据集上，使用16种随机森林配置进行重复两折交叉验证，评估均方误差。系统性地测试BR从0.2到5.0的取值。通过分析数据特征（如全局特征-目标关系强度、局部目标方差）与最优BR的关系，并结合可控噪声的合成数据实验，验证偏差-方差权衡机制。

Result: 24个数据集在BR ≤ 1.0时表现最佳，15个在BR > 1.0时表现最佳，仅4个在BR = 1.0时最优。低噪声数据中高BR降低偏差，高噪声数据中低BR降低方差。表明BR是关键可调超参数。

Conclusion: 自助采样率（BR）是影响随机森林回归性能的重要超参数，应根据数据特性进行调优，而非固定为1.0。合理选择BR可显著提升模型表现。

Abstract: Random Forests (RFs) typically train each tree on a bootstrap sample of the same size as the training set, i.e., bootstrap rate (BR) equals 1.0. We systematically examine how varying BR from 0.2 to 5.0 affects RF performance across 39 heterogeneous regression datasets and 16 RF configurations, evaluating with repeated two-fold cross-validation and mean squared error. Our results demonstrate that tuning the BR can yield significant improvements over the default: the best setup relied on BR \leq 1.0 for 24 datasets, BR > 1.0 for 15, and BR = 1.0 was optimal in 4 cases only. We establish a link between dataset characteristics and the preferred BR: datasets with strong global feature-target relationships favor higher BRs, while those with higher local target variance benefit from lower BRs. To further investigate this relationship, we conducted experiments on synthetic datasets with controlled noise levels. These experiments reproduce the observed bias-variance trade-off: in low-noise scenarios, higher BRs effectively reduce model bias, whereas in high-noise settings, lower BRs help reduce model variance. Overall, BR is an influential hyperparameter that should be tuned to optimize RF regression models.

</details>


### [148] [Data Whitening Improves Sparse Autoencoder Learning](https://arxiv.org/abs/2511.13981)
*Ashwin Saraswatula,David Klindt*

Main category: cs.LG

TL;DR: 通过在稀疏自编码器（SAE）训练前对输入激活应用PCA去相关化（whitening），可显著提升模型的可解释性，尽管重建质量略有下降。该方法使优化景观更凸，更容易收敛，适用于多种架构与稀疏度设置。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏自编码器训练中因输入数据相关性导致的优化困难问题，提升特征的可解释性。

Method: 采用PCA Whitening对输入激活进行预处理，并在不同模型架构、宽度和稀疏度条件下评估ReLU与Top-K SAE的性能。

Result: 实证结果表明，去相关化显著提升了稀疏探测准确率和特征解耦性，虽重建质量轻微下降，但整体可解释性明显增强。

Conclusion: 去相关化应作为SAE训练的默认预处理步骤，尤其在以可解释性为首要目标时。

Abstract: Sparse autoencoders (SAEs) have emerged as a promising approach for learning interpretable features from neural network activations. However, the optimization landscape for SAE training can be challenging due to correlations in the input data. We demonstrate that applying PCA Whitening to input activations -- a standard preprocessing technique in classical sparse coding -- improves SAE performance across multiple metrics. Through theoretical analysis and simulation, we show that whitening transforms the optimization landscape, making it more convex and easier to navigate. We evaluate both ReLU and Top-K SAEs across diverse model architectures, widths, and sparsity regimes. Empirical evaluation on SAEBench, a comprehensive benchmark for sparse autoencoders, reveals that whitening consistently improves interpretability metrics, including sparse probing accuracy and feature disentanglement, despite minor drops in reconstruction quality. Our results challenge the assumption that interpretability aligns with an optimal sparsity--fidelity trade-off and suggest that whitening should be considered as a default preprocessing step for SAE training, particularly when interpretability is prioritized over perfect reconstruction.

</details>


### [149] [Node-Level Uncertainty Estimation in LLM-Generated SQL](https://arxiv.org/abs/2511.13984)
*Hilaf Hasson,Ruocheng Guo*

Main category: cs.LG

TL;DR: 本文提出了一种实用的框架，用于检测大语言模型生成的SQL中的错误，通过在抽象语法树（AST）的节点级别估计不确定性。该方法分为两个阶段：首先，引入一种语义感知的标注算法，对生成的SQL与参考答案进行对比，分配节点级别的正确性标签，避免对结构容器或别名变化过度惩罚；其次，为每个节点构建包含模式感知和词汇特征的丰富表示，涵盖标识符有效性、别名解析、类型兼容性、作用域模糊性和拼写错误信号等，并训练监督分类器预测每个节点的错误概率。这些概率被解释为校准后的不确定性，实现细粒度诊断，精确定位查询中可能出错的位置。在多个数据库和数据集上，该方法显著优于传统的词元概率：平均AUC提升27.44%，且在跨数据库评估下仍保持鲁棒性。除了作为准确率信号外，节点级不确定性还支持定向修复、人机协同审查及下游选择性执行。整体表明，以节点为中心、语义基础的不确定性估计是传统序列级置信度度量的一种强大且可解释的替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于序列级置信度（如词元日志概率）来评估大语言模型生成的SQL质量，但这类方法缺乏细粒度诊断能力，无法定位具体错误位置，且容易受结构或别名变化干扰。因此，亟需一种更精确、可解释的错误检测机制，以支持精准修复与人机协作。

Method: 1. 设计语义感知的节点级标注算法，基于生成SQL与黄金标准的对比，自动标记每个AST节点的正确性，避免因结构容器或别名差异导致误判；2. 提取丰富的节点特征，包括标识符合法性、别名解析状态、类型兼容性、作用域模糊性及拼写错误信号等，形成多维度的上下文感知表示；3. 使用监督学习训练分类器，预测每个节点的错误概率；4. 将预测概率解释为校准后的不确定性，用于指导错误定位、修复建议与执行策略选择。

Result: 在多个数据库和数据集上，所提方法的平均AUC相比传统词元日志概率提升27.44%；在跨数据库测试中依然表现稳健；节点级不确定性有效支持了精准错误定位、定向修复、人工审核优化和选择性执行等应用。

Conclusion: 本研究证明，基于节点级、语义驱动的不确定性估计，是一种比传统序列级置信度更精确、更具可解释性的方法，为大语言模型生成SQL的质量评估与调试提供了新范式。

Abstract: We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.

</details>


### [150] [Certified but Fooled! Breaking Certified Defences with Ghost Certificates](https://arxiv.org/abs/2511.14003)
*Quoc Viet Vo,Tashreque M. Haq,Paul Montague,Tamas Abraham,Ehsan Abbasnejad,Damith C. Ranasinghe*

Main category: cs.LG

TL;DR: 本文研究了概率性认证框架可能被恶意利用的问题，旨在揭示现有鲁棒性保证的局限性。通过设计针对特定区域的对抗样本，攻击者可生成微小且难以察觉的扰动，使分类器误判的同时诱导认证系统为错误类别生成虚假的鲁棒性保证，甚至超过原始类别的证书半径。在ImageNet上的实验表明，该方法能有效绕过如Densepure等先进的认证防御机制。


<details>
  <summary>Details</summary>
Motivation: 现有的认证防御虽提供可证明的鲁棒性保证，但其依赖的概率性认证框架可能存在被恶意利用的风险，攻击者可通过精心设计的扰动欺骗认证过程，生成对错误输入的虚假鲁棒性声明，从而削弱认证机制的实际防护能力。因此，有必要深入探究认证机制的脆弱性边界。

Method: 提出一种区域聚焦的对抗样本构造方法，通过生成微小、不可察觉的扰动，将输入引导至能够产生高鲁棒性保证的区域，从而实现对认证过程的欺骗，使模型为错误类别颁发过大的认证半径。

Result: 在ImageNet数据集上的实验验证了该方法的有效性，能够成功绕过包括Densepure在内的多种先进认证防御，生成对错误类别的虚假大半径认证，揭示了当前认证框架在安全性上的潜在漏洞。

Conclusion: 本研究揭示了当前鲁棒性认证方法存在被欺骗的可能，即使扰动极小，也可能导致认证系统产生误导性结果。这表明必须重新审视认证机制的设计原则，以增强其抗欺骗能力，推动更安全可靠的认证防御体系发展。

Abstract: Certified defenses promise provable robustness guarantees. We study the malicious exploitation of probabilistic certification frameworks to better understand the limits of guarantee provisions. Now, the objective is to not only mislead a classifier, but also manipulate the certification process to generate a robustness guarantee for an adversarial input certificate spoofing. A recent study in ICLR demonstrated that crafting large perturbations can shift inputs far into regions capable of generating a certificate for an incorrect class. Our study investigates if perturbations needed to cause a misclassification and yet coax a certified model into issuing a deceptive, large robustness radius for a target class can still be made small and imperceptible. We explore the idea of region-focused adversarial examples to craft imperceptible perturbations, spoof certificates and achieve certification radii larger than the source class ghost certificates. Extensive evaluations with the ImageNet demonstrate the ability to effectively bypass state-of-the-art certified defenses such as Densepure. Our work underscores the need to better understand the limits of robustness certification methods.

</details>


### [151] [Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds](https://arxiv.org/abs/2511.14056)
*Marios Papamichals,Regina Ruane*

Main category: cs.LG

TL;DR: 提出Radial Compensation（RC）方法，解决生成模型在曲面空间中因曲率导致的参数纠缠与梯度方差问题。RC通过选择切空间中的基密度，使似然仅依赖于测地距离，实现曲率与参数解耦。引入Balanced-Exponential（bExp）图表族，在体积失真与测地误差间取得平衡。所有bExp设置保持相同流形密度和费雪信息，小拨号值降低梯度方差与流成本。实验证明RC在图像、图、蛋白质模型等任务中提升似然、稳定训练、防止半径爆炸，是流形上似然训练生成模型的稳健默认方案。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在曲面空间中依赖图表映射，但指数映射存在半径相关刚性雅可比，保体积图表则扭曲测地距离，两者均将曲率与模型参数纠缠，导致梯度方差大、高维流中半径膨胀、测试似然差等问题。

Method: 提出信息几何方法Radial Compensation（RC），通过设计切空间基密度，使似然函数仅依赖于从极点出发的测地距离，从而解耦参数语义与曲率；进一步构建Balanced-Exponential（bExp）图表族，平衡体积畸变与测地误差，并证明在该框架下唯一满足曲率不变费雪信息的构造。

Result: RC-bExp在图像、图、蛋白质等多类数据上均表现稳定，显著提升似然，恢复合理的测地半径，抑制高维流中的半径爆炸现象，且不同参数配置下保持一致的流形密度与费雪信息，小参数值有效降低梯度方差与计算成本。

Conclusion: Radial Compensation结合bExp图表是流形上似然训练生成模型的稳健默认选择，能有效应对曲率带来的建模挑战，实现高效、稳定、可解释的生成建模。

Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.

</details>


### [152] [A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation](https://arxiv.org/abs/2511.14057)
*Xianghe Liu,Jiajia Liu,Chuxian Xu,Minghan Wang,Hongbo Peng,Tao Sun,Jiaqi Xu*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的多模态框架，结合可穿戴传感器数据实现射箭运动中的动作识别与压力评估。通过自研腕戴设备采集同步的运动与生理信号，引入新型特征Smoothed Differential Acceleration（SmoothDiff）并使用LSTM模型进行动作阶段识别，准确率达96.8%，F1得分为95.9%；同时利用PPG信号提取心率变异性（HRV）特征，采用MLP分类器进行压力水平区分，准确率达80%。该方法为精准运动中技术与心理状态的实时监测与训练优化提供了可行路径。


<details>
  <summary>Details</summary>
Motivation: 传统运动分析系统成本高且侵入性强，难以在自然训练环境中应用，因此需要一种低成本、非侵入式的智能监测方法来同时评估运动员的动作表现与心理状态。

Method: 采用自研腕戴设备采集加速度计和光电容积脉搏波（PPG）信号，提取Smoothed Differential Acceleration（SmoothDiff）特征用于动作识别，结合LSTM模型实现运动阶段分类；从PPG信号中提取心率变异性（HRV）特征，使用MLP分类器进行高/低压力水平的判断。

Result: 动作识别准确率达到96.8%，F1得分为95.9%；压力估计准确率为80%，能够有效区分高、低压力状态。

Conclusion: 融合运动与生理传感数据的多模态分析框架可有效提供对运动员技术和心理状态的综合洞察，为射箭等精准运动的智能化实时反馈系统奠定基础。

Abstract: In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.

</details>


### [153] [CafeMed: Causal Attention Fusion Enhanced Medication Recommendation](https://arxiv.org/abs/2511.14064)
*Kelin Ren,Chan-Yang Ju,Dong-Ho Lee*

Main category: cs.LG

TL;DR: CafeMed提出了一种结合动态因果推理与跨模态注意力的药物推荐框架，通过动态调节权重和捕捉诊断与操作间的复杂依赖关系，提升药物推荐的准确性和安全性。在MIMIC-III和MIMIC-IV数据集上的实验表明，该方法显著优于现有基线，同时保持较低的药物相互作用率。


<details>
  <summary>Details</summary>
Motivation: 现有药物推荐系统存在两个核心问题：一是将医疗实体视为独立特征，未能建模其协同效应；二是采用静态因果关系，无法适应患者个体化情境与健康状态。因此需要一种能动态调整因果影响并捕捉多模态交互的新型方法。

Method: CafeMed引入两个关键组件：1）因果权重生成器（CWG），根据患者状态将静态因果效应转化为动态调制权重；2）通道协调注意力优化模块（CHARM），用于捕获诊断与操作之间的复杂相互依赖关系。整体框架融合动态因果推理与跨模态注意力机制，实现安全、个性化的药物推荐。

Result: 在MIMIC-III和MIMIC-IV数据集上，CafeMed在药物预测准确性方面显著优于现有先进方法，并且药物-药物相互作用率更低，验证了其临床适用性与安全性。

Conclusion: 引入动态因果关系与跨模态协同效应能够显著提升药物推荐系统的个性化水平与临床合理性，为智能辅助诊疗提供有效支持。代码已公开。

Abstract: Medication recommendation systems play a crucial role in assisting clinicians with personalized treatment decisions. While existing approaches have made significant progress in learning medication representations, they suffer from two fundamental limitations: (i) treating medical entities as independent features without modeling their synergistic effects on medication selection; (ii) employing static causal relationships that fail to adapt to patient-specific contexts and health states. To address these challenges, we propose CafeMed, a framework that integrates dynamic causal reasoning with cross-modal attention for safe and accurate medication recommendation. CafeMed introduces two key components: the Causal Weight Generator (CWG) that transforms static causal effects into dynamic modulation weights based on individual patient states, and the Channel Harmonized Attention Refinement Module (CHARM) that captures complex interdependencies between diagnoses and procedures. This design enables CafeMed to model how different medical conditions jointly influence treatment decisions while maintaining medication safety constraints. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that CafeMed significantly outperforms state-of-the-art baselines, achieving superior accuracy in medication prediction while maintaining the lower drug--drug interaction rates. Our results indicate that incorporating dynamic causal relationships and cross-modal synergies leads to more clinically-aligned and personalized medication recommendations. Our code is released publicly at https://github.com/rkl71/CafeMed.

</details>


### [154] [CFG-EC: Error Correction Classifier-Free Guidance](https://arxiv.org/abs/2511.14075)
*Nakkyu Yang,Yechan Lee,SooJean Han*

Main category: cs.LG

TL;DR: CFG-EC 是一种适用于任何基于 CFG 的方法的通用修正方案，通过优化无条件噪声预测来减少训练与采样过程中的不一致问题。它使无条件噪声误差分量与条件误差分量正交，从而降低干扰，提升生成质量与提示对齐度，尤其在低引导采样场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: CFG 在采样过程中同时输出无条件和条件提示，导致训练与采样阶段的噪声估计不一致，影响生成质量与提示忠实度。

Method: 提出 CFG-EC，通过主动调整无条件噪声预测，使其与条件误差分量正交，以减少两者的干扰，约束采样误差上界。

Result: 数值实验表明，CFG-EC 在低引导采样时性能显著优于 CFG 和 CFG++，且在所有条件下均实现更高的提示对齐度。

Conclusion: CFG-EC 有效缓解了 CFG 中无条件与条件噪声之间的干扰，提升了生成图像的保真度与提示一致性，是一种高效且通用的改进方案。

Abstract: Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.

</details>


### [155] [Observational Auditing of Label Privacy](https://arxiv.org/abs/2511.14084)
*Iden Kalemaj,Luca Melis,Maxime Boucher,Ilya Mironov,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 提出一种无需修改训练数据的观测审计框架，利用数据分布的固有随机性进行差分隐私评估，扩展了隐私审计范围至受保护属性（如标签），在Criteo和CIFAR-10上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私审计方法需修改训练数据（如注入异常样本或删除样本），在大规模系统中成本高、工程复杂；亟需无需干预原数据的高效审计方法。

Method: 基于数据分布的固有随机性，构建观测型审计框架，实现对标签及其他受保护属性的隐私泄露评估，无需修改训练数据。

Result: 在Criteo和CIFAR-10数据集上的实验表明，该方法能有效评估标签隐私保护水平，且无需改动原始训练数据。

Conclusion: 所提框架为大规模生产环境中的实用化隐私审计提供了新路径，突破了传统方法对数据修改的依赖。

Abstract: Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.

</details>


### [156] [MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts](https://arxiv.org/abs/2511.14102)
*Wenfeng Wang,Jiacheng Liu,Xiaofeng Hou,Xinfeng Xia,Peng Tang,Mingxuan Zhang,Chao Li,Minyi Guo*

Main category: cs.LG

TL;DR: MoE-SpeQ提出一种新型推理系统，通过推测执行与专家卸载的协同设计，利用小型设备端草稿模型预测未来令牌所需的专家，提前从主机内存预取专家，从而隐藏数据移动延迟，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型在推理时面临巨大的内存需求，将专家卸载到主机内存会引入严重的PCIe I/O瓶颈，且由于专家选择的数据依赖性，同步传输直接位于执行关键路径上，严重影响性能。

Method: 采用小型设备端草稿模型预测未来令牌所需专家；运行时协调器据此预取专家；基于折旧屋顶模型的自适应调节器动态优化推测策略以适配硬件。

Result: 在内存受限设备上对Phi-MoE模型的评估显示，MoE-SpeQ相比最先进的卸载框架最高实现2.34倍加速。

Conclusion: 该工作建立了一种管理资源受限环境下数据依赖性内存访问的新原则性方法，使MoE推理更适用于通用硬件。

Abstract: The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.
  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.

</details>


### [157] [Soft-Label Training Preserves Epistemic Uncertainty](https://arxiv.org/abs/2511.14117)
*Agamdeep Singh,Ashish Tiwari,Hosein Hasanbeig,Priyanshu Gupta*

Main category: cs.LG

TL;DR: 本文提出在机器学习任务中，标注分布应被视为真实标签，而非简单地合并为单一标签。通过软标签训练，模型能更好地保留认知不确定性，在视觉和自然语言处理任务中显著降低与人类标注的KL散度（32%）并增强模型与标注熵的相关性（61%），同时保持与硬标签训练相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 标准做法将多样的人类标注合并为单一标签，忽略了数据固有的模糊性，导致模型对本质上模糊的情况表现出虚假的确定性，造成模型置信度与人类感知多样性之间的不一致。

Method: 采用软标签训练，将标注分布作为模型学习的目标，直接建模人类标注的不确定性，避免信息损失。

Result: 在多个视觉和NLP任务上，软标签训练使模型与人类标注的KL散度降低32%，模型与标注熵的相关性提升61%，且准确率与硬标签训练相当。

Conclusion: 标注分布不应被当作需要聚合的噪声信号，而应被视为反映认知不确定性的忠实表示，模型应学会重现这种不确定性。

Abstract: Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.

</details>


### [158] [Synthetic Survival Control: Extending Synthetic Controls for "When-If" Decision](https://arxiv.org/abs/2511.14133)
*Jessy Xinyi Han,Devavrat Shah*

Main category: cs.LG

TL;DR: 本文提出Synthetic Survival Control (SSC)方法，用于在面板数据中估计因果生存分析的反事实风险轨迹，解决观察性数据中的删失、样本量小和治疗分配非随机等问题。通过低秩结构框架，提供识别性和有限样本保证，并在多国癌症治疗数据中验证，发现新疗法可降低风险率，提升生存率。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，常需回答‘如果某干预何时发生’的问题，但观察性数据存在删失、样本量小及非随机治疗分配等挑战，导致因果效应估计困难。

Method: 提出SSC方法，将目标单位的反事实风险轨迹建模为其他单位观测轨迹的加权组合，并引入具有低秩结构的面板框架进行理论支持。

Result: 在多国癌症治疗数据上验证，新疗法的引入与更低的风险轨迹相关，表明其改善了生存率；方法具备理论保障和实际应用价值。

Conclusion: SSC框架为基于观察数据的反事实生存推断提供了通用且可解释的工具，适用于医学、经济和公共政策等多个领域。

Abstract: Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such "when-if" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.

</details>


### [159] [Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation](https://arxiv.org/abs/2511.14135)
*Promise Ekpo,Saesha Agarwal,Felix Grimm,Lekan Molu,Angelique Taylor*

Main category: cs.LG

TL;DR: 本文提出一种名为Fair-GNE的新型多智能体强化学习框架，旨在解决医疗工作者调度场景中任务负载分配不公的问题。通过将MARL建模为约束型广义纳什均衡（GNE）问题，实现自洽、不可篡改的公平性保障。实验在高保真心肺复苏模拟器中验证，结果表明Fair-GNE在负载均衡上显著优于传统基线方法（JFI：0.89 vs. 0.33，p < 0.01），同时保持86%的任务成功率，证明其在维持性能的同时实现了显著的公平性提升。


<details>
  <summary>Details</summary>
Motivation: 在多智能体学习驱动的医疗人员调度系统中，如何确保各智能体间工作负载的公平分配至关重要。现有方法依赖事后奖励设计来促进公平，缺乏可验证且不可被个体智能体操纵的自强制公平机制。尤其在资源共享环境下，个体行为相互影响，亟需一种内在公平、稳定且高效的协调机制。

Method: 本文提出基于约束广义纳什均衡（GNE）的Fair-GNE框架，将多智能体学习建模为一个博弈论问题，其中每个智能体的目标是最大化自身效用，但受限于全局公平性约束。通过设计可适应的约束机制，使系统收敛至一个安全且局部高效的均衡点，即任一智能体无法单方面改变策略以获得更好收益。该方法无需外部干预，具备自洽性和抗操纵性。

Result: 在自研的高保真心肺复苏模拟器中，Fair-GNE在所有实验条件下均表现出显著更高的工作负载均衡性（JFI达0.89，相较固定惩罚基线0.33，p < 0.01），同时保持86%的任务成功完成率，证明其在保证系统性能的前提下有效提升了公平性。

Conclusion: Fair-GNE通过将多智能体学习置于广义纳什均衡的理论框架下，实现了内在、可验证且不可篡改的公平性保障。该方法不仅在理论上具有坚实基础，在实际医疗协作场景中也展现出优越的性能与稳定性，为大规模多智能体学习系统中的公平性设计提供了可复现、可解释的解决方案。

Abstract: Enforcing a fair workload allocation among multiple agents tasked to achieve an objective in learning enabled demand side healthcare worker settings is crucial for consistent and reliable performance at runtime. Existing multi-agent reinforcement learning (MARL) approaches steer fairness by shaping reward through post hoc orchestrations, leaving no certifiable self-enforceable fairness that is immutable by individual agents at runtime. Contextualized within a setting where each agent shares resources with others, we address this shortcoming with a learning enabled optimization scheme among self-interested decision makers whose individual actions affect those of other agents. This extends the problem to a generalized Nash equilibrium (GNE) game-theoretic framework where we steer group policy to a safe and locally efficient equilibrium, so that no agent can improve its utility function by unilaterally changing its decisions. Fair-GNE models MARL as a constrained generalized Nash equilibrium-seeking (GNE) game, prescribing an ideal equitable collective equilibrium within the problem's natural fabric. Our hypothesis is rigorously evaluated in our custom-designed high-fidelity resuscitation simulator. Across all our numerical experiments, Fair-GNE achieves significant improvement in workload balance over fixed-penalty baselines (0.89 vs.\ 0.33 JFI, $p < 0.01$) while maintaining 86\% task success, demonstrating statistically significant fairness gains through adaptive constraint enforcement. Our results communicate our formulations, evaluation metrics, and equilibrium-seeking innovations in large multi-agent learning-based healthcare systems with clarity and principled fairness enforcement.

</details>


### [160] [A Comprehensive Study of Implicit and Explicit Biases in Large Language Models](https://arxiv.org/abs/2511.14153)
*Fatima Kazi,Alex Young,Yash Inani,Setareh Rafatirad*

Main category: cs.LG

TL;DR: 该研究针对大语言模型（LLMs）中的显性和隐性偏见问题，提出了一种自动化偏见识别框架，通过StereoSet和CrowSPairs等基准测试评估了BERT和GPT 3.5等模型的偏见表现。研究采用双管齐下的方法检测显性和隐性偏见，发现微调模型在性别偏见上表现不佳，但在种族偏见上表现较好，且普遍依赖关键词。通过词袋分析揭示了词汇层面的隐性刻板印象。通过提示工程和数据增强进行微调后，模型在跨数据集测试中展现出更强适应性，隐性偏见检测性能提升最高达20%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型从训练数据中继承了显性和隐性偏见，可能加剧社会刻板印象和错误信息传播，因此需要有效识别与缓解这些偏见以确保输出公平性。随着生成式AI的广泛应用，解决此问题尤为迫切。

Method: 采用多模型对比分析，结合显性与隐性偏见检测方法；利用StereoSet和CrowSPairs等基准测试评估模型表现；提出自动化偏见识别框架；应用词袋分析探索隐性偏见；通过提示工程与数据增强对模型进行优化。

Result: 微调后的模型在隐性偏见识别任务中表现显著提升，跨数据集测试中具备更强泛化能力，性能最高提升20%；但对性别偏见仍存在处理不足；模型仍过度依赖关键词。

Conclusion: 尽管现有模型在部分偏见检测上取得进展，但对性别偏见的应对仍不充分，且普遍存在关键词依赖问题。通过提示工程与数据增强可有效提升模型对隐性偏见的识别能力，为构建更公平的生成式AI系统提供了可行路径。

Abstract: Large Language Models (LLMs) inherit explicit and implicit biases from their training datasets. Identifying and mitigating biases in LLMs is crucial to ensure fair outputs, as they can perpetuate harmful stereotypes and misinformation. This study highlights the need to address biases in LLMs amid growing generative AI. We studied bias-specific benchmarks such as StereoSet and CrowSPairs to evaluate the existence of various biases in multiple generative models such as BERT and GPT 3.5. We proposed an automated Bias-Identification Framework to recognize various social biases in LLMs such as gender, race, profession, and religion. We adopted a two-pronged approach to detect explicit and implicit biases in text data. Results indicated fine-tuned models struggle with gender biases but excelled at identifying and avoiding racial biases. Our findings illustrated that despite having some success, LLMs often over-relied on keywords. To illuminate the capability of the analyzed LLMs in detecting implicit biases, we employed Bag-of-Words analysis and unveiled indications of implicit stereotyping within the vocabulary. To bolster the model performance, we applied an enhancement strategy involving fine-tuning models using prompting techniques and data augmentation of the bias benchmarks. The fine-tuned models exhibited promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.

</details>


### [161] [Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts](https://arxiv.org/abs/2511.14218)
*Xinlei Xiong,Wenbo Hu,Shuxun Zhou,Kaifeng Bi,Lingxi Xie,Ying Liu,Richang Hong,Qi Tian*

Main category: cs.LG

TL;DR: 本文提出了一种统一的混合贝叶斯深度学习框架，用于集合天气预报，通过变分推断和物理信息的随机扰动方案，显式分解预测不确定性为认知不确定性和偶然不确定性。该框架在ERA5再分析数据集上验证，显著提升预报准确率与不确定性校准，并在计算效率上优于现有概率扩散模型。


<details>
  <summary>Details</summary>
Motivation: 传统集合预报（EPS）虽能处理大气混沌带来的不确定性，但计算成本高；而贝叶斯深度学习（BDL）虽具潜力，却常与传统方法脱节。本文旨在融合两者，建立统一理论框架，实现高效且可解释的不确定性量化。

Method: 提出一种混合贝叶斯深度学习框架，利用变分推断学习认知不确定性，结合物理信息的随机扰动建模流依赖的大气动力学以捕捉偶然不确定性，构建连接BDL与EPS的统一理论体系。

Result: 在1979-2019年、0.25°分辨率的大型ERA5数据集上实验表明，该方法在预报精度、不确定性校准和计算效率方面均优于现有先进模型，尤其在降低计算开销的同时保持高性能。

Conclusion: 所提出的混合贝叶斯深度学习框架成功实现了对天气预报中不确定性的有效分解与建模，兼具理论严谨性与实际应用优势，为未来高精度、低耗时的概率化气象预测提供了新范式。

Abstract: Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25° spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.

</details>


### [162] [EBind: a practical approach to space binding](https://arxiv.org/abs/2511.14229)
*Jim Broadbent,Felix Cohen,Frederik Hvilshøj,Eric Landau,Eren Sasoglu*

Main category: cs.LG

TL;DR: 提出EBind方法，通过单一模态编码器和高质量数据，实现多模态嵌入空间的高效对齐，在单个GPU上数小时内训练出高性能模型，1.8B参数模型性能超越4-17倍更大的模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态嵌入空间对齐中依赖复杂架构和大量计算资源，难以高效训练大规模模型；同时缺乏高质量、多样化的数据支持。

Method: 采用单一模态编码器、精心构建的三类高质量数据集（自动化五元组、人工标注的三元组、已有带字幕数据），结合参数高效训练策略实现多模态嵌入对齐。

Result: 1.8B参数模型在多个任务上超越4-17倍更大的模型；引入首个高质量跨音频与PC的零样本分类基准；所有代码、模型权重和数据集开源。

Conclusion: 通过数据驱动与参数效率优化，EBind实现了高效且高性能的多模态对齐，为未来多模态学习提供了可复现、可扩展的新范式。

Abstract: We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.

</details>


### [163] [Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention](https://arxiv.org/abs/2511.14265)
*Rui Zhang,Chao Li,Kezhong Liu,Chen Wang,Bolong Zheng,Hongbo Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种统一的多模态船舶轨迹预测框架，通过引入可解释的航行意图（分为持续性与瞬时性两类），提升了模型在复杂海事环境中的适用性和可解释性。利用历史轨迹构建持续性意图树，采用条件变分自编码器（CVAE）建模动态瞬时意图，并结合非局部注意力机制保持全局场景一致性。实验基于真实AIS数据集验证了方法在多种场景下的有效性，在ADE和FDE指标上均有显著提升，同时能够明确揭示预测轨迹背后的航行意图。


<details>
  <summary>Details</summary>
Motivation: 现有船舶多模态轨迹预测方法在复杂海事环境中存在场景适用性有限和可解释性不足的问题，难以有效捕捉快速行为变化并提供清晰的决策依据。

Method: 构建持续性意图树以分析历史轨迹，使用条件变分自编码器（CVAE）建模动态瞬时意图，结合非局部注意力机制确保全局场景一致性，实现对航行意图的显式建模与可解释预测。

Result: 在真实AIS数据集上的实验表明，该方法在多种复杂场景下均表现出色，显著优于现有方法，在ADE和FDE指标上均有提升；同时具备良好的可解释性，能清晰揭示预测轨迹背后的航行意图。

Conclusion: 所提出的统一多模态轨迹预测框架通过融合可解释的航行意图建模，有效解决了现有方法在场景适应性与可解释性方面的局限，为智能海事系统提供了更可靠、更透明的轨迹预测能力。

Abstract: Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.

</details>


### [164] [Comparing Task-Agnostic Embedding Models for Tabular Data](https://arxiv.org/abs/2511.14276)
*Frederik Hoppe,Lars Kleinemeier,Astrid Franz,Udo Göbel*

Main category: cs.LG

TL;DR: 该研究聚焦于表格数据基础模型中的表示学习，评估了任务无关的嵌入（如TabPFN、TabICL与TableVectorizer），发现经典特征工程方法TableVectorizer在多种任务中表现相当或更优，且速度提升达三个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有表格基础模型虽在特定任务上表现优异，但其将表示学习与任务推理一体化，导致资源消耗大。本研究旨在探索更高效、可迁移的任务无关表示学习方法。

Method: 系统评估了TabPFN、TabICL与TableVectorizer三种方法在异常检测（ADBench）和监督学习（TabArena Lite）等任务中的表现，比较其性能与计算效率。

Result: TableVectorizer在性能上与基础模型相当或更优，且计算速度提升达三个数量级，展现出显著的效率优势。

Conclusion: 经典特征工程方法在任务无关表示学习中具有竞争力，且远优于当前主流基础模型的效率，应被重新重视。

Abstract: Recent foundation models for tabular data achieve strong task-specific performance via in-context learning. Nevertheless, they focus on direct prediction by encapsulating both representation learning and task-specific inference inside a single, resource-intensive network. This work specifically focuses on representation learning, i.e., on transferable, task-agnostic embeddings. We systematically evaluate task-agnostic representations from tabular foundation models (TabPFN and TabICL) alongside with classical feature engineering (TableVectorizer) across a variety of application tasks as outlier detection (ADBench) and supervised learning (TabArena Lite). We find that simple TableVectorizer features achieve comparable or superior performance while being up to three orders of magnitude faster than tabular foundation models. The code is available at https://github.com/ContactSoftwareAI/TabEmbedBench.

</details>


### [165] [Weight Variance Amplifier Improves Accuracy in High-Sparsity One-Shot Pruning](https://arxiv.org/abs/2511.14282)
*Vincent-Daniel Yun,Junhyuk Jo,Sunwoo Lee*

Main category: cs.LG

TL;DR: This paper introduces VAR, a variance-amplifying regularizer that boosts pruning robustness by increasing parameter variance during training. It provides theoretical support and strong empirical evidence showing superior performance over existing methods while avoiding high computational overhead.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks have high parameter counts, making them impractical for real-world use. One-shot pruning reduces model size without extra training, but standard training leads to significant accuracy drops after aggressive pruning. Existing methods like SAM and CrAM improve robustness by targeting flatter regions in parameter space but add substantial computational cost.

Method: Propose a Variance Amplifying Regularizer (VAR) that increases the variance of model parameters during training. The method leverages the observation that higher parameter variance correlates with better pruning robustness, thereby enhancing model resilience to pruning.

Result: Extensive empirical results show VAR significantly improves pruning robustness. Theoretical analysis supports its convergence behavior, demonstrating effectiveness without incurring major additional computational costs.

Conclusion: VAR effectively enhances model robustness to aggressive one-shot pruning by increasing parameter variance, offering a computationally efficient alternative to existing methods.

Abstract: Deep neural networks achieve outstanding performance in visual recognition tasks, yet their large number of parameters makes them less practical for real-world applications. Recently, one-shot pruning has emerged as an effective strategy for reducing model size without additional training. However, models trained with standard objective functions often suffer a significant drop in accuracy after aggressive pruning. Some existing pruning-robust optimizers, such as SAM, and CrAM, mitigate this accuracy drop by guiding the model toward flatter regions of the parameter space, but they inevitably incur non-negligible additional computations. We propose a Variance Amplifying Regularizer (VAR) that deliberately increases the variance of model parameters during training. Our study reveals an intriguing finding that parameters with higher variance exhibit greater pruning robustness. VAR exploits this property by promoting such variance in the weight distribution, thereby mitigating the adverse effects of pruning. We further provide a theoretical analysis of its convergence behavior, supported by extensive empirical results demonstrating the superior pruning robustness of VAR.

</details>


### [166] [H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata](https://arxiv.org/abs/2511.14312)
*Chenyang Xu,Siming Li,Hao Wang*

Main category: cs.LG

TL;DR: 提出H-LDM，一种用于生成临床准确且可控的心音图（PCG）信号的分层潜在扩散模型。通过多尺度变分自编码器学习生理解耦的潜在空间，分离心律、心音和杂音；构建基于丰富临床元数据的细粒度控制文本到生物信号管道；引入新型医学注意力模块引导可解释的扩散过程。在PhysioNet CirCor数据集上表现优异，弗雷歇音频距离达9.7，属性解耦率达92%，临床有效性获心脏病专家验证达87.1%。合成数据增强诊断模型后，罕见病分类准确率提升11.3%。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标注的病理数据，人工智能系统在心音图分析中的能力受限。为解决数据稀缺问题，需生成高质量、可控且临床有效的合成心音图数据。

Method: 采用多尺度变分自编码器构建生理解耦的潜在空间；设计分层文本到生物信号生成管道，利用临床元数据实现对17种不同病症的精细控制；引入医学注意力机制指导扩散过程，提升生成结果的可解释性与临床相关性。

Result: 在PhysioNet CirCor数据集上，模型达到9.7的弗雷歇音频距离，92%的属性解耦分数，87.1%的临床有效性评分。使用合成数据训练的诊断模型在罕见病分类任务中准确率提升11.3%。

Conclusion: H-LDM为心脏诊断中的数据增强提供了新方向，有效缓解数据稀缺问题，同时提供可解释的临床洞察，推动智能医疗发展。

Abstract: Phonocardiogram (PCG) analysis is vital for cardiovascular disease diagnosis, yet the scarcity of labeled pathological data hinders the capability of AI systems. To bridge this, we introduce H-LDM, a Hierarchical Latent Diffusion Model for generating clinically accurate and controllable PCG signals from structured metadata. Our approach features: (1) a multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs; (2) a hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions; and (3) an interpretable diffusion process guided by a novel Medical Attention module. Experiments on the PhysioNet CirCor dataset demonstrate state-of-the-art performance, achieving a Fréchet Audio Distance of 9.7, a 92% attribute disentanglement score, and 87.1% clinical validity confirmed by cardiologists. Augmenting diagnostic models with our synthetic data improves the accuracy of rare disease classification by 11.3\%. H-LDM establishes a new direction for data augmentation in cardiac diagnostics, bridging data scarcity with interpretable clinical insights.

</details>


### [167] [Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect](https://arxiv.org/abs/2511.14317)
*Yuwen Zhang,Viet Tran,Paul Weng*

Main category: cs.LG

TL;DR: 本文针对临床机器学习中因多重模型表现相近（即Rashomon效应）带来的可信部署与评估难题，提出两种互补工具：干预效率（IE）和扰动验证框架（PVF）。IE衡量模型在有限干预条件下识别可操作真阳性事件的效率，将预测性能与临床实用性关联；PVF通过数据扰动评估模型稳定性，筛选出在噪声或数据分布偏移下表现最稳健的模型。实验表明，该方法能有效选择更鲁棒且符合资源约束的模型，为解决临床场景中的Rashomon效应提供新思路。


<details>
  <summary>Details</summary>
Motivation: 临床机器学习中存在多个性能相近的模型，导致模型选择困难；小样本、不平衡、噪声数据及高维弱识别特征加剧了这一问题，传统评估指标如F1分数忽略资源限制与实际操作优先级，难以保障模型部署的可靠性与可解释性。

Method: 提出干预效率（IE）作为容量感知指标，量化模型在有限干预条件下的临床实用性；设计扰动验证框架（PVF），系统评估模型在数据扰动下的稳定性，从而筛选出更具泛化能力的模型。

Result: 在合成与真实医疗数据集上的实证结果显示，结合IE与PVF可有效识别出泛化能力更强、更符合实际资源约束的模型，显著提升模型选择的可靠性与临床适用性。

Conclusion: 通过引入IE与PVF，本文为应对临床机器学习中的Rashomon效应提供了可操作的评估与选择框架，有助于实现更稳健、更具临床意义的模型部署。

Abstract: In clinical machine learning, the coexistence of multiple models with comparable performance -- a manifestation of the Rashomon Effect -- poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.

</details>


### [168] [Learning with Statistical Equality Constraints](https://arxiv.org/abs/2511.14320)
*Aneesh Barthakur,Luiz F. O. Chamon*

Main category: cs.LG

TL;DR: 本文针对机器学习中除准确率外的多种需求（如公平性、边界值问题）带来的挑战，提出一种基于等式约束的统计学习泛化理论。传统加权惩罚方法需繁琐调参，尤其在等式约束下失效；而现有约束优化方法缺乏对等式约束的通用保证。本文通过建立等式约束学习的泛化理论，提出一种可实用的算法：通过求解一系列无约束经验学习问题来近似原问题解。该方法在公平学习、插值分类器和边界值问题中表现优异，展示了等式约束带来的新可能性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习优化依赖加权惩罚处理多目标需求，但需大量超参数调优，尤其在涉及等式约束（如公平性、边界条件）时效率低下且缺乏理论保障。现有约束优化方法无法有效处理等式约束，限制了其应用范围。

Method: 构建等式约束统计学习问题的泛化理论，证明其解可通过样本和丰富参数化逼近；设计一种迭代算法，将原等式约束问题转化为一系列无约束的经验学习问题求解。

Result: 所提算法在公平学习、插值分类器及边界值问题中均表现出色，验证了等式约束建模的有效性和实用性；理论分析提供了对等式约束学习问题的通用泛化保证。

Conclusion: 本文建立了等式约束学习的泛化理论基础，提出了一种高效、可扩展的算法框架，显著提升了复杂需求下的机器学习系统设计能力，为公平性、边界控制等关键场景提供了新工具。

Abstract: As machine learning applications grow increasingly ubiquitous and complex, they face an increasing set of requirements beyond accuracy. The prevalent approach to handle this challenge is to aggregate a weighted combination of requirement violation penalties into the training objective. To be effective, this approach requires careful tuning of these hyperparameters (weights), involving trial-and-error and cross-validation, which becomes ineffective even for a moderate number of requirements. These issues are exacerbated when the requirements involve parities or equalities, as is the case in fairness and boundary value problems. An alternative technique uses constrained optimization to formulate these learning problems. Yet, existing approximation and generalization guarantees do not apply to problems involving equality constraints. In this work, we derive a generalization theory for equality-constrained statistical learning problems, showing that their solutions can be approximated using samples and rich parametrizations. Using these results, we propose a practical algorithm based on solving a sequence of unconstrained, empirical learning problems. We showcase its effectiveness and the new formulations enabled by equality constraints in fair learning, interpolating classifiers, and boundary value problems.

</details>


### [169] [Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406)
*Bastien Vuillod,Pierre-Alain Moellic,Jean-Max Dutertre*

Main category: cs.LG

TL;DR: 本文首次分析了低秩适配（LoRA）对联邦学习（FL）中针对大模型适配的先进后门攻击的影响，重点研究了后门生命周期这一关键特性。实验发现，在最优注入情况下，LoRA的秩越低，后门在攻击后的持续时间越长。研究还揭示了现有后门攻击评估中的问题，推动了更鲁棒、公平的评估方法发展，提升了对关键FL系统风险评估的可靠性。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前联邦学习中使用参数高效微调技术（如LoRA）进行大模型适配面临后门攻击等安全威胁，尤其是攻击者可在客户端本地训练阶段注入恶意行为。现有研究缺乏对LoRA在后门攻击中作用的系统分析，且评估方法可能存在偏差，亟需更可靠的风险评估框架。

Method: 通过构建基于LoRA的联邦学习场景，模拟多种后门攻击情境，系统评估不同LoRA秩设置下后门的注入成功率与持久性，分析后门生命周期的变化规律，并对比现有评估方法的局限性。

Result: 实验表明，当后门以最优方式注入时，较低的LoRA秩会导致后门在模型更新后具有更长的存活时间；同时揭示了现有评估体系在衡量后门攻击效果时可能存在的偏差，影响风险判断的准确性。

Conclusion: LoRA的秩是影响后门攻击持久性的关键因素，低秩配置会增强后门的隐蔽性和长期存活能力。该研究强调了在评估联邦学习系统安全性时必须考虑适配技术的影响，为构建更稳健的后门攻击评估标准提供了依据。

Abstract: Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.

</details>


### [170] [Toward Robust and Harmonious Adaptation for Cross-modal Retrieval](https://arxiv.org/abs/2511.14416)
*Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 本文针对跨模态检索（CMR）中普遍存在的查询偏移（QS）问题，提出了一种名为REST的新方法。该方法同时应对在线偏移和多样偏移两大挑战：通过优化查询预测并设计鲁棒的目标函数来维持通用空间；利用梯度解耦模块防止模型遗忘通用知识。实验在20个基准上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有通用到定制化的跨模态检索方法假设可访问全部目标域数据，但现实中查询是在线到达且用户需求多样，导致查询偏移问题，使模型难以保持通用知识与有效检索性能。

Method: 提出REST方法，包括基于查询预测的在线适应机制与梯度解耦模块，以在在线和多样化查询场景下保持通用空间并避免知识遗忘。

Result: 在20个跨模态检索基准上的实验证明，REST在应对查询偏移方面显著优于现有方法，具备更强的鲁棒性与适应性。

Conclusion: REST通过在线优化与梯度解耦机制，成功缓解了跨模态检索中的查询偏移问题，在动态和多样的实际应用场景中表现出优异性能。

Abstract: Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.

</details>


### [171] [FlowRoI A Fast Optical Flow Driven Region of Interest Extraction Framework for High-Throughput Image Compression in Immune Cell Migration Analysis](https://arxiv.org/abs/2511.14419)
*Xiaowei Xu,Justin Sonneck,Hongxiao Wang,Roman Burkard,Hendrik Wohrle,Anton Grabmasier,Matthias Gunzer,Jianxu Chen*

Main category: cs.LG

TL;DR: FlowRoI is a fast, optical-flow-based framework for region of interest (RoI) extraction in high-throughput immune cell migration imaging. It enables efficient, RoI-aware image compression by combining optical flow estimation with JPEG2000 encoding, achieving up to 2.2x higher compression than standard JPEG2000 while maintaining superior image quality in cellular regions. The system runs at ~30 fps on a modern laptop, making it suitable for real-time, large-scale data processing.


<details>
  <summary>Details</summary>
Motivation: High-throughput imaging platforms like ComplexEye generate massive amounts of data, creating significant challenges for storage and transmission. There is a need for efficient, scalable compression methods that preserve critical biological information without compromising performance.

Method: FlowRoI uses optical flow to estimate motion between consecutive frames and generates accurate RoI masks covering migrating cells. These masks are used to guide JPEG2000 encoding, enabling selective compression of relevant regions while preserving image fidelity. The method is optimized for speed and compatibility with existing pipelines.

Result: FlowRoI achieves an average throughput of 30 frames per second on a laptop with Intel i7-1255U CPU. It provides 2.0–2.2x higher compression rates than standard JPEG2000 at the same PSNR, with improved PSNR in cellular regions, demonstrating superior efficiency and quality.

Conclusion: FlowRoI offers a computationally efficient, high-performance solution for compressing high-throughput live-cell imaging data in immune cell migration studies. Its ability to maintain high image quality while drastically reducing data size makes it highly suitable for clinical and large-scale research applications.

Abstract: Autonomous migration is essential for the function of immune cells such as neutrophils and plays a pivotal role in diverse diseases. Recently, we introduced ComplexEye, a multi-lens array microscope comprising 16 independent aberration-corrected glass lenses arranged at the pitch of a 96-well plate, capable of capturing high-resolution movies of migrating cells. This architecture enables high-throughput live-cell video microscopy for migration analysis, supporting routine quantification of autonomous motility with strong potential for clinical translation. However, ComplexEye and similar high-throughput imaging platforms generate data at an exponential rate, imposing substantial burdens on storage and transmission. To address this challenge, we present FlowRoI, a fast optical-flow-based region of interest (RoI) extraction framework designed for high-throughput image compression in immune cell migration studies. FlowRoI estimates optical flow between consecutive frames and derives RoI masks that reliably cover nearly all migrating cells. The raw image and its corresponding RoI mask are then jointly encoded using JPEG2000 to enable RoI-aware compression. FlowRoI operates with high computational efficiency, achieving runtimes comparable to standard JPEG2000 and reaching an average throughput of about 30 frames per second on a modern laptop equipped with an Intel i7-1255U CPU. In terms of image quality, FlowRoI yields higher peak signal-to-noise ratio (PSNR) in cellular regions and achieves 2.0-2.2x higher compression rates at matched PSNR compared to standard JPEG2000.

</details>


### [172] [MiAD: Mirage Atom Diffusion for De Novo Crystal Generation](https://arxiv.org/abs/2511.14426)
*Andrey Okhotin,Maksim Nakhodnov,Nikita Kazeev,Andrey E Ustyuzhanin,Dmitry Vetrov*

Main category: cs.LG

TL;DR: 本文提出了一种名为mirage infusion的新技术，使基于扩散的模型能够在生成过程中改变晶体中原子的数量，从而提升生成材料的多样性与质量。所提出的MiAD模型在MP-20数据集上实现了8.2%的S.U.N.率，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型无法在生成过程中改变晶体中原子数量，限制了采样轨迹的多样性与生成能力。

Method: 引入mirage infusion技术，使扩散模型能够实现原子从存在到不存在（mirage）状态的转换，构建了一个等变联合扩散模型用于从头生成晶体。

Result: MiAD模型在MP-20数据集上达到8.2%的S.U.N.率，模型质量相比未改进版本提升达2.5倍。

Conclusion: mirage infusion技术有效突破了传统扩散模型在原子数量变化上的限制，显著提升了晶体生成的稳定性、唯一性和新颖性，为新材料发现提供了新范式。

Abstract: In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \href{https://github.com/andrey-okhotin/miad.git}{\texttt{github.com/andrey-okhotin/miad}}.

</details>


### [173] [Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters](https://arxiv.org/abs/2511.14452)
*Emanuele Palumbo,Sorawit Saengkyongam,Maria R. Cervera,Jens Behrmann,Andrew C. Miller,Guillermo Sapiro,Christina Heinze-Deml,Antoine Wehenkel*

Main category: cs.LG

TL;DR: 本文提出一种混合方法，结合血流动力学模拟和未标注临床数据，从非侵入性光体积脉搏波图（PPG）信号中估计心血管生物标志物。该方法利用配对的PPG-动脉压波形（APW）数据训练条件变分自编码器，并基于标记的模拟APW片段训练条件密度估计器来预测心输出量和每搏输出量等关键心脏生物标志物。实验表明，该方法能够有效检测心输出量和每搏输出量的波动，在监测这些生物标志物的时间变化方面优于监督基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前连续心血管监测在精准健康中具有重要意义，但关键心脏生物标志物如心输出量和每搏输出量通常需要侵入式测量（如动脉压波形）。虽然光体积脉搏波图（PPG）是非侵入性且在医院中广泛使用，但从PPG准确预测这些生物标志物仍面临挑战，尤其受限于标注的PPG数据稀缺。因此，亟需一种无需大量标注数据即可实现高精度估计的方法。

Method: 提出一种混合框架：首先使用配对的PPG-APW数据训练条件变分自编码器（CVAE），以学习从PPG到模拟APW的映射；然后利用已标注的模拟APW片段训练条件密度估计器，直接从PPG推断心输出量和每搏输出量等生物标志物。整个模型融合了真实临床数据与仿真生成数据的优势，减少对人工标注的依赖。

Result: 实验结果显示，所提出的混合方法能有效捕捉心输出量和每搏输出量的动态变化，其性能优于仅依赖监督学习的基线模型，尤其在缺乏大量标注数据的情况下展现出更强的鲁棒性和泛化能力。

Conclusion: 本研究验证了结合血流动力学模拟与无标签临床数据的混合方法在非侵入式心血管生物标志物估计中的有效性，为未来在真实医疗场景中实现低成本、持续的心血管监测提供了可行路径。

Abstract: Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.

</details>


### [174] [nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers](https://arxiv.org/abs/2511.14465)
*Clément Dumas*

Main category: cs.LG

TL;DR: nnterp 是一个轻量级封装，基于 NNsight 提供统一的 Transformer 分析接口，兼顾 HuggingFace 模型的精确行为与跨架构的一致性。它通过自动模块重命名和验证测试，支持在 50+ 模型变体、16 种架构家族中复用干预代码，并内置常见可解释性方法（如 logit lens、patchscope、activation steering）及注意力概率访问功能，提升机制可解释性研究的正确性与易用性。


<details>
  <summary>Details</summary>
Motivation: 当前机制可解释性工具在一致性与精确性之间存在权衡：自定义实现（如 TransformerLens）虽具标准化接口但需手动适配各架构，易引入数值偏差；而直接使用 HuggingFace 的 NNsight 虽保留原始行为，却缺乏跨模型标准化。因此亟需一种兼具准确性和通用性的分析工具。

Method: nnterp 通过自动重命名模块、集成验证测试，将 NNsight 与 HuggingFace 实现无缝对接，构建统一接口。其核心是自动化兼容处理与内置测试套件，确保干预代码在多种模型上可靠运行。

Result: nnterp 可在 50+ 模型变体、16 种架构家族中实现一次编写、多处部署；支持常见可解释性方法，并提供注意力概率访问；内置验证测试帮助用户本地验证自定义模型兼容性。

Conclusion: nnterp 成功弥合了机制可解释性工具中正确性与可用性之间的鸿沟，为跨架构、跨模型的 Transformer 内部分析提供了高效、可靠的解决方案。

Abstract: Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.

</details>


### [175] [Notes on Kernel Methods in Machine Learning](https://arxiv.org/abs/2511.14485)
*Diego Armando Pérez-Rosero,Danna Valentina Salazar-Dubois,Juan Camilo Lugo-Rojas,Andrés Marino Álvarez-Meza,Germán Castellanos-Dominguez*

Main category: cs.LG

TL;DR: 本文系统介绍了核方法及其在机器学习中的几何基础，从希尔伯特空间出发，阐述正定核、再生核希尔伯特空间（RKHS）及希尔伯特-施密特算子的理论，并强调其在统计估计和概率测度表示中的作用。通过希尔伯特空间几何视角重新审视协方差、回归与信息度量等经典概念，引入核密度估计、分布的核嵌入及最大均值差异（MMD），为高斯过程、核贝叶斯推断及现代机器学习的功能分析方法奠定基础。


<details>
  <summary>Details</summary>
Motivation: 为了提供核方法在机器学习中几何基础的自包含介绍，帮助理解其在统计建模和概率表示中的核心作用，同时为更高级主题如高斯过程和核贝叶斯推断建立理论基础。

Method: 基于希尔伯特空间构建，发展正定核、再生核希尔伯特空间（RKHS）及希尔伯特-施密特算子的理论框架，结合几何视角重新分析经典统计概念，并引入核密度估计、分布核嵌入与最大均值差异（MMD）。

Result: 建立了核方法的完整理论框架，揭示了其在统计估计、概率测度表示以及现代机器学习中的广泛适用性，为后续研究提供了坚实基础。

Conclusion: 核方法的几何基础不仅深化了对传统统计概念的理解，也为现代机器学习中的高级技术（如高斯过程与核贝叶斯推断）提供了强有力的数学支持。

Abstract: These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.

</details>


### [176] [Towards Stable and Structured Time Series Generation with Perturbation-Aware Flow Matching](https://arxiv.org/abs/2511.14488)
*Jintao Zhang,Mingyue Cheng,Zirui Liu,Xianquan Wang,Yitong Zhou,Qi Liu*

Main category: cs.LG

TL;DR: PAFM 是一种针对扰动感知的时间序列生成框架，通过引入扰动引导训练和双路径速度场，有效捕捉局部扰动下的时间序列动态变化，结合混合专家解码器与流路由机制，提升了模型对不同轨迹动态的表达能力。在无条件和条件生成任务中，PAFM 均显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于流匹配的方法因使用全局共享参数，难以有效建模受局部扰动影响的时间序列中的突变行为，导致生成的时间序列结构不一致。因此需要一种能感知扰动并保持结构一致性的生成框架。

Method: 提出 PAFM 框架，包含扰动引导训练以模拟局部扰动，双路径速度场用于捕捉扰动下的轨迹偏移，并采用混合专家解码器结合流路由机制，动态分配建模能力以增强对不同动态的敏感性和表达力。

Result: 在多个无条件与条件时间序列生成任务上，PAFM 均取得优于现有强基线的结果，验证了其在生成结构一致、稳定时间序列方面的有效性。

Conclusion: PAFM 通过引入扰动感知机制与自适应建模结构，有效解决了传统流匹配在处理局部扰动时的局限性，为高质量时间序列生成提供了新范式。

Abstract: Time series generation is critical for a wide range of applications, which greatly supports downstream analytical and decision-making tasks. However, the inherent temporal heterogeneous induced by localized perturbations present significant challenges for generating structurally consistent time series. While flow matching provides a promising paradigm by modeling temporal dynamics through trajectory-level supervision, it fails to adequately capture abrupt transitions in perturbed time series, as the use of globally shared parameters constrains the velocity field to a unified representation. To address these limitations, we introduce \textbf{PAFM}, a \textbf{P}erturbation-\textbf{A}ware \textbf{F}low \textbf{M}atching framework that models perturbed trajectories to ensure stable and structurally consistent time series generation. The framework incorporates perturbation-guided training to simulate localized disturbances and leverages a dual-path velocity field to capture trajectory deviations under perturbation, enabling refined modeling of perturbed behavior to enhance the structural coherence. In order to further improve sensitivity to trajectory perturbations while enhancing expressiveness, a mixture-of-experts decoder with flow routing dynamically allocates modeling capacity in response to different trajectory dynamics. Extensive experiments on both unconditional and conditional generation tasks demonstrate that PAFM consistently outperforms strong baselines. Code is available at https://anonymous.4open.science/r/PAFM-03B2.

</details>


### [177] [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://arxiv.org/abs/2511.14510)
*Jiawei Yi,Ping Gong,Youhui Bai,Jiaqi Ruan,Shengnan Wang,Pengcheng Wang,Haibo Wang,Weiguang Wang,Xia Zhu,Feng Wu,Cheng Li*

Main category: cs.LG

TL;DR: CLO是一个通过算法-系统协同设计实现的轻量级CPU KVCache卸载系统，旨在解决大规模语言模型推理中因KVCache导致的内存和传输瓶颈。它采用粗粒度按头近似GPU缓存、数据预取与持久缓存结合、零拷贝传输引擎及以GPU为中心的同步机制，显著降低CPU开销、充分利用PCIe带宽，使解码吞吐提升9.3%-66.6%。


<details>
  <summary>Details</summary>
Motivation: 现有KVCache卸载系统虽通过top-k注意力和系统优化减少数据传输，但忽视了CPU端在细粒度缓存管理、PCIe带宽利用率低以及GPU运行时空洞等方面的瓶颈，限制了整体性能提升。

Method: 提出CLO系统，包含：(1) 粗粒度头级别近似GPU缓存策略，减少缓存管理开销；(2) 预取与持久缓存无缝结合，降低传输开销；(3) 零拷贝传输引擎以最大化PCIe带宽；(4) 以GPU为中心的同步方法消除GPU停顿。

Result: 在两个主流LLM上评估显示，CLO在保持与先进系统相当精度的同时，显著降低CPU负载、完全利用PCIe带宽，解码吞吐提升9.3%-66.6%。

Conclusion: 算法-系统协同设计对现代GPU平台上的内存受限大模型推理至关重要，CLO展示了其在性能与资源效率上的巨大潜力。

Abstract: The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.

</details>


### [178] [MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation](https://arxiv.org/abs/2511.14543)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: 本文提出了一种混合确定性扩散框架，用于处理包含数值、类别和离散属性的异构表格数据中的缺失值问题。该框架将特征分为两个互补的生成通道：基于DDIM的连续通道用于高效稳定地对数值变量进行确定性去噪；基于漏洞引导的离散潜在路径扩散通道则能保持类别和离散变量在其有效样本流形上建模。两者在统一的条件插补目标下联合训练，实现对混合类型不完整数据的一致重建。实验表明，该方法在多种真实数据集上优于现有扩散模型及经典方法，在各类缺失机制（MCAR、MAR、MNAR）下均表现出更高的准确性、更稳定的采样轨迹和更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的插补模型通常假设特征空间同质，依赖随机去噪轨迹，难以维持条件一致性，且在处理类别变量时易导致信息坍塌，或在需要确定性更新的数值变量上出现不稳定。这表明单一扩散过程不足以应对混合类型表格数据的插补挑战。

Method: 提出一种混合确定性扩散框架，将异构特征分为两个生成通道：1）基于DDIM的连续通道，用于数值变量的确定性去噪；2）基于漏洞引导的离散潜在路径扩散通道，用于建模类别和离散变量，确保其不脱离有效样本流形。两通道在统一条件插补目标下联合训练，实现跨类型协同重建。

Result: 在多个真实世界数据集上的实验表明，所提框架在各类缺失机制（MCAR、MAR、MNAR）下均显著提升插补精度，具有更稳定的采样轨迹和更强的鲁棒性，优于现有扩散模型与经典方法。

Conclusion: 结构感知的扩散过程对推进深度学习在不完整表格数据上的应用至关重要。通过分离异构特征并设计针对性的生成通道，可有效克服传统扩散模型在混合类型数据中的局限性，为复杂数据插补提供了新范式。

Abstract: Incomplete data are common in real-world tabular applications, where numerical, categorical, and discrete attributes coexist within a single dataset. This heterogeneous structure presents significant challenges for existing diffusion-based imputation models, which typically assume a homogeneous feature space and rely on stochastic denoising trajectories. Such assumptions make it difficult to maintain conditional consistency, and they often lead to information collapse for categorical variables or instability when numerical variables require deterministic updates. These limitations indicate that a single diffusion process is insufficient for mixed-type tabular imputation.
  We propose a hybrid deterministic diffusion framework that separates heterogeneous features into two complementary generative channels. A continuous DDIM-based channel provides efficient and stable deterministic denoising for numerical variables, while a discrete latent-path diffusion channel, inspired by loopholing-based discrete diffusion, models categorical and discrete features without leaving their valid sample manifolds. The two channels are trained under a unified conditional imputation objective, enabling coherent reconstruction of mixed-type incomplete data.
  Extensive experiments on multiple real-world datasets show that the proposed framework achieves higher imputation accuracy, more stable sampling trajectories, and improved robustness across MCAR, MAR, and MNAR settings compared with existing diffusion-based and classical methods. These results demonstrate the importance of structure-aware diffusion processes for advancing deep learning approaches to incomplete tabular data.

</details>


### [179] [Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction](https://arxiv.org/abs/2511.14544)
*Jaume Ros,Alessio Arleo,Fernando Paulovich*

Main category: cs.LG

TL;DR: 本文提出了一种新的二维投影质量度量方法——扭曲指数（Warping Index, WI），旨在评估降维（DR）投影在视觉上对数据结构的忠实程度。与现有方法主要关注全局或局部结构保持不同，WI特别强调空区域（即点之间的空白空间）的保留，因为这些区域对于避免视觉误导至关重要。该指标能够识别出可能由异常值或伪影引起的视觉失真，从而提升可视化分析的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的投影质量度量（PQMs）大多只关注数据的全局或局部结构保持，而忽略了投影图中可能出现的视觉失真，如异常值或伪影造成的误导性布局，这可能导致用户得出错误结论。因此，亟需一种能反映视觉保真度的新指标。

Method: 提出基于空区域保留假设的扭曲指数（WI），通过量化投影前后点之间空区域的变化来衡量投影质量，特别关注视觉上不连续或失真的部分。

Result: 实验表明，该指标能有效检测出传统度量忽略的视觉失真，尤其在存在异常值或非均匀分布时表现更优，提升了对降维结果可靠性的评估能力。

Conclusion: 扭曲指数（WI）为降维投影提供了一个新的、更贴近人类视觉感知的质量评估标准，有助于防止因视觉失真导致的误判，增强了数据可视化的可信度。

Abstract: Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.

</details>


### [180] [Task Addition and Weight Disentanglement in Closed-Vocabulary Models](https://arxiv.org/abs/2511.14569)
*Adam Hazimeh,Alessandro Favero,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文研究了任务算术在闭词汇图像分类模型中的应用，发现预训练带来的权重解耦特性使任务算术在闭词汇视觉变压器中同样有效，且线性探测可作为竞争性基线，拓展了任务算术的适用范围。


<details>
  <summary>Details</summary>
Motivation: 现有任务算术主要应用于开词汇模型，而大量未受语言监督的闭词汇模型尚未被探索，亟需研究其是否适用于任务算术编辑。

Method: 在多种预训练方案下评估闭词汇视觉模型的任务算术性能，分析权重解耦现象，并与线性探测进行对比实验。

Result: 预训练的闭词汇视觉变压器支持任务算术，表现出良好的任务添加性能，且线性探测表现接近甚至优于任务算术。

Conclusion: 任务算术不仅适用于开词汇模型，也可有效扩展至闭词汇模型，为高效部署多任务模型提供了新路径。

Abstract: Task arithmetic has recently emerged as a promising method for editing pre-trained \textit{open-vocabulary} models, offering a cost-effective alternative to standard multi-task fine-tuning. However, despite the abundance of \textit{closed-vocabulary} models that are not pre-trained with language supervision, applying task arithmetic to these models remains unexplored. In this paper, we deploy and study task addition in closed-vocabulary image classification models. We consider different pre-training schemes and find that \textit{weight disentanglement} -- the property enabling task arithmetic -- is a general consequence of pre-training, as it appears in different pre-trained closed-vocabulary models. In fact, we find that pre-trained closed-vocabulary vision transformers can also be edited with task arithmetic, achieving high task addition performance and enabling the efficient deployment of multi-task models. Finally, we demonstrate that simple linear probing is a competitive baseline to task addition. Overall, our findings expand the applicability of task arithmetic to a broader class of pre-trained models and open the way for more efficient use of pre-trained models in diverse settings.

</details>


### [181] [ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents](https://arxiv.org/abs/2511.14584)
*Ankush Kadu,Ashwanth Krishnan*

Main category: cs.LG

TL;DR: ReflexGrad 是一种新型架构，通过紧密耦合大语言模型（LLM）的分层待办事项分解、基于历史的因果反思以及基于梯度的优化，实现零样本泛化。该方法在无需任务特定示例或微调的情况下，仅依赖 LLM 的语义推理，在 ALFWorld 基准上达到 67% 的零样本成功率，显著优于传统方法，并展现出稳定的收敛性和跨任务迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习与决策系统难以在不进行任务特定训练的情况下从经验中学习并泛化到多样化任务。现有方法如情景记忆、基于梯度的提示优化和层次任务分解虽各有优势，但缺乏协同整合，限制了性能提升。因此，亟需一种能够融合多种学习机制、实现真正零样本泛化的框架。

Method: ReflexGrad 集成三种互补机制：(1) 基于 LLM 的分层待办事项分解用于战略规划；(2) 历史感知的因果反思，分析近期动作模式以识别失败根源，支持试验内学习；(3) 基于梯度的优化，实现系统性改进。整个系统完全依赖 LLM 的语义推理，不依赖少样本示例、微调或硬编码相似性度量。

Result: 在 ALFWorld 基准测试中，ReflexGrad 在无任何先前任务经验或演示的情况下，实现了 67% 的零样本成功率达到第一次尝试即有效表现。实证分析揭示了其稳定收敛（避免零动作循环）和高效跨任务迁移（性能提升 67% 到 78%）的机制。

Conclusion: 通过协同整合多种学习机制，ReflexGrad 实现了鲁棒的零样本泛化能力，其性能接近甚至媲美以往依赖少样本基线的方法，验证了多机制融合在复杂决策任务中的巨大潜力。

Abstract: Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.

</details>


### [182] [Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare](https://arxiv.org/abs/2511.14619)
*Marco Locatelli,Arjen Hommersom,Roberto Clemens Cerioli,Daniela Besozzi,Fabio Stella*

Main category: cs.LG

TL;DR: Fuzzy MAP EM算法通过将专家知识融入期望最大化（EM）框架，利用专家定义的模糊模型生成模糊伪计数，将参数估计问题转化为最大后验（MAP）估计，从而在数据有限的环境下提升学习效果。该方法在合成医疗模拟中优于标准EM算法，并在重症肌无力案例中恢复出临床合理的POMDP模型，展现出在医疗领域数据高效建模的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 在数据有限的环境中，传统POMDP参数估计方法性能下降，亟需一种能够融合专家知识以增强学习效果的方法，以应对低数据和高噪声条件下的挑战。

Method: 提出Fuzzy MAP EM算法，将模糊伪计数引入EM框架，构建基于专家知识的先验信息，实现对参数的MAP估计，从而在数据稀疏情况下引导更有效的学习过程。

Result: 在合成医疗模拟中，该方法在低数据和高噪声条件下均显著优于标准EM算法；在重症肌无力的实际案例中成功恢复出具有临床意义的POMDP模型，验证了其在医疗建模中的实用性与有效性。

Conclusion: Fuzzy MAP EM算法通过融合专家知识有效提升了POMDP在数据稀缺环境下的学习性能，具备在医疗等高价值但数据受限领域的实际应用前景。

Abstract: Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.

</details>


### [183] [Failure to Mix: Large language models struggle to answer according to desired probability distributions](https://arxiv.org/abs/2511.14630)
*Ivy Yuqian Yang,David Yu Zhang*

Main category: cs.LG

TL;DR: 本文研究了大语言模型（LLMs）在生成符合特定概率分布输出时的表现，发现现有LLMs在遵循简单概率分布方面存在严重缺陷。例如，当要求模型以49%的概率输出'1'时，模型几乎总是输出'0'，表现出类似阶跃函数的行为，即使在模型自身已有强烈偏置的情况下也难以改变。


<details>
  <summary>Details</summary>
Motivation: 当前的AI基准测试通常有明确的正确答案，通过强化学习训练的大语言模型倾向于追求确定性输出，这抑制了其进行概率性探索的能力。然而，在科学创新等任务中，需要模型能够根据目标概率分布进行探索性生成，因此有必要评估和改进模型在概率分布遵循方面的能力。

Method: 通过系统性实验，让多种现代大语言模型生成符合简单概率分布（如二元分布）的输出，并测量其实际输出分布与目标分布之间的偏差。

Result: 所有测试的LLM均显著偏离目标概率分布，表现出强烈的偏好单一输出的倾向，即即使目标分布为49%对51%，模型仍倾向于几乎完全选择概率较高的那个输出，无法实现真正的概率探索。

Conclusion: 现有大语言模型在遵循目标概率分布方面表现极差，其行为呈现极端非连续性，严重阻碍了其在需要概率探索的任务中的应用。未来的研究需针对此问题设计新的训练方法或架构，以增强模型的概率表达能力。

Abstract: Scientific idea generation and selection requires exploration following a target probability distribution. In contrast, current AI benchmarks have objectively correct answers, and training large language models (LLMs) via reinforcement learning against these benchmarks discourages probabilistic exploration. Here, we conducted systematic experiments requesting LLMs to produce outputs following simple probabilistic distributions, and found that all modern LLMs tested grossly fail to follow the distributions. For example, requesting a binary output of "1" 49% of the time produces an answer of "0" nearly 100% of the time. This step function-like behavior of near-exclusively generating the output with marginally highest probability even overrules even strong in-built LLM biases.

</details>


### [184] [Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting](https://arxiv.org/abs/2511.14632)
*Yuchen Luo,Xinyu Li,Liuhua Peng,Mingming Gong*

Main category: cs.LG

TL;DR: Adapformer is a novel Transformer-based model for multivariate time series forecasting that combines the strengths of channel-independent and channel-dependent approaches through adaptive channel management. It features a dual-stage encoder-decoder architecture with ACE (Adaptive Channel Enhancer) and ACF (Adaptive Channel Forecaster) modules to selectively enrich embeddings and refine predictions, reducing noise and improving accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Traditional MTSF models either ignore inter-channel dependencies (CI) or include excessive extraneous information (CD), leading to suboptimal performance. There is a need for a balanced approach that leverages useful dependencies while avoiding overfitting.

Method: Adapformer employs a dual-stage encoder-decoder framework: ACE enhances token representations by adaptively incorporating relevant inter-channel dependencies; ACF refines predictions by focusing on the most pertinent covariates, thus reducing redundancy and noise.

Result: Adapformer achieves state-of-the-art performance across multiple datasets, outperforming existing models in both predictive accuracy and computational efficiency.

Conclusion: By intelligently managing channel interactions, Adapformer effectively balances the trade-off between leveraging inter-variable dependencies and avoiding overfitting, making it a highly effective solution for multivariate time series forecasting.

Abstract: In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \textbf{channel-independent} (CI) or \textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \textbf{A}daptive \textbf{C}hannel \textbf{E}nhancer (\textbf{ACE}) for enriching embedding processes and the \textbf{A}daptive \textbf{C}hannel \textbf{F}orecaster (\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [185] [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)
*Xiaoxing Lian,Aidong Yang,Jun Zhu,Peng Wang,Yue Zhang*

Main category: cs.AI

TL;DR: 该研究提出SpatiaLite基准测试，系统评估大语言模型和视觉语言模型在空间推理任务中的表现，发现当前模型主要依赖语言表征而非视觉感知，导致在涉及3D几何变换和空间关系的任务中表现不佳，且推理效率低下。为此，作者提出基于意象驱动的框架（IDF），以构建内部世界模型，提升模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前先进视觉语言模型在空间推理方面存在显著缺陷，尤其是对三维几何变换、心理旋转等任务处理能力不足，而人类空间推理依赖于内在的想象机制，因此需要一个专门的基准来揭示这些模型的真实能力与局限，并推动更有效的训练方法发展。

Method: 引入SpatiaLite——一个完全合成的基准，用于联合测量空间推理的准确性和效率；通过实验分析现有VLMs在不同复杂度空间任务中的表现，并提出基于意象驱动的数据合成与训练框架（IDF）以增强内部世界模型的构建。

Result: 实验表明：1）先进VLMs主要依赖语言表示进行空间推理，缺乏对视觉中心任务的有效处理；2）其空间推理过程效率极低，随着任务复杂度增加，令牌使用量急剧上升；3）提出的IDF框架能有效促进内部世界模型的隐式构建，显著改善空间推理能力。

Conclusion: 本研究揭示了当前先进VLMs在空间推理方面的关键瓶颈，明确了其依赖语言而非视觉感知的本质问题，提出了通过意象驱动方式构建内部世界模型的新路径，为未来提升模型的空间认知能力提供了理论依据与实践方向。

Abstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances

</details>


### [186] [Causal computations in Semi Markovian Structural Causal Models using divide and conquer](https://arxiv.org/abs/2511.13852)
*Anna Rodum Bjøru,Rafael Cabañas,Helge Langseth,Antonio Salmerón*

Main category: cs.AI

TL;DR: 本文研究了将Bjøru等人提出的分治算法从马尔可夫结构因果模型（SCM）扩展到半马尔可夫SCM的可行性，后者能表示马尔可夫模型无法捕捉的混杂关系。通过一个最小示例揭示了扩展中的挑战，并提出了若干替代解决方案，进行了理论分析与计算评估。


<details>
  <summary>Details</summary>
Motivation: 现有分治算法仅适用于马尔可夫SCM，无法处理具有多端点影响的外生变量，而半马尔可夫模型能更准确地表示现实中的混杂关系，因此有必要拓展该方法以支持更复杂模型。

Method: 基于最小反事实示例分析扩展困难，提出并比较多种替代策略，包括结构重构、子模型分解优化及边界聚合机制改进，结合理论推导和数值实验进行验证。

Result: 所提方法在理论上可有效处理半马尔可夫结构中的混杂问题，在计算实验中表现出良好的边界紧致性和效率，证明了其可行性和优越性。

Conclusion: 该研究成功将原分治算法推广至半马尔可夫SCM，为复杂混杂场景下的反事实概率推理提供了新工具，拓展了结构因果建模的应用范围。

Abstract: Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.

</details>


### [187] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 本文系统分析了集成于智能交通系统（ITS）中的大型视觉语言模型（LVLMs）在精心设计的越狱攻击下的脆弱性。研究构建了一个与交通相关的有害查询数据集，提出一种通过图像排版操纵和多轮提示利用LVLM漏洞的新越狱攻击方法，并设计了一种多层响应过滤防御技术以防止生成不当回复。实验在主流开源与闭源LVLM上进行，采用GPT-4判断及人工验证评估攻击与防御效果，结果表明基于图像排版操纵和多轮提示的越狱攻击存在严重安全风险。


<details>
  <summary>Details</summary>
Motivation: LVLMs在智能交通系统中广泛应用，但其对越狱攻击高度敏感，可能引发安全与伦理问题。现有研究缺乏针对交通场景下有害内容的系统性分析，亟需揭示其具体漏洞并提出有效防御方案。

Method: 1. 构建基于OpenAI禁止类别、面向交通场景的有害查询数据集；2. 提出结合图像排版操纵与多轮提示的新型越狱攻击方法；3. 设计多层响应过滤防御机制，通过文本与视觉特征双重检测阻止恶意输出。

Result: 所提攻击在多种主流LVLM上成功诱导出有害响应，且显著优于现有方法；多层过滤防御可有效降低毒性输出率，提升模型安全性。实验验证了图像排版操纵与多轮提示组合攻击的高效性与隐蔽性。

Conclusion: LVLMs在智能交通系统中面临严峻的越狱攻击风险，尤其在图像排版操纵与多轮提示协同作用下表现尤为脆弱。提出的攻击方法揭示了关键安全隐患，而多层响应过滤防御策略展现出良好的防护潜力，为未来安全部署提供重要参考。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


### [188] [CORGI: Efficient Pattern Matching With Quadratic Guarantees](https://arxiv.org/abs/2511.13942)
*Daniel Weitekamp*

Main category: cs.AI

TL;DR: CORGI是一种新型的模式匹配算法，旨在解决规则系统在实时应用中因复杂匹配问题导致的时间和空间瓶颈。与传统的RETE方法不同，CORGI通过前向构建关系图并反向迭代生成匹配，避免了存储完整冲突集的高内存开销，提供二次时间与空间复杂度保证，并支持流式输出后续匹配结果。实验表明，在组合匹配任务中，CORGI显著优于SOAR和OPS5中的RETE实现。


<details>
  <summary>Details</summary>
Motivation: 传统RETE-based模式匹配系统在处理具有大量未约束变量或产生组合中间部分匹配的规则时，可能面临指数级时间和空间消耗，导致系统性能下降甚至崩溃。尤其在自动规则生成场景下（如基于示例归纳或代码合成），容易生成导致最坏情况匹配的模式，使系统不可用。因此需要一种更高效、可预测且内存友好的匹配算法。

Method: 提出CORGI（Collection-Oriented Relational Graph Iteration）算法：采用两阶段策略——第一阶段前向构建并维护一个已接地的关系图；第二阶段通过反向遍历该图，按需生成匹配结果。不依赖传统的β-内存来存储部分匹配，从而避免内存溢出和延迟。

Result: 在组合匹配任务上的性能评估显示，CORGI在执行速度和内存使用上均显著优于SOAR和OPS5中的RETE实现，具备二次时间与空间复杂度保证，并支持增量式匹配输出，有效缓解高延迟与内存压力问题。

Conclusion: CORGI为复杂规则系统的实时匹配提供了高效、可扩展且稳定的解决方案，特别适用于自动生成规则的认知系统，能够避免传统RETE方法的不可预测失败风险，提升系统整体实用性与可靠性。

Abstract: Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.

</details>


### [189] [Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios](https://arxiv.org/abs/2511.13970)
*Sanjay Acharjee,Abir Khan Ratul,Diego Patino,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 本研究提出一种基于场景图的生成式AI框架，利用OSHA事故报告中的文本信息，通过GPT-4o提取结构化危险推理，并转化为物体级场景图，指导文生图扩散模型生成具有空间和上下文关系的逼真危险场景图像。为评估生成数据的真实性和语义保真度，引入视觉问答（VQA）框架，结果表明所提出的VQA Graph Score在区分不同生成模型方面优于CLIP和BLIP指标。


<details>
  <summary>Details</summary>
Motivation: 获取真实工作场所危险场景的训练数据困难，因为事故现场难以实时捕捉。现有方法无法有效生成符合实际风险特征的图像，因此需要一种能够基于历史事故数据合成高保真危险场景的新方法。

Method: 首先使用GPT-4o分析OSHA事故报告，提取结构化危害推理；将其转化为包含对象及其空间与上下文关系的场景图；再以场景图为指导，驱动文生图扩散模型生成逼真图像；最后构建VQA框架，通过基于熵的验证评估生成图像的现实性与语义准确性。

Result: 所提VQA Graph Score在对比四种主流生成模型时表现出更高的判别敏感性，优于传统基于CLIP和BLIP的评估指标，证明生成图像在语义和视觉真实性上更优。

Conclusion: 该框架成功实现了从事故报告到逼真危险场景图像的自动化合成，为训练视觉模型检测工作场所风险提供了高质量、可扩展的数据来源。

Abstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.

</details>


### [190] [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)
*Minghu Wang,Shuliang Zhao,Yuanyuan Zhao,Hongxia Xu*

Main category: cs.AI

TL;DR: ALEX 是一种轻量级的知识编辑框架，通过分层记忆架构将知识更新组织为语义簇，将检索复杂度从线性 O(N) 降低至可扩展的 O(K+N/C)，并结合推理查询生成（IQS）模块和动态证据仲裁（DEA）引擎，显著提升多跳问答的准确率与推理路径可靠性，同时减少超过 80% 的搜索空间。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在处理复杂多跳问题时面临可扩展性和检索效率的挑战，而 LLMs 的静态知识难以适应动态信息变化，亟需高效、可扩展的知识编辑方案。

Method: 提出 ALEX 框架，采用分层记忆架构对知识编辑进行语义聚类，结合推理查询生成（IQS）模块以弥合查询与事实间的语义鸿沟，并引入动态证据仲裁（DEA）引擎实现两阶段高效检索。

Result: 在 MQUAKE 基准测试中，ALEX 显著提升了多跳答案准确率（MultiHop-ACC）和推理路径可靠性（HopWise-ACC），并将所需搜索空间减少超过 80%，验证了其在可扩展性、效率与准确性方面的优势。

Conclusion: ALEX 为构建高效、可扩展且准确的知识编辑系统提供了可行路径，尤其适用于需要多步推理的复杂知识更新场景。

Abstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.

</details>


### [191] [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)
*Chiharu Hagiwara,Naoki Nonaka,Yuhta Hashimoto,Ryu Uchimido,Jun Seita*

Main category: cs.AI

TL;DR: 该研究提出了一种基于大语言模型（LLM）的合成三分类数据生成框架Syn-STARTS，用于解决大规模伤亡事件（MCIs）中真实数据稀缺的问题。该框架生成的三分类案例在质量上与人工标注的TRIAGE公开数据集无明显差异，且在绿、黄、红、黑四类标准三分类评估中表现出高度稳定性，证明了合成数据在开发高性能医疗AI模型中的可行性。


<details>
  <summary>Details</summary>
Motivation: 由于大规模伤亡事件发生频率低，难以收集足够数量和质量的真实三分类数据，限制了AI在紧急医疗决策中的发展和评估，因此亟需一种有效的合成数据生成方法以支持高质量训练与测试。

Method: 采用大语言模型（LLM）构建Syn-STARTS框架，自动生成符合标准三分类方法START的三分类医疗场景数据，并通过与人工生成数据集对比验证其质量与一致性。

Result: Syn-STARTS生成的数据在视觉和语义上与真实数据无法区分；在多类别三分类任务中，模型表现稳定，表明合成数据具备高可靠性与实用性。

Conclusion: 该研究证实了利用合成数据生成技术可有效克服真实数据稀缺问题，为开发高性能、高可靠性的急救决策AI系统提供了可行路径。

Abstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.

</details>


### [192] [Making Evidence Actionable in Adaptive Learning](https://arxiv.org/abs/2511.14052)
*Amirreza Mehrabi,Jason W. Morphew,Breejha Quezada,N. Sanjay Rebello*

Main category: cs.AI

TL;DR: 本文提出一种由教师控制的反馈循环，将概念级评估证据转化为经过验证的微干预措施。通过三个保障机制（充分性、注意力、多样性）确保干预的精准与高效，并将干预分配建模为带约束的二元整数规划问题。采用贪心法、梯度松弛法及混合方法适应不同资源丰富度和延迟需求场景，在模拟和1204名学生的物理课程部署中均实现全技能覆盖且耗时可控。梯度法减少冗余约12个百分点并均衡难度，贪心法在资源有限时计算成本更低。松弛变量支持内容缺失定位与针对性优化，保障各群体公平性。整体系统具备可解释性与可扩展性，实现课堂规模的负载感知个性化教学。


<details>
  <summary>Details</summary>
Motivation: 当前自适应学习系统虽能精准诊断学习差距，但干预策略常因时机不当或与需求错配而效果不佳。如何构建一个既能精准诊断又能有效干预的闭环系统，是提升个性化教学效能的关键挑战。本文旨在解决诊断与教学之间脱节的问题，实现及时、适切、公平的个性化干预。

Method: 将干预分配建模为带多约束的二元整数规划问题，包括覆盖范围、时间预算、难度窗口（基于能力估计）、先修知识约束（通过概念矩阵编码）以及防冗余的多样性约束。针对不同场景设计三种求解策略：贪心选择适用于资源少、延迟敏感的环境；梯度基松弛法适用于资源丰富的场景；混合方法沿资源丰富度-延迟权衡边界动态切换。引入松弛变量以识别缺失内容并支持靶向内容优化。

Result: 在模拟实验和1204名学生的真实物理课程部署中，两种求解方法均能在有限观看时间内实现几乎所有学习者的全技能覆盖。梯度基方法相比贪心法减少约12个百分点的冗余覆盖，同时更均匀地调节干预难度；贪心法在资源受限场景下具有更低的计算开销，且保持相当的覆盖率。松弛变量成功定位缺失内容，支持跨子群体的内容均衡，维持系统整体充足性与公平性。

Conclusion: 本研究构建了一个可计算、可审计的自适应教学控制器，实现了从诊断到干预的闭环管理。该系统在保证教学充分性的同时，兼顾时间效率、多样性与公平性，支持在大规模课堂环境中进行负载感知的个性化教学，为智能教育系统的实用化提供了可行路径。

Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.

</details>


### [193] [APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design](https://arxiv.org/abs/2511.14101)
*Xinpeng Chen,Xiaofeng Han,Kaihao Zhang,Guochao Ren,Yujie Wang,Wenhao Cao,Yang Zhou,Jianfeng Lu,Zhenbo Song*

Main category: cs.AI

TL;DR: 本文提出APD-agents，一个基于大语言模型的多智能体框架，用于自动化移动应用页面设计。该框架通过动态协作的多个智能体（如语义解析、布局生成、模板检索和递归组件生成）实现从用户描述到高质量页面布局的端到端生成，显著提升设计效率与一致性，在RICO数据集上达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前移动应用页面设计耗时且依赖设计师经验，尽管有设计工具辅助，仍需大量培训；跨页面协作时风格不一致问题突出，亟需自动化、智能化的设计方案。

Method: 提出多智能体系统APD-agents，包括协调器、语义解析、主布局、模板检索和递归组件生成五个智能体，协同完成从自然语言描述到精细页面布局的生成任务。

Result: 在RICO数据集上的实验表明，APD-agents在布局生成质量与一致性方面优于现有方法，达到当前最佳性能。

Conclusion: APD-agents框架有效利用大模型的多智能体协作能力，实现了高效、自动化的移动端页面设计，为降低设计门槛、提升开发效率提供了可行路径。

Abstract: Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.

</details>


### [194] [Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation](https://arxiv.org/abs/2511.14131)
*Yu Zhong,Zihao Zhang,Rui Zhang,Lingdong Huang,Haihan Gao,Shuo Wang,Da Li,Ruijian Han,Jiaming Guo,Shaohui Peng,Di Huang,Yunji Chen*

Main category: cs.AI

TL;DR: 提出了一种名为R3的双进程思维框架，用于视觉-语言导航（VLN），结合大型语言模型（LLM）的泛化能力与特定领域的专家知识，在零样本条件下实现高效导航。该框架包含三个模块：轻量级的跑步者（Runner）、基于多模态LLM的沉思者（Ruminator）和监控导航进度的调节器（Regulator）。实验表明，R3在REVERIE基准测试中显著优于现有方法，SPL和RGSPL分别提升3.28%和3.30%。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的VLN方法虽然具备常识和推理能力，但在空间理解上存在不足，且计算成本高、延迟大。因此需要一种既能利用LLM优势又兼顾效率与精度的解决方案。

Method: 设计了R3双进程思维框架，包括：1）轻量级的Runner模型负责常规情况下的高效导航；2）基于多模态LLM的Ruminator采用链式思考（CoT）提示进行结构化推理；3）Regulator根据导航进展动态切换模式，协调两者协同工作。

Result: R3在REVERIE基准测试中实现了3.28%的SPL提升和3.30%的RGSPL提升，显著优于当前最先进的方法，证明其在处理复杂VLN任务中的有效性。

Conclusion: R3框架通过融合通用推理与领域专长，在保持低延迟的同时提升了导航性能，为未来高效智能导航系统提供了新思路。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.

</details>


### [195] [Do Large Language Models (LLMs) Understand Chronology?](https://arxiv.org/abs/2511.14214)
*Pattaraphon Kenny Wongchamcharoen,Paul Glasserman*

Main category: cs.AI

TL;DR: 本研究评估大语言模型（LLMs）在金融与经济领域中处理时间顺序任务的能力，包括时间排序、条件排序和错位检测。结果显示，尽管模型在局部顺序上表现良好，但随着序列长度增加，全局时间一致性显著下降。条件排序的失败主要源于过滤步骤而非排序本身。GPT-5 和 Claude-3.7 Sonnet 带有扩展思维（ET）时表现优异，尤其在中高推理预算下实现完美排序。错位检测相对简单，但重叠时间线或实体仍导致性能下降。研究强调推理资源分配对时间任务的重要性，并为实时金融应用提供关键洞见。代码与评估模板已公开以支持可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在金融与经济中的应用日益广泛，但其对时间顺序的理解能力尚不明确。尤其在提示工程中隐含假设模型具备时间感知能力，因此亟需系统检验模型是否真正理解时间逻辑，以避免回溯偏差。

Method: 设计三类递增复杂度的时间相关任务：（1）时间排序，（2）条件排序（先筛选后排序），（3）错位检测。在多个推理努力水平下，评估 GPT-4.1、Claude-3.7 Sonnet（含/不含扩展思维）、GPT-5 的表现。通过精确匹配率与排名相关性分析模型行为。

Result: 随着序列长度增加，精确匹配率急剧下降，但排名相关性保持较高，表明模型保留局部顺序但难以维持全局时间一致性。条件排序失败多因过滤错误。带扩展思维的 GPT-5 和 Claude-3.7 Sonnet 在中高推理预算下实现完美排序与条件排序。错位检测最易，但仍受重叠时间线影响。

Conclusion: 当前大语言模型在时间任务上存在明显局限，尤其在长序列和复杂条件场景下。合理分配推理预算能显著提升性能，尤其在金融等实时应用场景中至关重要。研究揭示了任务复杂性与推理需求之间的关系，为模型优化与应用提供了实证依据。

Abstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.

</details>


### [196] [Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219)
*Kumud Tripathi,Aditya Srinivas Menon,Aman Gaurav,Raj Prakash Gohil,Pankaj Wasnik*

Main category: cs.AI

TL;DR: 本文提出一种两阶段架构以提升Whisper模型在嘈杂环境下的鲁棒性，减少幻觉错误。第一阶段通过自适应层注意力（ALA）增强编码器，通过层间相关性分析将编码层分组，并利用可学习的多头注意力融合高层与低层特征；第二阶段采用多目标知识蒸馏（KD）框架，使学生模型在噪声音频上训练时，其语义和注意力分布与教师模型在干净输入下的表现对齐。实验表明，该方法显著降低幻觉和词错误率，同时保持在干净语音上的性能。


<details>
  <summary>Details</summary>
Motivation: Whisper模型虽在多语言和零样本场景下表现优异，但在噪声环境下常出现幻觉错误。现有方法多依赖音频预处理或转录后处理，未充分探索对Whisper模型本身的改进。因此，亟需从模型内部结构出发，直接缓解幻觉问题。

Method: 提出两阶段架构：1）使用自适应层注意力（ALA）对编码器层进行分组并融合多层级特征，提升编码鲁棒性；2）设计多目标知识蒸馏框架，使学生模型在噪声输入下学习教师模型在干净输入下的语义与注意力分布，从而抑制幻觉。

Result: 在多个噪声语音基准测试中，该方法显著降低了幻觉发生率和词错误率，同时保持了在干净语音上的高性能，验证了方法的有效性和实用性。

Conclusion: ALA与KD的结合为提升Whisper模型在真实噪声环境中的可靠性提供了一种系统性、可扩展的解决方案，具有良好的应用前景。

Abstract: The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.

</details>


### [197] [DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](https://arxiv.org/abs/2511.14227)
*Yuxiang Wang,Siwen Wang,Haowei Han,Ao Wang,Boya Liu,Yong Zhao,Chengbo Wu,Bin Zhu,Bin Qin,Xiaokai Zhou,Xiao Yan,Jiawei Jiang,Bo Du*

Main category: cs.AI

TL;DR: 提出基于大模型的物联网设备操作推荐系统DevPiolt，通过持续预训练、多任务微调和直接偏好优化，结合置信度控制机制，显著提升推荐效果与用户体验。在真实场景中部署后，用户覆盖和页面接受率分别提升21.6%和29.1%。


<details>
  <summary>Details</summary>
Motivation: 现有推荐模型难以应对物联网设备操作中的复杂逻辑、用户偏好多样性和对劣质建议的敏感性问题，亟需更精准、个性化的推荐方法。

Method: 通过持续预训练和多任务微调赋予大模型物联网领域知识；采用直接偏好优化对齐用户偏好；设计基于置信度的暴露控制机制以避免低质量推荐影响用户体验。

Result: 在多个数据集上，DevPiolt平均性能优于基线模型69.5%；在小米家庭应用中实际部署后，用户设备覆盖率提升21.6%，页面浏览接受率提升29.1%。

Conclusion: DevPiolt有效解决了物联网设备操作推荐中的关键挑战，具备良好的实用性和可扩展性，为智能家庭场景下的个性化服务提供了可靠方案。

Abstract: Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.

</details>


### [198] [Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility](https://arxiv.org/abs/2511.14248)
*Hongju Lee,Youngjun Park,Jisun An,Dongman Lee*

Main category: cs.AI

TL;DR: 本文提出一种新颖的时序预测框架，用于预测首尔地区Airbnb的收入、预订天数和预订数量等关键指标，通过滑动窗口方法实现1至3个月的前瞻性预测。该方法将结构化表格数据转换为基于提示的输入，输入大型语言模型（LLM）生成区域嵌入，再结合RNN、LSTM和Transformer等先进时序模型捕捉复杂的时空动态。实验表明，相比传统统计与机器学习基线模型，该方法在平均RMSE和MAE上均降低约48%，显著提升预测精度，并为识别房源过剩区域和制定数据驱动的城市政策提供支持。


<details>
  <summary>Details</summary>
Motivation: 短租平台如Airbnb的扩张对本地住房市场造成显著冲击，导致租金上涨和住房可负担性问题。准确预测区域级Airbnb市场趋势对于政策制定者和城市规划者具有重要意义，但现有研究多聚焦于单一房源在固定时间点的表现，缺乏对区域层面综合特征与外部环境因素的整合分析。因此亟需一种能够融合多源信息、捕捉复杂时空模式的新方法。

Method: 采用滑动窗口策略进行未来1-3个月的预测；将房源特征与城市可达性、人类移动性等外部上下文因素相结合，构建区域表征；利用大语言模型（LLM）将结构化数据转化为提示式输入，生成高质量的区域嵌入；将这些嵌入输入至RNN、LSTM和Transformer等先进时序模型中，以建模复杂的时空依赖关系。

Result: 在首尔Airbnb数据集上的实验结果显示，所提方法在预测准确性上优于传统基线模型，平均RMSE和MAE分别降低约48%；不仅提升了预测性能，还具备识别区域房源供应过剩的能力，为城市政策制定提供实用洞察。

Conclusion: 本研究提出的融合大语言模型与先进时序模型的区域级预测框架，在准确性与实用性方面均表现优异，能够有效支持城市管理者应对短期租赁市场带来的挑战，推动更科学、及时的公共政策决策。

Abstract: The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.

</details>


### [199] [PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2511.14256)
*Yu Liu,Xixun Lin,Yanmin Shang,Yangxi Li,Shi Wang,Yanan Cao*

Main category: cs.AI

TL;DR: PathMind 是一种新型知识图谱推理框架，通过‘检索-优先级排序-推理’范式，解决现有基于大语言模型（LLM）的KGR方法中路径选择不当和高调用成本的问题。它利用语义感知的路径优先级函数识别关键路径，结合双阶段训练策略提升推理准确性和可解释性，在复杂任务上以更少输入标记实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的知识图谱推理方法存在两个主要问题：一是盲目提取推理路径，引入无关噪声；二是动态探索路径需要频繁调用LLM，导致高检索开销和计算成本。

Method: PathMind采用‘检索-优先级排序-推理’三阶段框架：1）通过检索模块获取查询子图；2）设计语义感知的路径优先级函数，综合考虑累积代价与未来预期代价，筛选重要路径；3）采用任务特定指令微调与路径级偏好对齐的双阶段训练策略，生成逻辑一致且准确的回答。

Result: 在多个基准数据集上的实验表明，PathMind显著优于现有基线方法，尤其在复杂推理任务中表现突出，且使用更少的输入标记即可获得高性能，证明其在提高推理忠实度和可解释性方面的有效性。

Conclusion: PathMind通过智能路径选择与高效训练机制，有效缓解了现有LLM-KGR方法中的噪声干扰与高计算开销问题，为构建可信、高效的知识图谱推理系统提供了新思路。

Abstract: Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a "Retrieve-Prioritize-Reason" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.

</details>


### [200] [DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning](https://arxiv.org/abs/2511.14299)
*Xiaochuan Liu,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.AI

TL;DR: DataSage is a multi-agent framework that enhances automated data insight discovery by integrating external knowledge retrieval, multi-role debating for deeper analysis, and multi-path reasoning to improve code accuracy. It outperforms existing agents on InsightBench across all difficulty levels.


<details>
  <summary>Details</summary>
Motivation: Existing data insight agents lack sufficient domain knowledge, have shallow analytical depth, and generate error-prone code, limiting their effectiveness in real-world applications.

Method: DataSage employs a multi-agent architecture with three key components: external knowledge retrieval to enrich context, a multi-role debating mechanism to simulate diverse perspectives, and multi-path reasoning to enhance code and insight accuracy.

Result: Experiments on InsightBench show DataSage consistently surpasses current data insight agents in performance across all difficulty levels, demonstrating its effectiveness in automated insight discovery.

Conclusion: DataSage provides a robust and scalable solution for end-to-end automated data insight discovery, addressing critical limitations of existing approaches through advanced multi-agent mechanisms.

Abstract: In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.

</details>


### [201] [When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling](https://arxiv.org/abs/2511.14334)
*Alessio Pellegrino,Jacopo Mauro*

Main category: cs.AI

TL;DR: 本文研究大语言模型（LLM）在自动生成约束编程（CP）模型时的真实推理能力，发现其表现可能受训练数据污染影响。通过改写和扰动CSPLib中的经典问题，研究发现当问题上下文或表述发生变化时，LLM生成的模型质量显著下降，表明其理解浅显且对语言表达敏感。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在自动生成约束编程模型时是否具备真正的推理能力，而非依赖于训练数据中的已知问题。

Method: 系统性地重述和扰动一组经典的CSPLib问题，保持其结构不变但改变上下文和引入误导性元素，随后对比三个代表性LLM在原始和修改后描述下的模型生成结果。

Result: LLM虽能生成语法正确、语义合理的模型，但在面对上下文和语言变化时性能急剧下降，表现出浅层理解与对措辞的高度敏感性。

Conclusion: 当前大语言模型在约束编程模型生成方面的能力很大程度上依赖于训练数据中的数据污染，缺乏真正的泛化与推理能力，需谨慎评估其在实际应用中的可靠性。

Abstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.

</details>


### [202] [Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476)
*Dalia Ali,Dora Zhao,Allison Koenecke,Orestis Papakyriakopoulos*

Main category: cs.AI

TL;DR: 本研究探讨了在大型语言模型（LLM）对齐过程中引入多元价值观的影响，通过系统评估社会群体差异和对齐流程中的设计参数。研究收集了来自美国和德国参与者（N=1,095，27,375个评分）对模型输出在毒性、情绪意识、敏感性、刻板偏见和帮助性五个维度的评价，并基于不同社会群体的偏好微调多个LLM和大推理模型，同时调整评分量表、分歧处理方法和优化技术。结果显示存在显著的人口统计学差异：男性参与者比女性参与者将响应评为低18%的毒性；保守派和非裔参与者分别比自由派和白人参与者高出27.9%和44%的情绪意识评分。基于特定群体偏好的微调模型表现出明显不同的行为特征。技术设计选择影响显著：保留评分者分歧相比多数投票可实现约53%更高的毒性降低，五点量表比二元格式带来约22%更优的减少效果；直接偏好优化（DPO）在多价值优化中始终优于组相对策略优化（GRPO）。研究为关键问题提供了初步答案：如何在确保安全性和公平代表性之间平衡专家驱动与用户驱动信号？


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的对齐过程虽依赖人类反馈以保障安全与价值观一致，但常忽视人类社会多样性。本研究旨在探索多元价值观如何影响模型行为，揭示不同社会群体在价值判断上的差异，并评估对齐流程中设计参数的影响，从而推动更具包容性的模型对齐机制。

Method: 研究通过跨文化实验收集美国和德国参与者的数据（共1,095人，27,375次评分），评估模型输出在五个维度（毒性、情绪意识、敏感性、刻板偏见、帮助性）的表现。采用多种微调策略，基于不同社会群体的偏好训练模型，同时对比不同评分量表（二元/五点）、分歧处理方式（多数投票/保留分歧）及优化算法（DPO vs GRPO），系统分析其对模型行为的影响。

Result: 发现显著的性别与政治/种族群体差异：男性认为内容毒性更低（-18%），保守派和非裔参与者对情绪意识评价更高（+27.9% 和 +44%）。模型根据群体偏好微调后表现出差异化行为。技术上，保留评分者分歧使毒性降低提升约53%，五点量表优于二元格式（+22%），且DPO在多值优化中表现持续优于GRPO。

Conclusion: 该研究揭示了社会多样性在模型对齐中的核心作用，表明仅依赖单一群体或简化反馈机制可能导致偏差。未来对齐应综合考虑多元价值观，合理设计反馈流程，结合技术手段如保留分歧与高效优化算法，以实现更安全、公平且具代表性的模型行为。

Abstract: Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?

</details>


### [203] [Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2511.14595)
*Yuan An,Ruhma Hashmi,Michelle Rogers,Jane Greenberg,Brian K. Smith*

Main category: cs.AI

TL;DR: 本文提出了一种基于率失真（RD）理论和最优传输几何的知識圖譜構建與優化框架，用於將非結構化的教育材料（如講義、幻燈片）轉換為高質量的知識圖譜。通過將講義內容建模為度量-測度空間，並利用融合格羅莫夫-沃瑟斯坦（FGW）耦合量化語義失真，結合圖譜大小作為速率項，以最小化率失真拉格朗日函數，實現知識圖譜的精煉（增、併、分、刪、重連）。實驗結果顯示，經優化後的知識圖譜生成的多選題在15項質量指標上均優於原始講義，展示了該方法在個性化與AI輔助教育中的有效性。


<details>
  <summary>Details</summary>
Motivation: 現有技術難以將非結構化的教育材料自動轉化為能捕捉關鍵教學內容的任務導向知識圖譜，限制了AI學習助手系統生成高質量多選題的能力。因此需要一種更具理論基礎的方法來優化知識圖譜的構建與精煉過程。

Method: 將講義內容建模為度量-測度空間，使用融合格羅莫夫-沃瑟斯坦（FGW）耦合對候選知識圖譜進行對齊以量化語義失真；定義圖譜大小為速率項，結合失真與速率構建率失真拉格朗日函數，並通過添加、合併、分割、刪除、重連等精煉操作最小化該函數，從而獲得緊湊且信息保留良好的知識圖譜。

Result: 應用於數據科學講義的原型系統產生了可解釋的率失真曲線，經優化後的知識圖譜所生成的多選題在15項評價標準上均顯著優於原始講義生成的題目，驗證了方法的有效性與穩定性。

Conclusion: 本研究建立了一個基於資訊理論的知識圖譜優化原則框架，為個人化及AI輔助教育中的知識圖譜構建提供了理論支持與實踐路徑。

Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.

</details>


### [204] [AutoTool: Efficient Tool Selection for Large Language Model Agents](https://arxiv.org/abs/2511.14650)
*Jingyi Jia,Qinbin Li*

Main category: cs.AI

TL;DR: AutoTool proposes a graph-based framework to reduce inference costs in LLM agents by leveraging tool usage inertia—predictable sequential patterns in tool selection. It builds a directed graph from historical trajectories to model transitions between tools and integrates parameter-level information for better input generation. This allows efficient tool selection with minimal LLM inference, achieving up to 30% cost reduction while maintaining high task completion rates.


<details>
  <summary>Details</summary>
Motivation: Current LLM agent frameworks, especially those using ReAct, suffer from high inference costs due to repeated LLM calls for tool selection. The need for more efficient and scalable solutions motivates the development of AutoTool.

Method: AutoTool constructs a directed graph from historical agent trajectories, where nodes are tools and edges represent transition probabilities based on tool usage inertia. It uses this graph to guide tool selection and incorporates parameter-level data to improve input generation, reducing reliance on real-time LLM inference.

Result: AutoTool reduces inference costs by up to 30% across diverse tasks while maintaining competitive task completion rates, demonstrating significant efficiency gains without sacrificing performance.

Conclusion: Integrating statistical structure like tool usage patterns into LLM agent design offers a promising path toward efficient, scalable, and high-performing agent systems.

Abstract: Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.

</details>
