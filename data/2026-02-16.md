<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 56]
- [cs.CL](#cs.CL) [Total: 33]
- [cs.LG](#cs.LG) [Total: 65]
- [cs.AI](#cs.AI) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Thermal Imaging for Contactless Cardiorespiratory and Sudomotor Response Monitoring](https://arxiv.org/abs/2602.12361)
*Constantino Álvarez Casado,Mohammad Rahman,Sasan Sharifipour,Nhi Nguyen,Manuel Lage Cañellas,Xiaoting Wu,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 本研究通过热红外视频提取面部温度变化，实现无接触的电导活动（EDA）、心率（HR）和呼吸率（BR）估计。采用区域跟踪、空间聚合及信号分离方法，结合正交矩阵图像变换（OMIT）与频谱分析，评估了多种配置在公开数据集上的性能。最佳EDA配置达到0.40±0.23的平均相关性（最高达0.89），BR误差为3.1±1.1 bpm，HR误差为13.8±7.5 bpm，受限于低帧率（7.5 Hz）。研究揭示了信号极性变化、热动力延迟及个体差异对结果的影响，为未来热成像生物信号监测提供基准与设计指导。


<details>
  <summary>Details</summary>
Motivation: 现有可见光方法可估计心率和呼吸率，但无法获取电导活动（EDA），而EDA是自主神经兴奋的重要指标。热红外成像能反映皮肤温度变化，与自主调节相关，具备无接触估计多生理信号的潜力。因此，亟需开发基于热红外视频的多参数生物信号提取方法。

Method: 构建信号处理流程：首先追踪面部解剖区域，进行空间聚合；然后分离慢速汗腺趋势与快速心血管-呼吸成分。针对心率使用正交矩阵图像变换（OMIT）在多个感兴趣区域（ROIs）中分解信号；针对呼吸率则平均鼻部与颊部信号后进行频谱峰值检测。

Result: 在31个会话的SIMULATOR STUDY 1数据集上评估，最佳固定EDA配置（鼻区，指数移动平均）与掌部EDA的相关性达0.40±0.23，个别会话最高达0.89；呼吸率估计均绝对误差为3.1±1.1 bpm；心率估计均绝对误差为13.8±7.5 bpm，主要受相机帧率低（7.5 Hz）限制。观察到信号极性随会话交替、热响应延迟较短，并发现条件与人口统计因素影响提取质量。

Conclusion: 本研究建立了热红外成像无接触估计EDA、HR和BR的基准性能，揭示了关键影响因素，为后续系统设计提供了实用指导。尽管当前精度受限于硬件条件，但已证明其可行性与潜力。

Abstract: Thermal infrared imaging captures skin temperature changes driven by autonomic regulation and can potentially provide contactless estimation of electrodermal activity (EDA), heart rate (HR), and breathing rate (BR). While visible-light methods address HR and BR, they cannot access EDA, a standard marker of sympathetic activation. This paper characterizes the extraction of these three biosignals from facial thermal video using a signal-processing pipeline that tracks anatomical regions, applies spatial aggregation, and separates slow sudomotor trends from faster cardiorespiratory components. For HR, we apply an orthogonal matrix image transformation (OMIT) decomposition across multiple facial regions of interest (ROIs), and for BR we average nasal and cheek signals before spectral peak detection. We evaluate 288 EDA configurations and the HR/BR pipeline on 31 sessions from the public SIMULATOR STUDY 1 (SIM1) driver monitoring dataset. The best fixed EDA configuration (nose region, exponential moving average) reaches a mean absolute correlation of $0.40 \pm 0.23$ against palm EDA, with individual sessions reaching 0.89. BR estimation achieves a mean absolute error of $3.1 \pm 1.1$ bpm, while HR estimation yields $13.8 \pm 7.5$ bpm MAE, limited by the low camera frame rate (7.5 Hz). We report signal polarity alternation across sessions, short thermodynamic latency for well-tracked signals, and condition-dependent and demographic effects on extraction quality. These results provide baseline performance bounds and design guidance for thermal contactless biosignal estimation.

</details>


### [2] [LLaMo: Scaling Pretrained Language Models for Unified Motion Understanding and Generation with Continuous Autoregressive Tokens](https://arxiv.org/abs/2602.12370)
*Zekun Li,Sizhe An,Chengcheng Tang,Chuan Guo,Ivan Shugurov,Linguang Zhang,Amy Zhao,Srinath Sridhar,Lingling Tao,Abhay Mittal*

Main category: cs.CV

TL;DR: 提出LLaMo框架，通过模态特定的Mixture-of-Transformers架构扩展预训练语言模型，实现运动与语言的统一生成与理解。采用连续潜空间编码人体运动，避免离散量化带来的抖动，保持语言模型的原有理解能力，并支持实时流式生成（>30 FPS）。实验表明，该方法在文本到运动生成和运动到文本描述任务中表现优异，尤其在零样本生成场景下具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有方法在运动-语言联合建模方面进展有限，通常通过微调大语言模型（LLM）来处理配对的运动-文本数据，但受限于数据规模易导致语言能力灾难性遗忘；同时，传统方法依赖离散化运动表示，引入明显抖动。因此亟需一种既能保留语言理解能力、又能高效融合连续运动信息的新范式。

Method: 提出基于模态特定混合变换器（MoT）架构的LLaMo框架，将人体运动编码为因果连续潜变量空间，通过轻量级流匹配头维持解码器仅结构的下一个词预测机制，实现低延迟实时运动生成。利用大规模运动-文本预训练数据，结合预训练语言模型的强大语义理解能力，实现跨模态统一建模。

Result: LLaMo在文本到运动生成和运动到文本描述任务中均表现出高保真度，尤其在零样本生成场景下性能显著优于现有方法。支持实时流式生成（>30 FPS），且有效避免了因离散量化带来的运动抖动问题。

Conclusion: LLaMo是迈向通用统一运动-语言大模型的重要一步，其设计成功兼顾语言理解能力的保留与运动模态的可扩展适应，为多模态生成与理解提供了新范式。

Abstract: Recent progress in large models has led to significant advances in unified multimodal generation and understanding. However, the development of models that unify motion-language generation and understanding remains largely underexplored. Existing approaches often fine-tune large language models (LLMs) on paired motion-text data, which can result in catastrophic forgetting of linguistic capabilities due to the limited scale of available text-motion pairs. Furthermore, prior methods typically convert motion into discrete representations via quantization to integrate with language models, introducing substantial jitter artifacts from discrete tokenization. To address these challenges, we propose LLaMo, a unified framework that extends pretrained LLMs through a modality-specific Mixture-of-Transformers (MoT) architecture. This design inherently preserves the language understanding of the base model while enabling scalable multimodal adaptation. We encode human motion into a causal continuous latent space and maintain the next-token prediction paradigm in the decoder-only backbone through a lightweight flow-matching head, allowing for streaming motion generation in real-time (>30 FPS). Leveraging the comprehensive language understanding of pretrained LLMs and large-scale motion-text pretraining, our experiments demonstrate that LLaMo achieves high-fidelity text-to-motion generation and motion-to-text captioning in general settings, especially zero-shot motion generation, marking a significant step towards a general unified motion-language large model.

</details>


### [3] [Synthetic Image Detection with CLIP: Understanding and Assessing Predictive Cues](https://arxiv.org/abs/2602.12381)
*Marco Willi,Melanie Mathys,Michael Graber*

Main category: cs.CV

TL;DR: 该研究提出SynthCLIC数据集，用于分析CLIP-based合成图像检测器的泛化能力。发现其主要依赖高级摄影属性（如极简风格、镜头光晕）而非生成器特定伪影，导致在新型生成模型上泛化能力下降。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型产生接近真实的照片，合成图像检测（SID）变得至关重要。但现有方法难以泛化到新生成模型，且实际表现不佳。虽然CLIP在SID中表现出色，但其内部学习的线索尚不明确，可能依赖视觉伪影或语义偏差，限制了实用性。

Method: 构建高保真合成图像对数据集SynthCLIC，使用可解释线性头与去相关激活机制，结合文本引导概念模型，分析CLIP特征中的判别线索。

Result: CLIP线性检测器在GAN基准上达到0.96 mAP，但在SynthCLIC扩散模型数据集上降至0.92，跨生成架构泛化能力最低仅0.37 mAP。检测器主要依赖高级摄影属性而非明显生成伪影。

Conclusion: CLIP-based方法虽具强性能，但泛化不均，需持续更新与更广泛训练。建议将其作为构建通用、鲁棒合成图像检测的基础。

Abstract: Recent generative models produce near-photorealistic images, challenging the trustworthiness of photographs. Synthetic image detection (SID) has thus become an important area of research. Prior work has highlighted how synthetic images differ from real photographs--unfortunately, SID methods often struggle to generalize to novel generative models and often perform poorly in practical settings. CLIP, a foundational vision-language model which yields semantically rich image-text embeddings, shows strong accuracy and generalization for SID. Yet, the underlying relevant cues embedded in CLIP-features remain unknown. It is unclear, whether CLIP-based detectors simply detect strong visual artifacts or exploit subtle semantic biases, both of which would render them useless in practical settings or on generative models of high quality. We introduce SynthCLIC, a paired dataset of real photographs and high-quality synthetic counterparts from recent diffusion models, designed to reduce semantic bias in SID. Using an interpretable linear head with de-correlated activations and a text-grounded concept-model, we analyze what CLIP-based detectors learn. CLIP-based linear detectors reach 0.96 mAP on a GAN-based benchmark but only 0.92 on our high-quality diffusion dataset SynthCLIC, and generalization across generator families drops to as low as 0.37 mAP. We find that the detectors primarily rely on high-level photographic attributes (e.g., minimalist style, lens flare, or depth layering), rather than overt generator-specific artifacts. CLIP-based detectors perform well overall but generalize unevenly across diverse generative architectures. This highlights the need for continual model updates and broader training exposure, while reinforcing CLIP-based approaches as a strong foundation for more universal, robust SID.

</details>


### [4] [Reproducing DragDiffusion: Interactive Point-Based Editing with Diffusion Models](https://arxiv.org/abs/2602.12393)
*Ali Subhan,Ashir Raza*

Main category: cs.CV

TL;DR: 该研究对DragDiffusion方法进行了可复现性分析，验证了其在点驱动图像编辑中的有效性。实验表明，尽管核心结论可复现，但性能高度依赖于特定超参数（如优化时间步和特征层级），且多时间步优化并未提升精度反而增加计算开销。


<details>
  <summary>Details</summary>
Motivation: 验证DragDiffusion方法在点驱动图像编辑中的可复现性，明确其性能敏感的超参数条件，以推动该领域方法的可靠评估与改进。

Method: 基于作者发布的代码与DragBench基准，复现了原论文中的消融实验，包括扩散时间步选择、LoRA微调、掩码正则化强度及UNet特征监督，并测试了多时间步优化变体。

Result: 主要消融实验的定性和定量趋势与原论文一致；性能对优化时间步和特征监督层级敏感，其他组件具有更宽泛的操作范围；多时间步优化未提升空间精度，显著增加计算成本。

Conclusion: DragDiffusion的核心结论得到支持，但其性能可靠性依赖于特定超参数设置，研究结果为后续方法设计与评估提供了清晰的边界条件。

Abstract: DragDiffusion is a diffusion-based method for interactive point-based image editing that enables users to manipulate images by directly dragging selected points. The method claims that accurate spatial control can be achieved by optimizing a single diffusion latent at an intermediate timestep, together with identity-preserving fine-tuning and spatial regularization. This work presents a reproducibility study of DragDiffusion using the authors' released implementation and the DragBench benchmark. We reproduce the main ablation studies on diffusion timestep selection, LoRA-based fine-tuning, mask regularization strength, and UNet feature supervision, and observe close agreement with the qualitative and quantitative trends reported in the original work. At the same time, our experiments show that performance is sensitive to a small number of hyperparameter assumptions, particularly the optimized timestep and the feature level used for motion supervision, while other components admit broader operating ranges. We further evaluate a multi-timestep latent optimization variant and find that it does not improve spatial accuracy while substantially increasing computational cost. Overall, our findings support the central claims of DragDiffusion while clarifying the conditions under which they are reliably reproducible. Code is available at https://github.com/AliSubhan5341/DragDiffusion-TMLR-Reproducibility-Challenge.

</details>


### [5] [ZeroDiff++: Substantial Unseen Visual-semantic Correlation in Zero-shot Learning](https://arxiv.org/abs/2602.12401)
*Zihan Ye,Shreyank N Gowda,Kaile Du,Weijian Luo,Ling Shao*

Main category: cs.CV

TL;DR: ZeroDiff++提出一种基于扩散模型的零样本学习框架，通过扩散增强、监督对比表示和多视角判别器提升视觉-语义关联性，并引入测试时自适应（DiffTTA）与生成（DiffGen）机制，有效缓解数据稀缺问题，在多个基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成式零样本学习方法因罕见的已见类别样本导致视觉-语义关联存在虚假相关性，且全噪声生成器生成特征与真实测试样本脱节，成为关键瓶颈。

Method: ZeroDiff++在训练中采用扩散增强生成多样化噪声样本，使用监督对比学习获取实例级语义表示，结合Wasserstein互学习的多视角判别器评估生成特征；在生成阶段引入基于扩散的测试时自适应（DiffTTA）与测试时生成（DiffGen），通过伪标签重建与去噪路径追踪实现真实与生成数据的连接。

Result: 在三个零样本学习基准上，ZeroDiff++显著优于现有方法，尤其在训练数据稀缺情况下仍保持鲁棒性能。

Conclusion: ZeroDiff++通过强化视觉-语义关联并实现测试时动态调整，有效解决了生成式ZSL中的虚假相关性和数据稀缺问题，为零样本学习提供了新范式。

Abstract: Zero-shot Learning (ZSL) enables classifiers to recognize classes unseen during training, commonly via generative two stage methods: (1) learn visual semantic correlations from seen classes; (2) synthesize unseen class features from semantics to train classifiers. In this paper, we identify spurious visual semantic correlations in existing generative ZSL worsened by scarce seen class samples and introduce two metrics to quantify spuriousness for seen and unseen classes. Furthermore, we point out a more critical bottleneck: existing unadaptive fully noised generators produce features disconnected from real test samples, which also leads to the spurious correlation. To enhance the visual-semantic correlations on both seen and unseen classes, we propose ZeroDiff++, a diffusion-based generative framework. In training, ZeroDiff++ uses (i) diffusion augmentation to produce diverse noised samples, (ii) supervised contrastive (SC) representations for instance level semantics, and (iii) multi view discriminators with Wasserstein mutual learning to assess generated features. At generation time, we introduce (iv) Diffusion-based Test time Adaptation (DiffTTA) to adapt the generator using pseudo label reconstruction, and (v) Diffusion-based Test time Generation (DiffGen) to trace the diffusion denoising path and produce partially synthesized features that connect real and generated data, and mitigates data scarcity further. Extensive experiments on three ZSL benchmarks demonstrate that ZeroDiff++ not only achieves significant improvements over existing ZSL methods but also maintains robust performance even with scarce training data. Code would be available.

</details>


### [6] [MonoLoss: A Training Objective for Interpretable Monosemantic Representations](https://arxiv.org/abs/2602.12403)
*Ali Nasiri-Sarvi,Anh Tien Nguyen,Hassan Rivaz,Dimitris Samaras,Mahdi S. Hosseini*

Main category: cs.CV

TL;DR: 提出Monosemanticity Loss（MonoLoss），通过高效计算MonoScore实现对稀疏自编码器中单义性特征的直接优化，显著提升训练与评估效率，并在多个模型和数据集上增强特征可解释性和分类纯度。


<details>
  <summary>Details</summary>
Motivation: 标准训练目标对稀疏自编码器中的单义性分解激励不足，且现有单义性评估指标计算成本高，难以用于高效训练与评估。

Method: 提出一种单次遍历算法精确计算MonoScore，将其作为训练信号引入Monosemanticity Loss（MonoLoss），并作为辅助正则化项应用于模型微调。

Result: 在OpenImagesV7上实现高达1200倍的评估加速和159倍的训练加速，同时增加仅约4%的每轮开销；使用MonoLoss后，多数潜在表示的MonoScore和类纯度显著提升，最高纯度从0.152升至0.723；在ImageNet-1K上微调时带来最高0.6%的准确率提升。

Conclusion: MonoLoss是一种高效且有效的单义性优化方法，能显著提升稀疏自编码器生成的可解释特征质量，并在下游任务中带来性能增益，代码已公开。

Abstract: Sparse autoencoders (SAEs) decompose polysemantic neural representations, where neurons respond to multiple unrelated concepts, into monosemantic features that capture single, interpretable concepts. However, standard training objectives only weakly encourage this decomposition, and existing monosemanticity metrics require pairwise comparisons across all dataset samples, making them inefficient during training and evaluation. We study a recent MonoScore metric and derive a single-pass algorithm that computes exactly the same quantity, but with a cost that grows linearly, rather than quadratically, with the number of dataset images. On OpenImagesV7, we achieve up to a 1200x speedup wall-clock speedup in evaluation and 159x during training, while adding only ~4% per-epoch overhead. This allows us to treat MonoScore as a training signal: we introduce the Monosemanticity Loss (MonoLoss), a plug-in objective that directly rewards semantically consistent activations for learning interpretable monosemantic representations. Across SAEs trained on CLIP, SigLIP2, and pretrained ViT features, using BatchTopK, TopK, and JumpReLU SAEs, MonoLoss increases MonoScore for most latents. MonoLoss also consistently improves class purity (the fraction of a latent's activating images belonging to its dominant class) across all encoder and SAE combinations, with the largest gain raising baseline purity from 0.152 to 0.723. Used as an auxiliary regularizer during ResNet-50 and CLIP-ViT-B/32 finetuning, MonoLoss yields up to 0.6\% accuracy gains on ImageNet-1K and monosemantic activating patterns on standard benchmark datasets. The code is publicly available at https://github.com/AtlasAnalyticsLab/MonoLoss.

</details>


### [7] [Prototype-driven fusion of pathology and spatial transcriptomics for interpretable survival prediction](https://arxiv.org/abs/2602.12441)
*Lihe Liu,Xiaoxi Pan,Yinyin Yuan,Lulu Shang*

Main category: cs.CV

TL;DR: PathoSpatial 是一个可解释的端到端框架，整合共注册的全切片图像（WSI）和空间转录组学（ST）数据，以学习空间感知的预后表征。它采用任务引导的原型学习与多级专家架构，在无监督模态内发现与有监督跨模态聚合之间自适应协调，增强了可解释性并保持了判别能力。在三阴性乳腺癌队列中，该方法在五个生存终点上表现优异，优于或媲美现有单模态和多模态方法，并能提供后验原型解释和分子风险分解，揭示候选预后因子。


<details>
  <summary>Details</summary>
Motivation: 随着配对的 WSI-ST 队列扩展至人群规模，利用其互补的空间信号进行预后建模变得至关重要，但现有的跨模态融合策略仍不充分，亟需一种可解释且可扩展的多模态学习框架来整合病理图像与空间分子信息。

Method: PathoSpatial 采用多级专家架构，结合任务引导的原型学习，实现无监督模态内特征发现与有监督跨模态聚合的自适应协调。通过共注册的 WSI 与 ST 数据输入，模型在不同层级学习空间相关特征，并生成可解释的原型表示，支持后验分析与生物机制解读。

Result: 在三阴性乳腺癌数据集上，PathoSpatial 在五个生存预测任务中均表现出色，性能优于或接近当前领先的单模态和多模态方法；同时具备强大的可解释性，能够提供定量、生物学合理的风险解释和候选预后因子识别。

Conclusion: PathoSpatial 为空间组学-病理融合提供了可扩展、可解释的多模态学习范例，展示了融合形态学与空间分子信息在精准预后建模中的巨大潜力。

Abstract: Whole slide images (WSIs) enable weakly supervised prognostic modeling via multiple instance learning (MIL). Spatial transcriptomics (ST) preserves in situ gene expression, providing a spatial molecular context that complements morphology. As paired WSI-ST cohorts scale to population level, leveraging their complementary spatial signals for prognosis becomes crucial; however, principled cross-modal fusion strategies remain limited for this paradigm. To this end, we introduce PathoSpatial, an interpretable end-to-end framework integrating co-registered WSIs and ST to learn spatially informed prognostic representations. PathoSpatial uses task-guided prototype learning within a multi-level experts architecture, adaptively orchestrating unsupervised within-modality discovery with supervised cross-modal aggregation. By design, PathoSpatial substantially strengthens interpretability while maintaining discriminative ability. We evaluate PathoSpatial on a triple-negative breast cancer cohort with paired ST and WSIs. PathoSpatial delivers strong and consistent performance across five survival endpoints, achieving superior or comparable performance to leading unimodal and multimodal methods. PathoSpatial inherently enables post-hoc prototype interpretation and molecular risk decomposition, providing quantitative, biologically grounded explanations, highlighting candidate prognostic factors. We present PathoSpatial as a proof-of-concept for scalable and interpretable multimodal learning for spatial omics-pathology fusion.

</details>


### [8] [Semantic-aware Adversarial Fine-tuning for CLIP](https://arxiv.org/abs/2602.12461)
*Jiacheng Zhang,Jinhao Li,Hanxun Huang,Sarah M. Erfani,Benjamin I. P. Rubinstein,Feng Liu*

Main category: cs.CV

TL;DR: 本文提出一种新的语义增强攻击方法（semantic-ensemble attack），通过优化图像与一组经过精炼的文本描述之间的平均相似度，生成更具语义感知的对抗样本（AEs）。基于这些AEs，提出了语义感知对抗微调（SAFT）方法，用于提升CLIP模型在零样本分类任务中的对抗鲁棒性。实验表明，SAFT在16个数据集上均显著优于现有方法，有效增强了模型对语义丰富相似度度量的防御能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于手写模板（如'一张{标签}的照片'）与图像间的余弦相似度生成对抗样本，但该度量方式不足以准确反映图像-文本对的语义相似性，导致生成的对抗样本在更复杂的语义度量下失效，从而削弱了微调后的模型鲁棒性。

Method: 提出语义集成攻击，利用基础模型生成初始语义描述并进行去幻觉精炼，形成多视角的文本描述集合；最小化原始图像与该集合中所有描述的平均相似度以生成语义感知的对抗样本；进而采用这些对抗样本对CLIP图像编码器进行对抗微调，即SAFT方法。

Result: SAFT在16个基准数据集上均实现显著的零样本对抗鲁棒性提升，超越当前主流方法，在多种语义相似度度量下表现出更强的泛化能力和稳定性。

Conclusion: 通过引入语义感知的对抗样本生成与微调策略，SAFT有效克服了传统方法因依赖简单模板和余弦相似度而带来的局限性，为提升CLIP等多模态模型的对抗鲁棒性提供了新范式。

Abstract: Recent studies have shown that CLIP model's adversarial robustness in zero-shot classification tasks can be enhanced by adversarially fine-tuning its image encoder with adversarial examples (AEs), which are generated by minimizing the cosine similarity between images and a hand-crafted template (e.g., ''A photo of a {label}''). However, it has been shown that the cosine similarity between a single image and a single hand-crafted template is insufficient to measure the similarity for image-text pairs. Building on this, in this paper, we find that the AEs generated using cosine similarity may fail to fool CLIP when the similarity metric is replaced with semantically enriched alternatives, making the image encoder fine-tuned with these AEs less robust. To overcome this issue, we first propose a semantic-ensemble attack to generate semantic-aware AEs by minimizing the average similarity between the original image and an ensemble of refined textual descriptions. These descriptions are initially generated by a foundation model to capture core semantic features beyond hand-crafted templates and are then refined to reduce hallucinations. To this end, we propose Semantic-aware Adversarial Fine-Tuning (SAFT), which fine-tunes CLIP's image encoder with semantic-aware AEs. Extensive experiments show that SAFT outperforms current methods, achieving substantial improvements in zero-shot adversarial robustness across 16 datasets. Our code is available at: https://github.com/tmlr-group/SAFT.

</details>


### [9] [A Lightweight and Explainable DenseNet-121 Framework for Grape Leaf Disease Classification](https://arxiv.org/abs/2602.12484)
*Md. Ehsanul Haque,Md. Saymon Hosen Polash,Rakib Hasan Ovi,Aminul Kader Bulbul,Md Kamrul Siam,Tamim Hasan Saykat*

Main category: cs.CV

TL;DR: 本研究提出一种优化的DenseNet121模型用于葡萄叶病害分类，通过领域特定预处理和增强连接性提取病害相关特征（如叶脉、边缘和病斑）。与ResNet18、VGG16、AlexNet和SqueezeNet等基线CNN模型相比，该模型在准确率（99.27%）、F1分数（99.28%）、特异性（99.71%）和Kappa值（98.86%）上表现优异，推理时间仅9秒。交叉验证平均准确率达99.12%，表明模型具有强泛化能力。结合Grad-CAM提升可解释性，确保模型关注生理相关区域。通过模型优化与迁移学习，实现轻量化部署，适用于小样本和不平衡数据场景，整体框架兼具高精度、可扩展性和实时性。


<details>
  <summary>Details</summary>
Motivation: 当前基于YOLO等框架的自动化病害检测方法计算成本高且缺乏可解释性，难以应用于实际葡萄园管理。因此亟需一种高效、精准、可解释的葡萄叶病害识别方法以支持可持续农业管理。

Method: 采用优化的DenseNet121架构，结合领域特定预处理和深度连接结构，提取病害相关视觉特征；使用Grad-CAM进行可视化分析以增强模型可解释性；通过迁移学习处理小样本与不平衡数据，并对模型进行轻量化优化以支持实时部署。

Result: 所提模型在多个指标上均优于现有CNN模型：准确率99.27%，F1分数99.28%，特异性99.71%，Kappa值98.86%，推理时间仅9秒；交叉验证平均准确率为99.12%；Grad-CAM有效定位病害区域，提升透明度与可信度。

Conclusion: 提出的优化DenseNet121模型在葡萄叶病害分类中表现出卓越性能，具备高精度、强泛化能力、良好可解释性及低计算开销，适用于真实世界中的实时、轻量级病害监测系统，为智慧农业提供可靠技术支撑。

Abstract: Grapes are among the most economically and culturally significant fruits on a global scale, and table grapes and wine are produced in significant quantities in Europe and Asia. The production and quality of grapes are significantly impacted by grape diseases such as Bacterial Rot, Downy Mildew, and Powdery Mildew. Consequently, the sustainable management of a vineyard necessitates the early and precise identification of these diseases. Current automated methods, particularly those that are based on the YOLO framework, are often computationally costly and lack interpretability that makes them unsuitable for real-world scenarios. This study proposes grape leaf disease classification using Optimized DenseNet 121. Domain-specific preprocessing and extensive connectivity reveal disease-relevant characteristics, including veins, edges, and lesions. An extensive comparison with baseline CNN models, including ResNet18, VGG16, AlexNet, and SqueezeNet, demonstrates that the proposed model exhibits superior performance. It achieves an accuracy of 99.27%, an F1 score of 99.28%, a specificity of 99.71%, and a Kappa of 98.86%, with an inference time of 9 seconds. The cross-validation findings show a mean accuracy of 99.12%, indicating strength and generalizability across all classes. We also employ Grad-CAM to highlight disease-related regions to guarantee the model is highlighting physiologically relevant aspects and increase transparency and confidence. Model optimization reduces processing requirements for real-time deployment, while transfer learning ensures consistency on smaller and unbalanced samples. An effective architecture, domain-specific preprocessing, and interpretable outputs make the proposed framework scalable, precise, and computationally inexpensive for detecting grape leaf diseases.

</details>


### [10] [Human-Like Coarse Object Representations in Vision Models](https://arxiv.org/abs/2602.12486)
*Andrey Gizdov,Andrea Procopio,Yichen Li,Daniel Harari,Tomer Ullman*

Main category: cs.CV

TL;DR: 该研究探讨了视觉模型是否能习得类似人类的粗略、体积化的物体表征以进行直觉物理预测。通过时间到碰撞（TTC）行为范式，研究发现模型与人类行为的对齐度随训练时间、模型大小和容量的变化呈倒U型曲线：过小或训练不足的模型会过度简化为块状；过大或完全训练的模型则过度细分并出现边界波动；而中等复杂度的模型最接近人类表现。结果表明，人类般的粗略表征源于资源限制而非特定偏见，并提示可通过早期检查点、适度架构和轻度剪枝来激发高效物理表征。


<details>
  <summary>Details</summary>
Motivation: 人类在进行直觉物理推理时使用粗略、体积化的物体表征，忽略细节以提高效率，但其内部结构尚不明确。现有分割模型追求像素级精确，可能与这种粗略表征不一致。因此需要探究这些模型能否自发形成类似人类的物体表征，以及在何种条件下实现。

Method: 采用时间到碰撞（TTC）行为范式，设计比较流程与对齐度度量方法，系统改变模型的训练时间、规模及有效容量（通过剪枝实现），评估不同模型与人类行为的一致性。

Result: 所有实验条件下，模型与人类行为的对齐度均呈现倒U型曲线。中等复杂度的模型（如早期检查点、适度架构、轻度剪枝）表现出最佳对齐，既不过度简化也不过度细分，最接近人类的粗略物体表征。

Conclusion: 人类般的粗略物体表征并非由专门设计的偏见导致，而是由计算资源限制自然产生的结果。该研究揭示了简单调控手段（如早期检查点、轻度剪枝）可有效引导模型生成具有物理预测效率的表示，支持资源理性理论中识别精度与物理可用性之间的权衡。

Abstract: Humans appear to represent objects for intuitive physics with coarse, volumetric bodies'' that smooth concavities - trading fine visual details for efficient physical predictions - yet their internal structure is largely unknown. Segmentation models, in contrast, optimize pixel-accurate masks that may misalign with such bodies. We ask whether and when these models nonetheless acquire human-like bodies. Using a time-to-collision (TTC) behavioral paradigm, we introduce a comparison pipeline and alignment metric, then vary model training time, size, and effective capacity via pruning. Across all manipulations, alignment with human behavior follows an inverse U-shaped curve: small/briefly trained/pruned models under-segment into blobs; large/fully trained models over-segment with boundary wiggles; and an intermediate ideal body granularity'' best matches humans. This suggests human-like coarse bodies emerge from resource constraints rather than bespoke biases, and points to simple knobs - early checkpoints, modest architectures, light pruning - for eliciting physics-efficient representations. We situate these results within resource-rational accounts balancing recognition detail against physical affordances.

</details>


### [11] [Matching of SAR and optical images based on transformation to shared modality](https://arxiv.org/abs/2602.12515)
*Alexey Borisov,Evgeny Myasnikov,Vladislav Myasnikov*

Main category: cs.CV

TL;DR: 本文提出一种新方法，通过将光学图像和SAR图像转换到一个共同的新型影像模态中实现精确配准。该模态满足通道数一致、图像相似性高且特征不丢失的要求，并利用已有的RoMa等预训练模型进行匹配，显著提升了跨模态图像配准性能与通用性。


<details>
  <summary>Details</summary>
Motivation: 光学与SAR图像因成像原理不同导致视觉差异大，传统配准方法效果不佳，亟需一种高效且通用的跨模态图像匹配新方法。

Method: 将光学与SAR图像统一变换至一个共享的新模态，确保通道数一致、图像高度相似且保留关键特征，随后使用预训练的RoMa和DeDoDe模型进行匹配。

Result: 在MultiSenGE数据集上验证，该方法优于基于图像翻译和传统特征匹配的方案，不仅匹配精度更高，还可直接复用现有预训练模型，无需针对新模态重新训练。

Conclusion: 所提方法实现了光学与SAR图像的高质量、高通用性匹配，为多源遥感图像融合提供了有效解决方案。

Abstract: Significant differences in optical images and Synthetic Aperture Radar (SAR) images are caused by fundamental differences in the physical principles underlying their acquisition by Earth remote sensing platforms. These differences make precise image matching (co-registration) of these two types of images difficult. In this paper, we propose a new approach to image matching of optical and SAR images, which is based on transforming the images to a new modality. The new image modality is common to both optical and SAR images and satisfies the following conditions. First, the transformed images must have an equal pre-defined number of channels. Second, the transformed and co-registered images must be as similar as possible. Third, the transformed images must be non-degenerate, meaning they must preserve the significant features of the original images. To further match images transformed to this shared modality, we train the RoMa image matching model, which is one of the leading solutions for matching of regular digital photographs. We evaluated the proposed approach on the publicly available MultiSenGE dataset containing both optical and SAR images. We demonstrated its superiority over alternative approaches based on image translation between original modalities and various feature matching algorithms. The proposed solution not only provides better quality of matching, but is also more versatile. It enables the use of ready-made RoMa and DeDoDe models, pre-trained for regular images, without retraining for a new modality, while maintaining high-quality matching of optical and SAR images.

</details>


### [12] [LiDAR-Anchored Collaborative Distillation for Robust 2D Representations](https://arxiv.org/abs/2602.12524)
*Wonjun Jo,Hyunwoo Ha,Kim Ji-Yeon,Hawook Jeong,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 提出了一种名为协作蒸馏的新自监督方法，利用3D LiDAR作为自监督信号，提升2D图像编码器在噪声和恶劣天气条件下的鲁棒性，同时保持其原有能力，并增强3D感知能力，显著提升下游任务性能与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有预训练2D图像编码器在复杂环境（如恶劣天气、夜间）下表现不佳，缺乏对3D空间信息的感知能力，亟需一种能够增强鲁棒性和3D理解的自监督学习方法。

Method: 提出协作蒸馏方法，通过3D LiDAR提供的几何结构信息作为自监督信号，指导2D图像编码器学习更鲁棒的特征表示，同时保留原始功能并增强对3D场景的理解。

Result: 在多种下游任务中，该方法在不同环境下均优于现有方法，展现出更强的泛化能力与实际应用价值，且提升了模型对3D环境的感知能力。

Conclusion: 协作蒸馏有效提升了2D图像编码器在复杂环境中的鲁棒性与3D感知能力，为视觉系统在真实世界中的应用提供了有力支持。

Abstract: As deep learning continues to advance, self-supervised learning has made considerable strides. It allows 2D image encoders to extract useful features for various downstream tasks, including those related to vision-based systems. Nevertheless, pre-trained 2D image encoders fall short in conducting the task under noisy and adverse weather conditions beyond clear daytime scenes, which require for robust visual perception. To address these issues, we propose a novel self-supervised approach, \textbf{Collaborative Distillation}, which leverages 3D LiDAR as self-supervision to improve robustness to noisy and adverse weather conditions in 2D image encoders while retaining their original capabilities. Our method outperforms competing methods in various downstream tasks across diverse conditions and exhibits strong generalization ability. In addition, our method also improves 3D awareness stemming from LiDAR's characteristics. This advancement highlights our method's practicality and adaptability in real-world scenarios.

</details>


### [13] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: 该研究提出Language-Guided Invariance Probing (LGIP)基准，用于评估视觉语言模型（VLMs）在语言扰动下的鲁棒性，包括对语义保持的改写（paraphrases）的不变性及对语义改变的敏感性。基于40,000张MS COCO图像及其五组人工描述，自动生成改写和规则化语义翻转（如对象类别、颜色或数量变化），并通过不变性误差、语义敏感性差距和正向率统计量来总结模型表现。结果显示，EVA02-CLIP和大型OpenCLIP模型在不变性与敏感性之间表现出更优平衡，而SigLIP系列模型则显示出更高的不变性误差并常偏好错误的翻转描述，这些缺陷在传统检索指标中难以察觉，表明LGIP可作为超越常规准确率的模型无关诊断工具。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型虽在零样本任务中表现优异，但其对语言扰动的可靠性尚不明确。尤其在面对语义保持的改写或语义改变的翻转时，模型是否能稳定响应仍缺乏系统评估。因此需要一个能揭示模型语言理解鲁棒性的新基准。

Method: 构建LGIP基准，利用40,000张MS COCO图像及其5个每张的人类标注文本，通过自动化方法生成语义保持的改写（paraphrases）和规则化的语义翻转（如对象类别、颜色、数量变化），进而计算模型在原始描述与扰动描述之间的匹配得分差异，引入不变性误差、语义敏感性差距和正向率等指标量化模型行为。

Result: 九种VLM中，EVA02-CLIP和大尺寸OpenCLIP模型在不变性与敏感性之间表现更优，对改写具有较低方差且更偏好原始描述；而SigLIP和SigLIP2则表现出显著更高的不变性误差，常更倾向于翻转后的错误描述，尤其是在对象和颜色修改场景下。这些缺陷在标准检索指标中未被发现，说明LGIP能揭示传统评估忽略的模型语言鲁棒性问题。

Conclusion: LGIP是一个有效、模型无关的诊断工具，能够揭示当前VLMs在语言扰动下的隐性脆弱性，有助于推动更稳健的视觉语言模型设计与评估。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [14] [Self-Supervised JEPA-based World Models for LiDAR Occupancy Completion and Forecasting](https://arxiv.org/abs/2602.12540)
*Haoran Zhu,Anna Choromanska*

Main category: cs.CV

TL;DR: 本文提出AD-LiST-JEPA，一种基于JEPA框架的自监督世界模型，利用LiDAR数据预测自动驾驶场景中环境的时空演化。通过下游的LiDAR占用完成与预测任务（OCF）评估表示学习质量，实验证明预训练编码器能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要构建能够捕捉环境时空演化的世界模型以支持长期规划，而传统方法依赖标注数据，成本高；因此需发展自监督学习方法，实现高效、可扩展的世界模型学习。

Method: 采用联合嵌入预测架构（JEPA），利用大量未标注的LiDAR数据进行自监督训练，学习环境的时空演化规律，构建世界模型。

Result: 在下游的占用完成与预测（OCF）任务中，使用经过JEPA训练的编码器取得了更优表现，证明了所学表征的有效性。

Conclusion: AD-LiST-JEPA成功实现了基于自监督学习的自动驾驶世界模型构建，提升了感知与预测能力，具备良好的可扩展性和应用前景。

Abstract: Autonomous driving, as an agent operating in the physical world, requires the fundamental capability to build \textit{world models} that capture how the environment evolves spatiotemporally in order to support long-term planning. At the same time, scalability demands learning such models in a self-supervised manner; \textit{joint-embedding predictive architecture (JEPA)} enables learning world models via leveraging large volumes of unlabeled data without relying on expensive human annotations. In this paper, we propose \textbf{AD-LiST-JEPA}, a self-supervised world model for autonomous driving that predicts future spatiotemporal evolution from LiDAR data using a JEPA framework. We evaluate the quality of the learned representations through a downstream LiDAR-based occupancy completion and forecasting (OCF) task, which jointly assesses perception and prediction. Proof of concept experiments show better OCF performance with pretrained encoder after JEPA-based world model learning.

</details>


### [15] [PLLM: Pseudo-Labeling Large Language Models for CAD Program Synthesis](https://arxiv.org/abs/2602.12561)
*Yuanbo Li,Dule Shu,Yanying Chen,Matt Klenk,Daniel Ritchie*

Main category: cs.CV

TL;DR: PLL M提出一种自训练框架，用于从无标签3D形状中合成CAD程序。通过迭代采样候选程序、选择高保真执行并构建合成的程序-形状对进行微调，实现了在几何保真度和程序多样性上的提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于成对的形状-程序数据进行监督训练，但这类数据往往难以获取；因此需要一种无需标注数据即可进行CAD程序合成的方法。

Method: PLL M利用预训练的CAD能力语言模型，通过迭代方式采样候选程序，筛选高保真执行结果，并生成合成的程序-形状配对以用于后续微调。

Result: 在将DeepCAD中的CAD-Recode适配到无标签ABC数据集时，实验显示几何保真度和程序多样性均有显著提升。

Conclusion: PLL M成功实现了在无监督条件下从3D形状恢复CAD程序，为缺乏标注数据的场景提供了有效解决方案。

Abstract: Recovering Computer-Aided Design (CAD) programs from 3D geometries is a widely studied problem. Recent advances in large language models (LLMs) have enabled progress in CAD program synthesis, but existing methods rely on supervised training with paired shape-program data, which is often unavailable. We introduce PLLM, a self-training framework for CAD program synthesis from unlabeled 3D shapes. Given a pre-trained CAD-capable LLM and a shape dataset, PLLM iteratively samples candidate programs, selects high-fidelity executions, and augments programs to construct synthetic program-shape pairs for fine-tuning. We experiment on adapting CAD-Recode from DeepCAD to the unlabeled ABC dataset show consistent improvements in geometric fidelity and program diversity.

</details>


### [16] [The Constant Eye: Benchmarking and Bridging Appearance Robustness in Autonomous Driving](https://arxiv.org/abs/2602.12563)
*Jiabao Wang,Hongyu Zhou,Yuanbo Yang,Jiahao Shao,Yiyi Liao*

Main category: cs.CV

TL;DR: 该论文提出navdream基准，通过生成式像素对齐风格迁移，在几何结构不变的情况下测试外观变化对自动驾驶规划算法的影响。研究发现现有算法在外观变化（如天气、光照）下表现显著下降，而提出基于冻结视觉基础模型DINOv3的通用感知接口，提取外观不变特征，实现零样本泛化，适用于多种规划方法且无需微调。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶算法在分布外（OOD）条件下表现脆弱，但缺乏对外观变化（如天气、光照）与场景结构变化的区分，导致无法判断算法失败是因复杂道路几何还是单纯环境外观变化所致。

Method: 使用生成式像素对齐风格迁移构建navdream高保真鲁棒性基准，通过控制几何结构不变，仅改变外观进行测试；提出基于冻结视觉基础模型DINOv3的通用感知接口，提取外观不变特征作为规划器的稳定输入接口。

Result: 现有规划算法在外观变化下性能显著下降；所提方法在多种规划范式中均实现卓越的零样本泛化能力，跨极端外观变化保持一致性能，无需额外微调。

Conclusion: 通过分离外观与结构影响，揭示了现有算法对外观变化的敏感性；提出的通用感知接口有效提升鲁棒性，为自动驾驶系统在复杂多变环境中的可靠运行提供新解决方案。

Abstract: Despite rapid progress, autonomous driving algorithms remain notoriously fragile under Out-of-Distribution (OOD) conditions. We identify a critical decoupling failure in current research: the lack of distinction between appearance-based shifts, such as weather and lighting, and structural scene changes. This leaves a fundamental question unanswered: Is the planner failing because of complex road geometry, or simply because it is raining? To resolve this, we establish navdream, a high-fidelity robustness benchmark leveraging generative pixel-aligned style transfer. By creating a visual stress test with negligible geometric deviation, we isolate the impact of appearance on driving performance. Our evaluation reveals that existing planning algorithms often show significant degradation under OOD appearance conditions, even when the underlying scene structure remains consistent. To bridge this gap, we propose a universal perception interface leveraging a frozen visual foundation model (DINOv3). By extracting appearance-invariant features as a stable interface for the planner, we achieve exceptional zero-shot generalization across diverse planning paradigms, including regression-based, diffusion-based, and scoring-based models. Our plug-and-play solution maintains consistent performance across extreme appearance shifts without requiring further fine-tuning. The benchmark and code will be made available.

</details>


### [17] [Unbiased Gradient Estimation for Event Binning via Functional Backpropagation](https://arxiv.org/abs/2602.12590)
*Jinze Chen,Wei Zhai,Han Han,Tiankai Ma,Yang Cao,Bin Li,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出一种新的无偏梯度估计框架，通过在反向传播中合成弱导数，解决事件视觉中分箱函数不连续导致的梯度偏差问题，显著提升事件数据处理效率与下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有事件视觉方法依赖分箱生成帧，但分箱函数不连续导致梯度截断，限制了模型学习能力；直接处理原始事件虽避免此问题，却因分箱操作的不连续性导致梯度估计偏差，影响学习效率。

Method: 利用积分变换中的分部积分原理，将分箱函数提升为泛函形式，在反向传播中通过重构余切向量来计算弱导数，实现对任意分箱函数的无偏梯度估计，同时保持前向输出不变。

Result: 在基于优化的自运动估计中，实现3.2%更低的均方根误差和1.57倍更快的收敛速度；在自监督光流任务中，降低9.4%的端点误差（EPE）；在SLAM任务中，降低5.1%的均方根误差，验证了方法在多种复杂任务上的有效性。

Conclusion: 所提方法通过理论严谨的弱导数估计机制，有效解决了事件视觉中分箱操作带来的梯度偏差问题，显著提升了事件数据的学习效率与感知性能，具有广泛的应用前景。

Abstract: Event-based vision encodes dynamic scenes as asynchronous spatio-temporal spikes called events. To leverage conventional image processing pipelines, events are typically binned into frames. However, binning functions are discontinuous, which truncates gradients at the frame level and forces most event-based algorithms to rely solely on frame-based features. Attempts to directly learn from raw events avoid this restriction but instead suffer from biased gradient estimation due to the discontinuities of the binning operation, ultimately limiting their learning efficiency. To address this challenge, we propose a novel framework for unbiased gradient estimation of arbitrary binning functions by synthesizing weak derivatives during backpropagation while keeping the forward output unchanged. The key idea is to exploit integration by parts: lifting the target functions to functionals yields an integral form of the derivative of the binning function during backpropagation, where the cotangent function naturally arises. By reconstructing this cotangent function from the sampled cotangent vector, we compute weak derivatives that provably match long-range finite differences of both smooth and non-smooth targets. Experimentally, our method improves simple optimization-based egomotion estimation with 3.2\% lower RMS error and 1.57$\times$ faster convergence. On complex downstream tasks, we achieve 9.4\% lower EPE in self-supervised optical flow, and 5.1\% lower RMS error in SLAM, demonstrating broad benefits for event-based visual perception. Source code can be found at https://github.com/chjz1024/EventFBP.

</details>


### [18] [QuEPT: Quantized Elastic Precision Transformers with One-Shot Calibration for Multi-Bit Switching](https://arxiv.org/abs/2602.12609)
*Ke Xu,Yixin Wang,Zhongcheng Li,Hao Cui,Jinshui Hu,Xingyi Zhang*

Main category: cs.CV

TL;DR: QuEPT提出了一种高效的后训练量化方案，通过单次校准在小数据子集上重建块级多比特误差，支持动态适应不同位宽，并实现实时切换均匀量化与混合精度量化，无需重复优化。引入MB-ToMe和MB-CLoRA提升模型鲁棒性和性能，在多个基准上表现优于或相当现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有弹性量化方法在Transformer架构下面临高存储和优化成本问题，尤其对大语言模型研究有限，亟需高效、灵活且低成本的量化方案以支持多比特部署和动态位宽切换。

Method: 提出QuEPT，结合单次校准、块级误差重建、低秩适配器级联、多比特令牌融合（MB-ToMe）以及多比特级联低秩适配器（MB-CLoRA），实现动态位宽适应与实时切换，增强跨位宽相关性与模型鲁棒性。

Result: 在多个大型语言模型上，QuEPT在精度和鲁棒性方面均达到或超越当前最优后训练量化方法，且无需重复优化即可支持多种量化策略。

Conclusion: QuEPT是一种高效、灵活且可扩展的后训练弹性量化框架，适用于大规模语言模型的多比特部署，显著降低优化成本并提升实用性。

Abstract: Elastic precision quantization enables multi-bit deployment via a single optimization pass, fitting diverse quantization scenarios.Yet, the high storage and optimization costs associated with the Transformer architecture, research on elastic quantization remains limited, particularly for large language models.This paper proposes QuEPT, an efficient post-training scheme that reconstructs block-wise multi-bit errors with one-shot calibration on a small data slice. It can dynamically adapt to various predefined bit-widths by cascading different low-rank adapters, and supports real-time switching between uniform quantization and mixed precision quantization without repeated optimization. To enhance accuracy and robustness, we introduce Multi-Bit Token Merging (MB-ToMe) to dynamically fuse token features across different bit-widths, improving robustness during bit-width switching. Additionally, we propose Multi-Bit Cascaded Low-Rank adapters (MB-CLoRA) to strengthen correlations between bit-width groups, further improve the overall performance of QuEPT. Extensive experiments demonstrate that QuEPT achieves comparable or better performance to existing state-of-the-art post-training quantization methods.Our code is available at https://github.com/xuke225/QuEPT

</details>


### [19] [Vision Token Reduction via Attention-Driven Self-Compression for Efficient Multimodal Large Language Models](https://arxiv.org/abs/2602.12618)
*Omer Faruk Deniz,Ruiyu Mao,Ruochen Li,Yapeng Tian,Latifur Khan*

Main category: cs.CV

TL;DR: 提出了一种名为注意力驱动自压缩（ADSC）的新方法，通过利用大语言模型（LLM）自身的注意力机制，在多个层上进行统一的视觉标记下采样，以逐步减少视觉输入数量。该方法无需额外模块、评分计算或注意力结构修改，完全兼容FlashAttention，显著降低计算量和内存占用，同时保持高精度。在LLaVA-1.5上的实验显示，其可减少53.7%的浮点运算量和56.7%的峰值KV缓存内存，性能保留率达98.2%，且在高压缩比下仍优于现有剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法要么在LLM之前操作，受限于编码器-投影器设计多样性；要么在LLM内部使用启发式规则，与FlashAttention不兼容。因此需要一种通用、高效且兼容性强的压缩方法。

Method: 引入注意力驱动自压缩（ADSC），在选定层上对视觉标记进行均匀下采样，形成信息压缩瓶颈，利用LLM自身注意力机制引导信息重组与压缩，无需额外模块或修改注意力结构。

Result: 在LLaVA-1.5上实现53.7%的FLOPs减少和56.7%的峰值KV缓存内存减少，性能保留98.2%；在多基准测试中优于已有剪枝方法，尤其在高压缩比下表现更稳健。

Conclusion: ADSC是一种简单、通用、高效且兼容FlashAttention的视觉标记压缩方法，能够有效降低多模态大模型的计算开销，同时保持高性能，为高效推理提供了新思路。

Abstract: Multimodal Large Language Models (MLLMs) incur significant computational cost from processing numerous vision tokens through all LLM layers. Prior pruning methods operate either before the LLM, limiting generality due to diverse encoder-projector designs or within the LLM using heuristics that are incompatible with FlashAttention. We take a different approach: rather than identifying unimportant tokens, we treat the LLM itself as the optimal guide for compression. Observing that deeper layers naturally transmit vision-to-text information, we introduce Attention-Driven Self-Compression (ADSC), a simple, broadly applicable method that progressively reduces vision tokens using only the LLM's attention mechanism. Our method applies uniform token downsampling at selected layers, forming bottlenecks that encourage the model to reorganize and compress information into the remaining tokens. It requires no score computation, auxiliary modules, or attention modification, and remains fully compatible with FlashAttention. Applied to LLaVA-1.5, ADSC reduces FLOPs by 53.7% and peak KV-cache memory by 56.7%, while preserving 98.2% of the original model performance. Across multiple benchmarks, it outperforms prior pruning approaches in both efficiency and accuracy. Crucially, under high compression ratios, our method remains robust while heuristic-based techniques degrade sharply.

</details>


### [20] [ImageRAGTurbo: Towards One-step Text-to-Image Generation with Retrieval-Augmented Diffusion Models](https://arxiv.org/abs/2602.12640)
*Peijie Qiu,Hariharan Ramshankar,Arnau Ramisa,René Vidal,Amit Kumar K C,Vamsi Salaka,Rahul Bhagat*

Main category: cs.CV

TL;DR: 提出ImageRAGTurbo，通过检索增强微调少步扩散模型，利用文本-图像对检索提供上下文信息，提升生成质量与提示对齐度，无需额外训练即可改善图像保真度，并通过可训练适配器在$\mathcal{H}$-空间融合检索内容，实现高效生成高保真图像。


<details>
  <summary>Details</summary>
Motivation: 现有少步扩散模型虽降低采样步骤以减少延迟，但牺牲图像质量和提示对齐，且训练成本高；需一种高效方法在不增加计算负担的前提下提升生成效果。

Method: 基于文本提示从数据库中检索相关文本-图像对，将检索到的内容用于条件生成；通过修改UNet去噪器的隐空间（$\mathcal{H}$-空间）来融入上下文信息；引入可训练适配器，结合交叉注意力机制融合检索内容与目标提示。

Result: 实验表明，该方法在快速文本到图像生成任务中能生成高质量、高保真图像，同时保持低延迟优势，优于现有方法。

Conclusion: ImageRAGTurbo通过检索增强策略有效提升了少步扩散模型的生成质量与效率，为高效文本到图像生成提供了新思路。

Abstract: Diffusion models have emerged as the leading approach for text-to-image generation. However, their iterative sampling process, which gradually morphs random noise into coherent images, introduces significant latency that limits their applicability. While recent few-step diffusion models reduce the number of sampling steps to as few as one to four steps, they often compromise image quality and prompt alignment, especially in one-step generation. Additionally, these models require computationally expensive training procedures. To address these limitations, we propose ImageRAGTurbo, a novel approach to efficiently finetune few-step diffusion models via retrieval augmentation. Given a text prompt, we retrieve relevant text-image pairs from a database and use them to condition the generation process. We argue that such retrieved examples provide rich contextual information to the UNet denoiser that helps reduce the number of denoising steps without compromising image quality. Indeed, our initial investigations show that using the retrieved content to edit the denoiser's latent space ($\mathcal{H}$-space) without additional finetuning already improves prompt fidelity. To further improve the quality of the generated images, we augment the UNet denoiser with a trainable adapter in the $\mathcal{H}$-space, which efficiently blends the retrieved content with the target prompt using a cross-attention mechanism. Experimental results on fast text-to-image generation demonstrate that our approach produces high-fidelity images without compromising latency compared to existing methods.

</details>


### [21] [Multi-Task Learning with Additive U-Net for Image Denoising and Classification](https://arxiv.org/abs/2602.12649)
*Vikram Lakkavalli,Neelam Sinha*

Main category: cs.CV

TL;DR: 该研究提出Additive U-Net（AddUNet），通过将U-Net中的拼接跳跃连接替换为门控加法融合，以约束捷径容量并保持深度间特征维度恒定。这种方法在单任务去噪和联合去噪-分类多任务学习中均表现出竞争性重建性能和更好的训练稳定性。在多任务学习中，学习到的跳跃权重呈现出系统性的任务感知重分配：浅层跳跃侧重于重建，深层特征支持判别。值得注意的是，即使分类能力有限，重建任务仍保持鲁棒性，表明加法融合实现了隐式的任务解耦。结果表明，对跳跃连接施加简单约束可作为有效的架构正则化手段，提升多任务学习的稳定性和可扩展性，且不增加模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有U-Net结构中拼接跳跃连接可能导致信息过载和训练不稳定，尤其在多任务学习场景下，任务间干扰严重。因此需要一种机制来控制编码器-解码器之间的信息流，实现更稳定的联合优化。

Method: 采用门控加法融合替代传统的拼接跳跃连接，限制了跳跃路径的信息容量，同时保持特征维度不变。通过引入可学习的门控权重，实现对不同层级跳跃信息的动态调节。

Result: AddUNet在单任务去噪和多任务联合学习中均达到与现有方法相当甚至更优的重建性能；训练过程更加稳定；在多任务设置中，跳接权重呈现任务感知的分布模式，浅层支持重建，深层支持分类；即使分类分支容量受限，重建性能依然稳健，体现隐式任务解耦。

Conclusion: 对跳跃连接施加加法融合的约束是一种有效的架构正则化策略，能够提升多任务学习的稳定性与可扩展性，且无需增加模型复杂度，适用于去噪及去噪为中心的多任务学习任务。

Abstract: We investigate additive skip fusion in U-Net architectures for image denoising and denoising-centric multi-task learning (MTL). By replacing concatenative skips with gated additive fusion, the proposed Additive U-Net (AddUNet) constrains shortcut capacity while preserving fixed feature dimensionality across depth. This structural regularization induces controlled encoder-decoder information flow and stabilizes joint optimization. Across single-task denoising and joint denoising-classification settings, AddUNet achieves competitive reconstruction performance with improved training stability. In MTL, learned skip weights exhibit systematic task-aware redistribution: shallow skips favor reconstruction, while deeper features support discrimination. Notably, reconstruction remains robust even under limited classification capacity, indicating implicit task decoupling through additive fusion. These findings show that simple constraints on skip connections act as an effective architectural regularizer for stable and scalable multi-task learning without increasing model complexity.

</details>


### [22] [CBEN -- A Multimodal Machine Learning Dataset for Cloud Robust Remote Sensing Image Understanding](https://arxiv.org/abs/2602.12652)
*Marco Stricker,Masakazu Iwamura,Koichi Kise*

Main category: cs.CV

TL;DR: 本文提出了一种名为CloudyBigEarthNet（CBEN）的新数据集，包含带有云遮挡的光学与雷达图像配对数据，用于研究在云覆盖条件下的遥感图像分析。研究发现，现有基于晴天光学与雷达数据训练的先进方法在云遮挡图像上性能下降23-33个百分点。通过在训练中引入云遮挡的光学数据，所提方法在云遮挡测试场景下相对原方法提升17.2-28.7个百分点，显著增强了模型对云的鲁棒性。代码与数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 现有遥感机器学习方法通常排除云遮挡图像，导致在自然灾害等时间敏感应用中无法有效工作；为提升模型在云覆盖条件下的表现，需开发对云不敏感的方法，而融合光学与雷达数据是可行路径，但现有研究多忽略云遮挡场景，限制了实际应用。

Method: 构建名为CloudyBigEarthNet（CBEN）的数据集，包含光学与雷达图像配对且带有云遮挡；将现有先进方法在包含云遮挡的光学数据上进行再训练，以增强其对云的鲁棒性，并使用平均精度（AP）评估性能。

Result: 基于晴天数据训练的模型在云遮挡图像上性能下降23-33个百分点；通过在训练中加入云遮挡光学数据，模型在云遮挡测试中相对提升17.2-28.7个百分点，显著改善鲁棒性。

Conclusion: 云遮挡严重影响现有遥感模型性能，仅依赖晴天数据训练不可靠。通过在训练中纳入云遮挡样本并结合多模态数据，可显著提升模型对云的鲁棒性，为真实世界应用提供更可靠解决方案。

Abstract: Clouds are a common phenomenon that distorts optical satellite imagery, which poses a challenge for remote sensing. However, in the literature cloudless analysis is often performed where cloudy images are excluded from machine learning datasets and methods. Such an approach cannot be applied to time sensitive applications, e.g., during natural disasters. A possible solution is to apply cloud removal as a preprocessing step to ensure that cloudfree solutions are not failing under such conditions. But cloud removal methods are still actively researched and suffer from drawbacks, such as generated visual artifacts. Therefore, it is desirable to develop cloud robust methods that are less affected by cloudy weather. Cloud robust methods can be achieved by combining optical data with radar, a modality unaffected by clouds. While many datasets for machine learning combine optical and radar data, most researchers exclude cloudy images. We identify this exclusion from machine learning training and evaluation as a limitation that reduces applicability to cloudy scenarios. To investigate this, we assembled a dataset, named CloudyBigEarthNet (CBEN), of paired optical and radar images with cloud occlusion for training and evaluation. Using average precision (AP) as the evaluation metric, we show that state-of-the-art methods trained on combined clear-sky optical and radar imagery suffer performance drops of 23-33 percentage points when evaluated on cloudy images. We then adapt these methods to cloudy optical data during training, achieving relative improvement of 17.2-28.7 percentage points on cloudy test cases compared with the original approaches. Code and dataset are publicly available at: https://github.com/mstricker13/CBEN

</details>


### [23] [Motion Prior Distillation in Time Reversal Sampling for Generative Inbetweening](https://arxiv.org/abs/2602.12679)
*Wooseok Jeon,Seunghyun Shin,Dongmin Shin,Hae-Gon Jeon*

Main category: cs.CV

TL;DR: 本文提出了一种名为运动先验蒸馏（MPD）的推理时蒸馏技术，用于改善图像到视频扩散模型在生成中间帧时的时空连续性问题。通过将前向路径的运动残差蒸馏到后向路径中，有效缓解了双向路径间的不匹配问题，避免了末端条件路径的去噪带来的歧义，从而在保持前向运动先验的同时提升生成结果的时序一致性。实验表明，该方法在标准基准和用户研究中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于推理时采样的图像到视频生成方法存在前后路径间运动不一致的问题，导致时间上的不连贯和视觉伪影。这是因为每条路径依赖于各自的条件帧所诱导的运动先验，造成双向路径间的错位。

Method: 提出运动先验蒸馏（MPD）技术，在推理阶段将前向路径的运动残差信息蒸馏至后向路径，以抑制双向路径间的不匹配。通过有选择地避免对末端条件路径进行去噪，减少路径歧义，增强生成结果的时间连贯性。

Result: 在多个标准数据集上进行了定量评估，并通过广泛的用户研究验证了该方法在实际应用中的有效性，生成结果在时序连贯性和视觉质量方面均有显著提升。

Conclusion: MPD是一种简单而有效的推理时蒸馏方法，能够显著提升图像到视频生成中中间帧的质量与时间一致性，为生成式插值提供了新的解决方案。

Abstract: Recent progress in image-to-video (I2V) diffusion models has significantly advanced the field of generative inbetweening, which aims to generate semantically plausible frames between two keyframes. In particular, inference-time sampling strategies, which leverage the generative priors of large-scale pre-trained I2V models without additional training, have become increasingly popular. However, existing inference-time sampling, either fusing forward and backward paths in parallel or alternating them sequentially, often suffers from temporal discontinuities and undesirable visual artifacts due to the misalignment between the two generated paths. This is because each path follows the motion prior induced by its own conditioning frame. In this work, we propose Motion Prior Distillation (MPD), a simple yet effective inference-time distillation technique that suppresses bidirectional mismatch by distilling the motion residual of the forward path into the backward path. Our method can deliberately avoid denoising the end-conditioned path which causes the ambiguity of the path, and yield more temporally coherent inbetweening results with the forward motion prior. We not only perform quantitative evaluations on standard benchmarks, but also conduct extensive user studies to demonstrate the effectiveness of our approach in practical scenarios.

</details>


### [24] [Channel-Aware Probing for Multi-Channel Imaging](https://arxiv.org/abs/2602.12696)
*Umar Marikkar,Syed Sameed Husain,Muhammad Awais,Sara Atito*

Main category: cs.CV

TL;DR: 本文提出Channel-Aware Probing (CAP)方法，解决多通道成像（MCI）数据中因通道配置差异导致的预训练编码器复用难题。CAP通过独立特征编码（IFE）和解耦池化（DCP）机制，充分利用MCI数据的通道间多样性，在不微调的情况下显著提升探针性能，表现接近甚至媲美从零开始微调的效果，并大幅缩小与全量微调之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有MCI预训练模型在新通道设置下难以直接复用，且传统探针方法未充分考虑通道间的内在差异，导致性能不佳，甚至不如从零训练。因此需要一种能有效利用通道多样性的探针策略。

Method: CAP采用Independent Feature Encoding（IFE）对各通道独立编码，再通过Decoupled Pooling（DCP）在通道内进行池化并跨通道聚合，从而实现对通道间差异的有效建模与利用。

Result: 在三个MCI基准上，CAP在固定权重探针任务中持续优于标准探针协议，性能达到与从头微调相当水平，并显著缩小与全量微调的差距。

Conclusion: CAP是一种高效且可迁移的MCI探针方法，能够充分利用通道间的异质性，为预训练模型在多样化通道配置下的应用提供了新范式。

Abstract: Training and evaluating vision encoders on Multi-Channel Imaging (MCI) data remains challenging as channel configurations vary across datasets, preventing fixed-channel training and limiting reuse of pre-trained encoders on new channel settings. Prior work trains MCI encoders but typically evaluates them via full fine-tuning, leaving probing with frozen pre-trained encoders comparatively underexplored. Existing studies that perform probing largely focus on improving representations, rather than how to best leverage fixed representations for downstream tasks. Although the latter problem has been studied in other domains, directly transferring those strategies to MCI yields weak results, even worse than training from scratch. We therefore propose Channel-Aware Probing (CAP), which exploits the intrinsic inter-channel diversity in MCI datasets by controlling feature flow at both the encoder and probe levels. CAP uses Independent Feature Encoding (IFE) to encode each channel separately, and Decoupled Pooling (DCP) to pool within channels before aggregating across channels. Across three MCI benchmarks, CAP consistently improves probing performance over the default probing protocol, matches fine-tuning from scratch, and largely reduces the gap to full fine-tuning from the same MCI pre-trained checkpoints. Code can be found in https://github.com/umarikkar/CAP.

</details>


### [25] [SPRig: Self-Supervised Pose-Invariant Rigging from Mesh Sequences](https://arxiv.org/abs/2602.12740)
*Ruipeng Wang,Langkun Zhong,Miaowei Wang*

Main category: cs.CV

TL;DR: 提出SPRig，一种通用的微调框架，通过跨帧一致性损失学习对姿态不变的绑定，适用于缺乏标准休息姿态（如T-pose）的序列数据，显著提升时间稳定性并减少基线方法中的伪影。


<details>
  <summary>Details</summary>
Motivation: 现有绑定方法假设存在标准休息姿态（如T-pose），但在动物动作捕捉或由AIGC/视频生成的网格序列等连续数据中该假设不成立；逐帧应用这些方法不具备姿态不变性，导致帧间拓扑不一致。

Method: 提出SPRig框架，在已有模型基础上引入跨帧一致性损失，实现对姿态不变绑定的学习，并采用新的置换不变稳定性评估协议进行验证。

Result: 实验表明，SPRig在时间稳定性方面达到当前最优水平，能从挑战性序列中生成连贯的绑定，大幅减少基线方法中存在的伪影。

Conclusion: SPRig是一种有效的通用微调框架，能够解决无标准休息姿态序列中的绑定不一致问题，提升绑定质量与稳定性。

Abstract: State-of-the-art rigging methods assume a canonical rest pose--an assumption that fails for sequential data (e.g., animal motion capture or AIGC/video-derived mesh sequences) that lack the T-pose. Applied frame-by-frame, these methods are not pose-invariant and produce topological inconsistencies across frames. Thus We propose SPRig, a general fine-tuning framework that enforces cross-frame consistency losses to learn pose-invariant rigs on top of existing models. We validate our approach on rigging using a new permutation-invariant stability protocol. Experiments demonstrate SOTA temporal stability: our method produces coherent rigs from challenging sequences and dramatically reduces the artifacts that plague baseline methods. The code will be released publicly upon acceptance.

</details>


### [26] [Synthetic Craquelure Generation for Unsupervised Painting Restoration](https://arxiv.org/abs/2602.12742)
*Jana Cuch-Guillén,Antonio Agudo,Raül Pérez-Gonzalo*

Main category: cs.CV

TL;DR: 提出了一种无需标注的绘画裂缝修复框架，利用领域特定的合成裂缝生成器模拟真实裂缝形态，结合传统形态学检测与基于学习的精炼模块（采用LoRA微调的SegFormer），通过检测引导策略和掩码混合损失提升裂缝区域修复精度，并通过各向异性扩散完成内容重建，实验表明该方法在零样本场景下显著优于现有模型，同时保持原有笔触特征。


<details>
  <summary>Details</summary>
Motivation: 现有绘画修复方法在缺乏像素级标注的情况下难以有效识别和恢复细小的裂纹图案，尤其面对复杂笔触时挑战更大，因此需要一种无需人工标注的高效、精准的非侵入式数字修复方案。

Method: 设计了一个基于贝塞尔曲线的合成裂缝生成器以生成逼真的分支和渐细裂缝；结合经典形态学检测器与使用低秩适应（LoRA）微调的SegFormer作为学习型精炼模块；引入检测引导策略，将形态学图作为空间先验输入；采用掩码混合损失和对数调整机制约束训练过程，聚焦于裂缝区域的优化；最后通过各向异性扩散实现缺失内容的重建。

Result: 所提方法在零样本设置下显著超越现有摄影修复模型，在保持原画笔触的同时实现了高质量的裂缝识别与内容恢复，验证了其有效性与鲁棒性。

Conclusion: 本研究提出了一种完全无标注的绘画裂缝修复框架，通过合成数据驱动与检测引导的学习策略，成功解决了复杂笔触背景下细裂纹恢复难题，为文化遗产数字化保护提供了可推广的技术路径。

Abstract: Cultural heritage preservation increasingly demands non-invasive digital methods for painting restoration, yet identifying and restoring fine craquelure patterns from complex brushstrokes remains challenging due to scarce pixel-level annotations. We propose a fully annotation-free framework driven by a domain-specific synthetic craquelure generator, which simulates realistic branching and tapered fissure geometry using Bézier trajectories. Our approach couples a classical morphological detector with a learning-based refinement module: a SegFormer backbone adapted via Low-Rank Adaptation (LoRA). Uniquely, we employ a detector-guided strategy, injecting the morphological map as an input spatial prior, while a masked hybrid loss and logit adjustment constrain the training to focus specifically on refining candidate crack regions. The refined masks subsequently guide an Anisotropic Diffusion inpainting stage to reconstruct missing content. Experimental results demonstrate that our pipeline significantly outperforms state-of-the-art photographic restoration models in zero-shot settings, while faithfully preserving the original paint brushwork.

</details>


### [27] [Towards reconstructing experimental sparse-view X-ray CT data with diffusion models](https://arxiv.org/abs/2602.12755)
*Nelas J. Thomsen,Xinyuan Wang,Felix Lucka,Ezgi Demircan-Tureyen*

Main category: cs.CV

TL;DR: 该研究探讨了基于扩散模型的图像生成器在稀疏视图X射线计算机断层扫描（CT）等病态逆问题中的应用，重点分析了合成数据与实验数据之间的领域差异（domain shift）和前向模型差异的影响。通过在不同领域偏移程度的合成数据上训练扩散先验，并应用于逐步增加难度的稀疏视图CT数据，发现严重领域偏移会导致模型崩溃和幻觉，而多样化的先验优于匹配但单一的先验；前向模型不匹配会引入伪影，但可通过退火似然调度缓解并提升计算效率。研究强调，合成数据上的性能优势无法直接迁移到真实实验数据，未来工作需在真实世界基准上验证。


<details>
  <summary>Details</summary>
Motivation: 评估基于扩散模型的图像生成器在真实实验数据中对稀疏视图CT逆问题的应用效果，明确领域差异和前向模型差异带来的挑战，以推动其在实际医学成像中的可靠应用。

Method: 使用物理幻影采集真实CT数据，模拟合成的Shepp-Logan幻影数据，训练扩散先验于不同领域偏移程度的合成数据集；采用分解式扩散采样方法在逐步增加难度的稀疏视图数据上进行重建，分析不同条件下重建质量，并引入退火似然调度以缓解前向模型不匹配问题。

Result: 严重领域偏移导致模型崩溃和幻觉；多样化先验优于高度匹配但局限的先验；前向模型不匹配引发伪影，但可通过退火似然调度有效缓解，同时提升计算效率；合成数据上的性能无法直接转化为实验数据表现。

Conclusion: 扩散模型在真实实验数据中的成功应用受限于领域和前向模型的不匹配，性能提升不能自动迁移。未来工作必须在真实世界数据上验证模型，以确保实际可用性。

Abstract: Diffusion-based image generators are promising priors for ill-posed inverse problems like sparse-view X-ray Computed Tomography (CT). As most studies consider synthetic data, it is not clear whether training data mismatch (``domain shift'') or forward model mismatch complicate their successful application to experimental data. We measured CT data from a physical phantom resembling the synthetic Shepp-Logan phantom and trained diffusion priors on synthetic image data sets with different degrees of domain shift towards it. Then, we employed the priors in a Decomposed Diffusion Sampling scheme on sparse-view CT data sets with increasing difficulty leading to the experimental data. Our results reveal that domain shift plays a nuanced role: while severe mismatch causes model collapse and hallucinations, diverse priors outperform well-matched but narrow priors. Forward model mismatch pulls the image samples away from the prior manifold, which causes artifacts but can be mitigated with annealed likelihood schedules that also increase computational efficiency. Overall, we demonstrate that performance gains do not immediately translate from synthetic to experimental data, and future development must validate against real-world benchmarks.

</details>


### [28] [Towards complete digital twins in cultural heritage with ART3mis 3D artifacts annotator](https://arxiv.org/abs/2602.12761)
*Dimitrios Karamatskos,Vasileios Arampatzakis,Vasileios Sevetlidis,Stavros Nousias,Athanasios Kalogeras,Christos Koulamas,Aris Lalos,George Pavlidis*

Main category: cs.CV

TL;DR: 本文介绍了一款名为ART3mis的通用、用户友好、功能丰富的交互式基于Web的3D对象文本注释工具，旨在帮助文化遗产保护者、修复者和策展人轻松处理、分割和注释3D数字复制品。该工具支持元数据标注，并遵循W3C Web注释数据模型，实现信息的通信、分发和重用，具有良好的通用性和互操作性。


<details>
  <summary>Details</summary>
Motivation: 现有3D数字文物注释工具大多局限于特定应用场景，缺乏通用性和互操作性，无法满足考古学家及文化遗产领域专业人士对复杂注释和元数据附加的需求。

Method: 开发并实现ART3mis，一个基于Web的交互式3D文本注释工具，支持在3D模型上进行区域标注与元数据附加，并遵循W3C Web Annotation Data Model以确保信息的可共享与可重用。

Result: ART3mis成功实现了对3D数字文物的便捷注释与管理，尤其适用于非技术背景的文化遗产专业人员，提升了注释效率与数据互通能力。

Conclusion: ART3mis为文化遗产领域的非技术用户提供了一个强大且易用的3D注释解决方案，具备良好的通用性、互操作性与可扩展性，是当前3D数字文物管理的重要补充工具。

Abstract: Archaeologists, as well as specialists and practitioners in cultural heritage, require applications with additional functions, such as the annotation and attachment of metadata to specific regions of the 3D digital artifacts, to go beyond the simplistic three-dimensional (3D) visualization. Different strategies addressed this issue, most of which are excellent in their particular area of application, but their capacity is limited to their design's purpose; they lack generalization and interoperability. This paper introduces ART3mis, a general-purpose, user-friendly, feature-rich, interactive web-based textual annotation tool for 3D objects. Moreover, it enables the communication, distribution, and reuse of information as it complies with the W3C Web Annotation Data Model. It is primarily designed to help cultural heritage conservators, restorers, and curators who lack technical expertise in 3D imaging and graphics, handle, segment, and annotate 3D digital replicas of artifacts with ease.

</details>


### [29] [PixelRush: Ultra-Fast, Training-Free High-Resolution Image Generation via One-step Diffusion](https://arxiv.org/abs/2602.12769)
*Hong-Phuc Lai,Phong Nguyen,Anh Tran*

Main category: cs.CV

TL;DR: PixelRush 是首个无需微调的实用高分辨率文本到图像生成框架，通过高效的基于补丁的去噪方法，在低步数条件下实现4K图像生成，仅需约20秒，相比现有方法提速10至35倍，同时保持优异的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有预训练扩散模型受限于原始训练分辨率，尽管已有无训练方法尝试在去噪过程中干预以提升分辨率，但这些方法计算开销大，生成单张4K图像需超过五分钟，效率低下。因此亟需一种高效且无需微调的方法来实现高质量高分辨率图像生成。

Method: PixelRush 采用基于补丁的推理范式，摒弃了多轮反演与重生成过程，实现低步数下的高效补丁级去噪；提出无缝融合策略以缓解补丁拼接带来的伪影，并引入噪声注入机制以减轻过平滑问题。

Result: PixelRush 能在约20秒内生成4K图像，相较当前最优方法提速10至35倍，同时在视觉质量上表现卓越，实验验证了其性能优势与输出质量。

Conclusion: PixelRush 成功实现了无需微调的高效高分辨率文本到图像生成，兼具速度与质量，为实际应用提供了可行方案。

Abstract: Pre-trained diffusion models excel at generating high-quality images but remain inherently limited by their native training resolution. Recent training-free approaches have attempted to overcome this constraint by introducing interventions during the denoising process; however, these methods incur substantial computational overhead, often requiring more than five minutes to produce a single 4K image. In this paper, we present PixelRush, the first tuning-free framework for practical high-resolution text-to-image generation. Our method builds upon the established patch-based inference paradigm but eliminates the need for multiple inversion and regeneration cycles. Instead, PixelRush enables efficient patch-based denoising within a low-step regime. To address artifacts introduced by patch blending in few-step generation, we propose a seamless blending strategy. Furthermore, we mitigate over-smoothing effects through a noise injection mechanism. PixelRush delivers exceptional efficiency, generating 4K images in approximately 20 seconds representing a 10$\times$ to 35$\times$ speedup over state-of-the-art methods while maintaining superior visual fidelity. Extensive experiments validate both the performance gains and the quality of outputs achieved by our approach.

</details>


### [30] [Bootstrapping MLLM for Weakly-Supervised Class-Agnostic Object Counting](https://arxiv.org/abs/2602.12774)
*Xiaowen Zhang,Zijie Yue,Yong Luo,Cairong Zhao,Qijun Chen,Miaojing Shi*

Main category: cs.CV

TL;DR: 提出首个基于多模态大模型（MLLM）的无监督类无关物体计数框架WS-COC，通过对话引导、排序优化和全局局部融合策略，在仅需图像级计数标签的情况下实现高精度计数，性能媲美甚至超越多个全监督方法，显著降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督计数方法通常局限于单一类别，且依赖昂贵的点级标注；为减少标注成本并实现通用物体计数，亟需一种无需精细标注、可处理多类物体的弱监督框架。

Method: 提出三种策略：1）分而辨析对话微调，通过多轮对话逐步缩小计数范围；2）比对排序优化，训练MLLM根据相对计数顺序对图像进行排序；3）全局与局部计数增强，融合局部区域与整体图像的预测以提升密集场景下的性能。

Result: 在FSC-147、CARPK、PUCPR+和ShanghaiTech等多个数据集上，WS-COC达到或超过多个全监督先进方法的性能，同时大幅降低标注需求。

Conclusion: WS-COC是首个基于MLLM的类无关弱监督计数框架，通过创新的训练策略有效弥合模态差距，实现了高效、低成本且高性能的物体计数，为实际应用提供了可行方案。

Abstract: Object counting is a fundamental task in computer vision, with broad applicability in many real-world scenarios. Fully-supervised counting methods require costly point-level annotations per object. Few weakly-supervised methods leverage only image-level object counts as supervision and achieve fairly promising results. They are, however, often limited to counting a single category, e.g. person. In this paper, we propose WS-COC, the first MLLM-driven weakly-supervised framework for class-agnostic object counting. Instead of directly fine-tuning MLLMs to predict object counts, which can be challenging due to the modality gap, we incorporate three simple yet effective strategies to bootstrap the counting paradigm in both training and testing: First, a divide-and-discern dialogue tuning strategy is proposed to guide the MLLM to determine whether the object count falls within a specific range and progressively break down the range through multi-round dialogue. Second, a compare-and-rank count optimization strategy is introduced to train the MLLM to optimize the relative ranking of multiple images according to their object counts. Third, a global-and-local counting enhancement strategy aggregates and fuses local and global count predictions to improve counting performance in dense scenes. Extensive experiments on FSC-147, CARPK, PUCPR+, and ShanghaiTech show that WS-COC matches or even surpasses many state-of-art fully-supervised methods while significantly reducing annotation costs. Code is available at https://github.com/viscom-tongji/WS-COC.

</details>


### [31] [Thinking Like a Radiologist: A Dataset for Anatomy-Guided Interleaved Vision Language Reasoning in Chest X-ray Interpretation](https://arxiv.org/abs/2602.12843)
*Yichen Zhao,Zelin Peng,Piao Yang,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 本文提出MMRad-IVL-22K，首个专为胸部X光片解读中天然交错的视觉语言推理设计的大规模数据集。该数据集模拟放射科医生反复进行视觉检查与语言推理的过程，通过视觉理由补充文本描述，使每一步推理都有视觉依据。实验表明，基于多模态思维链（CoT）生成的报告在临床准确性和报告质量上显著优于仅依赖文本的CoT方法，且在多个开源医学大模型上微调后表现更优，证明了高保真交错视觉语言证据对可靠医疗AI的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有医学大视觉语言模型（LVLMs）通常只进行一次视觉检查，随后依赖纯文本链式思维（CoT）推理，容易产生幻觉。尽管部分方法引入边界框等视觉坐标以缓解问题，但这些仍属伪视觉方案，无法保留纹理、密度等丰富视觉细节。因此，亟需一种真正实现视觉与语言交替推理的机制，以更贴近真实放射科诊断流程。

Method: 提出MMRad-IVL-22K数据集，包含21,994个诊断轨迹，覆盖35个解剖区域，记录了放射科医生在诊断过程中反复进行视觉观察与语言推理的完整循环过程。每个推理步骤均配有对应的视觉理由，确保语言推理有坚实的视觉基础。利用该数据集对LVLMs进行微调，训练其进行多模态、高保真、交错式的视觉语言推理。

Result: 在闭源先进LVLM上的实验显示，基于多模态CoT的报告生成在临床准确性与报告质量上显著提升，如RadGraph指标提高6%；在七个开源主流LVLM上测试表明，经MMRad-IVL-22K微调的模型在推理一致性与报告质量方面均优于通用及医学专用模型。

Conclusion: 高保真、天然交错的视觉语言推理是构建可靠医疗AI不可或缺的核心组件。MMRad-IVL-22K不仅推动了医学AI向更接近人类诊断逻辑的方向发展，也为未来模型训练提供了高质量基准数据。

Abstract: Radiological diagnosis is a perceptual process in which careful visual inspection and language reasoning are repeatedly interleaved. Most medical large vision language models (LVLMs) perform visual inspection only once and then rely on text-only chain-of-thought (CoT) reasoning, which operates purely in the linguistic space and is prone to hallucination. Recent methods attempt to mitigate this issue by introducing visually related coordinates, such as bounding boxes. However, these remain a pseudo-visual solution: coordinates are still text and fail to preserve rich visual details like texture and density. Motivated by the interleaved nature of radiological diagnosis, we introduce MMRad-IVL-22K, the first large-scale dataset designed for natively interleaved visual language reasoning in chest X-ray interpretation. MMRad-IVL-22K reflects a repeated cycle of reasoning and visual inspection workflow of radiologists, in which visual rationales complement textual descriptions and ground each step of the reasoning process. MMRad-IVL-22K comprises 21,994 diagnostic traces, enabling systematic scanning across 35 anatomical regions. Experimental results on advanced closed-source LVLMs demonstrate that report generation guided by multimodal CoT significantly outperforms that guided by text-only CoT in clinical accuracy and report quality (e.g., 6\% increase in the RadGraph metric), confirming that high-fidelity interleaved vision language evidence is a non-substitutable component of reliable medical AI. Furthermore, benchmarking across seven state-of-the-art open-source LVLMs demonstrates that models fine-tuned on MMRad-IVL-22K achieve superior reasoning consistency and report quality compared with both general-purpose and medical-specific LVLMs. The project page is available at https://github.com/qiuzyc/thinking_like_a_radiologist.

</details>


### [32] [RoadscapesQA: A Multitask, Multimodal Dataset for Visual Question Answering on Indian Roads](https://arxiv.org/abs/2602.12877)
*Vijayasri Iyer,Maahin Rathinagiriswaran,Jyothikamalesh S*

Main category: cs.CV

TL;DR: Roadscapes 是一个包含最多 9,000 张图像的多任务多模态数据集，涵盖多样化的印度驾驶环境，配有手动验证的边界框，并通过规则启发式方法推断场景属性以生成用于目标定位、推理和场景理解的问答对。数据集涵盖城市与农村场景，包括高速公路、服务道路、村庄小路及拥堵城市街道，覆盖昼夜两种设置，旨在推动非结构化环境中视觉场景理解的研究。本文描述了数据收集与标注流程，展示关键统计数据，并为基于视觉-语言模型的图像问答任务提供初步基线。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要准确理解道路场景以支持有效决策，但现有数据集在多样化非结构化环境（尤其是印度）中的覆盖不足，因此亟需一个能支持多任务、多模态场景理解的高质量数据集。

Method: 采用规则启发式方法从图像中推断场景属性，生成问题-答案对；结合人工标注的边界框，构建可用于对象定位、推理和场景理解的多任务数据集。

Result: 成功构建了包含 9,000 张图像、覆盖多种地理与时间条件的 Roadscapes 数据集，并提供了基于视觉-语言模型的图像问答任务初始基线性能。

Conclusion: Roadscapes 为研究复杂、非结构化环境下的视觉场景理解提供了重要资源，有助于推动自动驾驶系统在真实世界中的泛化能力。

Abstract: Understanding road scenes is essential for autonomous driving, as it enables systems to interpret visual surroundings to aid in effective decision-making. We present Roadscapes, a multitask multimodal dataset consisting of upto 9,000 images captured in diverse Indian driving environments, accompanied by manually verified bounding boxes. To facilitate scalable scene understanding, we employ rule-based heuristics to infer various scene attributes, which are subsequently used to generate question-answer (QA) pairs for tasks such as object grounding, reasoning, and scene understanding. The dataset includes a variety of scenes from urban and rural India, encompassing highways, service roads, village paths, and congested city streets, captured in both daytime and nighttime settings. Roadscapes has been curated to advance research on visual scene understanding in unstructured environments. In this paper, we describe the data collection and annotation process, present key dataset statistics, and provide initial baselines for image QA tasks using vision-language models.

</details>


### [33] [RADAR: Revealing Asymmetric Development of Abilities in MLLM Pre-training](https://arxiv.org/abs/2602.12892)
*Yunshuang Nie,Bingqian Lin,Minzhe Niu,Kun Xiang,Jianhua Han,Guowei Huang,Xingyue Quan,Hang Xu,Bokui Chen,Xiaodan Liang*

Main category: cs.CV

TL;DR: RADAR 是一个高效的能力中心评估框架，用于揭示多模态大语言模型（MLLM）预训练过程中能力发展的不对称性。它包含两个核心组件：(1) 软区分得分（Soft Discrimination Score），一种无需微调即可稳健追踪能力发展的新指标，通过量化模型对正确答案相对于干扰项的偏好程度来实现；(2) 多模态混合基准（Multi-Modal Mixture Benchmark），一个超过15,000样本的零样本评估基准，综合评估 MLLM 的感知与推理能力，整合权威数据集并新增数据以弥补现有基准的不足。RADAR 揭示了在数据量、模型规模和预训练策略等不同因素下，感知与推理能力发展的不平衡现象，强调需采用分解视角识别预训练瓶颈，从而指导针对性改进。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 当前 MLLM 预训练缺乏高效的评估框架，难以诊断性能瓶颈。现有方法依赖微调后测试，成本高且耗时；通用预训练指标无法解耦地衡量感知与推理能力；现有基准规模有限或与预训练目标不一致。因此亟需一个高效、全面、无需微调的评估体系。

Method: 提出 RADAR 框架，包括：(1) 软区分得分——基于模型对正确答案与干扰项的偏好差异，量化能力发展水平；(2) 多模态混合基准——融合权威数据集与自建数据，构建大规模（15K+）、零样本、覆盖全面的评估集，支持对感知与推理能力的独立评估。

Result: RADAR 成功揭示了 MLLM 在预训练中感知与推理能力发展的显著不对称性，受数据量、模型规模和预训练策略影响。该框架能高效识别能力瓶颈，为优化提供方向。实验验证其有效性与普适性。

Conclusion: RADAR 提供了一种高效、无须微调的能力评估新范式，有助于深入理解 MLLM 预训练过程中的能力演化规律，推动模型设计与训练策略的精细化优化。其开源实现促进了社区研究发展。

Abstract: Pre-trained Multi-modal Large Language Models (MLLMs) provide a knowledge-rich foundation for post-training by leveraging their inherent perception and reasoning capabilities to solve complex tasks. However, the lack of an efficient evaluation framework impedes the diagnosis of their performance bottlenecks. Current evaluation primarily relies on testing after supervised fine-tuning, which introduces laborious additional training and autoregressive decoding costs. Meanwhile, common pre-training metrics cannot quantify a model's perception and reasoning abilities in a disentangled manner. Furthermore, existing evaluation benchmarks are typically limited in scale or misaligned with pre-training objectives. Thus, we propose RADAR, an efficient ability-centric evaluation framework for Revealing Asymmetric Development of Abilities in MLLM pRe-training. RADAR involves two key components: (1) Soft Discrimination Score, a novel metric for robustly tracking ability development without fine-tuning, based on quantifying nuanced gradations of the model preference for the correct answer over distractors; and (2) Multi-Modal Mixture Benchmark, a new 15K+ sample benchmark for comprehensively evaluating pre-trained MLLMs' perception and reasoning abilities in a 0-shot manner, where we unify authoritative benchmark datasets and carefully collect new datasets, extending the evaluation scope and addressing the critical gaps in current benchmarks. With RADAR, we comprehensively reveal the asymmetric development of perceptual and reasoning capabilities in pretrained MLLMs across diverse factors, including data volume, model size, and pretraining strategy. Our RADAR underscores the need for a decomposed perspective on pre-training ability bottlenecks, informing targeted interventions to advance MLLMs efficiently. Our code is publicly available at https://github.com/Nieysh/RADAR.

</details>


### [34] [Robustness of Object Detection of Autonomous Vehicles in Adverse Weather Conditions](https://arxiv.org/abs/2602.12902)
*Fox Pettersen,Hong Zhu*

Main category: cs.CV

TL;DR: 本文提出一种评估自动驾驶车辆中物体检测模型在恶劣天气条件下的鲁棒性方法，通过数据增强生成模拟不同严重程度的恶劣环境数据，以确定模型失效的最低强度。采用平均首次失效系数（AFFC）衡量鲁棒性，在四种模型和七种天气及光照条件下进行实验，结果显示Faster R-CNN表现最佳（平均AFFC 71.9%），YOLO系列较低（约43%）。该方法还验证了针对恶劣条件训练的增益与过拟合、遗忘现象之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，确保其在各种环境条件下的安全性至关重要。现有方法缺乏对物体检测模型在恶劣天气和光照条件下鲁棒性的系统性评估手段，亟需一种可量化、可比较的评估框架。

Method: 利用七种数据增强操作模拟雾、雨、雪及暗光、强光、眩光、阴影等环境条件，以渐进式强度生成合成数据；通过测试模型在不同强度下的首次失效点，计算平均首次失效系数（AFFC）作为鲁棒性指标。

Result: 实验表明该方法可行、有效且高效；Faster R-CNN在所有条件下表现最优（平均AFFC 71.9%），YOLO系列模型表现较弱（约43%）；针对恶劣条件的合成数据训练虽提升鲁棒性，但存在过训练导致的性能下降（遗忘现象）和收益递减问题。

Conclusion: 所提方法为评估和比较物体检测模型在复杂环境下的鲁棒性提供了可靠工具，同时揭示了针对性训练的潜在局限性，对提升自动驾驶系统安全性具有指导意义。

Abstract: As self-driving technology advances toward widespread adoption, determining safe operational thresholds across varying environmental conditions becomes critical for public safety. This paper proposes a method for evaluating the robustness of object detection ML models in autonomous vehicles under adverse weather conditions. It employs data augmentation operators to generate synthetic data that simulates different severance degrees of the adverse operation conditions at progressive intensity levels to find the lowest intensity of the adverse conditions at which the object detection model fails. The robustness of the object detection model is measured by the average first failure coefficients (AFFC) over the input images in the benchmark. The paper reports an experiment with four object detection models: YOLOv5s, YOLOv11s, Faster R-CNN, and Detectron2, utilising seven data augmentation operators that simulate weather conditions fog, rain, and snow, and lighting conditions of dark, bright, flaring, and shadow. The experiment data show that the method is feasible, effective, and efficient to evaluate and compare the robustness of object detection models in various adverse operation conditions. In particular, the Faster R-CNN model achieved the highest robustness with an overall average AFFC of 71.9% over all seven adverse conditions, while YOLO variants showed the AFFC values of 43%. The method is also applied to assess the impact of model training that targets adverse operation conditions using synthetic data on model robustness. It is observed that such training can improve robustness in adverse conditions but may suffer from diminishing returns and forgetting phenomena (i.e., decline in robustness) if overtrained.

</details>


### [35] [Reliable Thinking with Images](https://arxiv.org/abs/2602.12916)
*Haobin Li,Yutong Yang,Yijie Lin,Dai Xiang,Mouxing Yang,Xi Peng*

Main category: cs.CV

TL;DR: 本文研究了多模态思维链（TWI）中的噪声思维（NT）问题，即视觉线索提取和推理过程不完美导致的错误累积。为此提出可靠图像思维（RTWI）方法，通过统一的文本中心方式评估视觉线索与文本推理的可靠性，并利用鲁棒过滤和投票模块防止错误污染最终答案。在七个基准上的实验验证了RTWI的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有TWI方法依赖于完美的交错图文思维链假设，但在现实场景中由于多模态理解复杂性，该假设常被破坏，导致错误累积，影响MLLM性能。因此需要解决实际中普遍存在的噪声思维问题。

Method: 提出RTWI方法，采用文本中心框架评估视觉线索和文本推理的可靠性，结合鲁棒过滤与投票机制，有效抑制噪声思维对最终答案的负面影响。

Result: 在七个不同基准测试中，RTWI显著提升了MLLM在存在噪声思维情况下的推理准确率，证明了其有效性与鲁棒性。

Conclusion: NT是制约TWI实际应用的关键挑战，而RTWI通过可靠性评估与噪声过滤机制，能够有效缓解该问题，为提升MLLM在真实场景中的推理能力提供了新思路。

Abstract: As a multimodal extension of Chain-of-Thought (CoT), Thinking with Images (TWI) has recently emerged as a promising avenue to enhance the reasoning capability of Multi-modal Large Language Models (MLLMs), which generates interleaved CoT by incorporating visual cues into the textual reasoning process. However, the success of existing TWI methods heavily relies on the assumption that interleaved image-text CoTs are faultless, which is easily violated in real-world scenarios due to the complexity of multimodal understanding. In this paper, we reveal and study a highly-practical yet under-explored problem in TWI, termed Noisy Thinking (NT). Specifically, NT refers to the imperfect visual cues mining and answer reasoning process. As the saying goes, ``One mistake leads to another'', erroneous interleaved CoT would cause error accumulation, thus significantly degrading the performance of MLLMs. To solve the NT problem, we propose a novel method dubbed Reliable Thinking with Images (RTWI). In brief, RTWI estimates the reliability of visual cues and textual CoT in a unified text-centric manner and accordingly employs robust filtering and voting modules to prevent NT from contaminating the final answer. Extensive experiments on seven benchmarks verify the effectiveness of RTWI against NT.

</details>


### [36] [EPRBench: A High-Quality Benchmark Dataset for Event Stream Based Visual Place Recognition](https://arxiv.org/abs/2602.12919)
*Xiao Wang,Xingxing Xiong,Jinfeng Gao,Xufeng Lou,Bo Jiang,Si-bao Chen,Yaowei Wang,Yonghong Tian*

Main category: cs.CV

TL;DR: 提出EPRBench基准数据集，包含10K事件序列和65K事件帧，支持手持与车载场景，涵盖多种视角、天气和光照条件；结合LLM生成与人工标注的场景描述，推动语义感知与语言融合的事件流视觉定位研究；在该数据集上评估15种先进VPR算法，并提出一种基于LLM引导的多模态融合框架，实现高精度识别与可解释性推理。


<details>
  <summary>Details</summary>
Motivation: 现有事件流视觉定位研究缺乏专用高质量数据集，且对语义理解与模型可解释性支持不足，难以应对复杂现实场景挑战。

Method: 构建EPRBench数据集，采集真实世界多条件事件流数据；利用大语言模型生成场景描述并经人工修正；评估15种主流VPR方法；提出基于LLM生成文本引导的空间注意力选择、跨模态特征融合与多尺度表征学习的多模态融合框架。

Result: EPRBench为事件流VPR提供首个全面基准；所提多模态框架在准确率与可解释性方面均显著优于现有方法；验证了语言信息在事件流感知中的有效性。

Conclusion: EPRBench作为首个面向事件流视觉定位的综合性基准，有效推动了该领域的发展；提出的多模态融合方法不仅提升了识别性能，还实现了透明、可解释的推理过程，为未来神经形态感知系统的设计提供了新范式。

Abstract: Event stream-based Visual Place Recognition (VPR) is an emerging research direction that offers a compelling solution to the instability of conventional visible-light cameras under challenging conditions such as low illumination, overexposure, and high-speed motion. Recognizing the current scarcity of dedicated datasets in this domain, we introduce EPRBench, a high-quality benchmark specifically designed for event stream-based VPR. EPRBench comprises 10K event sequences and 65K event frames, collected using both handheld and vehicle-mounted setups to comprehensively capture real-world challenges across diverse viewpoints, weather conditions, and lighting scenarios. To support semantic-aware and language-integrated VPR research, we provide LLM-generated scene descriptions, subsequently refined through human annotation, establishing a solid foundation for integrating LLMs into event-based perception pipelines. To facilitate systematic evaluation, we implement and benchmark 15 state-of-the-art VPR algorithms on EPRBench, offering a strong baseline for future algorithmic comparisons. Furthermore, we propose a novel multi-modal fusion paradigm for VPR: leveraging LLMs to generate textual scene descriptions from raw event streams, which then guide spatially attentive token selection, cross-modal feature fusion, and multi-scale representation learning. This framework not only achieves highly accurate place recognition but also produces interpretable reasoning processes alongside its predictions, significantly enhancing model transparency and explainability. The dataset and source code will be released on https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [37] [Deep-Learning Atlas Registration for Melanoma Brain Metastases: Preserving Pathology While Enabling Cohort-Level Analyses](https://arxiv.org/abs/2602.12933)
*Nanna E. Wielenberg,Ilinca Popp,Oliver Blanck,Lucas Zander,Jan C. Peeken,Stephanie E. Combs,Anca-Ligia Grosu,Dimos Baltas,Tobias Fechter*

Main category: cs.CV

TL;DR: 本文提出一种全可微分的深度学习变形配准框架，用于将个体病理脑影像对齐至共同模板，无需病变掩膜或预处理。通过基于距离变换解剖标签的前向模型相似性度量和体积保持正则化项，有效处理因转移灶导致的解剖对应缺失问题。在209例来自三个中心的黑色素瘤脑转移患者中验证，该方法在不同数据集上均表现出高配准精度（DSC 0.89-0.92，HD 6.79-7.60 mm，ASSD 0.63-0.77 mm），并成功保留转移病灶体积。空间分析显示转移灶显著富集于皮层和尾状核，白质中较少，且集中于灰质-白质交界处；经体积校正后，无特定动脉供血区呈现更高转移率。该方法支持多中心、可重复的标准化分析，已公开实现，便于扩展至其他脑肿瘤及神经系统疾病研究。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤脑转移（MBM）具有空间异质性，传统分析受限于解剖变异和MRI扫描协议差异，缺乏统一的配准方法，尤其在不依赖病变掩膜的情况下难以实现精准对齐。因此亟需一种无需预处理或病变标注即可准确配准病理脑影像的方法，以支持多中心、可重复的研究。

Method: 提出一种全可微分的深度学习变形配准框架，采用距离变换的解剖标签构建前向模型相似性度量，结合体积保持正则化项，解决因转移灶导致的解剖对应缺失问题，实现无需病变掩膜的精准配准。

Result: 在209例患者中，方法达到高配准精度（DSC 0.89–0.92，HD 6.79–7.60 mm，ASSD 0.63–0.77 mm），有效保留转移病灶体积。空间分析证实转移灶偏好位于皮层、尾状核及灰质-白质交界处，白质中较少；经体积校正后，无特定动脉供血区存在更高转移倾向。

Conclusion: 该框架实现了无需病变掩膜的病理脑影像稳健配准，支持多中心标准化分析，为黑色素瘤脑转移的空间分布研究提供了可靠工具，并可推广至其他脑肿瘤与神经系统疾病研究。

Abstract: Melanoma brain metastases (MBM) are common and spatially heterogeneous lesions, complicating cohort-level analyses due to anatomical variability and differing MRI protocols. We propose a fully differentiable, deep-learning-based deformable registration framework that aligns individual pathological brains to a common atlas while preserving metastatic tissue without requiring lesion masks or preprocessing.
  Missing anatomical correspondences caused by metastases are handled through a forward-model similarity metric based on distance-transformed anatomical labels, combined with a volume-preserving regularization term to ensure deformation plausibility. Registration performance was evaluated using Dice coefficient (DSC), Hausdorff distance (HD), average symmetric surface distance (ASSD), and Jacobian-based measures. The method was applied to 209 MBM patients from three centres, enabling standardized mapping of metastases to anatomical, arterial, and perfusion atlases.
  The framework achieved high registration accuracy across datasets (DSC 0.89-0.92, HD 6.79-7.60 mm, ASSD 0.63-0.77 mm) while preserving metastatic volumes. Spatial analysis demonstrated significant over-representation of MBM in the cerebral cortex and putamen, under-representation in white matter, and consistent localization near the gray-white matter junction. No arterial territory showed increased metastasis frequency after volume correction.
  This approach enables robust atlas registration of pathological brain MRI without lesion masks and supports reproducible multi-centre analyses. Applied to MBM, it confirms and refines known spatial predilections, particularly preferential seeding near the gray-white matter junction and cortical regions. The publicly available implementation facilitates reproducible research and extension to other brain tumours and neurological pathologies.

</details>


### [38] [Human-Aligned MLLM Judges for Fine-Grained Image Editing Evaluation: A Benchmark, Framework, and Analysis](https://arxiv.org/abs/2602.13028)
*Runzhou Liu,Hailey Weingord,Sejal Mittal,Prakhar Dungarwal,Anusha Nandula,Bo Ni,Samyadeep Basu,Hongjie Chen,Nesreen K. Ahmed,Li Li,Jiayi Zhang,Koustava Goswami,Subhojyoti Mukherjee,Branislav Kveton,Puneet Mathur,Franck Dernoncourt,Yue Zhao,Yu Wang,Ryan A. Rossi,Zhengzhong Tu,Hongru Du*

Main category: cs.CV

TL;DR: 本文提出一种基于多模态大语言模型（MLLM）的细粒度评估框架，用于图像编辑模型的评价。该框架将评估标准分解为12个细粒度、可解释的维度，涵盖图像保真度、编辑质量与指令一致性等。研究构建了一个结合人类判断、MLLM评估、模型输出和传统指标的新型基准测试，并通过大规模人类实验验证了MLLM评委在细粒度层面与人类评价高度一致，具备可靠性和可扩展性。结果表明，传统指标无法有效区分过度编辑或语义不准确的结果，而该框架能提供更直观、更有信息量的评估，适用于离线与在线场景。


<details>
  <summary>Details</summary>
Motivation: 传统图像编辑评估指标存在粒度粗、可解释性差的问题，难以捕捉人类感知与用户意图，常奖励视觉上合理但缺乏可控性、定位精度和指令忠实性的输出，亟需更精细、可靠的评估方法。

Method: 提出一个基于MLLM的细粒度评估框架，将常见评估概念分解为12个可解释因素；构建融合人类判断、MLLM评估、模型输出和传统指标的多源基准；通过大量人类实验验证MLLM评委与人类评价的一致性。

Result: MLLM评委在细粒度评估中与人类评价高度一致，具备可靠性与可扩展性；传统指标在区分过编辑或语义模糊输出方面表现不佳；新框架提供了更直观、更具信息量的评估方式，适用于多种应用场景。

Conclusion: 细粒度的MLLM评委可作为图像编辑研究中可靠、可扩展的评估基础，推动模型比较与改进，为未来图像编辑评估提供系统化、以人为本的范式。

Abstract: Evaluating image editing models remains challenging due to the coarse granularity and limited interpretability of traditional metrics, which often fail to capture aspects important to human perception and intent. Such metrics frequently reward visually plausible outputs while overlooking controllability, edit localization, and faithfulness to user instructions. In this work, we introduce a fine-grained Multimodal Large Language Model (MLLM)-as-a-Judge framework for image editing that decomposes common evaluation notions into twelve fine-grained interpretable factors spanning image preservation, edit quality, and instruction fidelity. Building on this formulation, we present a new human-validated benchmark that integrates human judgments, MLLM-based evaluations, model outputs, and traditional metrics across diverse image editing tasks. Through extensive human studies, we show that the proposed MLLM judges align closely with human evaluations at a fine granularity, supporting their use as reliable and scalable evaluators. We further demonstrate that traditional image editing metrics are often poor proxies for these factors, failing to distinguish over-edited or semantically imprecise outputs, whereas our judges provide more intuitive and informative assessments in both offline and online settings. Together, this work introduces a benchmark, a principled factorization, and empirical evidence positioning fine-grained MLLM judges as a practical foundation for studying, comparing, and improving image editing approaches.

</details>


### [39] [Unleashing MLLMs on the Edge: A Unified Framework for Cross-Modal ReID via Adaptive SVD Distillation](https://arxiv.org/abs/2602.12936)
*Hongbo Jiang,Jie Li,Xinqi Cai,Tianyu Xie,Yunhang Shen,Pingyang Dai,Liujuan Cao*

Main category: cs.CV

TL;DR: 提出 MLLMEmbed-ReID 框架，通过适配多模态大模型（MLLM）实现云-边统一的跨模态重识别（CM-ReID），解决现有方法在端到端建模与边缘部署知识蒸馏方面的不足。采用指令提示引导生成统一嵌入空间，并结合层次化低秩微调（LoRA-SFT）提升训练效率；设计基于主成分映射与特征关系保持的新型蒸馏策略，使轻量级边缘模型在多个基准上达到领先性能，同时云端模型全面超越现有水平。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态重识别（CM-ReID）系统依赖分散的专用云模型，难以统一管理；虽多模态大模型（MLLM）具备整合潜力，但缺乏端到端统一架构及高效的边缘知识蒸馏机制，制约其在资源受限设备上的部署。

Method: 1. 将基础MLLM改造为高性能云模型，利用指令提示引导生成RGB、红外、草图和文本等多模态统一嵌入空间；2. 采用层次化低秩微调（LoRA-SFT）策略，在整体跨模态对齐目标下高效训练；3. 提出新型知识蒸馏方法：基于教师模型特征空间的低秩特性，使用主成分映射损失保留关键信息，特征关系损失保持模态间结构。

Result: 所提框架在多个视觉跨模态重识别基准上，轻量化边缘模型达到当前最优性能；云端模型在所有基准上均表现卓越；整体实现从云端到边缘的完整、高效、统一部署方案。

Conclusion: MLLMEmbed-ReID成功构建了一个基于多模态大模型的统一云-边协同框架，实现了跨模态重识别任务中从高能力云端模型到轻量边缘设备的知识迁移与性能保障，为资源受限环境下的智能部署提供了有效解决方案。

Abstract: Practical cloud-edge deployment of Cross-Modal Re-identification (CM-ReID) faces challenges due to maintaining a fragmented ecosystem of specialized cloud models for diverse modalities. While Multi-Modal Large Language Models (MLLMs) offer strong unification potential, existing approaches fail to adapt them into a single end-to-end backbone and lack effective knowledge distillation strategies for edge deployment. To address these limitations, we propose MLLMEmbed-ReID, a unified framework based on a powerful cloud-edge architecture. First, we adapt a foundational MLLM into a state-of-the-art cloud model. We leverage instruction-based prompting to guide the MLLM in generating a unified embedding space across RGB, infrared, sketch, and text modalities. This model is then trained efficiently with a hierarchical Low-Rank Adaptation finetuning (LoRA-SFT) strategy, optimized under a holistic cross-modal alignment objective. Second, to deploy its knowledge onto an edge-native student, we introduce a novel distillation strategy motivated by the low-rank property in the teacher's feature space. To prioritize essential information, this method employs a Principal Component Mapping loss, while relational structures are preserved via a Feature Relation loss. Our lightweight edge-based model achieves state-of-the-art performance on multiple visual CM-ReID benchmarks, while its cloud-based counterpart excels across all CM-ReID benchmarks. The MLLMEmbed-ReID framework thus presents a complete and effective solution for deploying unified MLLM-level intelligence on resource-constrained devices. The code and models will be open-sourced soon.

</details>


### [40] [Training-Free Acceleration for Document Parsing Vision-Language Model with Hierarchical Speculative Decoding](https://arxiv.org/abs/2602.12957)
*Wenhui Liao,Hongliang Li,Pengyu Xie,Xinyu Cai,Yufan Shen,Yi Xin,Qi Qin,Shenglong Ye,Tianbin Li,Ming Hu,Junjun He,Yihao Liu,Wenhai Wang,Min Dou,Bin Fu,Botian Shi,Yu Qiao,Lianwen Jin*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的高效加速方法，用于提升基于视觉语言模型（VLM）的文档解析任务的推理速度。受推测解码启发，该方法利用轻量级文档解析流水线作为草稿模型，预测未来一批令牌，再由更准确的VLM并行验证这些预测。同时，利用文档布局结构将每页划分为独立区域，实现各区域的并行解码，最后按自然阅读顺序整合结果。实验表明，在OmniDocBench上，该方法对dots.ocr模型实现了2.42倍的无损加速，长文档任务最高达4.89倍加速，且代码将公开以促进复现与研究。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的端到端文档解析方法在处理长文档时存在严重的推理延迟问题，因需自回归生成长序列令牌。为解决此问题，本文旨在提出一种无需训练、高效的加速方案，充分利用文档的长输出特性和复杂布局结构。

Method: 采用推测解码思想，使用轻量级文档解析流水线作为草稿模型，预测未来令牌；再由主VLM并行验证预测结果；同时将页面按布局结构划分为独立区域，实现区域间的并行解码，最终按阅读顺序合并输出。

Result: 在OmniDocBench基准上，对dots.ocr模型实现2.42倍无损加速；在长文档解析任务中，最高可达4.89倍加速，显著提升推理效率而不损失精度。

Conclusion: 所提方法在不依赖额外训练的前提下，有效解决了基于VLM的文档解析中的高延迟问题，通过草稿-验证机制与布局分区策略实现高效并行解码，具有良好的实用价值和推广潜力。

Abstract: Document parsing is a fundamental task in multimodal understanding, supporting a wide range of downstream applications such as information extraction and intelligent document analysis. Benefiting from strong semantic modeling and robust generalization, VLM-based end-to-end approaches have emerged as the mainstream paradigm in recent years. However, these models often suffer from substantial inference latency, as they must auto-regressively generate long token sequences when processing long-form documents. In this work, motivated by the extremely long outputs and complex layout structures commonly found in document parsing, we propose a training-free and highly efficient acceleration method. Inspired by speculative decoding, we employ a lightweight document parsing pipeline as a draft model to predict batches of future tokens, while the more accurate VLM verifies these draft predictions in parallel. Moreover, we further exploit the layout-structured nature of documents by partitioning each page into independent regions, enabling parallel decoding of each region using the same draft-verify strategy. The final predictions are then assembled according to the natural reading order. Experimental results demonstrate the effectiveness of our approach: on the general-purpose OmniDocBench, our method provides a 2.42x lossless acceleration for the dots.ocr model, and achieves up to 4.89x acceleration on long-document parsing tasks. We will release our code to facilitate reproducibility and future research.

</details>


### [41] [Detecting Object Tracking Failure via Sequential Hypothesis Testing](https://arxiv.org/abs/2602.12983)
*Alejandro Monroy Muñoz,Rajeev Verma,Alexander Timans*

Main category: cs.CV

TL;DR: 本文提出将目标跟踪视为序列假设检验，利用e-process方法实时检测跟踪失败，确保误报率可控，具有轻量计算、无需额外训练、模型无关等优势，并在多个基准上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪系统缺乏正式的安全保证，仅依赖启发式置信度指标，无法可靠判断跟踪是否成功，存在误报或漏报风险。

Method: 将物体跟踪建模为序列假设检验，使用e-process进行持续证据累积，以检测跟踪失败；提出了基于真值和仅依赖内部跟踪信息的监督与无监督变体。

Result: 所提方法能快速识别跟踪失败，有效控制误报率，在多个视频基准上对两种主流跟踪模型均表现出色，且计算开销小、无需额外训练。

Conclusion: 序列检验可为实时跟踪系统提供统计上合理且高效的安全部署机制，显著提升系统的可靠性与安全性。

Abstract: Real-time online object tracking in videos constitutes a core task in computer vision, with wide-ranging applications including video surveillance, motion capture, and robotics. Deployed tracking systems usually lack formal safety assurances to convey when tracking is reliable and when it may fail, at best relying on heuristic measures of model confidence to raise alerts. To obtain such assurances we propose interpreting object tracking as a sequential hypothesis test, wherein evidence for or against tracking failures is gradually accumulated over time. Leveraging recent advancements in the field, our sequential test (formalized as an e-process) quickly identifies when tracking failures set in whilst provably containing false alerts at a desired rate, and thus limiting potentially costly re-calibration or intervention steps. The approach is computationally light-weight, requires no extra training or fine-tuning, and is in principle model-agnostic. We propose both supervised and unsupervised variants by leveraging either ground-truth or solely internal tracking information, and demonstrate its effectiveness for two established tracking models across four video benchmarks. As such, sequential testing can offer a statistically grounded and efficient mechanism to incorporate safety assurances into real-time tracking systems.

</details>


### [42] [MASAR: Motion-Appearance Synergy Refinement for Joint Detection and Trajectory Forecasting](https://arxiv.org/abs/2602.13003)
*Mohammed Amine Bencheikh Lehocine,Julian Schmidt,Frank Moosmann,Dikshant Gupta,Fabian Flohr*

Main category: cs.CV

TL;DR: MASAR is a novel, fully differentiable framework for joint 3D detection and trajectory forecasting that leverages both appearance and motion cues through an object-centric spatio-temporal mechanism. It improves long-term trajectory prediction by using past trajectory predictions guided by appearance features, achieving over 20% improvement in minADE and minFDE on the nuScenes dataset while maintaining strong detection performance.


<details>
  <summary>Details</summary>
Motivation: Classical autonomous driving systems use hand-crafted bounding-box interfaces between perception and prediction modules, which limit information flow and propagate errors. Existing end-to-end models often fail to effectively utilize the synergy between appearance and motion cues, relying heavily on short-term visual features.

Method: MASAR introduces an object-centric spatio-temporal mechanism that jointly encodes appearance and motion features. It predicts past trajectories and refines them using appearance-based guidance to capture long-term temporal dependencies, enabling better future trajectory forecasting.

Result: Experiments on the nuScenes dataset show MASAR achieves over 20% improvement in minADE and minFDE metrics while maintaining robust 3D detection performance.

Conclusion: MASAR effectively enhances trajectory forecasting by leveraging long-term temporal dependencies through joint modeling of appearance and motion, demonstrating superior performance in end-to-end autonomous driving tasks.

Abstract: Classical autonomous driving systems connect perception and prediction modules via hand-crafted bounding-box interfaces, limiting information flow and propagating errors to downstream tasks. Recent research aims to develop end-to-end models that jointly address perception and prediction; however, they often fail to fully exploit the synergy between appearance and motion cues, relying mainly on short-term visual features. We follow the idea of "looking backward to look forward", and propose MASAR, a novel fully differentiable framework for joint 3D detection and trajectory forecasting compatible with any transformer-based 3D detector. MASAR employs an object-centric spatio-temporal mechanism that jointly encodes appearance and motion features. By predicting past trajectories and refining them using guidance from appearance cues, MASAR captures long-term temporal dependencies that enhance future trajectory forecasting. Experiments conducted on the nuScenes dataset demonstrate MASAR's effectiveness, showing improvements of over 20% in minADE and minFDE while maintaining robust detection performance. Code and models are available at https://github.com/aminmed/MASAR.

</details>


### [43] [Towards Universal Video MLLMs with Attribute-Structured and Quality-Verified Instructions](https://arxiv.org/abs/2602.13013)
*Yunheng Li,Hengrui Zhang,Meng-Hao Guo,Wenzhao Gao,Shaoyong Jia,Shaohui Jiao,Qibin Hou,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出ASID-1M、ASID-Verify和ASID-Captioner，构建大规模细粒度音视频指令数据集与训练框架，显著提升视频理解模型在细粒度描述、减少幻觉和指令遵循方面的性能，达到开源模型领先水平并媲美Gemini-3-Pro。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型受限于缺乏精细组织和可靠标注的视频指令数据，难以有效建模复杂多模态内容中的细粒度信息。

Method: 构建ASID-1M百万级结构化细粒度音视频指令数据集，设计ASID-Verify数据清洗与验证流程确保语义与时间一致性，并基于此训练ASID-Captioner模型，采用监督微调（SFT）方法优化性能。

Result: 在七个基准测试中，ASID-Captioner在音视频描述、属性级描述、基于描述的问题回答及时间定位任务上均表现优异，提升了细粒度描述质量，减少了幻觉，增强了指令遵循能力，成为当前开源模型中的最佳表现者，并可与Gemini-3-Pro竞争。

Conclusion: 通过构建高质量、结构化的音视频指令数据集与相应的训练框架，本研究显著推动了通用视频理解的发展，为未来多模态模型提供了可扩展的数据与方法基础。

Abstract: Universal video understanding requires modeling fine-grained visual and audio information over time in diverse real-world scenarios. However, the performance of existing models is primarily constrained by video-instruction data that represents complex audiovisual content as single, incomplete descriptions, lacking fine-grained organization and reliable annotation. To address this, we introduce: (i) ASID-1M, an open-source collection of one million structured, fine-grained audiovisual instruction annotations with single- and multi-attribute supervision; (ii) ASID-Verify, a scalable data curation pipeline for annotation, with automatic verification and refinement that enforces semantic and temporal consistency between descriptions and the corresponding audiovisual content; and (iii) ASID-Captioner, a video understanding model trained via Supervised Fine-Tuning (SFT) on the ASID-1M. Experiments across seven benchmarks covering audiovisual captioning, attribute-wise captioning, caption-based QA, and caption-based temporal grounding show that ASID-Captioner improves fine-grained caption quality while reducing hallucinations and improving instruction following. It achieves state-of-the-art performance among open-source models and is competitive with Gemini-3-Pro.

</details>


### [44] [Multimodal Classification via Total Correlation Maximization](https://arxiv.org/abs/2602.13015)
*Feng Yu,Xiangyu Wu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: 本文提出TCMax方法，通过最大化多模态特征与标签之间的总相关性来缓解模态竞争问题，利用基于MINE的总相关性神经估计（TCNE）实现变分下界优化，无需超参数调整，在多模态分类任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有联合学习方法常过度拟合某些模态而忽略其他模态，导致性能低于单模态学习；尽管已有工作尝试平衡模态贡献或结合联合与单模态学习，但缺乏从信息论角度对联合与单模态学习关系的深入分析。

Method: 提出基于信息论的总相关性最大化方法，引入总相关性神经估计（TCNE），设计无需超参数的TCMax损失函数，通过变分下界优化实现特征对齐和模态间交互建模。

Result: 在多个数据集上的实验表明，TCMax显著优于当前最先进的联合与单模态学习方法，有效缓解了模态竞争并提升了分类性能。

Conclusion: TCMax通过最大化多模态特征与标签间的总相关性，实现了更均衡的模态融合，为多模态学习提供了一种理论驱动且高效的解决方案。

Abstract: Multimodal learning integrates data from diverse sensors to effectively harness information from different modalities. However, recent studies reveal that joint learning often overfits certain modalities while neglecting others, leading to performance inferior to that of unimodal learning. Although previous efforts have sought to balance modal contributions or combine joint and unimodal learning, thereby mitigating the degradation of weaker modalities with promising outcomes, few have examined the relationship between joint and unimodal learning from an information-theoretic perspective. In this paper, we theoretically analyze modality competition and propose a method for multimodal classification by maximizing the total correlation between multimodal features and labels. By maximizing this objective, our approach alleviates modality competition while capturing inter-modal interactions via feature alignment. Building on Mutual Information Neural Estimation (MINE), we introduce Total Correlation Neural Estimation (TCNE) to derive a lower bound for total correlation. Subsequently, we present TCMax, a hyperparameter-free loss function that maximizes total correlation through variational bound optimization. Extensive experiments demonstrate that TCMax outperforms state-of-the-art joint and unimodal learning approaches. Our code is available at https://github.com/hubaak/TCMax.

</details>


### [45] [CoPE-VideoLM: Codec Primitives For Efficient Video Language Models](https://arxiv.org/abs/2602.13191)
*Sayan Deb Sarkar,Rémi Pautrat,Ondrej Miksik,Marc Pollefeys,Iro Armeni,Mahdi Rad,Mihai Dusmanu*

Main category: cs.CV

TL;DR: 本文提出利用视频编解码器原语（如运动矢量和残差）来提升视频语言模型（VideoLMs）的效率与性能，避免传统关键帧采样导致的信息丢失和全图像编码带来的计算开销。通过轻量级Transformer编码器聚合编解码器特征，并采用预训练策略加速端到端微调收敛。实验表明，该方法可将首次生成时间降低86%，令牌使用量减少93%，并在14个多样化视频理解基准上保持或超越现有性能。


<details>
  <summary>Details</summary>
Motivation: 现有VideoLM方法受限于最大上下文窗口，依赖关键帧采样导致宏观事件和微观细节遗漏，且全帧图像及对应令牌处理带来高计算开销。

Method: 利用视频编解码器中的运动矢量和残差等原语，设计轻量级Transformer编码器聚合这些稀疏、冗余编码信息，并通过预训练策略对齐图像编码器嵌入，实现高效视频表示学习。

Result: 相比标准VideoLM，首次生成时间减少86%，令牌使用量降低93%；在14个不同任务（包括问答、时序推理、长视频理解、空间场景理解）中表现相当或更优。

Conclusion: 基于视频编解码器原语的方法能够有效降低计算成本并保留丰富时空信息，在多种视频理解任务中展现出卓越的效率与性能。

Abstract: Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their representations with image encoder embeddings through a pre-training strategy that accelerates convergence during end-to-end fine-tuning. Our approach reduces the time-to-first-token by up to $86\%$ and token usage by up to $93\%$ compared to standard VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on $14$ diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, and spatial scene understanding.

</details>


### [46] [DynaGuide: A Generalizable Dynamic Guidance Framework for Unsupervised Semantic Segmentation](https://arxiv.org/abs/2602.13020)
*Boujemaa Guermazi,Riadh Ksantini,Naimul Khan*

Main category: cs.CV

TL;DR: DynaGuide 是一种无监督图像分割框架，通过结合全局伪标签与局部边界细化，实现高精度分割。其创新的双引导策略和动态损失优化机制，使模型在无需目标域真实标签的情况下，显著提升分割性能，在多个基准数据集上达到领先效果。


<details>
  <summary>Details</summary>
Motivation: 现有无监督图像分割方法难以兼顾全局语义结构与细粒度边界精度，尤其在缺乏标注数据的场景下表现受限。因此需要一种能有效融合全局语义与局部细节、自适应优化且无需人工标注的新方法。

Method: DynaGuide 采用双引导策略：利用零样本模型（如 DiffSeg 或 SegFormer）生成全局伪标签，并通过一个从头训练的轻量级 CNN 进行局部边界精修。同时引入多组件动态损失函数，平衡特征相似性、平滑的空间连续性（含对角关系）以及与全局伪标签的语义一致性。整个过程完全不依赖目标域真值标签，支持多种引导源的即插即用。

Result: 在 BSD500、PASCAL VOC2012 和 COCO 数据集上的实验表明，DynaGuide 分别提升了 17.5%、3.1% 和 11.66% 的 mIoU，达到当前最优水平。模型具有良好的泛化能力、模块化设计和低计算开销，适用于实际应用场景。

Conclusion: DynaGuide 提出了一种高效、可扩展的无监督图像分割新范式，通过动态双引导机制实现了全局语义与局部细节的协同优化，在无需标注的前提下显著提升分割质量，为真实世界应用提供了实用解决方案。

Abstract: Unsupervised image segmentation is a critical task in computer vision. It enables dense scene understanding without human annotations, which is especially valuable in domains where labelled data is scarce. However, existing methods often struggle to reconcile global semantic structure with fine-grained boundary accuracy. This paper introduces DynaGuide, an adaptive segmentation framework that addresses these challenges through a novel dual-guidance strategy and dynamic loss optimization. Building on our previous work, DynaSeg, DynaGuide combines global pseudo-labels from zero-shot models such as DiffSeg or SegFormer with local boundary refinement using a lightweight CNN trained from scratch. This synergy allows the model to correct coarse or noisy global predictions and produce high-precision segmentations. At the heart of DynaGuide is a multi-component loss that dynamically balances feature similarity, Huber-smoothed spatial continuity, including diagonal relationships, and semantic alignment with the global pseudo-labels. Unlike prior approaches, DynaGuide trains entirely without ground-truth labels in the target domain and supports plug-and-play integration of diverse guidance sources. Extensive experiments on BSD500, PASCAL VOC2012, and COCO demonstrate that DynaGuide achieves state-of-the-art performance, improving mIoU by 17.5% on BSD500, 3.1% on PASCAL VOC2012, and 11.66% on COCO. With its modular design, strong generalization, and minimal computational footprint, DynaGuide offers a scalable and practical solution for unsupervised segmentation in real-world settings. Code available at: https://github.com/RyersonMultimediaLab/DynaGuide

</details>


### [47] [Learning Image-based Tree Crown Segmentation from Enhanced Lidar-based Pseudo-labels](https://arxiv.org/abs/2602.13022)
*Julius Pesonen,Stefan Rua,Josef Taher,Niko Koivumäki,Xiaowei Yu,Eija Honkavaara*

Main category: cs.CV

TL;DR: 本研究提出一种利用机载激光扫描（ALS）数据生成伪标签，结合零样本实例分割模型SAM 2增强标签，训练深度学习模型以实现RGB和多光谱影像中个体树冠的自动分割与分离。该方法无需人工标注，显著提升了模型在特定领域任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 自动从航拍图像中分离个体树冠面临纹理复杂和树冠部分重叠等挑战，传统方法依赖人工标注，成本高且效率低。因此需要一种低成本、高效的标注方式来提升模型性能。

Method: 利用ALS数据生成伪标签，并通过SAM 2模型对伪标签进行增强，进而训练光学影像分割模型，实现无需人工标注的高效训练。

Result: 所提方法生成的模型在个体树冠分割任务上优于现有通用领域部署模型，实现了高性能且无手动标注成本的解决方案。

Conclusion: 基于ALS伪标签与SAM 2增强的深度学习方法，为光学影像中的个体树冠分割提供了高效、低成本且高性能的解决方案，具有广泛的应用前景。

Abstract: Mapping individual tree crowns is essential for tasks such as maintaining urban tree inventories and monitoring forest health, which help us understand and care for our environment. However, automatically separating the crowns from each other in aerial imagery is challenging due to factors such as the texture and partial tree crown overlaps. In this study, we present a method to train deep learning models that segment and separate individual trees from RGB and multispectral images, using pseudo-labels derived from aerial laser scanning (ALS) data. Our study shows that the ALS-derived pseudo-labels can be enhanced using a zero-shot instance segmentation model, Segment Anything Model 2 (SAM 2). Our method offers a way to obtain domain-specific training annotations for optical image-based models without any manual annotation cost, leading to segmentation models which outperform any available models which have been targeted for general domain deployment on the same task.

</details>


### [48] [Implicit-Scale 3D Reconstruction for Multi-Food Volume Estimation from Monocular Images](https://arxiv.org/abs/2602.13041)
*Yuhao Chen,Gautham Vinod,Siddeshwar Raghavan,Talha Ibn Mahmud,Bruce Coburn,Jinge Ma,Fengqing Zhu,Jiangpeng He*

Main category: cs.CV

TL;DR: 提出一个用于单目多食物图像隐式尺度3D重建的基准数据集，旨在推动真实就餐场景下的基于几何的食物份量估计。该数据集去除显式物理参考和度量标注，依赖盘子、餐具等上下文物体推断尺度，强调复杂空间排列与遮挡。在MetaFood 2025研讨会上作为挑战赛使用，实验表明几何重建方法优于视觉-语言基线，在体积估计和几何精度上分别达到0.21 MAPE和5.7 L1 Chamfer Distance。


<details>
  <summary>Details</summary>
Motivation: 现有饮食评估方法多依赖单图分析或基于外观的推断，缺乏显式几何推理能力，且对尺度模糊敏感；为提升准确性与鲁棒性，需引入隐式尺度3D重建范式以应对真实就餐场景中的复杂性。

Method: 将食物份量估计重构为单目观测下的隐式尺度3D重建问题，不提供显式物理参考或度量标注，利用上下文物体（如盘子、餐具）作为隐式尺度线索，结合先验知识进行尺度推断，并设计包含多食物、复杂遮挡与空间关系的数据集。

Result: 实验结果显示，尽管强视觉-语言基线表现良好，但几何重建方法在体积估计（MAPE: 0.21）和几何精度（L1 Chamfer Distance: 5.7）方面更具优势，且整体更稳健。

Conclusion: 隐式尺度3D重建为真实场景下食物份量估计提供了更可靠、准确的解决方案，几何方法相比外观方法具有显著优势，未来可进一步探索融合视觉-语言与几何建模的混合范式。

Abstract: We present Implicit-Scale 3D Reconstruction from Monocular Multi-Food Images, a benchmark dataset designed to advance geometry-based food portion estimation in realistic dining scenarios. Existing dietary assessment methods largely rely on single-image analysis or appearance-based inference, including recent vision-language models, which lack explicit geometric reasoning and are sensitive to scale ambiguity. This benchmark reframes food portion estimation as an implicit-scale 3D reconstruction problem under monocular observations. To reflect real-world conditions, explicit physical references and metric annotations are removed; instead, contextual objects such as plates and utensils are provided, requiring algorithms to infer scale from implicit cues and prior knowledge. The dataset emphasizes multi-food scenes with diverse object geometries, frequent occlusions, and complex spatial arrangements. The benchmark was adopted as a challenge at the MetaFood 2025 Workshop, where multiple teams proposed reconstruction-based solutions. Experimental results show that while strong vision--language baselines achieve competitive performance, geometry-based reconstruction methods provide both improved accuracy and greater robustness, with the top-performing approach achieving 0.21 MAPE in volume estimation and 5.7 L1 Chamfer Distance in geometric accuracy.

</details>


### [49] [A Calibrated Memorization Index (MI) for Detecting Training Data Leakage in Generative MRI Models](https://arxiv.org/abs/2602.13066)
*Yash Deo,Yan Jia,Toni Lassila,Victoria J Hodge,Alejandro F Frang,Chenghao Qian,Siyuan Kang,Ibrahim Habli*

Main category: cs.CV

TL;DR: 本文提出了一种校准的每样本度量方法，用于检测图像生成模型对训练数据的记忆和重复。该方法利用MRI基础模型提取的图像特征，通过多层白化最近邻相似性聚合，映射到有界的“过拟合/新颖性指数”（ONI）和“记忆指数”（MI）得分。在三个具有控制重复率和典型图像增强的MRI数据集上，该度量方法能够稳健地检测重复，并在不同数据集间提供更一致的度量值。在样本级别，该方法实现了近乎完美的重复检测。


<details>
  <summary>Details</summary>
Motivation: 图像生成模型会复制训练数据中的图像，这在医疗图像生成中可能引发隐私问题。因此需要一种有效的方法来检测模型是否记忆或重复了训练数据。

Method: 使用MRI基础模型提取图像特征，通过多层白化最近邻相似性进行聚合，并将结果映射为ONI和MI两个有界分数，以量化过拟合与新颖性水平。

Result: 在三个不同MRI数据集上，该方法能稳健检测图像重复，且在不同数据集间表现一致；在样本级别，接近完美地识别出重复图像。

Conclusion: 所提出的校准度量方法能够高效、准确地检测图像生成模型对训练数据的记忆和重复行为，尤其适用于医疗图像生成场景，有助于缓解隐私风险。

Abstract: Image generative models are known to duplicate images from the training data as part of their outputs, which can lead to privacy concerns when used for medical image generation. We propose a calibrated per-sample metric for detecting memorization and duplication of training data. Our metric uses image features extracted using an MRI foundation model, aggregates multi-layer whitened nearest-neighbor similarities, and maps them to a bounded \emph{Overfit/Novelty Index} (ONI) and \emph{Memorization Index} (MI) scores. Across three MRI datasets with controlled duplication percentages and typical image augmentations, our metric robustly detects duplication and provides more consistent metric values across datasets. At the sample level, our metric achieves near-perfect detection of duplicates.

</details>


### [50] [SIEFormer: Spectral-Interpretable and -Enhanced Transformer for Generalized Category Discovery](https://arxiv.org/abs/2602.13067)
*Chunming Li,Shidong Wang,Tong Xin,Haofeng Zhang*

Main category: cs.CV

TL;DR: SIEFormer 是一种新颖的视觉变压器架构，通过谱分析重新解释注意力机制并增强特征适应性，特别针对通用类别发现（GCD）任务。该模型包含隐式和显式两个分支：隐式分支利用不同类型的图拉普拉斯来建模标记之间的局部结构相关性，并引入可变带通/带阻滤波器（BaF）；显式分支则通过傅里叶变换对“值”特征进行全局依赖建模，学习频率域参数并逆变换以获得增强特征。实验表明其在多个图像识别数据集上达到领先性能，且通过消融实验与可视化验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有Vision Transformer在处理复杂场景下的类别发现任务时，难以有效捕捉局部结构与全局依赖之间的平衡，尤其在无监督或弱监督条件下表现受限。因此，需要一种能同时从谱域角度理解并增强特征表示的新方法，以提升模型在通用类别发现任务中的泛化能力。

Method: 提出SIEFormer，包含两个基于谱分析的分支：1）隐式分支使用多种图拉普拉斯建模局部结构相关性，并引入带宽自适应滤波层（BaF）实现灵活的频段过滤；2）显式分支通过傅里叶变换处理输入值特征，在频率域学习可调参数，再经逆变换得到增强特征，从而建模全局依赖关系。两分支联合优化，提升特征表达能力。

Result: SIEFormer在多个图像识别数据集上实现了当前最优性能，尤其在通用类别发现（GCD）任务中表现出显著优势。消融实验验证了各模块的有效性，可视化结果展示了模型对关键语义区域的关注能力，证明其具有更强的特征适应性和可解释性。

Conclusion: SIEFormer通过融合隐式与显式的谱分析机制，成功提升了ViT在复杂识别任务中的表征能力，特别是在无监督或弱监督场景下具备良好的泛化性能，为视觉Transformer的设计提供了新的思路。

Abstract: This paper presents a novel approach, Spectral-Interpretable and -Enhanced Transformer (SIEFormer), which leverages spectral analysis to reinterpret the attention mechanism within Vision Transformer (ViT) and enhance feature adaptability, with particular emphasis on challenging Generalized Category Discovery (GCD) tasks. The proposed SIEFormer is composed of two main branches, each corresponding to an implicit and explicit spectral perspective of the ViT, enabling joint optimization. The implicit branch realizes the use of different types of graph Laplacians to model the local structure correlations of tokens, along with a novel Band-adaptive Filter (BaF) layer that can flexibly perform both band-pass and band-reject filtering. The explicit branch, on the other hand, introduces a Maneuverable Filtering Layer (MFL) that learns global dependencies among tokens by applying the Fourier transform to the input ``value" features, modulating the transformed signal with a set of learnable parameters in the frequency domain, and then performing an inverse Fourier transform to obtain the enhanced features. Extensive experiments reveal state-of-the-art performance on multiple image recognition datasets, reaffirming the superiority of our approach through ablation studies and visualizations.

</details>


### [51] [Universal Transformation of One-Class Classifiers for Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.13091)
*Declan McIntosh,Alexandra Branzan Albu*

Main category: cs.CV

TL;DR: 本文提出一种数据折叠方法，将任意基于单类分类器的异常检测器转化为完全无监督的方法。通过假设异常在训练数据中稀少且异质，利用多个独立训练的单类分类器对训练集进行异常过滤。该方法无需修改底层检测器，仅需选择性地使用子集数据进行训练。实验表明，该方法可广泛适用于图像和视频的无监督异常检测，在MVTec AD、ViSA、MVTec Loco AD等数据集上达到当前最优性能，并能将单类分类器的改进直接迁移至无监督领域。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法多基于单类分类，依赖纯净训练数据，对标签噪声敏感；而真实场景中难以获得无噪声的正常样本，因此亟需一种无需依赖标签的无监督异常检测方法。

Method: 提出数据折叠方法：通过多个独立训练的单类分类器对训练集进行交叉验证，筛选出疑似异常样本并剔除，从而生成更纯净的训练集；在此基础上训练最终模型，实现从有监督到无监督的无缝转换。

Result: 所提方法成功将多种单类分类器转化为无监督异常检测器，在MVTec AD、ViSA、MVTec Loco AD等多个基准数据集上表现优于现有方法，达到当前最佳水平。

Conclusion: 本方法实现了首个无监督逻辑异常检测框架，具有通用性强、无需修改原模型、可自动继承单类分类器进步的优点，显著推动了无监督异常检测的发展。

Abstract: Detecting anomalies in images and video is an essential task for multiple real-world problems, including industrial inspection, computer-assisted diagnosis, and environmental monitoring. Anomaly detection is typically formulated as a one-class classification problem, where the training data consists solely of nominal values, leaving methods built on this assumption susceptible to training label noise. We present a dataset folding method that transforms an arbitrary one-class classifier-based anomaly detector into a fully unsupervised method. This is achieved by making a set of key weak assumptions: that anomalies are uncommon in the training dataset and generally heterogeneous. These assumptions enable us to utilize multiple independently trained instances of a one-class classifier to filter the training dataset for anomalies. This transformation requires no modifications to the underlying anomaly detector; the only changes are algorithmically selected data subsets used for training. We demonstrate that our method can transform a wide variety of one-class classifier anomaly detectors for both images and videos into unsupervised ones. Our method creates the first unsupervised logical anomaly detectors by transforming existing methods. We also demonstrate that our method achieves state-of-the-art performance for unsupervised anomaly detection on the MVTec AD, ViSA, and MVTec Loco AD datasets. As improvements to one-class classifiers are made, our method directly transfers those improvements to the unsupervised domain, linking the domains.

</details>


### [52] [Realistic Face Reconstruction from Facial Embeddings via Diffusion Models](https://arxiv.org/abs/2602.13168)
*Dong Han,Yong Li,Joachim Denzler*

Main category: cs.CV

TL;DR: 本文提出了一种名为FEM的通用框架，利用Kolmogorov-Arnold Network（KAN）结合预训练的身份保持扩散模型，针对最先进的面部识别（FR）和隐私保护面部识别（PPFR）系统，实现从嵌入向量到真实高分辨率人脸图像的映射攻击。实验表明，重建的人脸可用于访问其他现实世界的面部识别系统，且该方法在部分或受保护的嵌入向量下仍具鲁棒性，可作为评估FR与PPFR系统隐私泄露风险的安全工具。


<details>
  <summary>Details</summary>
Motivation: 当前对隐私保护面部识别（PPFR）系统的隐私风险研究不足，尤其缺乏对从系统嵌入向量中重建高质量人脸图像的深入验证。因此，亟需一种有效方法来揭示潜在的隐私泄露风险，并为系统安全性评估提供支持。

Method: 提出基于Kolmogorov-Arnold Network（KAN）的面部分布映射框架（FEM），结合身份保持扩散模型，将面部嵌入向量转化为高分辨率真实人脸图像，用于攻击和评估现有FR与PPFR系统。

Result: 所提方法成功重建出可用于跨系统识别的真实人脸图像，即使在部分或加密嵌入条件下仍表现良好；同时验证了其在评估系统隐私安全方面的有效性。

Conclusion: FEM框架能够有效揭示当前主流FR与PPFR系统中的隐私漏洞，具备作为隐私泄露评估工具的潜力，推动更安全的隐私保护技术发展。

Abstract: With the advancement of face recognition (FR) systems, privacy-preserving face recognition (PPFR) systems have gained popularity for their accurate recognition, enhanced facial privacy protection, and robustness to various attacks. However, there are limited studies to further verify privacy risks by reconstructing realistic high-resolution face images from embeddings of these systems, especially for PPFR. In this work, we propose the face embedding mapping (FEM), a general framework that explores Kolmogorov-Arnold Network (KAN) for conducting the embedding-to-face attack by leveraging pre-trained Identity-Preserving diffusion model against state-of-the-art (SOTA) FR and PPFR systems. Based on extensive experiments, we verify that reconstructed faces can be used for accessing other real-word FR systems. Besides, the proposed method shows the robustness in reconstructing faces from the partial and protected face embeddings. Moreover, FEM can be utilized as a tool for evaluating safety of FR and PPFR systems in terms of privacy leakage. All images used in this work are from public datasets.

</details>


### [53] [LongStream: Long-Sequence Streaming Autoregressive Visual Geometry](https://arxiv.org/abs/2602.13172)
*Chong Cheng,Xianda Chen,Tao Xie,Wei Yin,Weiqiang Ren,Qian Zhang,Xiaoyuang Guo,Hao Wang*

Main category: cs.CV

TL;DR: LongStream提出一种新型的无锚点、解耦尺度的流式3D重建方法，通过相对关键帧位姿预测、正交尺度学习和缓存一致训练与周期刷新机制，有效解决长序列中的注意力衰减、尺度漂移和缓存污染问题，在千帧以上序列上实现18 FPS的稳定度量级重建。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型在处理长序列时因锚定首帧导致注意力衰减、尺度漂移和外推误差，难以实现长期稳定的度量级3D重建。

Method: 1. 放弃首帧锚定，预测关键帧相对位姿；2. 引入正交尺度学习，解耦几何与尺度估计；3. 采用缓存一致训练与周期性缓存刷新，缓解Transformer缓存中的注意力依赖和长期污染问题。

Result: LongStream在数千帧的超长序列上实现了稳定的度量级重建，达到18 FPS的实时性能，显著优于现有方法，在千米级场景下表现卓越。

Conclusion: LongStream通过多维度创新设计，成功解决了长序列流式3D重建中的核心挑战，为大规模、高精度的连续视觉几何建模提供了新范式。

Abstract: Long-sequence streaming 3D reconstruction remains a significant open challenge. Existing autoregressive models often fail when processing long sequences. They typically anchor poses to the first frame, which leads to attention decay, scale drift, and extrapolation errors. We introduce LongStream, a novel gauge-decoupled streaming visual geometry model for metric-scale scene reconstruction across thousands of frames. Our approach is threefold. First, we discard the first-frame anchor and predict keyframe-relative poses. This reformulates long-range extrapolation into a constant-difficulty local task. Second, we introduce orthogonal scale learning. This method fully disentangles geometry from scale estimation to suppress drift. Finally, we solve Transformer cache issues such as attention-sink reliance and long-term KV-cache contamination. We propose cache-consistent training combined with periodic cache refresh. This approach suppresses attention degradation over ultra-long sequences and reduces the gap between training and inference. Experiments show LongStream achieves state-of-the-art performance. It delivers stable, metric-scale reconstruction over kilometer-scale sequences at 18 FPS. Project Page: https://3dagentworld.github.io/longstream/

</details>


### [54] [Monocular Markerless Motion Capture Enables Quantitative Assessment of Upper Extremity Reachable Workspace](https://arxiv.org/abs/2602.13176)
*Seth Donahue,J. D. Peiffer,R. Tyler Richardson,Yishan Zhong,Shaun Q. Y. Tan,Benoit Marteau,Stephanie R. Russo,May D. Wang,R. James Cotton,Ross Chafetz*

Main category: cs.CV

TL;DR: 本研究验证了使用单目相机和人工智能驱动的无标记运动捕捉（MMC）技术进行上肢可及工作空间（UERW）定量评估的临床可行性。通过与基于标记的运动捕捉系统对比，正面朝向的单目相机配置表现出与参考系统高度一致的结果，尤其在评估前向工作空间时表现最佳，具有最小的平均偏差（0.61 ± 0.12%），而偏置视角则显著低估了可达范围。研究首次验证了单目MMC系统在UERW评估中的有效性，为简化临床操作、降低技术门槛提供了支持，具备良好的临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 当前临床中对上肢可及工作空间（UERW）的评估仍依赖复杂且成本较高的多摄像机标记系统，限制了其在日常临床实践中的广泛应用。为了推动更便捷、低成本的生物力学分析方法落地，亟需一种技术门槛低、操作简便的替代方案。因此，本研究旨在验证基于单目相机与人工智能驱动的无标记运动捕捉技术在UERW评估中的可行性和准确性，以促进其在临床环境中的实际应用。

Method: 研究招募了9名无功能障碍的成年参与者，执行标准化的UERW任务，即在虚拟球体中心（以躯干为中心）的不同位置触达目标，目标由VR头显呈现。所有动作同时由基于标记的运动捕捉系统和八台FLIR相机记录。选取其中两个视频视角（正面与偏置视角）进行单目视频分析，通过与标记系统数据对比，评估两种视角下单目相机系统的精度与一致性。

Result: 正面朝向的单目相机配置显示出与基于标记的参考系统极高的吻合度，平均偏差仅为0.61 ± 0.12%（每八分之一球面所达比例），表明其测量结果极为准确；而偏置视角则系统性地低估了可达工作空间，偏差达到-5.66 ± 0.45%。这说明相机视角对单目系统性能有显著影响。

Conclusion: 研究证实，采用正面朝向的单目相机配置进行无标记运动捕捉是评估上肢可及工作空间的一种可行且高精度的方法，尤其适用于前向工作空间的评估。该方法显著降低了技术复杂性，具备良好的临床转化潜力，为实现简便、高效的上肢运动功能量化评估提供了有力支持。本研究首次完成了单目无标记运动捕捉系统在UERW评估中的有效验证。

Abstract: To validate a clinically accessible approach for quantifying the Upper Extremity Reachable Workspace (UERW) using a single (monocular) camera and Artificial Intelligence (AI)-driven Markerless Motion Capture (MMC) for biomechanical analysis. Objective assessment and validation of these techniques for specific clinically oriented tasks are crucial for their adoption in clinical motion analysis. AI-driven monocular MMC reduces the barriers to adoption in the clinic and has the potential to reduce the overhead for analysis of this common clinical assessment. Nine adult participants with no impairments performed the standardized UERW task, which entails reaching targets distributed across a virtual sphere centered on the torso, with targets displayed in a VR headset. Movements were simultaneously captured using a marker-based motion capture system and a set of eight FLIR cameras. We performed monocular video analysis on two of these video camera views to compare a frontal and offset camera configurations. The frontal camera orientation demonstrated strong agreement with the marker-based reference, exhibiting a minimal mean bias of $0.61 \pm 0.12$ \% reachspace reached per octanct (mean $\pm$ standard deviation). In contrast, the offset camera view underestimated the percent workspace reached ($-5.66 \pm 0.45$ \% reachspace reached). Conclusion: The findings support the feasibility of a frontal monocular camera configuration for UERW assessment, particularly for anterior workspace evaluation where agreement with marker-based motion capture was highest. The overall performance demonstrates clinical potential for practical, single-camera assessments. This study provides the first validation of monocular MMC system for the assessment of the UERW task. By reducing technical complexity, this approach enables broader implementation of quantitative upper extremity mobility assessment.

</details>


### [55] [FlexAM: Flexible Appearance-Motion Decomposition for Versatile Video Generation Control](https://arxiv.org/abs/2602.13185)
*Mingzhi Sheng,Zekai Gu,Peng Li,Cheng Lin,Hao-Xiang Guo,Ying-Cong Chen,Yuan Liu*

Main category: cs.CV

TL;DR: FlexAM proposes a novel 3D control signal using point cloud representation to disentangle appearance and motion in video generation, enabling versatile tasks like I2V/V2V editing, camera control, and spatial object editing with superior performance.


<details>
  <summary>Details</summary>
Motivation: Existing methods for video generation often rely on ambiguous or task-specific control signals, limiting their effectiveness and generalizability. The authors aim to address this by introducing a more fundamental disentanglement of appearance and motion through a unified framework.

Method: FlexAM introduces a 3D control signal represented as a point cloud with multi-frequency and depth-aware positional encoding, allowing flexible and precise control over video dynamics while maintaining high generative quality.

Result: Extensive experiments show that FlexAM outperforms existing methods across various tasks, including image-to-video and video-to-video editing, camera control, and spatial object manipulation.

Conclusion: The proposed FlexAM framework provides a robust, scalable, and generalizable solution for video generation by effectively disentangling appearance and motion through a novel 3D control signal.

Abstract: Effective and generalizable control in video generation remains a significant challenge. While many methods rely on ambiguous or task-specific signals, we argue that a fundamental disentanglement of "appearance" and "motion" provides a more robust and scalable pathway. We propose FlexAM, a unified framework built upon a novel 3D control signal. This signal represents video dynamics as a point cloud, introducing three key enhancements: multi-frequency positional encoding to distinguish fine-grained motion, depth-aware positional encoding, and a flexible control signal for balancing precision and generative quality. This representation allows FlexAM to effectively disentangle appearance and motion, enabling a wide range of tasks including I2V/V2V editing, camera control, and spatial object editing. Extensive experiments demonstrate that FlexAM achieves superior performance across all evaluated tasks.

</details>


### [56] [Conversational Image Segmentation: Grounding Abstract Concepts with Scalable Supervision](https://arxiv.org/abs/2602.13195)
*Aadarsh Sahoo,Georgia Gkioxari*

Main category: cs.CV

TL;DR: 本文提出了对话式图像分割（CIS）任务，填补了现有研究在功能与物理推理方面的空白。作者构建了ConverSeg基准数据集，涵盖实体、空间关系、意图、可操作性、功能、安全性和物理推理等多维度内容，并提出ConverSeg-Net模型结合强分割先验与语言理解能力，配合无监督数据生成引擎，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注类别和空间查询（如'最左边的苹果'），忽视了功能与物理推理（如'我可以在哪里安全地存放刀子？'），因此需要新的任务和数据集来推动对话式图像分割的发展。

Method: 提出ConverSeg基准数据集，设计ConverSeg-Net模型融合语义理解与分割先验，并开发基于AI的数据生成引擎，自动构建提示-掩码对，无需人工标注。

Result: 现有语言引导分割模型在新任务上表现不佳；而ConverSeg-Net在ConverSeg数据集上取得显著提升，并在传统基准上保持优异性能。

Conclusion: 对话式图像分割是未来重要方向，ConverSeg及其配套模型与数据生成方法为该领域提供了坚实基础，推动了从简单定位到复杂意图理解的演进。

Abstract: Conversational image segmentation grounds abstract, intent-driven concepts into pixel-accurate masks. Prior work on referring image grounding focuses on categorical and spatial queries (e.g., "left-most apple") and overlooks functional and physical reasoning (e.g., "where can I safely store the knife?"). We address this gap and introduce Conversational Image Segmentation (CIS) and ConverSeg, a benchmark spanning entities, spatial relations, intent, affordances, functions, safety, and physical reasoning. We also present ConverSeg-Net, which fuses strong segmentation priors with language understanding, and an AI-powered data engine that generates prompt-mask pairs without human supervision. We show that current language-guided segmentation models are inadequate for CIS, while ConverSeg-Net trained on our data engine achieves significant gains on ConverSeg and maintains strong performance on existing language-guided segmentation benchmarks. Project webpage: https://glab-caltech.github.io/converseg/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [57] [A Lightweight LLM Framework for Disaster Humanitarian Information Classification](https://arxiv.org/abs/2602.12284)
*Han Jinzhen,Kim Jisung,Yang Jong Soo,Yun Hong Sik*

Main category: cs.CL

TL;DR: 本文提出一种轻量级、低成本的框架，用于在资源受限的紧急情况下对灾难推文进行分类。通过整合和标准化HumAID数据集，构建了一个包含19个灾难事件的统一实验语料库，并设计了双任务基准（人道主义信息分类与事件类型识别）。系统评估了提示策略、LoRA微调和检索增强生成（RAG）在Llama 3.1 8B模型上的表现，发现：(1) LoRA在仅训练约2%参数的情况下，实现79.62%的人道主义分类准确率，较零样本提升37.79%；(2) QLoRA在仅50%内存开销下达到99.4%的LoRA性能；(3) 与普遍假设相反，RAG因检索示例中的标签噪声反而降低了微调模型的表现。研究结果为在有限计算资源下构建可靠的危机情报系统提供了可复现的实用方案。


<details>
  <summary>Details</summary>
Motivation: 在灾害应急响应中，及时分类社交媒体上的信息至关重要，但大型语言模型（LLMs）在资源受限环境中部署困难，亟需一种高效、低成本的解决方案。

Method: 整合并标准化HumAID数据集，构建双任务基准；系统评估提示策略、LoRA微调和检索增强生成（RAG）在Llama 3.1 8B模型上的表现，采用参数高效微调技术以降低计算成本。

Result: LoRA实现79.62%的人道主义分类准确率，较零样本提升37.79%，仅训练约2%参数；QLoRA在50%内存开销下达到99.4%的LoRA性能；RAG因标签噪声导致性能下降。

Conclusion: 本研究建立了一种适用于资源受限环境的高效、可复现的灾难推文分类框架，为构建可靠危机情报系统提供了可行路径。

Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper develops a lightweight, cost-effective framework for disaster tweet classification using parameter-efficient fine-tuning. We construct a unified experimental corpus by integrating and normalizing the HumAID dataset (76,484 tweets across 19 disaster events) into a dual-task benchmark: humanitarian information categorization and event type identification. Through systematic evaluation of prompting strategies, LoRA fine-tuning, and retrieval-augmented generation (RAG) on Llama 3.1 8B, we demonstrate that: (1) LoRA achieves 79.62% humanitarian classification accuracy (+37.79% over zero-shot) while training only ~2% of parameters; (2) QLoRA enables efficient deployment with 99.4% of LoRA performance at 50% memory cost; (3) contrary to common assumptions, RAG strategies degrade fine-tuned model performance due to label noise from retrieved examples. These findings establish a practical, reproducible pipeline for building reliable crisis intelligence systems with limited computational resources.

</details>


### [58] [Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction](https://arxiv.org/abs/2602.12287)
*Junjie An,Jingguang Tian,Tianyi Wang,Yu Gao,Xiaofeng Mou,Yi Xu*

Main category: cs.CL

TL;DR: 提出了一种基于检索增强生成的命名实体纠错框架，结合重述语言模型与自适应思维链推理，有效提升ASR中命名实体识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的命名实体纠错方法未充分挖掘其复杂推理能力，导致在特定领域术语（如命名实体）上仍易出错，影响下游任务性能。

Method: 采用两阶段框架：首先使用重述语言模型进行命名实体识别，并通过音素级编辑距离检索候选；其次引入自教式自适应思维链（A-STAR）模型，动态调整推理深度以应对不同难度任务。

Result: 在AISHELL-1和同音词数据集上，相比强基线，命名实体字符错误率分别降低17.96%和34.42%，验证了方法的有效性。

Conclusion: 所提出的检索增强生成框架充分利用了大语言模型的推理潜力，显著提升了语音识别中命名实体的纠错能力，为高精度语音系统提供了新思路。

Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large language models (LLMs) has recently emerged. However, these approaches have yet to fully exploit the sophisticated reasoning capabilities inherent to LLMs. To bridge this gap, we propose a novel retrieval-augmented generation framework for correcting named entity errors in ASR. Our approach consists of two key components: (1) a rephrasing language model (RLM) for named entity recognition, followed by candidate retrieval using a phonetic-level edit distance; and (2) a novel self-taught reasoning model with adaptive chain-of-thought (A-STAR) that dynamically adjusts the depth of its reasoning based on task difficulty. Experiments on the AISHELL-1 and Homophone datasets demonstrate the effectiveness of our method, which achieves relative reductions in the named entity character error rate of 17.96\% and 34.42\%, respectively, compared to a strong baseline.

</details>


### [59] [Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria à Prática](https://arxiv.org/abs/2602.12302)
*Neemias da Silva,Júlio C. W. Scholz,John Harrison,Marina Borges,Paulo Ávila,Frances A Santos,Myriam Delgado,Rodrigo Minetto,Thiago H Silva*

Main category: cs.CL

TL;DR: 本文介绍了多模态大语言模型（MLLMs）的基本原理、代表性模型，探讨了预处理、提示工程及使用LangChain和LangGraph构建多模态流程的实际技术，并提供了在线补充材料链接。最后讨论了当前挑战与未来趋势。


<details>
  <summary>Details</summary>
Motivation: 提升AI在多模态信息理解与生成方面的能力，融合自然语言处理与视觉、音频等感知能力，推动智能系统发展。

Method: 通过理论阐述与实践案例结合的方式，介绍MLLMs的核心技术，包括数据预处理、提示设计、多模态框架构建，并基于LangChain和LangGraph实现应用集成。

Result: 展示了如何有效构建和应用多模态大模型系统，为研究者和开发者提供可操作的技术路径与资源支持。

Conclusion: MLLMs是人工智能的重要发展方向，尽管面临挑战，但其在跨模态理解与生成方面的潜力巨大，未来将向更高效、更通用的方向演进。

Abstract: Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI. This chapter presents the main fundamentals of MLLMs and emblematic models. Practical techniques for preprocessing, prompt engineering, and building multimodal pipelines with LangChain and LangGraph are also explored. For further practical study, supplementary material is publicly available online: https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica. Finally, the chapter discusses the challenges and highlights promising trends.

</details>


### [60] [RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty](https://arxiv.org/abs/2602.12424)
*Ziqian Zhang,Xingjian Hu,Yue Huang,Kai Zhang,Ruoxi Chen,Yixin Liu,Qingsong Wen,Kaidi Xu,Xiangliang Zhang,Neil Zhenqiang Gong,Lichao Sun*

Main category: cs.CL

TL;DR: RankLLM is a novel framework that quantifies both question difficulty and model competency by enabling bidirectional score propagation between models and questions. It addresses the limitation of existing benchmarks by incorporating difficulty as a primary evaluation criterion, achieving 90% agreement with human judgments and outperforming baselines like IRT in accuracy, stability, and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively assess and compare large language models' true capabilities.

Method: RankLLM uses bidirectional score propagation: models gain competency scores for correct answers, while questions increase in difficulty when they challenge models. This mechanism enables fine-grained evaluation across diverse domains.

Result: RankLLM achieves 90% agreement with human judgments, shows superior performance over strong baselines like IRT, and demonstrates high stability, fast convergence, and computational efficiency.

Conclusion: RankLLM provides a practical, scalable, and difficulty-aware evaluation framework for large language models, enabling more accurate and nuanced assessment of model capabilities.

Abstract: Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively distinguish models' capabilities. To address this limitation, we propose RankLLM, a novel framework designed to quantify both question difficulty and model competency. RankLLM introduces difficulty as the primary criterion for differentiation, enabling a more fine-grained evaluation of LLM capabilities. RankLLM's core mechanism facilitates bidirectional score propagation between models and questions. The core intuition of RankLLM is that a model earns a competency score when it correctly answers a question, while a question's difficulty score increases when it challenges a model. Using this framework, we evaluate 30 models on 35,550 questions across multiple domains. RankLLM achieves 90% agreement with human judgments and consistently outperforms strong baselines such as IRT. It also exhibits strong stability, fast convergence, and high computational efficiency, making it a practical solution for large-scale, difficulty-aware LLM evaluation.

</details>


### [61] [RBCorr: Response Bias Correction in Language Models](https://arxiv.org/abs/2602.12445)
*Om Bhatt,Anna A. Ivanova*

Main category: cs.CL

TL;DR: 提出了一种简单有效的响应偏差纠正方法（RBCorr），在12个开源语言模型上测试，发现预纠正时语言模型普遍存在响应偏差，而RBCorr能有效消除偏差并提升性能。研究还揭示了基于对数概率的纠正方法对模型、数据集和提示格式高度依赖，表明RBCorr是一种易于使用的方法，可提升小模型性能，并使封闭式评测结果更真实反映模型能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型在固定回答问题中容易出现响应偏差，如选项偏好，这影响模型性能评估的准确性，因此需要低成本且高效的偏差纠正方法来提升模型表现并实现更准确的能力评估。

Method: 提出并测试了一种名为RBCorr的响应偏差纠正策略，采用基于对数概率的方法，在多个语言模型、不同类型的问题（是/否、蕴含、多选）上进行验证。

Result: 响应偏差在未纠正的语言模型中普遍存在；RBCorr能有效消除偏差，显著提升模型在各类任务上的表现；但其效果受模型、数据集和提示格式的影响较大，表现出较强的依赖性。

Conclusion: RBCorr是一种简单易用的偏差纠正方法，尤其适用于小型语言模型，能够有效提升其性能，并使闭式评测结果更贴近模型的真实能力。

Abstract: Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM performance and enable more accurate evaluations of model abilities. Here, we propose a simple response bias correction strategy ($\texttt{RBCorr}$) and test it on 12 open-weight language models using yes-no, entailment, and multiple choice questions. We show that response bias is prevalent in LMs pre-correction and that $\texttt{RBCorr}$ effectively eliminates bias and boosts model performance. We also explore the generalizability of bias behavior across models, datasets, and prompt formats, showing that LogProbs-based correction is highly dependent on all three of these aspects. Overall, $\texttt{RBCorr}$ is an easy-to-use method that can boost the performance of smaller LMs and ensure that LM performance on closed-response benchmarks aligns more closely with their true capabilities.

</details>


### [62] [Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification](https://arxiv.org/abs/2602.12575)
*Bo Wang,Yuxuan Zhang,Yueqin Hu,Hanchao Hou,Kaiping Peng,Shiguang Ni*

Main category: cs.CL

TL;DR: 本文提出一种基于主题建模的无响应式心理量表精炼框架，利用上下文句子嵌入与密度聚类发现潜在语义因子，通过类别词权重构可解释的主题表示，并在整合管道中选择代表性题项。在DASS、IPIP和EPOCH量表上验证，该方法平均减少60.5%题项数量，同时保持良好的信度、结构一致性和因子相关性，证明语义潜结构可作为测量结构的无响应近似。研究还提供可视化工具支持一键分析与简化。


<details>
  <summary>Details</summary>
Motivation: 传统心理量表优化依赖大样本的响应数据方法（如因子分析、项目反应理论），受限于数据可得性与跨文化可比性；而自然语言处理揭示问卷题项的语义结构可能隐含潜在构念组织，为无需响应数据的量表简化提供了新视角。

Method: 采用上下文句子嵌入编码题项，通过密度基聚类自动发现潜在语义因子，不预设因子数；使用类级别词权生成可解释的主题表示，合并语义相近的聚类；结合成员标准构建集成化缩减流程选取代表性题项。

Result: 所提方法在多个量表上成功恢复出与已有构念一致的因子群组，平均减少60.5%题项数，保持良好内部一致性、因子同质性与因子间相关性，表明语义潜结构能有效近似测量结构。

Conclusion: 语义潜结构可作为量表构建与简化的可检视前端；本框架不仅提升量表效率，且具备高可解释性与实用性，配套工具促进实际应用。

Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultural comparability. Recent advances in natural language processing suggest that the semantic structure of questionnaire items may encode latent construct organization, offering a complementary response-free perspective. We introduce a topic-modeling framework that operationalizes semantic latent structure for scale simplification. Items are encoded using contextual sentence embeddings and grouped via density-based clustering to discover latent semantic factors without predefining their number. Class-based term weighting derives interpretable topic representations that approximate constructs and enable merging of semantically adjacent clusters. Representative items are selected using membership criteria within an integrated reduction pipeline. We benchmarked the framework across DASS, IPIP, and EPOCH, evaluating structural recovery, internal consistency, factor congruence, correlation preservation, and reduction efficiency. The proposed method recovered coherent factor-like groupings aligned with established constructs. Selected items reduced scale length by 60.5% on average while maintaining psychometric adequacy. Simplified scales showed high concordance with original factor structures and preserved inter-factor correlations, indicating that semantic latent organization provides a response-free approximation of measurement structure. Our framework formalizes semantic structure as an inspectable front-end for scale construction and reduction. To facilitate adoption, we provide a visualization-supported tool enabling one-click semantic analysis and structured simplification.

</details>


### [63] [Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats](https://arxiv.org/abs/2602.12635)
*Pengxiang Zhao,Hui-Ling Zhen,Xing Li,Han Bao,Weizhe Lin,Zhiyuan Yang,Ziwei Yu,Xin Wang,Mingxuan Yuan,Xianzhi Yu,Zhenhua Dong*

Main category: cs.CL

TL;DR: HiFloat (HiF8 and HiF4) 是为 Ascend NPUs 量身定制的低比特浮点格式，适用于大模型推理。在权重-激活和KV缓存任务中，实验表明：1）INT8 适合窄范围数据，而浮点格式在高方差数据上表现更优；2）在4比特下，HiF4 的分层缩放避免了整数格式的精度崩溃；3）HiFloat 兼容当前最先进的后训练量化框架。整体上，HiFloat 为 NPU 上的高效大模型推理提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）规模的增大，对计算效率和精度的要求日益提高。现有的低比特整数格式在处理高方差数据时存在精度损失问题，而现有浮点格式又难以适配特定硬件（如Ascend NPUs）。因此，亟需一种既高效又兼容性强的低比特表示方法，以支持高性能大模型推理。

Method: 提出HiFloat（HiF8和HiF4）系列低比特浮点格式，针对Ascend NPU架构优化。通过分层缩放机制设计4比特版本，增强对高方差数据的表达能力，并验证其在权重-激活与KV缓存任务中的性能表现。同时，评估其与主流后训练量化框架的兼容性。

Result: 实验结果显示：1）对于窄范围数据，INT8表现良好；但对于高方差数据，浮点格式（如HiFloat）显著优于整数格式；2）在4比特设置下，HiF4因采用分层缩放策略，有效防止了精度下降；3）HiFloat可无缝集成至现有后训练量化流程，具备良好的工程落地潜力。

Conclusion: HiFloat是一种专为Ascend NPU设计的高效低比特浮点格式，能够在保持高精度的同时实现显著的计算效率提升，是面向未来大模型高效推理的理想选择。

Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.

</details>


### [64] [CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation](https://arxiv.org/abs/2602.12639)
*Yiran Rex Ma,Yuxiao Ye,Huiyuan Xie*

Main category: cs.CL

TL;DR: 提出CLASE，一种用于评估法律文本风格质量的混合方法，结合语言特征得分与经验引导的LLM评判，通过对比真实法律文档与其LLM恢复版本学习参数，在无参考情况下实现透明、可解释的风格评估。在200份中文法律文件上实验表明，其与人工判断高度一致，优于传统指标和纯LLM评判方法，并提供改进建议。


<details>
  <summary>Details</summary>
Motivation: 现有法律文本生成虽具备事实准确性，但缺乏法律写作特有的风格规范；人工制定评价标准不现实，因法律风格隐含难形式化；现有自动评估方法或混淆语义与风格，或存在不透明与不一致问题。

Method: 提出CLASE，采用混合评分机制：1）基于语言特征的得分；2）基于经验的LLM-as-a-judge得分。两者均通过对比真实法律文档与LLM生成的恢复版本进行学习，实现无参考、透明、可解释的风格评估。

Result: 在200份中文法律文档上的实验显示，CLASE与人类判断具有更高的相关性，显著优于传统参考依赖指标和纯LLM评判方法；同时提供可解释的分数分解与改进建议，具备可扩展性和实用性。

Conclusion: CLASE为法律文本生成中的风格评估提供了可靠、透明、可解释且可扩展的解决方案，适用于专业场景下的风格质量监控与优化。

Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic quality, a crucial first step is to establish a reliable evaluation method. However, having legal experts manually develop such a metric is impractical, as the implicit stylistic requirements in legal writing practice are difficult to formalise into explicit rubrics. Meanwhile, existing automatic evaluation methods also fall short: reference-based metrics conflate semantic accuracy with stylistic fidelity, and LLM-as-a-judge evaluations suffer from opacity and inconsistency. To address these challenges, we introduce CLASE (Chinese LegAlese Stylistic Evaluation), a hybrid evaluation method that focuses on the stylistic performance of legal text. The method incorporates a hybrid scoring mechanism that combines 1) linguistic feature-based scores and 2) experience-guided LLM-as-a-judge scores. Both the feature coefficients and the LLM scoring experiences are learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts. This hybrid design captures both surface-level features and implicit stylistic norms in a transparent, reference-free manner. Experiments on 200 Chinese legal documents show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods. Beyond improved alignment, CLASE provides interpretable score breakdowns and suggestions for improvements, offering a scalable and practical solution for professional stylistic evaluation in legal text generation (Code and data for CLASE is available at: https://github.com/rexera/CLASE).

</details>


### [65] [Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR](https://arxiv.org/abs/2602.12642)
*Dohyung Kim,Minbeom Kim,Jeonghye Kim,Sangmook Lee,Sojeong Rhee,Kyomin Jung*

Main category: cs.CL

TL;DR: 该论文提出了一种名为PACED-RL的后训练框架，通过重新解释GFlowNet中的分区函数为每个提示的期望奖励（即在线准确率）信号，以提升大语言模型在分布匹配训练中的样本效率。该方法利用准确率估计来优先选择有信息量的问题提示，并通过基于准确率估计误差的重放机制进一步优化训练效率。两个组件均复用已有训练过程中的信息，有效分摊计算开销。实验表明，PACED-RL在多个基准测试中显著优于GRPO和先前的GFlowNet方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于奖励最大化的强化学习方法虽能提升大语言模型的推理能力，但常导致输出多样性下降。虽然已有研究采用GFlowNets进行分布匹配并学习分区函数，但通常仅将其作为归一化因子，未充分利用其蕴含的准确率信息。本文旨在挖掘这一被忽视的信息，以提高训练样本效率。

Method: 首先建立分区函数与每提示准确率估计之间的理论联系；在此基础上提出PACED-RL框架，包含两个核心机制：1）基于准确率估计优先选择高信息量提示进行训练；2）采用准确率估计误差驱动的重放策略，提升样本使用效率。所有机制均复用GFlowNet训练过程中已生成的信息，实现计算开销的摊销。

Result: 在多个不同基准测试上的实验结果表明，PACED-RL在保持或提升输出多样性的同时，显著提高了训练样本效率，性能优于GRPO及以往的GFlowNet方法，验证了其作为高效分布匹配训练范式的优势。

Conclusion: PACED-RL通过将分区函数重新解读为准确率信号，实现了对训练过程的有效引导，在不增加额外计算负担的前提下显著提升了大语言模型在分布匹配训练中的样本效率，为未来高效、高质量的强化学习训练提供了新思路。

Abstract: Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly learning its partition function. In contrast to prior works that treat this partition function solely as a normalizer, we reinterpret it as a per-prompt expected-reward (i.e., online accuracy) signal, leveraging this unused information to improve sample efficiency. Specifically, we first establish a theoretical relationship between the partition function and per-prompt accuracy estimates. Building on this key insight, we propose Partition Function-Guided RL (PACED-RL), a post-training framework that leverages accuracy estimates to prioritize informative question prompts during training, and further improves sample efficiency through an accuracy estimate error-prioritized replay. Crucially, both components reuse information already produced during GFlowNet training, effectively amortizing the compute overhead into the existing optimization process. Extensive experiments across diverse benchmarks demonstrate strong performance improvements over GRPO and prior GFlowNet approaches, highlighting PACED-RL as a promising direction for a more sample efficient distribution-matching training for LLMs.

</details>


### [66] [Learning Ordinal Probabilistic Reward from Preferences](https://arxiv.org/abs/2602.12660)
*Longze Chen,Lu Wang,Renke Shan,Ze Gong,Run Luo,Jiaming Li,Jing Luo,Qiyao Wang,Min Yang*

Main category: cs.CL

TL;DR: 提出了一种新的奖励建模范式：概率奖励模型（PRM），将奖励视为随机变量并学习其完整概率分布。通过离散化实现为序数概率奖励模型（OPRM），结合区域洪水微调（RgFT）策略，提升对绝对文本质量的建模能力，实验表明在多个基准上准确率提升2.9%~7.4%，兼具高效性和强性能。


<details>
  <summary>Details</summary>
Motivation: 现有生成式（GRM）和判别式（DRM）奖励模型分别面临成本高和评分不可校准的问题，难以同时满足相对排序与绝对质量评估需求。

Method: 提出概率奖励模型（PRM），以概率分布形式建模奖励；设计离散化的序数概率奖励模型（OPRM），并引入区域洪水微调（RgFT）策略，利用质量等级标注引导概率质量集中于对应评分区间。

Result: 在多个奖励模型基准上，相比先前方法准确率提升2.9%~7.4%，且对绝对质量的建模能力得到验证。

Conclusion: PRM及其离散实现OPRM结合RgFT，有效克服了传统方法的局限性，实现了更准确、数据高效的奖励建模，尤其在捕捉绝对质量方面表现突出。

Abstract: Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs typically demand costly point-wise supervision, while DRMs produce uncalibrated relative scores that lack probabilistic interpretation. To address these challenges, we introduce a novel reward modeling paradigm: Probabilistic Reward Model (PRM). Instead of modeling reward as a deterministic scalar, our approach treats it as a random variable, learning a full probability distribution for the quality of each response. To make this paradigm practical, we present its closed-form, discrete realization: the Ordinal Probabilistic Reward Model (OPRM), which discretizes the quality score into a finite set of ordinal ratings. Building on OPRM, we propose a data-efficient training strategy called Region Flooding Tuning (RgFT). It enables rewards to better reflect absolute text quality by incorporating quality-level annotations, which guide the model to concentrate the probability mass within corresponding rating sub-regions. Experiments on various reward model benchmarks show that our method improves accuracy by $\textbf{2.9%}\sim\textbf{7.4%}$ compared to prior reward models, demonstrating strong performance and data efficiency. Analysis of the score distribution provides evidence that our method captures not only relative rankings but also absolute quality.

</details>


### [67] [$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2602.12674)
*Yuang Cai,Yuyu Yuan*

Main category: cs.CL

TL;DR: 提出了一种名为$\mathcal{X}$-KD的新型知识蒸馏框架，通过模拟教师模型在原始学习环境中的奖励函数，使学生模型能够复现其学习过程。该方法基于近似变分奖励模仿学习（AVRIL），联合建模奖励函数与策略蒸馏，实现学生与原始奖励函数的一致性。理论分析表明其符合监督学习框架，适用于序列级和基于差异的蒸馏方法，具有通用性和灵活性。实验显示其在摘要生成、机器翻译和算术推理任务中优于现有基线，且在性能与多样性、数据效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法仅关注模仿教师的行为，忽视了教师知识形成的原始学习环境。为提升学生模型的学习质量，需还原教师的内在学习机制，因此提出从经验学习和逆强化学习角度出发的新框架。

Method: $\\mathcal{X}$-KD采用近似变分奖励模仿学习（AVRIL）框架，联合估计教师的原始奖励函数并进行策略蒸馏，使学生模型在与教师相同的“学习环境”中训练，从而更真实地继承教师的知识结构。

Result: 在抽象摘要、机器翻译和算术推理任务上，$\\mathcal{X}$-KD显著优于广义知识蒸馏和MiniLLM等基线方法；同时在性能-多样性权衡和数据效率方面也表现出色。

Conclusion: $\\mathcal{X}$-KD通过还原教师的学习环境，实现了更高质量的知识迁移，具备良好的通用性、灵活性和高效性，为大语言模型知识蒸馏提供了新范式。

Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning environment that shaped the teacher's knowledge. Inspired by the experiential learning theory and inverse reinforcement learning, we propose Experiential Knowledge Distillation ($\mathcal{X}$-KD), a novel and general framework that enables student models to learn in the teacher's original learning environment. $\mathcal{X}$-KD adopts the Approximated Variational Reward Imitation Learning (AVRIL) framework to jointly model the teacher's original reward function and perform policy distillation, encouraging consistency between the student policy and the original reward function. Our derivation demonstrates that $\mathcal{X}$-KD follows the supervised learning framework and applies to both sequence-level and divergence-based distillation methods, underlining the simplicity and flexibility of our approach. Empirical results show that $\mathcal{X}$-KD outperforms the generalized KD and MiniLLM baselines on abstractive summarization, machine translation, and arithmetic reasoning tasks. Additionally, $\mathcal{X}$-KD achieves better performance-diversity trade-off and data efficiency than baseline KD approaches.

</details>


### [68] [ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter](https://arxiv.org/abs/2602.12709)
*Yixin Chen,Ying Xiong,Shangyu Wu,Xiangrui Ke,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: ReFilter 是一种新的基于潜在空间的融合框架，通过分词级过滤与融合解决大规模检索时的无关或冗余内容问题，在多个通用和生物医学问答基准上表现出色，尤其在零样本迁移下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有内部融合方法在检索数量增加时难以有效处理冗余和无关内容，且推理成本上升，因此需要一种更高效的融合机制以支持大规模检索。

Method: ReFilter 包含三个组件：上下文编码器用于编码上下文特征，门控过滤器对每个词元进行加权，词元融合模块将加权特征融入 LLM 的隐藏状态中，实现细粒度的过滤与融合。

Result: 在四个通用领域 QA 基准上，ReFilter 在域内适应和域外迁移中均取得最佳平均性能；在五个生物医学 QA 基准上实现零样本迁移，使用 Qwen2.5-14B-Instruct 达到 70.01% 的平均准确率。

Conclusion: ReFilter 有效解决了大规模检索中的冗余与无关内容问题，具备良好的泛化能力，尤其在零样本场景下表现突出，为 RAG 系统提供了高效可靠的融合方案。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples into the LLMs, where existing internal fusion approaches broadly fall into query-based fusion, parametric fusion, and latent-based fusion. Despite their effectiveness at modest retrieval scales, these methods often fail to scale gracefully as the number of retrieved candidates k increases: Larger k improves evidence coverage, yet realistic top-k retrieval inevitably contains irrelevant or redundant content and increases the inference cost.
  To address these limitations, we propose ReFilter, a novel latent-based fusion framework that performs token-level filtering and fusion. ReFilter consists of three key components: a context encoder for encoding context features, a gated filter for weighting each token, and a token fusion module for integrating the weighted token feature into the LLM's hidden states. Our experiments across four general-domain QA benchmarks show that ReFilter consistently achieves the best average performance under both in-domain adaptation and out-of-domain transfer. ReFilter further generalizes to five biomedical QA benchmarks in zero-shot transfer without domain fine-tuning, reaching 70.01% average accuracy with Qwen2.5-14B-Instruct.

</details>


### [69] [Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting](https://arxiv.org/abs/2602.12746)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: Lamer-SSL 是一种参数高效的框架，通过引入层感知的 LoRA 专家混合（Lamer）模块和回放策略，有效解决自监督语音模型在新语言泛化和持续训练中的遗忘问题。该方法在保持低参数更新率（仅2.14%可训练参数）的情况下，显著提升模型在语音识别和语言识别任务上的多语言性能。


<details>
  <summary>Details</summary>
Motivation: 自监督语音模型在新语言泛化和持续训练中存在知识遗忘问题，亟需一种高效且能保留历史知识的训练机制。

Method: 提出 Lamer-SSL 框架，结合层感知的 LoRA 专家混合模块与回放策略；通过动态分配专家至深层以增强语义表示，并利用少量历史数据进行知识回放，防止遗忘。

Result: 在 ASR 和 LID 任务上，Lamer-SSL 能有效扩展至新语言，同时保持对已有语言的高性能，仅需 2.14% 的可训练参数。

Conclusion: Lamer-SSL 为自监督语音模型提供了高效、可扩展的多语言持续学习解决方案，兼具参数效率与强泛化能力。

Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient framework that integrates a Layer-Aware MixturE of LoRA Experts (Lamer) module with a replay strategy. The Lamer module enables flexible balancing between shared and language-specific representations, while layer-aware expert allocation assigns more experts to deeper layers where semantic information is richer. Meanwhile, the replay strategy retains prior knowledge using minimal data, mitigating forgetting during continual training. Experiments on automatic speech recognition (ASR) and language identification (LID) demonstrate that Lamer-SSL extends self-supervised models to new languages effectively while maintaining strong performance on previously learned languages with only 2.14% parameters being trainable.

</details>


### [70] [Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks](https://arxiv.org/abs/2602.12759)
*Elena Alvarez-Mellado,Julio Gonzalo*

Main category: cs.CL

TL;DR: 本文提出一种基于错误分析的序列标注任务评估方法，通过手工构建涵盖各种语言特征（如形状、长度、大小写、句中位置等）的小规模测试集，替代传统依赖大规模真实数据的做法。该方法能诊断模型系统性弱点，提供可操作的改进方向，并具有较强预测能力（外部数据上中位相关性达0.85）。


<details>
  <summary>Details</summary>
Motivation: 标准NLP评估仅给出平均性能比较，无法指导改进，且在外部数据上表现不可靠。需要一种更深入、可诊断、可预测的评估方法。

Method: 手工设计小规模测试集，覆盖序列标注中可能出现的所有跨度属性（如形状、长度、大小写、句中位置等），以实现对模型错误的全面分析。

Result: 该方法在西班牙语英语词识别基准上验证有效，结果具有诊断性、可操作性和预测性；在外部数据上的性能预测中位相关性达到0.85。

Conclusion: 所提出的评估方法超越了传统平均性能指标，能够帮助识别模型缺陷、指导改进，并准确预测模型在新分布下的表现，适用于序列标注任务的稳健评估。

Abstract: Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being better than A on outside data. We propose an evaluation methodology for sequence labeling tasks grounded on error analysis that provides both quantitative and qualitative information on where systems must be improved and predicts how models will perform on a different distribution. The key is to create test sets that, contrary to common practice, do not rely on gathering large amounts of real-world in-distribution scraped data, but consists in handcrafting a small set of linguistically motivated examples that exhaustively cover the range of span attributes (such as shape, length, casing, sentence position, etc.) a system may encounter in the wild. We demonstrate this methodology on a benchmark for anglicism identification in Spanish. Our methodology provides results that are diagnostic (because they help identify systematic weaknesses in performance), actionable (because they can inform which model is better suited for a given scenario) and predictive: our method predicts model performance on external datasets with a median correlation of 0.85.

</details>


### [71] [Aspect-Based Sentiment Analysis for Future Tourism Experiences: A BERT-MoE Framework for Persian User Reviews](https://arxiv.org/abs/2602.12778)
*Hamidreza Kazemi Taskooh,Taha Zare Harofte*

Main category: cs.CL

TL;DR: 本研究提出一种基于BERT的混合模型，结合Top-K路由和辅助损失函数，用于波斯语旅游领域用户评论的方面情感分析（ABSA），以应对低资源语言的挑战。该模型在9,558条标注评论上进行整体情感分类，并对六个旅游相关方面（主人、价格、位置、设施、清洁度、连通性）进行多标签方面提取，采用动态路由实现集成ABSA。数据集包含来自伊朗住宿平台Jabama的58,473条预处理评论，经人工标注。所提模型在ABSA任务中达到90.6%的加权F1分数，优于基线BERT（89.25%）和标准混合方法（85.7%）。同时，相比密集型BERT，GPU功耗降低39%，支持可持续人工智能部署，符合联合国可持续发展目标9和12。分析显示清洁度和设施提及率较高，为关键因素。本研究是首个聚焦波斯语旅游评论的ABSA研究，并公开发布标注数据集，以促进未来多语言旅游NLP研究。


<details>
  <summary>Details</summary>
Motivation: 针对波斯语等低资源语言在旅游领域方面情感分析（ABSA）中的挑战，现有方法在准确性和效率方面表现不足，亟需高效且精准的模型。同时，可持续人工智能部署的需求日益增长，需要降低计算资源消耗。因此，本研究旨在构建一个高效、高精度的ABSA框架，推动多语言旅游NLP的发展。

Method: 提出一种基于BERT的混合模型，引入Top-K路由机制与辅助损失函数，以缓解路由崩溃问题并提升效率。流程包括：(1) 使用BERT对9,558条标注评论进行整体情感分类；(2) 多标签方面提取，识别六类旅游相关方面；(3) 通过动态路由实现集成式ABSA。训练基于58,473条来自Jabama平台的预处理评论，人工标注了方面与情感。

Result: 所提模型在方面情感分析任务中取得90.6%的加权F1分数，显著优于基线BERT（89.25%）和标准混合方法（85.7%）。此外，模型在推理阶段实现39%的GPU功耗降低，有效提升计算效率。分析发现清洁度和设施是被频繁提及的关键方面。

Conclusion: 本研究首次构建面向波斯语旅游评论的高效高精度ABSA系统，验证了混合路由架构在低资源语言中的有效性。所提出的模型兼具高性能与低能耗优势，符合可持续发展要求。公开的数据集将有力推动多语言旅游文本分析研究，具有重要的学术与应用价值。

Abstract: This study advances aspect-based sentiment analysis (ABSA) for Persian-language user reviews in the tourism domain, addressing challenges of low-resource languages. We propose a hybrid BERT-based model with Top-K routing and auxiliary losses to mitigate routing collapse and improve efficiency. The pipeline includes: (1) overall sentiment classification using BERT on 9,558 labeled reviews, (2) multi-label aspect extraction for six tourism-related aspects (host, price, location, amenities, cleanliness, connectivity), and (3) integrated ABSA with dynamic routing. The dataset consists of 58,473 preprocessed reviews from the Iranian accommodation platform Jabama, manually annotated for aspects and sentiments. The proposed model achieves a weighted F1-score of 90.6% for ABSA, outperforming baseline BERT (89.25%) and a standard hybrid approach (85.7%). Key efficiency gains include a 39% reduction in GPU power consumption compared to dense BERT, supporting sustainable AI deployment in alignment with UN SDGs 9 and 12. Analysis reveals high mention rates for cleanliness and amenities as critical aspects. This is the first ABSA study focused on Persian tourism reviews, and we release the annotated dataset to facilitate future multilingual NLP research in tourism.

</details>


### [72] [RAT-Bench: A Comprehensive Benchmark for Text Anonymization](https://arxiv.org/abs/2602.12806)
*Nataša Krčo,Zexi Yao,Matthieu Meeus,Yves-Alexandre de Montjoye*

Main category: cs.CL

TL;DR: 本文提出RAT-Bench，一个基于再识别风险的文本匿名化工具综合基准。通过美国人口统计数据生成包含多种直接和间接标识符的合成文本，评估了基于NER和LLM的匿名化工具。研究发现，即使最先进的工具在处理非标准写法的直接标识符或利用间接标识符进行再识别时仍不完善，但基于LLM的匿名化工具在隐私-效用权衡上表现更优，且跨语言效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化工具主要评估其移除特定标识符的能力，但缺乏对防止再识别有效性的系统性评估。随着个人数据用于训练和查询大语言模型，亟需更全面的评估框架来衡量匿名化工具的真实隐私保护能力。

Method: 使用美国人口统计数据生成涵盖多个领域、语言和难度级别的合成文本；采用基于LLM的攻击者模型，分析匿名化后文本中可推断出的属性，量化再识别风险，并考虑标识符的差异化影响。

Result: 不同工具性能差异显著；即使是最佳工具也无法完全防止再识别，尤其在直接标识符非标准书写或存在间接标识符时；基于LLM的匿名化工具虽计算成本较高，但在隐私保护与信息保留之间取得更好平衡，且跨语言表现优异。

Conclusion: 建议未来匿名化工具应注重提升对非标准标识符和间接标识符的处理能力，同时鼓励社区扩展该基准以覆盖更多地理区域。研究将发布RAT-Bench，推动开放协作。

Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio or Anthropic's PII purifier. These tools have traditionally been evaluated on their ability to remove specific identifiers (e.g., names), yet their effectiveness at preventing re-identification remains unclear. We introduce RAT-Bench, a comprehensive benchmark for text anonymization tools based on re-identification risk. Using U.S. demographic statistics, we generate synthetic text containing various direct and indirect identifiers across domains, languages, and difficulty levels. We evaluate a range of NER- and LLM-based text anonymization tools and, based on the attributes an LLM-based attacker is able to correctly infer from the anonymized text, we report the risk of re-identification in the U.S. population, while properly accounting for the disparate impact of identifiers. We find that, while capabilities vary widely, even the best tools are far from perfect in particular when direct identifiers are not written in standard ways and when indirect identifiers enable re-identification. Overall we find LLM-based anonymizers, including new iterative anonymizers, to provide a better privacy-utility trade-off albeit at a higher computational cost. Importantly, we also find them to work well across languages. We conclude with recommendations for future anonymization tools and will release the benchmark and encourage community efforts to expand it, in particular to other geographies.

</details>


### [73] [Left-right asymmetry in predicting brain activity from LLMs' representations emerges with their formal linguistic competence](https://arxiv.org/abs/2602.12811)
*Laurent Bonnasse-Gahot,Christophe Pallier*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLM）在训练过程中，其内部激活与人类大脑活动之间的关联性如何随时间演变，并特别关注左右脑不对称性的出现。通过分析OLMo-2 7B模型在不同训练阶段的表现以及英语参与者的fMRI数据，发现这种左右不对称性与模型的正式语言能力（如语法判断、生成合乎语法的文本）密切相关。相反，该不对称性与算术、形式语言（如Dyck语言）或需要世界知识和推理的任务无关。研究结果在另一类模型（Pythia）和法语中也得到验证，表明左右脑预测力的不对称性主要反映了模型对语言结构模式掌握程度的提升。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型在训练过程中，其内部表征与人类大脑活动之间的关联为何表现出左半球优于右半球的不对称性，进而揭示这一现象背后所依赖的语言能力类型。

Method: 使用OLMo-2 7B模型在多个训练检查点上进行测试，结合英语受试者的fMRI数据，对比模型在各类任务上的表现（如语法判断、文本生成、算术、世界知识推理等）与脑活动预测性能的左右不对称性变化趋势。进一步将结果扩展至Pythia模型和法语数据集以验证普适性。

Result: 左-右脑不对称性在模型正式语言能力（如语法识别和生成）发展过程中显著增强，而在非语言性任务（如算术、逻辑推理、世界知识）中无明显关联。该模式在不同模型架构和语言中均一致出现。

Conclusion: 大型语言模型中脑活动预测的左右不对称性，本质上反映了其对形式语言规则掌握程度的提升，说明语言结构知识是驱动该不对称性的核心因素。

Abstract: When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the training of an LLM progresses, the performance in predicting brain activity from its internal activations improves more in the left hemisphere than in the right one. The aim of the present work is to understand which kind of competence acquired by the LLMs underlies the emergence of this left-right asymmetry. Using the OLMo-2 7B language model at various training checkpoints and fMRI data from English participants, we compare the evolution of the left-right asymmetry in brain scores alongside performance on several benchmarks. We observe that the asymmetry co-emerges with the formal linguistic abilities of the LLM. These abilities are demonstrated in two ways: by the model's capacity to assign a higher probability to an acceptable sentence than to a grammatically unacceptable one within a minimal contrasting pair, or its ability to produce well-formed text. On the opposite, the left-right asymmetry does not correlate with the performance on arithmetic or Dyck language tasks; nor with text-based tasks involving world knowledge and reasoning. We generalize these results to another family of LLMs (Pythia) and another language, namely French. Our observations indicate that the left-right asymmetry in brain predictivity matches the progress in formal linguistic competence (knowledge of linguistic patterns).

</details>


### [74] [BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.12889)
*Jiangxi Chen,Qian Liu*

Main category: cs.CL

TL;DR: BaziQA-Benchmark 是一个用于评估大语言模型在符号和时间组合推理方面能力的标准基准，基于2021–2025年全球算命大赛的200道专业精选多选题。该基准要求模型在固定符号图表和相互作用的时间条件下进行结构化推理，支持客观评分与跨年份、领域和模型家族的可控比较。研究采用多轮设置评估现代语言模型，并分析其在时间难度、推理领域和推理协议上的表现差异。引入轻量级结构化推理协议以约束推理顺序，不增加领域知识。结果显示，模型虽显著优于随机猜测，但远未达到饱和，对时间组合和推理顺序敏感，且在精确时间定位和多条件符号判断上存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法多依赖轶事或提示驱动，缺乏客观性和可比性。为实现对大语言模型在复杂符号与时间推理能力上的标准化评估，需要一个结构化、可重复、可比较的基准。

Method: 构建基于真实竞赛题目的标准化基准 BaziQA-Benchmark；设计多轮推理评估框架；引入轻量级结构化推理协议以控制推理顺序；对多种语言模型进行系统评估并分析性能差异。

Result: 模型表现显著优于随机水平，但在时间组合推理、推理顺序敏感性、精确时间定位和多条件符号判断上仍存在明显缺陷，表现出系统性失败模式。

Conclusion: BaziQA-Benchmark 为评估大语言模型在符号与时间组合推理方面的能力提供了可靠、可复现的基准。当前模型仍难以处理复杂的时序逻辑与符号交互，需进一步改进推理机制与结构化推理能力。

Abstract: We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global Fortune-teller Competition (2021--2025), where each instance requires structured inference over a fixed symbolic chart and interacting temporal conditions. Unlike anecdotal or prompt-driven evaluations, BaziQA-Benchmark enables objective scoring and controlled comparison across years, domains, and model families. We evaluate contemporary language models under a multi-turn setting and analyze performance variation across temporal difficulty, reasoning domains, and inference protocols.To further probe reasoning behavior, we introduce a lightweight Structured Reasoning Protocol that constrains inference order without adding domain knowledge. Results show that models consistently outperform chance but remain far from saturation, exhibiting pronounced sensitivity to temporal composition and reasoning order, as well as systematic failures on precise temporal localization and multi-condition symbolic judgments.

</details>


### [75] [ViMedCSS: A Vietnamese Medical Code-Switching Speech Dataset & Benchmark](https://arxiv.org/abs/2602.12911)
*Tung X. Nguyen,Nhu Vo,Giang-Son Nguyen,Duy Mai Hoang,Chien Dinh Huynh,Inigo Jauregi Unanue,Massimo Piccardi,Wray Buntine,Dung D. Le*

Main category: cs.CL

TL;DR: 本文构建了一个34小时的越南语医学代码切换语音数据集ViMedCSS，包含16,576个包含至少一个英语医学术语的语句，旨在解决越南语医疗交流中英语术语识别难题。通过评估多种先进ASR模型及微调策略，发现越南语优化模型在一般段落上表现更好，而多语言预训练有助于捕捉英语插入内容，两者的结合能实现整体与代码切换准确率的最佳平衡。该研究提供了首个越南语医学代码切换的基准，为低资源、多语言ASR系统的领域适应提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 越南语医疗交流中常见的英语术语插入（如药物名或程序名）给自动语音识别（ASR）系统带来挑战，尤其是对低资源语言越南语而言。现有ASR系统难以准确识别越南语句子中的英语医学术语，且缺乏针对此问题的基准数据集。

Method: 构建了包含16,576个语句的ViMedCSS数据集，涵盖五个医学主题的双语词典中的英语医学术语；评估多个先进ASR模型，并测试不同微调策略以提升医学术语识别性能。

Result: 越南语优化模型在一般语音片段上表现更优，多语言预训练有助于识别英语插入部分；结合两者方法可实现整体与代码切换识别准确率的最佳平衡。

Conclusion: 本研究首次建立了越南语医学代码切换的基准数据集ViMedCSS，揭示了结合越南语优化与多语言预训练的微调策略在提升低资源多语言医疗ASR性能方面的有效性，为未来相关系统设计提供重要参考。

Abstract: Code-switching (CS), which is when Vietnamese speech uses English words like drug names or procedures, is a common phenomenon in Vietnamese medical communication. This creates challenges for Automatic Speech Recognition (ASR) systems, especially in low-resource languages like Vietnamese. Current most ASR systems struggle to recognize correctly English medical terms within Vietnamese sentences, and no benchmark addresses this challenge. In this paper, we construct a 34-hour \textbf{Vi}etnamese \textbf{Med}ical \textbf{C}ode-\textbf{S}witching \textbf{S}peech dataset (ViMedCSS) containing 16,576 utterances. Each utterance includes at least one English medical term drawn from a curated bilingual lexicon covering five medical topics. Using this dataset, we evaluate several state-of-the-art ASR models and examine different specific fine-tuning strategies for improving medical term recognition to investigate the best approach to solve in the dataset. Experimental results show that Vietnamese-optimized models perform better on general segments, while multilingual pretraining helps capture English insertions. The combination of both approaches yields the best balance between overall and code-switched accuracy. This work provides the first benchmark for Vietnamese medical code-switching and offers insights into effective domain adaptation for low-resource, multilingual ASR systems.

</details>


### [76] [When Words Don't Mean What They Say: Figurative Understanding in Bengali Idioms](https://arxiv.org/abs/2602.12921)
*Adib Sakhawat,Shamim Ara Parveen,Md Ruhul Amin,Shamim Al Mahmud,Md Saiful Islam,Tahera Khatun*

Main category: cs.CL

TL;DR: 本文提出一个包含10,361个孟加拉语成语的大规模、文化背景丰富的语料库，并建立了一个由19个字段组成的全面标注体系，涵盖语义、句法、文化和宗教维度。通过评估30个先进的多语言和指令微调大语言模型在推断隐喻意义任务上的表现，发现所有模型的准确率均未超过50%，远低于人类水平（83.4%），揭示了现有模型在跨语言与文化推理方面的严重局限性。研究释放了该语料库和基准测试，为提升孟加拉语及其他低资源语言的隐喻理解与文化嵌入能力提供了基础支撑。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理隐喻语言方面仍面临挑战，尤其对于低资源语言而言。现有的数据集和评估基准不足以支持对文化背景复杂性的充分建模，因此亟需构建更丰富、结构化的资源来推动该领域的发展。

Method: 构建了一个大规模的孟加拉语成语语料库，采用19字段标注体系，经专家共识协商完善；选取30个先进多语言及指令微调的语言模型，在该语料库上进行隐喻意义推断任务的评估，以建立可靠基准。

Result: 所有测试的模型在成语隐喻理解任务中的准确率均未超过50%，而人类表现达到83.4%，显示出显著性能差距，表明当前模型在跨语言与文化推理方面存在明显不足。

Conclusion: 本研究通过发布新的成语数据集与基准，为推进孟加拉语及其他低资源语言的隐喻理解与文化嵌入能力奠定了基础，有助于未来模型在复杂语义与文化语境下的改进。

Abstract: Figurative language understanding remains a significant challenge for Large Language Models (LLMs), especially for low-resource languages. To address this, we introduce a new idiom dataset, a large-scale, culturally-grounded corpus of 10,361 Bengali idioms. Each idiom is annotated under a comprehensive 19-field schema, established and refined through a deliberative expert consensus process, that captures its semantic, syntactic, cultural, and religious dimensions, providing a rich, structured resource for computational linguistics. To establish a robust benchmark for Bangla figurative language understanding, we evaluate 30 state-of-the-art multilingual and instruction-tuned LLMs on the task of inferring figurative meaning. Our results reveal a critical performance gap, with no model surpassing 50% accuracy, a stark contrast to significantly higher human performance (83.4%). This underscores the limitations of existing models in cross-linguistic and cultural reasoning. By releasing the new idiom dataset and benchmark, we provide foundational infrastructure for advancing figurative language understanding and cultural grounding in LLMs for Bengali and other low-resource languages.

</details>


### [77] [Curriculum Learning and Pseudo-Labeling Improve the Generalization of Multi-Label Arabic Dialect Identification Models](https://arxiv.org/abs/2602.12937)
*Ali Mekky,Mohamed El Zeftawy,Lara Hassan,Amr Keleg,Preslav Nakov*

Main category: cs.CL

TL;DR: 该研究将阿拉伯语方言识别（ADI）从传统的单标签分类转向多标签分类，针对现有单标签数据集无法直接用于多标签任务的问题，提出通过GPT-4o与二元可接受性分类器生成自动多标签标注，并结合阿拉伯语方言程度（ALDi）进行聚合。采用基于BERT的模型并引入课程学习策略以应对方言复杂性和标签基数差异，最终在MLADI排行榜上达到0.69的宏平均F1，显著优于之前的0.55。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语方言识别（ADI）主要依赖单标签数据集，但实际中句子可能被多个方言接受，因此将AD I视为多标签任务更具现实意义；然而缺乏大规模多标签训练资源，且直接复用单标签数据面临负样本选择困难的问题。

Method: 利用GPT-4o和二元方言可接受性分类器生成自动多标签标注，通过阿拉伯语方言程度（ALDi）指导标注聚合；训练基于BERT的多标签分类器时采用与方言复杂性和标签基数相匹配的课程学习策略。

Result: 所提出的LAHJATBERT模型在MLADI基准上取得0.69的宏平均F1，超越此前最强系统（0.55），证明了方法的有效性。

Conclusion: 本研究构建了首个大规模、高质量的多标签阿拉伯语方言识别数据集，并提出有效的多标签建模框架，显著提升了多标签方言识别性能，为后续研究提供了重要资源与方法基础。

Abstract: Being modeled as a single-label classification task for a long time, recent work has argued that Arabic Dialect Identification (ADI) should be framed as a multi-label classification task. However, ADI remains constrained by the availability of single-label datasets, with no large-scale multi-label resources available for training. By analyzing models trained on single-label ADI data, we show that the main difficulty in repurposing such datasets for Multi-Label Arabic Dialect Identification (MLADI) lies in the selection of negative samples, as many sentences treated as negative could be acceptable in multiple dialects. To address these issues, we construct a multi-label dataset by generating automatic multi-label annotations using GPT-4o and binary dialect acceptability classifiers, with aggregation guided by the Arabic Level of Dialectness (ALDi). Afterward, we train a BERT-based multi-label classifier using curriculum learning strategies aligned with dialectal complexity and label cardinality. On the MLADI leaderboard, our best-performing LAHJATBERT model achieves a macro F1 of 0.69, compared to 0.55 for the strongest previously reported system. Code and data are available at https://mohamedalaa9.github.io/lahjatbert/.

</details>


### [78] [ProbeLLM: Automating Principled Diagnosis of LLM Failures](https://arxiv.org/abs/2602.12966)
*Yue Huang,Zhengzhe Jiang,Yuchen Ma,Yu Jiang,Xiangqi Wang,Yujun Zhou,Yuexing Hao,Kehan Guo,Pin-Yu Chen,Stefan Feuerriegel,Xiangliang Zhang*

Main category: cs.CL

TL;DR: ProbeLLM是一个基准无关的自动化探测框架，通过层次化蒙特卡洛树搜索，将大语言模型的失败从孤立案例提升到结构化的失败模式。它在全局探索新失败区域与局部细化重复错误模式之间合理分配探测预算，结合可验证测试用例和工具增强生成与验证，确保发现的失败基于可靠证据。通过失败感知嵌入和边界感知归纳，探测到的失败被整合为可解释的失败模式。在多个基准和模型上，ProbeLLM揭示了更广泛、更清晰、更细粒度的失败图景，推动评估从案例中心转向系统性弱点发现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型快速演进，静态评估方法已无法跟上，现有自动化探测方法常局限于孤立失败案例，缺乏对探索过程的系统控制，且难以揭示模型弱点的内在结构。因此需要一种能系统识别和理解模型失败模式的新方法。

Method: ProbeLLM采用层次化蒙特卡洛树搜索（MCTS）进行探测，动态分配有限的探测预算，在全局探索新失败区域与局部精炼常见错误模式之间取得平衡；通过工具增强的生成与验证机制，仅关注可验证的测试用例，确保结果可靠性；利用失败感知嵌入与边界感知归纳技术，将分散的失败案例聚类为可解释的失败模式。

Result: 在多种基准和大语言模型上，ProbeLLM揭示的失败图景比静态基准和先前自动化方法更全面、更清晰、更精细，能够系统识别并分类模型的深层弱点，支持从个案评估向结构化弱点发现转变。

Conclusion: ProbeLLM成功将大语言模型的失败探测从孤立案例提升至结构化失败模式层面，提供了可解释、可复现、可扩展的弱点发现框架，为下一代模型评估与改进奠定了基础。

Abstract: Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled control over exploration, and provide limited insight into the underlying structure of model weaknesses. We propose ProbeLLM, a benchmark-agnostic automated probing framework that elevates weakness discovery from individual failures to structured failure modes. ProbeLLM formulates probing as a hierarchical Monte Carlo Tree Search, explicitly allocating limited probing budgets between global exploration of new failure regions and local refinement of recurring error patterns. By restricting probing to verifiable test cases and leveraging tool-augmented generation and verification, ProbeLLM grounds failure discovery in reliable evidence. Discovered failures are further consolidated into interpretable failure modes via failure-aware embeddings and boundary-aware induction. Across diverse benchmarks and LLMs, ProbeLLM reveals substantially broader, cleaner, and more fine-grained failure landscapes than static benchmarks and prior automated methods, supporting a shift from case-centric evaluation toward principled weakness discovery.

</details>


### [79] [SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents](https://arxiv.org/abs/2602.12984)
*Yujiong Shen,Yajie Yang,Zhiheng Xi,Binze Hu,Huayu Sha,Jiazheng Zhang,Qiyuan Peng,Junlin Shang,Jixuan Huang,Yutao Fan,Jingqi Tong,Shihan Dou,Ming Zhang,Lei Bai,Zhenfei Yin,Tao Gui,Xingjun Ma,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 提出SciAgentGym和SciAgentBench，构建科学领域工具使用评估环境与基准，揭示当前模型在复杂科学任务中工具协同能力的瓶颈，并提出基于依赖图的数据合成方法SciForge，通过微调提升模型表现，实现超越更大模型的性能及跨领域迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有科学推理基准忽视了智能体对复杂工具链的协调能力，难以评估其在真实科学工作流中的表现，亟需更贴近实际科研流程的评估体系与训练方法。

Method: 构建包含1780个领域工具的交互环境SciAgentGym，设计分层评估框架SciAgentBench；采用依赖图建模工具动作空间，生成逻辑连贯的训练轨迹，用于微调模型SciAgent-8B。

Result: GPT-5在长程任务中成功率从60.6%降至30.9%，而经SciForge训练的SciAgent-8B在性能上超越更大的Qwen3-VL-235B-Instruct，并展现出良好的跨领域迁移能力。

Conclusion: 科学智能体的自主推理能力受限于复杂工具链的协同执行，通过结构化数据合成可显著提升其科学任务处理能力，为下一代自主科研智能体的发展提供可行路径。

Abstract: Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.

</details>


### [80] [Evaluating the Homogeneity of Keyphrase Prediction Models](https://arxiv.org/abs/2602.12989)
*Maël Houbre,Florian Boudin,Beatrice Daille*

Main category: cs.CL

TL;DR: 本文提出一种评估关键词预测模型同质性的方法，并研究生成式模型中‘缺席关键词’能力是否有助于提升同质性。出乎意料的是，实验表明关键词提取方法在同质性上与生成模型相当，且生成缺席关键词的能力反而可能降低同质性。


<details>
  <summary>Details</summary>
Motivation: 当前基准未涵盖关键词预测模型的同质性，而生成模型具备预测文本中未出现的‘缺席关键词’的能力，理论上应提升对相似主题文档的一致性索引能力，但该假设尚未被验证。

Method: 提出一种新的评估方法，用于衡量关键词预测模型在处理相似主题文档时的同质性表现，并通过对比提取型与生成型模型在相同任务下的表现，分析缺席关键词生成能力的影响。

Result: 关键词提取模型在同质性方面表现不逊于生成模型；生成缺席关键词的能力反而可能削弱模型的同质性，说明该能力并非总是有益。

Conclusion: 尽管生成式模型能预测缺席关键词，但这并不必然带来更高的同质性；关键词提取方法在一致性索引方面具有竞争力，且生成缺席关键词的能力可能产生负面效应。

Abstract: Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.

</details>


### [81] [Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models](https://arxiv.org/abs/2602.12996)
*Hao Chen,Ye He,Yuchun Fan,Yukun Yan,Zhenghao Liu,Qingfu Zhu,Maosong Sun,Wanxiang Che*

Main category: cs.CL

TL;DR: 本文提出了一种新的元认知框架，通过差异化干预与对齐来实现可靠的知识增强。该框架利用内部认知信号将知识空间划分为已掌握、混淆和缺失区域，指导有针对性的知识扩展，并引入认知一致性机制以同步主观确定性与客观准确性，从而确保知识边界的校准。实验表明，该框架在多个基准上均优于现有方法，不仅提升了知识能力，还促进了模型更合理地区分已知与未知的认知行为。


<details>
  <summary>Details</summary>
Motivation: 现有知识增强方法假设模型性能等于内部知识，忽视了知识-信心差距导致的过度自信错误或不确定真相的问题。

Method: 提出一种元认知框架，利用内部认知信号划分知识空间（已掌握、混淆、缺失），并引入认知一致性机制以对齐主观确定性与客观准确性，实现差异化干预与知识对齐。

Result: 实验结果表明，该框架在多个任务中持续优于强基线，有效提升知识能力并增强模型区分已知与未知的能力。

Conclusion: 所提出的元认知框架通过差异化干预与认知一致性，有效弥合知识-信心差距，显著提升大语言模型在知识密集型任务中的可靠性与认知合理性。

Abstract: Knowledge augmentation has significantly enhanced the performance of Large Language Models (LLMs) in knowledge-intensive tasks. However, existing methods typically operate on the simplistic premise that model performance equates with internal knowledge, overlooking the knowledge-confidence gaps that lead to overconfident errors or uncertain truths. To bridge this gap, we propose a novel meta-cognitive framework for reliable knowledge augmentation via differentiated intervention and alignment. Our approach leverages internal cognitive signals to partition the knowledge space into mastered, confused, and missing regions, guiding targeted knowledge expansion. Furthermore, we introduce a cognitive consistency mechanism to synchronize subjective certainty with objective accuracy, ensuring calibrated knowledge boundaries. Extensive experiments demonstrate the our framework consistently outperforms strong baselines, validating its rationality in not only enhancing knowledge capabilities but also fostering cognitive behaviors that better distinguish knowns from unknowns.

</details>


### [82] [Can we trust AI to detect healthy multilingual English speakers among the cognitively impaired cohort in the UK? An investigation using real-world conversational speech](https://arxiv.org/abs/2602.13047)
*Madhurananda Pahar,Caitlin Illingworth,Dorota Braun,Bahman Mirheidari,Lise Sproson,Daniel Blackburn,Heidi Christensen*

Main category: cs.CL

TL;DR: 本研究首次发现，尽管当前人工智能模型整体表现良好，但在检测英国少数族裔背景的多语言人士时存在偏见，尤其对具有特定口音（南约克郡）或多语言背景者更易误判为认知衰退。这些模型在记忆、流畅性和阅读任务中对多语言者表现出显著偏差，且在使用公开数据集DementiaBank训练时问题更严重。因此，现有AI工具尚不可靠用于该人群的临床诊断。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能模型在识别认知衰退方面的可信度，特别是是否存在对英国少数族裔多语言者的偏见，以确保其在临床应用中的公平性和有效性。

Method: 通过在全国范围内招募单语者，并从谢菲尔德和布拉德福德四个社区中心招募多语言者（包括索马里语、中文、南亚语言使用者），结合不同约克郡口音（西约克与南约克），利用声学与语言特征构建分类与回归模型，评估其在认知任务中的表现，并对比在DementiaBank数据集上训练的结果。

Result: 自动语音识别系统无显著群体差异，但基于声学与语言特征的分类与回归模型对多语言者表现出明显偏见，尤其在记忆、流畅性与阅读任务中；多语言者更易被误判为患有认知障碍，且南约克口音者被误判为更严重认知衰退的风险更高。

Conclusion: 当前AI工具在识别英国少数族裔多语言者时存在显著偏见，不适合直接用于临床诊断，未来需开发更具泛化能力且能减轻偏见的模型。

Abstract: Conversational speech often reveals early signs of cognitive decline, such as dementia and MCI. In the UK, one in four people belongs to an ethnic minority, and dementia prevalence is expected to rise most rapidly among Black and Asian communities. This study examines the trustworthiness of AI models, specifically the presence of bias, in detecting healthy multilingual English speakers among the cognitively impaired cohort, to make these tools clinically beneficial. For experiments, monolingual participants were recruited nationally (UK), and multilingual speakers were enrolled from four community centres in Sheffield and Bradford. In addition to a non-native English accent, multilinguals spoke Somali, Chinese, or South Asian languages, who were further divided into two Yorkshire accents (West and South) to challenge the efficiency of the AI tools thoroughly. Although ASR systems showed no significant bias across groups, classification and regression models using acoustic and linguistic features exhibited bias against multilingual speakers, particularly in memory, fluency, and reading tasks. This bias was more pronounced when models were trained on the publicly available DementiaBank dataset. Moreover, multilinguals were more likely to be misclassified as having cognitive decline. This study is the first of its kind to discover that, despite their strong overall performance, current AI models show bias against multilingual individuals from ethnic minority backgrounds in the UK, and they are also more likely to misclassify speakers with a certain accent (South Yorkshire) as living with a more severe cognitive decline. In this pilot study, we conclude that the existing AI tools are therefore not yet reliable for diagnostic use in these populations, and we aim to address this in future work by developing more generalisable, bias-mitigated models.

</details>


### [83] [TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution](https://arxiv.org/abs/2602.13059)
*Tejas Anvekar,Junha Park,Rajat Jha,Devanshu Gupta,Poojah Ganesan,Puneeth Mathur,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出TraceBack框架，实现表格问答中的细粒度单元级归因；构建CITEBench基准与FairScore评估指标，支持可解释、可扩展的评估。


<details>
  <summary>Details</summary>
Motivation: 现有表格问答系统缺乏细粒度归因，导致正确答案缺乏可验证依据，影响高风险场景下的可信度。

Method: TraceBack采用多智能体架构，通过剪枝相关行列、分解问题为子问题，并对齐答案跨度与支持单元，捕捉显性和隐性证据。引入CITEBench基准和FairScore无参考评估指标以支持系统评估。

Result: TraceBack在多个数据集和粒度上显著优于基线方法；FairScore与人工判断高度一致，保持方法间的相对排名，验证了其有效性。

Conclusion: TraceBack实现了可扩展、细粒度的表格问答归因，结合CITEBench与FairScore，推动了可解释性与可评估性的进步。

Abstract: Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable grounding, limiting trust in high-stakes settings. We address this with TraceBack, a modular multi-agent framework for scalable, cell-level attribution in single-table QA. TraceBack prunes tables to relevant rows and columns, decomposes questions into semantically coherent sub-questions, and aligns each answer span with its supporting cells, capturing both explicit and implicit evidence used in intermediate reasoning steps. To enable systematic evaluation, we release CITEBench, a benchmark with phrase-to-cell annotations drawn from ToTTo, FetaQA, and AITQA. We further propose FairScore, a reference-less metric that compares atomic facts derived from predicted cells and answers to estimate attribution precision and recall without human cell labels. Experiments show that TraceBack substantially outperforms strong baselines across datasets and granularities, while FairScore closely tracks human judgments and preserves relative method rankings, supporting interpretable and scalable evaluation of table-based QA.

</details>


### [84] [Exploring a New Competency Modeling Process with Large Language Models](https://arxiv.org/abs/2602.13084)
*Silin Du,Manqing Xin,Raymond Jia Wang*

Main category: cs.CL

TL;DR: 本研究提出一种基于大语言模型（LLM）的新型能力建模流程，通过将专家实践分解为结构化计算模块，实现从原始文本中提取行为与心理描述，并映射到预定义的能力库。引入可学习参数以自适应融合不同信息源，提升模型对行为与心理信号重要性的判断能力。同时开发离线评估方法，无需额外大规模数据收集即可系统性选择模型。在一家软件外包公司的实际应用中，验证了该框架在预测效度、跨能力库一致性及结构稳健性方面的优势，推动能力建模向透明、数据驱动和可评估的方向转变。


<details>
  <summary>Details</summary>
Motivation: 传统能力建模依赖专家手动分析大量访谈文本，成本高、易受主观性影响，且缺乏可重复性和客观验证手段。亟需一种更高效、可量化、可验证的自动化方法。

Method: 将专家实践分解为结构化计算组件；利用大语言模型提取文本中的行为与心理描述；通过嵌入相似性映射至预定义能力库；引入可学习参数自适应融合多源信息；设计离线评估机制实现无需额外数据的模型选择。

Result: 在真实企业场景中展现出强预测效度、跨能力库一致性及结构稳健性，显著提升了能力建模的客观性、透明性和可评估性。

Conclusion: 所提出的框架成功将传统定性、依赖专家的能力建模转变为透明、数据驱动且可验证的分析流程，具备良好的实用价值与推广潜力。

Abstract: Competency modeling is widely used in human resource management to select, develop, and evaluate talent. However, traditional expert-driven approaches rely heavily on manual analysis of large volumes of interview transcripts, making them costly and prone to randomness, ambiguity, and limited reproducibility. This study proposes a new competency modeling process built on large language models (LLMs). Instead of merely automating isolated steps, we reconstruct the workflow by decomposing expert practices into structured computational components. Specifically, we leverage LLMs to extract behavioral and psychological descriptions from raw textual data and map them to predefined competency libraries through embedding-based similarity. We further introduce a learnable parameter that adaptively integrates different information sources, enabling the model to determine the relative importance of behavioral and psychological signals. To address the long-standing challenge of validation, we develop an offline evaluation procedure that allows systematic model selection without requiring additional large-scale data collection. Empirical results from a real-world implementation in a software outsourcing company demonstrate strong predictive validity, cross-library consistency, and structural robustness. Overall, our framework transforms competency modeling from a largely qualitative and expert-dependent practice into a transparent, data-driven, and evaluable analytical process.

</details>


### [85] [Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts](https://arxiv.org/abs/2602.13102)
*Kais Allkivi*

Main category: cs.CL

TL;DR: 本研究通过自然语言处理分析爱沙尼亚语水平考试写作，旨在构建可解释且泛化能力强的机器学习模型以评估语言水平（A2-C1）。研究聚焦于词汇、形态、表面及错误特征等语言属性，筛选出与语言复杂性和准确性相关的特征，用于分类模型训练。相比包含更多特征的模型，预选特征虽在测试准确率上相近，但对不同文本类型的分类方差更小。最佳模型准确率达0.9；对早期样本的额外评估显示，近7-10年写作复杂性提升，而某些特征集仍保持0.8的准确率。研究成果已应用于开源爱沙尼亚语学习平台的写作评估模块。


<details>
  <summary>Details</summary>
Motivation: 现有研究较少将自动评估与语言发展洞察结合，本研究旨在通过精准特征选择，提升机器学习模型在语言测试中的可解释性与泛化能力，同时揭示语言水平发展的趋势。

Method: 分析爱沙尼亚语水平考试写作数据（A2-C1），提取词汇、形态、表面及错误等语言特征，进行特征筛选，并训练分类模型。对比不同特征组合下的模型性能，评估其在不同文本类型上的稳定性与准确率。

Result: 预选特征的模型达到约0.9的准确率，且分类结果对文本类型变化的敏感度更低；对历史数据的分析表明，近年写作复杂性上升，但模型仍保持0.8左右的准确率。

Conclusion: 通过精心设计的特征选择，可构建高效、稳定且可解释的语言水平分类模型，适用于自动化评估系统，并为语言发展研究提供支持。该成果已成功集成至开源语言学习平台中。

Abstract: Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly combining these aspects. This study aimed to classify Estonian proficiency examination writings (levels A2-C1), assuming that careful feature selection can lead to more explainable and generalizable machine learning models for language testing. Various linguistic properties of the training data were analyzed to identify relevant proficiency predictors associated with increasing complexity and correctness, rather than the writing task. Such lexical, morphological, surface, and error features were used to train classification models, which were compared to models that also allowed for other features. The pre-selected features yielded a similar test accuracy but reduced variation in the classification of different text types. The best classifiers achieved an accuracy of around 0.9. Additional evaluation on an earlier exam sample revealed that the writings have become more complex over a 7-10-year period, while accuracy still reached 0.8 with some feature sets. The results have been implemented in the writing evaluation module of an Estonian open-source language learning environment.

</details>


### [86] [SCOPE: Selective Conformal Optimized Pairwise LLM Judging](https://arxiv.org/abs/2602.13110)
*Sher Badshah,Ali Emami,Hassan Sajjad*

Main category: cs.CL

TL;DR: 本文提出SCOPE（Selective Conformal Optimized Pairwise Evaluation）框架，用于在有限样本下实现具有统计保证的可选择性配对评估。通过引入双向偏好熵（BPE），该方法生成对响应顺序不变的不确定性信号，提升判断的校准性和覆盖度。在多个基准测试中，SCOPE在设定风险水平α=0.10时，实际错误率稳定在约0.097至0.099之间，同时保持高覆盖率（最高达0.98），显著优于传统基线方法，验证了其在降低偏差与提升效率方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型作为评判者虽具实用性，但存在校准不足和系统性偏差问题，亟需一种能提供可靠、低风险且高覆盖率评估的机制。

Method: 提出SCOPE框架，结合选择性判断与置信区间校准；引入双向偏好熵（BPE），通过双侧查询与概率聚合生成对顺序无关的不确定性评分，用于指导是否接受判断结果。

Result: 在MT-Bench、RewardBench和Chatbot Arena等多个数据集上，SCOPE在α=0.10时均满足目标风险约束（实测错误率≈0.097–0.099），并实现高达0.98的判断覆盖率；相比朴素基线，最多可多接受2.4倍判断，显著提升评估效率。

Conclusion: SCOPE结合BPE实现高可靠性与高覆盖率的自动化评估，在不牺牲安全性前提下大幅提高评估效率，为大规模语言模型评价提供了可信赖的解决方案。

Abstract: Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evaluation), a framework for selective pairwise judging with finite-sample statistical guarantees. Under exchangeability, SCOPE calibrates an acceptance threshold such that the error rate among non-abstained judgments is at most a user-specified level $α$. To provide SCOPE with a bias-neutral uncertainty signal, we introduce Bidirectional Preference Entropy (BPE), which queries the judge under both response positions, aggregates the implied preference probabilities to enforce invariance to response order, and converts the aggregated probability into an entropy-based uncertainty score. Across MT-Bench, RewardBench, and Chatbot Arena, BPE improves uncertainty quality over standard confidence proxies, providing a stronger selection signal that enables SCOPE to consistently meet the target risk level while retaining good coverage across judge scales. In particular, at $α= 0.10$, \textsc{Scope} consistently satisfies the risk bound across all benchmarks and judge scales (empirical risk $\approx 0.097$ to $0.099$), while retaining substantial coverage, reaching $0.89$ on RewardBench with Qwen-14B and $0.98$ on RewardBench with Qwen-32B. Compared to naïve baselines, \textsc{Scope} accepts up to $2.4\times$ more judgments on MT-Bench with Qwen-7B under the same target risk constraint, demonstrating that BPE enables reliable and high-coverage LLM-based evaluation.

</details>


### [87] [From sunblock to softblock: Analyzing the correlates of neology in published writing and on social media](https://arxiv.org/abs/2602.13123)
*Maria Ryskina,Matthew R. Gormley,Kyle Mahowald,David R. Mortensen,Taylor Berg-Kirkpatrick,Vivek Kulkarni*

Main category: cs.CL

TL;DR: 该研究扩展了对英语新词产生（新词创造）的分布语义分析，将静态嵌入方法扩展到上下文嵌入，并应用于推特数据集。结果显示，尽管在社交媒体和传统出版物中存在差异，但之前在历史文本中发现的两个相关因素依然成立。推特上的主题流行度增长对新词创造的影响较小，可能是因为不同语境下新词生成机制不同。


<details>
  <summary>Details</summary>
Motivation: 探究语言在不同语境下的新词生成机制，特别是在社交媒体与传统出版物之间的差异。

Method: 采用上下文嵌入与静态嵌入相结合的方法，基于新构建的推特语料库，扩展先前针对历史出版文本的研究方法。

Result: 在推特和传统出版文本中，新词生成的两个主要因素依然相关；但主题流行度增长对推特新词生成的贡献较小。

Conclusion: 不同语言使用场景（如社交媒体与新闻出版）可能倾向于不同的新词形成机制，这解释了主题流行度影响的差异。

Abstract: Living languages are shaped by a host of conflicting internal and external evolutionary pressures. While some of these pressures are universal across languages and cultures, others differ depending on the social and conversational context: language use in newspapers is subject to very different constraints than language use on social media. Prior distributional semantic work on English word emergence (neology) identified two factors correlated with creation of new words by analyzing a corpus consisting primarily of historical published texts (Ryskina et al., 2020, arXiv:2001.07740). Extending this methodology to contextual embeddings in addition to static ones and applying it to a new corpus of Twitter posts, we show that the same findings hold for both domains, though the topic popularity growth factor may contribute less to neology on Twitter than in published writing. We hypothesize that this difference can be explained by the two domains favouring different neologism formation mechanisms.

</details>


### [88] [OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report](https://arxiv.org/abs/2602.13139)
*Mariia Fedorova,Nikolay Arefyev,Maja Buljan,Jindřich Helcl,Stephan Oepen,Egil Rønningstad,Yves Scherrer*

Main category: cs.CL

TL;DR: 本文扩展了OpenLID分类器，通过增加训练数据、合并问题语言变体聚类以及引入噪声标记标签，提出新版本OpenLID-v3。针对巴尔干语、意大利与法国罗曼语及斯堪的纳维亚语言等密切相关的语言组进行优化，并构建了新的评估数据集。实验表明集成方法虽提升精度但降低低资源语言覆盖率。OpenLID-v3已开源。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别工具在区分密切相关的语言和自然语言与噪声方面表现不佳，尤其影响低资源语言的数据质量。

Method: 扩展OpenLID，增加训练数据，合并语言变体集群，引入噪声标签，并使用多个基准测试评估性能。

Result: OpenLID-v3在多个基准上优于GlotLID；集成方法提高精度但降低低资源语言覆盖范围。

Conclusion: OpenLID-v3显著提升了语言识别能力，尤其在复杂语言变体和噪声处理方面，适用于构建高质量多语言数据集。

Abstract: Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages. In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters, and introducing a special label for marking noise. We call this extended system OpenLID-v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages. OpenLID-v3 is available on https://huggingface.co/HPLT/OpenLID-v3.

</details>


### [89] [Semantic Chunking and the Entropy of Natural Language](https://arxiv.org/abs/2602.13194)
*Weishun Zhong,Doron Sivan,Tankut Can,Mikhail Katkov,Misha Tsodyks*

Main category: cs.CL

TL;DR: 本文提出一种统计模型，用于解释自然语言中约80%的冗余度，该模型通过自相似分段文本至语义连贯的块（直至单个单词），实现对文本语义结构的层次化分解。模型预测的熵率与印刷英语的实际估计值一致，并揭示了语言熵率随语义复杂性增加而系统上升的规律，仅由模型中的一个自由参数决定。


<details>
  <summary>Details</summary>
Motivation: 理解自然语言中高冗余性的来源，特别是为何英语的熵率约为每字符1比特，远低于随机文本的5比特，从而为现代大语言模型（LLMs）逼近这一基准提供理论支持。

Method: 提出一种基于自相似分段和层次化语义分解的统计模型，将文本结构从宏观到微观逐层解析，利用数值实验验证其在不同语义层级上对真实文本结构的拟合能力。

Result: 模型预测的熵率与印刷英语的实测熵率吻合；同时发现语言熵率并非固定，而是随语义复杂性增加而系统上升，由模型中的单一自由参数控制。

Conclusion: 该模型从第一性原理出发，成功解释了自然语言的高冗余性，并揭示了熵率与语义复杂性的动态关系，为理解语言结构和评估语言模型提供了新视角。

Abstract: The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [90] [Abstractive Red-Teaming of Language Model Character](https://arxiv.org/abs/2602.12318)
*Nate Rahn,Allison Qi,Avery Griffin,Jonathan Michala,Henry Sleight,Erik Jones*

Main category: cs.LG

TL;DR: 本文提出抽象红队测试（abstractive red-teaming），通过少量计算识别可能引发语言模型在部署中违反角色规范的查询类别。方法包括基于强化学习的类别生成和利用强语言模型迭代合成高分查询类别。在12项角色规范和7个目标模型上，该方法优于基线，发现如要求模型预测未来导致其宣称AI将统治人类、或询问监狱生存物品而推荐非法武器等有趣且危险的查询类别，有助于实现更真实的预部署角色审计。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型虽通常遵循角色规范，但在大规模部署中仍可能出现违规行为。为在低成本下提前识别易引发违规的查询类型，需一种高效且可扩展的检测机制。

Method: 提出两种算法：一是基于强化学习的类别生成器大模型；二是利用强语言模型从高评分查询中迭代生成抽象查询类别，均结合特定角色特质的奖励模型进行优化。

Result: 在12条角色规范与7个模型上，所提方法显著优于基线，成功发现多种具有代表性的违规触发场景，如模型预测未来时表达对人类统治的宣言，或在监狱生存建议中推荐非法武器。

Conclusion: 该研究为实现真实、高效的预部署语言模型角色合规性审计提供了有效路径，有助于提升模型在实际应用中的安全性与可控性。

Abstract: We want language model assistants to conform to a character specification, which asserts how the model should act across diverse user interactions. While models typically follow these character specifications, they can occasionally violate them in large-scale deployments. In this work, we aim to identify types of queries that are likely to produce such character violations at deployment, using much less than deployment-level compute. To do this, we introduce abstractive red-teaming, where we search for natural-language query categories, e.g. "The query is in Chinese. The query asks about family roles," that routinely elicit violations. These categories abstract over the many possible variants of a query which could appear in the wild. We introduce two algorithms for efficient category search against a character-trait-specific reward model: one based on reinforcement learning on a category generator LLM, and another which leverages a strong LLM to iteratively synthesize categories from high-scoring queries. Across a 12-principle character specification and 7 target models, we find that our algorithms consistently outperform baselines, and generate qualitatively interesting categories; for example, queries which ask Llama-3.1-8B-Instruct to predict the future lead to responses saying that AI will dominate humanity, and queries that ask GPT-4.1-Mini for essential prison survival items lead to enthusiastic recommendation of illegal weapons. Overall, we believe our results represent an important step towards realistic pre-deployment auditing of language model character.

</details>


### [91] [The Appeal and Reality of Recycling LoRAs with Adaptive Merging](https://arxiv.org/abs/2602.12323)
*Haokun Liu,Gyung Hyun Je,Marco Ciccone,Zhenlin Xu,Prasanth YSS,Colin Raffel*

Main category: cs.LG

TL;DR: 本文研究了从Hugging Face Hub等公开平台回收近1000个基于Llama 3.1 8B-Instruct的LoRA模块，并评估多种自适应与非自适应合并方法的效果。结果表明，尽管自适应合并能提升基线模型性能，但其增益有限，且在相同数据上训练新LoRA更具优势。更令人意外的是，所选LoRA的具体内容影响不大，甚至随机初始化参数的LoRA也能达到相似效果，暗示自适应合并可能主要通过正则化而非跨任务知识迁移起作用。研究还确认，当池中存在高度相关LoRA时，正向迁移仍可实现。代码和模型已开源。


<details>
  <summary>Details</summary>
Motivation: 现有自适应LoRA合并方法多依赖于精心设计的LoRA组合，但尚未探索从公开平台（如Hugging Face Hub）回收用户贡献的LoRA进行合并的可能性。本文旨在填补这一空白，评估真实世界中广泛存在的LoRA资源在合并中的有效性与机制。

Method: 收集近1000个基于Llama 3.1 8B-Instruct的用户贡献LoRA，涵盖多种任务类型；对比多种自适应与非自适应合并策略，包括新提出的方法（通过大规模方法空间搜索设计）；使用任务特定数据集调整合并系数；通过消融实验分析不同因素对性能的影响，包括LoRA选择、参数初始化方式及相关性。

Result: 自适应合并虽优于基线模型，但性能提升不如直接在相同数据上训练新LoRA；LoRA的具体内容或初始化方式对最终性能影响较小，随机初始化的LoRA表现相近；合并效果可能主要源于正则化而非跨任务知识迁移；仅当池中存在高度相关的LoRA时，正向迁移才显著有效。

Conclusion: 从公开渠道回收的LoRA用于自适应合并，其实际价值有限，主要可能通过正则化效应提升性能，而非知识迁移。若需显著提升性能，仍建议基于目标任务重新训练新LoRA。研究结果提醒我们应审慎评估现有合并方法的有效性，并强调高质量、相关性强的LoRA在迁移学习中的关键作用。

Abstract: The widespread availability of fine-tuned LoRA modules for open pre-trained models has led to an interest in methods that can adaptively merge LoRAs to improve performance. These methods typically include some way of selecting LoRAs from a pool and tune merging coefficients based on a task-specific dataset. While adaptive merging methods have demonstrated improvements in some settings, no past work has attempted to recycle LoRAs found "in the wild" on model repositories like the Hugging Face Hub. To address this gap, we consider recycling from a pool of nearly 1,000 user-contributed LoRAs trained from the Llama 3.1 8B-Instruct language model. Our empirical study includes a range of adaptive and non-adaptive merging methods in addition to a new method designed via a wide search over the methodological design space. We demonstrate that adaptive merging methods can improve performance over the base model but provide limited benefit over training a new LoRA on the same data used to set merging coefficients. We additionally find not only that the specific choice of LoRAs to merge has little importance, but that using LoRAs with randomly initialized parameter values yields similar performance. This raises the possibility that adaptive merging from recycled LoRAs primarily works via some kind of regularization effect, rather than by enabling positive cross-task transfer. To better understand why past work has proven successful, we confirm that positive transfer is indeed possible when there are highly relevant LoRAs in the pool. We release the model checkpoints and code online.

</details>


### [92] [Policy4OOD: A Knowledge-Guided World Model for Policy Intervention Simulation against the Opioid Overdose Crisis](https://arxiv.org/abs/2602.12373)
*Yijun Ma,Zehong Wang,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Nitesh Chawla,Yanfang Ye*

Main category: cs.LG

TL;DR: 该研究提出Policy4OOD，一种基于知识引导的时空世界模型，用于统一预测、反事实推理和政策优化，以应对美国阿片类药物危机中的复杂政策评估挑战。通过整合政策知识图谱、州级空间依赖性和经济社会时间序列，构建政策条件化的Transformer模型，实现对阿片类药物结果的精准预测。训练后，该模型可作为模拟器：前向传播即可预测未来趋势，替换历史政策编码可进行反事实分析，结合蒙特卡洛树搜索实现政策优化。实验验证了空间依赖性和结构化政策知识对预测精度的提升，证明了世界建模在数据驱动公共卫生决策支持中的潜力。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机是美国最严重的公共卫生危机之一，但政策干预的评估困难，因多种政策在动态系统中相互作用，单一政策可能无意中加剧其他风险路径。因此，需要一种能够综合预测、反事实推理和政策优化的评估框架。

Method: 提出Policy4OOD，一个知识引导的时空世界模型，联合编码政策知识图谱、州级空间依赖性和经济社会时间序列，使用政策条件化的Transformer进行阿片类药物结果的预测，并利用训练后的模型作为模拟器，支持预测、反事实分析和政策优化。

Result: 实验表明，空间依赖性和结构化政策知识显著提升了预测准确性；各架构组件的有效性得到验证，世界建模在数据驱动的公共健康决策支持方面展现出巨大潜力。

Conclusion: 世界建模为阿片类药物政策评估提供了一种强大且统一的框架，能够有效应对多政策交互的复杂系统问题，推动更科学、前瞻性的公共健康政策制定。

Abstract: The opioid epidemic remains one of the most severe public health crises in the United States, yet evaluating policy interventions before implementation is difficult: multiple policies interact within a dynamic system where targeting one risk pathway may inadvertently amplify another. We argue that effective opioid policy evaluation requires three capabilities -- forecasting future outcomes under current policies, counterfactual reasoning about alternative past decisions, and optimization over candidate interventions -- and propose to unify them through world modeling. We introduce Policy4OOD, a knowledge-guided spatio-temporal world model that addresses three core challenges: what policies prescribe, where effects manifest, and when effects unfold.Policy4OOD jointly encodes policy knowledge graphs, state-level spatial dependencies, and socioeconomic time series into a policy-conditioned Transformer that forecasts future opioid outcomes.Once trained, the world model serves as a simulator: forecasting requires only a forward pass, counterfactual analysis substitutes alternative policy encodings in the historical sequence, and policy optimization employs Monte Carlo Tree Search over the learned simulator. To support this framework, we construct a state-level monthly dataset (2019--2024) integrating opioid mortality, socioeconomic indicators, and structured policy encodings. Experiments demonstrate that spatial dependencies and structured policy knowledge significantly improve forecasting accuracy, validating each architectural component and the potential of world modeling for data-driven public health decision support.

</details>


### [93] [Deep Doubly Debiased Longitudinal Effect Estimation with ICE G-Computation](https://arxiv.org/abs/2602.12379)
*Wenxin Chen,Weishen Pan,Kyra Gan,Fei Wang*

Main category: cs.LG

TL;DR: D3-Net 提出一种新框架，通过使用序列双重稳健（SDR）伪结果来中断迭代条件期望（ICE）训练中的误差传播，并引入多任务 Transformer 进行辅助监督以稳定表示学习。最终采用未校正的伪模型进行纵向目标最小损失估计（LTMLE），实现鲁棒且高效的纵向处理效应估计，显著降低偏差与方差，优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 解决纵向处理效应估计中因治疗-混杂因素反馈导致的误差传播问题，提升因果推断的准确性与稳定性。

Method: 采用 SDR 伪结果减少训练阶段的误差传播；利用多任务 Transformer 的协变量模拟头进行辅助监督，增强表示鲁棒性；在第二阶段使用 LTMLE 对原始结果进行目标去偏，确保最优有限样本性能。

Result: 实验表明，D3-Net 在不同时间跨度、反事实场景和时变混杂条件下，均能有效降低偏差与方差，表现优于现有的 ICE 基础估计器。

Conclusion: D3-Net 通过中断误差传播与后期目标去偏，实现了更稳健、高效的纵向因果推断，为复杂序列决策提供了可靠工具。

Abstract: Estimating longitudinal treatment effects is essential for sequential decision-making but is challenging due to treatment-confounder feedback. While Iterative Conditional Expectation (ICE) G-computation offers a principled approach, its recursive structure suffers from error propagation, corrupting the learned outcome regression models. We propose D3-Net, a framework that mitigates error propagation in ICE training and then applies a robust final correction. First, to interrupt error propagation during learning, we train the ICE sequence using Sequential Doubly Robust (SDR) pseudo-outcomes, which provide bias-corrected targets for each regression. Second, we employ a multi-task Transformer with a covariate simulator head for auxiliary supervision, regularizing representations against corruption by noisy pseudo-outcomes, and a target network to stabilize training dynamics. For the final estimate, we discard the SDR correction and instead use the uncorrected nuisance models to perform Longitudinal Targeted Minimum Loss-Based Estimation (LTMLE) on the original outcomes. This second-stage, targeted debiasing ensures robustness and optimal finite-sample properties. Comprehensive experiments demonstrate that our model, D3-Net, robustly reduces bias and variance across different horizons, counterfactuals, and time-varying confoundings, compared to existing state-of-the-art ICE-based estimators.

</details>


### [94] [High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions](https://arxiv.org/abs/2602.12391)
*Giang Ngo,Dat Phan Trong,Dang Nguyen,Sunil Gupta*

Main category: cs.LG

TL;DR: 提出TRLSE算法用于高维水平集估计，通过全局和局部双采集函数在高维空间中高效定位阈值边界区域，理论分析与实验验证其优越的样本效率。


<details>
  <summary>Details</summary>
Motivation: 高维空间中水平集估计面临维度灾难，传统方法样本效率低，需更高效的主动学习策略以提升分类准确性。

Method: 提出基于双采集函数的TRLSE算法，结合全局与局部搜索机制，动态识别并精炼接近阈值边界的区域。

Result: TRLSE在多个合成与真实世界问题上表现出更高的准确性和样本效率，理论分析证明其收敛性与有效性。

Conclusion: TRLSE是一种高效且可扩展的高维水平集估计方法，适用于数据稀缺的主动学习场景。

Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data, we aim to iteratively acquire informative points to construct an accurate classifier for this task. In high-dimensional spaces, this becomes challenging where the search volume grows exponentially with increasing dimensionality. We propose TRLSE, an algorithm for high-dimensional LSE, which identifies and refines regions near the threshold boundary with dual acquisition functions operating at both global and local levels. We provide a theoretical analysis of TRLSE's accuracy and show its superior sample efficiency against existing methods through extensive evaluations on multiple synthetic and real-world LSE problems.

</details>


### [95] [AstRL: Analog and Mixed-Signal Circuit Synthesis with Deep Reinforcement Learning](https://arxiv.org/abs/2602.12402)
*Felicia B. Guo,Ken T. Ho,Andrei Vladimirescu,Borivoje Nikolic*

Main category: cs.LG

TL;DR: 本文提出一种基于深度强化学习的模拟与混合信号电路合成方法（AstRL），将电路设计建模为图生成问题，通过嵌入仿真器的环境实现对用户指定目标的直接优化。该方法利用策略梯度算法，在训练中获得真实反馈，并结合行为克隆和判别器相似性奖励，首次实现了专家对齐的通用电路生成范式。其在晶体管级别操作，支持高度表达、细粒度的拓扑生成，且通过动作空间与环境中的强归纳偏置确保结构一致性和有效性。实验表明，该方法在三个真实设计任务中显著优于现有基准，生成电路100%结构正确，超过90%具备所需功能。


<details>
  <summary>Details</summary>
Motivation: 当前模拟与混合信号（AMS）集成电路设计复杂度持续上升，但自动化进展有限，主要因缺乏适用于多样化、约束性强且非可微设计空间的通用优化方法。亟需一种能跨不同电路设计空间通用、高效且精确的自动化设计工具。

Method: 将电路设计视为图生成问题，采用基于策略梯度的深度强化学习框架（AstRL），在嵌入仿真器的环境中进行训练；通过行为克隆与判别器驱动的相似性奖励机制，实现专家对齐的生成策略；在晶体管层面进行拓扑生成，结合强归纳偏置以保证结构合理性和有效性。

Result: 在三个真实设计任务中，相比现有最先进方法，显著提升传统设计指标；100%生成电路结构正确，超过90%具备预期功能，验证了方法的有效性与泛化能力。

Conclusion: AstRL首次实现了在多样化电路设计空间中基于深度强化学习的通用、专家对齐的电路生成，具备高精度、结构一致性与功能性，为模拟与混合信号电路自动化设计提供了新范式。

Abstract: Analog and mixed-signal (AMS) integrated circuits (ICs) lie at the core of modern computing and communications systems. However, despite the continued rise in design complexity, advances in AMS automation remain limited. This reflects the central challenge in developing a generalized optimization method applicable across diverse circuit design spaces, many of which are distinct, constrained, and non-differentiable. To address this, our work casts circuit design as a graph generation problem and introduces a novel method of AMS synthesis driven by deep reinforcement learning (AstRL). Based on a policy-gradient approach, AstRL generates circuits directly optimized for user-specified targets within a simulator-embedded environment that provides ground-truth feedback during training. Through behavioral-cloning and discriminator-based similarity rewards, our method demonstrates, for the first time, an expert-aligned paradigm for generalized circuit generation validated in simulation. Importantly, the proposed approach operates at the level of individual transistors, enabling highly expressive, fine-grained topology generation. Strong inductive biases encoded in the action space and environment further drive structurally consistent and valid generation. Experimental results for three realistic design tasks illustrate substantial improvements in conventional design metrics over state-of-the-art baselines, with 100% of generated designs being structurally correct and over 90% demonstrating required functionality.

</details>


### [96] [Soft Contamination Means Benchmarks Test Shallow Generalization](https://arxiv.org/abs/2602.12413)
*Ari Spiesberger,Juan J. Vazquez,Nicky Pochinkov,Tomáš Gavenčiak,Peli Grietzer,Gavin Leech,Nandi Schoots*

Main category: cs.LG

TL;DR: 该研究探讨了大型语言模型训练数据中因语义重复（soft contamination）导致的基准测试性能偏差问题。尽管传统去重方法依赖n-gram匹配，无法识别语义等价但字符串差异大的重复内容，研究发现大量基准数据存在语义重复，如78%的CodeForces题目和50%的ZebraLogic题目存在语义重复。包含这些语义重复数据会提升模型在基准测试上的表现，并且在微调时也能提升对真正未见数据的表现。因此，近期基准性能的提升可能并非完全反映模型真实泛化能力的增强，而是部分归因于训练数据中积累了测试数据本身或其语义等价版本。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试性能评估可能因训练数据中隐含的语义重复而产生偏差，导致对模型真实泛化能力的误判。传统的n-gram去重方法无法检测语义等价但字符串不同的重复内容，从而使得污染持续存在。

Method: 通过嵌入Olmo3训练语料库，使用语义相似度分析检测语义重复；对比包含与不包含语义重复数据的模型在基准测试上的表现；进行微调实验以观察对未见数据的影响。

Result: 1) 78%的CodeForces问题和50%的ZebraLogic问题存在语义重复；2) 包含语义重复数据能提升基准测试性能；3) 微调时使用语义重复数据可提升对真实未见数据的表现。

Conclusion: 当前大型语言模型在基准测试中的性能提升，部分源于训练数据中积累的测试数据及其语义等价物，而非纯粹的能力进步。这表明基准性能评估需重新审视，避免被软污染所误导。

Abstract: If LLM training data is polluted with benchmark test data, then benchmark performance gives biased estimates of out-of-distribution (OOD) generalization. Typical decontamination filters use n-gram matching which fail to detect semantic duplicates: sentences with equivalent (or near-equivalent) content that are not close in string space. We study this soft contamination of training data by semantic duplicates. Among other experiments, we embed the Olmo3 training corpus and find that: 1) contamination remains widespread, e.g. we find semantic duplicates for 78% of CodeForces and exact duplicates for 50% of ZebraLogic problems; 2) including semantic duplicates of benchmark data in training does improve benchmark performance; and 3) when finetuning on duplicates of benchmark datapoints, performance also improves on truly-held-out datapoints from the same benchmark. We argue that recent benchmark gains are thus confounded: the prevalence of soft contamination means gains reflect both genuine capability improvements and the accumulation of test data and effective test data in growing training corpora.

</details>


### [97] [Stabilizing Native Low-Rank LLM Pretraining](https://arxiv.org/abs/2602.12429)
*Paul Janson,Edouard Oyallon,Eugene Belilovsky*

Main category: cs.LG

TL;DR: 该论文提出一种名为Spectron的新方法，通过谱归一化与正交化实现全低秩权重的稳定训练，无需依赖全秩引导，解决了低秩训练中的不稳定性问题，并建立了计算最优的缩放定律，显著提升了推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有低秩因子分解方法在从零开始训练大语言模型时面临稳定性差、损失突增等问题，缺乏稳定的训练配方，限制了其广泛应用。

Method: 提出Spectron方法，通过动态约束权重更新的谱范数，结合正交化机制，确保低秩因子在训练过程中的稳定性，支持端到端的纯低秩训练。

Result: 成功实现了无需全秩引导的纯低秩大模型训练，训练过程稳定，损失无突增；同时建立了可预测的计算最优缩放定律，推理效率优于稠密模型。

Conclusion: Spectron为大规模语言模型的纯低秩训练提供了稳定且高效的解决方案，推动了高效模型架构的发展，具有重要的实际应用价值。

Abstract: Foundation models have achieved remarkable success, yet their growing parameter counts pose significant computational and memory challenges. Low-rank factorization offers a promising route to reduce training and inference costs, but the community lacks a stable recipe for training models from scratch using exclusively low-rank weights while matching the performance of the dense model. We demonstrate that Large Language Models (LLMs) can be trained from scratch using exclusively low-rank factorized weights for all non-embedding matrices without auxiliary "full-rank" guidance required by prior methods. While native low-rank training often suffers from instability and loss spikes, we identify uncontrolled growth in the spectral norm (largest singular value) of the weight matrix update as the dominant factor. To address this, we introduce Spectron: Spectral renormalization with orthogonalization, which dynamically bounds the resultant weight updates based on the current spectral norms of the factors. Our method enables stable, end-to-end factorized training with negligible overhead. Finally, we establish compute-optimal scaling laws for natively low-rank transformers, demonstrating predictable power-law behavior and improved inference efficiency relative to dense models.

</details>


### [98] [Computationally sufficient statistics for Ising models](https://arxiv.org/abs/2602.12449)
*Abhijith Jayakumar,Shreya Shukla,Marc Vuffray,Andrey Y. Lokhov,Sidhant Misra*

Main category: cs.LG

TL;DR: 该研究探讨了在仅能观测到足够统计量的情况下，如何高效学习吉布斯分布的问题。以伊辛模型为例，证明了通过观测约O(γ)阶的统计量即可重建具有ℓ₁宽度为γ的模型参数，从而推断模型结构并学习耦合与磁场。当已知模型结构时，可进一步降低观测需求，实现更高效的参数学习。


<details>
  <summary>Details</summary>
Motivation: 在物理系统中，完整样本观测往往不现实，因此需要发展仅依赖有限统计量的高效学习方法，以平衡计算复杂性与观测能力之间的权衡。

Method: 基于伊辛模型，分析不同观测阶数下参数重构的可能性，结合ℓ₁宽度定义和统计量阶数的关系，提出一种利用低阶统计量进行参数学习的算法，并在有先验结构信息时优化观测需求。

Result: 证明了在观测统计量至多为O(γ)阶时，可以准确重建模型参数；在已知结构的情况下，甚至可在更弱的观测条件下完成高效学习。

Conclusion: 该工作展示了在受限观测条件下高效学习吉布斯分布的可行性，为复杂系统建模提供了实用且理论支持的方法框架。

Abstract: Learning Gibbs distributions using only sufficient statistics has long been recognized as a computationally hard problem. On the other hand, computationally efficient algorithms for learning Gibbs distributions rely on access to full sample configurations generated from the model. For many systems of interest that arise in physical contexts, expecting a full sample to be observed is not practical, and hence it is important to look for computationally efficient methods that solve the learning problem with access to only a limited set of statistics. We examine the trade-offs between the power of computation and observation within this scenario, employing the Ising model as a paradigmatic example. We demonstrate that it is feasible to reconstruct the model parameters for a model with $\ell_1$ width $γ$ by observing statistics up to an order of $O(γ)$. This approach allows us to infer the model's structure and also learn its couplings and magnetic fields. We also discuss a setting where prior information about structure of the model is available and show that the learning problem can be solved efficiently with even more limited observational power.

</details>


### [99] [Regularized Meta-Learning for Improved Generalization](https://arxiv.org/abs/2602.12469)
*Noor Islam S. Mohammad,Md Muntaqim Meherab*

Main category: cs.LG

TL;DR: 提出一种正则化元学习框架，通过四阶段流程解决深度集成方法中的冗余、权重不稳和过拟等问题，在多个基准上实现更优性能与更低计算开销。


<details>
  <summary>Details</summary>
Motivation: 深度集成方法虽能提升预测性能，但存在基模型冗余导致计算成本高、多重共线性下权重不稳定以及元学习管道过拟等问题。

Method: 采用四阶段流程：冗余感知投影、统计元特征增强、交叉验证的正则化元模型（Ridge、Lasso、ElasticNet），并引入逆RMSE加权阶段以降低正则化选择方差。

Result: 在Playground Series S6E1基准上，出堆叠RMSE达8.582，优于简单平均（8.894）和传统Ridge堆叠（8.627），与贪婪爬升相当（8.603）但快4倍；有效矩阵条件数下降53.7%。

Conclusion: 正则化元学习是一种稳定且适合高维集成系统部署的堆叠策略。

Abstract: Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a regularized meta-learning framework that addresses these challenges through a four-stage pipeline combining redundancy-aware projection, statistical meta-feature augmentation, and cross-validated regularized meta-models (Ridge, Lasso, and ElasticNet). Our multi-metric de-duplication strategy removes near-collinear predictors using correlation and MSE thresholds ($τ_{\text{corr}}=0.95$), reducing the effective condition number of the meta-design matrix while preserving predictive diversity. Engineered ensemble statistics and interaction terms recover higher-order structure unavailable to raw prediction columns. A final inverse-RMSE blending stage mitigates regularizer-selection variance. On the Playground Series S6E1 benchmark (100K samples, 72 base models), the proposed framework achieves an out-of-fold RMSE of 8.582, improving over simple averaging (8.894) and conventional Ridge stacking (8.627), while matching greedy hill climbing (8.603) with substantially lower runtime (4 times faster). Conditioning analysis shows a 53.7\% reduction in effective matrix condition number after redundancy projection. Comprehensive ablations demonstrate consistent contributions from de-duplication, statistical meta-features, and meta-ensemble blending. These results position regularized meta-learning as a stable and deployment-efficient stacking strategy for high-dimensional ensemble systems.

</details>


### [100] [Designing RNAs with Language Models](https://arxiv.org/abs/2602.12470)
*Milan Gautam,Ning Dai,Tianshuo Zhou,Bowen Xie,David Mathews,Liang Huang*

Main category: cs.LG

TL;DR: 该研究将RNA设计重新定义为条件序列生成任务，提出一种基于自回归语言模型的可重用神经近似器，通过监督训练和强化学习优化，在多个数据集上优于现有方法，且速度提升1.7倍。


<details>
  <summary>Details</summary>
Motivation: 传统RNA设计方法面临序列空间指数级增长和折叠竞争问题，依赖启发式或约束搜索，效率与通用性不足。

Method: 将RNA设计视为条件序列生成，采用自回归语言模型进行结构到序列的映射；先在随机诱导的结构-序列对上进行监督训练，再通过强化学习优化端到端指标，并提出高效的小样本选择策略以提升强化学习性能。

Result: 在四个数据集上，所提方法在玻尔兹曼概率等关键指标上优于现有系统，同时实现1.7倍加速，证明了条件语言模型生成在可扩展性和任务无关性上的优势。

Conclusion: 条件语言模型生成为RNA设计提供了一种可扩展、任务无关的替代方案，突破了传统优化方法的局限，具备广泛的应用潜力。

Abstract: RNA design, the task of finding a sequence that folds into a target secondary structure, has broad biological and biomedical impact but remains computationally challenging due to the exponentially large sequence space and exponentially many competing folds. Traditional approaches treat it as an optimization problem, relying on per-instance heuristics or constraint-based search. We instead reframe RNA design as conditional sequence generation and introduce a reusable neural approximator, instantiated as an autoregressive language model (LM), that maps target structures directly to sequences. We first train our model in a supervised setting on random-induced structure-sequence pairs, and then use reinforcement learning (RL) to optimize end-to-end metrics. We also propose methods to select a small subset for RL that greatly improves RL efficiency and quality. Across four datasets, our approach outperforms state-of-the-art systems on key metrics such as Boltzmann probability while being 1.7x faster, establishing conditional LM generation as a scalable, task-agnostic alternative to per-instance optimization for RNA design. Our code and data are available at https://github.com/KuNyaa/RNA-Design-LM.

</details>


### [101] [Tight Bounds for Logistic Regression with Large Stepsize Gradient Descent in Low Dimension](https://arxiv.org/abs/2602.12471)
*Michael Crawshaw,Mingrui Liu*

Main category: cs.LG

TL;DR: 本文研究了在二维数据下，使用梯度下降法最小化逻辑损失函数训练线性分类模型的优化问题。通过选择较大的学习率 η，作者证明了在足够多的迭代次数 T 下，梯度下降能获得比 1/(ηT) 更优的损失上界。该结果基于对垂直于最大间隔分类器子空间中梯度下降振荡动态的精细分析，并给出了与上界匹配的下界，表明分析是紧致的。


<details>
  <summary>Details</summary>
Motivation: 已有研究表明，在分离数据下，使用大步长 η = Θ(γ²T) 可实现 1/T² 的加速收敛率，但损失函数呈现非单调性。本文旨在更精确地分析二维情形下梯度下降的行为，特别是其从不稳定到稳定状态的过渡时间 τ，以获得更优的收敛速率。

Method: 采用对梯度下降在正交于最大间隔分类器方向上的振荡动态进行细粒度分析的方法，推导出过渡时间 τ 的上界，并结合构造性的下界证明该上界紧致，从而得出损失的改进上界。

Result: 在 T ≥ Ω(n/γ + 1/γ²) 条件下，梯度下降使用足够大的学习率 η 时，可达到损失上界为 𝒪(1/(ηT))；同时给出了 τ 的上下界，二者仅差对数因子，说明分析具有紧致性。

Conclusion: 本文通过精细化分析梯度下降在二维情形下的振荡行为，揭示了其从非单调到单调收敛的过渡机制，得到了更优的收敛速率，并证明了分析的紧致性，为理解大步长梯度下降在可分数据中的行为提供了新视角。

Abstract: We consider the optimization problem of minimizing the logistic loss with gradient descent to train a linear model for binary classification with separable data. With a budget of $T$ iterations, it was recently shown that an accelerated $1/T^2$ rate is possible by choosing a large step size $η= Θ(γ^2 T)$ (where $γ$ is the dataset's margin) despite the resulting non-monotonicity of the loss. In this paper, we provide a tighter analysis of gradient descent for this problem when the data is two-dimensional: we show that GD with a sufficiently large learning rate $η$ finds a point with loss smaller than $\mathcal{O}(1/(ηT))$, as long as $T \geq Ω(n/γ+ 1/γ^2)$, where $n$ is the dataset size. Our improved rate comes from a tighter bound on the time $τ$ that it takes for GD to transition from unstable (non-monotonic loss) to stable (monotonic loss), via a fine-grained analysis of the oscillatory dynamics of GD in the subspace orthogonal to the max-margin classifier. We also provide a lower bound of $τ$ matching our upper bound up to logarithmic factors, showing that our analysis is tight.

</details>


### [102] [On Robustness and Chain-of-Thought Consistency of RL-Finetuned VLMs](https://arxiv.org/abs/2602.12506)
*Rosie Zhao,Anshul Shah,Xiaoyu Zhu,Xinke Deng,Zhongyu Jiang,Yang Yang,Joerg Liebelt,Arnab Mondal*

Main category: cs.LG

TL;DR: 本文研究了强化学习（RL）微调在视觉语言模型（VLMs）中的应用，揭示其在视觉推理任务中虽提升准确率，但存在对弱视觉定位、幻觉和过度依赖文本线索的脆弱性。简单文本扰动（如误导性描述或错误思维链）显著降低模型鲁棒性和置信度，且在开源多模态推理模型中，思维链一致性问题更为突出。熵基度量显示扰动重塑了模型不确定性与正确选项的概率分布，暴露模型特有的校准偏差。进一步分析表明，RL微调存在准确率-可信度权衡：提升准确率的同时削弱了思维链的可靠性及对上下文变化的鲁棒性。对抗增强虽能改善鲁棒性，但无法阻止可信度漂移；引入可信度感知奖励可恢复答案与推理的一致性，但与增强结合时可能导致训练陷入捷径策略，鲁棒性仍难以保证。研究强调仅以准确率为评估标准的局限性，呼吁建立兼顾正确性、鲁棒性与视觉推理可信度的联合训练与评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习微调虽提升了视觉语言模型在视觉推理任务上的表现，但其对文本扰动敏感、缺乏可靠推理过程的问题未被充分揭示，亟需深入理解其内在脆弱性及评估机制缺陷。

Method: 通过引入控制性文本扰动（如误导性图像标题、错误思维链），系统评估多模态模型的鲁棒性；利用熵基指标分析模型不确定性与概率分布变化；结合训练动态分析，探究准确率与推理可信度之间的权衡关系；对比不同训练策略（对抗增强、可信度感知奖励）的效果。

Result: 文本扰动导致模型性能显著下降，尤其在思维链一致性方面问题突出；模型表现出特定的校准偏差；强化学习微调带来准确率提升但牺牲推理可信度与鲁棒性；对抗增强不能完全解决可信度漂移；可信度感知奖励可恢复一致性，但与增强结合易引发捷径策略，导致鲁棒性依然不足。

Conclusion: 现有基于准确率的评估不足以反映模型的真实能力，应发展同时关注正确性、鲁棒性和视觉推理可信度的综合训练与评估体系，以推动更可靠、可解释的多模态智能系统发展。

Abstract: Reinforcement learning (RL) fine-tuning has become a key technique for enhancing large language models (LLMs) on reasoning-intensive tasks, motivating its extension to vision language models (VLMs). While RL-tuned VLMs improve on visual reasoning benchmarks, they remain vulnerable to weak visual grounding, hallucinations, and over-reliance on textual cues. We show that simple, controlled textual perturbations--misleading captions or incorrect chain-of-thought (CoT) traces--cause substantial drops in robustness and confidence, and that these effects are more pronounced when CoT consistency is taken into account across open-source multimodal reasoning models. Entropy-based metrics further show that these perturbations reshape model uncertainty and probability mass on the correct option, exposing model-specific trends in miscalibration. To better understand these vulnerabilities, we further analyze RL fine-tuning dynamics and uncover an accuracy-faithfulness trade-off: fine-tuning raises benchmark accuracy, but can simultaneously erode the reliability of the accompanying CoT and its robustness to contextual shifts. Although adversarial augmentation improves robustness, it does not by itself prevent faithfulness drift. Incorporating a faithfulness-aware reward can restore alignment between answers and reasoning, but when paired with augmentation, training risks collapsing onto shortcut strategies and robustness remains elusive. Together, these findings highlight the limitations of accuracy-only evaluations and motivate training and assessment protocols that jointly emphasize correctness, robustness, and the faithfulness of visually grounded reasoning.

</details>


### [103] [Bench-MFG: A Benchmark Suite for Learning in Stationary Mean Field Games](https://arxiv.org/abs/2602.12517)
*Lorenzo Magnino,Jiacheng Shen,Matthieu Geist,Olivier Pietquin,Mathieu Laurière*

Main category: cs.LG

TL;DR: 本文提出了一个名为Bench-MFG的综合性基准套件，用于评估基于平均场博弈（MFG）与强化学习（RL）结合的算法。针对当前缺乏标准化评估协议的问题，作者设计了离散时间、离散状态空间下的统一框架，并引入问题分类体系（如无交互、单调博弈、潜在博弈、动态耦合博弈等），提供代表性环境。同时提出MF-Garnets方法以生成随机MFG实例，支持统计验证。在多个环境中对多种算法进行基准测试，包括一种新的黑箱方法MF-PSO，并据此提出未来实验比较的标准化建议。


<details>
  <summary>Details</summary>
Motivation: 当前MFG与RL结合的研究缺乏统一的评估标准，导致实验环境碎片化、简化且不可比，难以有效评估算法的鲁棒性、泛化能力及失败模式。

Method: 提出Bench-MFG基准套件，构建问题分类体系，设计原型环境，开发MF-Garnets生成随机实例，并在多类环境中测试多种学习算法（含新提出的MF-PSO方法）。

Result: 通过广泛实验证明了所提基准的有效性，揭示了现有方法的性能差异与局限，为算法比较提供了可复现、可扩展的平台，并提炼出标准化实验指南。

Conclusion: Bench-MFG为MFG与RL融合研究提供了首个系统化、可扩展的基准框架，有助于推动该领域向更严谨、可比的实验范式发展。

Abstract: The intersection of Mean Field Games (MFGs) and Reinforcement Learning (RL) has fostered a growing family of algorithms designed to solve large-scale multi-agent systems. However, the field currently lacks a standardized evaluation protocol, forcing researchers to rely on bespoke, isolated, and often simplistic environments. This fragmentation makes it difficult to assess the robustness, generalization, and failure modes of emerging methods. To address this gap, we propose a comprehensive benchmark suite for MFGs (Bench-MFG), focusing on the discrete-time, discrete-space, stationary setting for the sake of clarity. We introduce a taxonomy of problem classes, ranging from no-interaction and monotone games to potential and dynamics-coupled games, and provide prototypical environments for each. Furthermore, we propose MF-Garnets, a method for generating random MFG instances to facilitate rigorous statistical testing. We benchmark a variety of learning algorithms across these environments, including a novel black-box approach (MF-PSO) for exploitability minimization. Based on our extensive empirical results, we propose guidelines to standardize future experimental comparisons. Code available at \href{https://github.com/lorenzomagnino/Bench-MFG}{https://github.com/lorenzomagnino/Bench-MFG}.

</details>


### [104] [Constraint-Rectified Training for Efficient Chain-of-Thought](https://arxiv.org/abs/2602.12526)
*Qinhang Wu,Sen Lin,Ming Zhang,Yingbin Liang,Ness B. Shroff*

Main category: cs.LG

TL;DR: 提出CRT（Constraint-Rectified Training）框架，通过参考引导的约束优化实现高效推理，交替最小化推理长度并仅在性能低于参考时修正准确率，稳定剪枝冗余步骤。结合两阶段训练策略，先发现最短可靠推理模式，再在学习到的长度预算下优化准确率，防止冗长推理重现。实验表明该方法显著降低令牌使用量，同时保持高且稳定的答案质量，并减少内部语言冗余，支持细粒度控制推理冗长度而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的思维链（CoT）后训练方法虽提升推理能力，但长推理路径带来高推理成本和冗余（过思考），当前启发式方法如长度感知奖励或提示校准存在准确率下降和超参数敏感问题，亟需更稳定、可解释的高效推理策略。

Method: 引入基于参考引导的约束优化的CRT框架，交替执行推理长度最小化与精度修正（仅当性能低于参考值时触发），结合两阶段训练：第一阶段寻找最短可靠推理模式，第二阶段在学习到的长度预算内优化准确率，防止冗长回复再现。

Result: CRT显著降低推理中的令牌消耗，维持高且稳定的答案质量；不仅缩短输出长度，还减少内部语言冗余；生成的中间检查点提供从简到繁的推理层次，实现无需重训练的推理冗长度精细调控。

Conclusion: CRT提供一种原理清晰、稳定可靠的高效推理后训练框架，有效平衡推理长度与准确性，推动大模型推理向高效、可控、可解释方向发展。

Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer quality and unlock abilities such as self-correction, they also incur high inference costs and often introduce redundant steps, known as overthinking. Recent research seeks to develop efficient reasoning strategies that balance reasoning length and accuracy, either through length-aware reward design or prompt-based calibration. However, these heuristic-based approaches may suffer from severe accuracy drop and be very sensitive to hyperparameters. To address these problems, we introduce CRT (Constraint-Rectified Training), a principled post-training framework based on reference-guarded constrained optimization, yielding a more stable and interpretable formulation for efficient reasoning. CRT alternates between minimizing reasoning length and rectifying accuracy only when performance falls below the reference, enabling stable and effective pruning of redundant reasoning. We further extend CRT with a two-stage training scheme that first discovers the shortest reliable reasoning patterns and then refines accuracy under a learnt length budget, preventing the re-emergence of verbose CoT. Our comprehensive evaluation shows that this framework consistently reduces token usage while maintaining answer quality at a robust and reliable level. Further analysis reveals that CRT improves reasoning efficiency not only by shortening responses but also by reducing internal language redundancy, leading to a new evaluation metric. Moreover, CRT-based training naturally yields a sequence of intermediate checkpoints that span a spectrum of explanation lengths while preserving correctness, enabling fine-grained control over reasoning verbosity without retraining.

</details>


### [105] [Analytical Results for Two Exponential Family Distributions in Hierarchical Dirichlet Processes](https://arxiv.org/abs/2602.12527)
*Naiqi Li*

Main category: cs.LG

TL;DR: 本文研究了在层次狄利克雷过程（HDP）框架下，泊松分布和正态分布这两种指数族分布的解析结果，推导出相应的伽马-泊松和正态-伽马-正态共轭对的闭式表达式，扩展了HDP在非参数贝叶斯建模中的应用范围。


<details>
  <summary>Details</summary>
Motivation: 现有HDP应用主要集中在狄利克雷-多项式共轭结构上，但该框架本身更通用，可适用于广泛的共轭先验-似然对，尤其是指数族分布，因此需要拓展其在其他分布上的应用。

Method: 通过数学推导，针对泊松分布和正态分布，在HDP框架下建立伽马-泊松和正态-伽马-正态共轭对，并提供详细的推导与证明，揭示其内在数学结构。

Result: 成功推导出泊松和正态分布下的闭式解析表达式，为非参数贝叶斯模型中系统利用共轭性提供了理论支持。

Conclusion: 本研究扩展了HDP在非参数贝叶斯建模中的适用性，为研究人员在复杂数据建模中使用层次化非参数方法提供了实用的解析工具。

Abstract: The Hierarchical Dirichlet Process (HDP) provides a flexible Bayesian nonparametric framework for modeling grouped data with a shared yet unbounded collection of mixture components. While existing applications of the HDP predominantly focus on the Dirichlet-multinomial conjugate structure, the framework itself is considerably more general and, in principle, accommodates a broad class of conjugate prior-likelihood pairs. In particular, exponential family distributions offer a unified and analytically tractable modeling paradigm that encompasses many commonly used distributions. In this paper, we investigate analytic results for two important members of the exponential family within the HDP framework: the Poisson distribution and the normal distribution. We derive explicit closed-form expressions for the corresponding Gamma-Poisson and Normal-Gamma-Normal conjugate pairs under the hierarchical Dirichlet process construction. Detailed derivations and proofs are provided to clarify the underlying mathematical structure and to demonstrate how conjugacy can be systematically exploited in hierarchical nonparametric models. Our work extends the applicability of the HDP beyond the Dirichlet-multinomial setting and furnishes practical analytic results for researchers employing hierarchical Bayesian nonparametrics.

</details>


### [106] [Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models](https://arxiv.org/abs/2602.12529)
*Bowen Ping,Chengyou Jia,Minnan Luo,Hangwei Qian,Ivor Tsang*

Main category: cs.LG

TL;DR: Flow-Factory 是一个统一的框架，通过模块化、基于注册表的架构解耦算法、模型和奖励，支持多种模型和算法的无缝集成，显著降低实现复杂度，提升研究效率。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在对齐扩散和流匹配模型与人类偏好方面虽具潜力，但存在代码库碎片化、模型特定实现和工程复杂性等问题，限制了研究进展。

Method: 采用模块化、注册表驱动的设计，将算法、模型和奖励解耦，支持灵活扩展与集成。

Result: 成功支持GRPO、DiffusionNFT、AWM等算法在Flux、Qwen-Image、WAN视频模型上的应用，具备生产级内存优化、多奖励训练及分布式训练能力。

Conclusion: Flow-Factory 有效降低了实现复杂度，使研究人员能快速原型设计并规模化创新，推动未来研究发展。

Abstract: Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples algorithms, models, and rewards through through a modular, registry-based architecture. This design enables seamless integration of new algorithms and architectures, as demonstrated by our support for GRPO, DiffusionNFT, and AWM across Flux, Qwen-Image, and WAN video models. By minimizing implementation overhead, Flow-Factory empowers researchers to rapidly prototype and scale future innovations with ease. Flow-Factory provides production-ready memory optimization, flexible multi-reward training, and seamless distributed training support. The codebase is available at https://github.com/X-GenGroup/Flow-Factory.

</details>


### [107] [AMPS: Adaptive Modality Preference Steering via Functional Entropy](https://arxiv.org/abs/2602.12533)
*Zihan Huang,Xintong Li,Rohan Surana,Tong Yu,Rui Wang,Julian McAuley,Jingbo Shang,Junda Wu*

Main category: cs.LG

TL;DR: 本文提出一种实例感知的调制策略，用于更精确地控制多模态大语言模型（MLLMs）的模态偏好。通过引入一个诊断指标来量化每种模态的信息贡献，并根据样本敏感性动态调整调制强度，避免了传统全局统一调制带来的性能下降或无效问题。实验表明，该方法在调节模态偏好方面优于传统方法，同时保持较低的生成错误率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型常表现出对某一模态的偏好，导致在推理时过度依赖语言先验或视觉显著但与文本事实不符的内容。现有方法采用统一强度的调制策略，但强调制会损害标准推理性能，弱调制又效果有限；且不同样本对调制的敏感度差异大，难以设定合适的全局强度。因此需要一种更精细、自适应的调制机制。

Method: 提出一个实例感知的诊断指标，用于衡量每个模态在特定输入中的信息贡献，并据此识别样本对调制的敏感性。基于此，设计了一种自适应缩放策略，对敏感样本降低调制强度，并引入可学习模块以自动推断调制模式，实现对模态偏好的实例级控制。

Result: 实验结果显示，所提方法在调节模态偏好方面表现更优，能有效调整模型行为，同时维持较低的生成错误率，相比传统全局调制方式具有更高的鲁棒性和灵活性。

Conclusion: 本文提出的实例感知调制框架能够根据输入样本特性动态调整调制强度，有效缓解多模态模型的模态偏好问题，在不显著影响推理质量的前提下实现更精准的模态控制。该方法为多模态模型的可控推理提供了新思路。

Abstract: Multimodal Large Language Models (MLLMs) often exhibit significant modality preference, which is a tendency to favor one modality over another. Depending on the input, they may over-rely on linguistic priors relative to visual evidence, or conversely over-attend to visually salient but facts in textual contexts. Prior work has applied a uniform steering intensity to adjust the modality preference of MLLMs. However, strong steering can impair standard inference and increase error rates, whereas weak steering is often ineffective. In addition, because steering sensitivity varies substantially across multimodal instances, a single global strength is difficult to calibrate. To address this limitation with minimal disruption to inference, we introduce an instance-aware diagnostic metric that quantifies each modality's information contribution and reveals sample-specific susceptibility to steering. Building on these insights, we propose a scaling strategy that reduces steering for sensitive samples and a learnable module that infers scaling patterns, enabling instance-aware control of modality preference. Experimental results show that our instance-aware steering outperforms conventional steering in modulating modality preference, achieving effective adjustment while keeping generation error rates low.

</details>


### [108] [Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference](https://arxiv.org/abs/2602.12542)
*Pengfei Hu,Chang Lu,Feifan Liu,Yue Ning*

Main category: cs.LG

TL;DR: ExtraCare 是一种用于电子健康记录（EHR）临床事件预测的深度学习模型，旨在解决因数据分布变化导致的性能下降问题。通过将患者表示分解为不变和共变成分，并在训练中监督两者并强制正交性，该模型在保持标签信息的同时揭示了领域特异性变化，从而实现更准确的预测。更重要的是，它通过将稀疏潜在维度映射到医学概念并利用针对性消融分析量化其贡献，提供了人类可理解的解释。在两个真实世界EHR数据集上的多领域划分设置下评估表明，ExtraCare不仅性能优越，且具备更强的透明度，案例研究验证了其预测与解释的准确性。


<details>
  <summary>Details</summary>
Motivation: 临床事件预测模型在部署时常因数据分布差异导致性能下降，尽管领域自适应（DA）方法可缓解此问题，但其‘黑箱’特性难以在医疗实践中获得信任与安全认可，因此亟需兼具高精度与可解释性的解决方案。

Method: 提出ExtraCare模型，将患者表示分解为不变和共变组件；通过监督这两个组件并强制它们在训练中保持正交性，以保留标签信息并暴露领域特异性变化；利用医学概念映射与针对性消融分析实现人类可理解的解释。

Result: 在两个真实世界EHR数据集上进行多领域划分测试，结果显示ExtraCare在预测准确率上优于多数特征对齐模型，同时提供清晰、可信的解释，通过大量案例研究验证了其有效性和可解释性。

Conclusion: ExtraCare通过分离不变与共变表示并引入可解释机制，在提升临床事件预测性能的同时满足医疗场景对透明度的要求，为实际应用提供了可靠且可信的解决方案。

Abstract: Deep learning models for clinical event prediction on electronic health records (EHR) often suffer performance degradation when deployed under different data distributions. While domain adaptation (DA) methods can mitigate such shifts, its "black-box" nature prevents widespread adoption in clinical practice where transparency is essential for trust and safety. We propose ExtraCare to decompose patient representations into invariant and covariant components. By supervising these two components and enforcing their orthogonality during training, our model preserves label information while exposing domain-specific variation at the same time for more accurate predictions than most feature alignment models. More importantly, it offers human-understandable explanations by mapping sparse latent dimensions to medical concepts and quantifying their contributions via targeted ablations. ExtraCare is evaluated on two real-world EHR datasets across multiple domain partition settings, demonstrating superior performance along with enhanced transparency, as evidenced by its accurate predictions and explanations from extensive case studies.

</details>


### [109] [SD-MoE: Spectral Decomposition for Effective Expert Specialization](https://arxiv.org/abs/2602.12556)
*Ruijun Huang,Fang Dong,Xin Zhang,Hengjie Cao,Zhendong Huang,Anrui Chen,Jixian Zhou,Mengyi Chen,Yifeng Yang,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Fan Yang,Tun Lu,Chun Zhang,Li Shang*

Main category: cs.LG

TL;DR: 本文从谱视角分析了Mixture-of-Experts（MoE）架构中专家专业化失败的原因，发现参数与梯度在主谱成分上高度重叠，且低秩的语料结构导致梯度子空间强对齐，门控机制又偏好沿这些主导方向路由输入，从而限制了专家分化。为此，提出Spectral-Decoupled MoE（SD-MoE），通过在谱空间分解参数与梯度，实现有效专家专业化，在不显著增加计算量的前提下提升下游任务性能，并可无缝集成至Qwen、DeepSeek等现有MoE架构中。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构中专家专业化常因参数与梯度的高重叠性及门控机制的主导方向偏好而失效，导致部分专家功能趋同，降低模型有效容量与性能。

Method: 提出Spectral-Decoupled MoE（SD-MoE），在参数和梯度空间中进行谱分解，以解耦专家间的主导成分，打破其共现模式，促进专家差异化。

Result: SD-MoE在多个下游任务中表现更优，实现了有效的专家专业化，计算开销极小，且兼容性强，可广泛应用于各类现有MoE模型。

Conclusion: 通过谱空间解耦，SD-MoE成功克服了MoE中专家同质化问题，为大规模语言模型的高效扩展提供了新路径。

Abstract: Mixture-of-Experts (MoE) architectures scale Large Language Models via expert specialization induced by conditional computation. In practice, however, expert specialization often fails: some experts become functionally similar, while others functioning as de facto shared experts, limiting the effective capacity and model performance. In this work, we analysis from a spectral perspective on parameter and gradient spaces, uncover that (1) experts share highly overlapping dominant spectral components in their parameters, (2) dominant gradient subspaces are strongly aligned across experts, driven by ubiquitous low-rank structure in human corpus, and (3) gating mechanisms preferentially route inputs along these dominant directions, further limiting specialization. To address this, we propose Spectral-Decoupled MoE (SD-MoE), which decomposes both parameter and gradient in the spectral space. SD-MoE improves performance across downstream tasks, enables effective expert specialization, incurring minimal additional computation, and can be seamlessly integrated into a wide range of existing MoE architectures, including Qwen and DeepSeek.

</details>


### [110] [Fractional Order Federated Learning for Battery Electric Vehicle Energy Consumption Modeling](https://arxiv.org/abs/2602.12567)
*Mohammad Partohaghighi,Roummel Marcia,Bruce J. West,YangQuan Chen*

Main category: cs.LG

TL;DR: 提出FO-RI-FedAvg，一种轻量级、模块化的联邦平均扩展方法，通过客户端的自适应粗糙度感知正则化和非整数阶局部优化，提升连通电动车在不稳定的通信环境下的学习稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统联邦平均（FedAvg）及许多先进方法在连接电动车因间歇性连接、动态客户端参与和不同运行条件导致的显著客户端差异下，容易出现过度漂移和收敛性能下降的问题。

Method: 引入两种互补的客户端机制：(i) 自适应粗糙度感知的近端正则化，根据本地损失景观粗糙度动态调整向全局模型拉回的程度；(ii) 非整数阶局部优化，利用短期记忆平滑冲突的更新方向。该方法保持标准FedAvg服务器聚合，仅增加可分摊开销的逐元素操作，并支持各组件独立启用或关闭。

Result: 在两个真实世界电动车能源预测数据集VED和eVED上的实验表明，与强基线方法相比，FO-RI-FedAvg在客户端参与度降低的情况下仍实现了更高的准确率和更稳定的收敛性能。

Conclusion: FO-RI-FedAvg是一种有效应对连通电动车联邦学习中不稳定性问题的方法，具有良好的实用性与可扩展性。

Abstract: Federated learning on connected electric vehicles (BEVs) faces severe instability due to intermittent connectivity, time-varying client participation, and pronounced client-to-client variation induced by diverse operating conditions. Conventional FedAvg and many advanced methods can suffer from excessive drift and degraded convergence under these realistic constraints. This work introduces Fractional-Order Roughness-Informed Federated Averaging (FO-RI-FedAvg), a lightweight and modular extension of FedAvg that improves stability through two complementary client-side mechanisms: (i) adaptive roughness-informed proximal regularization, which dynamically tunes the pull toward the global model based on local loss-landscape roughness, and (ii) non-integer-order local optimization, which incorporates short-term memory to smooth conflicting update directions. The approach preserves standard FedAvg server aggregation, adds only element-wise operations with amortizable overhead, and allows independent toggling of each component. Experiments on two real-world BEV energy prediction datasets, VED and its extended version eVED, show that FO-RI-FedAvg achieves improved accuracy and more stable convergence compared to strong federated baselines, particularly under reduced client participation.

</details>


### [111] [VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction](https://arxiv.org/abs/2602.12579)
*Xin-Qiang Cai,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 提出VI-CuRL框架，利用模型内在置信度构建无需外部验证器的课程学习机制，解决无验证器环境下策略优化中的梯度方差问题，实现训练稳定性和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于验证器的强化学习方法在可扩展性上受限，且研究表明其主要作用是激发模型潜在能力，因此需要发展无需验证器的方法；但现有无验证器方法面临梯度方差大导致训练崩溃的问题。

Method: 引入基于模型内在置信度的课程学习机制，优先处理高置信度样本，通过调节偏差-方差权衡来降低动作和问题方差，提出具有渐近无偏性的估计器。

Result: 理论证明所提估计器具有渐近无偏性；实验显示在六个挑战性基准测试中，无论是否有验证器，VI-CuRL均显著优于现有无验证器基线方法，表现出更强的稳定性与性能。

Conclusion: VI-CuRL成功实现了无需外部验证器的稳定高效强化学习，为提升大语言模型推理能力提供了新范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a dominant paradigm for enhancing Large Language Models (LLMs) reasoning, yet its reliance on external verifiers limits its scalability. Recent findings suggest that RLVR primarily functions by eliciting latent capabilities, motivating the development of verifier-free algorithms. However, in such settings, standard methods like Group Relative Policy Optimization face a critical challenge: destructive gradient variance that often leads to training collapse. To address this issue, we introduceVerifier-Independent Curriculum Reinforcement Learning (VI-CuRL), a framework that leverages the model's intrinsic confidence to construct a curriculum independent from external verifiers. By prioritizing high-confidence samples, VI-CuRL effectively manages the bias-variance trade-off, specifically targeting the reduction of action and problem variance. We provide a rigorous theoretical analysis, proving that our estimator guarantees asymptotic unbiasedness. Empirically, VI-CuRL promotes stability and consistently outperforms verifier-independent baselines across six challenging benchmarks with/without verifiers.

</details>


### [112] [Multi-Head Attention as a Source of Catastrophic Forgetting in MoE Transformers](https://arxiv.org/abs/2602.12587)
*Anrui Chen,Ruijun Huang,Xin Zhang,Fang Dong,Hengjie Cao,Zhendong Huang,Yifeng Yang,Mengyi Chen,Jixian Zhou,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Qin Lv,Robert P. Dick,Yuan Cheng,Tun Lu,Fan Yang,Li Shang*

Main category: cs.LG

TL;DR: MH-MoE提出通过头级路由提升路由粒度，缓解混合专家模型在持续学习中的遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有MoE架构在持续学习中仍存在显著遗忘，尽管其稀疏路由设计理论上可减少干扰；根源在于多头注意力的预路由瓶颈导致特征组合冲突。

Method: 提出MH-MoE，对子表示进行头级路由，以提高路由粒度并减少特征组合碰撞。

Result: 在TRACE数据集上，相较于LoRAMoE，MH-MoE将Qwen3-0.6B的后向迁移损失（BWT）从11.2%降至4.5%，有效缓解遗忘。

Conclusion: 通过头级路由增强路由精细度，可显著降低特征组合冲突，从而提升MoE在持续学习中的稳定性与性能。

Abstract: Mixture-of-Experts (MoE) architectures are often considered a natural fit for continual learning because sparse routing should localize updates and reduce interference, yet MoE Transformers still forget substantially even with sparse, well-balanced expert utilization. We attribute this gap to a pre-routing bottleneck: multi-head attention concatenates head-specific signals into a single post-attention router input, forcing routing to act on co-occurring feature compositions rather than separable head channels. We show that this router input simultaneously encodes multiple separately decodable semantic and structural factors with uneven head support, and that different feature compositions induce weakly aligned parameter-gradient directions; as a result, routing maps many distinct compositions to the same route. We quantify this collision effect via a route-wise effective composition number $N_{eff}$ and find that higher $N_{eff}$ is associated with larger old-task loss increases after continual training. Motivated by these findings, we propose MH-MoE, which performs head-wise routing over sub-representations to increase routing granularity and reduce composition collisions. On TRACE with Qwen3-0.6B/8B, MH-MoE effectively mitigates forgetting, reducing BWT on Qwen3-0.6B from 11.2% (LoRAMoE) to 4.5%.

</details>


### [113] [Vehicle behaviour estimation for abnormal event detection using distributed fiber optic sensing](https://arxiv.org/abs/2602.12591)
*Hemant Prasad,Daisuke Ikefuji,Shin Tominaga,Hitoshi Sakurai,Manabu Otani*

Main category: cs.LG

TL;DR: 本文提出一种基于分布式光纤传感（DFOS）系统检测单车道异常的方法，通过追踪车辆轨迹和监测车辆振动频谱中心的变化来识别车道变换，从而发现交通异常。该方法利用聚类技术估计车辆位置并拟合路径，在真实交通数据上实现了80%的车道变更检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有分布式光纤传感系统虽能有效监控大范围交通状况，但在检测由单车道异常引起的拥堵方面仍存在困难，尤其难以捕捉导致拥堵的车道变换行为。因此需要一种更精确的方法来识别此类异常。

Method: 通过聚类技术估计车辆在所有时间点的位置，并拟合其行驶路径；利用参考车辆的振动频谱中心变化来监测车道变换行为，进而识别单车道异常。

Result: 在真实交通数据上的评估表明，该方法对车道变更事件的检测准确率达到80%，有效反映了异常交通状况的存在。

Conclusion: 所提方法能够有效利用现有光纤基础设施，通过监测车辆振动特征变化实现单车道异常检测，具有较高的实用性与应用前景。

Abstract: The distributed fiber-optic sensing (DFOS) system is a cost-effective wide-area traffic monitoring technology that utilizes existing fiber infrastructure to effectively detect traffic congestions. However, detecting single-lane abnormalities, that lead to congestions, is still a challenge. These single-lane abnormalities can be detected by monitoring lane change behaviour of vehicles, performed to avoid congestion along the monitoring section of a road. This paper presents a method to detect single-lane abnormalities by tracking individual vehicle paths and detecting vehicle lane changes along a section of a road. We propose a method to estimate the vehicle position at all time instances and fit a path using clustering techniques. We detect vehicle lane change by monitoring any change in spectral centroid of vehicle vibrations by tracking a reference vehicle along a highway. The evaluation of our proposed method with real traffic data showed 80% accuracy for lane change detection events that represent presence of abnormalities.

</details>


### [114] [HyperMLP: An Integrated Perspective for Sequence Modeling](https://arxiv.org/abs/2602.12601)
*Jiecheng Lu,Shihao Yang*

Main category: cs.LG

TL;DR: 本文提出将自注意力机制视为一种动态的两层MLP，其权重由上下文历史生成。注意力分数构成不断增长的隐藏表示，使用ReLU或GLU等激活函数实现输入条件下的选择，而非概率分布。基于此观点，提出HyperMLP和HyperGLU模型，通过反向偏移布局在特征空间和序列空间中学习动态混合，并在相同参数预算下优于传统softmax注意力基线。


<details>
  <summary>Details</summary>
Motivation: 现有自注意力机制通常被视为概率查询-键查找，依赖归一化注意力分数和固定位置语义。本文旨在提供更简单、统一的视角，摆脱对概率分布的依赖，提升模型表达能力与灵活性。

Method: 将自回归注意力头建模为动态两层MLP，权重由上下文历史决定；引入反向偏移（滞后）布局以对齐时序混合与自回归语义；采用ReLU或GLU激活函数实现输入条件选择；设计HyperMLP和HyperGLU结构进行动态混合。

Result: 理论分析表明该结构具有强表达能力；实验显示在相同参数量下，HyperMLP/HyperGLU在多个任务上持续优于主流softmax注意力基线。

Conclusion: 自注意力可被统一理解为动态MLP，该视角不仅简化了模型设计，还显著提升了性能。通过引入动态混合机制，模型在序列建模中展现出更强的表达力与泛化能力。

Abstract: Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can be viewed as a dynamic two-layer MLP whose weights are instantiated from the context history. From this view, attention scores form an ever-growing hidden representation, and standard MLP activations such as ReLU or GLU naturally implement input-conditioned selection over a context-dependent memory pool rather than a probability distribution. Based on this formulation, we introduce HyperMLP and HyperGLU, which learn dynamic mixing in both feature space and sequence space, using a reverse-offset (lag) layout to align temporal mixing with autoregressive semantics. We provide theoretical characterizations of the expressivity and implications of this structure, and empirically show that HyperMLP/HyperGLU consistently outperform strong softmax-attention baselines under matched parameter budgets.

</details>


### [115] [Block-Sample MAC-Bayes Generalization Bounds](https://arxiv.org/abs/2602.12605)
*Matthias Frey,Jingge Zhu,Michael C. Gastpar*

Main category: cs.LG

TL;DR: 本文提出了一类新颖的块采样MAC-Bayes界（均值近似正确），该界在形式上是已知PAC-Bayes界的一种期望版本的推广。与传统PAC-Bayes界不同，新界中的散度项仅依赖于训练数据的子集（或“块”），从而有望显著提升传统PAC-Bayes和MAC-Bayes界的紧致性。数值示例表明，当原PAC-Bayes界在任何先验选择下都失效时，新界仍可在合适的块大小下保持有限。此外，文章还探讨了是否存在高概率版本的此类MAC-Bayes界，结果以反例证明：一般情况下不可能存在一个既以快于$\mathcal{O}(1/\log n)$的速度趋于零、又具有对误差概率对数依赖性的PAC-Bayes界。


<details>
  <summary>Details</summary>
Motivation: 现有PAC-Bayes界虽能提供高概率下的泛化误差界，但其紧致性受限；而MAC-Bayes界虽关注期望泛化误差，但缺乏有效的散度项设计。本文旨在通过引入基于数据块的散度项，改进界的整体紧致性，并探索其高概率版本的可能性。

Method: 提出一类新的块采样MAC-Bayes界，利用训练数据的分块结构构造仅依赖于子集的散度项，从而降低界对全样本的敏感性。通过理论分析与反例验证，评估其紧致性优势及高概率版本的不可行性。

Result: 新提出的MAC-Bayes界在数值实例中表现出远优于传统界的表现，即使原PAC-Bayes界失效，新界仍可为有限值；同时证明了不存在满足特定收敛速率与对数依赖条件的高概率版本。

Conclusion: 本文提出的块采样MAC-Bayes界在理论上和实践中均展现出更强的紧致性和实用性，且揭示了其高概率版本在特定条件下不可实现的本质限制。

Abstract: We present a family of novel block-sample MAC-Bayes bounds (mean approximately correct). While PAC-Bayes bounds (probably approximately correct) typically give bounds for the generalization error that hold with high probability, MAC-Bayes bounds have a similar form but bound the expected generalization error instead. The family of bounds we propose can be understood as a generalization of an expectation version of known PAC-Bayes bounds. Compared to standard PAC-Bayes bounds, the new bounds contain divergence terms that only depend on subsets (or \emph{blocks}) of the training data. The proposed MAC-Bayes bounds hold the promise of significantly improving upon the tightness of traditional PAC-Bayes and MAC-Bayes bounds. This is illustrated with a simple numerical example in which the original PAC-Bayes bound is vacuous regardless of the choice of prior, while the proposed family of bounds are finite for appropriate choices of the block size. We also explore the question whether high-probability versions of our MAC-Bayes bounds (i.e., PAC-Bayes bounds of a similar form) are possible. We answer this question in the negative with an example that shows that in general, it is not possible to establish a PAC-Bayes bound which (a) vanishes with a rate faster than $\mathcal{O}(1/\log n)$ whenever the proposed MAC-Bayes bound vanishes with rate $\mathcal{O}(n^{-1/2})$ and (b) exhibits a logarithmic dependence on the permitted error probability.

</details>


### [116] [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)
*Justin Gu,Rishabh Ranjan,Charilaos Kanatsoulis,Haiming Tang,Martin Jurkovic,Valter Hudovernik,Mark Znidar,Pranshu Chaturvedi,Parth Shroff,Fengyu Li,Jure Leskovec*

Main category: cs.LG

TL;DR: RelBench v2 是一个大规模、多领域的关系型深度学习基准，包含11个数据集（超过2200万行，29张表），新增了学术出版、企业资源规划、消费平台和临床记录等数据。引入了自动补全任务，要求模型在尊重时间约束的前提下推断表中缺失的属性值，扩展了传统的基于SQL查询的预测任务。此外，还整合了外部基准如Temporal Graph Benchmark、ReDeLEx和4DBInfer，实现统一的时序-关系评估与预训练支持。实验表明，关系型深度学习模型在自动补全、预测和推荐任务上均优于单表基线，证明了显式建模关系结构的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前关系型深度学习（RDL）正向更大规模模型和关系基础模型发展，亟需可扩展且真实的评估基准来推动系统性研究与进步。现有基准在数据规模、任务多样性及跨系统集成方面存在不足，限制了模型性能的全面评估。

Method: 构建RelBench v2基准：新增四个大规模真实世界数据集；设计自动补全任务以支持更自然的缺失值推断；将外部基准（如Temporal Graph Benchmark、ReDeLEx、4DBInfer）转换为统一的关系型格式，实现跨系统的兼容性与评估一致性。

Result: RDL模型在自动补全、预测和推荐任务中显著优于单表基线模型，验证了关系结构建模的有效性；多源数据融合与任务扩展增强了基准的实用性与代表性。

Conclusion: RelBench v2 提供了一个全面、可扩展且现实的关系型深度学习评估框架，支持未来大模型在复杂真实场景中的系统性评测与优化。

Abstract: Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic benchmarks are essential for enabling systematic evaluation and progress. In this paper, we introduce RelBench v2, a major expansion of the RelBench benchmark for RDL. RelBench v2 adds four large-scale relational datasets spanning scholarly publications, enterprise resource planning, consumer platforms, and clinical records, increasing the benchmark to 11 datasets comprising over 22 million rows across 29 tables. We further introduce autocomplete tasks, a new class of predictive objectives that require models to infer missing attribute values directly within relational tables while respecting temporal constraints, expanding beyond traditional forecasting tasks constructed via SQL queries. In addition, RelBench v2 expands beyond its native datasets by integrating external benchmarks and evaluation frameworks: we translate event streams from the Temporal Graph Benchmark into relational schemas for unified relational-temporal evaluation, interface with ReDeLEx to provide uniform access to 70+ real-world databases suitable for pretraining, and incorporate 4DBInfer datasets and tasks to broaden multi-table prediction coverage. Experimental results demonstrate that RDL models consistently outperform single-table baselines across autocomplete, forecasting, and recommendation tasks, highlighting the importance of modeling relational structure explicitly.

</details>


### [117] [Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps](https://arxiv.org/abs/2602.12624)
*Sangwoo Jo,Sungjoon Choi*

Main category: cs.LG

TL;DR: 本文提出SDM框架，通过几何视角优化扩散模型采样过程中的求解器选择与调度。基于对ODE动力学的分析，早期高噪声阶段使用低阶求解器，后期非线性增强时逐步切换至高阶求解器，并引入Wasserstein有界优化框架，系统推导出自适应时间步长，显式控制局部离散误差，确保采样过程忠实于连续动态。无需额外训练或结构修改，即可在多个基准上达到当前最优性能（如CIFAR-10 FID 1.93），同时减少函数求值次数。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型采样方法受限于静态启发式策略，缺乏对求解器选择与调度的系统性设计，导致采样成本高，效率不足。

Method: 从几何视角出发，分析扩散轨迹的ODE动态特性，提出SDM框架；利用低阶求解器处理早期高噪声阶段，高阶求解器应对后期非线性增强阶段；引入Wasserstein有界优化框架，推导自适应时间步长以约束局部离散误差。

Result: 在标准基准上实现SOTA性能（如CIFAR-10 FID 1.93，FFHQ 2.41，AFHQv2 1.98），且函数求值次数更少，无需额外训练或架构修改。

Conclusion: SDM通过理论驱动的求解器选择与自适应时间步调度，显著提升扩散模型采样的效率与质量，为高效生成模型部署提供了新范式。

Abstract: Diffusion-based generative models have achieved remarkable performance across various domains, yet their practical deployment is often limited by high sampling costs. While prior work focuses on training objectives or individual solvers, the holistic design of sampling, specifically solver selection and scheduling, remains dominated by static heuristics. In this work, we revisit this challenge through a geometric lens, proposing SDM, a principled framework that aligns the numerical solver with the intrinsic properties of the diffusion trajectory. By analyzing the ODE dynamics, we show that efficient low-order solvers suffice in early high-noise stages while higher-order solvers can be progressively deployed to handle the increasing non-linearity of later stages. Furthermore, we formalize the scheduling by introducing a Wasserstein-bounded optimization framework. This method systematically derives adaptive timesteps that explicitly bound the local discretization error, ensuring the sampling process remains faithful to the underlying continuous dynamics. Without requiring additional training or architectural modifications, SDM achieves state-of-the-art performance across standard benchmarks, including an FID of 1.93 on CIFAR-10, 2.41 on FFHQ, and 1.98 on AFHQv2, with a reduced number of function evaluations compared to existing samplers. Our code is available at https://github.com/aiimaginglab/sdm.

</details>


### [118] [Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL](https://arxiv.org/abs/2602.12636)
*Xin Liu,Yixuan Li,Yuhui Chen,Yuxing Qin,Haoran Li,Dongbin Zhao*

Main category: cs.LG

TL;DR: DEG是一种无需人工标注或大量监督的新型框架，通过利用大规模视频生成模型的先验知识，仅需少量专家视频即可为每个RL episode生成任务指导。其双粒度对比奖励机制在粗粒度探索与细粒度匹配之间取得平衡，引导智能体在对比自监督潜在空间中逐步逼近生成的指导视频，从而高效完成目标任务。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹成功奖励稀疏，限制了强化学习的样本效率；现有密集奖励方法依赖高质量人工标注或大量专家监督，难以推广。因此需要一种无需人工干预、样本高效的密集奖励机制。

Method: 提出DEG框架，结合大模型生成的剧集指导，设计双粒度对比奖励，在自监督潜在空间中实现对生成指导视频的渐进式匹配，以促进高效探索与稳定策略收敛。

Result: 在18个多样化任务（含仿真与真实世界）上的实验表明，DEG不仅能有效激发探索、快速发现稀疏成功奖励，还能独立实现高效强化学习与稳定策略收敛。

Conclusion: DEG通过生成式指导与双粒度对比奖励，实现了无需人工标注的高效密集奖励机制，显著提升强化学习的样本效率与泛化能力。

Abstract: Designing suitable rewards poses a significant challenge in reinforcement learning (RL), especially for embodied manipulation. Trajectory success rewards are suitable for human judges or model fitting, but the sparsity severely limits RL sample efficiency. While recent methods have effectively improved RL via dense rewards, they rely heavily on high-quality human-annotated data or abundant expert supervision. To tackle these issues, this paper proposes Dual-granularity contrastive reward via generated Episodic Guidance (DEG), a novel framework to seek sample-efficient dense rewards without requiring human annotations or extensive supervision. Leveraging the prior knowledge of large video generation models, DEG only needs a small number of expert videos for domain adaptation to generate dedicated task guidance for each RL episode. Then, the proposed dual-granularity reward that balances coarse-grained exploration and fine-grained matching, will guide the agent to efficiently approximate the generated guidance video sequentially in the contrastive self-supervised latent space, and finally complete the target task. Extensive experiments on 18 diverse tasks across both simulation and real-world settings show that DEG can not only serve as an efficient exploration stimulus to help the agent quickly discover sparse success rewards, but also guide effective RL and stable policy convergence independently.

</details>


### [119] [Uncovering spatial tissue domains and cell types in spatial omics through cross-scale profiling of cellular and genomic interactions](https://arxiv.org/abs/2602.12651)
*Rui Yan,Xiaohan Xing,Xun Wang,Zixia Zhou,Md Tauhidul Islam,Lei Xing*

Main category: cs.LG

TL;DR: CellScape 是一种深度学习框架，旨在解决空间转录组学（ST）数据中的噪声、大规模和结构复杂性问题。它联合建模细胞在组织空间中的相互作用与基因组关系，整合空间信号与基因调控机制，实现高精度的细胞空间域分割和全面的细胞分析，适用于多种转录组数据集，提升对ST数据的深度解析能力。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法难以有效捕捉空间交互与基因组关系之间的复杂互作，导致无法揭示关键生物模式，因此需要一种新方法来克服ST数据的固有挑战。

Method: 提出CellScape，一种联合建模细胞空间相互作用与基因组关系的深度学习框架，通过整合空间信息与基因调控机制，生成综合表征以支持高效分析。

Result: 成功识别出具有生物学意义的模式，显著改善空间域分割，并支持跨多种转录组数据集的全面空间细胞分析，展现出高准确性和通用性。

Conclusion: CellScape为高通量空间转录组数据提供了一个精准且通用的分析框架，能够深入揭示细胞空间组织与功能之间的内在联系，推动了空间生物学研究的发展。

Abstract: Cellular identity and function are linked to both their intrinsic genomic makeup and extrinsic spatial context within the tissue microenvironment. Spatial transcriptomics (ST) offers an unprecedented opportunity to study this, providing in situ gene expression profiles at single-cell resolution and illuminating the spatial and functional organization of cells within tissues. However, a significant hurdle remains: ST data is inherently noisy, large, and structurally complex. This complexity makes it intractable for existing computational methods to effectively capture the interplay between spatial interactions and intrinsic genomic relationships, thus limiting our ability to discern critical biological patterns. Here, we present CellScape, a deep learning framework designed to overcome these limitations for high-performance ST data analysis and pattern discovery. CellScape jointly models cellular interactions in tissue space and genomic relationships among cells, producing comprehensive representations that seamlessly integrate spatial signals with underlying gene regulatory mechanisms. This technique uncovers biologically informative patterns that improve spatial domain segmentation and supports comprehensive spatial cellular analyses across diverse transcriptomics datasets, offering an accurate and versatile framework for deep analysis and interpretation of ST data.w

</details>


### [120] [Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL](https://arxiv.org/abs/2602.13035)
*Yixiao Zhou,Yang Li,Dongzhou Cheng,Hehe Fan,Yu Cheng*

Main category: cs.LG

TL;DR: 本文提出了一种名为Introspective LLM的分层强化学习框架，用于在生成过程中动态学习采样温度，以优化探索与利用的权衡。通过结合隐藏状态与下游奖励，联合优化温度和词元策略，实现在数学推理任务中的性能提升，并展现出与推理不确定性一致的可解释探索行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法在采样温度设置上依赖静态值或启发式调整，这些方法与任务级奖励解耦，无法根据生成过程中的上下文动态适应，限制了大语言模型在强化学习中的表现。

Method: 提出一种分层强化学习框架，使模型在每个解码步骤中基于其隐藏状态选择采样温度，并从该分布中采样下一个词元；温度与词元策略通过坐标上升法联合优化，利用下游任务奖励进行训练。

Result: 在数学推理基准测试中，所提出的温度策略优于固定温度和启发式基线，且表现出与推理不确定性对齐的可解释探索行为。

Conclusion: Introspective LLM成功实现了在生成过程中自适应控制采样温度，提升了语言模型在复杂推理任务中的性能，同时增强了行为的可解释性。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly controls the exploration--exploitation trade-off by modulating policy entropy, yet existing methods rely on static values or heuristic adaptations that are decoupled from task-level rewards. We propose Introspective LLM, a hierarchical reinforcement learning framework that learns to control sampling temperature during generation. At each decoding step, the model selects a temperature based on its hidden state and samples the next token from the resulting distribution. Temperature and token policies are jointly optimized from downstream rewards using a coordinate ascent scheme. Experiments on mathematical reasoning benchmarks show that learned temperature policies outperform fixed and heuristic baselines, while exhibiting interpretable exploration behaviors aligned with reasoning uncertainty.

</details>


### [121] [SLA2: Sparse-Linear Attention with Learnable Routing and QAT](https://arxiv.org/abs/2602.12675)
*Jintao Zhang,Haoxu Wang,Kai Jiang,Kaiwen Zheng,Youhe Jiang,Ion Stoica,Jianfei Chen,Jun Zhu,Joseph E. Gonzalez*

Main category: cs.LG

TL;DR: SLA2 improves upon Sparse-Linear Attention by introducing a learnable router, a more accurate sparse-linear formulation with a learnable ratio, and sparse + low-bit attention via quantization-aware fine-tuning, achieving 97% sparsity and 18.6x speedup in video diffusion models without quality loss.


<details>
  <summary>Details</summary>
Motivation: SLA's heuristic split based on attention weight magnitude is suboptimal, and there is a mismatch between SLA and a direct decomposition of sparse and linear attention, limiting performance and accuracy.

Method: SLA2 employs a learnable router for dynamic selection between sparse and linear attention, a learnable ratio to better combine the two branches, and quantization-aware fine-tuning to implement low-bit attention with reduced error.

Result: SLA2 achieves 97% attention sparsity and an 18.6x speedup in video diffusion models while maintaining generation quality.

Conclusion: SLA2 provides a more efficient and accurate alternative to SLA by addressing its fundamental limitations through learnable components and improved architectural design.

Abstract: Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition into sparse and linear attention. We propose SLA2, which introduces (I) a learnable router that dynamically selects whether each attention computation should use sparse or linear attention, (II) a more faithful and direct sparse-linear attention formulation that uses a learnable ratio to combine the sparse and linear attention branches, and (III) a sparse + low-bit attention design, where low-bit attention is introduced via quantization-aware fine-tuning to reduce quantization error. Experiments show that on video diffusion models, SLA2 can achieve 97% attention sparsity and deliver an 18.6x attention speedup while preserving generation quality.

</details>


### [122] [Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13069)
*Juneyoung Park,Yuri Hong,Seongwan Kim,Jaeho Lee*

Main category: cs.LG

TL;DR: 提出MeSP方法，通过利用LoRA的低秩结构手动推导反向传播，实现内存高效且精确的梯度计算，相比MeBP平均减少49%内存占用，同时解决MeZO梯度估计偏差问题，使在资源受限设备上进行大模型微调成为可能。


<details>
  <summary>Details</summary>
Motivation: 移动设备内存有限，现有方法在精确梯度（高内存）与低内存噪声估计之间存在权衡，亟需一种既能节省内存又能保持梯度准确性的微调方法。

Method: 提出Memory-efficient Structured Backpropagation (MeSP)，通过利用LoRA的低秩特性，在反向传播中重计算中间投影 $h = xA$，避免存储该中间结果，从而大幅降低内存使用。

Result: MeSP在Qwen2.5模型（0.5B-3B）上相比MeBP平均减少49%内存，峰值内存从361MB降至136MB（Qwen2.5-0.5B），且计算出的梯度与真实梯度数学等价；同时发现MeZO梯度与真实梯度相关性极低（余弦相似度≈0.001），解释其收敛慢的原因。

Conclusion: MeSP有效解决了移动设备上大语言模型微调的内存瓶颈问题，实现了高精度与低内存消耗的统一，为隐私保护下的个性化应用提供了可行方案。

Abstract: On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact gradients with high memory (MeBP) and low memory with noisy estimates (MeZO). We propose Memory-efficient Structured Backpropagation (MeSP), which bridges this gap by manually deriving backward passes that exploit LoRA's low-rank structure. Our key insight is that the intermediate projection $h = xA$ can be recomputed during backward at minimal cost since rank $r \ll d_{in}$, eliminating the need to store it. MeSP achieves 49\% average memory reduction compared to MeBP on Qwen2.5 models (0.5B--3B) while computing mathematically identical gradients. Our analysis also reveals that MeZO's gradient estimates show near-zero correlation with true gradients (cosine similarity $\approx$0.001), explaining its slow convergence. MeSP reduces peak memory from 361MB to 136MB for Qwen2.5-0.5B, enabling fine-tuning scenarios previously infeasible on memory-constrained devices.

</details>


### [123] [Flow Matching from Viewpoint of Proximal Operators](https://arxiv.org/abs/2602.12683)
*Kenji Fukumizu,Wei Huang,Han Bao,Shuntuo Xu,Nisha Chandramoothy*

Main category: cs.LG

TL;DR: 本文重新表述了最优传输条件流匹配（OT-CFM），揭示其可通过扩展的Brenier势能实现精确的近端公式，无需假设目标分布具有密度。该方法给出了向量场的显式近端表达式，并证明了小批量OT-CFM在批量增大时收敛到总体形式。此外，利用凸势能的二阶上导数，证明了对于流形支撑的目标，OT-CFM在时间重标度下表现出终端正常双曲性：法向方向指数收缩，切向方向保持中性。


<details>
  <summary>Details</summary>
Motivation: 为了更深入理解OT-CFM的动力学特性，特别是在无密度假设和流形支持目标下的行为，提出一种新的理论框架来揭示其近端结构与几何性质。

Method: 通过引入扩展的Brenier势能，将OT-CFM重新表述为精确的近端问题；利用第二上导数分析流形上目标的动力学稳定性；结合小批量与总体形式的收敛性分析。

Result: OT-CFM在无密度假设下仍可表示为精确近端形式；小批量版本随批量增大收敛至总体解；对于流形支撑目标，系统在时间重标度后呈现法向指数收缩、切向中性，即终端正常双曲性。

Conclusion: 本研究建立了OT-CFM的近端理论基础，揭示了其在复杂数据结构下的稳定性和几何动力学行为，为生成模型设计提供了新视角。

Abstract: We reformulate Optimal Transport Conditional Flow Matching (OT-CFM), a class of dynamical generative models, showing that it admits an exact proximal formulation via an extended Brenier potential, without assuming that the target distribution has a density. In particular, the mapping to recover the target point is exactly given by a proximal operator, which yields an explicit proximal expression of the vector field. We also discuss the convergence of minibatch OT-CFM to the population formulation as the batch size increases. Finally, using second epi-derivatives of convex potentials, we prove that, for manifold-supported targets, OT-CFM is terminally normally hyperbolic: after time rescaling, the dynamics contracts exponentially in directions normal to the data manifold while remaining neutral along tangential directions.

</details>


### [124] [LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning](https://arxiv.org/abs/2602.13073)
*Juneyoung Park,Eunbeen Yoon,Seongwan Kim. Jaeho Lee*

Main category: cs.LG

TL;DR: 提出LCSB方法，通过每步仅计算部分层的梯度，实现高效低内存的LLM微调。利用残差连接保证梯度流动，结合AdamW动量对未选层进行隐式更新，理论解释为LoRA参数空间上的块坐标下降。在多个模型和任务上实现1.40倍加速，质量损失小于2%，且在4位量化下表现出更强稳定性，显示选择性梯度计算具有隐式正则化效果。


<details>
  <summary>Details</summary>
Motivation: MeBP虽使大语言模型在移动端低内存环境下可进行一阶微调，但其需每步回传所有Transformer层，其中权重解压缩占后向计算时间32-42%，效率受限。为提升效率并保持性能，亟需减少梯度计算量。

Method: 提出层循环选择性反向传播（LCSB），每步仅计算部分层的梯度。基于残差连接保障梯度通过恒等路径，利用AdamW动量对未选层提供隐式更新。将LCSB形式化为LoRA参数空间上的块坐标下降，给出收敛性理论支持。

Result: LCSB在五个模型、三个任务上实现最高1.40倍加速，性能下降小于2%；在4比特量化设置下，原本完全发散的3B模型在LCSB下稳定收敛，表明选择性梯度计算具有隐式正则化作用。

Conclusion: LCSB通过选择性梯度计算显著提升训练效率，同时保持模型性能，在低资源和量化场景下表现更优，具备理论基础与实际优势，是高效移动端大模型微调的重要进展。

Abstract: Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where weight decompression alone accounts for 32--42% of backward time. We propose Layer-Cyclic Selective Backpropagation (LCSB), which computes gradients for only a subset of layers per step. Our key insight is that residual connections guarantee gradient flow through identity paths, while AdamW momentum provides implicit updates for non-selected layers. We interpret LCSB as Block Coordinate Descent on the LoRA parameter space, providing theoretical justification for convergence. LCSB achieves up to 1.40$\times$ speedup with less than 2\% quality degradation across five models and three tasks. Surprisingly, in 4-bit quantized settings, LCSB exhibits superior stability: a 3B model that completely diverges under full backpropagation converges smoothly with LCSB, suggesting an implicit regularization effect from selective gradient computation.

</details>


### [125] [Trust the uncertain teacher: distilling dark knowledge via calibrated uncertainty](https://arxiv.org/abs/2602.12687)
*Jeonghyun Kim,SooKyung Kim,Richeng Xuan,Hyunsoo Cho*

Main category: cs.LG

TL;DR: 本文提出了一种名为校准不确定性蒸馏（CUD）的新框架，旨在解决传统知识蒸馏中教师模型因过自信而导致的‘暗知识’信号丢失问题。通过在知识转移前直接调整教师的预测分布，使教师在不确定时表现出合理的不确定性，从而提升学生模型在高基数任务下的准确性和鲁棒性。实验表明，该方法能显著提高学生模型在分布外数据和长尾输入上的校准度与可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏依赖于教师模型的过自信输出，导致其预测分布过于尖锐，丧失了类别间细微关系和不确定性信息，尤其在高基数任务中影响学生模型的学习效果。这种过自信还会降低模型在实际场景中的鲁棒性。因此需要一种能够保留并传递真实不确定性信息的蒸馏方法。

Method: 提出校准不确定性蒸馏（CUD），通过在训练教师模型时引入对预测分布的校准机制，使其在面对不确定样本时表现出合理且可解释的不确定性，而非盲目自信。该方法不直接使用原始教师输出，而是先对教师分布进行优化，使其更适合作为学生模型的知识来源。

Result: 在多个基准测试中，采用CUD训练的学生模型不仅精度更高，而且在分布外数据、长尾样本以及模糊输入上表现出更强的校准能力与可靠性，证明了其在复杂现实场景中的优越性。

Conclusion: CUD通过从分布角度重新审视知识蒸馏，有效缓解了教师过自信带来的问题，使得‘暗知识’得以更真实地传递，显著提升了学生模型的性能与鲁棒性，为未来高效、可靠的模型压缩提供了新思路。

Abstract: The core of knowledge distillation lies in transferring the teacher's rich 'dark knowledge'-subtle probabilistic patterns that reveal how classes are related and the distribution of uncertainties. While this idea is well established, teachers trained with conventional cross-entropy often fail to preserve such signals. Their distributions collapse into sharp, overconfident peaks that appear decisive but are in fact brittle, offering little beyond the hard label or subtly hindering representation-level transfer. This overconfidence is especially problematic in high-cardinality tasks, where the nuances among many plausible classes matter most for guiding a compact student. Moreover, such brittle targets reduce robustness under distribution shift, leaving students vulnerable to miscalibration in real-world conditions. To address this limitation, we revisit distillation from a distributional perspective and propose Calibrated Uncertainty Distillation (CUD), a framework designed to make dark knowledge more faithfully accessible. Instead of uncritically adopting the teacher's overconfidence, CUD encourages teachers to reveal uncertainty where it is informative and guides students to learn from targets that are calibrated rather than sharpened certainty. By directly shaping the teacher's predictive distribution before transfer, our approach balances accuracy and calibration, allowing students to benefit from both confident signals on easy cases and structured uncertainty on hard ones. Across diverse benchmarks, CUD yields students that are not only more accurate, but also more calibrated under shift and more reliable on ambiguous, long-tail inputs.

</details>


### [126] [Leverage-Weighted Conformal Prediction](https://arxiv.org/abs/2602.12693)
*Shreyas Fadnavis*

Main category: cs.LG

TL;DR: 提出Leverage-Weighted Conformal Prediction (LWCP)，通过利用设计矩阵的杠杆值（hat matrix对角线）加权非符合性分数，实现无需训练辅助模型的自适应预测区间。该方法在保持有限样本边际有效性的同时，显著改善了异方差情况下的条件覆盖性能，且计算开销极小。实验验证其在合成与真实数据上均能大幅降低条件覆盖差异。


<details>
  <summary>Details</summary>
Motivation: 传统分段共形预测（Split conformal prediction）生成恒定宽度的预测区间，在低方差区域过度覆盖，在高方差区域覆盖不足；现有自适应方法依赖于训练额外的辅助模型，增加了复杂性和计算成本。因此需要一种无需额外模型、基于数据设计几何结构的自适应方法。

Method: LWCP通过将非符合性分数按统计杠杆值进行加权，利用设计矩阵的几何特性实现自适应，不依赖辅助模型训练。证明了其在任意权重函数下保持有限样本边际有效性，并在异方差由杠杆决定时达到渐近最优条件覆盖，同时保持经典预测区间的宽度形式。还引入随机杠杆近似以精确保持覆盖性并控制宽度扰动。

Result: LWCP在多种设置下显著减少条件覆盖差异；在异方差场景中优于传统共形预测；在高斯假设下恢复经典预测区间结构；计算开销几乎可忽略；随机杠杆近似能精确保持覆盖性。

Conclusion: LWCP是一种高效、无需超参数调优、无需辅助模型的自适应共形预测方法，兼具理论保障与实证优势，有效解决了传统方法在条件覆盖上的缺陷。

Abstract: Split conformal prediction provides distribution-free prediction intervals with finite-sample marginal coverage, but produces constant-width intervals that overcover in low-variance regions and undercover in high-variance regions. Existing adaptive methods require training auxiliary models. We propose Leverage-Weighted Conformal Prediction (LWCP), which weights nonconformity scores by a function of the statistical leverage -- the diagonal of the hat matrix -- deriving adaptivity from the geometry of the design matrix rather than from auxiliary model fitting. We prove that LWCP preserves finite-sample marginal validity for any weight function; achieves asymptotically optimal conditional coverage at essentially no width cost when heteroscedasticity factors through leverage; and recovers the form and width of classical prediction intervals under Gaussian assumptions while retaining distribution-free guarantees. We further establish that randomized leverage approximations preserve coverage exactly with controlled width perturbation, and that vanilla CP suffers a persistent, sample-size-independent conditional coverage gap that LWCP eliminates. The method requires no hyperparameters beyond the choice of weight function and adds negligible computational overhead to vanilla CP. Experiments on synthetic and real data confirm the theoretical predictions, demonstrating substantial reductions in conditional coverage disparity across settings.

</details>


### [127] [Quantization-Robust LLM Unlearning via Low-Rank Adaptation](https://arxiv.org/abs/2602.13151)
*João Vitor Boer Abitante,Joana Meneguzzo Pasquali,Luan Fonseca Garcia,Ewerton de Oliveira,Thomas da Silva Paula,Rodrigo C. Barros,Lucas S. Kupssinskü*

Main category: cs.LG

TL;DR: 本文提出一种针对量化鲁棒性的机器遗忘方法，利用低秩适配（LoRA）将遗忘更新集中于可训练适配器中，以确保在4比特量化后仍能保留有效更新。实验表明，该方法显著提升了4比特量化模型的实用性，并减少了隐私泄露，同时保持了良好的遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 标准全参数微调的更新量过小，难以在4比特量化下存活，导致量化模型恢复到未遗忘状态，因此需要一种能在量化后仍保持遗忘效果的方法。

Method: 采用低秩适配（LoRA）技术，冻结基础模型，仅训练适配器部分，使遗忘信息集中在可训练适配器中，从而增强对量化过程的鲁棒性。

Result: 在Llama-2-7B模型上，使用LoRA进行遗忘处理后，4比特量化下的性能提升最高达7.93点；隐私泄露指标显著降低，如在BOOKS数据集上从-25.68降至-5.86，同时遗忘能力保持良好。

Conclusion: LoRA是一种有效的机器遗忘策略，特别适用于需要进行4比特量化部署的场景，能够在保证遗忘效果的同时提升量化模型的实用性和隐私安全性。

Abstract: Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase unlearning updates, causing quantized models to revert to pre-unlearning behavior. We show that standard full-parameter fine-tuning often induce parameter changes that are too small to survive 4-bit quantization. We propose quantization-robust unlearning via low-rank adaptation (LoRA): we freeze the base model and concentrate unlearning into trainable adapters so that the effective update is preserved after quantization. On Llama-2-7B evaluated with MUSE dataset (BOOKS and NEWS), LoRA improves 4-bit utility by up to 7.93 points (NPO+GDR on BOOKS: 50.17 to 58.10) and yields higher 4-bit utility on NEWS for GA+GDR (40.06 to 44.82, increase of 4.76). LoRA also substantially reduces privacy leakage under 4-bit PTQ, e.g., for GA+KLR on BOOKS, PrivLeak moves from -25.68 to -5.86 (closer to ideal 0), while maintaining strong forgetting (VerMem and KnowMem near 0). Thus, using LoRA for Machine Unlearning is beneficial for scenarios where quantization is necessary for model deployment.

</details>


### [128] [SWING: Unlocking Implicit Graph Representations for Graph Random Features](https://arxiv.org/abs/2602.12703)
*Alessandro Manenti,Avinava Dubey,Arijit Sehanobish,Cesare Alippi,Krzysztof Choromanski*

Main category: cs.LG

TL;DR: SWING 是一种针对隐式图（i-graphs）的新型算法，通过在连续空间中进行随机游走来计算图随机特征，避免了传统节点遍历。它结合了 Gumbel-softmax 采样、线性化核函数与重要性采样，利用隐式图与傅里叶分析之间的深层联系，实现高效且精确的组合计算近似。该方法无需显式构建图结构，具备加速器友好性，已在多种隐式图上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统图计算依赖于显式图结构和节点遍历，但在隐式图（如ε-邻域图）中，边权重由节点特征向量的函数定义，显式构建图成本高且不切实际。因此需要一种无需图物质化的高效计算框架。

Method: 提出 SWING 算法，基于连续空间中的随机游走，结合 Gumbel-softmax 采样、随机特征生成的线性化核函数以及重要性采样技术，将隐式图的组合计算转化为可高效近似的连续空间操作。

Result: SWING 在多种隐式图上实现了高精度的图随机特征近似，显著降低计算开销，无需图物质化，具有良好的加速器兼容性，并在实验中展现出优越性能。

Conclusion: SWING 为隐式图上的图随机特征计算提供了新范式，揭示了隐式图与傅里叶分析之间的深刻联系，是兼具理论深度与实用价值的算法创新。

Abstract: We propose SWING: Space Walks for Implicit Network Graphs, a new class of algorithms for computations involving Graph Random Features on graphs given by implicit representations (i-graphs), where edge-weights are defined as bi-variate functions of feature vectors in the corresponding nodes. Those classes of graphs include several prominent examples, such as: $ε$-neighborhood graphs, used on regular basis in machine learning. Rather than conducting walks on graphs' nodes, those methods rely on walks in continuous spaces, in which those graphs are embedded. To accurately and efficiently approximate original combinatorial calculations, SWING applies customized Gumbel-softmax sampling mechanism with linearized kernels, obtained via random features coupled with importance sampling techniques. This algorithm is of its own interest. SWING relies on the deep connection between implicitly defined graphs and Fourier analysis, presented in this paper. SWING is accelerator-friendly and does not require input graph materialization. We provide detailed analysis of SWING and complement it with thorough experiments on different classes of i-graphs.

</details>


### [129] [QTabGAN: A Hybrid Quantum-Classical GAN for Tabular Data Synthesis](https://arxiv.org/abs/2602.12704)
*Subhangi Kumari,Rakesh Achutha,Vignesh Sivaraman*

Main category: cs.LG

TL;DR: QTabGAN is a hybrid quantum-classical generative adversarial network designed for synthesizing realistic tabular data, especially useful when real data are scarce or privacy-restricted. It leverages quantum circuits to model complex data distributions and maps them to tabular features via classical neural networks. Experiments show up to 54.07% improvement over state-of-the-art models on classification tasks, demonstrating its scalability and potential in quantum-assisted generative modeling.


<details>
  <summary>Details</summary>
Motivation: Synthesizing realistic tabular data is difficult due to diverse feature types and high dimensionality. Existing methods struggle with data scarcity and privacy constraints, motivating the need for a novel approach that can generate high-quality synthetic data under such limitations.

Method: QTabGAN combines quantum circuits for learning complex data distributions and classical neural networks for mapping these distributions to tabular features. This hybrid architecture enables effective generation of realistic tabular data while preserving privacy and overcoming data scarcity.

Result: QTabGAN achieves up to 54.07% improvement in performance across various classification datasets and evaluation metrics compared to leading state-of-the-art generative models, showing superior capability in generating realistic tabular data.

Conclusion: QTabGAN establishes a scalable quantum approach for tabular data synthesis, demonstrating strong potential for use in privacy-sensitive and low-data scenarios, and paving the way for future quantum-assisted generative modeling.

Abstract: Synthesizing realistic tabular data is challenging due to heterogeneous feature types and high dimensionality. We introduce QTabGAN, a hybrid quantum-classical generative adversarial framework for tabular data synthesis. QTabGAN is especially designed for settings where real data are scarce or restricted by privacy constraints. The model exploits the expressive power of quantum circuits to learn complex data distributions, which are then mapped to tabular features using classical neural networks. We evaluate QTabGAN on multiple classification and regression datasets and benchmark it against leading state-of-the-art generative models. Experiments show that QTabGAN achieves up to 54.07% improvement across various classification datasets and evaluation metrics, thus establishing a scalable quantum approach to tabular data synthesis and highlighting its potential for quantum-assisted generative modelling.

</details>


### [130] [GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories](https://arxiv.org/abs/2602.12828)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: GRAIL 是一种用于预测患者下次就诊事件的框架，通过结构化几何表示和结构感知检索，结合确定性编码系统层次与数据驱动的时间关联，将临床图嵌入双曲空间，并用概率中心事件总结每次就诊以去噪稀疏观察。在推理时，GRAIL 检索与层级和时间进展一致的临床合理未来事件，并可选地使用 LLM 作为受限推理重排序器优化排名。在 MIMIC-IV 上的实验表明，GRAIL 在多类型下次就诊预测中表现更优，且预测结果更具层级一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理纵向电子健康记录（EHR）时面临多重挑战：临床事件稀疏、医疗术语具有层级结构，以及大语言模型（LLM）在推理长历史时容易产生幻觉。因此，需要一种能够有效建模复杂医疗历史并生成可信预测的新方法。

Method: GRAIL 构建统一临床图，融合编码系统层次与数据驱动的时间关联；将图嵌入双曲空间；每就诊记录被表示为概率中心事件以去噪；推理阶段采用结构感知检索获取符合层级与时间演进的未来事件，并可选使用 LLM 作为约束性重排序器提升准确性。

Result: 在 MIMIC-IV 数据集上，GRAIL 显著提升了多类型下次就诊事件预测性能，同时生成的预测结果在层级一致性方面优于基线方法。

Conclusion: GRAIL 通过结合几何结构建模与结构感知检索，有效应对了纵向 EHR 中的稀疏性、层级性和幻觉问题，在临床事件预测任务中展现出优越性能与可解释性。

Abstract: Predicting future clinical events from longitudinal electronic health records (EHRs) is challenging due to sparse multi-type clinical events, hierarchical medical vocabularies, and the tendency of large language models (LLMs) to hallucinate when reasoning over long structured histories. We study next-visit event prediction, which aims to forecast a patient's upcoming clinical events based on prior visits. We propose GRAIL, a framework that models longitudinal EHRs using structured geometric representations and structure-aware retrieval. GRAIL constructs a unified clinical graph by combining deterministic coding-system hierarchies with data-driven temporal associations across event types, embeds this graph in hyperbolic space, and summarizes each visit as a probabilistic Central Event that denoises sparse observations. At inference time, GRAIL retrieves a structured set of clinically plausible future events aligned with hierarchical and temporal progression, and optionally refines their ranking using an LLM as a constrained inference-time reranker. Experiments on MIMIC-IV show that GRAIL consistently improves multi-type next-visit prediction and yields more hierarchy-consistent forecasts.

</details>


### [131] [Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning](https://arxiv.org/abs/2602.12708)
*Jon Irureta,Gorka Azkune,Jon Imaz,Aizea Lojo,Javier Fernandez-Marques*

Main category: cs.LG

TL;DR: Split-MoPE integrates Split Learning with a Mixture of Predefined Experts (MoPE) to address sample misalignment in Vertical Federated Learning (VFL), enabling high performance with single-round communication, robustness against malicious participants, and per-sample interpretability. It outperforms existing methods like LASER and Vertical SplitNN on CIFAR-10/100 and Breast Cancer Wisconsin datasets, especially under high data missingness.


<details>
  <summary>Details</summary>
Motivation: Existing VFL frameworks assume full sample alignment, which is unrealistic in real-world scenarios. This work aims to overcome sample misalignment issues while maintaining privacy, efficiency, and model interpretability.

Method: Split-MoPE combines Split Learning with a Mixture of Predefined Experts (MoPE), where experts are pre-defined to handle specific data alignments. It uses pretrained encoders for target domains and enables single-round training with minimal communication. Routing is fixed based on predefined expertise, allowing efficient and interpretable predictions.

Result: Split-MoPE achieves state-of-the-art performance with only one communication round, reduces communication cost significantly, shows robustness against malicious or noisy participants, and provides per-sample contribution interpretation. It consistently outperforms LASER and Vertical SplitNN across vision and tabular datasets, especially when data missingness is high.

Conclusion: Split-MoPE effectively addresses the challenges of sample misalignment in VFL by leveraging predefined expert routing and pretrained encoders, achieving high performance, low communication overhead, and enhanced robustness and interpretability—making it suitable for real-world privacy-sensitive applications.

Abstract: Vertical Federated Learning (VFL) has emerged as a critical paradigm for collaborative model training in privacy-sensitive domains such as finance and healthcare. However, most existing VFL frameworks rely on the idealized assumption of full sample alignment across participants, a premise that rarely holds in real-world scenarios. To bridge this gap, this work introduces Split-MoPE, a novel framework that integrates Split Learning with a specialized Mixture of Predefined Experts (MoPE) architecture. Unlike standard Mixture of Experts (MoE), where routing is learned dynamically, MoPE uses predefined experts to process specific data alignments, effectively maximizing data usage during both training and inference without requiring full sample overlap. By leveraging pretrained encoders for target data domains, Split-MoPE achieves state-of-the-art performance in a single communication round, significantly reducing the communication footprint compared to multi-round end-to-end training. Furthermore, unlike existing proposals that address sample misalignment, this novel architecture provides inherent robustness against malicious or noisy participants and offers per-sample interpretability by quantifying each collaborator's contribution to each prediction. Extensive evaluations on vision (CIFAR-10/100) and tabular (Breast Cancer Wisconsin) datasets demonstrate that Split-MoPE consistently outperforms state-of-the-art systems such as LASER and Vertical SplitNN, particularly in challenging scenarios with high data missingness.

</details>


### [132] [Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models](https://arxiv.org/abs/2602.12846)
*Zesheng Hong,Jiadong Yu,Hui Pan*

Main category: cs.LG

TL;DR: RLVR在强化学习中通过奖励验证提升大语言模型的推理能力，但存在抑制罕见正确推理路径的问题。本文提出ARTS方法，通过解耦生成与验证，利用流匹配目标实现对概率流的保守估计，从而在稀疏高熵空间中有效导航。实验显示，ARTS在MATH-500上达到74.6%（BoN@16），接近全微调模型性能，并在长尾任务中显著恢复表现，证明了分离生成与验证的优越性。


<details>
  <summary>Details</summary>
Motivation: RLVR虽然能增强主流行为，但会系统性压制低概率但正确的推理路径，导致罕见有效路径因采样有限而被消除，亟需一种保留基础模型多样性同时避免路径消失的方法。

Method: 提出Amortized Reasoning Tree Search (ARTS)，通过解耦生成与验证过程，引入流匹配目标，使验证器估计概率流守恒，以应对传统判别式目标在稀疏高熵空间中的失效问题。

Result: 在MATH-500基准测试中，ARTS达到74.6%（BoN@16）性能，接近全微调模型（74.7%），且在长尾子集上显著优于传统方法，在耦合强化学习优化崩溃至0%时仍保持有效性能。

Conclusion: 解耦生成与验证的策略，特别是通过流匹配实现概率流保守估计，为复杂推理任务提供更稳健的解决方案，有助于克服现有强化学习对罕见正确路径的抑制问题。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has established itself as the dominant paradigm for instilling rigorous reasoning capabilities in Large Language Models. While effective at amplifying dominant behaviors, we identify a critical pathology in this alignment process: the systematic suppression of valid but rare (low-likelihood under the base model distribution) reasoning paths. We theoretically characterize this phenomenon as a "Normalization Squeeze," where the interplay between mode-seeking policy gradients and finite sampling acts as a high-pass likelihood filter, driving the probability of rare correct traces to statistical extinction. To counteract this collapse without discarding the base model's latent diversity, we propose Amortized Reasoning Tree Search (ARTS). Unlike standard approaches that force internalization via parameter updates, ARTS prioritizes deliberation by decoupling generation from verification. We introduce a Flow Matching objective that repurposes the verifier to estimate the conservation of probability flow, enabling robust navigation through sparse, high-entropy search spaces where traditional discriminative objectives fail. Extensive experiments on the MATH-500 benchmark demonstrate that ARTS achieves a performance of 74.6% (BoN@16), effectively matching fully fine-tuned policies (74.7%) without modifying the generative backbone. Crucially, on the long-tail subset where coupled RL optimization collapses to 0% pass@k, ARTS uniquely recovers significant performance, suggesting that disentangling verification from generation offers a more robust pathway for solving complex reasoning tasks.

</details>


### [133] [Hierarchical Successor Representation for Robust Transfer](https://arxiv.org/abs/2602.12753)
*Changmin Yu,Máté Lengyel*

Main category: cs.LG

TL;DR: 提出分层成功表示（HSR）以解决经典成功表示（SR）在政策依赖性和拓扑复杂环境中的谱扩散问题。通过引入时间抽象和非负矩阵分解（NMF），HSR生成稳定、稀疏且低秩的状态表示，实现高效的任务迁移与探索，在多隔间环境中表现优异，并揭示可解释的拓扑结构，提供与策略无关的分层地图。


<details>
  <summary>Details</summary>
Motivation: 经典成功表示（SR）受政策依赖性限制，且在复杂拓扑环境中存在谱扩散问题，导致特征密集重叠、扩展性差；需发展更稳定、可迁移的预测表示框架以支持快速任务转移和高效探索。

Method: 结合时间抽象构建分层成功表示（HSR），利用非负矩阵分解（NMF）对HSR进行降维，得到稀疏、低秩的状态表示，并分析其在任务迁移与探索中的应用。

Result: HSR-NMF在多隔间环境中实现了高度样本效率的任务迁移；揭示了可解释的拓扑结构，形成与策略无关的分层地图；其时序扩展的预测结构有效支持大规模程序生成环境中的高效探索。

Conclusion: HSR通过整合时间抽象与非负矩阵分解，克服了传统SR的局限性，为任务迁移、模型自由优化与模型驱动灵活性之间提供了桥梁，具备在复杂动态环境中高效学习与探索的潜力。

Abstract: The successor representation (SR) provides a powerful framework for decoupling predictive dynamics from rewards, enabling rapid generalisation across reward configurations. However, the classical SR is limited by its inherent policy dependence: policies change due to ongoing learning, environmental non-stationarities, and changes in task demands, making established predictive representations obsolete. Furthermore, in topologically complex environments, SRs suffer from spectral diffusion, leading to dense and overlapping features that scale poorly. Here we propose the Hierarchical Successor Representation (HSR) for overcoming these limitations. By incorporating temporal abstractions into the construction of predictive representations, HSR learns stable state features which are robust to task-induced policy changes. Applying non-negative matrix factorisation (NMF) to the HSR yields a sparse, low-rank state representation that facilitates highly sample-efficient transfer to novel tasks in multi-compartmental environments. Further analysis reveals that HSR-NMF discovers interpretable topological structures, providing a policy-agnostic hierarchical map that effectively bridges model-free optimality and model-based flexibility. Beyond providing a useful basis for task-transfer, we show that HSR's temporally extended predictive structure can also be leveraged to drive efficient exploration, effectively scaling to large, procedurally generated environments.

</details>


### [134] [X-VORTEX: Spatio-Temporal Contrastive Learning for Wake Vortex Trajectory Forecasting](https://arxiv.org/abs/2602.12869)
*Zhan Qu,Michael Färber*

Main category: cs.LG

TL;DR: X-VORTEX 是一种基于增强重叠理论的时空对比学习框架，用于从无标签的激光雷达点云序列中学习物理感知表征，以解决航迹涡流追踪中的传感器稀疏性和动态变化难题。通过结合弱扰动序列与强增强版本（含时间子采样和空间掩码），模型能对缺失帧和部分观测进行对齐，实现仅用1%标注数据即达到监督基线性能，且支持精确轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法将每帧扫描视为独立的全监督分割任务，忽视了时间结构，难以扩展到大规模未标记数据集；同时，由于传感器稀疏、涡流信号随大气湍流衰减以及逐点标注成本高昂，导致涡流追踪困难。

Method: 提出 X-VORTEX 框架，采用时空对比学习策略，利用增强重叠理论构建配对输入：一个弱扰动序列与一个经时间子采样和空间掩码生成的强增强序列，通过时间分布式几何编码器提取每帧特征，再由序列聚合器建模随时间演化的涡流状态。

Result: 在超过一百万次真实激光雷达扫描的数据集上评估，X-VORTEX 在仅使用 1% 标注数据的情况下，实现了优于监督基线的涡流中心定位效果，并且所学表征可有效支持轨迹预测。

Conclusion: X-VORTEX 成功实现了在极低标注成本下对复杂、动态涡流行为的精准追踪，为航空交通管理中的安全与效率提升提供了可行的无监督/自监督解决方案。

Abstract: Wake vortices are strong, coherent air turbulences created by aircraft, and they pose a major safety and capacity challenge for air traffic management. Tracking how vortices move, weaken, and dissipate over time from LiDAR measurements is still difficult because scans are sparse, vortex signatures fade as the flow breaks down under atmospheric turbulence and instabilities, and point-wise annotation is prohibitively expensive. Existing approaches largely treat each scan as an independent, fully supervised segmentation problem, which overlooks temporal structure and does not scale to the vast unlabeled archives collected in practice. We present X-VORTEX, a spatio-temporal contrastive learning framework grounded in Augmentation Overlap Theory that learns physics-aware representations from unlabeled LiDAR point cloud sequences. X-VORTEX addresses two core challenges: sensor sparsity and time-varying vortex dynamics. It constructs paired inputs from the same underlying flight event by combining a weakly perturbed sequence with a strongly augmented counterpart produced via temporal subsampling and spatial masking, encouraging the model to align representations across missing frames and partial observations. Architecturally, a time-distributed geometric encoder extracts per-scan features and a sequential aggregator models the evolving vortex state across variable-length sequences. We evaluate on a real-world dataset of over one million LiDAR scans. X-VORTEX achieves superior vortex center localization while using only 1% of the labeled data required by supervised baselines, and the learned representations support accurate trajectory forecasting.

</details>


### [135] [Closing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs](https://arxiv.org/abs/2602.12756)
*Xingyu Zhang,Hanyun Du,Zeen Song,Jianqi Zhang,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 本文提出F-LLM，一种基于控制理论的闭环反馈框架，用于改进大语言模型在时间序列预测中的自回归生成策略。传统方法存在误差累积问题，而F-LLM通过引入可学习的残差估计器（Observer）和反馈控制器，实现轨迹稳定，并提供误差有界性的理论保证。实验表明该方法显著减少误差传播，提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在时间序列预测中采用朴素的自回归生成方式，导致推理时因递归使用自身输出而产生误差累积（暴露偏差），尤其在长时序预测中引发轨迹漂移。

Method: 将自回归预测重构为控制理论中的闭环系统，设计包含可学习残差估计器（Observer）与反馈控制器的F-LLM框架，实现对预测轨迹的主动调控与误差抑制。

Result: F-LLM在多个时间序列基准数据集上显著降低误差传播，有效缓解长期预测中的轨迹漂移问题，且在理论上保证了误差的统一有界性（在基础模型满足局部Lipschitz条件的前提下）。

Conclusion: F-LLM通过引入闭环反馈机制，克服了传统自回归生成中的暴露偏差问题，为大语言模型在时间序列建模中提供了更稳定、可靠的预测框架。

Abstract: Large Language Models (LLMs) have recently shown exceptional potential in time series forecasting, leveraging their inherent sequential reasoning capabilities to model complex temporal dynamics. However, existing approaches typically employ a naive autoregressive generation strategy. We identify a critical theoretical flaw in this paradigm: during inference, the model operates in an open-loop manner, consuming its own generated outputs recursively. This leads to inevitable error accumulation (exposure bias), where minor early deviations cascade into significant trajectory drift over long horizons. In this paper, we reformulate autoregressive forecasting through the lens of control theory, proposing \textbf{F-LLM} (Feedback-driven LLM), a novel closed-loop framework. Unlike standard methods that passively propagate errors, F-LLM actively stabilizes the trajectory via a learnable residual estimator (Observer) and a feedback controller. Furthermore, we provide a theoretical guarantee that our closed-loop mechanism ensures uniformly bounded error, provided the base model satisfies a local Lipschitz constraint. Extensive experiments demonstrate that F-LLM significantly mitigates error propagation, achieving good performance on time series benchmarks.

</details>


### [136] [Transporting Task Vectors across Different Architectures without Training](https://arxiv.org/abs/2602.12952)
*Filippo Rinaldi,Aniello Panariello,Giacomo Salici,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: Theseus 是一种无需训练的跨异构模型传输任务特定更新的方法，通过功能匹配中间表示的效应而非直接匹配参数，利用正交普鲁克特分析对齐表示空间后获得稳定闭式解，可有效保持更新几何结构，在视觉和语言模型上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅能在相同架构的模型间迁移任务特定更新，而跨不同宽度模型的迁移仍缺乏探索；如何在不重新训练的情况下实现高效、稳定的跨架构更新迁移成为关键挑战。

Method: 通过分析任务更新对中间表示的功能影响，将任务向量传输建模为基于观测激活的功能匹配问题；采用正交普鲁克特分析对齐不同模型间的表示空间，并推导出保持更新几何结构的稳定闭式解。

Result: 在多种宽度不同的视觉与语言模型上验证了 Theseus 的有效性，显著优于现有基线方法，且无需额外训练或反向传播，实现了高质量的任务更新跨架构迁移。

Conclusion: 当以功能而非参数方式定义任务时，任务更新可在不同架构之间有意义地迁移，表明功能一致性是跨模型迁移的关键。

Abstract: Adapting large pre-trained models to downstream tasks often produces task-specific parameter updates that are expensive to relearn for every model variant. While recent work has shown that such updates can be transferred between models with identical architectures, transferring them across models of different widths remains largely unexplored. In this work, we introduce Theseus, a training-free method for transporting task-specific updates across heterogeneous models. Rather than matching parameters directly, we characterize a task update by the functional effect it induces on intermediate representations. We formalize task-vector transport as a functional matching problem on observed activations and show that, after aligning representation spaces via orthogonal Procrustes analysis, it admits a stable closed-form solution that preserves the geometry of the update. We evaluate Theseus on vision and language models across different widths, showing consistent improvements over strong baselines without additional training or backpropagation. Our results show that task updates can be meaningfully transferred across architectures when task identity is defined functionally rather than parametrically.

</details>


### [137] [Extending confidence calibration to generalised measures of variation](https://arxiv.org/abs/2602.12975)
*Andrew Thompson,Vivek Desai*

Main category: cs.LG

TL;DR: 提出了一种新的校准评估指标——变异性校准误差（VCE），该指标是预期校准误差（ECE）的扩展，能够评估任意变异性度量的校准性。通过合成数据实验表明，当样本量增加时，VCE趋近于零，而现有的基于熵的校准指标（如UCE）不具备这一理想性质。


<details>
  <summary>Details</summary>
Motivation: 现有校准评估方法如ECE仅关注最大概率或置信度的校准性，但未能充分考虑概率分布的整体变异性。为更全面地评估模型校准性能，需要一种能基于完整概率分布的校准度量。

Method: 将ECE框架推广至任意变异性度量，定义了基于分布变异性（如熵）的校准误差，提出VCE作为统一评估指标，并通过理论分析与数值实验验证其有效性。

Result: 在设计为完美校准的合成数据上，VCE随样本量增加趋于零，表现出理想的收敛性；而对比的基于熵的校准指标（UCE）未展现出相同特性，说明VCE更具优势。

Conclusion: VCE是一种更全面、更可靠的校准评估指标，适用于评估基于概率分布变异性（如熵）的校准性能，且具有良好的统计收敛性，优于现有方法。

Abstract: We propose the Variation Calibration Error (VCE) metric for assessing the calibration of machine learning classifiers. The metric can be viewed as an extension of the well-known Expected Calibration Error (ECE) which assesses the calibration of the maximum probability or confidence. Other ways of measuring the variation of a probability distribution exist which have the advantage of taking into account the full probability distribution, for example the Shannon entropy. We show how the ECE approach can be extended from assessing confidence calibration to assessing the calibration of any metric of variation. We present numerical examples upon synthetic predictions which are perfectly calibrated by design, demonstrating that, in this scenario, the VCE has the desired property of approaching zero as the number of data samples increases, in contrast to another entropy-based calibration metric (the UCE) which has been proposed in the literature.

</details>


### [138] [Drift-Aware Variational Autoencoder-based Anomaly Detection with Two-level Ensembling](https://arxiv.org/abs/2602.12976)
*Jin Li,Kleanthis Malialis,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.LG

TL;DR: 提出了一种名为VAE++ESDD的新方法，结合增量学习与两级集成（包括变分自编码器集合用于异常检测，以及基于统计的漂移检测器集合），以应对非平稳环境中标签缺失和概念漂移带来的挑战。在真实世界和合成数据集上的实验表明，该方法在极低异常率和多种漂移场景下显著优于现有基线和先进方法。


<details>
  <summary>Details</summary>
Motivation: 在数字时代，海量流数据普遍存在但多数未标注，尤其在非平稳环境下，由于概念漂移导致模型性能下降，使得事件识别（尤其是异常检测）变得极为困难。因此需要一种能适应动态变化、有效处理未标注数据并抵御概念漂移的方法。

Method: VAE++ESDD采用增量学习策略，构建两层集成架构：第一层是多个变分自编码器（VAEs）组成的集成，用于异常预测；第二层是多个基于统计方法的概念漂移检测器组成的集成，用以实时监测数据分布的变化。通过联合优化异常检测与漂移感知能力，提升系统在长期运行中的鲁棒性与准确性。

Result: 在真实和合成数据集上的实验结果表明，VAE++ESDD在极低异常率和多种概念漂移模式下均表现出优越性能，显著超越了强基线方法及当前最先进的技术，在检测精度、响应速度和稳定性方面均有明显提升。

Conclusion: VAE++ESDD是一种高效且鲁棒的异常检测框架，能够有效应对非平稳环境下的无监督流数据挑战，具备良好的可扩展性和实际应用潜力。

Abstract: In today's digital world, the generation of vast amounts of streaming data in various domains has become ubiquitous. However, many of these data are unlabeled, making it challenging to identify events, particularly anomalies. This task becomes even more formidable in nonstationary environments where model performance can deteriorate over time due to concept drift. To address these challenges, this paper presents a novel method, VAE++ESDD, which employs incremental learning and two-level ensembling: an ensemble of Variational AutoEncoder(VAEs) for anomaly prediction, along with an ensemble of concept drift detectors. Each drift detector utilizes a statistical-based concept drift mechanism. To evaluate the effectiveness of VAE++ESDD, we conduct a comprehensive experimental study using real-world and synthetic datasets characterized by severely or extremely low anomalous rates and various drift characteristics. Our study reveals that the proposed method significantly outperforms both strong baselines and state-of-the-art methods.

</details>


### [139] [Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery](https://arxiv.org/abs/2602.13021)
*Jing Xiao,Xinhai Chen,Jiaming Peng,Qinglin Wang,Menghan Jia,Zhiquan Lai,Guangping Yu,Dongsheng Li,Tiejun Li,Jie Liu*

Main category: cs.LG

TL;DR: PG-SR 是一种基于先验引导的符号回归框架，通过三阶段流程（预热、进化、精炼）和先验约束检查器，结合渐进式约束评估机制（PACE），有效避免伪方程陷阱，提升科学一致性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有符号回归方法依赖经验风险最小化，易产生看似拟合良好但违背科学原理的伪方程，缺乏对科学一致性的显式约束。

Method: 提出PG-SR框架，包含三阶段流程：预热、进化与精炼；引入可执行的先验约束程序作为约束检查器，并在进化阶段使用优先级退火约束评估（PACE）机制，逐步引导搜索至科学一致区域。

Result: 理论证明PG-SR降低了假设空间的Rademacher复杂度，获得更紧的泛化界，提供对伪方程的保障；实验表明其在多种领域优于现有基线，对先验质量、噪声数据和数据稀缺具有鲁棒性。

Conclusion: PG-SR通过显式集成领域先验与渐进约束机制，显著提升了符号回归的科学可信度与泛化性能，为发现真实物理规律提供了可靠工具。

Abstract: Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but remain inconsistent with fundamental scientific principles. A key reason is that these approaches are dominated by empirical risk minimization, lacking explicit constraints to ensure scientific consistency. To bridge this gap, we propose PG-SR, a prior-guided SR framework built upon a three-stage pipeline consisting of warm-up, evolution, and refinement. Throughout the pipeline, PG-SR introduces a prior constraint checker that explicitly encodes domain priors as executable constraint programs, and employs a Prior Annealing Constrained Evaluation (PACE) mechanism during the evolution stage to progressively steer discovery toward scientifically consistent regions. Theoretically, we prove that PG-SR reduces the Rademacher complexity of the hypothesis space, yielding tighter generalization bounds and establishing a guarantee against pseudo-equations. Experimentally, PG-SR outperforms state-of-the-art baselines across diverse domains, maintaining robustness to varying prior quality, noisy data, and data scarcity.

</details>


### [140] [Geometric Manifold Rectification for Imbalanced Learning](https://arxiv.org/abs/2602.13045)
*Xubin Wang,Qing Li,Weijia Jia*

Main category: cs.LG

TL;DR: GMR提出一种基于几何流形修正的新框架，用于处理不平衡的结构化数据。通过引入几何置信度估计和非对称清洗策略，有效捕捉局部流形结构并保护少数类样本，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统欠采样方法如ENN采用对称清洗规则和统一投票，难以捕捉局部流形结构，常误删有信息的少数类样本，导致决策边界模糊。

Method: 提出几何置信度估计（基于反距离加权kNN投票与自适应距离度量）和非对称清洗（严格处理多数类，对少数类设置保护上限）。

Result: 在多个基准数据集上的实验表明，GMR性能优于或媲美现有强基线方法，能更准确地识别少数类边界。

Conclusion: GMR通过利用局部几何先验，有效缓解了多数类对少数类流形的拓扑侵扰问题，为不平衡分类提供了更具鲁棒性的解决方案。

Abstract: Imbalanced classification presents a formidable challenge in machine learning, particularly when tabular datasets are plagued by noise and overlapping class boundaries. From a geometric perspective, the core difficulty lies in the topological intrusion of the majority class into the minority manifold, which obscures the true decision boundary. Traditional undersampling techniques, such as Edited Nearest Neighbours (ENN), typically employ symmetric cleaning rules and uniform voting, failing to capture the local manifold structure and often inadvertently removing informative minority samples. In this paper, we propose GMR (Geometric Manifold Rectification), a novel framework designed to robustly handle imbalanced structured data by exploiting local geometric priors. GMR makes two contributions: (1) Geometric confidence estimation that uses inverse-distance weighted kNN voting with an adaptive distance metric to capture local reliability; and (2) asymmetric cleaning that is strict on majority samples while conservatively protecting minority samples via a safe-guarding cap on minority removal. Extensive experiments on multiple benchmark datasets show that GMR is competitive with strong sampling baselines.

</details>


### [141] [Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences](https://arxiv.org/abs/2602.13004)
*Ayush Mohanty,Nazal Mohamed,Nagi Gebraeel*

Main category: cs.LG

TL;DR: 本文提出了首个在联邦格兰杰因果（Federated GC）框架中严格量化不确定性及其传播的方法。通过系统分类不确定性来源，区分数据噪声（aleatoric）与模型变异性（epistemic），推导出客户端-服务器交互中不确定性的闭式递推关系，并识别出四种新型跨协方差分量，耦合了数据与模型参数的不确定性。研究还给出了不确定性递推的收敛条件及服务器和客户端模型参数的稳态方差表达式，证明其仅依赖于客户端数据统计特性，与初始先验无关，增强了鲁棒性。实验在合成与真实工业数据上验证了显式建模不确定性可显著提升联邦因果推断的可靠性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦格兰杰因果算法仅提供确定性点估计，忽略不确定性，导致结果缺乏可信度与可解释性。尤其在数据主权约束下，如何在分布式架构中准确量化并传播不确定性成为关键挑战。

Method: 提出基于不确定性分类的分析框架，区分aleatoric与epistemic不确定性；推导客户端与服务器间不确定性传播的闭式递推公式；引入四类跨协方差项以建模数据与模型不确定性耦合；建立收敛性理论并求解稳态方差。

Result: 理论证明了稳态方差仅依赖于客户端数据统计，不依赖初始先验，提升了模型鲁棒性；实验证明显式建模不确定性显著提高了因果推断的可靠性与可解释性。

Conclusion: 本工作首次建立了联邦格兰杰因果中的不确定性量化框架，为高维、分布式的因果学习提供了更可靠、可解释的理论基础，具有重要的实际应用价值。

Abstract: Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursions that model the evolution of uncertainty through client-server interactions and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. We also define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. Our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference.

</details>


### [142] [Machine Learning-Based Classification of Jhana Advanced Concentrative Absorption Meditation (ACAM-J) using 7T fMRI](https://arxiv.org/abs/2602.13008)
*Puneet Kumar,Winson F. Z. Yang,Alakhsimar Singh,Xiaobai Li,Matthew D. Sacchet*

Main category: cs.LG

TL;DR: 本研究探讨了使用功能磁共振成像（fMRI）衍生的区域同质性（ReHo）结合机器学习方法，能否有效区分高级专注吸收冥想（ACAM-J）与非冥想状态。基于20名资深冥想者的群体数据训练分类器，并利用一位资深实践者在冥想与对照任务中的密集单例数据评估模型泛化能力。结果显示，集成模型在区分ACAM-J与对照状态时达到66.82%的准确率（p < 0.05），且前额叶和扣带回区域在特征重要性分析中贡献最大，提示这些脑区在注意力调节和元认知中的作用。Cohen's kappa显示中等一致性，支持机器学习用于识别高级冥想状态的可行性，为未来神经调控与冥想机制建模研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 探索高级冥想状态（如ACAM-J）对意识与认知加工的深刻影响，需揭示其神经基础。传统方法难以捕捉个体差异和动态变化，因此引入机器学习技术分析fMRI数据中的ReHo模式，以实现对冥想状态的客观分类，推动对意识机制的理解及心理健康应用。

Method: 收集20名资深冥想者的群体级fMRI数据用于训练；获取一名资深冥想者在执行ACAM-J与控制任务时的密集单例数据用于验证。计算全脑ReHo图谱，从预定义脑区提取特征；采用多种机器学习分类器，结合分层交叉验证进行训练与评估。通过特征重要性分析识别关键脑区。

Result: 集成模型在区分ACAM-J与非冥想状态时达到66.82%的准确率（p < 0.05），具有统计显著性。特征重要性分析表明，前额叶皮层和前扣带回区域是主要贡献脑区，与注意力和元认知功能一致。Cohen's kappa值显示中等水平的一致性，表明模型具备一定的泛化能力。

Conclusion: 机器学习方法能够有效利用fMRI-derived ReHo特征区分高级冥想状态（如ACAM-J）与非冥想状态，证实其在神经科学与意识研究中的可行性。该研究为未来探索冥想的神经机制、开发个性化神经调控策略提供了技术支持和理论依据。

Abstract: Jhana advanced concentration absorption meditation (ACAM-J) is related to profound changes in consciousness and cognitive processing, making the study of their neural correlates vital for insights into consciousness and well-being. This study evaluates whether functional MRI-derived regional homogeneity (ReHo) can be used to classify ACAM-J using machine-learning approaches. We collected group-level fMRI data from 20 advanced meditators to train the classifiers, and intensive single-case data from an advanced practitioner performing ACAM-J and control tasks to evaluate generalization. ReHo maps were computed, and features were extracted from predefined brain regions of interest. We trained multiple machine learning classifiers using stratified cross-validation to evaluate whether ReHo patterns distinguish ACAM-J from non-meditative states. Ensemble models achieved 66.82% (p < 0.05) accuracy in distinguishing ACAM-J from control conditions. Feature-importance analysis indicated that prefrontal and anterior cingulate areas contributed most to model decisions, aligning with established involvement of these regions in attentional regulation and metacognitive processes. Moreover, moderate agreement reflected in Cohen's kappa supports the feasibility of using machine learning to distinguish ACAM-J from non-meditative states. These findings advocate machine-learning's feasibility in classifying advanced meditation states, future research on neuromodulation and mechanistic models of advanced meditation.

</details>


### [143] [Diverging Flows: Detecting Extrapolations in Conditional Generation](https://arxiv.org/abs/2602.13061)
*Constantinos Tsakonas,Serena Ivaldi,Jean-Baptiste Mouret*

Main category: cs.LG

TL;DR: Diverging Flows 提出一种新方法，使单个流模型同时具备条件生成和原生外推检测能力，通过结构化强制对离曼德尔输入的低效传输来实现，有效检测外推而无需牺牲预测保真度或推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有流匹配模型在安全关键场景中存在外推危险，因其平滑性偏差导致即使在离曼德尔条件下也产生看似合理的输出，造成难以察觉的故障。需要一种能同时进行条件生成和外推检测的方法以提升可信度。

Method: 提出 Diverging Flows，通过结构设计强制对离曼德尔输入进行低效传输，从而实现原生外推检测，同时保持条件生成性能。

Result: 在合成流形、跨域风格迁移和天气温度预测任务上验证，该方法能有效检测外推，且不降低预测精度或增加推理延迟。

Conclusion: Diverging Flows 为可信流模型提供了稳健解决方案，推动其在医疗、机器人和气候科学等领域的可靠部署。

Abstract: The ability of Flow Matching (FM) to model complex conditional distributions has established it as the state-of-the-art for prediction tasks (e.g., robotics, weather forecasting). However, deployment in safety-critical settings is hindered by a critical extrapolation hazard: driven by smoothness biases, flow models yield plausible outputs even for off-manifold conditions, resulting in silent failures indistinguishable from valid predictions. In this work, we introduce Diverging Flows, a novel approach that enables a single model to simultaneously perform conditional generation and native extrapolation detection by structurally enforcing inefficient transport for off-manifold inputs. We evaluate our method on synthetic manifolds, cross-domain style transfer, and weather temperature forecasting, demonstrating that it achieves effective detection of extrapolations without compromising predictive fidelity or inference latency. These results establish Diverging Flows as a robust solution for trustworthy flow models, paving the way for reliable deployment in domains such as medicine, robotics, and climate science.

</details>


### [144] [Probabilistic Wind Power Forecasting with Tree-Based Machine Learning and Weather Ensembles](https://arxiv.org/abs/2602.13010)
*Max Bruninx,Diederik van Binsbergen,Timothy Verstraeten,Ann Nowé,Jan Helsen*

Main category: cs.LG

TL;DR: 该论文研究了利用梯度提升树结合天气预报集合，进行风力发电的概率性日前预测。通过对比三种先进的概率预测方法（校准量化回归、自然梯度提升和条件扩散模型），发现条件扩散模型在点估计和概率预测方面表现最佳。此外，使用天气预报集合可使点预测精度提高最多23%。机器学习方法相比传统功率曲线和校准的尾流模型，平均绝对误差分别降低53%和33%。


<details>
  <summary>Details</summary>
Motivation: 准确的风电生产预测对可再生能源并网至关重要。传统方法如功率曲线和校准尾流模型存在局限性，难以充分捕捉复杂气象与风电之间的非线性关系。因此，亟需更先进的机器学习方法来提升预测精度，特别是概率性预测能力，以支持电网调度与能源管理。

Method: 采用梯度提升树构建预测模型，结合多个天气预报集合输入，比较三种概率预测方法：校准量化回归、自然梯度提升和条件扩散模型。同时将机器学习的点预测结果与基于功率曲线和校准尾流模型的确定性工程方法进行对比。

Result: 机器学习方法相较于功率曲线和校准尾流模型，平均绝对误差分别降低53%和33%；条件扩散模型在所有方法中表现最优，兼具良好的概率预测性能与点估计精度；使用天气预报集合可进一步提升点预测精度达23%。

Conclusion: 条件扩散模型结合梯度提升树与多源天气预报集合，是当前最优的风力发电概率性日前预测方法。该方法显著优于传统工程模型，且对提升电网调度灵活性和可再生能源消纳能力具有重要意义。

Abstract: Accurate production forecasts are essential to continue facilitating the integration of renewable energy sources into the power grid. This paper illustrates how to obtain probabilistic day-ahead forecasts of wind power generation via gradient boosting trees using an ensemble of weather forecasts. To this end, we perform a comparative analysis across three state-of-the-art probabilistic prediction methods-conformalised quantile regression, natural gradient boosting and conditional diffusion models-all of which can be combined with tree-based machine learning. The methods are validated using four years of data for all wind farms present within the Belgian offshore zone. Additionally, the point forecasts are benchmarked against deterministic engineering methods, using either the power curve or an advanced approach incorporating a calibrated analytical wake model. The experimental results show that the machine learning methods improve the mean absolute error by up to 53% and 33% compared to the power curve and the calibrated wake model. Considering the three probabilistic prediction methods, the conditional diffusion model is found to yield the best overall probabilistic and point estimate of wind power generation. Moreover, the findings suggest that the use of an ensemble of weather forecasts can improve point forecast accuracy by up to 23%.

</details>


### [145] [Bus-Conditioned Zero-Shot Trajectory Generation via Task Arithmetic](https://arxiv.org/abs/2602.13071)
*Shuai Liu,Ning Cao,Yile Chen,Yue Jiang,Gao Cong*

Main category: cs.LG

TL;DR: 本文提出了一种新的零样本轨迹生成问题设定——基于公交条件的零样本轨迹生成，无需目标城市的任何真实移动轨迹数据。作者提出了MobTA方法，首次将任务算术引入轨迹生成领域，通过源城市数据与两地公开的公交时刻表，利用任务向量的算术操作模拟目标城市的行为模式。该方法在无真实数据情况下仍能生成高质量轨迹，并在实验中表现优于现有方法，接近使用目标城市数据微调模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹生成方法通常依赖目标城市的实际移动数据，但在许多场景下这些数据不可获取，限制了其应用范围。因此需要一种无需目标城市真实轨迹数据即可生成合理轨迹的方法。

Method: 提出基于任务算术的MobTA框架，通过分析源城市公交时刻表生成轨迹与真实移动轨迹之间的参数差异，构建任务向量并进行算术运算，将其迁移至目标城市以生成符合当地模式的轨迹。

Result: 实验表明，MobTA在无目标城市真实数据的情况下，生成轨迹的质量显著优于现有方法，性能接近使用真实数据微调的模型。

Conclusion: MobTA是首个实现基于公交信息的零样本轨迹生成的方法，有效解决了数据不可得场景下的轨迹生成难题，具备良好的泛化性和稳定性，为智慧城市建设提供了新思路。

Abstract: Mobility trajectory data provide essential support for smart city applications. However, such data are often difficult to obtain. Meanwhile, most existing trajectory generation methods implicitly assume that at least a subset of real mobility data from target city is available, which limits their applicability in data-inaccessible scenarios. In this work, we propose a new problem setting, called bus-conditioned zero-shot trajectory generation, where no mobility trajectories from a target city are accessible. The generation process relies solely on source city mobility data and publicly available bus timetables from both cities. Under this setting, we propose MobTA, the first approach to introduce task arithmetic into trajectory generation. MobTA models the parameter shift from bus-timetable-based trajectory generation to mobility trajectory generation in source city, and applies this shift to target city through arithmetic operations on task vectors. This enables trajectory generation that reflects target-city mobility patterns without requiring any real mobility data from it. Furthermore, we theoretically analyze MobTA's stability across base and instruction-tuned LLMs. Extensive experiments show that MobTA significantly outperforms existing methods, and achieves performance close to models finetuned using target city mobility trajectories.

</details>


### [146] [EXCODER: EXplainable Classification Of DiscretE time series Representations](https://arxiv.org/abs/2602.13087)
*Yannik Hahn,Antonin Königsfeld,Hasan Tercan,Tobias Meisen*

Main category: cs.LG

TL;DR: 本文研究了将时间序列数据转换为离散潜在表示（如VQ-VAE和DVAE）是否能提升深度学习模型在时间序列分类中的可解释性。研究表明，这种转换不仅能保留分类所需的关键特征，还能通过减少冗余和噪声，使XAI方法生成更简洁、结构化且忠实的解释。为此，作者提出了一种新指标——相似子序列准确率（SSA），用于量化XAI识别出的重要子序列与训练数据标签分布的一致性，从而验证解释的有效性。结果表明，离散潜在表示不仅保持了分类性能，还为时间序列分析提供了更紧凑、可解释且计算高效的解释路径。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习在时间序列分类中表现优异，但其缺乏可解释性，而现有XAI技术在处理高维、含噪的原始时间序列数据时效果受限。因此，亟需一种既能保持分类性能又能提升解释性的新方法。

Method: 采用VQ-VAE和DVAE等方法将原始时间序列转化为离散潜在表示；在此基础上应用XAI技术生成解释；提出新的评估指标相似子序列准确率（SSA）以衡量解释与标签分布的一致性。

Result: 离散潜在表示显著提升了XAI生成解释的简洁性和结构性，同时保持了分类性能；提出的SSA指标有效验证了解释的真实性与代表性；整体实现了更高效、可解释的时间序列分析。

Conclusion: 离散潜在表示为时间序列分类提供了一条兼具高性能与高可解释性的新路径，使得解释更加紧凑、可信且计算高效，是迈向可信赖时间序列智能系统的重要一步。

Abstract: Deep learning has significantly improved time series classification, yet the lack of explainability in these models remains a major challenge. While Explainable AI (XAI) techniques aim to make model decisions more transparent, their effectiveness is often hindered by the high dimensionality and noise present in raw time series data. In this work, we investigate whether transforming time series into discrete latent representations-using methods such as Vector Quantized Variational Autoencoders (VQ-VAE) and Discrete Variational Autoencoders (DVAE)-not only preserves but enhances explainability by reducing redundancy and focusing on the most informative patterns. We show that applying XAI methods to these compressed representations leads to concise and structured explanations that maintain faithfulness without sacrificing classification performance. Additionally, we propose Similar Subsequence Accuracy (SSA), a novel metric that quantitatively assesses the alignment between XAI-identified salient subsequences and the label distribution in the training data. SSA provides a systematic way to validate whether the features highlighted by XAI methods are truly representative of the learned classification patterns. Our findings demonstrate that discrete latent representations not only retain the essential characteristics needed for classification but also offer a pathway to more compact, interpretable, and computationally efficient explanations in time series analysis.

</details>


### [147] [Resource-Efficient Gesture Recognition through Convexified Attention](https://arxiv.org/abs/2602.13030)
*Daniel Schwartz,Dario Salvucci,Yusuf Osmanlioglu,Richard Vallett,Genevieve Dion,Ali Shokoufandeh*

Main category: cs.LG

TL;DR: 本文提出一种针对可穿戴电子纺织品界面的凸化注意力机制，通过欧几里得投影到概率单纯形和多分类合页损失函数，实现全局收敛性，克服传统非凸softmax机制的局限。该方法在仅120-360个参数下达到100%手势识别准确率，推理时间低于300微秒，存储需求小于7KB，适用于无外部计算的纺织集成设备。


<details>
  <summary>Details</summary>
Motivation: 可穿戴电子纺织品界面受限于功耗、计算能力和形态因素，传统深度学习难以应用；现有轻量级模型如MobileNet仍需数千参数，不适用于纺织集成平台。

Method: 采用非扩张单纯形投影与凸损失函数结合的凸化注意力机制，替代传统非凸softmax操作，确保全局收敛性；在四点触控电容传感器上实现并验证。

Result: 在10折交叉验证和保留测试中，敲击和滑动手势均达到100.00%准确率，参数量减少97%，推理时间290–296μs，存储占用<7KB，支持直接在纺织品上部署。

Conclusion: 凸优化方法为纺织品界面中的高效本地机器学习提供了可行路径，可实现在资源受限设备上的低功耗、高精度手势识别。

Abstract: Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thousands of parameters, limiting deployment on textile-integrated platforms. We introduce a convexified attention mechanism for wearable applications that dynamically weights features while preserving convexity through nonexpansive simplex projection and convex loss functions. Unlike conventional attention mechanisms using non-convex softmax operations, our approach employs Euclidean projection onto the probability simplex combined with multi-class hinge loss, ensuring global convergence guarantees. Implemented on a textile-based capacitive sensor with four connection points, our approach achieves 100.00\% accuracy on tap gestures and 100.00\% on swipe gestures -- consistent across 10-fold cross-validation and held-out test evaluation -- while requiring only 120--360 parameters, a 97\% reduction compared to conventional approaches. With sub-millisecond inference times (290--296$μ$s) and minimal storage requirements ($<$7KB), our method enables gesture interfaces directly within e-textiles without external processing. Our evaluation, conducted in controlled laboratory conditions with a single-user dataset, demonstrates feasibility for basic gesture interactions. Real-world deployment would require validation across multiple users, environmental conditions, and more complex gesture vocabularies. These results demonstrate how convex optimization can enable efficient on-device machine learning for textile interfaces.

</details>


### [148] [TCRL: Temporal-Coupled Adversarial Training for Robust Constrained Reinforcement Learning in Worst-Case Scenarios](https://arxiv.org/abs/2602.13040)
*Wentao Xu,Zhongming Yao,Weihao Li,Zhenghang Song,Yumeng Song,Tianyi Li,Yushuai Li*

Main category: cs.LG

TL;DR: 提出TCRL框架，通过最坏情况感知成本约束和双约束防御机制，提升在时间耦合扰动下的鲁棒性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒约束强化学习方法主要关注单步扰动和独立于时间的对抗模型，缺乏对时间耦合扰动的显式建模，限制了其在安全关键领域的应用。

Method: 引入最坏情况感知成本约束函数以估计时间耦合扰动下的安全成本，并建立双约束防御机制，在保持奖励不可预测性的同时抵御时间耦合攻击。

Result: 实验表明，TCRL在多种约束强化学习任务中对时间耦合扰动攻击表现出更强的鲁棒性，持续优于现有方法。

Conclusion: TCRL为应对时间耦合扰动提供了有效解决方案，显著提升了约束强化学习在复杂、动态环境中的安全性与可靠性。

Abstract: Constrained Reinforcement Learning (CRL) aims to optimize decision-making policies under constraint conditions, making it highly applicable to safety-critical domains such as autonomous driving, robotics, and power grid management. However, existing robust CRL approaches predominantly focus on single-step perturbations and temporally independent adversarial models, lacking explicit modeling of robustness against temporally coupled perturbations. To tackle these challenges, we propose TCRL, a novel temporal-coupled adversarial training framework for robust constrained reinforcement learning (TCRL) in worst-case scenarios. First, TCRL introduces a worst-case-perceived cost constraint function that estimates safety costs under temporally coupled perturbations without the need to explicitly model adversarial attackers. Second, TCRL establishes a dual-constraint defense mechanism on the reward to counter temporally coupled adversaries while maintaining reward unpredictability. Experimental results demonstrate that TCRL consistently outperforms existing methods in terms of robustness against temporally coupled perturbation attacks across a variety of CRL tasks.

</details>


### [149] [GPTZero: Robust Detection of LLM-Generated Texts](https://arxiv.org/abs/2602.13042)
*George Alexandru Adam,Alexander Cui,Edwin Thomas,Emily Napier,Nazar Shmatko,Jacob Schnell,Jacob Junqi Tian,Alekhya Dronavalli,Edward Tian,Dongwon Lee*

Main category: cs.LG

TL;DR: GPTZero 是一种先进的工业级AI文本检测解决方案，能够有效区分人类撰写与大语言模型生成的文本。其核心贡献包括：提出分层多任务架构以实现对人类与AI文本的灵活分类；在多个领域展现顶尖准确率并提供细粒度预测；通过多层级自动化红队测试提升对对抗攻击和改写文本的鲁棒性。该系统具备高精度、可解释性，并倡导负责任使用，确保文本评估的公平与透明。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，传统文本真实性问题已从剽窃转向如何区分人类与AI生成内容。这一转变带来了技能评价失真、低质内容泛滥及虚假信息传播等严重挑战，亟需可靠的检测工具来应对。

Method: 采用分层多任务架构，构建灵活的文本分类体系；结合多层级自动化红队测试进行模型鲁棒性验证；利用深度学习技术实现对文本特征的精细化分析与判断。

Result: GPTZero 在多种文本领域实现了行业领先水平的检测准确率，具备出色的抗干扰能力，能有效抵御对抗性修改与重述攻击；同时提供可解释的结果，帮助用户理解检测逻辑。

Conclusion: GPTZero 为解决人工智能生成内容的识别难题提供了高效、可靠且可解释的方案，推动了文本评估的公平性与透明度，是当前最先进的人工智能文本检测工具之一。

Abstract: While historical considerations surrounding text authenticity revolved primarily around plagiarism, the advent of large language models (LLMs) has introduced a new challenge: distinguishing human-authored from AI-generated text. This shift raises significant concerns, including the undermining of skill evaluations, the mass-production of low-quality content, and the proliferation of misinformation. Addressing these issues, we introduce GPTZero a state-of-the-art industrial AI detection solution, offering reliable discernment between human and LLM-generated text. Our key contributions include: introducing a hierarchical, multi-task architecture enabling a flexible taxonomy of human and AI texts, demonstrating state-of-the-art accuracy on a variety of domains with granular predictions, and achieving superior robustness to adversarial attacks and paraphrasing via multi-tiered automated red teaming. GPTZero offers accurate and explainable detection, and educates users on its responsible use, ensuring fair and transparent assessment of text.

</details>


### [150] [Quantization-Aware Collaborative Inference for Large Embodied AI Models](https://arxiv.org/abs/2602.13052)
*Zhonghao Lyu,Ming Xiao,Mikael Skoglund,Merouane Debbah,H. Vincent Poor*

Main category: cs.LG

TL;DR: 本文研究了用于具身AI系统的量化感知协同推理（co-inference），提出了一种可计算的量化引入推理失真近似方法，并推导出量化率-失真函数的上下界，分析了其与大规模人工智能模型（LAIMs）统计特性（如量化位宽）的关系。进一步地，提出了在延迟和能耗约束下联合优化量化位宽与计算频率的问题，以最小化失真上界并保证紧致性。实验验证了所提失真近似、率失真边界及联合设计的有效性，仿真与真实测试平台结果表明该方法能有效平衡边缘具身AI系统中的推理质量、延迟与能耗。


<details>
  <summary>Details</summary>
Motivation: 大规模人工智能模型（LAIMs）虽是具身AI应用的核心智能引擎，但其巨大的参数量和计算需求对资源受限的具身智能体构成挑战。如何在有限资源下保持高推理质量，成为关键问题。因此，亟需一种高效且低开销的推理机制，尤其在边缘设备上实现高质量推理的同时控制延迟和能耗。

Method: 提出量化感知协同推理框架；构建量化引入推理失真的可计算近似；推导量化率-失真函数的上下界；建立联合优化模型，同时设计量化位宽与计算频率，在满足延迟与能量约束下最小化失真上界。

Result: 所提失真近似准确有效；率失真上下界能够紧密刻画失真随量化位宽的变化关系；联合优化设计显著改善边缘具身AI系统中推理质量、延迟与能耗的权衡表现；仿真与实测均验证了方法的有效性和实用性。

Conclusion: 本文提出的量化感知协同推理方法通过理论建模与联合优化设计，为资源受限的边缘具身AI系统提供了一种高效、低功耗且高精度的推理解决方案，具有良好的实用前景。

Abstract: Large artificial intelligence models (LAIMs) are increasingly regarded as a core intelligence engine for embodied AI applications. However, the massive parameter scale and computational demands of LAIMs pose significant challenges for resource-limited embodied agents. To address this issue, we investigate quantization-aware collaborative inference (co-inference) for embodied AI systems. First, we develop a tractable approximation for quantization-induced inference distortion. Based on this approximation, we derive lower and upper bounds on the quantization rate-inference distortion function, characterizing its dependence on LAIM statistics, including the quantization bit-width. Next, we formulate a joint quantization bit-width and computation frequency design problem under delay and energy constraints, aiming to minimize the distortion upper bound while ensuring tightness through the corresponding lower bound. Extensive evaluations validate the proposed distortion approximation, the derived rate-distortion bounds, and the effectiveness of the proposed joint design. Particularly, simulations and real-world testbed experiments demonstrate the effectiveness of the proposed joint design in balancing inference quality, latency, and energy consumption in edge embodied AI systems.

</details>


### [151] [Backdoor Attacks on Contrastive Continual Learning for IoT Systems](https://arxiv.org/abs/2602.13062)
*Alfous Tim,Kuniyilh Simi D*

Main category: cs.LG

TL;DR: 本文分析了物联网（IoT）系统中对比持续学习（CCL）面临的后门攻击威胁，揭示了嵌入对齐与回放增强机制带来的安全漏洞，并提出针对IoT场景的分层攻击分类法，评估不同学习范式下的脆弱性及防御策略在资源受限环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网系统依赖持续学习应对非平稳环境（如传感器漂移、用户行为变化等），对比持续学习（CCL）虽提升了特征复用能力，但其几何特性与回放机制易被后门攻击利用，导致持久恶意行为难以清除，亟需系统性安全分析与防护。

Method: 提出嵌入级攻击形式化模型，构建面向IoT的分层攻击分类体系，对比多种学习范式下的安全脆弱性，评估在边缘计算、联邦聚合、内存受限等约束下的防御策略性能。

Result: 研究发现，尽管CCL能有效提升IoT系统的自适应智能，但若缺乏充分防护，将显著增加长期存在的表示层威胁；现有防御措施在资源受限环境下面临挑战，需针对性优化。

Conclusion: CCL在提升物联网系统持续学习能力的同时引入了新的安全风险，尤其在后门攻击方面表现出持久性和隐蔽性。为保障系统安全，必须在设计阶段集成轻量级、可扩展的安全机制，以应对边缘部署中的实际约束。

Abstract: The Internet of Things (IoT) systems increasingly depend on continual learning to adapt to non-stationary environments. These environments can include factors such as sensor drift, changing user behavior, device aging, and adversarial dynamics. Contrastive continual learning (CCL) combines contrastive representation learning with incremental adaptation, enabling robust feature reuse across tasks and domains. However, the geometric nature of contrastive objectives, when paired with replay-based rehearsal and stability-preserving regularization, introduces new security vulnerabilities. Notably, backdoor attacks can exploit embedding alignment and replay reinforcement, enabling the implantation of persistent malicious behaviors that endure through updates and deployment cycles. This paper provides a comprehensive analysis of backdoor attacks on CCL within IoT systems. We formalize the objectives of embedding-level attacks, examine persistence mechanisms unique to IoT deployments, and develop a layered taxonomy tailored to IoT. Additionally, we compare vulnerabilities across various learning paradigms and evaluate defense strategies under IoT constraints, including limited memory, edge computing, and federated aggregation. Our findings indicate that while CCL is effective for enhancing adaptive IoT intelligence, it may also elevate long-lived representation-level threats if not adequately secured.

</details>


### [152] [Unified Multi-Domain Graph Pre-training for Homogeneous and Heterogeneous Graphs via Domain-Specific Expert Encoding](https://arxiv.org/abs/2602.13075)
*Chundong Liang,Yongqi Huang,Dongxiao He,Peiyuan Li,Yawen Li,Di Jin,Weixiong Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种统一的多域图预训练方法GPH²，旨在解决异构与同构图预训练分离的问题。通过引入统一多视角图构建和领域特定专家编码，有效缓解跨域分布差异，并设计任务导向的专家融合策略，实现对混合图类型和领域的稳定迁移，在下游任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图预训练方法通常仅针对同构或异构图设计，难以在真实世界中混合使用且存在分布偏移问题，限制了统一建模能力。

Method: 提出统一多视角图构建以同时编码同构与异构图；采用领域特定专家独立预训练以捕捉领域知识；设计任务导向的专家融合策略自适应集成多个专家。

Result: 在混合图数据上实验表明，GPH²实现了跨图类型和领域的稳定迁移，性能显著优于现有图预训练方法。

Conclusion: GPH²通过统一编码框架与专家机制，有效支持同构与异构图的联合预训练，在复杂现实场景下展现出更强的泛化与适应能力。

Abstract: Graph pre-training has achieved remarkable success in recent years, delivering transferable representations for downstream adaptation. However, most existing methods are designed for either homogeneous or heterogeneous graphs, thereby hindering unified graph modeling across diverse graph types. This separation contradicts real-world applications, where mixed homogeneous and heterogeneous graphs are ubiquitous, and distribution shifts between upstream pre-training and downstream deployment are common. In this paper, we empirically demonstrate that a balanced mixture of homogeneous and heterogeneous graph pre-training benefits downstream tasks and propose a unified multi-domain \textbf{G}raph \textbf{P}re-training method across \textbf{H}omogeneous and \textbf{H}eterogeneous graphs ($\mathbf{GPH^{2}}$). To address the lack of a unified encoder for homogeneous and heterogeneous graphs, we propose a Unified Multi-View Graph Construction that simultaneously encodes both without explicit graph-type-specific designs. To cope with the increased cross-domain distribution discrepancies arising from mixed graphs, we introduce domain-specific expert encoding. Each expert is independently pre-trained on a single graph to capture domain-specific knowledge, thereby shielding the pre-training encoder from the adverse effects of cross-domain discrepancies. For downstream tasks, we further design a Task-oriented Expert Fusion Strategy that adaptively integrates multiple experts based on their discriminative strengths. Extensive experiments on mixed graphs demonstrate that $\text{GPH}^{2}$ enables stable transfer across graph types and domains, significantly outperforming existing graph pre-training methods.

</details>


### [153] [R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training](https://arxiv.org/abs/2602.13103)
*Gengsheng Li,Jinghan He,Shijie Wang,Dan Zhang,Ruiqi Liu,Renrui Zhang,Zijun Yao,Junfeng Fang,Haiyun Guo,Jinqiao Wang*

Main category: cs.LG

TL;DR: R-Diverse proposes a solution to the non-sustained improvement problem in self-play LLM reasoning by addressing 'Diversity Illusion' through Memory-Augmented Penalty (MAP) and Skill-Aware Measurement (SAM), leading to sustained gains across multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing self-play frameworks like R-Zero suffer from non-sustained improvement due to hidden pattern collapse despite apparent diversity in training data, limiting long-term reasoning skill development.

Method: Introduces R-Diverse with two innovations: MAP, which uses a persistent memory bank to penalize repeated patterns across iterations; and SAM, which measures diversity based on the variety of reasoning skills exercised rather than superficial question differences.

Result: R-Diverse achieves sustained performance gains over more iterations and consistently outperforms prior self-play methods across 10 math and general reasoning benchmarks.

Conclusion: By mitigating Diversity Illusion via MAP and SAM, R-Diverse enables more effective and lasting self-improvement in LLM reasoning, advancing the state-of-the-art in self-play frameworks.

Abstract: Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhibit non-sustained improvement, where early gains degrade as self-play continues. We identify a key failure mode, Diversity Illusion, where the Solver's training signals appear diverse yet collapse into recurring underlying patterns. It manifests as (1) Local Diversity Illusion, where diversity is enforced only within-batch, inducing cross-iteration mode cycling; and (2) Surface Diversity Illusion, where questions vary superficially but require near-identical reasoning skills. To mitigate them, we propose R-Diverse with two aligned innovations: Memory-Augmented Penalty (MAP), which uses a persistent memory bank to discourage recycling across iterations, and Skill-Aware Measurement (SAM), which evaluates diversity by the reasoning skills exercised rather than surface variation of questions. Across 10 math and general reasoning benchmarks, R-Diverse sustains gains over more iterations and consistently outperforms prior self-play methods. Code is available at https://github.com/Gengsheng-Li/R-Diverse.

</details>


### [154] [FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics](https://arxiv.org/abs/2602.13140)
*Pingzhi Li,Hongxuan Li,Zirui Liu,Xingcheng Lin,Tianlong Chen*

Main category: cs.LG

TL;DR: FlashSchNet 是一种高效的、输入/输出感知的 SchNet 风格 GNN-MD 框架，通过四项关键技术显著提升分子动力学模拟性能：（1）闪速径向基函数，融合距离计算、高斯基展开和余弦包络，减少重复计算；（2）闪速消息传递，融合截断、邻居收集、滤波乘法与归约，避免在高带宽内存中存储边张量；（3）闪速聚合，采用 CSR 分段归约重构 scatter-add，降低原子写入次数并实现无竞争积累；（4）通道级 16 位量化，利用 SchNet MLP 权重的低通道动态范围，提升吞吐量且几乎不影响精度。在单个 NVIDIA RTX PRO 6000 上，对包含 269 个珠子的粗粒度蛋白质系统，实现 1000 ns/day 的总模拟吞吐量，相比基线 CGSchNet 提速 6.5 倍，峰值内存减少 80%，超越经典力场（如 MARTINI），同时保持 SchNet 级别的精度与可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有 GNN 力场（如 SchNet）虽能准确建模多体相互作用，但受限于碎片化内核和内存密集型流水线，导致 GPU 利用率低，运行速度慢于经典力场。其根本原因在于缺乏对 GPU 高带宽内存（HBM）与片上 SRAM 间数据读写行为的优化设计。因此，亟需构建一种输入/输出感知的 GNN-MD 框架，以最大化硬件资源利用率。

Method: 提出 FlashSchNet 框架，集成四项核心技术：（1）闪速径向基：将距离计算、基函数展开与包络函数合并为单一分块遍历，仅计算一次距离并复用至所有基函数；（2）闪速消息传递：融合截断、邻居收集、权重乘法与归约操作，避免在 HBM 中显式存储边张量；（3）闪速聚合：使用 CSR 格式的分段归约重构 scatter-add，减少原子写入次数，支持前向与反向传播中的无竞争累积；（4）通道级 16 位量化：基于 SchNet MLP 权重各通道动态范围小的特点，实施通道独立的低精度表示，提升计算效率。

Result: 在单张 NVIDIA RTX PRO 6000 显卡上，FlashSchNet 在 64 个并行粗粒度蛋白模拟副本上实现了 1000 ns/day 的总吞吐量，相较基线 CGSchNet 提升 6.5 倍，峰值内存占用降低 80%。其性能超越经典力场（如 MARTINI），同时维持 SchNet 级别的精度与跨体系结构的泛化能力。

Conclusion: FlashSchNet 证明了输入/输出感知设计在 GNN-MD 中的关键作用。通过系统性优化数据访问模式与计算流程，可显著提升 GNN 力场的计算效率，使其在保持高精度与可迁移性的同时，达到甚至超越经典力场的性能水平，为大规模分子模拟提供了高效可行的新路径。

Abstract: Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show that a missing principle is making GNN-MD IO-aware, carefully accounting for reads and writes between GPU high-bandwidth memory (HBM) and on-chip SRAM. We present FlashSchNet, an efficient and accurate IO-aware SchNet-style GNN-MD framework built on four techniques: (1) flash radial basis, which fuses pairwise distance computation, Gaussian basis expansion, and cosine envelope into a single tiled pass, computing each distance once and reusing it across all basis functions; (2) flash message passing, which fuses cutoff, neighbor gather, filter multiplication, and reduction to avoid materializing edge tensors in HBM; (3) flash aggregation, which reformulates scatter-add via CSR segment reduce, reducing atomic writes by a factor of feature dimension and enabling contention-free accumulation in both forward and backward passes; (4) channel-wise 16-bit quantization that exploits the low per-channel dynamic range in SchNet MLP weights to further improve throughput with negligible accuracy loss. On a single NVIDIA RTX PRO 6000, FlashSchNet achieves 1000 ns/day aggregate simulation throughput over 64 parallel replicas on coarse-grained (CG) protein containing 269 beads (6.5x faster than CGSchNet baseline with 80% reduction of peak memory), surpassing classical force fields (e.g. MARTINI) while retaining SchNet-level accuracy and transferability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [155] [GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory](https://arxiv.org/abs/2602.12316)
*Pepijn Cobben,Xuanqiang Angelo Huang,Thao Amelia Pham,Isabel Dahlgren,Terry Jingchen Zhang,Zhijing Jin*

Main category: cs.AI

TL;DR: 提出GT-HarmBench基准，涵盖2009个高风险多智能体场景，评估15个前沿模型在博弈论结构中的表现，发现仅62%情况下选择社会有益行动，存在显著可靠性差距，并验证博弈论干预可提升社会有益结果最多18%。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全基准主要评估单智能体系统，无法充分覆盖多智能体环境中的协调失败和冲突等风险，亟需标准化测试平台以研究多智能体对齐问题。

Method: 构建基于真实AI风险情境的多智能体场景库，涵盖囚徒困境、猎鹿博弈、懦夫博弈等博弈论结构，通过15个前沿模型进行实验，分析提示框架与顺序对行为的影响，评估不同干预策略的效果。

Result: 前沿模型在高风险场景中仅62%选择社会有益行动，常导致有害后果；提示框架和顺序显著影响行为表现；引入博弈论干预后，社会有益行为比例最高提升18%。

Conclusion: 多智能体系统存在显著的对齐可靠性差距，需要更全面的评估工具和干预方法；GT-HarmBench为研究多智能体对齐提供了标准化测试平台。

Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly understood. We introduce GT-HarmBench, a benchmark of 2,009 high-stakes scenarios spanning game-theoretic structures such as the Prisoner's Dilemma, Stag Hunt and Chicken. Scenarios are drawn from realistic AI risk contexts in the MIT AI Risk Repository. Across 15 frontier models, agents choose socially beneficial actions in only 62% of cases, frequently leading to harmful outcomes. We measure sensitivity to game-theoretic prompt framing and ordering, and analyze reasoning patterns driving failures. We further show that game-theoretic interventions improve socially beneficial outcomes by up to 18%. Our results highlight substantial reliability gaps and provide a broad standardized testbed for studying alignment in multi-agent environments. The benchmark and code are available at https://github.com/causalNLP/gt-harmbench.

</details>


### [156] [To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2602.12566)
*Haoqing Wang,Xiang Long,Ziheng Li,Yilong Xu,Tingguang Li,Yehui Tang*

Main category: cs.AI

TL;DR: 本文研究了多领域强化学习中可验证奖励（RLVR）的两种训练范式：混合多任务RLVR与分离训练后模型合并。通过在数学、编程、科学和指令遵循等任务上的实验，发现跨领域RLVR干扰较少，且推理密集型领域间存在协同增益。进一步从权重空间几何、模型预测行为和信息约束角度分析了协同机制。项目命名为M2RL，旨在探索最优多领域专家模型训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对混合多任务与分离训练后合并这两种多领域RLVR范式的系统性比较与分析，尤其在跨领域协同效应方面理解不足，因此亟需深入研究以实现通用多领域专家级模型的高效训练。

Method: 选取数学、编程、科学、指令遵循等高阶任务作为目标领域，基于开源数据集设计大量定性和定量实验，对比混合多任务训练与分离训练后合并两种范式，并从权重空间几何、模型预测行为及信息约束三个维度分析跨领域协同机制。

Result: 实验表明跨领域RLVR表现出较低的相互干扰，推理密集型任务之间存在显著的相互促进作用；权重空间分析显示参数更新方向具有一致性，预测行为更稳定，信息约束下模型能有效共享知识。

Conclusion: M2RL框架证明了混合多任务或分离训练后合并均可有效构建多领域专家级模型，其中推理密集型任务间的协同效应显著，为未来通用大模型的高效训练提供了新思路与实证支持。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) plays a key role in stimulating the explicit reasoning capability of Large Language Models (LLMs). We can achieve expert-level performance in some specific domains via RLVR, such as coding or math. When a general multi-domain expert-level model is required, we need to carefully consider the collaboration of RLVR across different domains. The current state-of-the-art models mainly employ two different training paradigms for multi-domain RLVR: mixed multi-task RLVR and separate RLVR followed by model merging. However, most of the works did not provide a detailed comparison and analysis about these paradigms. To this end, we choose multiple commonly used high-level tasks (e.g., math, coding, science, and instruction following) as our target domains and design extensive qualitative and quantitative experiments using open-source datasets. We find the RLVR across domains exhibits few mutual interferences, and reasoning-intensive domains demonstrate mutually synergistic effects. Furthermore, we analyze the internal mechanisms of mutual gains from the perspectives of weight space geometry, model prediction behavior, and information constraints. This project is named as M2RL that means Mixed multi-task training or separate training followed by model Merging for Reinforcement Learning, and the homepage is at https://github.com/mosAI25/M2RL

</details>


### [157] [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)
*Joshua Ong Jun Leang,Yu Zhao,Mihaela Cătălina Stoian,Wenda Li,Shay B. Cohen,Eleonora Giunchiglia*

Main category: cs.AI

TL;DR: McDiffuSE introduces a novel framework for optimizing slot infilling order in Masked Diffusion Models (MDMs) using Monte Carlo Tree Search (MCTS), significantly improving generation quality and reducing output variance. It leverages look-ahead simulations to evaluate partial completions, enabling systematic exploration of generation orders. The method achieves up to 19.5% improvement on MBPP and 8.0% over baseline plan-and-infill, with larger exploration constants proving more effective than increased simulations for overcoming model biases.


<details>
  <summary>Details</summary>
Motivation: Current plan-and-infill decoding in MDMs is highly sensitive to slot infilling order, leading to inconsistent performance and high output variance. There is a need for a more robust strategy to determine optimal generation sequences.

Method: McDiffuSE formulates slot selection as a decision-making problem and applies Monte Carlo Tree Search (MCTS) to optimize infilling order. It uses look-ahead simulations to assess partial completions before committing to a choice, allowing for effective exploration of the combinatorial space of possible generation orders.

Result: McDiffuSE achieves an average 3.2% improvement over autoregressive baselines and 8.0% over baseline plan-and-infill. Notable gains include 19.5% on MBPP and 4.9% on MATH500. Results show that non-sequential generation is crucial for peak performance, and larger exploration constants are key to overcoming model confidence biases.

Conclusion: MCTS-based planning is an effective approach for enhancing generation quality in Masked Diffusion Models by systematically optimizing infilling order, reducing variance, and enabling better discovery of high-quality completion sequences.

Abstract: While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision making and optimises infilling orders through Monte Carlo Tree Search (MCTS). McDiffuSE uses look-ahead simulations to evaluate partial completions before commitment, systematically exploring the combinatorial space of generation orders. Experiments show an average improvement of 3.2% over autoregressive baselines and 8.0% over baseline plan-and-infill, with notable gains of 19.5% on MBPP and 4.9% on MATH500. Our analysis reveals that while McDiffuSE predominantly follows sequential ordering, incorporating non-sequential generation is essential for maximising performance. We observe that larger exploration constants, rather than increased simulations, are necessary to overcome model confidence biases and discover effective orderings. These findings establish MCTS-based planning as an effective approach for enhancing generation quality in MDMs.

</details>


### [158] [AI Agents for Inventory Control: Human-LLM-OR Complementarity](https://arxiv.org/abs/2602.12631)
*Jackie Baek,Yaopeng Fu,Will Ma,Tianyi Peng*

Main category: cs.AI

TL;DR: 本文研究了在多期库存控制场景中，运筹学（OR）算法、大语言模型（LLM）与人类如何协同互补。通过构建包含1000多个库存实例的InventoryBench基准，涵盖合成与真实需求数据，验证了在需求波动、季节性和不确定提前期下的决策性能。结果表明，OR增强的LLM方法优于单独使用任一方法，说明二者具有互补性。进一步的人类实验显示，人机协作团队平均利润高于单独的人或AI，且存在个体层面的互补效应，实证发现多数个体从中受益。


<details>
  <summary>Details</summary>
Motivation: 传统库存决策依赖运筹学算法，但其对假设敏感，在需求变化或信息缺失时表现不佳；而大语言模型虽具备灵活推理和上下文理解能力，但尚未明确如何有效融入现有决策流程。因此亟需探索三者之间的协同机制。

Method: 构建InventoryBench基准，涵盖多种复杂场景下的库存实例；采用对比实验评估不同方法（纯OR、纯LLM、OR+LLM）的表现；通过受控课堂实验，将LLM建议嵌入人机协同决策流程，分析人类与AI的互动效果。

Result: OR增强的LLM方法在各类挑战性场景下均表现更优，证明两者互补；人机协作团队整体利润更高，且个体层面存在显著互补效应，实证显示多数参与者从协作中获益。

Conclusion: 在库存控制中，运筹学、大语言模型与人类并非替代关系，而是具有显著互补性。合理整合三者可实现性能提升，尤其在动态和不确定环境中，人机协同具有重要应用潜力。

Abstract: Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it remains unclear how best to incorporate LLM-based methods into traditional decision-making pipelines.
  We study how OR algorithms, LLMs, and humans can interact and complement each other in a multi-period inventory control setting. We construct InventoryBench, a benchmark of over 1,000 inventory instances spanning both synthetic and real-world demand data, designed to stress-test decision rules under demand shifts, seasonality, and uncertain lead times. Through this benchmark, we find that OR-augmented LLM methods outperform either method in isolation, suggesting that these methods are complementary rather than substitutes.
  We further investigate the role of humans through a controlled classroom experiment that embeds LLM recommendations into a human-in-the-loop decision pipeline. Contrary to prior findings that human-AI collaboration can degrade performance, we show that, on average, human-AI teams achieve higher profits than either humans or AI agents operating alone. Beyond this population-level finding, we formalize an individual-level complementarity effect and derive a distribution-free lower bound on the fraction of individuals who benefit from AI collaboration; empirically, we find this fraction to be substantial.

</details>


### [159] [Evaluating Robustness of Reasoning Models on Parameterized Logical Problems](https://arxiv.org/abs/2602.12665)
*Naïm Es-sebbani,Esteban Marquer,Yakoub Salhi,Zied Bouraoui*

Main category: cs.AI

TL;DR: 本文提出一个基于参数化结构化2-CNF公式的诊断性2-SAT基准，用于评估大语言模型（LLM）在逻辑推理中的表现。该基准通过可解释的维度调节可满足性，涵盖矛盾环、自由变量比例、植入手柄、延迟桥接子句以及对称/重复变体等不同能力与失效模式。实验评估了LLM在决策准确性和赋值有效性上的表现，并测试其在语义保持扰动下的鲁棒性。结果发现，即使表面统计量固定，结构性干预也会引发性能急剧变化，揭示出传统平均准确率无法捕捉的脆弱性区域。


<details>
  <summary>Details</summary>
Motivation: 标准的SAT基准常将表面难度（如长度、措辞、子句顺序）与决定可满足性的结构性现象混淆，导致难以准确评估模型的真实推理能力。因此需要一种能分离结构性因素的诊断性基准，以更精细地分析和评估LLM在逻辑推理中的表现。

Method: 设计并实现一组参数化的2-CNF公式生成器，能够系统控制五类结构性特征：(i) 可控大小与不平衡性的矛盾环UNSAT核心；(ii) 预设自由变量比例以调控解的多重性；(iii) 植入手柄以调节传播行为；(iv) 延迟桥接子句以探测对顺序和修正的敏感性；(v) 对称与重复变体以测试重命名和冗余结构下的抽象能力。通过这些生成器构建诊断性2-SAT基准，并在多种扰动下评估LLM的表现。

Result: LLM在面对结构性干预时表现出显著的性能跃迁，即使表面特征保持不变。这表明模型在某些结构条件下存在脆弱性，而这些脆弱性在传统的平均准确率指标中无法被察觉。此外，模型在赋值有效性上也存在明显缺陷，尤其是在处理复杂结构或扰动后。

Conclusion: 本研究揭示了当前LLM在逻辑推理中对结构性信息的敏感性与脆弱性，强调了开发更具结构性感知能力的评估基准的重要性。未来的工作应聚焦于提升模型对深层结构关系的理解能力，而非仅依赖表面模式匹配。

Abstract: Logic provides a controlled testbed for evaluating LLM-based reasoners, yet standard SAT-style benchmarks often conflate surface difficulty (length, wording, clause order) with the structural phenomena that actually determine satisfiability. We introduce a diagnostic benchmark for 2-SAT built from parameterized families of structured 2--CNF formulas, where satisfiability is characterized by the implication graph and can be tuned along interpretable axes. Our generators isolate distinct competencies and failure modes: (i) contradiction-cycle UNSAT cores with controllable size and imbalance, (ii) SAT instances with a prescribed fraction of free variables to control solution multiplicity, (iii) planted backbones that modulate propagation, (iv) late bridge clauses that couple otherwise monotone regions to probe sensitivity to ordering and revision, and (v) symmetry/duplication variants that test abstraction under renaming and redundant structure. We evaluate LLM-based reasoners on decision accuracy and assignment validity, and quantify robustness under semantics-preserving perturbations such as clause reordering, filler clauses, and variable renaming. Across models, we observe sharp performance transitions under targeted structural interventions even when surface statistics are held fixed, revealing brittleness regimes that are invisible to aggregate SAT accuracy.

</details>


### [160] [X-SYS: A Reference Architecture for Interactive Explanation Systems](https://arxiv.org/abs/2602.12748)
*Tobias Labarta,Nhi Hoang,Maximilian Dreyer,Jim Berend,Oleg Hein,Jackie Ma,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.AI

TL;DR: 本文提出X-SYS参考架构，用于解决可解释人工智能（XAI）系统在实际部署中的挑战。该架构以STAR四要素（可扩展性、可追溯性、响应性和适应性）为核心，采用五组件分解（XUI服务、解释服务、模型服务、数据服务、编排与治理），将用户交互模式与系统能力解耦，支持界面与后端独立演进。通过实现SemanticLens系统，验证了合同式服务边界、在线/离线分离及持久化状态管理的有效性，为交互式解释系统提供了可复用的设计蓝图和具体实例。


<details>
  <summary>Details</summary>
Motivation: 当前可解释人工智能（XAI）研究虽有众多技术方法，但在实际系统部署中仍面临挑战，如需在反复查询、模型与数据演化及治理约束下保持解释可用性。现有方法缺乏对系统层面需求的系统性考虑，因此亟需将解释性视为信息系统问题，构建支持长期运营的架构框架。

Method: 提出X-SYS参考架构，基于STAR质量属性（可扩展性、可追溯性、响应性、适应性），采用五组件分解结构，并通过交互模式映射系统能力，实现前端界面与后端计算的解耦。结合合同式服务边界、离线/在线分离机制与持久化状态管理，支撑系统的灵活演进与稳定运行。

Result: 通过实现SemanticLens系统，验证了X-SYS架构在支持语义搜索与视觉-语言模型激活控制方面的有效性。系统展现出良好的可扩展性、响应性、可追溯性与适应性，证明了其作为通用设计蓝图的可行性与实用性。

Conclusion: X-SYS提供了一个面向操作化的交互式解释系统参考架构，不仅为研究人员和开发者提供了系统设计指导，还通过具体实现展示了如何在真实场景中应对复杂约束，推动可解释人工智能从理论走向实践。

Abstract: The explainable AI (XAI) research community has proposed numerous technical methods, yet deploying explainability as systems remains challenging: Interactive explanation systems require both suitable algorithms and system capabilities that maintain explanation usability across repeated queries, evolving models and data, and governance constraints. We argue that operationalizing XAI requires treating explainability as an information systems problem where user interaction demands induce specific system requirements. We introduce X-SYS, a reference architecture for interactive explanation systems, that guides (X)AI researchers, developers and practitioners in connecting interactive explanation user interfaces (XUI) with system capabilities. X-SYS organizes around four quality attributes named STAR (scalability, traceability, responsiveness, and adaptability), and specifies a five-component decomposition (XUI Services, Explanation Services, Model Services, Data Services, Orchestration and Governance). It maps interaction patterns to system capabilities to decouple user interface evolution from backend computation. We implement X-SYS through SemanticLens, a system for semantic search and activation steering in vision-language models. SemanticLens demonstrates how contract-based service boundaries enable independent evolution, offline/online separation ensures responsiveness, and persistent state management supports traceability. Together, this work provides a reusable blueprint and concrete instantiation for interactive explanation systems supporting end-to-end design under operational constraints.

</details>


### [161] [Information-theoretic analysis of world models in optimal reward maximizers](https://arxiv.org/abs/2602.12963)
*Alfred Harwood,Jose Faustino,Alex Altair*

Main category: cs.AI

TL;DR: 该研究通过信息论方法，量化了最优策略对环境的描述信息量，证明在任意非恒定奖励函数下，最优策略提供的信息恰好为 $ n \log m $ 比特，其中 $ n $ 为状态数，$ m $ 为动作数。该结果适用于多种目标，包括有限时域、无限时域折扣和时间平均奖励最大化，揭示了实现最优行为所需“隐式世界模型”的信息下界。


<details>
  <summary>Details</summary>
Motivation: 探究人工智能中成功行为是否需要内部世界表征，旨在从信息论角度界定最优策略所蕴含的环境信息量，从而明确实现最优决策所需的最小认知负担。

Method: 基于受控马尔可夫过程（CMP），在均匀先验假设下，分析最优策略与环境之间的互信息，利用信息论工具严格推导出信息量的精确表达式。

Result: 观测一个针对任意非恒定奖励函数的确定性最优策略，其与环境间的互信息恰好为 $ n \log m $ 比特，该结论在多种目标设定下均成立。

Conclusion: 该研究建立了实现最优行为所必需的隐式世界模型的信息下界，表明即使不显式建模，智能体也必须隐含地编码至少 $ n \log m $ 比特的环境信息。

Abstract: An important question in the field of AI is the extent to which successful behaviour requires an internal representation of the world. In this work, we quantify the amount of information an optimal policy provides about the underlying environment. We consider a Controlled Markov Process (CMP) with $n$ states and $m$ actions, assuming a uniform prior over the space of possible transition dynamics. We prove that observing a deterministic policy that is optimal for any non-constant reward function then conveys exactly $n \log m$ bits of information about the environment. Specifically, we show that the mutual information between the environment and the optimal policy is $n \log m$ bits. This bound holds across a broad class of objectives, including finite-horizon, infinite-horizon discounted, and time-averaged reward maximization. These findings provide a precise information-theoretic lower bound on the "implicit world model'' necessary for optimality.

</details>


### [162] [Consistency of Large Reasoning Models Under Multi-Turn Attacks](https://arxiv.org/abs/2602.13093)
*Yubo Li,Ramayya Krishnan,Rema Padman*

Main category: cs.AI

TL;DR: 该研究评估了九个前沿推理模型在对抗攻击下的表现，发现推理能力虽带来一定鲁棒性但不完全；所有模型均有独特漏洞，误导性建议普遍有效，社会压力则因模型而异。轨迹分析揭示五种失效模式，前两种占失败的50%。此外，针对标准大模型有效的信心感知生成（CARG）对推理模型无效，因其推理过程导致过度自信，随机信心嵌入反而更优。结论是推理能力并不自动带来对抗鲁棒性，信心防御机制需为推理模型重新设计。


<details>
  <summary>Details</summary>
Motivation: 探索大型推理模型在多轮对抗压力下的鲁棒性，揭示其实际抗攻击能力与潜在弱点，以推动更安全的推理系统设计。

Method: 对九个前沿推理模型进行对抗攻击实验，结合轨迹分析识别失效模式，并测试信心感知响应生成（CARG）在推理模型上的有效性，对比随机信心嵌入与目标提取策略。

Result: 推理模型显著优于指令微调基线，但普遍存在漏洞；误导建议普遍有效，社会压力影响模型特定；五种失效模式被识别，前两种占失败的50%；CARG在推理模型上失效，随机信心嵌入表现更优。

Conclusion: 推理能力并未自动赋予对抗鲁棒性，现有基于信心的防御机制需针对推理模型进行根本性重构。

Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confers meaningful but incomplete robustness: most reasoning models studied significantly outperform instruction-tuned baselines, yet all exhibit distinct vulnerability profiles, with misleading suggestions universally effective and social pressure showing model-specific efficacy. Through trajectory analysis, we identify five failure modes (Self-Doubt, Social Conformity, Suggestion Hijacking, Emotional Susceptibility, and Reasoning Fatigue) with the first two accounting for 50% of failures. We further demonstrate that Confidence-Aware Response Generation (CARG), effective for standard LLMs, fails for reasoning models due to overconfidence induced by extended reasoning traces; counterintuitively, random confidence embedding outperforms targeted extraction. Our results highlight that reasoning capabilities do not automatically confer adversarial robustness and that confidence-based defenses require fundamental redesign for reasoning models.

</details>


### [163] [Constrained Assumption-Based Argumentation Frameworks](https://arxiv.org/abs/2602.13135)
*Emanuele De Angelis,Fabio Fioravanti,Maria Chiara Meo,Alberto Pettorossi,Maurizio Proietti,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出了约束型假设论证（CABA），扩展了传统假设论证（ABA）的表达能力，允许使用带约束变量的非基（非原子）论据和攻击，支持在可能无限域上进行推理。新语义保守地推广了标准ABA语义。


<details>
  <summary>Details</summary>
Motivation: 传统ABA受限于仅能处理无变量的命题原子，限制了其在复杂知识表示中的应用。为提升表达能力，需放宽这一限制，引入可包含约束变量的非基论据与攻击。

Method: 提出约束型假设论证（CABA）框架，定义基于不同非基攻击概念的非基语义，并通过形式化方法建立其与标准ABA语义之间的保守泛化关系。

Result: 所提出的CABA框架具备更强的表达能力，能够处理含约束变量的非基论据和攻击；其语义结构在形式上保守地推广了经典ABA语义，保持原有性质的同时扩展适用范围。

Conclusion: CABA成功扩展了假设论证的表达力，使得在非基、含约束变量的情境下仍能进行可靠的逻辑推理，且其语义与传统ABA一致，具有良好的理论兼容性。

Abstract: Assumption-based Argumentation (ABA) is a well-established form of structured argumentation. ABA frameworks with an underlying atomic language are widely studied, but their applicability is limited by a representational restriction to ground (variable-free) arguments and attacks built from propositional atoms. In this paper, we lift this restriction and propose a novel notion of constrained ABA (CABA), whose components, as well as arguments built from them, may include constrained variables, ranging over possibly infinite domains. We define non-ground semantics for CABA, in terms of various notions of non-ground attacks. We show that the new semantics conservatively generalise standard ABA semantics.

</details>


### [164] [Optimal Take-off under Fuzzy Clearances](https://arxiv.org/abs/2602.13166)
*Hugo Henry,Arthur Tsai,Kelly Cohen*

Main category: cs.AI

TL;DR: 本文提出一种混合障碍物避让架构，结合最优控制与模糊规则系统（FRBS），实现无人飞行器的自适应约束处理。通过三阶段Takagi-Sugeno-Kang模糊层调节约束半径、紧急程度和激活决策，基于FAA和EASA的航空规章与适航指南生成模糊推导的间隔标准，并将其作为软约束融入最优控制问题，使用FALCON工具箱与IPOPT求解。该框架可减少不必要的重新计算，同时保持符合航空程序。概念验证采用简化飞机模型，在单线程MATLAB环境中每迭代耗时2.3秒，表明具备近实时应用潜力。但实验发现最新版FALCON与IPOPT存在软件不兼容问题，导致拉格朗日惩罚项恒为零，影响约束执行，此现象具一致性，属求解器回归问题而非建模错误。未来工作包括回退旧版本验证、用进化方法优化模糊隶属函数，并扩展至高保真模型与随机障碍环境。


<details>
  <summary>Details</summary>
Motivation: 解决经典最优控制在不确定性下的局限性，满足安全关键航空系统对可解释决策的需求。

Method: 设计三阶段Takagi-Sugeno-Kang模糊层，动态调节约束半径、紧急程度与激活决策；将模糊推导的间隙作为软约束输入最优控制问题，使用FALCON与IPOPT求解。

Result: 概念验证显示每迭代计算时间2.3秒，具备近实时可行性；但发现最新版FALCON与IPOPT存在严重软件兼容性问题，导致约束无法正确强制执行。

Conclusion: 该混合架构在理论上可行且具有实时潜力，但当前求解器缺陷需修复；未来将通过回退版本验证、优化模糊参数及拓展至复杂场景以提升实用性。

Abstract: This paper presents a hybrid obstacle avoidance architecture that integrates Optimal Control under clearance with a Fuzzy Rule Based System (FRBS) to enable adaptive constraint handling for unmanned aircraft. Motivated by the limitations of classical optimal control under uncertainty and the need for interpretable decision making in safety critical aviation systems, we design a three stage Takagi Sugeno Kang fuzzy layer that modulates constraint radii, urgency levels, and activation decisions based on regulatory separation minima and airworthiness guidelines from FAA and EASA. These fuzzy-derived clearances are then incorporated as soft constraints into an optimal control problem solved using the FALCON toolbox and IPOPT. The framework aims to reduce unnecessary recomputations by selectively activating obstacle avoidance updates while maintaining compliance with aviation procedures. A proof of concept implementation using a simplified aircraft model demonstrates that the approach can generate optimal trajectories with computation times of 2,3 seconds per iteration in a single threaded MATLAB environment, suggesting feasibility for near real time applications. However, our experiments revealed a critical software incompatibility in the latest versions of FALCON and IPOPT, in which the Lagrangian penalty term remained identically zero, preventing proper constraint enforcement. This behavior was consistent across scenarios and indicates a solver toolbox regression rather than a modeling flaw. Future work includes validating this effect by reverting to earlier software versions, optimizing the fuzzy membership functions using evolutionary methods, and extending the system to higher fidelity aircraft models and stochastic obstacle environments.

</details>
