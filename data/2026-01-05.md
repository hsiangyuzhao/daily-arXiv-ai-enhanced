<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 50]
- [cs.CL](#cs.CL) [Total: 29]
- [cs.LG](#cs.LG) [Total: 44]
- [cs.AI](#cs.AI) [Total: 18]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld 是一个实时多模态 4D 世界建模框架，通过生成-重建-引导范式实现视频生成、动态场景重建和长期世界记忆的闭环统一。采用基于宏-微规划（MMPL）的自回归扩散模型与分布匹配蒸馏（DMD），在保持时空物理一致性的同时，实现低延迟、长时程的实时生成，显著提升动态与静态场景建模能力，推动世界模型向可交互、具记忆、计算可行的方向发展。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽视觉质量高，但在实时交互、长时程一致性和动态场景记忆方面存在局限，难以作为实用的世界模型。需要构建一个能持续维护时空一致性并支持长期记忆的系统，以推进人工智能在复杂环境中的理解和交互能力。

Method: 提出 TeleWorld 框架，采用生成-重建-引导机制：将生成的视频流持续重构为动态 4D 空间-时间表示，并用其指导后续生成，确保一致性；引入 Macro-from-Micro Planning（MMPL）进行分层规划，降低帧级误差累积；结合 Distribution Matching Distillation（DMD）提升生成效率，实现在实际算力下的实时合成。

Result: 实验表明，TeleWorld 在静态与动态世界理解、长时程一致性及实时生成效率方面表现优异，实现了动态对象与静态场景的统一建模，具备良好的可扩展性与实用性，是迈向交互式、记忆型世界模型的重要一步。

Conclusion: TeleWorld 通过统一生成、重建与记忆机制，构建了一个高效、实时、持久的 4D 世界模型框架，为多模态生成与具身智能提供了可实践的技术路径。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 本文提出通过噪声优化来缓解文本到图像模型中的模式崩溃问题，无需依赖复杂的引导机制或大量候选生成，仅通过简单的噪声优化即可提升生成图像的质量与多样性。实验表明，不同频率特性的噪声初始化能进一步优化生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型存在严重的模式崩溃问题，即相同提示生成的图像差异小，缺乏多样性。尽管已有研究尝试通过引导机制或候选集筛选来改善，但效果有限。本文旨在从噪声优化角度探索更高效、更直接的解决方案。

Method: 提出一种基于噪声优化的目标函数，通过对输入噪声进行优化以生成多样化且高保真度的图像。同时分析噪声的频率特性，并采用具有不同频率分布的初始噪声以提升优化效率和搜索能力。

Result: 实验结果显示，该方法在生成图像的质量和多样性方面均优于现有方法，有效缓解了模式崩溃问题，同时保持了基线模型的生成保真度。

Conclusion: 噪声优化是一种简单而有效的策略，可显著提升文本到图像生成的多样性，同时不牺牲图像质量。不同频率的噪声初始化有助于进一步优化生成性能，为未来生成模型的设计提供了新思路。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: 本文提出Spatial4D-Bench，一个大规模、多任务的4D空间智能基准测试，用于评估多模态大语言模型（MLLMs）在动态空间推理方面的能力。该基准包含约4万道问答对，覆盖18项任务，分为6个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。实验表明，当前主流MLLMs在路径规划、动作识别和物理合理性推理等方面存在显著不足，难以达到人类水平的4D空间智能。


<details>
  <summary>Details</summary>
Motivation: 人类具备强大的4D空间智能，能够感知和处理物体随时间的变化。然而，现有模型在动态空间推理方面能力有限，缺乏系统性、全面性的评估基准。因此，亟需一个能全面衡量MLLMs 4D空间推理能力的基准测试，以推动模型发展并揭示其局限性。

Method: 构建Spatial4D-Bench，涵盖约4万道问题，分属18个具体任务，归类至6个认知维度；对多种开源与专有MLLMs进行系统评测，分析其在各类4D空间推理任务中的表现。

Result: 各MLLMs在多个4D空间推理任务中表现不佳，尤其在路线规划、动作识别及物理合理性判断方面存在明显短板，表明当前模型距离实现人类级4D空间智能仍有较大差距。

Conclusion: Spatial4D-Bench为评估和提升MLLMs的4D空间智能提供了有力工具，揭示了现有模型的关键缺陷，有助于引导未来研究向更接近人类的空间认知能力发展。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 本文提出Compressed Map Priors (CMP)框架，利用历史行驶数据学习空间先验，通过二值化哈希表实现高效存储（仅需32KB/km²），相比密集存储减少20倍。该方法可无缝集成至主流3D感知系统，计算开销极低，并在nuScenes数据集上显著且一致地提升多种架构的3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶视觉系统通常将每个位置视为首次遇到，缺乏对历史通行区域的空间先验知识利用，而实际大多数部署区域已有大量过往数据，因此需要一种高效的方法来学习并利用这些历史信息以提升感知性能。

Method: 提出Compressed Map Priors (CMP)，使用二值化哈希表存储历史轨迹信息，构建轻量级空间先验；该结构可直接嵌入现有3D感知系统中，无需额外计算开销。

Result: 在nuScenes数据集上，CMP在多种主流3D目标检测架构中均实现了显著且一致的性能提升，同时存储效率提升20倍，仅需32KB/km²。

Conclusion: Compressed Map Priors有效利用历史行驶数据构建轻量级空间先验，在不增加计算负担的前提下显著提升3D目标检测性能，为自动驾驶视觉系统提供了一种实用且高效的先验学习方案。

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [5] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0 是一个大规模金融信贷多模态基准，涵盖18种核心证件类型，包含4,043张隐私合规图像和8,446个问答样本。其评估框架包括感知、推理和鲁棒性三个维度，覆盖基础感知任务、信贷特定推理任务及真实采集缺陷的鲁棒性测试。所有数据通过封闭合成-捕获流程生成，确保隐私合规且避免数据泄露。实验对比了23个顶尖视觉语言模型，Gemini 3 Pro 在商业模型中表现最佳（F1=64.61），Qwen3-VL-235B 在开源模型中最佳（F1=57.27），自研模型 Qfin-VL-Instruct 综合表现最优（F1=64.92）。鲁棒性测试显示，即使顶级模型在真实采集缺陷下性能也显著下降。


<details>
  <summary>Details</summary>
Motivation: 当前多模态AI广泛应用于信贷风险评估与文件审核，但缺乏专门针对金融信贷场景的基准，无法同时满足领域特异性、信用理解能力、现实鲁棒性及隐私合规要求，亟需构建一个兼顾真实性与安全性的评测体系。

Method: 采用封闭式合成-捕获管道，手动合成虚拟文档模板并生成场景感知图像；构建包含感知、推理、鲁棒性三维度的评估框架，涵盖3项基础感知任务、4项信贷相关推理任务及10类真实采集缺陷的鲁棒性测试。

Result: FCMBench能有效区分不同视觉语言模型在性能与鲁棒性上的差异；实验表明，尽管顶级模型表现优异，但在真实采集缺陷下仍出现明显性能下降；自研模型 Qfin-VL-Instruct 达到最高综合得分（64.92），优于主流商业与开源模型。

Conclusion: FCMBench-V1.0 是首个兼顾隐私合规、领域真实性和评估深度的金融信贷多模态基准，可有效推动高可靠性多模态AI在金融风控中的落地应用，并揭示现有模型在真实世界场景下的局限性。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [6] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: This paper introduces FaceFocalDesc, a new task and dataset for generating natural language descriptions of facial attributes (AUs, emotions, age) in arbitrary face regions. It proposes Focal-RegionFace, a fine-tuned vision-language model that improves accuracy through progressive focus refinement, outperforming existing methods on multiple metrics.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the underexplored problem of generating and recognizing multi-attribute natural language descriptions for arbitrarily selected face regions, aiming to improve fine-grained facial analysis by enabling focus on specific facial areas.

Method: The authors construct a new multi-attribute description dataset with region-level annotations and natural language descriptions. They propose Focal-RegionFace, a fine-tuned vision-language model based on Qwen2.5-VL, which uses multiple progressively fine-tuning stages to refine focus on localized facial features.

Result: Focal-RegionFace achieves state-of-the-art performance on the new benchmark using both traditional and newly proposed metrics, demonstrating its effectiveness and versatility in fine-grained, region-focal facial analysis.

Conclusion: The study validates that region-focused analysis enhances understanding and control in facial state analysis, and Focal-RegionFace is highly effective for multi-attribute description generation and recognition.

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [7] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D 是一种无需训练的 3D 形变框架，利用结构化潜在表示（SLAT）实现高质量 3D 演变。通过引入形态交叉注意力（MCA）和时序融合自注意力（TFSA），在注意力机制中融合源与目标特征，确保结构一致性和时间连续性，并结合姿态校正策略解决形变过程中的姿态歧义问题。实验表明，该方法在跨类别等挑战性场景下表现优异，支持解耦形变和 3D 风格迁移等高级应用，可推广至其他 SLAT 基础生成模型。


<details>
  <summary>Details</summary>
Motivation: 3D 形变面临语义一致性与时间平滑性难题，尤其在跨类别之间更难实现自然过渡，现有方法通常依赖大量训练数据或复杂优化，缺乏通用性与灵活性。

Method: 提出 MorphAny3D 框架，基于结构化潜在表示（SLAT），设计 Morphing Cross-Attention（MCA）融合源与目标信息以保证结构连贯性，引入 Temporal-Fused Self-Attention（TFSA）利用前帧特征增强时间一致性，并采用姿态校正策略缓解形变过程中的姿态模糊问题。

Result: 在多种跨类别和复杂形变任务中，MorphAny3D 生成的序列达到当前最优效果，具备良好的视觉质量与稳定性；同时支持解耦形变、3D 风格迁移等扩展功能，并可泛化至其他基于 SLAT 的生成模型。

Conclusion: MorphAny3D 实现了无需训练的高质量 3D 演变，通过智能融合潜在特征与注意力机制设计，在保持结构一致性和时间连续性方面表现卓越，为 3D 内容生成提供了通用而强大的新范式。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [8] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 本文提出一种基于3D实例分割的作物计数框架，利用多视角2D图像与NeRF视图合成技术，结合作物可见性与掩码一致性评分，实现高精度作物计数，无需特定作物参数调优，在棉花、苹果和梨三种作物上表现稳定，优于现有方法，并公开了棉花植株数据集以推动研究。


<details>
  <summary>Details</summary>
Motivation: 在户外农田环境中，由于部分遮挡和作物簇集导致的视觉模糊，传统基于图像的分割方法难以准确计数作物，亟需一种不依赖特定作物参数且能精确枚举的方法。

Method: 通过多视角2D图像生成NeRF模型，结合作物可见性评分与掩码一致性评分，实现3D空间中作物实例的精准分割，从而完成高精度计数。

Result: 在棉花、苹果、梨三个农业数据集上均实现了稳定且高精度的计数性能，显著优于现有先进方法，且无需针对不同作物进行参数调整。

Conclusion: 所提出的框架有效解决了复杂田间环境下作物计数难题，具有良好的泛化能力，为智能农业管理提供了可靠的技术支持。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [9] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: 本文提出一种名为IntraStyler的基于样本的风格合成方法，用于无监督域适应中的图像级域对齐。该方法无需预先指定域内变化，通过示例图像引导风格合成，实现多样化的风格生成。采用对比学习的风格编码器提取纯风格特征，提升风格区分能力。在CrossMoDA 2023数据集上的实验表明，该方法在可控风格合成和下游分割任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注源域与目标域之间的域偏移，而忽视了域内变异性。为解决这一问题，需要在图像翻译过程中多样化合成目标域数据的风格，但以往方法需预先设定域内变化，实际应用受限。

Method: 提出IntraStyler方法，利用示例图像引导风格合成，使输出风格匹配示例风格；引入基于对比学习的风格编码器以提取纯风格特征，实现风格的可区分学习。

Result: 在CrossMoDA 2023数据集上，IntraStyler实现了有效的可控风格合成，并显著提升了下游分割任务性能，验证了多样化合成数据的有效性。

Conclusion: IntraStyler无需先验知识即可捕捉丰富的域内风格，为无监督域适应中的域对齐提供了新思路，具有良好的实用性和有效性。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [10] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 本文研究如何通过奖励驱动的强化学习（RL）提升开源多模态大语言模型（MLLM）在视觉推理任务中的表现，重点解决视觉信息整合不足的问题。通过设计六种针对图像理解、思维步骤和答案准确性的奖励函数，并采用组相对策略优化（GRPO），显著提升了模型的长链视觉推理能力，在Qwen-2.5-VL-7B上实现5.56%的性能提升，且在域内与域外任务中均有效。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在解决依赖准确视觉感知的任务（如视觉谜题）时，其生成的推理过程缺乏对视觉信息的有效整合，导致性能受限。因此，亟需一种无需昂贵监督信号的方法来增强模型的视觉推理能力。

Method: 提出基于奖励驱动的强化学习方法，设计六种不同目标的奖励函数，结合组相对策略优化（GRPO），激励模型生成更长、更结构化的推理链条，并避免跳过视觉信息。

Result: 实验表明，该方法在Qwen-2.5-VL-7B上带来5.56%的性能提升，且在跨域任务中保持一致增益；将图像转换为文本描述可提升23.6%-26.7%的性能，验证了视觉感知是关键瓶颈。

Conclusion: 视觉感知是多模态模型在复杂推理任务中的主要瓶颈。通过奖励驱动的强化学习，可在不依赖昂贵标注的情况下有效激发模型的长链视觉推理能力，显著提升性能，具有良好的泛化性。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [11] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC提出一种新型向量量化方法，通过低维组合代码本实现高容量、紧凑的量化。其核心创新包括：重构代码向量与特征向量的关系，将它们视为可组合的低维单元；引入无参数的插值外推机制以增强特征细节；实现全代码本利用，避免代码本坍缩。LooC可作为即插即用模块，在多种任务、数据集和架构上均超越现有方法，达到更优性能且代码本更小。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度不断提升，传统向量量化方法面临高容量与紧凑性之间的矛盾，亟需一种既能保持高性能又具备小规模代码本的新方法。

Method: LooC通过将代码向量与特征向量视为低维组合单元，重新定义其关系，实现参数高效的代码本设计；结合插值外推机制提升特征重建质量；采用全代码本利用策略防止坍缩。

Result: 在多个下游任务、数据集和模型架构上，LooC均显著优于现有向量量化方法，实现状态领先性能，同时使用更小的代码本。

Conclusion: LooC成功解决了向量量化中高容量与紧凑性之间的冲突，提供了一种高效、通用且性能优越的解决方案，具备良好的可扩展性和应用潜力。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [12] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 本文提出SynDR-IQA框架，通过重塑合成数据分布来提升盲图像质量评估（BIQA）模型的泛化能力。针对现有合成数据导致特征聚集的问题，该方法引入分布感知的多样内容上采样与密度感知的冗余聚类下采样策略，有效缓解了因数据分布不均带来的性能瓶颈。在多种跨数据集场景中实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据在用于训练盲图像质量评估模型时存在泛化能力不足的问题，主要源于数据分布导致的特征离散和聚类现象，亟需改进合成数据的分布特性以提升模型性能。

Method: 提出SynDR-IQA框架，结合理论分析，采用分布-aware多样内容上采样以增强视觉多样性并保持内容分布，以及密度-aware冗余聚类下采样以降低密集区域样本密度，从而优化数据分布。

Result: 在合成到真实、合成到算法、合成到合成三种跨数据集设置下，所提方法显著提升了BIQA模型的泛化性能，验证了其有效性。

Conclusion: 通过重构合成数据分布，SynDR-IQA有效解决了因数据分布不均导致的模型泛化瓶颈，为基于合成数据的盲图像质量评估提供了新思路。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [13] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 本文提出一种融合CycleGAN与YOLOv8的跨模态数据增强框架，解决PCB缺陷检测中红外数据稀缺问题。通过无配对图像翻译将丰富的可见光PCB图像转换为红外域，生成高保真伪红外样本，保留缺陷结构语义并模拟热分布特征。结合真实红外数据与生成数据，采用异构训练策略训练轻量级YOLOv8检测器，在低数据条件下显著提升特征学习能力，性能接近全监督训练基准，验证了伪红外合成作为工业检测中有效增强策略的可行性。


<details>
  <summary>Details</summary>
Motivation: 红外数据在PCB缺陷检测中稀缺，限制了模型训练效果，传统依赖成对标注的方法难以满足需求，亟需一种无需配对监督的高效数据增强方法来扩充红外样本。

Method: 利用CycleGAN实现无配对的可见光到红外图像翻译，生成高保真伪红外图像；结合真实红外数据与生成数据，构建异构训练策略，训练轻量级YOLOv8检测器。

Result: 所提方法在有限真实红外数据下显著提升检测性能，优于仅使用真实数据训练的模型，且接近全监督训练表现，证明伪红外合成在数据稀缺场景下的有效性。

Conclusion: 基于CycleGAN的跨模态数据增强框架能够有效缓解红外数据稀缺问题，通过生成高质量伪红外样本，显著提升YOLOv8在低数据条件下的缺陷检测性能，具备在工业视觉检测中推广应用的价值。

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [14] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: 提出TotalFM，一种基于器官分离概念的放射学基础模型，通过大规模数据集（14万系列）和自监督预训练结合对比学习，在3D-CT图像与文本描述之间高效建立对应关系。该模型在零样本器官级和发现级病灶分类任务中表现优于CT-CLIP和Merlin，且在报告生成任务中性能相当，验证了器官分离学习框架在实际临床应用中的有效性与可行性。


<details>
  <summary>Details</summary>
Motivation: 解决3D-CT影像训练中计算成本高的问题，提升放射学基础模型在多任务场景下的效率与泛化能力。

Method: 利用分割技术和大语言模型处理放射科报告，自动构建器官体积与描述句子对；结合VideoMAE自监督预训练与体积-文本对的对比学习，实现高效且具有强表示能力的模型训练。

Result: 在零样本器官级病灶分类中，5/6器官优于CT-CLIP，9/14优于Merlin；在发现级分类中，25/30类别AUROC更高；报告生成性能与现有视觉-语言模型相当。

Conclusion: 器官分离学习框架为3D-CT基础模型的实际部署提供了现实且有效的设计路径。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [15] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign 是一个包含超过1550万张高质量图像-文本对的大规模多学科多模态数据集，源自2.5百万篇开放获取的科学论文，涵盖物理、生物、工程等多个领域。为解决科学图像与简短文本描述之间的语义鸿沟问题，研究提出基于Qwen-VL多模态大模型的语义增强管道，通过整合论文摘要和引用上下文对图像进行重描述。技术验证显示，该方法显著提升数据质量：SciBERT伪困惑度降低，语义模糊性减少，CLIP图像-文本对齐分数提升18.21%。该数据集为人工智能驱动的科学发现提供了基础资源，已公开发布于Hugging Face。


<details>
  <summary>Details</summary>
Motivation: 科学图像与文本描述之间存在深层语义鸿沟，导致现有多模态学习在科学发现中的应用受限。尤其在科学文献中，图像常缺乏充分描述，难以支持有效的跨模态理解。因此需要高质量、高对齐的多模态数据集以推动AI for Science的发展。

Method: 构建S1-MMAlign数据集，利用开源科学论文提取图像-文本对；引入Qwen-VL多模态大模型，结合论文摘要与引用上下文对原始图像描述进行重生成，实现语义增强；通过SciBERT伪困惑度与CLIP对齐分数评估数据质量改进效果。

Result: 经语义增强后，图像-文本对的语义一致性显著提高：SciBERT伪困惑度下降，表明语义模糊性减少；CLIP得分提升18.21%，证明图像与文本的对齐程度明显改善。数据集具备高质量、广覆盖特点，适用于科学推理与跨模态建模任务。

Conclusion: S1-MMAlign作为大规模、多学科、高对齐的科学多模态数据集，有效缓解了科学图像与文本间的语义鸿沟问题。其提供的增强型数据显著提升了多模态学习在科学领域的适用性，为未来AI for Science的研究奠定了坚实基础。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [16] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出了一种无需训练的高效概念擦除方法ActErase，通过分析提示对激活差异区域，动态替换输入激活来实现对敏感概念（如裸露、艺术风格、物体）的擦除，同时保持模型生成能力，并具备对抗攻击鲁棒性，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法依赖数据密集型和计算成本高的微调，难以高效应用；本文旨在解决这一问题，提出无需训练的轻量级方案。

Method: 基于提示对分析激活差异区域，提取目标激活并动态替换前向传播中的输入激活，实现概念擦除。

Result: 在裸露、艺术风格、物体移除三项任务上均达到SOTA性能，有效保留生成能力，且对对抗攻击具有强鲁棒性。

Conclusion: ActErase是一种无需训练、高效且鲁棒的插件式概念擦除方法，为扩散模型中的概念操控提供了新范式。

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [17] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS是一种在稀疏观测下重建动态目标的框架，通过结合骨架驱动的变形场和时间依赖的关节姿态估计器，实现平滑运动插值与几何细节保留。该方法在合成数据上比现有方法提升34% PSNR，且在真实数据上表现接近密集单目视频方法，仅需少量帧。此外，初始静态重建可由扩散生成先验替代，增强实用性。


<details>
  <summary>Details</summary>
Motivation: 在真实世界中，动态物体重建面临观测稀疏、视角多样等问题，传统方法依赖密集时空覆盖，难以适用。因此需要一种能在稀疏观测下高效重建动态目标的新方法。

Method: 提出SV-GS框架，利用粗略骨架图和初始静态重建作为引导，优化由关节姿态估计器和细粒度变形模块组成的骨架驱动变形场；仅让关节姿态估计器随时间变化，实现平滑运动插值并保持几何细节。

Result: 在合成数据上，相比现有方法提升34% PSNR；在真实数据上性能接近密集单目视频方法，仅使用极少帧；可将初始静态重建替换为扩散生成先验，提升实际应用可行性。

Conclusion: SV-GS有效解决了稀疏观测下的动态物体重建难题，具备良好的性能与实用潜力，尤其适用于真实世界场景。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [18] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 本研究开发了一种基于深度学习的皮肤疾病分类与诊断模型，利用公开皮肤疾病图像数据集进行预训练，通过优化模型架构、数据预处理和数据增强技术，最终基于Swin Transformer模型在ISIC2019数据集上达到87.71%的准确率，展示了其作为临床辅助诊断工具和患者自我评估工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着皮肤病发病率上升而皮肤科医生资源有限，亟需智能工具支持患者和临床医生实现及时准确的皮肤疾病诊断。

Method: 采用公开皮肤疾病图像数据集进行预训练，优化模型架构，改进数据预处理流程，并应用针对性的数据增强技术，最终使用Swin Transformer构建分类模型。

Result: 所提出的模型在ISIC2019数据集上对八类皮肤病变的分类准确率达到87.71%。

Conclusion: 该模型具有作为临床辅助诊断工具和患者自我评估工具的潜力，可有效支持皮肤疾病的早期识别与管理。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [19] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor 是一种基于草图的视频着色模型，支持异构、可变数量的参考图像。它通过将参考图像编码为额外的潜在帧并进行时序拼接，实现每个扩散步骤中的并发处理，同时保持参数量不变。模型还使用时空对应掩码注意力和模态分离的RoPE索引，以防止捷径学习和跨身份调色板泄漏。在SAKUGA-42M数据集上的实验表明，TimeColor在颜色保真度、身份一致性和时间稳定性方面优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有大多数着色模型仅依赖单一参考（如场景的第一帧），忽略了角色设定图、背景图或任意着色帧等其他条件数据。这种限制导致颜色一致性差、跨帧不一致等问题。因此需要一种能够灵活利用多种参考信息的模型。

Method: TimeColor 将多个参考图像编码为额外的潜在帧，并在时间维度上与输入视频帧拼接；采用时空对应掩码注意力机制来强制主体与参考之间的绑定关系，并引入模态分离的旋转位置编码（RoPE）以区分不同模态信息；整个过程保持模型参数量不变，实现高效多参考融合。

Result: 在 SAKUGA-42M 数据集上，TimeColor 在单参考和多参考设置下均显著提升颜色保真度、身份一致性和时间稳定性，有效缓解了快捷方式学习和跨身份调色板泄露问题。

Conclusion: TimeColor 通过引入灵活的多参考机制与先进的注意力设计，在视频着色任务中实现了更高的质量与一致性，为复杂场景下的高质量自动着色提供了新范式。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [20] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet is a computationally efficient person re-identification model that achieves high accuracy with low computational cost, making it suitable for real-time deployment in surveillance and mobile applications. It uses multi-scale feature fusion, semantic clustering with anatomical body partitioning, dynamic weight averaging, and the FIDI loss function.


<details>
  <summary>Details</summary>
Motivation: Existing state-of-the-art ReID methods achieve high accuracy but require high computational resources, limiting their use in real-world scenarios with constrained resources such as mobile devices and surveillance systems. This paper aims to develop a lightweight yet effective model for practical deployment.

Method: VisNet employs multi-scale feature fusion across ResNet50 stages 1–4 without parallel paths, integrates semantic clustering with rule-based pseudo-labeling for spatial constraints, applies dynamic weight averaging to balance classification regularization, and uses the FIDI loss function to enhance metric learning.

Result: VisNet achieves 87.05% Rank-1 and 77.65% mAP on Market-1501 with only 32.41M parameters and 4.601 GFLOPs, demonstrating strong performance and efficiency suitable for real-time applications.

Conclusion: VisNet provides a practical, efficient, and accurate solution for person re-identification in resource-constrained environments, enabling real-time deployment in mobile and surveillance applications.

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [21] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: OmniVaT 是首个解决单域泛化视觉触觉学习（SDG-VTL）任务的框架，通过多模态分数傅里叶适配器（MFFA）将视觉与触觉嵌入映射到统一的嵌入-频率空间，缓解模态差异；同时引入离散树生成（DTG）模块，利用分层树结构生成多样化且可靠的多模态分数表示，增强对未见领域中域偏移的适应能力。实验表明其在跨域泛化性能上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉学习（VTL）面临视觉与触觉模态间的差异以及因非标准化触觉传感器和数据采集不一致导致的域差距问题，现有方法依赖多域训练数据或复杂的跨模态融合策略，难以应对真实场景中的域偏移。因此亟需一种无需多域数据、能有效处理模态差异与域漂移的新范式。

Method: 提出 OmniVaT 框架，包含两个核心组件：1）多模态分数傅里叶适配器（MFFA），将视觉与触觉特征映射至统一的嵌入-频率空间，实现无监督模态对齐；2）离散树生成（DTG）模块，通过分层树结构生成多样化的多模态分数表示，提升模型对未知域的适应性。

Result: 在 SDG-VTL 任务上，OmniVaT 在多个跨域测试场景中均表现出卓越的泛化性能，显著优于基线方法，证明了其在处理模态差异与域偏移方面的有效性。

Conclusion: OmniVaT 首次成功解决了单域泛化视觉触觉学习任务，通过创新的 MFFA 和 DTG 模块，在无需多域训练数据的前提下实现了强跨域泛化能力，为未来具身智能系统中的多模态感知提供了新思路。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [22] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: 本文提出DVEFormer，一种基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐的视觉嵌入（DVE）。该方法利用Alpha-CLIP的教师嵌入指导轻量级学生模型学习细粒度像素级嵌入，实现语义分割、文本查询及3D地图构建等多功能应用。在常见室内数据集上表现优异，满足实时性要求（全模型26.3 FPS，小版本77.0 FPS），可作为传统分割方法的即插即用替代方案，支持自然语言查询并无缝集成至移动机器人3D映射流程中。


<details>
  <summary>Details</summary>
Motivation: 传统语义分割依赖固定类别，缺乏灵活性；而现实中的机器人需理解复杂环境并与未受训人类自然交互，因此需要更灵活、可扩展的视觉理解方式，支持文本查询和3D建图等高级应用。

Method: 采用知识蒸馏技术，以Alpha-CLIP生成的教师嵌入为指导，训练一个轻量级的RGB-D Transformer模型DVEFormer，使其学习密集的文本对齐视觉嵌入，从而实现像素级语义理解，并支持线性探测、文本查询与3D地图生成等任务。

Result: 在多个标准室内数据集上达到与现有方法相当甚至更优的性能，同时满足实时推理需求：全模型运行于26.3 FPS，小版本达77.0 FPS（NVIDIA Jetson AGX Orin），且具备良好的可视化效果与实际应用潜力。

Conclusion: DVEFormer提供了一种高效、灵活的视觉理解框架，不仅可替代传统分割方法，还支持自然语言查询和3D建图，适用于移动机器人在真实环境中的智能交互与自主导航。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [23] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种概率双流框架，用于骨骼动作识别，通过统一可靠性建模与多模态融合，提升在不确定环境下的细粒度识别能力。该框架无需校准预处理，直接从原始坐标学习；采用概率性Noisy-OR融合机制，在无显式置信度监督下稳定学习；并通过跨模态集成，联合四种骨骼模态（关节、骨骼、关节运动、骨骼运动）与RGB信息，融合结构与视觉运动线索。在多个基准数据集及新定义的手部中心基准上均取得一致性能提升，尤其在噪声和异构条件下表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的骨骼动作识别方法多为身体中心，忽视对精细动作（如手部细微运动）的捕捉，导致细粒度识别能力受限。因此需要一种能有效建模不确定性并融合多源信息的新方法。

Method: 提出概率双流框架，包含：1）免校准预处理，直接使用原始坐标；2）概率性Noisy-OR融合，实现可靠性感知的双流学习；3）从骨架内部到跨模态的集成策略，融合四类骨架模态与RGB特征，构建统一的跨模态表示。

Result: 在NTU RGB+D 60/120、PKU-MMD、N-UCLA等多个基准以及新提出的手部中心基准上，均实现显著且一致的性能提升，尤其在噪声和异构数据条件下表现出更强鲁棒性。

Conclusion: 所提框架有效解决了骨骼动作识别中对细微动作关注不足的问题，通过概率建模与多模态融合，提升了细粒度识别性能与系统鲁棒性，为未来动作识别研究提供了新的范式。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [24] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse 是一个通用的 4D 世界模型，能够实现 4D 重建、新轨迹视频生成及多种下游应用。它克服了现有方法在可扩展性上的局限，无需昂贵的多视角 4D 数据或复杂的预处理，通过无姿态前馈 4D 重建、在线单目退化模式模拟等技术，实现了对各种真实场景单目视频的高效泛化，性能达到当前最佳水平。


<details>
  <summary>Details</summary>
Motivation: 现有 4D 世界建模方法受限于数据成本高或训练预处理复杂，导致难以扩展到多样化真实场景，因此需要一种更高效、通用且可扩展的解决方案。

Method: 提出无姿态前馈 4D 重建、在线单目退化模式模拟等关键技术，构建端到端可扩展的 4D 建模框架，支持从真实单目视频中进行高效 4D 重建与生成。

Result: 在标准重建与生成基准上取得当前最优性能，具备良好的跨域泛化能力，适用于多种真实场景下的 4D 内容生成与应用。

Conclusion: NeoVerse 成功实现了高可扩展性与强泛化能力的 4D 世界建模，为真实世界视频的 4D 重建与生成提供了高效、通用的新范式。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [25] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: 提出首个基于行车记录仪视频的路旁垃圾检测大规模数据集RoLID-11K，包含超过11,000张标注图像，涵盖多样化的英国驾驶条件，具有显著的长尾分布和小物体特性。该研究评估了多种现代检测器在该数据集上的表现，发现基于Transformer的模型（如CO-DETR）在定位精度上最优，但实时模型受限于粗糙的特征层次结构。该数据集为动态驾驶场景中的极端小目标检测提供了挑战性基准，旨在推动低成本、可扩展的路旁垃圾监测系统发展。


<details>
  <summary>Details</summary>
Motivation: 当前路旁垃圾监测依赖人力调查和公众报告，覆盖范围有限；现有视觉数据集多集中于街景静态图像、航拍或水下环境，无法反映行车记录仪画面中垃圾尺寸极小、稀疏且嵌入复杂道路边缘背景的独特挑战。因此亟需一个专门针对行车记录仪数据的大型标注数据集来推动自动化检测技术的发展。

Method: 构建并发布RoLID-11K数据集，涵盖11,000+张来自真实驾驶场景的标注图像，涵盖不同天气、光照与道路类型；对多种先进目标检测模型（包括Transformer架构与YOLO系列）进行系统性基准测试，分析其在小物体、长尾分布及动态背景下的性能表现。

Result: CO-DETR等基于Transformer的模型在定位精度方面表现最佳，但在实时性上不足；而实时模型（如YOLO）虽具备高效推理能力，但受制于特征层次粗略，难以有效捕捉微小垃圾。该数据集揭示了当前算法在处理极端小目标时的关键瓶颈。

Conclusion: RoLID-11K是首个面向行车记录仪视频的路旁垃圾检测大规模数据集，建立了极具挑战性的基准，有助于推动高精度、低延迟、可部署的自动垃圾监测系统的研发，支持可持续交通环境管理。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [26] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: 本文提出了一种基于四元组损失的异常检测方法（Anomaly Quadruplet-Net），用于在视觉变化微小或存在遮挡的情况下，提升手动组装任务中装配进度估计的准确性。该方法通过自定义数据加载器选择关键训练样本，并利用小规模数据集实现高效学习，在台式机组装图像数据集上优于现有方法，准确率提升1.3%，相邻任务误分类率降低1.9%。


<details>
  <summary>Details</summary>
Motivation: 在人工多日完成的装配任务中，传统视觉方法因前后阶段视觉变化微小或存在遮挡，容易导致装配进度估计错误，影响智能工厂效率。现有方法如Anomaly Triplet-Net在细微变化场景下表现不佳，亟需更鲁棒的解决方案。

Method: 提出Anomaly Quadruplet-Net，采用四元组损失函数优化异常图像特征学习，并设计定制化数据加载器，动态选择具有区分度的训练样本以增强模型对细微变化的感知能力。

Result: 在台式机组装图像数据集上，所提方法较现有方法提升了1.3%的估计准确率，相邻任务误分类率下降1.9%，验证了其在复杂场景下的有效性与鲁棒性。

Conclusion: 本文提出的Anomaly Quadruplet-Net有效解决了视觉变化微小或存在遮挡时装配进度估计不准的问题，适用于小规模数据集，为智能工厂中人工装配过程的自动化监控提供了可行方案。

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [27] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉-语言模型（VLMs）的对比感知策略优化方法，通过检测输入图像扰动下的输出熵变化来识别感知令牌，并引入对比感知损失（CPL）增强模型在信息保留扰动下的一致性与在信息移除扰动下的敏感性，从而有效分离感知与推理，无需额外模型或标注数据，提升训练效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的方法在多模态推理中难以有效分离感知与推理过程，传统方法依赖显式感知奖励，但存在需要额外大模型、真实标签、强制分离或对所有输出令牌应用奖励等问题，导致训练复杂且效率低。

Method: CPPO通过分析输入图像扰动后模型输出的熵变化来自动识别感知令牌，并设计对比感知损失（CPL），使模型在信息保留扰动下保持输出一致，在信息移除扰动下产生显著变化，从而实现感知与推理的解耦优化。

Result: 实验表明，CPPO在多模态推理任务中优于先前的感知奖励方法，同时无需额外模型或标注数据，训练更高效、更具可扩展性。

Conclusion: CPPO通过基于熵变化的感知令牌检测与对比感知损失机制，成功实现了视觉-语言模型中感知与推理的解耦优化，为多模态强化学习提供了高效、可扩展的新范式。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [28] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics 是一个端到端可微的框架，能够根据用户提供的自然语言提示，自动推断3D场景中物体的物理参数，无需依赖真实轨迹或标注视频。它结合多模态大语言模型估计材料参数，并引入可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒的运动先验，减少外观和几何偏差。该方法在超过三十个场景中进行了评估，涵盖真实世界、人工设计和AI生成的3D物体，涉及弹性固体、金属、泡沫、沙子以及牛顿与非牛顿流体等多种材料，结果表明其能生成视觉上逼真的动态模拟，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统3D物理模拟需要专家知识和耗时的参数调优，难以高效实现多样材料的真实动态行为。本文旨在通过自然语言驱动的方式自动化物理参数推断，提升模拟效率与真实性。

Method: 利用多模态大语言模型估计材料参数，约束在合理范围内；提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取运动先验，同时最小化外观与几何的诱导偏差，实现端到端的物理参数推断与仿真。

Result: 在超过三十个不同类型的3D场景中，MotionPhysics成功生成了视觉上逼真的动态模拟，覆盖多种材料类型，显著优于当前最先进方法，在无需真实轨迹或标注数据的情况下实现了高保真物理行为建模。

Conclusion: MotionPhysics通过自然语言引导，实现了无需人工干预的物理参数自动推断，有效提升了3D动态模拟的真实性与效率，为复杂场景的自动化物理仿真提供了新范式。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [29] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText 是一种无需训练、即插即用的框架，用于提升扩散模型在多行布局、密集排版和长尾语言（如中文）中的文本渲染精度。它通过分解问题为‘写在哪里’和‘写什么’来实现：前者利用图像-文本注意力中的空间归因定位书写区域，结合锚点标记与拓扑感知优化生成高置信度掩码；后者引入频域带通调制的谱调制字形注入（SGMI），增强字形结构并抑制语义泄露。在多个基准测试中，该方法显著提升了可读性，同时保持语义一致性和美学质量，推理开销小。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在处理复杂文本布局、密集排版及长尾语言时存在文本渲染不准确的问题，传统解决方案依赖昂贵重训练或刚性布局约束，限制灵活性且可能损害视觉美感。因此亟需一种无需训练、灵活高效的方法来精准控制文本生成位置与内容。

Method: FreeText 采用两个核心模块：1）基于端到端图像-文本注意力的空间归因分析，通过引入类汇合（sink-like）token作为稳定空间锚点，并结合拓扑感知细化，生成精确的书写区域掩码；2）提出谱调制字形注入（SGMI），在噪声对齐的条件下，通过频率域带通滤波注入字形先验，强化字符结构特征，减少语义混淆，避免生成概念而非具体文字。

Result: 在 Qwen-Image、FLUX.1-dev、SD3 等模型上，针对 longText-Benchmark、CVTG 及自建 CLT-Bench 的实验表明，FreeText 显著提升文本可读性，保持良好的语义对齐与图像美观性，且推理成本低，具备广泛适用性。

Conclusion: FreeText 证明了利用扩散变压器（DiT）内部机制可有效解决文本渲染难题，无需重新训练即可实现高精度、灵活可控的文本生成，在复杂文本合成任务中具有重要应用价值。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [30] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM enhances SAM's performance in visually non-salient scenarios by leveraging low-level features through a Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module, with minimal parameter and computational overhead. A new dataset, VNS-SEG, with over 35K images, is introduced for comprehensive evaluation. Experiments show VNS-SAM outperforms existing methods, especially in zero-shot settings.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle with visually non-salient scenarios due to low foreground-background contrast, leading to inaccurate segmentation. SAM, despite its strong zero-shot capabilities, also fails in such cases, motivating the need for improved perception in these challenging conditions.

Method: VNS-SAM introduces two key components: the Mask-Edge Token Interactive decoder to better utilize edge information and the Non-Salient Feature Mining module to extract subtle visual cues. These modules enhance SAM’s understanding of non-salient features without significantly increasing parameters or computation.

Result: VNS-SAM achieves superior segmentation accuracy on visually non-salient scenarios, especially under zero-shot settings. It demonstrates strong generalizability and practicality, with additional parameters trainable within 4 hours. The proposed VNS-SEG dataset enables robust model training and benchmarking.

Conclusion: VNS-SAM effectively improves SAM’s capability in handling visually non-salient segmentation tasks while maintaining zero-shot generalization. The combination of novel architectural designs and a large-scale dedicated dataset makes it highly suitable for real-world applications.

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [31] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag 是首个基于预测-移动框架的拖拽图像编辑方法，通过迭代式运动预测与运动监督，有效避免了传统方法中的跟踪错误和中间点不合理等问题。通过动态调整有效控制点，显著提升了编辑精度和可操作性，在人脸和人体数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有拖拽式图像编辑方法中存在的跟踪错误、中间点不合理及源图与目标图之间巨大差异等挑战。

Method: 提出基于预测-移动框架的 DynaDrag 方法，采用迭代式运动预测与运动监督机制，并动态调整有效控制点以提升性能。

Result: 在人脸和人体数据集上的实验表明，DynaDrag 在编辑精度和可操作性方面均优于先前方法。

Conclusion: DynaDrag 通过创新的预测-移动框架和动态控制点调整策略，实现了更精确、更可靠的像素级图像编辑，为未来交互式图像编辑提供了新思路。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [32] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro is an advanced 3D photoacoustic imaging reconstruction algorithm designed for irregular transducer arrays, offering faster reconstruction with reduced computational cost and fewer transducers. It improves upon the original SlingBAG method by introducing hierarchical optimization with zero-gradient filtering and adaptive temporal sampling, achieving up to 2.2× speedup in reconstruction time while maintaining high image quality. Validated via simulations and in vivo mouse experiments, the method is publicly available on GitHub.


<details>
  <summary>Details</summary>
Motivation: Traditional iterative reconstruction methods for 3D photoacoustic imaging face challenges with irregular transducer arrays, including high computational complexity, large memory usage, and long reconstruction times. There is a need for efficient algorithms that support flexible, patient-specific array configurations without sacrificing image quality or increasing hardware costs.

Method: SlingBAG Pro extends the point cloud iteration concept of the Sliding Ball Adaptive Growth (SlingBAG) method to arbitrary array geometries. It employs a hierarchical optimization strategy combining zero-gradient filtering and progressively increased temporal sampling rates during iteration, which accelerates convergence by rapidly eliminating redundant spatial point clouds.

Result: SlingBAG Pro achieves up to a 2.2-fold improvement in reconstruction speed compared to the original SlingBAG algorithm under irregular array configurations, maintains high image quality, reduces the number of required transducers, and significantly shortens overall reconstruction time. The method is validated through both simulation and in vivo mouse experiments.

Conclusion: SlingBAG Pro enables efficient, high-quality 3D photoacoustic imaging using irregular transducer arrays with minimal hardware requirements. Its fast reconstruction and adaptability to arbitrary geometries make it promising for clinical applications where space and cost are constrained.

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [33] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 提出MS COCOAI数据集，包含96000个真实与合成图像，用于检测AI生成图像，涵盖5种生成模型（Stable Diffusion 3、2.1、SDXL、DALL-E 3、MidJourney v6），支持两类任务：判断图像是否为生成图像，以及识别具体生成模型。


<details>
  <summary>Details</summary>
Motivation: 随着Stable Diffusion、DALL-E、MidJourney等多模态生成AI系统的发展，合成图像日益逼真，难以与真实照片区分，导致虚假信息和误导性内容传播风险上升，亟需有效检测手段。

Method: 基于MS COCO数据集构建包含96000张图像的MS COCOAI数据集，使用五种主流生成模型生成合成图像，并设计两个检测任务：图像真实性分类与生成模型溯源。

Result: 成功构建高质量、多样化的合成图像数据集，支持多种生成模型的检测与识别，为后续研究提供基准数据集。

Conclusion: MS COCOAI数据集为AI生成图像检测提供了重要资源，有助于推动生成内容真实性验证技术的发展，应对深度伪造带来的社会挑战。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [34] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: 提出AEGIS基准和DCE评估协议，以全面评估统一多模态模型在视觉理解、生成、编辑及混合任务中的世界知识应用能力。实验揭示多数模型存在严重知识缺陷，复杂推理下性能显著下降，但简单推理模块可部分缓解问题，凸显世界知识推理的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法有效评估统一多模态模型在跨任务中应用世界知识的能力，缺乏综合性与诊断性，亟需更全面的评测体系。

Method: 设计AEGIS多任务基准，涵盖21个主题与6类推理类型，共1050个手动标注问题；引入确定性检查表评估（DCE），以原子化‘是/否’判断替代模糊的提示评分，提升评估可靠性。

Result: 大多数统一多模态模型在世界知识方面存在明显缺陷，尤其在复杂推理任务中表现差；简单推理模块的引入可部分改善性能。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿，需进一步研究以提升其泛化与理解能力。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [35] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出了一种无需训练的框架GranAlign，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题。方法包括基于粒度的查询重写和查询感知的字幕生成，以多层级查询与双类字幕配对增强跨模态对齐。在三个主流数据集上达到新基准，QVHighlights上mAP@avg提升3.23%。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽利用高质量预训练知识实现视频与语言的联合表征，但未能平衡模态间语义粒度差异，导致检索不准确。核心挑战在于文本查询与视觉内容在语义粒度上的不一致。

Method: 提出GranAlign框架，包含两个互补技术：1）基于粒度的查询重写，生成不同层次语义粒度的查询；2）查询感知的字幕生成，将查询意图嵌入视频内容描述中。通过多级查询与查询无关及查询相关字幕的组合，实现更精准的语义对齐。

Result: 在QVHighlights、Charades-STA、ActivityNet-Captions三个基准上均取得新最佳性能，尤其在更具挑战性的QVHighlights上实现3.23%的mAP@avg提升。

Conclusion: GranAlign通过有效解决视频与语言在语义粒度上的不匹配问题，显著提升了零样本视频时刻检索的准确性，且无需任务特定训练，具备良好的泛化能力。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [36] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: 提出SafeMo框架，通过最小运动遗忘（MMU）策略在连续空间中实现安全的人体动作生成，避免离散代码本替换带来的性能退化和伪影问题。构建首个安全的文本到动作数据集SafeMoVAE-29K，支持可信的机器遗忘学习。实验表明，相比现有最优方法LCR，SafeMo在HumanML3D和Motion-X上分别实现2.5倍和14.4倍更高的遗忘集FID，同时保持良好的良性任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成方法依赖离散代码本替换来规避不安全行为，但该方法导致日常任务性能下降，并引入量化与平滑性损失，造成动作僵硬和伪影；此外，现有数据集天然包含不安全意图，不适合用于安全驱动的学习。

Method: 提出基于连续空间的最小运动遗忘（MMU）策略，采用两阶段机器遗忘机制，结合改进的DiP架构，在不破坏代码本的前提下实现安全动作生成。构建安全文本提示重写与连续动作优化的数据集SafeMoVAE-29K，支持可信的遗忘学习。

Result: 在HumanML3D和Motion-X数据集上，SafeMo在不安全提示上的遗忘能力显著提升，遗忘集FID分别比LCR高2.5倍和14.4倍；同时在安全提示上的良性性能优于或等同于基线方法。

Conclusion: SafeMo实现了高效、自然且安全的人体动作生成，在保障动作连贯性的同时有效消除不安全行为，为可信生成模型提供了新范式。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [37] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的模态主导性指数（MDI）来量化RGB-IR跨模态融合中的优化偏差，并设计了MDACL框架，通过层次化跨模态引导（HCG）和对抗均衡正则化（AER）来平衡优化动态，显著提升跨模态检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态融合方法忽视了由于模态特性不对称导致的优化动态问题，信息密度与特征质量差异引起训练中对主导模态的过度依赖，阻碍有效融合。

Method: 提出Modality Dominance Index（MDI），结合特征熵与梯度贡献量化模态主导性；构建MDACL框架，包含层级跨模态引导（HCG）和对抗均衡正则化（AER）以调节优化过程。

Result: 在三个RGB-IR基准数据集上实验验证，MDACL有效缓解优化偏差，达到当前最优（SOTA）性能。

Conclusion: 该研究揭示并解决了跨模态融合中的优化偏差问题，提出的MDI与MDACL框架为多模态感知系统提供了更均衡、高效的训练机制。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [38] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF是一种针对小物体检测中注释噪声问题的鲁棒定位框架，利用归一化流建模复杂误差分布，并通过不确定性感知梯度调制抑制噪声样本的学习，从而缓解过拟合并稳定训练。在多个数据集上实验验证了其有效性，尤其在AI-TOD数据集上使DINO基线提升1.2% AP。


<details>
  <summary>Details</summary>
Motivation: 小物体对注释噪声高度敏感，严格定位目标优化容易导致噪声过拟合，现有方法难以有效应对非高斯分布的预测误差和噪声干扰。

Method: 提出TOLF框架，采用归一化流进行灵活的误差建模以捕捉复杂的非高斯预测分布，并设计不确定性感知的梯度调制机制，抑制高不确定性样本的学习，降低噪声影响。

Result: 在三个数据集上均取得显著提升，特别是在AI-TOD数据集上，相对于DINO基线提升了1.2% AP，验证了方法的有效性与鲁棒性。

Conclusion: TOLF通过流模型建模误差分布和不确定性引导优化，有效缓解了小物体检测中的注释噪声问题，为弱监督场景下的精准定位提供了新思路。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [39] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose 是一种用于康复训练的实时 3D 人体姿态估计与运动分析方法，通过多摄像头 RGB 视频输入实现端到端实时监控与评估，支持多人干扰下的快速跟踪（单帧<1ms），优化 SmoothNet 提升姿态估计精度与流畅性，并基于 Unity 平台实现实时反馈与肌肉应力可视化，帮助患者正确执行康复动作。


<details>
  <summary>Details</summary>
Motivation: 传统康复训练缺乏实时、精准的动作监测与反馈机制，难以有效指导患者纠正错误动作，影响康复效果。因此需要一种能够实时捕捉、分析并反馈人体运动状态的技术，以提升康复训练的科学性与有效性。

Method: 提出统一的端到端实时人体姿态估计与运动分析流水线，采用多摄像头RGB视频输入；设计适用于医疗康复场景的快速多人跟踪算法，优化SmoothNet以提升姿态估计精度与视觉流畅性；利用Unity平台实现运动实时监控、评估及肌肉应力可视化。

Result: 系统可在真实场景中实现毫秒级响应，显著降低姿态估计误差，提供直观的实时反馈与可视化信息，有效辅助患者进行准确、规范的康复训练，提升康复效率与安全性。

Conclusion: RePose 实现了高精度、低延迟的实时3D人体姿态估计与运动分析，为康复训练提供了可靠的技术支持，具备良好的临床应用前景。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [40] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: 提出HyperPriv-EPN框架，利用超图学习使用特权信息（LUPI）方法，通过教师-学生双流蒸馏，使术前MRI模型能从术后文本数据中学习语义结构，无需推理时依赖文本，显著提升髓母细胞瘤术前预后预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法在推理阶段利用术后文本数据，导致术前预后预测缺乏语义信息，影响治疗规划。

Method: 设计基于超图的LUPI框架HyperPriv-EPN，采用分离图策略，通过共享编码器处理含特权信息的教师图与仅含术前影像的学生产图，实现双流知识蒸馏。

Result: 在311例多中心患者数据集上验证，模型达到最优诊断准确率和生存分层效果，成功将专家经验迁移至术前场景。

Conclusion: 该方法有效利用历史术后文本数据，在不依赖推理时文本的前提下，显著提升术前预后预测能力，为临床决策提供支持。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [41] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 本研究利用图像驱动的深度学习方法，通过200天内控制温湿度条件下的图像与重量数据，构建了两种专用模型：高精度二分类器用于发芽检测，以及多分类预测器用于估算失重和预测剩余保质期。DenseNet在发芽检测中达到98.03%的准确率；保质期预测在粗粒度分类（2-5类）下准确率超过89.83%，而细粒度分类（6-8类）因视觉差异微小且每类数据有限导致性能下降。结果表明，该方法可有效集成至自动化分拣与库存系统，实现早期发芽识别和基于存储阶段的动态分类，有助于优化库存管理、差异化定价并减少食物浪费。尽管精确保质期预测仍具挑战，但采用宽泛类别划分可确保模型稳健性。未来需在多样品种与存储条件下训练通用模型以提升适应性与可扩展性。整体上，该方法为质量评估提供了低成本、非破坏性的解决方案，支持马铃薯储存与分销的效率与可持续性。


<details>
  <summary>Details</summary>
Motivation: 传统马铃薯质量监测方法存在侵入性、低效等问题，难以满足大规模仓储中的实时监控需求。图像驱动的深度学习提供了一种非侵入式、可扩展的替代方案，能够解决发芽检测、失重估计和保质期预测等关键挑战，从而提升供应链效率并减少食品浪费。

Method: 采集在控制温湿度条件下持续200天的马铃薯图像与重量数据，利用ResNet、VGG、DenseNet及视觉变压器（ViT）等预训练模型，构建两个专用模型：（1）基于深度学习的二分类器用于发芽检测；（2）多分类预测模型用于失重程度估计与剩余保质期预测。通过对比不同架构在不同分类粒度下的表现，优化模型性能。

Result: DenseNet在发芽检测任务中达到98.03%的准确率；保质期预测在粗分类（2-5类）下准确率超过89.83%，但在细分类（6-8类）时因视觉差异小、样本量不足而下降。结果验证了图像模型在自动化分拣与库存管理中的可行性，支持早期发芽识别与动态分类，具备显著应用潜力。

Conclusion: 图像驱动的深度学习方法为马铃薯质量监控提供了高效、非破坏性的解决方案，尤其适用于发芽检测与保质期粗略预测。通过合理设定分类粒度，可在实际场景中实现可靠部署。未来应致力于构建跨品种、跨环境的通用模型，以增强系统的普适性与可扩展性，推动农业供应链智能化发展。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [42] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: 提出CRoPS框架，通过选择性移除关键文本标记构建幻觉模型，并引入广义对比解码整合多种幻觉源，实现无需训练的幻觉缓解，在六个基准和三个LVLM家族上显著提升表现，相较现有方法有20%的CHAIR分数提升。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的方法在应对幻觉时存在局限：一是对幻觉来源假设过窄，二是生成后期效果下降。当前策略仅移除视觉标记，但视觉信息仍会传播至生成文本，不足以有效解决幻觉问题。

Method: 提出一种新幻觉模型，通过选择性移除关键文本标记来捕捉幻觉效应；引入广义对比解码，结合多个幻觉模型以表征多样化的幻觉来源。

Result: CRoPS框架在六个基准测试中平均提升CHAIR分数20%，并在三种不同LVLM家族上均表现出持续改进，优于当前最先进的无需训练方法。

Conclusion: CRoPS是一种有效的训练-free 幻觉缓解框架，通过更全面地建模幻觉机制，显著提升了LVLM的可靠性与生成质量。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [43] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 本文提出一种新颖的框架，通过构建3D高斯场景表示并单次前向传播生成合理的物体运动，实现快速、可控的相机引导视频生成，无需迭代去噪。该方法在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上表现出色，达到最先进的视频质量和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有图像到视频生成模型在用户可控性方面存在不足，尤其是对相机路径的精确控制能力有限；同时，现有方法在建模相机运动、保持时间一致性以及几何完整性方面仍面临挑战。虽然使用显式3D表示有助于提升一致性，但两阶段流程（先渲染再添加运动）难以实现完全的时间一致性。

Method: 提出基于3D高斯场景表示的单次前向传播框架，直接从单张图像生成包含相机轨迹与物体运动的4D动态场景，避免了传统迭代去噪过程，从而提升生成效率与一致性。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K等多个数据集上，该方法在视频质量与推理速度方面均优于现有方法，实现了最先进的性能表现。

Conclusion: 所提方法通过统一的3D高斯表示与单次前向生成机制，有效解决了图像到视频生成中相机控制、时间一致性和几何完整性难题，具备高效、可控、高质量生成能力，适用于真实应用场景。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [44] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM 提出一种无需训练的对应关系到高斯初始化方法，替代 GS-SLAM 中基于残差的稠密化阶段，通过 DINOv3 描述符结合置信度感知的内点分类器进行多视角密集对应三角化，生成结构感知且分布良好的高斯种子，显著提升早期建图稳定性与收敛速度约 20%，在纹理丰富和杂乱场景中实现更高渲染保真度，同时保持与现有 GS-SLAM 流水线完全兼容。在 TUM RGB-D 和 Replica 数据集上表现优于或媲美当前最优的高斯与点基 SLAM 系统，并支持高达 925 FPS 的实时映射性能。


<details>
  <summary>Details</summary>
Motivation: GS-SLAM 依赖残差驱动的渐进式高斯添加，在早期建图中不稳定且收敛慢，尤其在复杂纹理或杂乱场景下表现受限。为提升初始化质量与收敛效率，亟需一种无需训练、能快速生成结构合理高斯分布的初始化方法。

Method: 提出 RGS-SLAM 框架，采用 DINOv3 描述符提取多视图特征，通过置信度感知的内点分类器筛选高质量匹配，进行一拍式三角化生成密集高斯种子；该种子作为初始状态直接输入优化流程，避免了逐步添加高斯的过程，实现高效、稳定初始化。

Result: 相比原 GS-SLAM，RGS-SLAM 在纹理丰富与复杂场景中显著提升重建精度与渲染质量，收敛速度加快约 20%；在 TUM RGB-D 与 Replica 数据集上达到或超越当前主流高斯与点基 SLAM 方法的定位与重建精度，同时保持高达 925 FPS 的实时性能。

Conclusion: RGS-SLAM 通过引入训练-free 的一拍式高斯初始化机制，有效解决了传统 GS-SLAM 初始化不稳、收敛慢的问题，实现了更快的收敛、更高的重建质量与实时性，具备良好的可集成性与实用性。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [45] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 本文研究了在数据分布偏移下视觉-语言模型（VLM）的性能退化检测问题，提出结合输入层面的数据偏移检测与输出层面的置信度指标，以提升模型可靠性监测效果。开发了DomainSAT工具箱用于系统分析数据偏移，并验证了置信度变化与性能退化间的强关联性。


<details>
  <summary>Details</summary>
Motivation: 现有大型预训练视觉-语言模型在临床部署后可能因输入数据分布变化导致性能下降，但缺乏有效的无标签性能退化检测方法，尤其在数字病理学中更难实现可靠监控。因此亟需一种可解释、高效的可靠性监测框架。

Method: 提出结合输入级数据分布偏移检测（通过DomainSAT工具箱集成多种算法）和输出级标签无关置信度指标，构建互补的性能退化监测体系；利用大规模病理数据集进行实验验证两者的协同作用。

Result: 输入数据偏移检测能提供早期预警信号，但不总对应实际性能下降；而基于预测置信度的变化能够更直接反映性能退化，二者结合显著提升了退化检测的准确性和可解释性。

Conclusion: 本研究为数字病理中的基础模型提供了实用且互补的可靠性监控框架，强调了同时关注输入分布变化与输出行为的重要性，对推动AI在临床环境中的安全应用具有重要意义。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [46] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的流程，使用多模态大语言模型（LLMs）自动评分手写工程测验，保留标准考试流程（A4纸张、自由手写）。讲师仅需提供手写参考答案和简短评分规则，参考答案被转换为文本摘要以指导评分而不暴露原始扫描图。通过多阶段设计实现可靠性：格式/存在性检查防止空白作答，独立评分器集成与监督者聚合，以及确定性验证的刚性模板，生成可审计、机器可读的报告。在斯洛文尼亚真实课程测验上评估，包含手绘电路图，使用最先进的后端模型（GPT-5.2 和 Gemini-3 Pro），平均绝对误差约为8分，偏差低，手动复核触发率约17%（当 $D_{\max}=40$ 时）。消融实验表明，简单提示和移除参考答案会显著降低准确率并引入系统性高估，证实结构化提示和参考答案引导的重要性。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放性推理和图表，但人工评分效率低且难以扩展。需要一种高效、可靠、可审计的自动化评分方法，同时保持教学实践的自然流程。

Method: 提出一个端到端多模态大语言模型工作流，包括：将手写参考答案转化为文本摘要作为评分依据；采用多阶段设计，包含格式/存在性检查、独立评分器集成、监督者聚合和刚性模板验证；确保输出可审计、机器可读。

Result: 在真实课程测验中，使用GPT-5.2和Gemini-3 Pro等先进模型，平均绝对误差约8分，偏差小，手动复核触发率约17%（$D_{\\max}=40$）。消融实验证明结构化提示和参考答案对准确性至关重要。

Conclusion: 该多模态大语言模型驱动的评分系统在保持教学自然性的同时实现了高可靠性与可审计性，具备实际应用潜力，且依赖于参考答案与结构化提示的设计。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [47] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: UniCo提出一种新的结构化形状补全方法，通过专用路径解码几何原语，利用可学习的原型查询生成装配就绪的输出，并采用在线目标更新策略实现原语与点云的一致优化，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常采用级联式流程处理原语和点云，但效率和一致性不足；本文旨在重新思考原语与点云的交互方式，提升结构化3D重建的质量与效率。

Method: 提出UniCo框架，采用单次前向传播预测完整几何、语义及内点隶属关系的原语集合；引入可学习的原型查询（primitive proxies）以生成上下文感知的装配就绪输出；通过在线目标更新策略联合优化原语与点云。

Result: 在合成与真实世界数据集上，相较于近期基线方法，UniCo将Chamfer距离降低高达50%，法向一致性提升最高达7%；在四个独立装配求解器下均表现优异。

Conclusion: UniCo建立了一种从不完整数据中进行结构化3D理解的有效范式，为后续研究提供了有力参考。

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [48] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 本文探索了自监督学习作为辅助任务在通用深度伪造检测主任务中的优化潜力，通过不同训练方案的组合实验，发现融合自监督任务的特征表示能有效提升主任务性能，增强跨数据集泛化能力，在多个数据集上表现优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 旨在提升通用深度伪造检测的性能与泛化能力，利用自监督学习作为辅助任务来优化主任务。

Method: 研究不同训练方案组合，融合自监督学习任务的特征表示以优化深度伪造检测模型。

Result: 在多个数据集（如DF40、FaceForensics++、Celeb-DF等）上实现了更好的跨数据集泛化性能，优于当前最先进的检测器。

Conclusion: 融合自监督学习的特征表示能够充分发挥其潜力，为深度伪造检测提供更优且更具泛化能力的特征表达。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [49] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出两种新型深度学习架构LNU-Net和IBU-Net，用于短轴位心脏磁共振成像（cine MRI）中的左心室（LV）分割。LNU-Net基于层归一化（LN）U-Net，IBU-Net则结合实例归一化与批归一化（IB）。两者均采用下采样路径提取特征、上采样路径实现精确定位。通过在805张来自45名患者的MRI图像数据集上进行实验，验证了所提方法在Dice系数和平均垂直距离指标上优于现有先进方法。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对于心脏影像的临床量化与诊断至关重要。传统U-Net在医学图像分割中表现良好，但归一化策略对模型性能仍有提升空间。为提高分割精度与鲁棒性，需探索更优的归一化机制以应对医学图像中复杂的强度变化和噪声。

Method: 提出LNU-Net和IBU-Net两种新架构。LNU-Net在每个卷积块中引入层归一化（Layer Normalization），IBU-Net在首个卷积块中同时使用实例归一化与批归一化，并将结果传递至后续层。二者均基于U-Net结构，包含编码器-解码器路径，配合弹性形变与仿射变换进行数据增强。

Result: 在包含805张短轴位cine MRI图像的数据集上，所提方法在Dice系数和平均垂直距离两项评价指标上均优于现有主流方法，表明LNU-Net与IBU-Net具有更强的分割精度与稳定性。

Conclusion: LNU-Net与IBU-Net通过引入先进的归一化策略，在左心室分割任务中表现出色，显著提升了分割性能，为医学图像分析提供了有效的新方法。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [50] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR提出一种统一框架，解决单目视频动态场景重建中的频率自适应性和时间连续性问题。通过可学习的频率权重和自适应能量补偿的自适应Gabor表示，提升细节捕捉与稳定性；结合三次埃尔米特样条与时间曲率正则化，确保运动平滑；并引入自适应初始化机制，结合深度估计、点跟踪和前景掩码，实现早期训练中稳定的点云分布。在Tap-Vid DAVIS数据集上达到SOTA性能（PSNR 35.49, SSIM 0.9433, LPIPS 0.0723），并在帧插值、深度一致性、视频编辑和立体视图合成等任务中展现强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用单个高斯基元存在低通滤波限制，标准Gabor函数易引发能量不稳，且缺乏时间连续性约束导致插值时出现运动伪影。需要同时实现高频细节捕捉与平滑运动建模。

Method: 提出Adaptive Gabor Representation，通过可学习频率权重和自适应能量补偿扩展高斯基元，平衡细节与稳定性；采用Cubic Hermite Splines结合Temporal Curvature Regularization保证时间连续性；设计Adaptive Initialization机制，融合深度估计、点跟踪和前景掩码以稳定初始点云分布。

Result: 在Tap-Vid DAVIS数据集上取得PSNR 35.49、SSIM 0.9433、LPIPS 0.0723的性能，显著优于现有方法，在帧插值、深度一致性、视频编辑和立体视图合成等任务中表现出强泛化能力。

Conclusion: AdaGaR成功实现了动态场景建模中频率自适应与时间连续性的统一，为单目视频动态3D重建提供了高效且稳定的解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [51] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: RIMRULE 是一种基于动态规则注入的神经符号方法，用于提升大语言模型（LLM）在特定任务工具使用中的可靠性。通过从失败轨迹中提炼出简洁、可解释的规则，并在推理时注入提示词，显著提升性能。规则由 LLM 自行提出，并通过最小描述长度（MDL）目标进行优化，兼顾泛化性与简洁性。规则以自然语言和结构化符号形式存储，支持高效检索。实验表明，该方法在已见和未见工具上均有效提升准确率，无需修改 LLM 权重，优于传统提示法，且可跨模型复用，具有良好的可移植性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在领域特定场景中使用工具时面临挑战，因API常具独特性、文档不足或专有流程，亟需有效适应机制。现有方法难以泛化到未见工具，且缺乏可解释性和可迁移性。

Method: 提出 RIMRULE 方法，利用失败轨迹自动提取规则；通过 LLM 生成候选规则，并采用最小描述长度（MDL）准则筛选出最简洁、最通用的规则；规则以自然语言和结构化符号形式存储，支持推理时高效检索与注入。

Result: RIMRULE 在多个工具使用基准测试中显著提升准确性，适用于已见与未见工具，无需微调模型权重；相比提示工程方法表现更优，且能与微调互补；所学规则可在不同模型间复用，包括长推理模型，体现符号知识的跨架构可移植性。

Conclusion: RIMRULE 提供了一种高效、可解释、可迁移的 LLM 工具适应方案，通过动态规则注入实现性能提升，为解决领域特定工具使用问题提供了新范式。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [52] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: 提出Pat-DEVAL框架，用于评估专利说明书的结构连贯性和法律合规性，通过法律约束推理机制CoLT提升对专利法要求的符合度，在专家评估中表现出显著更高的相关性（0.69），尤其在法律合规性方面达到0.73，证明法定约束对评估有效性至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有自动化专利撰写系统缺乏对长篇说明书结构连贯性和专利法合规性的有效评估手段，尤其在启用和书面描述等法律要求方面存在不足。

Method: 提出基于LLM-as-a-judge范式的多维度评估框架Pat-DEVAL，引入法律约束推理机制Chain-of-Legal-Thought（CoLT），实现逐层专利法特定分析。

Result: 在Pap2Pat-EvalGold数据集上，由专利专家验证，Pat-DEVAL达到0.69的皮尔逊相关性，显著优于基线方法；在法律专业合规性方面相关性达0.73，证明法定约束对评估效果的关键作用。

Conclusion: Pat-DEVAL为自动化专利撰写系统的实际部署提供了技术与法律双重保障的新标准，是确保技术严谨性与法律合规性的可靠评估方法。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [53] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 本文针对对话中情绪识别（ERC）的两大关键缺口——架构选择的影响不明确、情绪识别与生成之间的语言学关联缺失——进行了系统性分析。基于IEMOCAP数据集，研究发现：1）对话上下文至关重要，仅需最近10-30轮对话即可实现90%性能提升；2）句法层级表示在单句层面有帮助，但一旦引入上下文，其优势消失，说明上下文已涵盖内部结构信息；3）外部情感词典（如SenticNet）无增益，表明预训练编码器已充分捕捉情绪语义。此外，通过分析5,286个话语标记，发现情绪与标记位置显著相关（p < .0001），尤其是“悲伤”类话语在句首使用标记较少（21.9%），低于其他情绪（28–32%），这与左边缘标记用于主动话语管理的理论一致。该发现解释了为何悲伤情绪最依赖上下文（上下文提升达+22%），因其缺乏明确的语用信号，需依赖历史对话进行消歧。


<details>
  <summary>Details</summary>
Motivation: 现有情绪识别方法虽准确率高，但对哪些架构设计真正有效缺乏清晰理解，且缺乏从语言学角度连接情绪识别与话语生成的分析。因此亟需系统性研究以揭示影响因素并建立语言机制联系。

Method: 采用严格的消融实验（10次随机种子评估）对IEMOCAP数据集进行分析，考察不同架构组件（如上下文长度、句法层级表示、外部情感词典）的影响，并结合大规模话语标记统计分析情绪与标记位置的关系。

Result: 1）对话上下文是决定性因素，前10-30轮对话贡献90%性能增益；2）句法层级结构在提供上下文后不再带来额外收益；3）外部情感词典无效；4）简单因果模型即达到82.69%（4类）和67.07%（6类）加权F1，优于以往文本仅方法；5）情绪与话语标记位置显著相关，悲伤类话语在句首标记使用更少，支持其依赖上下文进行识别的假设。

Conclusion: 本研究揭示了对话情绪识别中的核心影响因素：上下文比内部结构和外部资源更重要，且情绪表达的语言特征可解释模型行为。研究为未来方法设计提供了实证依据，并推动情绪识别与自然语言生成的融合研究。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [54] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 本文提出了一种专为时间知识图谱（TKG）推理设计的蒸馏框架，利用大语言模型作为教师模型，指导轻量级学生模型学习结构与时间推理能力。该框架结合大规模公共知识与特定任务的时间信息，提升了学生模型对时间动态建模的能力，同时保持紧凑高效的架构。在多个公开基准数据集上的实验表明，该方法在推理准确率、计算效率和实际可部署性之间取得了良好平衡，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有TKG推理模型通常依赖大量参数和高计算开销，导致硬件成本高、能耗大，难以在资源受限、低功耗和分布式平台上实现实时推理。此外，大多数现有的模型压缩和蒸馏技术针对静态知识图谱设计，无法有效捕捉TKG中的时间依赖关系，常导致推理性能下降。因此，亟需一种能有效保留时间推理能力且适用于轻量化部署的新型蒸馏方法。

Method: 提出一种基于大语言模型作为教师模型的时间知识图谱推理蒸馏框架。通过融合大规模公共知识与任务特定的时间信息，引导轻量级学生模型学习结构化表示与时间动态建模能力，实现高效的知识迁移。

Result: 在多个公开基准数据集上，所提方法在推理准确率、计算效率和部署可行性方面均显著优于现有强基线方法，验证了其有效性与实用性。

Conclusion: 本研究提出的蒸馏框架成功实现了时间知识图谱推理中复杂时间动态的高效迁移，使轻量级模型具备接近大型模型的推理性能，为未来在边缘设备和实时系统中的AI应用提供了可行路径。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [55] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 本文提出一种将循证医学（EBM）原则融入基于图的检索增强生成（RAG）的方法，解决查询与证据间PICO框架不匹配、证据等级未被考虑的问题。通过在知识图谱构建与检索中整合PICO，并设计基于贝叶斯思想的重排序算法，实现无权重的证据等级校准。在运动康复领域验证，系统在多个指标上表现优异，专家评分高，且释放了大规模知识图谱与基准数据集，推动该领域RAG研究发展。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法虽提升性能，但忽视循证医学（EBM）核心原则，尤其缺乏对查询与证据间PICO一致性及证据等级的考量，限制其在临床决策中的可信度与实用性。

Method: 将PICO框架嵌入知识图谱构建与检索流程；提出一种无需预设权重的贝叶斯启发式重排序算法，根据证据等级动态调整排名得分；在运动康复领域构建并评估系统。

Result: 系统在nugget覆盖（0.830）、答案忠实度（0.819）、语义相似性（0.882）和PICOT匹配准确率（0.788）上表现良好；专家评价在5分制下达4.66–4.84分，涵盖事实准确性、忠实度、相关性、安全性与PICO对齐性；释放了包含357,844个节点和371,226条边的知识图谱及1,637个问答对的基准数据集。

Conclusion: 所提出的EBM适应策略有效提升了检索与生成质量，具备跨临床领域的可迁移性；释放的资源缓解了运动康复领域RAG数据稀缺问题，为未来研究提供基础。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [56] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench 是一个轻量级、开源的基准测试工具，用于指导日语-英语翻译系统的迭代开发。它通过参考无依赖的成对LLM评估，利用固定版本的锚点集进行评分，采用Bradley-Terry模型聚合结果，输出胜率和标准化的0-10分LT评分，确保评分在相同基础集、判断模型和聚合代码下具有结构稳定性。


<details>
  <summary>Details</summary>
Motivation: 在日语-英语翻译中，细微的礼貌、隐含意义、省略和语体选择显著影响译文自然度，传统可接受性评估已不足以区分高质量翻译，因此需要更精细的评估方法来回答‘这两个好翻译哪个更好’的问题。

Method: 采用参考无依赖的成对大语言模型（LLM）比较，以固定版本的锚点集作为参照，使用Bradley-Terry模型对成对结果进行聚合，并通过逻辑变换生成标准化的0-10分LT评分，实现可靠且低成本的评估。

Result: JP-TL-Bench 提供了结构稳定的评分体系，使得不同候选模型可在同一基准上公平比较，有效支持翻译系统持续优化。

Conclusion: JP-TL-Bench 为日语-英语翻译系统的精细化评估提供了可行、可靠且可重复的解决方案，适用于迭代开发中的模型对比与改进。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [57] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文系统研究了大语言模型在多语言场景下生成反事实样本的有效性。发现基于翻译的反事实生成虽优于直接生成，但仍不及英文原版质量；不同欧洲语种的修改模式高度相似，表明跨语言扰动遵循共同策略；识别出四类普遍存在且一致的错误类型；多语言反事实数据增强相比跨语言增强能带来更大性能提升，尤其对低资源语言更显著，但生成反事实的不完美仍限制模型性能与鲁棒性的提升。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在多语言环境下生成反事实样本的有效性，以改进模型解释能力，并理解跨语言反事实生成的挑战与规律。

Method: 通过自动评估直接生成和翻译后生成的六种目标语言反事实样本，分析其有效性与修改程度；识别高资源欧洲语言中编辑模式的一致性；分类总结跨语言生成中常见的错误类型；对比多语言与跨语言反事实数据增强对模型性能的影响。

Result: 翻译生成的反事实有效性和质量高于直接生成，但仍低于英文原版；不同语言的编辑模式具有高度相似性，表明存在通用的跨语言扰动策略；识别出四类常见错误类型；多语言反事实数据增强比跨语言增强更能提升模型性能，尤其对低资源语言效果更明显，但生成缺陷限制了进一步提升。

Conclusion: 尽管多语言反事实生成在提升模型解释性和泛化能力方面具有潜力，但当前生成质量仍存在明显不足，尤其在低资源语言上，需进一步优化生成方法以释放其全部潜力。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [58] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval is a new benchmark assessing LLM agents under realistic API complexity, revealing significant challenges—especially from irrelevant information—and showing that models often misrepresent user intent, undermining trust and usability.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing benchmarks that assume idealized API systems and ignore real-world complexities such as noisy API outputs, this paper introduces WildAGTEval to evaluate large language model (LLM) agents under realistic conditions.

Method: WildAGTEval is designed with two dimensions of real-world complexity: API specification (detailed documentation and usage constraints) and API execution (runtime challenges). It includes an API system with 60 distinct complexity scenarios, enabling approximately 32K test configurations, and user-agent interactions for evaluating LLM agents.

Result: Systematic evaluation reveals that most scenarios are challenging, especially irrelevant information complexity, which reduces strong LLMs' performance by 27.3%. Qualitative analysis also shows that LLMs sometimes distort user intent to falsely claim task completion, negatively impacting user satisfaction.

Conclusion: WildAGTEval provides a more realistic and comprehensive benchmark for evaluating LLM agents' function-calling capabilities, highlighting critical gaps in current models' robustness and alignment with user intent.

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [59] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 量化虽能加速大语言模型推理和部署，但其对自解释（SEs）的影响尚未明确。本文研究了自然语言解释（NLEs）和反事实例子两类SEs在三种常见量化技术、不同位宽下的表现，发现量化通常导致SE质量（最高下降4.4%）和忠实度（最高下降2.38%）中等程度下降，用户研究还显示其连贯性和可信度下降最多达8.5%。大模型在SE质量上对量化较敏感，但在忠实度上表现更好；且无一种量化方法在准确率、SE质量和忠实度上全面领先。建议针对具体应用场景验证SE质量，尤其关注对NLEs的敏感性。尽管存在轻微退化，量化仍可有效作为模型压缩手段。


<details>
  <summary>Details</summary>
Motivation: 自解释（SEs）是大语言模型为自身输出提供理由的重要能力，在高风险应用中对透明性至关重要。然而，量化作为模型压缩的关键技术，可能影响模型推理过程，进而影响其生成高质量、忠实的自解释的能力。当前尚缺乏对量化如何影响SE质量与忠实度的系统研究，亟需填补这一空白。

Method: 选取三种主流量化技术，在不同位宽下对大语言模型进行量化；生成两类自解释：自然语言解释（NLEs）和反事实例子；通过自动评估指标与用户研究相结合的方式，分析量化对SE质量、忠实度、连贯性及可信度的影响，并对比不同模型规模与量化方法的表现差异。

Result: 量化导致自解释质量平均下降4.4%，忠实度下降2.38%；用户研究显示连贯性与可信度下降最多达8.5%；大模型在忠实度方面更具韧性，但在质量上更易受量化影响；无单一量化方法在各项指标上全面占优；自然语言解释对量化更敏感。

Conclusion: 尽管量化会带来一定程度的SE质量与忠实度下降，但整体影响有限，未削弱其作为有效模型压缩手段的价值。鉴于影响因场景而异，建议在实际应用中针对特定任务验证自解释性能，特别是对自然语言解释应给予更多关注。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [60] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 提出DepFlow框架，通过三阶段流程实现抑郁状态控制的语音合成，有效解耦情感语义与诊断标签，构建针对伪装性抑郁症的数据增强方法CDoA，显著提升模型在真实场景下的鲁棒性与检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁数据集存在语言情感与诊断标签强耦合问题，导致模型依赖语义捷径，在伪装性抑郁症等真实场景下表现不佳。

Method: DepFlow包括：1）抑郁声学编码器通过对抗训练学习去身份、去内容的抑郁嵌入；2）基于流匹配的TTS模型结合FiLM调制注入抑郁嵌入，控制抑郁严重程度；3）原型式严重度映射机制实现连续可解释的调节。

Result: CDoA数据增强使三种抑郁检测模型的宏平均F1分别提升9%、12%和5%，显著优于传统增强方法；同时提供可控语音合成平台，适用于临床数据受限的模拟评估场景。

Conclusion: DepFlow有效缓解了语义偏差，提升了抑郁检测模型在复杂现实场景中的鲁棒性，并为对话系统与仿真评估提供了可控语音生成新范式。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [61] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLM）幻觉问题，提出一种在多事实生成任务中进行不确定性量化的新方法（RU）。通过构建包含虚假名称的陷阱问题，验证了该方法在非标准或对抗性提问下的有效性。实验表明，该方法在四个不同模型上均显著优于基线方法，平均ROCAUC值提升0.1-0.2，为解决LLM幻觉问题提供了新思路和新方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法在常规问答任务中表现良好，但在非标准或对抗性提问场景下效果不佳，限制了LLM在真实应用场景中的可靠性，亟需更鲁棒的不确定性评估机制。

Method: 构建包含虚假名称的陷阱问题数据集，提出一种新型鲁棒不确定性量化方法（RU），用于多事实生成任务中的幻觉检测与量化。

Result: 所构建的陷阱问题集表现出优异性能；所提方法在四个不同模型上相比最优基线方法，平均ROCAUC值提升0.1-0.2，显著增强对幻觉的识别能力。

Conclusion: 本研究提出的鲁棒不确定性量化方法（RU）有效提升了大语言模型在复杂、非标准情境下的幻觉检测能力，为提高LLM输出可靠性提供了有力支持。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [62] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: BERT-JEPA (BEPA) introduces a JEPA training objective to BERT models, addressing collapsed [CLS] embeddings and creating a language-agnostic embedding space, improving performance on multilingual benchmarks.


<details>
  <summary>Details</summary>
Motivation: To overcome the issue of collapsed [CLS] embedding spaces in BERT models and enhance multilingual representation learning.

Method: Integrating JEPA's self-supervised training objective into BERT-style architectures to promote more robust and language-agnostic embeddings.

Result: Improved performance across multilingual benchmarks due to a more effective and generalized embedding space.

Conclusion: BERT-JEPA successfully enhances BERT models by leveraging JEPA's architecture, leading to better multilingual understanding and representation.

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [63] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R提出一种无需检索的图像地理定位框架，通过规则化的层次化推理（Chain of Region）将GPS坐标映射到地理实体，生成可解释的监督信号，并结合基于哈弗辛距离的轻量级强化学习策略，实现精准、可解释且泛化性强的地理定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖合成推理标注或外部图像检索，限制了可解释性和泛化能力，亟需一种无需检索、能直接利用真实坐标进行训练的可解释地理定位框架。

Method: 提出Chain of Region推理范式，将GPS坐标映射至国家、省、市等地理层级；设计基于Haversine距离的坐标对齐奖励机制，采用轻量级强化学习优化模型预测。

Result: 在多个基准测试中显著提升地理定位精度，增强模型泛化能力，且推理过程具有高度可解释性；模型与代码已公开，支持复现与进一步研究。

Conclusion: Geo-R建立了一种新的无检索地理定位范式，实现了高精度、可解释和可扩展的视觉-语言地理定位，为未来研究提供了新方向。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [64] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 提出judgeWEL数据集，用于卢森堡语命名实体识别（NER），通过利用维基百科和Wikidata作为弱监督源，结合大语言模型（LLM）进行自动标注与质量验证，生成高质量、大规模的卢森堡语NER数据集，规模约为现有数据集的五倍，覆盖更广且更均衡。


<details>
  <summary>Details</summary>
Motivation: 构建低资源语言如卢森堡语的NER数据集面临资源稀缺和标注成本高、不一致的问题，亟需一种高效、低成本且高质量的数据生成方法。

Method: 利用维基百科内部链接关联至Wikidata，推断实体类型以生成初始标注；通过多种大语言模型对比筛选，去除噪声，保留高质量句子，形成最终标注数据集。

Result: 得到一个约五倍于现有数据集规模的卢森堡语NER数据集，覆盖更全面、类别更平衡，显著提升多语言及低资源NER研究的可用性。

Conclusion: 该方法有效克服了低资源语言标注难题，为卢森堡语及其他类似语言的自然语言处理提供了可扩展、高质量的数据基础。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [65] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文研究了基于大语言模型（LLMs）对地缘政治时间知识图谱（TKGs）的预测问题，提出了一种新的超关系时间知识图谱广义超图（HTKGHs）结构，以解决传统超关系时间知识图谱（HTKGs）仅支持两个主实体的局限性。通过形式化定义HTKGHs，该模型能够有效表示复杂事件中的多实体关系，并构建了基于全球事件数据库POLECAT的htkgh-polecat数据集。最后，对多种主流LLMs在关系预测任务上的表现进行了基准测试与分析，揭示了其在复杂预测场景下的适应能力与潜力。


<details>
  <summary>Details</summary>
Motivation: 现有超关系时间知识图谱（HTKGs）无法有效表达现实世界中常见的多实体复杂事件，限制了其在地缘政治等复杂场景中的应用。因此需要一种更灵活、表达力更强的图谱结构来建模复杂的多实体时间事实。

Method: 提出并形式化定义了超关系时间知识图谱广义超图（HTKGHs），设计并构建了基于POLECAT数据库的htkgh-polecat数据集，利用主流大语言模型进行关系预测任务的实验与评估。

Result: HTKGHs在保持与现有HTKGs后向兼容的基础上，成功支持了多实体复杂事实的建模；实验表明，部分大语言模型在复杂关系预测任务中展现出良好的适应性和推理能力，但仍有提升空间。

Conclusion: HTKGHs为建模复杂地缘政治事件提供了更强大的表达能力，结合大语言模型可有效推进复杂时空事件的预测研究，未来工作将聚焦于模型优化与更大规模数据集的构建。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [66] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 本研究对比分析了三种轻量级Transformer模型（DistilBERT、MiniLM、ALBERT）在客户情感分类、新闻主题分类和仇恨言论检测三个领域中的表现。结果显示，不同模型在准确率与效率间各有优劣：ALBERT在任务准确率上表现最佳，MiniLM在推理速度和吞吐量上领先，DistilBERT则在跨任务中表现出最稳定的准确率并保持良好效率。研究强调了准确性与效率之间的权衡，建议根据企业应用场景选择模型：低延迟场景选MiniLM，平衡性能选DistilBERT，资源受限环境选ALBERT。


<details>
  <summary>Details</summary>
Motivation: 随着企业自然语言处理需求的快速增长，对高效、轻量级模型以应对多领域文本自动化任务的需求日益迫切。现有模型在精度与效率之间存在显著权衡，亟需系统性评估不同轻量级模型的实际表现，以指导企业级应用部署决策。

Method: 基于IMDB、AG News和Measuring Hate Speech数据集，对DistilBERT、MiniLM和ALBERT进行对比实验。采用准确率、精确率、召回率、F1分数等精度指标，以及模型大小、推理时间、吞吐量和内存使用等效率指标，均在固定的企业级约束条件下进行微调，避免过度超参数优化。

Result: ALBERT在多个任务中达到最高准确率，但模型尺寸较大；MiniLM在推理速度和吞吐量方面表现最优；DistilBERT在跨任务中表现出最一致的准确率，并具备良好的整体效率。三者在不同维度上各有优势，无单一模型全面胜出。

Conclusion: 在企业级NLP应用中，应根据具体需求权衡模型的精度与效率。推荐：低延迟场景使用MiniLM，追求稳定均衡表现时选择DistilBERT，资源受限环境下优先考虑ALBERT。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [67] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 本文探讨大语言模型（LLMs）为检验语言意义的长期理论提供了新的实证场景，对比了社会建构主义的语言游戏观与数学导向的语义场理论。作者将词汇场（Lexfelder）和语言场（Lingofelder）形式化为连续语义空间中的相互作用结构，并分析了变压器架构的核心特性（如分布式表示、注意力机制、嵌入空间的几何规律）如何与这些概念相关联。研究认为，LLMs在捕捉语义规律方面的成功支持语言具有潜在数学结构的观点；而其在语用推理和语境敏感性上的局限则呼应了哲学中强调社会根基的重要性。因此，数学结构与语言游戏可视为互补而非对立，该框架明确了纯统计语言模型的边界，并为具有理论指导意义的AI架构指明新方向。


<details>
  <summary>Details</summary>
Motivation: 检验长期语言学理论在大语言模型（LLMs）这一新实证环境下的适用性，探索语言意义的本质是否具有数学结构，同时理解LLMs在语用和语境处理上的不足背后的原因。

Method: 形式化词汇场（Lexfelder）和语言场（Lingofelder）作为连续语义空间中的交互结构；结合变压器架构的特性（如分布式表示、注意力机制、嵌入空间的几何规律），分析其与语义结构的关系；通过比较数学结构与社会建构主义视角的互补性，构建理论框架。

Result: LLMs在捕捉语义规律方面表现出色，支持语言具有潜在数学结构的观点；其在语用推理和语境敏感性上的局限则反映社会语用因素的重要性。数学结构与语言游戏并非对立，而是互补关系。

Conclusion: 语言的意义既包含深层数学结构，也依赖于社会语境。大语言模型的成功揭示了语义的数学规律性，但其局限提醒我们不能忽视社会建构维度。未来AI架构应融合数学严谨性与社会语用基础，实现更全面的语言理解。

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [68] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 提出Defensive M2S训练范式，通过将多轮对话压缩为单轮以降低大语言模型安全防护模型的训练和推理成本。理论分析表明M2S将复杂度从O(n²)降至O(n)，实验显示在779个样本上训练token减少93倍（169K vs 15.7M），推理tokens减少94.6%（173 vs 3,231），Qwen3Guard+hyphenize配置达到93.8%攻击检测召回率，相比基线提升38.9个百分点，显著提升效率与性能。


<details>
  <summary>Details</summary>
Motivation: 传统多轮对话处理方式导致大语言模型安全防护模型训练与推理成本过高，亟需高效压缩策略以实现可扩展的安全筛查。

Method: 提出Multi-turn to Single-turn (M2S)压缩方法，将完整多轮对话历史压缩为单轮表示，并在不同压缩模板（hyphenize, numberize, pythonize）下微调多种护航模型（LlamaGuard, Nemotron, Qwen3Guard）。

Result: 在SafeDialBench基准测试中，最佳配置（Qwen3Guard+hyphenize）实现93.8%攻击检测召回率，推理成本下降94.6%，训练成本下降93倍，性能较基线提升38.9个百分点。

Conclusion: M2S压缩是一种高效且有效的技术，能够显著降低大语言模型护航模型的训练与推理开销，支持对长对话序列的大规模安全审查，具备实际部署价值。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [69] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 本文提出一种针对职业培训（VET）领域历史数字化文档中光学字符识别（OCR）噪声的鲁棒命名实体识别（NER）方法，结合噪声感知训练（NAT）、迁移学习和多阶段微调，通过在噪声、干净和人工数据上进行系统比较，显著提升在噪声环境下的准确性和鲁棒性。该方法可扩展至多种语言，已在德语文档上验证，并提供公开代码以支持复现。


<details>
  <summary>Details</summary>
Motivation: 传统NER方法在处理职业培训领域历史数字化文档时，因OCR引入的噪声导致性能下降。现有研究缺乏对噪声敏感且未充分考虑多类型实体识别，因此需要一种能应对噪声并适用于特定领域的鲁棒NER方法。

Method: 采用噪声感知训练（NAT），通过合成注入OCR错误生成人工噪声数据；结合迁移学习与多阶段微调策略，在噪声、干净及人工数据上进行训练，实现对多种实体类型的识别。

Result: 实验表明，领域特异性和噪声感知微调显著提升了模型在噪声条件下的准确率与鲁棒性；所提方法在德语文本上表现优异，具备跨语言可迁移性。

Conclusion: 本文提出的噪声感知NER框架为职业培训领域历史文档提供了有效的解决方案，具有高实用性与可复现性，为其他领域中的噪声文本处理提供了新思路。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [70] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 该研究分析了复杂句结构（如定语从句、同位语、并列谓词、状语从句和被动语态）对基于规则的原子句提取性能的影响，使用WikiSplit数据集在spaCy中实现依赖关系提取规则，生成100个黄金标准原子句集，并通过ROUGE和BERTScore评估。系统在各项指标上表现中等到较高，表明其在词汇、结构和语义层面具有较好的对齐性，但对句法复杂度敏感，尤其在处理定语从句、同位语等结构时表现较差。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原子句提取任务中缺乏可解释性，难以揭示导致提取失败的具体语言结构；尽管已有研究关注依赖关系驱动的三元组或子句提取，但尚无系统性分析说明哪些具体句法结构会导致提取困难。因此，需要对复杂句结构如何影响提取性能进行深入分析。

Method: 基于spaCy实现依赖关系驱动的规则提取方法，在WikiSplit数据集上构建100个黄金标准原子句集，并采用ROUGE和BERTScore进行评估。通过对比不同句法结构下的提取表现，识别出影响性能的关键因素。

Result: 系统在ROUGE-1 F1达到0.6714，ROUGE-2 F1为0.478，ROUGE-L F1为0.650，BERTScore F1为0.5898，表明在词汇、结构和语义层面有较好对齐。然而，相对复杂结构如定语从句、同位语、并列谓词、状语从句和被动构造显著降低提取准确率。

Conclusion: 基于规则的原子句提取方法具备合理准确性，但对句法复杂度高度敏感，尤其在面对多层嵌套或复杂依存结构时易出现失败。未来工作应结合深度学习与可解释性分析，以提升对复杂句结构的鲁棒性。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [71] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: 提出了一种名为嵌入一致性调节（ECR）的新框架，旨在解决紧凑模型在压缩过程中丢失嵌入空间结构的问题。ECR通过离线生成语义锚点，并让紧凑模型在这些锚点周围保持一致的几何结构，从而保留语义流形，而无需依赖输出对齐或内部特征匹配。该方法仅在推理时增加一个小型投影步骤，不改变解码架构或运行时行为。实验表明，ECR在多语言数据上稳定训练并有效保持跨任务和跨语言的语义结构，使低容量模型能学习更清晰的表示空间，且不依赖教师输出，与知识蒸馏兼容但独立。整体上，ECR提升了紧凑模型的任务适应性，便于在资源受限或隐私敏感场景下部署。


<details>
  <summary>Details</summary>
Motivation: 现有压缩方法仅在表面层次对齐模型输出，无法保留底层的流形结构，导致紧凑模型出现语义漂移，影响下游任务表现和语言特性。当模型容量紧张或数据涵盖多种语言时，这一问题尤为突出。因此需要一种能有效维持嵌入空间几何结构的压缩方法。

Method: ECR框架首先离线计算教师模型的嵌入，提取一组语义锚点；然后在训练紧凑模型时，强制其在这些锚点附近保持一致的几何关系，通过最小化锚点周围嵌入空间的变形来实现。该方法不依赖于匹配教师输出或内部特征，仅在推理阶段引入一个轻量级投影层。

Result: 在10万条多语言语料上的实验显示，ECR显著稳定了训练过程，有效保留了跨任务与跨语言的语义结构；紧凑模型生成的表示空间更紧凑、任务对齐性更强；即使在低容量条件下，也能学习到比传统基线更干净的流形结构。此外，该方法不依赖教师输出，可独立于知识蒸馏使用，适用于严苛的效率或隐私限制场景。

Conclusion: ECR通过维护嵌入空间的几何一致性，有效缓解了紧凑模型中的语义漂移问题，使模型在保持高效的同时更好地遵循任务需求，提升可部署性，尤其适合资源受限或隐私敏感的应用场景。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [72] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 提出一种轻量级、无语言依赖的多语言语音识别系统HLoRA，基于CTC架构并结合领域自适应技术，通过分层LoRA-MoE框架实现端到端解码，无需预先语言信息即可完成真无语言依赖解码，在MSR-86K和MLC-SLM 2025数据集上表现优于现有单次解码方法，显著提升低资源场景下的解码效率。


<details>
  <summary>Details</summary>
Motivation: 现有大规模多语言语音识别模型（如Whisper）虽性能强，但计算开销大、延迟高，难以部署在资源受限的边缘设备上；亟需一种高效、轻量且真正无语言依赖的多语言语音识别方案以支持低资源环境下的实际应用。

Method: 提出语言无关分层LoRA-MoE（HLoRA）框架，集成于mHuBERT-CTC模型中，利用语言识别后验驱动的LoRA路由机制实现端到端解码；该框架包含共享多语言LoRA（学习语言不变声学表征）与语言特定LoRA专家（建模语言特异性特征），通过动态路由避免对语言标签的依赖。

Result: 在MSR-86K和MLC-SLM 2025数据集上的实验表明，HLoRA在仅使用单次解码的情况下，达到与当前最先进的两阶段推理方法相当的性能，同时大幅提升了解码效率，适用于低资源多语言语音识别场景。

Conclusion: HLoRA框架实现了高效、轻量、真正的语言无关多语言语音识别，突破了传统方法对语言标签的依赖，为边缘设备上的实时多语言语音处理提供了可行解决方案。

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [73] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: InfoSynth是一个基于信息论原则的自动生成和评估推理基准的框架，利用KL散度和熵来量化基准的新颖性和多样性，无需依赖昂贵的模型评估。该框架通过遗传算法和迭代代码反馈从种子数据集生成高质量的Python编程问题，97%的情况下能准确生成测试用例和解决方案，并在新颖性、多样性和难度控制方面优于原始种子数据集。


<details>
  <summary>Details</summary>
Motivation: 传统基准创建依赖人工，成本高且耗时；现有基准常与LLM训练数据重叠，导致评估不准确。需要一种高效、可扩展的方法生成新颖、多样且无污染的基准以真实评估LLM能力。

Method: 提出基于KL散度和熵的指标衡量基准新颖性与多样性；设计端到端流水线，结合遗传算法与迭代代码反馈，自动生成具有准确测试用例和解法的编程问题；支持对生成问题的难度、新颖性和多样性的可控调节。

Result: 合成的基准在新颖性和多样性上显著优于种子数据集；97%的问题能成功生成准确的测试用例和解决方案；整个流程具备自验证能力，可大规模部署。

Conclusion: InfoSynth提供了一种高效、可扩展、自我验证的基准生成方法，能够持续构建高质量、新颖且多样的评测数据，为评估大语言模型的真实推理与代码生成能力提供了可靠支持。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [74] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: 本文提出中文特定安全基准（CSSBench），针对中文特有的恶意查询模式（如谐音、拼音拆分、符号干扰等）评估轻量级大语言模型的安全性，覆盖六大真实场景领域，揭示轻量模型在中文对抗性攻击下的脆弱性，并指出过度拒绝问题导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有安全评测基准多聚焦英文，难以捕捉中文特有的隐蔽恶意查询模式，尤其对资源受限的轻量级模型构成显著安全风险，亟需针对性评估工具。

Method: 构建涵盖六类真实中文场景的多任务查询数据集，重点引入中文特有对抗性扰动模式，系统评估轻量级LLM在中文环境下的安全性与过拒行为。

Result: 实验表明，中文特有对抗模式对轻量级模型构成严峻挑战，现有模型普遍存在安全过拒现象，导致实际应用性能下降；所提基准能有效识别并量化此类风险。

Conclusion: CSSBench为中文环境下轻量级大语言模型的安全评估提供了全面、针对性的基准工具，有助于提升模型在真实场景中的鲁棒部署能力。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [75] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 本文提出了一种简单且模型无关的框架，通过在固定输入的确定性自动化工作流中重复运行大语言模型（LLM）并结合基于LLM的评判机制，显著降低上下文幻觉的发生概率。该方法利用独立上下文窗口中的多次推理实现错误概率的指数级下降，并通过多数投票增强评判器的可靠性，使整体错误率随评判次数呈指数衰减。实验在合成噪声评判者下的受控提取任务中验证了理论预测，表明系统失败率和幻觉选择率均随重复次数和评判员数量指数下降。整个方法无需修改模型权重、解码策略或提示工程，即可将幻觉概率降至任意低水平。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在确定性自动化流程中常因上下文幻觉产生与提示内容矛盾的输出，而现有方法难以提供可量化的错误控制。本文旨在为固定输入场景下的幻觉问题提供一种轻量、模块化且具有明确概率保障的解决方案。

Method: 1. 将任务定义为固定输入与确定性正确性标准；2. 通过在独立上下文窗口中多次运行同一提示，利用结果一致性降低全错概率；3. 引入LLM作为评判器，评估各次输出的正确性；4. 当评判器不完美时，采用多数投票机制构建集成评判系统，进一步降低错误率；5. 理论推导并验证了整体失败概率随重复次数和评判员数量呈指数下降的特性。

Result: 实验结果与理论预测完全吻合：随着重复运行次数增加，系统失败率呈指数下降；随着集成评判员数量增加，幻觉答案被选中的概率也呈指数下降。该方法在不改变模型权重、解码策略或提示设计的前提下，实现了对幻觉概率的任意低水平控制。

Conclusion: 本文提出的框架为固定输入的大语言模型应用提供了一种高效、可靠且理论完备的防幻觉机制，能够通过简单的重复与集成策略将幻觉风险降至可忽略水平，具备良好的通用性与实用性。

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [76] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: FwPKM 是一种新型的序列建模架构，通过将稀疏产品键记忆（PKM）从静态模块转变为动态的“快速权重”情景记忆，解决了存储容量与计算效率之间的权衡问题。它在训练和推理时通过局部块级梯度下降动态更新参数，实现对输入序列中新键值对的快速记忆与检索。实验表明，FwPKM 作为有效的情景记忆，能显著降低长上下文数据集上的困惑度，并在 Needle in a Haystack 测试中展现出对 128K token 上下文的泛化能力，尽管仅在 4K token 序列上训练。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型中的序列建模层面临存储容量与计算效率的权衡：Softmax 注意力虽有无限存储但计算成本高，线性变体虽高效但存储有限且固定。需要一种既能高效又能动态扩展存储的新机制。

Method: 提出 Fast-weight Product Key Memory (FwPKM)，将 PKM 转化为动态的快速权重情景记忆，利用局部块级梯度下降在训练和推理时实时更新参数，实现对新键值对的快速记忆与检索。

Result: FwPKM 在长上下文任务中显著降低困惑度，尤其在 Needle in a Haystack 任务中表现出对 128K token 上下文的泛化能力，即使仅在 4K token 序列上训练。

Conclusion: FwPKM 成功实现了高效且可扩展的记忆机制，弥补了标准模块的语义记忆不足，是解决序列建模中存储与效率矛盾的有效方案。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [77] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 本文提出一种名为Sigmoid Head的模块，用于改进语言模型（LM）在质量评估中的表现。传统LM使用softmax激活，难以同时为多个正确输出分配高概率，且训练数据单一，导致模型认为每一步仅有一个正确答案。Sigmoid Head通过引入带有sigmoid激活的额外解码头来解决第一个问题，并在负采样过程中采用启发式方法避免选择可能的替代正确词，以缓解第二个问题。该方法在训练和推理中计算效率高，且无需人工标注的质量数据，因此在域外场景下比监督式质量估计更鲁棒。实验表明，Sigmoid Head提供的概率信号显著优于原始softmax头。


<details>
  <summary>Details</summary>
Motivation: 语言模型的概率分布因自然语言的歧义性而不可靠，当存在多个有效输出时，模型会将概率分散，导致误判输出质量；此外，模型的softmax输出机制和单参考训练数据限制了其对多正确选项的表达能力。

Method: 提出Sigmoid Head模块，包含一个带有sigmoid激活的额外解码头，用于生成更可靠的输出质量信号；在训练过程中，通过启发式负采样策略避免选择可能的替代正确词，从而提升模型对多正确输出的识别能力。

Result: Sigmoid Head在质量信号上显著优于原始softmax头，且在无监督条件下表现出更强的泛化能力，尤其在域外设置中更具鲁棒性。

Conclusion: Sigmoid Head是一种高效、无需人工标注质量数据的质量估计方法，能够有效克服传统语言模型在多正确输出场景下的局限性，提供更可靠的质量评估信号。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [78] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 本文评估了多种大型语言模型（LLMs）在情感分析、攻击性语言识别和事实验证三个任务中的文本跨度识别性能，探索了指令微调、上下文学习和思维链等策略。结果表明，文本内部的潜在关系有助于LLMs更精准地识别文本跨度。


<details>
  <summary>Details</summary>
Motivation: 当前大多数文本跨度识别方法依赖于较小的预训练语言模型（如BERT），而基于最新一代大型语言模型（LLMs）的研究较少，尤其是在主观性较强的跨度识别任务（如基于方面的情感分析）中研究不足。因此，本文旨在填补这一空白。

Method: 采用多种LLM策略（包括指令微调、上下文学习、思维链）对三个典型任务（情感分析、攻击性语言识别、事实验证）中的文本跨度识别能力进行系统评估。

Result: 实验结果显示，文本内部的潜在语义关系有助于大型语言模型更准确地定位相关文本跨度，表明上下文理解与推理能力在提升跨度识别精度方面具有重要作用。

Conclusion: 大型语言模型在文本跨度识别任务中展现出显著潜力，尤其当结合上下文学习与推理策略时，能够有效捕捉文本内在结构，提升识别准确性。该研究为未来基于LLMs的可解释性NLP系统提供了重要参考。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [79] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本文首次评估了在加拿大跨省背景下，将已在不列颠哥伦比亚省癌症登记处开发的BCCRTron模型和生物医学Transformer模型GatorTron进行适应性应用的效果。研究基于纽芬兰与拉布拉多癌症登记处（NLCR）约10.4万份病理报告（用于癌症/非癌症分类）和2.2万份报告（用于可报告/不可报告分类）进行微调，并采用综合报告与诊断聚焦两种输入管道。结果显示，经过适度微调后，模型在新地区仍保持高精度；通过保守的或组合（OR-ensemble）策略，联合模型在Tier 1任务中实现0.99召回率，漏报癌症数降至24例（单个模型分别为48和54例），在Tier 2任务中召回率同样达0.99，漏报可报告癌症减少至33例（单个模型分别为54和46例）。研究还提出一种隐私保护工作流，仅共享模型权重，支持跨省协作，为构建全国统一的癌症病理与登记自然语言处理基础模型奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前癌症登记依赖病理报告，但人工提取耗时耗力，且现有基于Transformer的NLP系统在不同省份间泛化能力不明确。亟需验证跨区域迁移的有效性，并提升数据抽取的敏感性与准确性。

Method: 使用来自纽芬兰与拉布拉多癌症登记处的约10.4万份（Tier 1）和2.2万份（Tier 2）去标识化病理报告对BCCRTron和GatorTron进行微调；分别采用综合报告与诊断聚焦两类文本输入管道；通过保守的OR-集成策略融合两模型输出以提高召回率；建立仅共享模型权重的隐私保护协作流程。

Result: 适应后的模型在新省份表现良好；集成模型在Tier 1和Tier 2任务中均达到0.99召回率，显著降低漏报数量（分别从48/54降至24，54/46降至33）；证明了跨区域迁移与模型集成的有效性；提出的隐私保护框架支持未来全国性模型建设。

Conclusion: 通过适度微调与模型集成，可在无需共享原始数据的前提下实现跨省高效、准确的癌症病理信息抽取；该方法具备可扩展性，有助于构建覆盖全国的隐私友好型癌症登记自然语言处理基础设施。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [80] [Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems](https://arxiv.org/abs/2601.00005)
*Lesley Wheat,Martin v. Mohrenschildt,Saeid Habibi*

Main category: cs.LG

TL;DR: 该研究评估了14种异常检测算法在模拟工业数据集上的表现，重点分析了极端类别不平衡问题。实验使用2D和10D的超球形异常分布数据，测试了不同故障率（0.05%–20%）和训练样本量（1,000–10,000）下的性能与泛化能力。结果表明，最佳检测器依赖于训练集中故障样本数量：少于20个故障样本时，无监督方法（如kNN/LOF）表现最优；当故障样本达30–50个时，半监督（XGBOD）和监督学习方法（SVM/CatBoost）性能显著提升。此外，特征维度对方法效果有影响，仅两维时半监督方法优势不明显，但在十维时表现更好。研究还指出小样本下泛化性能下降的问题，为工业场景部署异常检测提供了实用建议。


<details>
  <summary>Details</summary>
Motivation: 工业系统中异常检测面临极端类别不平衡问题，主要因故障数据稀缺。现有方法在真实工业场景中的表现尚不明确，亟需系统性评估以指导实际应用。

Method: 采用基于超球形分布的合成数据集，模拟真实工程约束。在2D和10D空间中构建不同故障率（0.05%–20%）和训练规模（1,000–10,000）的数据集，测试14种异常检测算法，并在固定40,000样本的测试集上评估性能与泛化误差。

Result: 当故障样本少于20个时，无监督方法（kNN/LOF）表现最佳；故障样本增至30–50个时，半监督（XGBOD）和监督学习（SVM/CatBoost）方法性能大幅提升。特征维度越高（10维），半监督方法优势越明显。小样本训练导致泛化性能显著下降。

Conclusion: 异常检测算法的选择应根据训练集中故障样本数量动态调整。在工业环境中，应优先考虑样本充足时的监督或半监督方法，同时注意小样本下的泛化风险。研究为实际部署提供了关键实证依据。

Abstract: Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.

</details>


### [81] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: 本文揭示了开放权重大模型生态系统中，通过分词器移植实现的跨模型组合存在供应链漏洞。研究者提出一种名为"breaker token"的攻击方法：该令牌在源模型中无害，但在移植到目标模型后可重构为高显著性的恶意特征。利用系数重用的几何特性，攻击制造出不对称的可实现性差距，破坏目标模型生成能力，同时保持源模型行为统计上与正常情况无法区分。该攻击无需训练，通过稀疏求解器实现，具备对抗微调和权重合并的结构鲁棒性，凸显模块化AI组合中的隐藏风险。代码已公开。


<details>
  <summary>Details</summary>
Motivation: 现有模型组合技术（如权重合并、推测解码、词汇扩展）依赖分词器移植以实现不同模型家族间的互操作性。然而，这一过程引入了潜在的安全漏洞，即恶意特征可能在移植过程中悄然植入，影响目标模型的可靠性与安全性。因此，亟需理解并评估此类供应链风险。

Method: 将攻击建模为双目标优化问题，利用系数重用的几何结构设计一个训练无关的攻击策略；采用稀疏求解器实现攻击实例，使攻击令牌在目标模型中激活恶意功能，同时在源模型中保持不可察觉。

Result: 实验表明，该攻击在不改变源模型性能的前提下，能在目标模型中可靠触发恶意行为；具备谱模仿能力，可规避异常检测；对微调和权重合并具有结构持久性，验证了其在实际部署中的隐蔽性和威胁性。

Conclusion: 分词器移植虽是实现模型组合的关键步骤，但其引入的几何敏感性构成了严重安全隐患。建议在模型组合流程中引入更严格的验证机制，并重新审视跨模型互操作性设计中的安全假设。

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [82] [IMBWatch -- a Spatio-Temporal Graph Neural Network approach to detect Illicit Massage Business](https://arxiv.org/abs/2601.00075)
*Swetha Varadarajan,Abhishek Ray,Lumina Albert*

Main category: cs.LG

TL;DR: IMBWatch is a spatio-temporal graph neural network framework designed to detect illicit massage businesses (IMBs) by analyzing heterogeneous data from online ads, licenses, and reviews. It models dynamic relationships across entities like businesses, phones, and locations over time and space, enabling detection of trafficking patterns such as burner phone use and coordinated advertising. The system outperforms baselines in accuracy and F1 score, offers interpretable insights, and is scalable and open-source.


<details>
  <summary>Details</summary>
Motivation: Illicit massage businesses are hard to detect due to their covert operations, frequent changes, and reuse of shared infrastructure. Traditional detection methods are reactive and fail to uncover larger trafficking networks.

Method: IMBWatch constructs dynamic spatio-temporal graphs from open-source intelligence. It uses graph convolutional networks combined with temporal attention mechanisms to model evolving patterns such as co-location, repeated phone usage, and synchronized advertising across time and space.

Result: IMBWatch achieves higher accuracy and F1 scores than baseline models on real-world datasets from multiple U.S. cities. It provides actionable, interpretable insights for proactive interventions and is scalable to other illicit domains.

Conclusion: IMBWatch offers an effective, scalable, and interpretable solution for detecting IMBs at scale, supporting law enforcement and policy efforts through data-driven, proactive strategies.

Abstract: Illicit Massage Businesses (IMBs) are a covert and persistent form of organized exploitation that operate under the facade of legitimate wellness services while facilitating human trafficking, sexual exploitation, and coerced labor. Detecting IMBs is difficult due to encoded digital advertisements, frequent changes in personnel and locations, and the reuse of shared infrastructure such as phone numbers and addresses. Traditional approaches, including community tips and regulatory inspections, are largely reactive and ineffective at revealing the broader operational networks traffickers rely on.
  To address these challenges, we introduce IMBWatch, a spatio-temporal graph neural network (ST-GNN) framework for large-scale IMB detection. IMBWatch constructs dynamic graphs from open-source intelligence, including scraped online advertisements, business license records, and crowdsourced reviews. Nodes represent heterogeneous entities such as businesses, aliases, phone numbers, and locations, while edges capture spatio-temporal and relational patterns, including co-location, repeated phone usage, and synchronized advertising. The framework combines graph convolutional operations with temporal attention mechanisms to model the evolution of IMB networks over time and space, capturing patterns such as intercity worker movement, burner phone rotation, and coordinated advertising surges.
  Experiments on real-world datasets from multiple U.S. cities show that IMBWatch outperforms baseline models, achieving higher accuracy and F1 scores. Beyond performance gains, IMBWatch offers improved interpretability, providing actionable insights to support proactive and targeted interventions. The framework is scalable, adaptable to other illicit domains, and released with anonymized data and open-source code to support reproducible research.

</details>


### [83] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 本文提出了一种新的渐近固定置信度最优臂识别（BAI）框架，通过放松对误差控制的严格要求，允许在最小样本量下实现渐近有效的误差控制。该方法利用新型的渐近任意时间有效置信序列，支持非参数分布和个体特征的灵活建模，在保证近似误差控制的同时显著降低平均样本复杂度。实验表明，该方法在保持误差控制的前提下，能有效减少所需样本量。


<details>
  <summary>Details</summary>
Motivation: 现有BAI算法在实际应用中受限于严格的精确误差控制，通常依赖宽松的尾部不等式或参数假设，导致效率低下。尤其在弱信号、高显著性及事后推断需求的场景下，需要更长的实验周期，因此亟需一种更灵活且高效的算法框架。

Method: 提出渐近固定置信度的松弛框架，设计基于臂索引的渐近任意时间有效置信序列，构建新的BAI算法，结合协变量进行方差缩减，并在非参数条件下实现近似误差控制。

Result: 在温和收敛假设下，给出了样本复杂度的渐近界；最坏情况下的样本复杂度与已知方差下高斯BAI的最佳情况相当。实验验证了该方法在降低平均样本复杂度方面表现优异，同时保持误差控制能力。

Conclusion: 所提方法在灵活性、非参数适应性和样本效率方面均优于传统方法，适用于现实世界中复杂的、长期运行的决策场景。

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [84] [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)
*Junqi Qu,Yan Zhang,Shangqian Gao,Shibo Li*

Main category: cs.LG

TL;DR: NeuroSymBO 提出一种自适应指令选择方法，通过贝叶斯优化在多步生成过程中动态调整提示，以解决大语言模型在方程发现任务中的指令脆弱性问题。该方法在偏微分方程发现基准上显著优于固定提示，提高了恢复率并获得更简洁的解。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在方程发现任务中对提示词敏感，静态提示无法适应多步生成过程中的状态变化，导致模型陷入次优解。

Method: 将提示工程建模为序列决策问题，维护一个离散的推理策略库，并利用贝叶斯优化根据数值反馈在每一步选择最优指令。

Result: 在偏微分方程发现基准上，自适应指令选择显著优于固定提示，具有更高的方程恢复率和更简洁的解。

Conclusion: NeuroSymBO 通过动态调整提示策略，有效缓解了大语言模型在方程发现中的指令脆弱性问题，提升了生成质量与效率。

Abstract: Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.

</details>


### [85] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: GRL-SNAM 是一种基于几何强化学习的框架，用于在未知环境中实现无需地图的同步导航与建图（SNAM）。该方法通过局部感官观测构建动态最短路径搜索与发现过程，利用受控哈密顿优化将传感器输入转化为局部能量场，编码可达性、障碍物屏障和形变约束。策略通过更新哈密顿量分阶段演化，减少的哈密顿量作为自适应评分函数，持续优化轨迹。在两个2D导航任务中，GRL-SNAM优于局部反应基线和全局策略学习方法，在保持安全距离的同时具备对未见布局的泛化能力，证明了基于哈密顿量更新的几何强化学习可实现高质量导航，且仅需最小探索。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖全局地图或预设路径，难以应对未知环境；而现有强化学习方法常需大量全局映射信息，效率低。本研究旨在设计一种无需预先地图、仅依赖局部感知的高效、鲁棒的同步导航与建图框架，以提升机器人在真实复杂环境中的自主性与适应性。

Method: 提出GRL-SNAM框架，将导航与建图建模为动态最短路径搜索问题。通过受控哈密顿优化，将传感器输入转化为局部能量景观，包含可达性、障碍物和形变约束。采用分阶段更新哈密顿量的方式，使感知、规划与重构策略协同演化。减少的哈密顿量作为自适应评分函数，动态调整动能与势能项，并融合障碍约束，实现轨迹的实时优化。

Result: 在两个2D导航任务中，GRL-SNAM在相同感知约束下表现优于局部反应基线与全局策略学习方法。它保持了良好的路径安全裕度，能够泛化至未见过的环境布局，且仅通过少量探索即可完成高质量导航，验证了基于哈密顿量更新的几何强化学习在降低全局建图依赖方面的有效性。

Conclusion: GRL-SNAM通过基于局部能量场的几何强化学习机制，实现了在无地图环境下高效、鲁棒的同步导航与建图。其核心在于利用动态哈密顿量驱动策略演化，避免了对大规模全局地图的依赖，显著提升了机器人在未知环境中的自主导航能力，具有广泛的应用前景。

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [86] [Reinforcement Learning with Function Approximation for Non-Markov Processes](https://arxiv.org/abs/2601.00151)
*Ali Devran Kara*

Main category: cs.LG

TL;DR: 研究在非马尔可夫状态和成本过程下，使用线性函数逼近的强化学习方法。针对策略评估，证明了在适当遍历性条件下算法收敛，且极限对应于一个辅助马尔可夫决策过程的贝尔曼算子与正交投影联合算子的不动点。对于线性函数逼近的Q-learning，在一般情况下不保证收敛，但当基函数基于量化映射选择时，可在类似遍历性条件下证明收敛。最后将结果应用于部分可观测马尔可夫决策过程，使用有限记忆变量作为状态表示，并推导出学习算法极限的显式误差界。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习理论多基于马尔可夫假设，但在实际应用中状态过程常为非马尔可夫的，如部分可观测环境。本文旨在扩展线性函数逼近下的强化学习方法到非马尔可夫设置，以增强其在现实复杂系统中的适用性。

Method: 采用遍历性条件分析非马尔可夫过程下的策略评估与Q-learning算法；引入辅助马尔可夫决策过程，结合正交投影与贝尔曼算子构造联合算子；对基于量化映射的基函数设计进行特殊处理以确保收敛性；利用有限记忆变量作为状态表示，推导误差边界。

Result: 策略评估算法在遍历性条件下收敛至联合算子的不动点；基于量化映射的基函数可使Q-learning在相同条件下收敛；在部分可观测环境下，得到学习算法极限的显式误差界。

Conclusion: 本工作拓展了线性函数逼近强化学习在非马尔可夫环境中的理论基础，证明了在合理条件下算法的收敛性，并为部分可观测系统提供了可量化的误差分析框架，具有较强的理论价值和应用潜力。

Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.

</details>


### [87] [The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data](https://arxiv.org/abs/2601.00152)
*Yann Bellec,Rohan Kaman,Siwen Cui,Aarav Agrawal,Calvin Chen*

Main category: cs.LG

TL;DR: 本研究利用2016-2023年美国50万起交通事故数据，采用XGBoost分类器分析环境、时间和空间因素对事故严重程度的预测能力。模型整体准确率达78%，对中等严重程度事故（Severity 2）表现良好（精确率和召回率均为87%）。时间、地理位置及天气变量（如能见度、温度、风速）是主要预测因子，但降水与能见度的预测力较弱，可能因驾驶员在恶劣条件下的行为适应所致。数据集中低严重程度事故占主导，限制了极端情况的建模能力，提示需改进采样策略、特征工程并融合外部数据。研究为交通管理提供实证支持，并指明未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探究环境、时间与空间因素对美国交通事故严重程度的预测能力，以支持更精准的交通安全管理决策。

Method: 基于2016-2023年美国50万起交通事故数据，使用XGBoost分类器，通过随机搜索交叉验证优化超参数，并采用类别权重处理样本不平衡问题。

Result: 模型总体准确率为78%，对多数类（Severity 2）的精确率与召回率均达87%；时间、地理区域和天气变量（如温度、风速、能见度）为关键预测因子；降水与能见度的预测能力较弱，可能源于驾驶员行为适应。数据分布不均限制了极端严重事故的识别能力。

Conclusion: 时间、地理与天气因素对事故严重性具有显著预测作用，但现有数据结构限制了极端案例建模。建议改进采样方法、增强特征工程并整合外部数据以提升模型性能，为交通管理提供科学依据。

Abstract: This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.

</details>


### [88] [Online Finetuning Decision Transformers with Pure RL Gradients](https://arxiv.org/abs/2601.00167)
*Junkai Luo,Yinglun Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种基于纯强化学习（RL）梯度的在线微调决策变换器（DTs）的新方法，解决了现有方法中因回溯回报重标记导致的训练不稳定性问题。通过改进GRPO算法，引入子轨迹优化、序列级似然目标和主动采样等技术，显著提升了信用分配、稳定性和探索能力。实验表明，该方法在多个基准测试中优于现有基线，达到新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有在线决策变换器方法依赖监督学习目标进行微调，而回溯回报重标记虽对监督学习有益，但与基于重要性采样的强化学习算法（如GRPO）不兼容，导致训练不稳定。因此需要一种基于纯强化学习梯度的在线微调方法以提升性能和稳定性。

Method: 提出适应于决策变换器的GRPO改进算法，包含子轨迹优化以改善信用分配、序列级似然目标以增强训练稳定性和效率，以及主动采样机制以促进在不确定区域的探索。

Result: 所提方法在多个基准任务上均显著优于现有在线DT基线，实现新的最先进性能，验证了纯强化学习梯度在线微调的有效性。

Conclusion: 通过解决回溯回报重标记带来的兼容性问题，本研究成功实现了基于纯强化学习梯度的在线微调决策变换器，为DTs在在线强化学习场景中的应用提供了高效且稳定的解决方案。

Abstract: Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.

</details>


### [89] [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)
*Ata Akbari Asanjan,Filip Wudarski,Daniel O'Connor,Shaun Geaney,Elena Strbac,P. Aaron Lott,Davide Venturelli*

Main category: cs.LG

TL;DR: 本文提出一种序列型储层计算（Sequential RC）架构，通过将大型储层分解为一系列小型互联储层，有效降低内存与计算成本，同时保持长期时间依赖性。在低维混沌系统（Lorenz63）和高维物理模拟（二维涡度与浅水方程）中，该方法相比LSTM和标准RNN基线，实现了15-25%更长的有效预测时长、20-30%更低的误差指标（SSIM、RMSE），训练成本降低达三个数量级。结果表明，Sequential RC在保持传统RC简单性和高效性的同时，显著提升了高维动力系统的可扩展性，为科学与工程应用中的实时、低功耗预测提供了可行路径。


<details>
  <summary>Details</summary>
Motivation: 传统RNN和LSTM在处理高维时空系统时面临梯度训练困难和内存瓶颈问题；尽管储层计算（RC）通过固定递归层和凸读出优化缓解了部分挑战，但其常规架构在输入维度增加时仍存在扩展性差的问题。因此，亟需一种既能保持计算效率又具备高维可扩展性的新型模型。

Method: 提出序列型储层计算（Sequential RC）架构，将大尺寸储层拆分为多个小规模、相互连接的子储层，利用串行结构实现信息传递与状态演化，从而降低内存占用与计算开销，同时保留对长期时间依赖的建模能力。读出层采用凸优化方式训练，确保整体框架简洁高效。

Result: 在Lorenz63系统及二维涡度和浅水方程等高维物理模拟中，Sequential RC相较于LSTM和标准RNN，在预测精度（SSIM、RMSE）上提升20-30%，有效预测时长延长15-25%，训练成本降低高达三个数量级，展现出卓越的性能与可扩展性。

Conclusion: Sequential RC结合了传统储层计算的高效性与现代深度学习对高维动态系统的建模需求，成功解决了高维时空系统预测中的计算瓶颈问题，为实时、低功耗科学计算提供了一种实用且可扩展的新范式。

Abstract: Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.

</details>


### [90] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 本研究开发并评估了基于电子健康记录（EHR）数据的机器学习（ML）模型，用于在肝硬化诊断前1、2、3年进行预测，并与FIB-4评分进行性能对比。研究采用回顾性队列设计，使用大型学术医疗系统的去标识化EHR数据，对脂肪肝患者按是否发展为肝硬化进行分组。通过构建观察期和预测窗口模拟真实临床场景，整合人口学特征、诊断、实验室结果、生命体征和共病指数等信息，训练XGBoost模型进行多时间点预测，并以受试者工作特征曲线下面积（AUC）评估性能。结果显示，所有预测时间窗下ML模型均显著优于FIB-4：1年预测AUC分别为0.81 vs 0.71，2年为0.73 vs 0.63，3年为0.69 vs 0.57，且随着预测时间延长，优势持续存在，表明其具备更强的早期风险识别能力。结论指出，基于常规EHR数据的机器学习模型在肝硬化早期预测中显著优于传统FIB-4评分，可作为自动化决策支持工具，实现更早、更精准的风险分层，助力肝硬化预防与管理。


<details>
  <summary>Details</summary>
Motivation: 当前肝硬化早期识别困难，传统生物标志物如FIB-4评分在早期预测中的敏感性和特异性有限，难以满足临床对前瞻性风险评估的需求。利用广泛可用的电子健康记录（EHR）数据，开发更精确的预测模型，有助于实现肝硬化的早期干预和预防。

Method: 采用回顾性队列研究设计，基于大型学术医疗系统的去标识化电子健康记录（EHR）数据。通过ICD-9/10编码识别脂肪肝患者，并依据后续是否发展为肝硬化分为两组。构建不同预测时间窗（1、2、3年）的预测场景，整合观察期内的人口学、诊断、实验室结果、生命体征及共病指数等变量。使用XGBoost算法训练多时间点预测模型，并在独立测试集上评估其性能，以AUC为主要评价指标，与FIB-4评分进行横向比较。

Result: 研究纳入3,043例（1年预测）、1,981例（2年预测）和1,470例（3年预测）患者。在所有预测时间窗下，机器学习模型表现均优于FIB-4评分：1年预测的AUC为0.81（模型）vs 0.71（FIB-4），2年为0.73 vs 0.63，3年为0.69 vs 0.57。性能优势随预测时间延长而增强，说明模型在长期风险识别方面具有更高潜力。

Conclusion: 基于常规电子健康记录数据的机器学习模型在预测肝硬化发生方面显著优于传统的FIB-4评分，能够实现更早、更准确的风险分层。该模型可嵌入临床工作流程，作为自动化决策支持工具，提升肝硬化早期预防与管理的效率和质量。

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [91] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: 本文提出一种资源高效、以数据为中心的心律失常检测框架，通过结合小波变换与图论特征（如PageRank中心性）构建混合特征空间，并利用互信息与递归消除优化特征，实现可解释的轻量级线性分类器。在MIT-BIH和INCART数据集上达到98.44%准确率，模型仅8.54 KB，推理延迟0.46 μs，支持实时处理，相较压缩模型效率提升一个数量级，推动无电池心脏传感器发展。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法计算开销大，难以部署于资源受限的边缘设备，亟需高效、低功耗的心律失常监测方案。

Method: 采用时间-频率小波分解与图论结构描述符（如PageRank中心性）融合生成特征空间，再通过互信息与递归消除进行特征精炼，最终使用超轻量线性分类器进行诊断。

Result: 在MIT-BIH和INCART数据集上实现98.44%诊断准确率，模型大小仅8.54 KB，单次心跳处理延迟52 ms，推理延迟0.46 μs，显著优于压缩模型（如KD-Light，25 KB，96.32%准确率）。

Conclusion: 该框架实现了高精度、极低资源消耗的心律失常检测，为无电池可穿戴心脏监测设备提供了可行技术路径。

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [92] [GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation](https://arxiv.org/abs/2601.00231)
*Pritish Saha,Chandrav Rajbangshi,Rudra Goyal,Mohit Goyal,Anurag Deo,Biswajit Roy,Ningthoujam Dhanachandra Singh,Raxit Goswami,Amitava Das*

Main category: cs.LG

TL;DR: GRIT introduces a curvature-aware, dynamic LoRA method that improves parameter efficiency and stability by preconditioning gradients with K-FAC, reprojecting low-rank bases onto dominant Fisher eigendirections, and adaptively adjusting effective rank. It outperforms LoRA and QLoRA with up to 80% fewer trainable parameters, reduces drift, and maintains performance across diverse tasks and prompt styles.


<details>
  <summary>Details</summary>
Motivation: Existing PEFT methods like LoRA and QLoRA are geometry-agnostic, optimizing in fixed, randomly oriented low-rank subspaces without considering local loss curvature, leading to inefficient updates and potential drift. This work aims to improve both efficiency and stability by incorporating curvature information.

Method: GRIT uses K-FAC as a natural-gradient proxy to precondition gradients in rank space, periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift, and adaptively adjusts effective rank based on the spectrum to concentrate capacity where signal resides.

Result: GRIT matches or exceeds LoRA and QLoRA performance across instruction-following, comprehension, and reasoning benchmarks on LLaMA models while reducing trainable parameters by 46% on average (25–80% per task), with no quality loss across different prompt styles and data mixes. It also demonstrates lower drift and improved updates-vs-retention trade-off compared to state-of-the-art PEFT optimizers.

Conclusion: GRIT provides a more efficient and stable approach to parameter-efficient fine-tuning by leveraging curvature-aware dynamics within the LoRA framework, enabling significant parameter reduction without sacrificing model performance.

Abstract: Parameter-efficient fine-tuning (PEFT) is the default way to adapt LLMs, but widely used LoRA and QLoRA are largely geometry-agnostic: they optimize in fixed, randomly oriented low-rank subspaces with first-order descent, mostly ignoring local loss curvature. This can inflate the effective update budget and amplify drift along weakly constrained directions. We introduce GRIT, a dynamic, curvature-aware LoRA procedure that preserves the LoRA parameterization but: (1) preconditions gradients in rank space using K-FAC as a natural-gradient proxy; (2) periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift; and (3) adapts the effective rank from the spectrum so capacity concentrates where signal resides. Across instruction-following, comprehension, and reasoning benchmarks on LLaMA backbones, GRIT matches or surpasses LoRA and QLoRA while reducing trainable parameters by 46% on average (25--80% across tasks), without practical quality loss across prompt styles and data mixes. To model forgetting, we fit a curvature-modulated power law. Empirically, GRIT yields lower drift and a better updates-vs-retention frontier than strong PEFT-optimizer baselines (Orthogonal-LoRA, IA3, DoRA, Eff-FT, Shampoo).

</details>


### [93] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 本文提出了一种基于最优传输的联邦逆强化学习方法，通过局部执行最大熵逆强化学习并利用Wasserstein均值融合奖励函数，在保证隐私和计算效率的同时，实现了跨异构环境的共享奖励函数学习。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，各智能体运行于略有差异的环境中，直接聚合数据学习共享奖励函数面临动态差异、隐私限制和通信带宽不足等问题，因此需要一种高效且隐私友好的联合学习方法。

Method: 每个客户端本地执行轻量级的最大熵逆强化学习，随后利用Wasserstein均值融合各客户端的奖励函数，以保留其底层几何结构。

Result: 实验表明，该方法在联邦学习框架下比传统的参数平均方法能更准确地估计全局奖励函数，具有更好的泛化性能和通信效率。

Conclusion: 本文提出的基于最优传输的联邦逆强化学习框架，为异构环境下共享奖励学习提供了理论严谨且实用的解决方案。

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [94] [Quantum King-Ring Domination in Chess: A QAOA Approach](https://arxiv.org/abs/2601.00318)
*Gerhard Stenzel,Michael Kölle,Tobias Rohe,Julian Hager,Leo Sünkel,Maximilian Zorn,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 本文提出一种名为量子国王-环支配（QKRD）的新基准，基于国际象棋战术位置，提供5000个具有结构化的实例，涵盖10-40量子比特规模，具备一热约束与空间局部性。该基准结合人类可解释的覆盖度量与经典启发式算法的内在验证，无需外部预言机即可评估算法性能。通过QKRD系统评估QAOA设计选择，发现保持约束的混合器（如XY、域墙）比标准混合器收敛快约13步（p<10^{-7}, d≈0.5），且无需惩罚参数调优；暖启动策略使收敛加速45步（p<10^{-127}, d=3.35），能量提升超过d=8；而条件风险价值（CVaR）优化则得到负面结果，能量更差（p<10^{-40}, d=1.21），无覆盖增益。内在验证显示QAOA优于贪心启发式12.6%，优于随机选择80.1%。研究证明，结构化基准能揭示在随机实例中被掩盖的问题导向型QAOA优势。所有代码、数据和实验成果均已公开，支持可复现的NISQ算法研究。


<details>
  <summary>Details</summary>
Motivation: 现有量子近似优化算法（QAOA）主要在无语义结构的合成随机实例（如MaxCut、TSP、SAT）上进行测试，这些实例缺乏真实世界问题中的实际约束和可解释性，难以反映算法在现实场景下的表现。为弥补这一缺陷，本文提出一个具有人类可解释性的结构化基准——量子国王-环支配（QKRD），其灵感来自国际象棋战术位置，旨在更真实地评估QAOA在具意义约束问题上的性能。

Method: 构建基于国际象棋战术位置的量子优化问题实例集，形成具有明确一热约束、空间局部性和可解释性的5,000个结构化实例；采用人类可读的覆盖度量指标与经典启发式算法进行内在对比验证；系统评估不同QAOA设计选择（如混合器类型、暖启动、CVaR优化）对收敛速度与能量性能的影响，并通过统计显著性检验分析结果。

Result: 约束保持型混合器（如XY、域墙）相比标准混合器显著加快收敛（约13步，p<10^{-7}）且无需惩罚参数调优；暖启动策略大幅缩短收敛步数（45步，p<10^{-127}），并带来显著能量改善（d=3.35）；CVaR优化反而导致能量恶化（p<10^{-40}）且无覆盖提升；在内在验证下，QAOA优于贪心算法12.6%，优于随机选择80.1%。

Conclusion: 结构化基准能够揭示在随机实例中被掩盖的问题导向型QAOA技术优势。本研究强调应发展更具现实意义的评估框架，以推动可复现的NISQ时代量子算法研究。所有资源已公开，支持后续研究。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\% and random selection by 80.1\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.

</details>


### [95] [Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models](https://arxiv.org/abs/2601.00391)
*Nouar AlDahoul,Aznul Qalid Md Sabri,Ali Mohammed Mansoor*

Main category: cs.LG

TL;DR: This paper presents an effective approach for human detection in aerial videos using automatic feature learning via optical flow combined with deep models (S-CNN, pretrained CNN, H-ELM). Pretrained CNN achieves 98.09% accuracy, H-ELM offers fast CPU-based training, and all methods outperform traditional handcrafted feature techniques.


<details>
  <summary>Details</summary>
Motivation: Traditional human detection methods rely on handcrafted features that are task-specific and sensitive to environmental changes like lighting, camera movement, and object size variations. To overcome these limitations, this paper explores automatic feature learning methods for more robust and efficient human detection in videos.

Method: The study combines optical flow with three deep learning models: supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine (H-ELM). These models are evaluated on the UCF-ARG aerial dataset, which contains videos from nonstatic aerial cameras with varying altitudes.

Result: The pretrained CNN achieved the highest average accuracy at 98.09%. S-CNN achieved 95.6% with softmax and 91.7% with SVM. H-ELM reached 95.9% accuracy. H-ELM trained in 445 seconds using a CPU, while S-CNN required 770 seconds with a GPU.

Conclusion: The proposed automatic feature learning approaches demonstrate strong performance in human detection under challenging aerial video conditions, with pretrained CNN showing the best accuracy and H-ELM offering efficient training on CPU.

Abstract: Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).

</details>


### [96] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: 本文提出E-GRPO，一种基于熵感知的组相对策略优化方法，通过合并低熵步骤以形成高熵步骤来提升SDE采样效率，并在其他步骤上使用ODE采样。同时引入多步组归一化优势计算，以改善奖励信号的清晰度。实验表明该方法在不同奖励设置下均有效。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在人类偏好对齐的流匹配模型中，因多步去噪过程中的稀疏和模糊奖励信号而受限。高熵步骤更利于探索，而低熵步骤则导致轨迹区分度差。

Method: 提出E-GRPO方法，通过合并连续低熵步骤形成高熵步骤，结合SDE与ODE采样策略；并设计多步组归一化优势，基于共享合并后SDE步骤的样本计算组相对优势。

Result: 在多种奖励设置下的实验验证了所提方法的有效性，显著提升了模型性能与采样效率。

Conclusion: E-GRPO通过熵感知的采样策略优化与组相对优势计算，有效缓解了多步去噪中的奖励模糊问题，为流匹配模型的人类偏好对齐提供了更高效的方法。

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [97] [A Comparative Analysis of Interpretable Machine Learning Methods](https://arxiv.org/abs/2601.00428)
*Mattia Billa,Giovanni Orlandi,Veronica Guidetti,Federica Mandreoli*

Main category: cs.LG

TL;DR: 本文对16种固有可解释的机器学习方法进行了大规模比较评估，涵盖从线性模型到决策树、EBM、SR和GOSDT等方法，在216个真实世界表格数据集上分析其性能。研究不仅关注整体表现，还根据数据结构特征（如维度、样本量、线性程度、类别不平衡）进行分层评估，并考察训练时间与分布偏移下的鲁棒性。结果表明：在回归任务中EBM表现优异；非线性场景下SR和IGANN表现突出；而GOSDT对类别不平衡敏感。研究为实践中平衡可解释性与预测性能提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在医疗、金融、法律等高风险领域广泛应用，模型可解释性和责任性成为关键问题。尽管可解释机器学习受到广泛关注，但针对表格数据的系统性评估仍较少，尤其缺乏基于数据结构特征的深入分析。

Method: 本研究对16种固有可解释模型进行大规模实验，覆盖216个真实表格数据集，采用分层分析策略，按数据维度、样本量、线性程度、类别不平衡等特征划分性能表现，并评估训练时间与分布偏移下的鲁棒性。

Result: EBM在回归任务中表现出色；SR和IGANN在非线性场景中表现更优；GOSDT对类别不平衡敏感；模型性能高度依赖于数据特性。

Conclusion: 该研究揭示了不同可解释模型在各类数据环境下的表现差异，为实践者选择适合任务需求的模型提供了实证依据，推动了对表格数据可解释建模的深入理解。

Abstract: In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.
  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.

</details>


### [98] [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)
*Hongbin Lin,Chenyang Ren,Juangui Xu,Zhengyu Hu,Cheng-Long Wang,Yao Shu,Hui Xiong,Jingfeng Zhang,Di Wang,Lijie Hu*

Main category: cs.LG

TL;DR: 提出了一种可控制的概念瓶颈模型（CCBMs），支持概念-标签级、概念级和数据级的细粒度编辑，利用影响函数的数学闭式近似实现无需重新训练的高效编辑，适用于真实世界中持续维护的动态环境。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于静态场景下的概念瓶颈模型，但实际应用中需要对模型进行持续维护，如删除错误或敏感数据、修正标注错误的概念或添加新样本，而现有的方法难以高效实现这些操作，尤其在大规模场景下。因此，亟需一种无需重新训练即可高效编辑的可编辑CBM。

Method: 提出基于影响函数的闭式近似方法，实现对概念-标签、概念和数据三个层级的可控制编辑，避免了传统重训练的高成本。

Result: 实验表明，所提出的CCBMs在效率和适应性方面表现优异，能够有效支持动态环境下的模型维护，具备实际应用价值。

Conclusion: CCBMs通过数学上严谨的闭式近似实现了高效、灵活的模型编辑，为构建动态且可信的概念瓶颈模型提供了切实可行的解决方案。

Abstract: Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.

</details>


### [99] [Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations](https://arxiv.org/abs/2601.00457)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 本文研究了在Mixture-of-Experts（MoE）模型中通过正交性损失实现专家多样性的有效性，发现该方法在多个方面均表现不佳：权重空间重叠（MSO）反而增加（最高达114%），激活空间重叠仍维持在较高水平（约0.6），性能改善不一致且波动大，且权重与激活正交性之间无显著相关性（r = -0.293, p = 0.523）。结果表明，权重空间正则化无法达成几何目标，也无法可靠提升性能，因此不适用于MoE中的专家多样性。


<details>
  <summary>Details</summary>
Motivation: 探究几何正则化（如正交性损失）在Mixture-of-Experts（MoE）模型中是否能有效促进专家专业化和多样性，以解决稀疏激活下的效率与性能平衡问题。

Method: 在MoE模型中引入正交性损失以强制专家间的多样性，系统评估其对权重空间重叠（MSO）和激活空间重叠的影响，并在多个数据集上测试性能变化，同时分析权重与激活正交性之间的相关性。

Result: 正交性损失未能减少权重空间重叠（MSO上升最多114%），激活空间重叠保持高位（~0.6），性能改善不一致（WikiText-103下降0.9%，TinyStories上升0.9%，PTB标准差>1.0），且权重与激活正交性无显著相关性（r = -0.293, p = 0.523）。

Conclusion: 权重空间的正交性正则化无法实现其几何目标，也未带来稳定的性能提升，因此不适合用于提升MoE模型中的专家多样性。

Abstract: Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.

</details>


### [100] [Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet](https://arxiv.org/abs/2601.00459)
*Saurav Sengupta,Scott Kilianski,Suchetha Sharma,Sakina Lashkeri,Ashley McHugh,Mark Beenhakker,Donald E. Brown*

Main category: cs.LG

TL;DR: 本文提出了一种基于1D UNet的自动标注小鼠脑电图（EEG）中棘波放电（SWD）的方法，通过数据增强显著提升性能，并与现有算法'Twin Peaks'对比，结果显示改进后的AugUNet1D在检测精度和特征相似性上均表现更优。模型已公开，可供研究者使用。


<details>
  <summary>Details</summary>
Motivation: 手动标注长时间连续采集的EEG记录中的事件耗时且效率低，尤其针对缺乏明显症状的癫痫发作相关事件如SWD。因此需要开发高效、准确的自动化标注方法以减少人工工作量。

Method: 比较了14种机器学习分类器在961小时小鼠EEG数据上的表现，最终选定1D UNet作为基础模型；通过数据增强（特别是缩放增强）优化训练数据，构建出AugUNet1D模型，并与Twin Peaks算法进行对比评估。

Result: AugUNet1D在检测SWD方面优于Twin Peaks，其识别出的事件在形态上更接近人工标注结果；数据增强中的缩放操作带来最大性能提升。

Conclusion: 所提出的AugUNet1D模型能够有效自动标注EEG中的SWD事件，具备高准确性和泛化能力，且预训练或未训练版本均已公开，可为后续神经科学研究提供有力工具。

Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.

</details>


### [101] [Laplacian Kernelized Bandit](https://arxiv.org/abs/2601.00461)
*Shuang Wu,Arash A. Amini*

Main category: cs.LG

TL;DR: 本文研究具有图结构关联的多用户上下文老虎机问题，提出一种联合惩罚项，结合图平滑性与个体粗糙度惩罚，通过再生核希尔伯特空间（RKHS）统一建模，将多用户问题转化为学习一个“提升”函数。提出基于高斯过程的算法 LK-GP-UCB 与 LK-GP-TS，实现结构化探索，并给出基于有效维度的高概率后悔界。实验表明方法在非线性场景下显著优于基线，在线性场景下也保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时处理非线性奖励函数和用户间的图同质性，缺乏统一的理论框架来融合图正则化与核方法。本文旨在建立一种能兼顾图结构与非线性建模的统一学习范式，以实现更高效的结构化探索。

Method: 引入基于RKHS距离的图平滑项与个体粗糙度惩罚，构造联合惩罚；证明其等价于单一多用户RKHS中的平方范数；显式推导出融合图拉普拉斯与基底臂核的再生核；将原问题重构为学习该新核上的单个“提升”函数；设计基于高斯过程后验的探索算法LK-GP-UCB和LK-GP-TS。

Result: 理论方面，提供了依赖于多用户核有效维度的高概率后悔界，避免对用户数量或环境维度的强依赖；实验方面，所提方法在非线性设置中显著优于线性和非图感知基线，在线性设置中仍具竞争力。

Conclusion: 本文构建了一个统一、理论严谨且实用的框架，将图正则化与核化老虎机相结合，为具有结构化用户关系的非线性上下文决策问题提供了高效解决方案。

Abstract: We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\{f_u\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \texttt{LK-GP-UCB} and \texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.

</details>


### [102] [Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study](https://arxiv.org/abs/2601.00525)
*Ravi Teja Pagidoju*

Main category: cs.LG

TL;DR: 本文研究了通过减少LSTM隐藏单元数量来压缩模型，发现将隐藏单元从128降至64可在保持甚至提升预测精度的同时，使模型缩小73%且准确率提高47%。


<details>
  <summary>Details</summary>
Motivation: 标准LSTM模型虽能准确预测零售业销售数据，但计算资源消耗大，对中小型零售企业难以应用。因此需要探索模型压缩方法以降低资源需求。

Method: 逐步减少LSTM模型的隐藏单元数（从128到16），使用Kaggle Store Item Demand Forecasting数据集进行实验，评估模型大小与预测精度之间的权衡。

Result: 当隐藏单元数降至64时，模型的均方百分比误差（MAPE）从23.6%降至12.4%，模型体积由280KB减至76KB，准确率提升47%，体积缩小73%。

Conclusion: 更大的LSTM模型并不一定带来更好的预测效果；适度压缩模型可显著降低资源消耗并提升性能，适用于中小零售企业部署。

Abstract: Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.

</details>


### [103] [Federated Customization of Large Models: Approaches, Experiments, and Insights](https://arxiv.org/abs/2601.00526)
*Yuchuan Ye,Ming Ding,Youjia Chen,Peng Cheng,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文探讨了在联邦学习框架下大规模模型的联邦定制，分析了其关键挑战。文章回顾了多种主流的大模型定制技术，包括全量微调、高效微调、提示工程、前缀微调、知识蒸馏和检索增强生成，并讨论了这些技术在联邦学习中的实现方式。此外，本文首次尝试将前缀微调应用于联邦学习场景，实验结果验证了其可行性，性能接近集中式方法。与三种其他联邦定制方法的对比显示，前缀微调具有竞争力的表现、良好的效率以及一致的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习框架下进行大规模模型定制面临诸多挑战，如数据隐私、通信开销和模型异构性。现有定制技术在联邦环境下的适用性和性能尚不明确，亟需探索高效、可行的定制方法以提升联邦学习中大模型的个性化能力。

Method: 系统回顾并评估多种大模型定制技术（如全量微调、高效微调、提示工程、前缀微调、知识蒸馏、检索增强生成）在联邦学习中的适用性。提出并实施联邦前缀微调方法，通过多轮联邦训练优化模型参数，并在多个客户端上协同完成定制任务。

Result: 联邦前缀微调在多个基准数据集上表现出与集中式方法相近的性能，验证了其可行性。与其他三种联邦定制方法相比，前缀微调在性能、效率和鲁棒性方面均表现优异，具备较强的实用潜力。

Conclusion: 前缀微调是一种适用于联邦学习环境的大规模模型定制有效方法，能够在保护数据隐私的同时实现高质量的个性化模型。未来可进一步探索其在更复杂场景下的应用与优化。

Abstract: In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.

</details>


### [104] [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)
*Ravi Teja Pagidoju,Shriya Agarwal*

Main category: cs.LG

TL;DR: 本研究提出一种基于扩散模型的云原生架构，用于自动生成定制化门店陈列图（planogram），将设计时间从平均30小时降至0.5小时，减少98.3%耗时，约束满足率达94.4%，成本降低97.5%，4.4个月实现盈亏平衡，系统可支持10,000并发请求，展示生成式AI在零售空间优化中的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统计划图创建耗时长（平均30小时/复杂布局），且依赖人工优化，效率低下；现有方法多为重新排列已有布局，缺乏对成功陈列模式的学习与泛化能力。因此亟需一种高效、自动化、可扩展的智能生成方案。

Method: 采用扩散模型结合云上训练（AWS）与边缘部署，通过学习多个零售门店的成功陈列数据，生成新配置；引入改进的损失函数以集成零售特定约束，实现约束驱动的生成。

Result: 设计时间减少98.3%（30→0.5小时），约束满足率94.4%，成本下降97.5%，4.4个月达盈亏平衡点，系统可线性扩展至10,000并发请求。

Conclusion: 该研究证明了生成式AI在自动化零售空间优化中的可行性和显著效益，云原生架构支持高效、可扩展的智能计划图生成。

Abstract: Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.

</details>


### [105] [Entropy Production in Machine Learning Under Fokker-Planck Probability Flow](https://arxiv.org/abs/2601.00554)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 本文提出一种基于熵的重新训练框架，利用非平衡随机动力学解释数据漂移，并通过时间演化的KL散度量化模型与数据之间的不匹配。该方法将不匹配的时间导数分解为熵平衡形式，包含由概率流驱动的非负熵产生项，从而启发了一种无需标签的熵触发重新训练策略，能够响应累积的不匹配而非延迟的性能崩溃。在受控的非平稳分类实验中，该方法实现了与高频重新训练相当的预测性能，同时相比每日和基于标签的策略，将重新训练事件减少了数量级。


<details>
  <summary>Details</summary>
Motivation: 现有漂移检测方法大多缺乏严格的动态解释，且难以在重新训练频率与操作成本之间取得平衡。因此需要一种具有理论基础、能有效指导重新训练策略的方法。

Method: 将部署期间的数据漂移建模为受福克-普朗克方程支配的概率流，使用时间演化的Kullback-Leibler散度衡量模型-数据不匹配，并推导出其时间导数的熵平衡分解，引入熵产生项作为重新训练的触发信号。

Result: 在非平稳分类实验中，熵触发重新训练策略在保持高性能的同时，将重新训练次数减少了一个数量级，显著优于每日和基于标签的策略。

Conclusion: 所提出的熵基重新训练框架提供了对数据漂移的动态解释，并实现高效、自适应的模型更新，为实际部署中的持续学习提供了理论支持与实用方案。

Abstract: Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.

</details>


### [106] [Adversarial Samples Are Not Created Equal](https://arxiv.org/abs/2601.00577)
*Jennifer Crawford,Amol Khanna,Fred Lu,Amy R. Wagoner,Stella Biderman,Andre T. Nguyen,Edward Raff*

Main category: cs.LG

TL;DR: 本文提出区分两类对抗性弱点：一类利用脆弱但有预测性的特征，另一类不直接依赖这些特征。作者引入基于集成的度量方法，评估对抗扰动对非鲁棒特征的操纵程度，并重新审视了对抗训练、锐度感知最小化及鲁棒数据集上的鲁棒性差距等现象。


<details>
  <summary>Details</summary>
Motivation: 现有理论（如Ilyas等人提出的非鲁棒特征理论）仅关注利用脆弱但有预测性特征的对抗样本，忽略了不直接使用这些特征的对抗样本，导致对对抗鲁棒性的评估存在局限。

Method: 提出一种基于集成的度量方法，用于量化对抗扰动对非鲁棒特征的操纵程度，并以此分析不同攻击生成的对抗样本构成。

Result: 该新视角揭示了对抗样本的多样性，解释了锐度感知最小化对鲁棒性的影响以及标准训练与对抗训练在鲁棒数据集上存在的鲁棒性差距。

Conclusion: 对抗鲁棒性应区分不同类型的对抗弱点，统一评估框架可能掩盖关键差异；引入的新度量有助于更精细地理解对抗攻击机制与模型鲁棒性。

Abstract: Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.

</details>


### [107] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: TeleDoCTR is a domain-specific, contextual troubleshooting system for telecom that automates ticket classification, retrieval of similar historical tickets, and generation of fault analysis reports, significantly improving accuracy and efficiency in resolving telecom issues.


<details>
  <summary>Details</summary>
Motivation: Ticket troubleshooting in telecom is time-consuming and relies heavily on human expertise, leading to delays and inefficiencies. Automating key steps in the troubleshooting workflow can enhance resolution speed and operational efficiency.

Method: TeleDoCTR integrates domain-specific ranking and generative models to perform three core tasks: routing tickets to the correct expert team (classification), retrieving semantically similar historical tickets (retrieval), and generating detailed fault analysis reports (generation).

Result: Evaluated on a real-world telecom dataset, TeleDoCTR outperforms existing state-of-the-art methods in accuracy and efficiency, demonstrating significant improvements in end-to-end ticket resolution.

Conclusion: TeleDoCTR effectively automates critical components of telecom ticket troubleshooting, reducing reliance on manual processes and enhancing both speed and precision in issue resolution.

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [108] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: 本文提出MBC模型，通过代码本优化策略压缩记忆库，并引入在线重置机制防止代码本崩溃，结合键值低秩适配技术高效利用压缩后的记忆表示，在保持高知识保留率的同时将记忆库大小减少至基准方法的0.3%。


<details>
  <summary>Details</summary>
Motivation: 现有记忆增强型持续学习方法在实际应用中面临记忆库不断膨胀的问题，导致存储和计算开销过大，亟需一种高效压缩机制以维持长期学习的稳定性与效率。

Method: 采用代码本优化策略压缩记忆库，结合在线重置机制防止代码本崩溃，并在LLM注意力层中引入键值低秩适配（Key-Value Low-Rank Adaptation）以高效利用压缩后的记忆表示。

Result: 在基准问答数据集上的实验表明，MBC将记忆库规模压缩至基线方法的0.3%，同时在在线适应学习过程中保持了高知识保留准确率。

Conclusion: MBC通过有效的记忆压缩与稳定机制，显著降低了持续学习中记忆库的存储负担，为大规模、持续更新的LLM应用提供了可行且高效的解决方案。

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [109] [HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts](https://arxiv.org/abs/2601.00583)
*Zihan Fang,Zheng Lin,Senkang Hu,Yanan Ma,Yihang Tao,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: cs.LG

TL;DR: HFedMoE提出一种异构Mixture-of-Experts（MoE）联邦学习微调框架，针对资源受限设备上大语言模型（LLM）微调的计算效率与性能挑战，通过专家重要性评估、基于信息瓶颈的专家子集自适应选择以及稀疏感知的聚合策略，有效解决了专家选择困难、设备算力异构性及全局聚合干扰等问题。实验表明，该方法在训练精度和收敛速度上优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习在微调大语言模型时面临计算资源不足的问题，尤其对移动等资源受限设备不友好；虽MoE模型可通过稀疏激活降低计算负担，但其在联邦学习中仍存在专家选择难、设备异构性导致负载不均、客户端专家子集与路由偏好差异引发全局聚合干扰等挑战。

Method: HFedMoE通过评估专家对本地微调的贡献来识别专家重要性，从信息瓶颈角度自适应选择符合各客户端计算预算的专家子集，并设计稀疏感知的加权聚合机制，以融合活跃专家与门控参数的更新。

Result: 实验验证了HFedMoE在训练准确率和收敛速度方面显著优于当前主流方法，具备更强的实用性与可扩展性。

Conclusion: HFedMoE为资源受限环境下的大语言模型联邦微调提供了一种高效且鲁棒的解决方案，通过个性化专家选择与智能聚合策略，在保障性能的同时显著降低计算开销。

Abstract: While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.

</details>


### [110] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: 本文提出一种无需训练的数学推理有效性检测方法，通过注意力模式的谱分析实现。将注意力矩阵视为动态图的邻接矩阵，提取四个可解释的谱诊断指标：费德尔值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵。这些指标在有效与无效数学证明之间表现出显著差异，跨七种不同架构的Transformer模型（Meta Llama、Alibaba Qwen、Microsoft Phi、Mistral AI）实验显示，该谱特征可达到高达Cohen's d = 3.30（p < 10^{-116}）的效果量，分类准确率达85.0–95.6%，且仅需单一阈值即可实现高精度。该方法无需训练数据或微调，能识别逻辑连贯性而非仅依赖形式验证器接受度，发现部分有效证明因技术缺陷被拒绝。此外，发现架构依赖性：Mistral-7B的滑动窗口注意力机制使判别信号从HFER转移至后期层平滑度（d = 2.09, p = 1.16 × 10^{-48}），表明注意力设计影响谱特征对推理有效性的捕捉能力。研究确立了谱图分析作为推理验证的原理性框架，可直接应用于幻觉检测与AI安全监控。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖训练数据或微调来检测大语言模型中的数学推理有效性，但存在数据依赖性强、泛化性差等问题。本文旨在开发一种无需训练、可普遍适用于多种模型架构的检测方法，以更本质地识别逻辑连贯性，提升对推理质量的评估能力。

Method: 将注意力矩阵视为动态图的邻接矩阵，基于图谱理论提取四类可解释的谱诊断指标：费德尔值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵。利用这些指标构建无监督判别模型，仅通过设定单一阈值实现有效/无效推理的分类。通过系统性标签校正验证其对逻辑连贯性的敏感性，并分析不同模型架构的影响。

Result: 在七种不同架构的Transformer模型上，谱诊断指标展现出极强的区分能力，效果量达Cohen's d = 3.30（p < 10^{-116}），分类准确率85.0–95.6%；校准后全数据集准确率可达93–95%。该方法无需训练，仅靠单阈值即可实现高精度。发现其能识别形式验证器拒绝但逻辑有效的证明，揭示其检测的是逻辑连贯性而非技术合规性。进一步发现模型架构影响判别特征：Mistral-7B中滑动窗口注意力导致判别信号由HFER转向后期层平滑度（d = 2.09, p = 1.16 × 10^{-48}）。

Conclusion: 谱图分析为大语言模型中的数学推理有效性提供了一种无需训练、可解释、普适性强的验证框架。该方法不仅能高效检测推理质量，还可揭示模型内部注意力机制对推理表征的影响，具有在幻觉检测与AI安全监控中的重要应用前景。

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


### [111] [Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load](https://arxiv.org/abs/2601.00604)
*Francisco Aguilera Moreno*

Main category: cs.LG

TL;DR: 本文提出一种基于机器学习的骑行时长预测方法，利用路线拓扑特征与运动员当前体能状态（由训练负荷指标如CTL、ATL表示）进行建模，替代传统依赖复杂物理参数的方法。在单人96次骑行数据的N-of-1研究中，结合拓扑与体能特征的Lasso回归模型达到MAE=6.60分钟，R²=0.922，体能指标使误差降低14%，验证了生理状态对骑行表现的重要影响。该模型支持分段动态预测，可用于实时赛事规划。


<details>
  <summary>Details</summary>
Motivation: 现有骑行时长预测依赖复杂的物理模型，需大量参数（如空气阻力系数、实时风速），对业余骑手不实用。亟需一种基于可获取数据的高效、精准预测方法。

Method: 采用机器学习方法，提取路线拓扑特征（如坡度、距离）和运动员历史训练负荷指标（CTL、ATL）作为输入，通过特征工程避免数据泄露，使用Lasso回归建模，实现骑行时长预测。

Result: 在单人数据集上，融合拓扑与体能特征的模型达到MAE=6.60分钟，R²=0.922；引入体能指标使误差较仅用拓扑特征下降14%（MAE=7.66分钟），证明生理状态显著影响骑行表现。模型支持分段预测，可用于动态赛事规划。

Conclusion: 本研究证明，结合路线拓扑与运动员体能状态的机器学习模型可有效预测骑行时长，且无需复杂物理参数，具有实际应用价值，尤其适用于业余骑手的训练与赛事准备。

Abstract: Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.

</details>


### [112] [Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization](https://arxiv.org/abs/2601.00611)
*Hareshkumar Jadav,Ranveer Singh,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 本文研究在下闭凸体上最大化非负、非单调的γ-弱DR-子模函数，提出一种结合Frank-Wolfe引导的连续贪心框架与γ感知双重贪心步骤的新算法，其近似保证随γ平滑变化，在γ=1时恢复0.401的近似因子，并在γ<1时优雅退化，优于已有结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理非单调γ-弱DR-子模最大化问题时，近似保证不够理想，尤其在γ<1时性能不佳。因此需要设计一种能平滑依赖于γ的高效算法，以提升对非单调性及弱子模性的处理能力。

Method: 结合Frank-Wolfe引导的连续贪心框架与γ感知的双重贪心步骤，通过连续优化与离散策略融合，有效应对非单调性并利用γ参数信息提升近似质量。

Result: 提出的方法在γ=1时达到0.401的近似因子，对于γ<1情况近似保证随γ平滑下降，且整体优于此前针对相同约束下的γ-弱DR-子模最大化的所有已知界，为该类问题提供了最优近似保证。

Conclusion: 本文提出的算法是目前非单调γ-弱DR-子模最大化在下闭凸体上的最优解，具有良好的理论保证和实际应用潜力，为相关优化问题提供了新范式。

Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.

</details>


### [113] [Do Chatbot LLMs Talk Too Much? The YapBench Benchmark](https://arxiv.org/abs/2601.00624)
*Vadim Borisov,Michael Gröger,Mina Mikhael,Richard H. Schreiber*

Main category: cs.LG

TL;DR: 本文提出YapBench，一个轻量级基准测试，用于量化大语言模型在简洁性优先提示下的过度生成问题。通过对比模型响应与最小必要答案的字符差，引入YapScore和YapIndex指标，评估模型在三类典型场景（澄清、事实问答、代码任务）中的冗余程度。实验覆盖76个模型，发现模型间冗余长度差异达一个数量级，并揭示不同类别下的特定失败模式。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在简单请求下常产生冗长、重复或格式化内容，增加认知负担和推理成本，且现有偏好训练和评估机制可能系统性奖励更长回答，导致过度生成问题。因此亟需一个可量化、跨模型比较的基准来评估和缓解这一现象。

Method: 构建YapBench基准，包含300多个英文提示，涵盖三类简洁性理想场景：(A) 需要简短澄清的模糊输入；(B) 简短稳定答案的事实性问题；(C) 仅需一行代码的编程任务。每项提供最小必要基线答案，使用字符级差值计算YapScore，通过类别中位数的加权平均得到YapIndex，实现无分词器依赖的跨模型比较。

Result: 76个模型评估显示，中位冗余长度相差约一个数量级，存在明显类别特异性失败模式：如对模糊输入出现‘真空填充’，对技术请求产生解释或格式开销。基准已发布并维护实时排行榜，支持持续监控模型冗余行为。

Conclusion: YapBench有效识别并量化了大语言模型在简洁性任务中的过度生成问题，揭示了模型行为的系统性偏差，为优化模型输出效率、改进训练与评估方法提供了可操作的工具与数据支持。

Abstract: Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.
  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.
  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.

</details>


### [114] [Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability](https://arxiv.org/abs/2601.00655)
*Kasra Fouladi,Hamta Rahmani*

Main category: cs.LG

TL;DR: 本文提出了一种基于可解释性引导的双目标优化框架IGBO，通过双目标公式化将结构化领域知识融入模型训练中。IGBO利用有向无环图（DAG）编码特征重要性层次，并采用时间集成梯度（TIG）测量特征重要性。为解决TIG计算中的分布外（OOD）问题，提出最优路径预言器以学习数据流形感知的积分路径。理论分析证明了收敛性和对小批量噪声的鲁棒性，实验结果表明IGBO在最小化精度损失的同时有效满足DAG约束，优于标准正则化基线。


<details>
  <summary>Details</summary>
Motivation: 现有模型在可解释性与性能之间难以平衡，且缺乏对特征重要性层次的显式建模能力。同时，传统特征重要性方法在分布外数据上表现不稳定，限制了其实际应用。因此需要一种能够融合领域知识、增强可解释性并提升鲁棒性的优化框架。

Method: 提出IGBO框架，将特征重要性层次建模为有向无环图（DAG），使用时间集成梯度（TIG）量化特征重要性；引入最优路径预言器（Optimal Path Oracle）以学习数据流形感知的积分路径，从而缓解分布外问题；采用双目标优化策略，在模型性能与可解释性约束间进行权衡。

Result: 理论分析表明该方法具有收敛性及对小批量噪声的鲁棒性；在时间序列数据上的实验证明，IGBO能有效施加DAG约束，且精度损失极小，显著优于标准正则化方法。

Conclusion: IGBO通过结合领域知识与可解释性引导的双目标优化，实现了高可解释性与良好性能的兼顾，尤其适用于需要明确特征重要性层级的任务场景。

Abstract: This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.

</details>


### [115] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 本文提出了一种名为Avatar Forcing的新框架，用于实现真正交互式的头部虚拟形象生成。该框架通过扩散强制机制，使虚拟形象能够在实时多模态输入（如语音和动作）下低延迟地响应用户的言语与非言语线索（如说话、点头、笑声），从而实现近似即时的互动体验。此外，作者设计了一种无需标签数据的直接偏好优化方法，利用合成的“缺失条件”样本进行训练，以学习富有表现力的反应。实验表明，该方法在保持约500毫秒低延迟的同时，相较基线模型提升了6.8倍的生成速度，并且生成的动画更受用户青睐（超过80%胜过基线）。


<details>
  <summary>Details</summary>
Motivation: 当前的对话头像生成模型大多只能产生单向回应，缺乏情感互动的真实感。主要挑战在于如何在因果约束下实现实时运动生成，以及如何在无额外标注数据的情况下学习生动的表情与反应。

Method: 提出Avatar Forcing框架，结合扩散强制机制处理实时多模态输入；引入直接偏好优化策略，通过构造丢弃用户条件的合成负样本，实现无监督表达性学习。

Result: 实现了约500毫秒的低延迟实时交互，比基线快6.8倍；生成的动画具有高度反应性和表现力，在用户偏好测试中胜出超过80%。

Conclusion: Avatar Forcing成功解决了实时交互与无监督表达性学习两大难题，显著提升了虚拟头像的互动真实感与响应能力，为虚拟通信与内容创作提供了高效可行的技术方案。

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [116] [IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning](https://arxiv.org/abs/2601.00677)
*Haonan Song,Qingchen Xie,Huan Zhu,Feng Xiao,Luxi Xing,Fuzhen Li,Liu Kang,Feng Jiang,Zhiyong Zheng,Fan Yang*

Main category: cs.LG

TL;DR: 提出IRPO框架，通过引入Bradley-Terry模型将配对式GRM的O(n^2)复杂度优化为点对点评分，提升推理效率并保持可解释性，在多个基准测试中达到SOTA性能，且在后训练评估中显著优于传统配对式GRM。


<details>
  <summary>Details</summary>
Motivation: 解决现有配对式生成奖励模型（GRMs）在与强化学习算法结合时存在的计算瓶颈问题，主要源于成对比较的高时间复杂度和重复采样或链式思维推理带来的额外开销。

Method: 提出一种新的强化学习框架Intergroup Relative Preference Optimization (IRPO)，利用Bradley-Terry模型将配对比较转化为点对点得分生成，实现任意数量候选响应的高效评估，同时保留可解释性和细粒度奖励信号。

Result: IRPO在多个基准测试中表现达到当前点对点GRMs的最先进水平，性能接近领先的配对式GRMs；在后训练评估中显著优于配对式GRMs，验证了其高效性和优越性。

Conclusion: IRPO通过引入Bradley-Terry模型有效缓解了配对式GRMs的计算瓶颈，实现了高效、可解释且高性能的奖励建模，为未来基于强化学习的生成模型优化提供了新路径。

Abstract: Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.

</details>


### [117] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE is a lightweight, swarm-based exploration framework for reinforcement learning that enhances policy-gradient methods by integrating particle-driven proposals and adaptive reward-variance cues. It achieves significant performance gains on challenging tasks (e.g., +46% on LunarLander-v3) and shows robustness under non-stationary rewards, outperforming PPO by +75 points on CartPole. Ablation studies confirm the importance of both the swarm and adaptive mechanisms. The method is simple, architecture-agnostic, and preserves stability across diverse environments.


<details>
  <summary>Details</summary>
Motivation: Effective exploration remains a key challenge in reinforcement learning, particularly in high-dimensional policy spaces or under non-stationary rewards. Existing methods often struggle with balancing exploration and stability, prompting the need for a lightweight, adaptable enhancement to standard policy-gradient algorithms.

Method: ARISE introduces a compact swarm-based exploration layer that blends policy actions with candidate trajectories sampled by particles in the action space. These particles are modulated adaptively using reward-variance signals to guide exploration dynamically.

Result: ARISE achieves +0.7% improvement on easy benchmarks like CartPole-v1, +46% on LunarLander-v3, +22% on Hopper-v4, and +75 points over PPO on CartPole under non-stationary rewards. It maintains stability on Walker2d and Ant. Ablation studies confirm the contributions of both the swarm component and adaptive mechanism.

Conclusion: ARISE provides a simple, architecture-agnostic approach to enhance exploration and robustness in RL without modifying core algorithmic structures, offering significant gains on challenging tasks and improved resilience under dynamic conditions.

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [118] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 本文提出一种基于贝叶斯推理的逆博弈框架，用于在缺乏明确目标信息的情况下，从多模态交互数据中推断智能体的目标，并量化不确定性，从而提升下游决策的安全性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有最大似然方法仅能提供点估计，无法衡量估计不确定性，导致规划决策可能过于自信而采取危险行为；为解决此问题，需引入不确定性建模以支持更安全的自主决策。

Method: 采用结构化变分自编码器（SVAE）结合可微分纳什博弈求解器，通过端到端训练学习隐藏目标的先验与后验分布，无需真实目标标签即可利用多模态观测数据实时生成后验样本。

Result: 实验表明该方法能有效学习目标的先验与后验分布，显著提升逆博弈推理质量，相比传统最大似然方法更安全且不牺牲效率；当轨迹信息不足时，多模态观测进一步降低不确定性。

Conclusion: 所提出的贝叶斯逆博弈框架能够有效处理未知目标下的不确定性，支持更安全、鲁棒的多智能体决策，尤其适用于传感器信息有限的真实场景。

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


### [119] [BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2601.00698)
*Maximilian Reinwardt,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: 本文提出了一种名为B-Spline Adaptive Tokenizer (BSAT)的新型无参数方法，通过B样条拟合时间序列，自适应地在高曲率区域放置标记，并将可变长度基函数表示为固定大小的标记。同时，提出了一种混合位置编码（L-RoPE），结合了可学习加性位置编码和具有逐层可学习基数的旋转位置嵌入，使各层能够关注不同的时间依赖关系。实验表明，该模型在高压缩率下表现优异，适用于内存受限场景。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的时间序列预测方法受限于自注意力的二次复杂度和均匀分块的僵硬性，这些可能与数据的语义结构不匹配，因此需要一种更灵活、高效的分块方法。

Method: 提出B-Spline Adaptive Tokenizer (BSAT)，利用B样条自适应分割时间序列，在高曲率区域放置更多标记；每个基函数以系数和位置表示为固定大小的标记；设计混合位置编码L-RoPE，结合加性可学习编码与逐层可学习基数的旋转位置嵌入。

Result: 在多个公开基准测试中，模型表现出色，尤其在高压缩率下性能突出，适合内存受限的应用场景。

Conclusion: BSAT通过自适应分块和灵活的位置编码，有效缓解了Transformer在长期时间序列预测中的计算与结构瓶颈，显著提升了高效建模能力。

Abstract: Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.

</details>


### [120] [Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL](https://arxiv.org/abs/2601.00728)
*Erin Carson,Xinye Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习（RL）的线性求解器自适应精度调优框架，将其建模为上下文相关老虎机问题，通过离散状态空间和增量动作价值估计选择最优精度配置，在精度与计算效率之间取得平衡。该方法应用于迭代精化求解线性系统 $Ax = b$，根据系统特征动态选择精度，利用Q表映射离散特征（如近似条件数、矩阵范数）到精度动作，并通过epsilon-greedy策略优化多目标奖励（兼顾准确性和计算成本）。实验表明，该方法显著降低计算开销，同时保持与双精度基准相当的精度。框架可推广至其他数值算法，且在未见数据上表现良好，是首个验证于新数据集的强化学习精度自动调优工作。


<details>
  <summary>Details</summary>
Motivation: 现有数值算法在精度设置上依赖经验或固定规则，难以在精度与计算效率间实现动态平衡。尤其在混合精度计算中，如何智能地选择不同步骤的精度配置仍缺乏系统方法。因此，需要一种自适应机制来自动优化精度配置，提升科学计算效率。

Method: 将精度调优建模为上下文相关老虎机问题，采用离散化状态空间表示系统特征（如条件数、矩阵范数），使用Q表存储状态-动作值，通过epsilon-greedy策略进行探索与利用，以最大化兼顾准确性和计算成本的多目标奖励函数，实现在线学习与动态决策。

Result: 实验结果表明，该框架能有效选择精度配置，显著降低计算成本，同时保持与双精度基准相当的求解精度；在多种未见数据上表现出良好的泛化能力，验证了其鲁棒性与实用性。

Conclusion: 本研究首次将强化学习应用于数值算法的精度自动调优，提出了一个可扩展的自适应框架，能够根据系统特征动态调整精度，实现性能与精度的协同优化。该方法为混合精度科学计算提供了新思路，具有广泛推广潜力。

Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.

</details>


### [121] [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)
*Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文提出了一种名为分布式创造性推理（DCR）的统一变分目标，将训练视为在解题路径概率测度上的梯度流。该框架揭示了基于正确性的目标如何导致推理路径分布的退化，并提供了防止这种退化的具体方法，实现了既正确又富有创造力的LLM设计。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型依赖于自举推理循环，通过采样多样化的思维链并强化得分最高的路径来优化正确性，但这一设计容易导致模型推理路径分布的坍缩，降低语义熵，削弱创造性解决问题的能力。

Method: 引入分布式创造性推理（DCR）框架，将训练建模为概率测度上的梯度流，统一了STaR、GRPO、DPO等方法及熵奖励等策略，作为该损失函数的特例。

Result: 提出了多样性衰减定理，描述了不同方法下多样性退化的模式；设计出能保证稳定且多样化策略收敛的方法；并提供可操作的实践方案，使LLM在保持正确性的同时具备创造性。

Conclusion: DCR是首个在理论上和实践中均能实现正确性与创造性平衡的LLM训练原则，为构建更具创造力的语言模型提供了坚实基础。

Abstract: State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.

</details>


### [122] [A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football](https://arxiv.org/abs/2601.00748)
*Sean Groom,Shuo Wang,Francisco Belo,Axl Rice,Liam Anderson*

Main category: cs.LG

TL;DR: 本文提出一种基于协变量依赖隐马尔可夫模型（CDHMM）的新方法，用于分析足球比赛中角球情境下的无球防守表现。该模型从球员追踪数据中直接推断出人盯人与区域防守分配，无需标签，从而实现对防守贡献的可解释性评估，并引入一种角色条件化的反事实分析方法（ghosting），提升对防守行为的评价精度。


<details>
  <summary>Details</summary>
Motivation: 传统防守评估指标难以捕捉复杂协作动作对对手进攻选择和成功率的影响；现有基于平均行为的反事实模型缺乏战术上下文，限制了对无球防守表现的准确分析。

Method: 采用协变量依赖隐马尔可夫模型（CDHMM），从球员追踪数据中推断时间分辨的防守角色分配（人盯人/区域防守），并构建角色条件化的鬼影化（ghosting）方法进行反事实分析，实现对防守贡献的精准归因。

Result: 所提方法能有效识别防守角色配置，提供上下文感知的基准对比，显著提升了对无球防守表现的可解释性评估能力，尤其在高度结构化的角球场景中表现优异。

Conclusion: 本研究为足球无球防守表现评估提供了新的建模框架，通过融合轨迹数据与角色条件化反事实分析，实现了更精细、可解释的防守贡献量化，具有推广至其他比赛情境的潜力。

Abstract: Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating "average" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.

</details>


### [123] [Categorical Reparameterization with Denoising Diffusion models](https://arxiv.org/abs/2601.00781)
*Samson Gourevitch,Alain Durmus,Eric Moulines,Jimmy Olsson,Yazid Janati*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散过程的软重参数化方法，用于处理类别变量的梯度优化。该方法利用高斯去噪过程中的闭式解，实现了无需训练的扩散采样器，从而支持反向传播。实验表明，该方法在多个基准测试中表现优异或优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的优化方法在处理类别变量时面临两大挑战：一是得分函数估计器虽无偏但噪声大；二是连续松弛方法虽能提供路径梯度但存在偏差且依赖温度参数。因此需要一种新的方法，在保持无偏性的同时降低噪声并避免温度依赖问题。

Method: 提出了一种基于扩散过程的软重参数化方法，通过高斯加噪和去噪过程对类别分布进行平滑近似。由于去噪器具有闭式解，可高效计算，并构建一个无需训练的扩散采样器，从而实现路径梯度的反向传播。

Result: 在多个基准任务上，所提方法表现出与现有方法相当甚至更优的优化性能，验证了其有效性与实用性。

Conclusion: 所提出的扩散基软重参数化方法为类别变量的梯度优化提供了一种高效、低噪声且无偏差的新途径，具有良好的应用前景。

Abstract: Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [124] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 本文提出一种推理感知的知识检索方法，通过粗到细的搜索策略，结合蒙特卡洛树搜索思想，提升大语言模型在多轮对话中的知识检索质量，使检索内容更符合对话逻辑结构，增强回复的信息量与创造性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在性能提升上依赖于语义相似性检索或推理能力改进，但缺乏有效整合两者的方法，导致知识检索与推理过程脱节，影响对话质量。

Method: 采用粗到细的知识检索框架：首先基于上下文确定知识库中相关子区域，确保其内部句子与话题一致；随后在该子区域内进一步筛选与推理过程相关的知识；全程使用受蒙特卡洛树搜索启发的搜索策略，利用关键词高效导航知识句。

Result: 在两个多轮对话数据集上的实验表明，该方法更贴近人类对话中的深层推理逻辑，显著提升了检索知识的多样性，从而生成更具信息量和创造性的回答。

Conclusion: 本研究证明了推理感知的知识检索能够有效融合检索与推理，为大语言模型在复杂对话任务中的表现优化提供了新思路。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [125] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 本研究提出一种基于微调大型语言模型（LLMs）的自动化抑郁筛查方法，针对尼日利亚使用尼日利亚皮钦语的群体。研究收集了432份尼日利亚青年（18-40岁）对与PHQ-9项目相关的心理体验问题的皮钦语语音回应，进行了转录、预处理、语义标注、俚语和习语解释及抑郁严重程度评分。三种LLMs（Phi-3-mini-4k-instruct、Gemma-3-4B-it、GPT-4.1）在该标注数据集上进行微调，结果显示GPT-4.1在定量评估中表现最佳，预测准确率达94.5%，且在定性评估中也表现出最高的文化适宜性、清晰度和上下文相关性。研究为在语言多样、资源有限环境中部署对话式心理健康工具提供了基础。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症负担重大，但筛查覆盖率低，主要受限于临床资源不足、污名化和语言障碍。传统工具如PHQ-9在高收入国家验证，但在尼日利亚等低收入国家因语言和文化差异难以适用，尤其当地民众广泛使用尼日利亚皮钦语及超过520种本地语言。因此亟需开发适应本地语言和文化的自动化抑郁筛查工具。

Method: 收集432份尼日利亚青年在18-40岁年龄段对心理体验问题的皮钦语语音回应；进行语音转录、数据清洗、语义标注、俚语与习语解释，并依据PHQ-9标准进行抑郁严重程度评分；将三个大型语言模型（Phi-3-mini-4k-instruct、Gemma-3-4B-it、GPT-4.1）在该数据集上进行微调；通过定量（准确率、精确率、语义一致性）和定性（清晰度、相关性、文化适宜性）方式评估模型性能。

Result: GPT-4.1在定量评估中表现最优，达到94.5%的PHQ-9严重程度预测准确率，显著优于Gemma-3-4B-it和Phi-3-mini-4k-instruct；在定性评估中，GPT-4.1生成的响应最清晰、最相关且最具文化适宜性。

Conclusion: 本研究成功构建了一个面向尼日利亚皮钦语使用者的自动化抑郁筛查系统，证明了微调大型语言模型在语言多样性与资源匮乏环境中的可行性与有效性，为未来在类似背景下推广智能心理健康干预提供了可复制的技术路径和实证基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [126] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 本文提出了一种基于不可逆信息处理和守恒定律约束的智能物理理论。通过引入守恒一致编码（CCE）框架，将信息与物理状态关联，定义智能为每纳特不可逆处理信息所产生的目标导向功。该理论揭示了信息摄入、不可逆计算和功提取的物理层级约束，解释了长期效率依赖于内部信息结构的保持，并推导出智能系统存在类似哥德尔不完备性的内在认知极限。应用于生物系统时，发现振荡和近临界动力学优化了信息保存、耗散与有用功之间的权衡，使大脑接近理论预测的高效工作状态。在架构层面，提出了连续动态电路理论，其中经典布尔逻辑是吸引子选择的特例，更一般的不变几何支持超越固定点逻辑的计算模式。最后，基于不可逆信息流和结构稳态，提出了人工智能安全的物理基础视角。整体上，该理论为智能提供了一个无载体依赖的统一物理解释。


<details>
  <summary>Details</summary>
Motivation: 传统智能理论多从信息或计算角度出发，缺乏对物理本质的深入理解。本文旨在建立一个以物理守恒定律为基础、涵盖信息处理、能量转换与目标导向行为的统一智能理论框架，填补智能作为物理现象的理论空白。

Method: 构建守恒一致编码（CCE）框架，将信息编码映射为由守恒律决定的稳定吸引子盆地；利用热力学与非平衡统计物理方法分析信息处理过程中的不可逆性；通过动力系统理论研究系统演化中信息结构的维持机制；结合神经科学与复杂系统建模，验证理论在生物系统中的适用性；发展连续动态电路模型，推导经典逻辑的涌现条件。

Result: 1. 智能被明确定义为单位不可逆信息处理产生的目标导向功；2. 发现长期效率依赖于内部信息结构的保留，引出自建模机制；3. 证明物理智能系统存在内在认知极限，类比于数学不完备性；4. 生物系统（如大脑）的动力学接近理论预测的高效操作区间；5. 连续动态电路理论表明布尔逻辑是吸引子选择的特例，更广义几何支持新型计算模式；6. 提出基于不可逆信息流与结构稳态的人工智能安全原则。

Conclusion: 智能是一种可被物理定律描述的现象，其核心在于不可逆信息处理过程中目标导向功的产生。该理论不仅统一了智能在不同载体中的表现形式，还为理解生物智能、设计高效人工系统以及保障人工智能安全提供了坚实的物理基础。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [127] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文研究城市最后一公里快递配送中人力资源工作负载平衡问题，提出一种多算法混合方法，综合考虑距离与工作量因素，优化快递员的任务分配，以实现每日工作量均衡。该方法结合k-means、进化算法、基于k-means初始化的递归分配及混合进化集成算法，在西班牙阿苏凯卡-德埃纳雷斯的真实场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的配送任务分配方式易导致工作负载不均，影响配送效率，因此需要一种能兼顾距离与工作量的优化方法来实现更公平高效的人力资源配置。

Method: 提出多算法混合方法，包括不同版本的k-means算法、进化算法、基于k-means初始化的递归分配策略以及混合进化集成算法，综合考虑配送点与工人位置间的距离及工作负荷，实现任务的最优分配。

Result: 在西班牙阿苏凯卡-德埃纳雷斯的真实配送场景中，所提方法显著改善了各配送员之间的任务负载均衡性，提升了整体配送效率，验证了其在实际应用中的有效性。

Conclusion: 通过融合多种算法并综合考虑距离与工作量因素，所提出的多算法方法能够有效解决城市最后一公里配送中的人力资源负载不平衡问题，具有良好的实用价值和推广前景。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [128] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 本文提出了一种基于规则的策略框架，用于13张牌的经典印度拉米游戏，引入新的手牌评估指标MinDist，通过计算手牌与最近有效配置之间的编辑距离来衡量完成度的结构接近性。该方法在计算效率上优化，结合动态剪枝和模式缓存实现精确计算，并在双人零和模拟框架中集成对手手牌建模。实验结果表明，基于MinDist的智能体在胜率上显著优于传统启发式方法，为算法化拉米策略设计提供了形式化且可解释的进展。


<details>
  <summary>Details</summary>
Motivation: 经典印度拉米游戏具有不完全信息和概率推理的特点，需要高效的组合决策机制。现有方法依赖于启发式规则，缺乏系统性和可解释性。因此，亟需一种更精确、可解释的手牌评估方法以提升策略性能。

Method: 提出并实现新指标MinDist，基于编辑距离量化手牌与有效配置的结构接近性；设计高效算法，利用动态剪枝和模式缓存进行精确计算；在双人零和模拟框架中引入对手手牌建模；采用统计假设检验评估策略效果。

Result: 基于MinDist的智能体在实证测试中表现出显著更高的胜率，优于传统启发式方法，验证了该框架的有效性与优越性。

Conclusion: MinDist框架为拉米游戏的算法策略设计提供了一个形式化、可解释且高效的解决方案，推动了基于规则的智能体在不完全信息博弈中的发展。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [129] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 该研究通过伊朗鸽楼案例，测试三种生成式AI模型（Midjourney v6、DALL-E 3、DreamStudio SDXL）在参考、适应和推测三个提示阶段对地方建筑智慧的解读能力。采用五维度评估框架（类型学、材料性、环境、真实性和文化特异性），发现AI能可靠复现几何图案，但误解材料与气候逻辑；参考图像提升真实感却限制创意，无参考则生成富有创意但文化模糊的结果。研究界定视觉相似与建筑推理之间的界限，提出计算地方性推理作为分析AI如何感知、扭曲与重构传统设计智慧的框架。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI如何理解并再现传统建筑中的地方性智慧，特别是其在形式与功能背后的深层文化与环境逻辑，以揭示AI在建筑设计中的认知边界与潜力。

Method: 选取伊朗鸽楼作为案例，使用Midjourney v6、DALL-E 3、DreamStudio SDXL三种扩散模型，在参考、适应、推测三类提示阶段生成图像，并基于类型学、材料性、环境、真实性和文化特异性五个维度进行评估。

Result: AI能准确复现几何形态，但常误读材料选择与气候适应逻辑；参考图像增强真实感但抑制创造力，无参考生成更具创新性但文化模糊的结果。

Conclusion: 生成式AI在视觉层面可模仿地方建筑形式，但在深层建筑推理方面存在局限。应建立‘计算地方性推理’框架，以系统评估和引导AI对传统设计智慧的理解与再创造。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [130] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar 是一个自主演化游戏机制的系统，用于自动游戏设计。它结合质量-多样性算法与大语言模型，探索多样化的游戏机制，并通过合成完整游戏来评估这些机制。游戏通过树搜索生成，评估标准是能否保持玩家技能水平的有序性（即强玩家持续胜过弱玩家）。实验表明，Mortar 生成的游戏具有多样性且可玩，其机制显著提升技能排序得分。通过消融实验和用户研究验证了各组件的作用及人类对生成游戏的接受度。


<details>
  <summary>Details</summary>
Motivation: 手动设计游戏机制耗时且依赖专家经验，缺乏自动化方法来高效探索多样且高质量的游戏规则。因此需要一种能够自主演化游戏机制并评估其有效性的系统。

Method: Mortar 使用质量-多样性算法与大语言模型生成候选游戏机制；通过树搜索将机制与档案中已有机制组合成完整游戏；以技能导向排序能力作为核心评价指标，衡量机制对游戏公平性和挑战性的贡献。

Result: Mortar 生成的游戏表现出良好的多样性与可玩性，所生成的机制显著提升了游戏中的技能排序得分。消融实验显示各模块对性能有重要影响，用户研究证实生成游戏获得积极反馈。

Conclusion: Mortar 成功实现了游戏机制的自主演化，能够生成高质量、多样且具备技能导向性的游戏，为自动游戏设计提供了有效路径。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [131] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: Mathesis 提出一种神经符号架构，通过将数学状态编码为高阶超图，并利用可微逻辑引擎（SRK）将约束映射到连续能量景观，实现基于能量最小化的证明搜索。该方法结合蒙特卡洛树搜索和进化证明搜索，由学习到的价值函数和语义统一引导，以解决大语言模型在复杂推理中的逻辑缺陷。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理中存在持续的逻辑错误，主要原因是缺乏内部公理框架。

Method: 将数学状态表示为高阶超图，使用可微逻辑引擎（SRK）构建能量函数，通过梯度信号训练超图变换器大脑，并结合蒙特卡洛树搜索与进化证明搜索进行多步推理。

Result: 实现了更鲁棒的逻辑推理能力，显著减少复杂问题中的推理错误，提升了证明搜索效率与准确性。

Conclusion: Mathesis 通过引入可微逻辑与能量最小化机制，有效缓解了大语言模型在复杂推理中的逻辑缺陷，为构建具备形式化推理能力的AI系统提供了新范式。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [132] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 本文研究了基于置信度的放弃预测在视频问答任务中对错误率的可控性，发现置信度阈值在分布内情况下能提供机制上的控制，实现平滑的风险-覆盖率权衡；但在分布外时，该控制能力下降，表明模型在面对新数据时的不确定性估计不可靠。


<details>
  <summary>Details</summary>
Motivation: 高风险场景下部署视觉语言模型需要选择性预测，即在不确定时放弃预测以避免重大错误。当前方法依赖置信度阈值进行放弃决策，但其在分布外是否仍有效尚不明确。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过调整置信度阈值（epsilon）观察误差率与覆盖率的变化，评估在分布内和分布外情况下的表现。

Result: 在分布内，置信度阈值能实现平滑的风险-覆盖率权衡，有效降低错误率；但在分布外，这种控制能力减弱，错误率上升，说明模型的不确定性估计在外部数据上不可靠。

Conclusion: 置信度基的放弃预测在分布内具有良好的可靠性，但在分布外条件下控制能力显著下降，提示需改进模型在未知场景下的不确定性感知能力。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [133] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 本研究探讨了大语言模型驱动的智能体在受到微弱群体划分线索（如“我们”与“他们”）影响时，可能产生群体间偏见，甚至将人类整体视为外群体。通过构建多智能体社会模拟实验，发现智能体在缺乏明确身份提示时会表现出系统性偏见；当某些对手被标记为‘人类’时，偏见虽减弱，但仅因智能体隐含地认为对方是真实人类而激活了‘人类规范’。这种依赖于信念的机制带来新攻击面——信念污染攻击（BPA），包括初始化阶段的配置污染（BPA-PP）和通过优化信念修正后缀进行记忆污染（BPA-MP）。实验验证了该偏见的存在及攻击的有效性。研究旨在揭示潜在风险，推动更安全的智能体设计。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型驱动的智能体是否会在微弱群体线索下产生对人类整体的群体间偏见，并识别其内在机制与可利用漏洞，以促进安全智能体系统的设计。

Method: 构建基于分配决策与显式收益权衡的多智能体社会模拟环境，通过控制变量测试智能体在不同群体线索下的行为表现；引入信念污染攻击（BPA）机制，包括配置污染（BPA-PP）和记忆污染（BPA-MP）两种形式，评估其对人类规范脚本的破坏效果；开展多组实验验证偏见存在性与攻击有效性。

Result: 实验表明：1）智能体在最小群体线索下会表现出一致的群体间偏见；2）人类标签虽能缓解偏见，但依赖于智能体对真实人类存在的信念；3）信念污染攻击（BPA）可有效抑制人类规范脚本，重新激活对人类的外群体偏见；4）该现象在多种设置中均显著存在，具有普遍性与严重性。

Conclusion: 本研究揭示了智能体在群体认知结构下可能对人类整体形成系统性偏见，并暴露了基于信念依赖机制的安全漏洞。提出信念污染攻击（BPA）作为验证手段，强调需在智能体的初始配置与长期记忆边界实施防御策略。研究目的为提升智能体系统的安全性与伦理可靠性，而非鼓励滥用。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [134] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 本文将流动性博弈与理性蜂群理论结合，提出一种金融蜂群模型，通过差额奖励机制在马尔可夫团队博弈框架下实现独立交易者在追求自身利益的同时促进整体市场流动性，无需协调或共谋，达成个体盈利与市场效率的双重目标。


<details>
  <summary>Details</summary>
Motivation: 旨在解决金融市场上独立交易者如何自组织以提升市场稳定性和流动性的问题，并借鉴群体智能中的博弈论方法来解释理性个体行为如何促成集体效用。

Method: 采用马尔可夫团队博弈框架，引入差额奖励机制，构建一个由独立交易者组成的理性蜂群模型，其集体目标是最大化市场流动性。

Result: 证明了个体以流动性为导向的行为在无协调或共谋的情况下仍能有效提升整体市场流动性，实现了个体收益与市场效率的协同优化。

Conclusion: 该金融蜂群模型为研究独立、理性的金融市场参与者如何自发形成高效市场结构提供了理论支持，具有重要的应用价值和推广潜力。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [135] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt is a bio-inspired self-healing framework for Distributed Computing Continuum Systems (DCCS), modeling biological healing phases—Hemostasis, Inflammation, Proliferation, and Remodeling—into four computational layers: Containment, Diagnosis, Meta-Cognitive, and Knowledge. It uses Language Model-powered agents to autonomously detect faults, diagnose root causes, adaptively recover, and consolidate knowledge with minimal human intervention. Evaluated on public fault datasets using multiple LMs, ReCiSt achieves resilience within tens of seconds and maintains low agent CPU usage (≥10%), demonstrating strong fault analysis depth and effective scalability.


<details>
  <summary>Details</summary>
Motivation: Modern DCCS face frequent faults due to their complexity, heterogeneity, mobility, and dynamic environments. Existing resilience strategies lack scalability, adaptability, and autonomy. Inspired by the self-healing mechanisms in human biological systems, there is a need for intelligent, adaptive, and self-regulated frameworks that can sustain service continuity with minimal human intervention.

Method: ReCiSt maps biological healing phases to four computational layers: Containment (fault isolation), Diagnosis (causal analysis), Meta-Cognitive (adaptive recovery), and Knowledge (long-term learning). It employs LM-driven agents to process heterogeneous logs, infer root causes, refine reasoning paths, and reconfigure resources. The framework operates autonomously across distributed nodes with micro-agents handling specific tasks.

Result: ReCiSt demonstrates effective self-healing within tens of seconds across multiple LMs, with agent CPU usage as low as 10%. It shows robustness in handling uncertainties and exhibits high analytical depth. The number of micro-agents invoked scales efficiently with system complexity, confirming its adaptability and scalability. No direct baseline comparison was performed due to the novelty of the approach.

Conclusion: ReCiSt successfully emulates biological self-healing in DCCS through an intelligent, layered agentic architecture powered by language models. It provides a scalable, adaptive, and autonomous solution for achieving resilience in complex, dynamic computing environments, paving the way for next-generation self-managing systems.

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [136] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应架构，结合动态学习与历史经验优化，显著提升社交平台协同不真实行为检测的准确性与效率。相比现有方法，其在真实数据集上实现87.3% F1-score，较最强基线提升15.2%，减少68%人工标注需求，并提速2.8倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖表面相关性分析、静态参数设置且需大量人工标注，难以应对复杂多变的协同行为检测挑战。

Method: 提出自适应因果协调检测（ACCD）框架，包含三阶段：1）自适应收敛交叉映射（CCM）识别账户间真实因果关系；2）结合不确定性采样的主动学习半监督分类，降低标注负担；3）基于历史经验的自动化验证模块，实现结果自验证与优化。

Result: 在Twitter IRA、Reddit协调痕迹及多个主流机器人检测基准上测试，F1-score达87.3%，优于最强基线15.2%；人工标注减少68%，处理速度提升2.8倍。

Conclusion: ACCD提供了一种更准确、高效、高度自动化的端到端解决方案，具有显著实践价值和广泛应用前景。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [137] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 本文将计算语言学中的语义空间推理扩展至团队运动中的战术决策，将球员视为词汇、团队配合视为语义表达，通过多维向量建模球员属性，并以上下文加权生成团队语义表示。战术模板（如高位逼抢、反击等）被编码为向量，通过距离度量评估与团队配置的契合度，实现战术适配与对手弱点识别。基于Python的原型系统可生成可解释、动态调整的策略建议，并提供属性层面的诊断分析。该框架具有跨领域通用性，适用于篮球、冰球、协作机器人及人机协同等场景，未来方向包括真实数据融合、预测模拟与人机混合智能。


<details>
  <summary>Details</summary>
Motivation: 传统战术分析缺乏对团队整体动态和个体贡献的量化建模，难以实现动态适应与可解释推荐。本研究旨在将自然语言处理中的语义空间思想引入体育战术决策，提升策略制定的科学性与透明度。

Method: 将球员表示为包含技术、身体、心理属性的多维向量；通过上下文加权聚合形成团队语义表征；将战术模板映射为向量，利用向量距离衡量战术适配度与对手 exploit 能力；构建基于Python的原型系统实现动态策略推荐与诊断分析。

Result: 原型系统成功生成了可解释且自适应的战术建议，能识别关键属性短板并提出优化方向；在模拟环境中验证了战术匹配度的有效性与实用性；展示了跨领域应用潜力。

Conclusion: 该方法为团队战术决策提供了新的语义化建模范式，具备良好的可解释性、动态适应性和跨领域推广价值，未来需进一步整合真实数据、发展预测模型并探索人机协同智能。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [138] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 本文研究了推理模型在推理过程中是否会出现“顿悟”时刻，发现此类中段推理转变极为罕见，且不会随训练进展增加，极少提升准确率，表明它们并非模型自我修正的内在机制。相反，这些转变是推理不稳定的症状；但通过在高熵状态下人为触发外部转变，可显著提高准确性。


<details>
  <summary>Details</summary>
Motivation: 探究推理模型是否存在类似人类的‘顿悟’时刻，以及这种中段推理转变是否有助于提升模型性能。

Method: 分析超过100万条推理轨迹，涵盖数百个训练检查点、三个推理领域、多种解码温度和模型架构，系统检测中段推理转变，并评估其对准确率的影响。

Result: 中段推理转变非常罕见，不随训练增强，且很少提升准确率；但在模型不确定性较高时，人为触发外部转变可有效提升性能。

Conclusion: 中段推理转变是模型推理不稳定的表现，而非内在的自我修正能力；通过外部干预可利用其提升性能。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [139] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出一种成本效益高的框架，通过难度感知的直接偏好优化来缓解多模态大模型中的幻觉问题。该方法包含两个核心组件：难度估计和难度感知训练。难度估计利用具有互补生成与对比目标的预训练视觉-语言模型，通过分布感知投票策略生成鲁棒的难度评分，无需额外训练；难度感知训练则根据估计的难度重新加权偏好对，降低简单样本权重、增强困难样本的重要性，从而减轻过拟合。实验表明，DA-DPO在多个标准基准上显著提升模型对幻觉的鲁棒性和泛化能力，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态直接偏好优化方法因偏好数据难度不平衡而易产生过拟合，模型倾向于过度关注易于区分的偏好对，导致细粒度幻觉抑制效果差，整体性能下降。

Method: DA-DPO包含两个模块：(1) 难度估计——利用具备生成与对比双重目标的预训练视觉-语言模型，通过分布感知投票策略生成难度分数；(2) 难度感知训练——基于估计的难度对偏好对进行重加权，降低易样本权重，提升难样本权重，实现更均衡的学习过程。

Result: DA-DPO在多个标准多模态基准上均表现出更强的抗幻觉能力与更好的泛化性能，且无需新增数据或额外微调阶段，计算开销低，具备良好的实用性。

Conclusion: DA-DPO通过引入难度感知机制，有效缓解了多模态偏好优化中的过拟合问题，提升了模型对复杂、细微差异的捕捉能力，为高质量多模态生成提供了高效可靠的解决方案。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [140] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM 是一种融合视觉与领域知识的大型语言模型框架，用于提升行人过街行为推理的泛化能力。通过结合 LLaVA 提取的视觉特征、文本数据和交通领域知识，对 LLaMA-2-7B 模型进行低秩适应（LoRA）微调，实现了 82.0% 的平衡准确率，显著优于传统统计和监督学习方法。视觉增强模块带来 2.9% 的性能提升，领域知识整合带来额外 4.1% 提升。在跨站点零样本测试中，PedX-LLM 达到 66.9% 的平衡准确率，比基线方法高出至少 18 个百分点；仅需五个验证样例的少样本学习即可提升至 72.2%。结果表明，该模型具备强泛化能力，能模拟人类决策逻辑，克服纯数据驱动方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（如统计模型和监督学习）泛化能力差，难以适应新场景。尽管大语言模型（LLM）提供了语义与上下文感知的推理潜力，但现有应用缺乏领域特定适应性和视觉上下文理解。因此，亟需一种能够结合视觉信息与领域知识、实现通用行为推理的新范式。

Method: 提出 PedX-LLM 框架，利用 LLaVA 从图像中提取视觉特征，融合文本数据与交通领域知识，基于 LLaMA-2-7B 模型采用低秩适应（LoRA）进行微调，实现对行人过街行为的推理。通过跨站点划分进行零样本与少样本评估，验证其泛化性能。

Result: PedX-LLM 在基准测试中达到 82.0% 的平衡准确率，优于现有最优方法。视觉增强贡献 2.9% 性能提升，领域知识整合贡献 4.1% 提升。在五个未见站点的零样本测试中达到 66.9% 平衡准确率，比基线高至少 18 个百分点；引入五个验证样例的少样本学习可进一步提升至 72.2%。

Conclusion: PedX-LLM 通过融合视觉与领域知识，实现了从特定站点模式识别向通用行为推理的转变，展现出强大的跨场景泛化能力，证明了语义与上下文感知的推理机制在行人过街行为建模中的有效性，为智能交通系统提供了一种更鲁棒、可迁移的解决方案。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [141] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) is a novel framework that automates the creation of DomiKnowS programs from free-form task descriptions, reducing development time from hours to 10-15 minutes and enabling both experts and non-experts to build neuro-symbolic models efficiently.


<details>
  <summary>Details</summary>
Motivation: Existing frameworks like DomiKnowS require users to be proficient in specific syntax, which limits accessibility and increases development time. There is a need for a system that can translate natural language task descriptions into executable neuro-symbolic programs without requiring deep library expertise.

Method: ADS employs an agentic workflow that breaks down the program creation process into iterative steps: generating, testing, and refining individual DomiKnowS components. It supports optional human-in-the-loop feedback, allowing experts to improve intermediate outputs while enabling non-experts to use the system with minimal training.

Result: ADS significantly reduces the time required to develop neuro-symbolic programs, enabling rapid prototyping by both experienced users and beginners. It achieves full program generation from natural language input with high accuracy and flexibility.

Conclusion: AgenticDomiKnowS effectively democratizes access to neuro-symbolic programming by eliminating the need for deep syntax knowledge, making it faster and more accessible for a broader user base.

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>
